{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVg781wTfKJm7qR5uaINgZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kodai-utsunomiya/memorization-and-generalization/blob/main/Disentangling_feature_and_lazy_training_in_deep_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# アーキテクチャ"
      ],
      "metadata": {
        "id": "wYZDDacUMJwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"green\"> `FC` クラス </font>\n",
        "\n",
        "### ネットワークの構造\n",
        "\n",
        "1. **入力層**: 次元数 $d$ の入力を受け取る．\n",
        "2. **隠れ層**: 層数 $L$ の隠れ層があり，各隠れ層のユニット数は $h$．\n",
        "3. **出力層**: 最終層は出力がスカラー値である 1 次元のベクトルを生成．\n",
        "\n",
        "<br>\n",
        "\n",
        "### 層ごとの計算\n",
        "\n",
        "1. **初期化**:\n",
        "   - 隠れ層 $i$ の重み行列 $W_i$ は，次のように初期化：\n",
        "     \n",
        "     $\n",
        "     W_i \\sim \\mathcal{N}(0, 1)\n",
        "     $\n",
        "\n",
        "     ここで，$W_i$ のサイズは $ h \\times \\text{hh}_{i}$ ．\n",
        "     \n",
        "     $\\text{hh}_{i} $ は前の層の出力ユニット数．\n",
        "\n",
        "   - メモリ効率を考慮し，重み行列を分割：\n",
        "     \n",
        "     $ W_i = $\n",
        "\n",
        "     \\begin{bmatrix}\n",
        "     W_i^{(0)} \\\\\n",
        "     W_i^{(1)} \\\\\n",
        "     \\vdots \\\\\n",
        "     W_i^{(n-1)}\n",
        "     \\end{bmatrix}\n",
        "     \n",
        "     各部分行列 $W_i^{(j)}$ はサイズ $m \\times \\text{hh}_{i}$．ここで，$m$ は分割サイズ．\n",
        "\n",
        "<br>\n",
        "\n",
        "2. **順伝播計算**:\n",
        "   - 入力テンソル $x$ は，初期の隠れ層で次のように変換：\n",
        "     \n",
        "     $\n",
        "     x^{(0)} = x W_0^T / \\sqrt{d}\n",
        "     $\n",
        "\n",
        "     ここで，$W_0$ は最初の隠れ層の重み行列．バイアス項がある場合，次のように加算：\n",
        "     \n",
        "     $\n",
        "     x^{(0)} = x^{(0)} + b_0\n",
        "     $\n",
        "\n",
        "     その後，活性化関数 $ \\sigma $ を適用：\n",
        "     \n",
        "     $\n",
        "     x^{(1)} = \\sigma(x^{(0)})\n",
        "     $\n",
        "\n",
        "   - 次の隠れ層も同様に計算．一般的に，隠れ層 $i$ の計算は次のようになる：\n",
        "     \n",
        "     $\n",
        "     x^{(i)} = x^{(i-1)} W_i^T / \\sqrt{h}\n",
        "     $\n",
        "\n",
        "     ここで，$W_i$ は現在の層の重み行列．バイアス項がある場合，次のように加算：\n",
        "\n",
        "     $\n",
        "     x^{(i)} = x^{(i)} + b_i\n",
        "     $\n",
        "\n",
        "     そして，活性化関数を適用：\n",
        "     \n",
        "     $\n",
        "     x^{(i+1)} = \\sigma(x^{(i)})\n",
        "     $\n",
        "\n",
        "   - 最終層では，次のように計算：\n",
        "     \n",
        "     $\n",
        "     x^{(L)} = x^{(L-1)} W_L^T / h + b_L\n",
        "     $\n",
        "     \n",
        "     ここで，$W_L$ は最終層の重み行列．出力テンソル $x$ を 1 次元に変換して返す：\n",
        "\n",
        "     $\n",
        "     x^{(L)} = x^{(L)} \\text{view}(-1)\n",
        "     $\n",
        "\n",
        "<br>\n",
        "\n",
        "### 要点\n",
        "\n",
        "- **入力層**: $d$ 次元の入力を受け取る．\n",
        "- **隠れ層**: 各層で線形変換と活性化関数を適用．線形変換は以下のようにスケーリング：\n",
        "  \n",
        "  $\n",
        "  x^{(i)} = x^{(i-1)} W_i^T / \\sqrt{h}\n",
        "  $\n",
        "- **出力層**: 最終層で線形変換を行い，スカラー値に変換：\n",
        "  \n",
        "  $\n",
        "  x^{(L)} = x^{(L-1)} W_L^T / h + b_L\n",
        "  $"
      ],
      "metadata": {
        "id": "gBByw7_uWcoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"green\">`Wide_ResNet` クラス </font>\n",
        "\n",
        "### 1. ネットワークの構造\n",
        "\n",
        "- 初期の畳み込み層\n",
        "- 複数の Wide-ResNet ブロックからなるレイヤー\n",
        "- 最終的な線形層\n",
        "\n",
        "<br>\n",
        "\n",
        "### 2. 初期の畳み込み層\n",
        "\n",
        "最初に入力データ $ x $ に対して，畳み込み演算を行う：\n",
        "\n",
        "$ \\mathbf{z}_1 = \\text{conv}(x) $\n",
        "\n",
        "ここで，`conv` はカーネルサイズ $ 3 \\times 3 $，ストライド $ 1 $，パディング $ 1 $ の畳み込み演算．出力のチャネル数は $ nStages[0] $．\n",
        "\n",
        "<br>\n",
        "\n",
        "### 3. Wide-ResNet レイヤー\n",
        "\n",
        "`Wide_ResNet` は，複数の `wide_basic` ブロックからなるレイヤーを持つ．各レイヤーは以下のように定義：\n",
        "\n",
        "- **ブロック数**: $ n $\n",
        "- **ストライド**: 最初のブロックのストライドは `stride` で指定し，以降はすべてストライド $ 1 $\n",
        "\n",
        "各レイヤー $ l $ は以下のように定義：\n",
        "\n",
        "$ \\mathbf{z}_l = \\text{layer}_l(\\mathbf{z}_{l-1}) $\n",
        "\n",
        "ここで，`layer` は `self._wide_layer` メソッドによって定義し，複数の `wide_basic` ブロックがストライドに従って連結．\n",
        "\n",
        "<br>\n",
        "\n",
        "### 4. Wide-ResNet ブロック\n",
        "\n",
        "`wide_basic` ブロック内での処理は次のように表される：\n",
        "\n",
        "$ \\mathbf{y} = \\text{conv2}(\\text{act}(\\text{conv1}(\\mathbf{x}))) $\n",
        "\n",
        "ここで，$\\text{conv1}$ と $\\text{conv2}$ はそれぞれカーネルサイズ $ 3 \\times 3 $ の畳み込み層であり，$\\text{act}$ は活性化関数．\n",
        "\n",
        "ショートカット接続の処理は次のように行う：\n",
        "\n",
        "$ \\text{shortcut} = \\text{conv}_{shortcut}(\\mathbf{x}) $\n",
        "\n",
        "（ストライドやチャネル数が異なる場合のみ，1x1 畳み込みを適用．）\n",
        "\n",
        "最終的な出力は，以下のように角度 $ \\theta $ に基づく線形結合で計算：\n",
        "\n",
        "$ \\mathbf{z}_\\text{out} = \\cos(\\theta) \\cdot \\text{shortcut} + \\sin(\\theta) \\cdot \\mathbf{y} $\n",
        "\n",
        "ここで，角度 $\\theta$ は `mix_angle` に基づいて計算され，ラジアンに変換：\n",
        "\n",
        "$ \\theta = \\frac{\\text{mix_angle} \\times \\pi}{180} $\n",
        "\n",
        "<br>\n",
        "\n",
        "### 5. 最終線形層\n",
        "\n",
        "最終的な特徴マップ $\\mathbf{z}_\\text{final}$ は，全てのレイヤーを通過した後にフラット化し，平均化：\n",
        "\n",
        "$ \\mathbf{z}_\\text{flat} = \\text{flatten}(\\mathbf{z}_\\text{final}) $\n",
        "\n",
        "$ \\mathbf{z}_\\text{avg} = \\text{mean}(\\mathbf{z}_\\text{flat}, \\text{dim}=2) $\n",
        "\n",
        "最後に線形変換を適用し，クラス数 $ \\text{num_classes} $ に基づく出力を得る：\n",
        "\n",
        "$ \\mathbf{z}_\\text{output} = \\mathbf{z}_\\text{avg} \\cdot \\frac{\\mathbf{W}}{h} + \\mathbf{b} $\n",
        "\n",
        "ここで，$\\mathbf{W}$ は最終線形層の重み，$h$ は重みのサイズ，$\\mathbf{b}$ はバイアス．\n",
        "\n",
        "<br>\n",
        "\n",
        "### 6. 出力のフラット化\n",
        "\n",
        "もし最終的な出力の次元が $1$ の場合，出力をフラット化：\n",
        "\n",
        "$ \\mathbf{z}_\\text{output} = \\text{flatten}(\\mathbf{z}_\\text{output}, \\text{dim}=0) $\n",
        "\n",
        "<br>\n",
        "\n",
        "### まとめ\n",
        "\n",
        "Wide-ResNet の全体的な流れ：\n",
        "\n",
        "1. **初期の畳み込み層**:\n",
        "   $ \\mathbf{z}_1 = \\text{conv}(x) $\n",
        "\n",
        "2. **Wide-ResNet レイヤー**:\n",
        "\n",
        "   $ \\mathbf{z}_l = \\text{layer}_l(\\mathbf{z}_{l-1}) \\text{ for } l = 1, 2, 3 $\n",
        "\n",
        "3. **Wide-ResNet ブロック**:\n",
        "\n",
        "   $ \\mathbf{z}_\\text{out} = \\cos(\\theta) \\cdot \\text{shortcut} + \\sin(\\theta) \\cdot \\mathbf{y} $\n",
        "\n",
        "4. **最終線形層**:\n",
        "\n",
        "   $ \\mathbf{z}_\\text{avg} = \\text{mean}(\\text{flatten}(\\mathbf{z}_\\text{final}), \\text{dim}=2) $\n",
        "\n",
        "   $ \\mathbf{z}_\\text{output} = \\mathbf{z}_\\text{avg} \\cdot \\frac{\\mathbf{W}}{h} + \\mathbf{b} $\n",
        "\n",
        "5. **出力のフラット化**（必要に応じて）:\n",
        "\n",
        "   $ \\mathbf{z}_\\text{output} = \\text{flatten}(\\mathbf{z}_\\text{output}, \\text{dim}=0) $"
      ],
      "metadata": {
        "id": "dnoVvgCoamI2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EiVUBkeAKWyg"
      },
      "outputs": [],
      "source": [
        "# pylint: disable=E1101, C, arguments-differ\n",
        "\"\"\"\n",
        "Defines three architectures:\n",
        "- Fully connecetd `FC`\n",
        "- Convolutional `CV`\n",
        "- And a resnet `Wide_ResNet`\n",
        "\"\"\"\n",
        "import functools\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\"\"\"\n",
        "全結合ネットワーク（Fully Connected Network, FC）のクラスを定義．\n",
        "このネットワークは，任意の層数 L を持ち，各層のユニット数は h で指定される．\n",
        "活性化関数 act は任意に指定可能で，バイアス項の有無も指定可能．\n",
        "\"\"\"\n",
        "\n",
        "class FC(nn.Module):\n",
        "    def __init__(self, d, h, L, act, bias=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # ネットワークの初期化\n",
        "        hh = d  # 入力の次元数\n",
        "        for i in range(L):\n",
        "            # 隠れ層の重み行列を正規分布で初期化\n",
        "            W = torch.randn(h, hh)\n",
        "\n",
        "            # メモリ効率を考慮し，重み行列を部分行列に分割して ParameterList に格納\n",
        "            # next two line are here to avoid memory issue when computing the kerne\n",
        "            n = max(1, 128 * 256 // hh)  # 分割サイズを計算\n",
        "            W = nn.ParameterList([nn.Parameter(W[j: j+n]) for j in range(0, len(W), n)])\n",
        "\n",
        "            # 分割した重み行列をレイヤーとして登録\n",
        "            setattr(self, \"W{}\".format(i), W)\n",
        "\n",
        "            # バイアス項が指定されている場合は，それをゼロで初期化して登録\n",
        "            if bias:\n",
        "                self.register_parameter(\"B{}\".format(i), nn.Parameter(torch.zeros(h)))\n",
        "\n",
        "            # 次のレイヤーの入力次元は現在の隠れ層のユニット数になる\n",
        "            hh = h\n",
        "\n",
        "        # 最終層の重み行列を初期化（出力がスカラー値なので次元は (1, h)）\n",
        "        self.register_parameter(\"W{}\".format(L), nn.Parameter(torch.randn(1, hh)))\n",
        "\n",
        "        # バイアス項が指定されている場合は，最終層のバイアスをゼロで初期化\n",
        "        if bias:\n",
        "            self.register_parameter(\"B{}\".format(L), nn.Parameter(torch.zeros(1)))\n",
        "\n",
        "        # クラス変数としてレイヤー数，活性化関数，バイアスの有無を保持\n",
        "        self.L = L\n",
        "        self.act = act\n",
        "        self.bias = bias\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 順伝播計算\n",
        "        for i in range(self.L + 1):\n",
        "            # i 番目の層の重み行列を取得\n",
        "            W = getattr(self, \"W{}\".format(i))\n",
        "\n",
        "            # ParameterList 形式の重み行列をフルの行列に結合\n",
        "            if isinstance(W, nn.ParameterList):\n",
        "                W = torch.cat(list(W))\n",
        "\n",
        "            # バイアス項が指定されている場合は，バイアスを取得\n",
        "            if self.bias:\n",
        "                B = self.bias * getattr(self, \"B{}\".format(i))\n",
        "            else:\n",
        "                B = 0\n",
        "\n",
        "            # 現在の入力の次元数を取得\n",
        "            h = x.size(1)\n",
        "\n",
        "            if i < self.L:\n",
        "                # 隠れ層での線形変換とスケーリング，そして活性化関数の適用\n",
        "                x = x @ (W.t() / h ** 0.5)  # 重み行列との積（次元スケーリング）\n",
        "                x = self.act(x + B)  # バイアス項を加えた後，活性化関数を適用\n",
        "            else:\n",
        "                # 最終層での線形変換（出力はスカラー値）\n",
        "                x = x @ (W.t() / h) + B  # スカラー出力\n",
        "\n",
        "        # 出力を 1 次元のテンソルに変換して返す\n",
        "        return x.view(-1)\n",
        "\n",
        "\n",
        "class CV(nn.Module):\n",
        "    def __init__(self, d, h, L1, L2, act, h_base, fsz, pad, stride_first):\n",
        "        super().__init__()\n",
        "\n",
        "        # 初期入力チャネル数\n",
        "        h1 = d\n",
        "\n",
        "        # L1: 深さのレベル（層数）\n",
        "        for i in range(L1):\n",
        "            # 各レベルでの出力チャネル数\n",
        "            h2 = round(h * h_base ** i)\n",
        "            for j in range(L2):\n",
        "                # 各レイヤーでの畳み込みフィルタを定義\n",
        "                # h2: 現在のレイヤーの出力チャネル数\n",
        "                # fsz: カーネルサイズ\n",
        "                W = nn.ParameterList([nn.Parameter(torch.randn(h1, fsz, fsz)) for _ in range(h2)])\n",
        "                setattr(self, \"W{}_{}\".format(i, j), W)  # 各レイヤーのパラメータを設定\n",
        "                h1 = h2 # 入力チャネル数を更新\n",
        "\n",
        "        # 最終の線形変換層のパラメータ\n",
        "        self.W = nn.Parameter(torch.randn(h1))\n",
        "\n",
        "        # パラメータの保存\n",
        "        self.L1 = L1   # 深さのレベル数\n",
        "        self.L2 = L2   # 各レベルのレイヤー数\n",
        "        self.act = act    # 活性化関数\n",
        "        self.pad = pad    # パディング\n",
        "        self.stride_first = stride_first  # 最初のレイヤーのストライド設定\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        順伝播計算を実行\n",
        "        \"\"\"\n",
        "\n",
        "        # 各レベルを順に処理\n",
        "        for i in range(self.L1):\n",
        "            for j in range(self.L2):\n",
        "                # 入力サイズが5x5以上であることを確認\n",
        "                assert x.size(2) >= 5 and x.size(3) >= 5\n",
        "\n",
        "                # 現在のレイヤーのパラメータを取得\n",
        "                W = getattr(self, \"W{}_{}\".format(i, j))\n",
        "                W = torch.stack(list(W))  # リストをテンソルに変換\n",
        "\n",
        "                # ストライド設定: 初回レイヤーや最初のレベルではストライド2，それ以外は1\n",
        "                stride = 2 if j == 0 and (i > 0 or self.stride_first) else 1\n",
        "\n",
        "                # カーネルの平均値で正規化\n",
        "                h = W[0].numel()\n",
        "                x = nn.functional.conv2d(x, W / h ** 0.5, None, stride=stride, padding=self.pad)\n",
        "                x = self.act(x)  # 活性化関数を適用\n",
        "\n",
        "        # 特徴マップのフラット化と平均化\n",
        "        x = x.flatten(2).mean(2)\n",
        "\n",
        "        # 最終線形変換: 特徴マップを最終出力に変換\n",
        "        W = self.W\n",
        "        h = len(W)\n",
        "        x = x @ (W / h)   # 行列の内積計算と正規化\n",
        "        return x.view(-1)   # 出力をフラット化\n",
        "\n",
        "\n",
        "class conv(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, bias=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # 初期の畳み込みカーネルを定義\n",
        "        w = torch.randn(out_planes, in_planes, kernel_size, kernel_size)\n",
        "        n = max(1, 256**2 // w[0].numel())\n",
        "        # パラメータを分割して保持\n",
        "        self.w = nn.ParameterList([nn.Parameter(w[j: j + n]) for j in range(0, len(w), n)])\n",
        "\n",
        "        # バイアスが必要な場合の設定\n",
        "        self.b = nn.Parameter(torch.zeros(out_planes)) if bias else None\n",
        "\n",
        "        # ストライドとパディングの設定\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        順伝播計算を実行\n",
        "        \"\"\"\n",
        "\n",
        "        # 全てのカーネルパラメータを結合\n",
        "        w = torch.cat(list(self.w))\n",
        "        # カーネルの平均値で正規化\n",
        "        h = w[0].numel()\n",
        "        # 畳み込み演算を実行\n",
        "        return F.conv2d(x, w / h ** 0.5, self.b, self.stride, self.padding)\n",
        "\n",
        "class wide_basic(nn.Module):\n",
        "    \"\"\"\n",
        "    Wide-ResNet の基本的なブロックを定義するクラス．\n",
        "    このクラスは，2 つの畳み込み層とショートカットパスを持ち，活性化関数と角度に基づく線形結合を行う．\n",
        "    \"\"\"\n",
        "    def __init__(self, in_planes, planes, act, stride=1, mix_angle=45):\n",
        "        \"\"\"\n",
        "        コンストラクタでブロックの初期設定を行う．\n",
        "\n",
        "        Parameters:\n",
        "        - in_planes: 入力チャネル数\n",
        "        - planes: 出力チャネル数\n",
        "        - act: 活性化関数\n",
        "        - stride: 畳み込みのストライド（デフォルトは1）\n",
        "        - mix_angle: ミックス角度（デフォルトは45度）\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # 第一の畳み込み層\n",
        "        self.conv1 = conv(in_planes, planes, kernel_size=3, padding=1, bias=True)\n",
        "        # 第二の畳み込み層\n",
        "        self.conv2 = conv(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
        "\n",
        "        # ショートカットパスの初期化\n",
        "        self.shortcut = nn.Sequential()\n",
        "        # ストライドが 1 でないか，入力と出力のチャネル数が異なる場合に 1x1 の畳み込みを使ってショートカットパスを調整\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = conv(in_planes, planes, kernel_size=1, stride=stride, bias=True)\n",
        "\n",
        "        # 活性化関数\n",
        "        self.act = act\n",
        "        # ミックス角度（度数法からラジアンに変換）\n",
        "        self.mix_angle = mix_angle\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        順伝播計算を行う．\n",
        "\n",
        "        Parameters:\n",
        "        - x: 入力テンソル\n",
        "\n",
        "        Returns:\n",
        "        - out: 出力テンソル\n",
        "        \"\"\"\n",
        "        # 入力 x に対して活性化関数を適用し，第一の畳み込み層を通過\n",
        "        out = self.conv1(self.act(x))\n",
        "        # 活性化関数を適用し，第二の畳み込み層を通過\n",
        "        out = self.conv2(self.act(out))\n",
        "        # ショートカットパスの出力を取得\n",
        "        cut = self.shortcut(x)\n",
        "\n",
        "        # ミックス角度をラジアンに変換\n",
        "        a = self.mix_angle * math.pi / 180\n",
        "        # ミックス角度に基づく線形結合\n",
        "        out = math.cos(a) * cut + math.sin(a) * out\n",
        "\n",
        "        return out\n",
        "\n",
        "class Wide_ResNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Wide Residual Network（Wide-ResNet）のクラスを定義．\n",
        "    深さ depth は 6n+4 の形で指定し，各層のユニット数を h で指定．\n",
        "    mix_angle は Wide-ResNet のブロック内での角度に関連するハイパーパラメータ．\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d, depth, h, act, num_classes, mix_angle=45):\n",
        "        super().__init__()\n",
        "\n",
        "        # 深さが6の倍数に4を加えた形であることを確認\n",
        "        assert (depth % 6 == 4), 'Wide-resnet depth should be 6n+4'\n",
        "        n = (depth - 4) // 6\n",
        "\n",
        "        # 各ステージの出力チャネル数を定義\n",
        "        nStages = [16, 16 * h, 32 * h, 64 * h]\n",
        "        # Wide-ResNet の基本ブロックを指定するためのファクトリ関数\n",
        "        block = functools.partial(wide_basic, act=act, mix_angle=mix_angle)\n",
        "\n",
        "        # 初期の畳み込み層の定義\n",
        "        self.conv1 = conv(d, nStages[0], kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.in_planes = nStages[0]\n",
        "\n",
        "        # 各レイヤーの定義（複数のブロックから成る）\n",
        "        self.layer1 = self._wide_layer(block, nStages[1], n, stride=1)\n",
        "        self.layer2 = self._wide_layer(block, nStages[2], n, stride=2)\n",
        "        self.layer3 = self._wide_layer(block, nStages[3], n, stride=2)\n",
        "\n",
        "        # 最終線形層の定義（出力次元はクラス数）\n",
        "        self.linear = nn.Parameter(torch.randn(num_classes, nStages[3]))\n",
        "        self.bias = nn.Parameter(torch.zeros(num_classes))\n",
        "        self.act = act\n",
        "\n",
        "    def _wide_layer(self, block, planes, num_blocks, stride):\n",
        "        \"\"\"\n",
        "        Wide-ResNet の層を定義．\n",
        "        各層は指定された数のブロックで構成され，最初のブロックのみ stride でダウンサンプリングを行う\n",
        "        \"\"\"\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "\n",
        "        # 各ブロックを追加\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride=stride))\n",
        "            self.in_planes = planes\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        順伝播計算を実行\n",
        "        \"\"\"\n",
        "\n",
        "        # 初期の畳み込み層を通過\n",
        "        out = self.conv1(x)\n",
        "\n",
        "        # 各層を順に通過\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "\n",
        "        # 活性化関数の適用\n",
        "        out = self.act(out)\n",
        "\n",
        "        # 特徴マップをフラット化し，各特徴の平均を取る\n",
        "        out = out.flatten(2).mean(2)\n",
        "\n",
        "        # 線形変換を行う（クラス数に対する出力）\n",
        "        h = self.linear.size(1)\n",
        "        out = F.linear(out, self.linear / h, self.bias)\n",
        "\n",
        "        # 出力次元が1の場合はフラット化\n",
        "        if out.size(1) == 1:\n",
        "            out = out.flatten(0)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# データセット"
      ],
      "metadata": {
        "id": "6JdOHFRoMRGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pylint: disable=no-member, E1102, C\n",
        "\"\"\"\n",
        "- Load mnist or cifar10\n",
        "- perform PCA\n",
        "- shuffle the dataset\n",
        "- split in train and test set in an equilibrated way (same amount of each classes)\n",
        "\"\"\"\n",
        "import functools\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "def pca(x, d, whitening):\n",
        "    '''\n",
        "    主成分分析（PCA）を実行する関数．\n",
        "\n",
        "    :param x: 入力データテンソル．形状は [P, ...] で，P は特徴量の次元．\n",
        "    :param d: 主成分の数．出力の次元．\n",
        "    :param whitening: データをホワイトニングするかどうかのフラグ．\n",
        "    :return: PCAにより次元削減されたデータ．形状は [P, d]．\n",
        "    '''\n",
        "\n",
        "    # データをフラット化し，中心化\n",
        "    # 入力テンソル x を 2 次元行列に変換．ここで，最初の次元が特徴量の次元 P になる．\n",
        "    z = x.flatten(1)\n",
        "\n",
        "    # 各サンプルの平均を計算し，その平均を引いてデータを中心化\n",
        "    mu = z.mean(0)\n",
        "    z = z - mu  # 中心化されたデータ\n",
        "    cov = (z.t() @ z) / len(z) # 共分散行列\n",
        "\n",
        "    # 共分散行列の固有値と固有ベクトルを計算\n",
        "    val, vec = cov.symeig(eigenvectors=True) # 固有値と固有ベクトルを計算\n",
        "    val, idx = val.sort(descending=True) # 固有値を降順にソートし，インデックスを取得\n",
        "    vec = vec[:, idx]  # ソートされた固有ベクトルを取得\n",
        "\n",
        "    # 主成分を計算\n",
        "    # データを主成分に射影．vec[:, :d] は最初の d 個の主成分（固有ベクトル）．\n",
        "    u = z @ vec[:, :d]  # 主成分に変換されたデータ\n",
        "\n",
        "    # ホワイトニング処理を実行\n",
        "    # whitening フラグが True の場合，データをホワイトニング（固有値の平方根の逆数でスケーリング）\n",
        "    if whitening:\n",
        "        u.mul_(val[:d].rsqrt())  # ホワイトニング（スケーリング）\n",
        "    else:\n",
        "        u.mul_(val[:d].mean().rsqrt())  # ホワイトニングしない場合のスケーリング\n",
        "\n",
        "    return u  # PCA により次元削減されたデータを返す\n",
        "\n",
        "\n",
        "def get_binary_pca_dataset(dataset, p, d, whitening, seed=None, device=None):\n",
        "    '''\n",
        "    バイナリ分類用にPCAを適用したデータセットを取得する関数\n",
        "\n",
        "    :param dataset: 使用するデータセットの名前（例: \"mnist\", \"cifar10\"など）\n",
        "    :param p: トレーニングデータとテストデータを分割するためのサンプル数の基準\n",
        "    :param d: PCAによる次元削減後の次元数\n",
        "    :param whitening: PCAの後にデータをホワイトニングするかどうかのフラグ\n",
        "    :param seed: データのシャッフルに使用するランダムシード\n",
        "    :param device: データを移動するデバイス（CPUまたはGPU）\n",
        "    :return: トレーニングセットとテストセットのタプル．各セットは (特徴量, ラベル) のタプル\n",
        "    '''\n",
        "\n",
        "    # ランダムシードが指定されていない場合は，ランダムに生成\n",
        "    if seed is None:\n",
        "        seed = torch.randint(2 ** 32, (), dtype=torch.long).item()\n",
        "\n",
        "    # 正規化されたデータセットを取得\n",
        "    x, y = get_normalized_dataset(dataset, seed)\n",
        "\n",
        "    # PCAを適用して次元を削減し，指定されたデバイスにデータを移動\n",
        "    x = pca(x, d, whitening).to(device)\n",
        "\n",
        "    # ラベルをバイナリに変換．ここでは，偶数クラスは 1，奇数クラスは -1 に変換\n",
        "    y = (2 * (torch.arange(len(y)) % 2) - 1).type(x.dtype).to(device)\n",
        "\n",
        "    # トレーニングデータとテストデータに分割\n",
        "    xtr = x[:p]\n",
        "    xte = x[p:]\n",
        "    ytr = y[:p]\n",
        "    yte = y[p:]\n",
        "\n",
        "    return (xtr, ytr), (xte, yte)\n",
        "\n",
        "\n",
        "def get_dataset(dataset, p, seed=None, device=None):\n",
        "    '''\n",
        "    指定されたデータセットを取得し，トレーニングセットとテストセットに分割する関数\n",
        "\n",
        "    :param dataset: 使用するデータセットの名前（例: \"mnist\", \"cifar10\"など）\n",
        "    :param p: トレーニングデータとテストデータを分割するためのサンプル数の基準\n",
        "    :param seed: データのシャッフルに使用するランダムシード\n",
        "    :param device: データを移動するデバイス（CPUまたはGPU）\n",
        "    :return: トレーニングセットとテストセットのタプル．各セットは (特徴量, ラベル) のタプル\n",
        "    '''\n",
        "    if seed is None:\n",
        "        seed = torch.randint(2 ** 32, (), dtype=torch.long).item()\n",
        "\n",
        "    # 正規化されたデータセットを取得\n",
        "    x, y = get_normalized_dataset(dataset, seed)\n",
        "\n",
        "    # データを指定されたデバイスに移動\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    # トレーニングデータとテストデータに分割\n",
        "    xtr = x[:p]\n",
        "    xte = x[p:]\n",
        "    ytr = y[:p]\n",
        "    yte = y[p:]\n",
        "\n",
        "    return (xtr, ytr), (xte, yte)\n",
        "\n",
        "\n",
        "def get_binary_dataset(dataset, p, seed=None, device=None):\n",
        "    '''\n",
        "    バイナリ分類用にデータセットを取得する関数\n",
        "    '''\n",
        "    if seed is None:\n",
        "        seed = torch.randint(2 ** 32, (), dtype=torch.long).item()\n",
        "\n",
        "    # 正規化されたデータセットを取得\n",
        "    x, y = get_normalized_dataset(dataset, seed)\n",
        "\n",
        "    # データを指定されたデバイスに移動\n",
        "    x = x.to(device)\n",
        "    # ラベルをバイナリに変換．ここでは，偶数クラスは 1，奇数クラスは -1 に変換\n",
        "    y = (2 * (torch.arange(len(y)) % 2) - 1).type(x.dtype).to(device)\n",
        "\n",
        "    # トレーニングデータとテストデータに分割\n",
        "    xtr = x[:p]\n",
        "    xte = x[p:]\n",
        "    ytr = y[:p]\n",
        "    yte = y[p:]\n",
        "\n",
        "    return (xtr, ytr), (xte, yte)\n",
        "\n",
        "\n",
        "@functools.lru_cache(maxsize=2)\n",
        "def get_normalized_dataset(dataset, seed):\n",
        "    '''\n",
        "    指定されたデータセットを正規化し，シャッフルして取得する関数\n",
        "\n",
        "    :param dataset: 使用するデータセットの名前（例: \"mnist\", \"cifar10\" など）\n",
        "    :param seed: データのシャッフルに使用するランダムシード\n",
        "    :return: 正規化されたデータとラベルのタプル．データは特徴量とラベルのテンソルとして返される．\n",
        "    '''\n",
        "    import torchvision\n",
        "    from itertools import chain\n",
        "\n",
        "    # データをTensor型に変換するための変換処理を定義\n",
        "    transform = torchvision.transforms.ToTensor()\n",
        "\n",
        "    # 指定されたデータセットに応じてデータをダウンロードし，変換を適用\n",
        "    if dataset == \"mnist\":\n",
        "        # MNISTデータセットをダウンロードし，トレーニングとテストのデータを取得\n",
        "        tr = torchvision.datasets.MNIST('~/.torchvision/datasets/MNIST', train=True, download=True, transform=transform)\n",
        "        te = torchvision.datasets.MNIST('~/.torchvision/datasets/MNIST', train=False, transform=transform)\n",
        "    elif dataset == \"kmnist\":\n",
        "        tr = torchvision.datasets.KMNIST('~/.torchvision/datasets/KMNIST', train=True, download=True, transform=transform)\n",
        "        te = torchvision.datasets.KMNIST('~/.torchvision/datasets/KMNIST', train=False, transform=transform)\n",
        "    elif dataset == \"emnist-letters\":\n",
        "        tr = torchvision.datasets.EMNIST('~/.torchvision/datasets/EMNIST', train=True, download=True, transform=transform, split='letters')\n",
        "        te = torchvision.datasets.EMNIST('~/.torchvision/datasets/EMNIST', train=False, transform=transform, split='letters')\n",
        "    elif dataset == \"fashion\":\n",
        "        tr = torchvision.datasets.FashionMNIST('~/.torchvision/datasets/FashionMNIST', train=True, download=True, transform=transform)\n",
        "        te = torchvision.datasets.FashionMNIST('~/.torchvision/datasets/FashionMNIST', train=False, transform=transform)\n",
        "    elif dataset == \"cifar10\":\n",
        "        tr = torchvision.datasets.CIFAR10('~/.torchvision/datasets/CIFAR10', train=True, download=True, transform=transform)\n",
        "        te = torchvision.datasets.CIFAR10('~/.torchvision/datasets/CIFAR10', train=False, transform=transform)\n",
        "    elif dataset == \"cifar_catdog\":\n",
        "        # CIFAR-10データセットから猫と犬のクラスを抽出\n",
        "        tr = [(x, y) for x, y in torchvision.datasets.CIFAR10('~/.torchvision/datasets/CIFAR10', train=True, download=True, transform=transform) if y in [3, 5]]\n",
        "        te = [(x, y) for x, y in torchvision.datasets.CIFAR10('~/.torchvision/datasets/CIFAR10', train=False, transform=transform) if y in [3, 5]]\n",
        "    elif dataset == \"cifar_shipbird\":\n",
        "        # CIFAR-10データセットから船と鳥のクラスを抽出\n",
        "        tr = [(x, y) for x, y in torchvision.datasets.CIFAR10('~/.torchvision/datasets/CIFAR10', train=True, download=True, transform=transform) if y in [8, 2]]\n",
        "        te = [(x, y) for x, y in torchvision.datasets.CIFAR10('~/.torchvision/datasets/CIFAR10', train=False, transform=transform) if y in [8, 2]]\n",
        "    elif dataset == \"cifar_catplane\":\n",
        "        # CIFAR-10データセットから猫と飛行機のクラスを抽出\n",
        "        tr = [(x, y) for x, y in torchvision.datasets.CIFAR10('~/.torchvision/datasets/CIFAR10', train=True, download=True, transform=transform) if y in [3, 0]]\n",
        "        te = [(x, y) for x, y in torchvision.datasets.CIFAR10('~/.torchvision/datasets/CIFAR10', train=False, transform=transform) if y in [3, 0]]\n",
        "    else:\n",
        "        raise ValueError(\"unknown dataset\")\n",
        "\n",
        "    # トレーニングデータとテストデータを結合し，データをテンソル形式でリストに変換\n",
        "    dataset = list(tr) + list(te)\n",
        "    # データとラベルをテンソル形式に変換し，ラベルを整数型に変換\n",
        "    dataset = [(x.type(torch.float64), int(y)) for x, y in dataset]\n",
        "    # ラベルのクラスを抽出し，ソート\n",
        "    classes = sorted({y for x, y in dataset})\n",
        "\n",
        "    # クラスごとにデータを分けてリストに格納\n",
        "    sets = [[(x, y) for x, y in dataset if y == i] for i in classes]\n",
        "\n",
        "    # ランダムシードを設定し，データをシャッフル\n",
        "    torch.manual_seed(seed)\n",
        "    sets = [\n",
        "        [x[i] for i in torch.randperm(len(x))]\n",
        "        for x in sets\n",
        "    ]\n",
        "\n",
        "    # シャッフルされたデータを元に戻し，リストを再結合\n",
        "    dataset = list(chain(*zip(*sets)))\n",
        "\n",
        "    # データをテンソルにスタックし，正規化\n",
        "    x = torch.stack([x for x, y in dataset])\n",
        "    x = x - x.mean(0)   # データを中心化\n",
        "    # データの標準化（各サンプルを標準化）\n",
        "    x = (x[0].numel() ** 0.5) * x / x.flatten(1).norm(dim=1).view(-1, *(1,) * (x.dim() - 1))\n",
        "\n",
        "    # ラベルをテンソルに変換\n",
        "    y = torch.tensor([y for x, y in dataset], dtype=torch.long)\n",
        "\n",
        "    return x, y  # 正規化されたデータとラベルのテンソルを返す"
      ],
      "metadata": {
        "id": "-QmQsiLDMPrT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ダイナミクス"
      ],
      "metadata": {
        "id": "nl2nqKpzfKVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pylint: disable=E1101, C\n",
        "\"\"\"\n",
        "This file implements a continuous version of momentum SGD\n",
        "Dynamics that compares the angle of the gradient between steps and keep it small\n",
        "\n",
        "- stop when margins are reached\n",
        "\n",
        "It contains two implementation of the same dynamics:\n",
        "1. `train_regular` for any kind of models\n",
        "2. `train_kernel` only for linear models\n",
        "\"\"\"\n",
        "import copy\n",
        "import itertools\n",
        "import math\n",
        "from time import perf_counter\n",
        "\n",
        "import torch\n",
        "\n",
        "# from hessian import gradient\n",
        "\n",
        "#####################################################################################################\n",
        "def gradient(outputs, inputs, grad_outputs=None, retain_graph=None, create_graph=False):\n",
        "    r'''\n",
        "    Compute the gradient of `outputs` with respect to `inputs`\n",
        "    ```\n",
        "    gradient(x.sum(), x)\n",
        "    gradient((x * y).sum(), [x, y])\n",
        "    ```\n",
        "    '''\n",
        "    if torch.is_tensor(inputs):\n",
        "        inputs = [inputs]\n",
        "    else:\n",
        "        inputs = list(inputs)\n",
        "    grads = torch.autograd.grad(outputs, inputs, grad_outputs,\n",
        "                                allow_unused=True,\n",
        "                                retain_graph=retain_graph,\n",
        "                                create_graph=create_graph)\n",
        "    grads = [x if x is not None else torch.zeros_like(y) for x, y in zip(grads, inputs)]\n",
        "    return torch.cat([x.contiguous().view(-1) for x in grads])\n",
        "#####################################################################################################\n",
        "\n",
        "\n",
        "def loglinspace(rate, step, end=None):\n",
        "    t = 0\n",
        "    while end is None or t <= end:\n",
        "        yield t\n",
        "        t = int(t + 1 + step * (1 - math.exp(-t * rate / step)))\n",
        "\n",
        "\n",
        "class ContinuousMomentum(torch.optim.Optimizer):\n",
        "    r\"\"\"Implements a continuous version of momentum.\n",
        "\n",
        "    d/dt velocity = -1/tau (velocity + grad)\n",
        "     or\n",
        "    d/dt velocity = -mu/t (velocity + grad)\n",
        "\n",
        "    d/dt parameters = velocity\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, dt, tau):\n",
        "        defaults = dict(dt=dt, tau=tau)\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "\n",
        "        Arguments:\n",
        "            closure (callable): A closure that reevaluates the model and\n",
        "                returns the loss. Optional for most optimizers.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            tau = group['tau']\n",
        "            dt = group['dt']\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "\n",
        "                param_state = self.state[p]\n",
        "                if 't' not in param_state:\n",
        "                    t = param_state['t'] = 0\n",
        "                else:\n",
        "                    t = param_state['t']\n",
        "\n",
        "                if tau != 0:\n",
        "                    if 'velocity' not in param_state:\n",
        "                        v = param_state['velocity'] = torch.zeros_like(p.data)\n",
        "                    else:\n",
        "                        v = param_state['velocity']\n",
        "\n",
        "                if tau > 0:\n",
        "                    x = math.exp(-dt / tau)\n",
        "                    v.mul_(x).add_(-(1 - x), p.grad.data)\n",
        "                elif tau < 0:\n",
        "                    mu = -tau\n",
        "                    x = (t / (t + dt)) ** mu\n",
        "                    v.mul_(x).add_(-(1 - x), p.grad.data)\n",
        "                else:\n",
        "                    v = -p.grad.data\n",
        "\n",
        "                p.data.add_(dt, v)\n",
        "                param_state['t'] += dt\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "def make_step(f, optimizer, dt, grad):\n",
        "    i = 0\n",
        "    for p in f.parameters():\n",
        "        n = p.numel()\n",
        "        p.grad = grad[i: i + n].view_as(p)\n",
        "        i += n\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['dt'] = dt\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    for p in f.parameters():\n",
        "        p.grad = None\n",
        "\n",
        "\n",
        "def train_regular(f0, x, y, tau, max_walltime, alpha, loss, subf0, max_dgrad=math.inf, max_dout=math.inf):\n",
        "    f = copy.deepcopy(f0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out0 = f0(x) if subf0 else 0\n",
        "\n",
        "    dt = 1\n",
        "    step_change_dt = 0\n",
        "    optimizer = ContinuousMomentum(f.parameters(), dt=dt, tau=tau)\n",
        "\n",
        "    checkpoint_generator = loglinspace(0.01, 100)\n",
        "    checkpoint = next(checkpoint_generator)\n",
        "    wall = perf_counter()\n",
        "    t = 0\n",
        "    converged = False\n",
        "\n",
        "    out = f(x)\n",
        "    grad = gradient(loss((out - out0) * y).mean(), f.parameters())\n",
        "\n",
        "    for step in itertools.count():\n",
        "\n",
        "        state = copy.deepcopy((f.state_dict(), optimizer.state_dict(), t))\n",
        "\n",
        "        while True:\n",
        "            make_step(f, optimizer, dt, grad)\n",
        "            t += dt\n",
        "            current_dt = dt\n",
        "\n",
        "            new_out = f(x)\n",
        "            new_grad = gradient(loss((new_out - out0) * y).mean(), f.parameters())\n",
        "\n",
        "            dout = (out - new_out).mul(alpha).abs().max().item()\n",
        "            if grad.norm() == 0 or new_grad.norm() == 0:\n",
        "                dgrad = 0\n",
        "            else:\n",
        "                dgrad = (grad - new_grad).norm().pow(2).div(grad.norm() * new_grad.norm()).item()\n",
        "\n",
        "            if dgrad < max_dgrad and dout < max_dout:\n",
        "                if dgrad < 0.5 * max_dgrad and dout < 0.5 * max_dout:\n",
        "                    dt *= 1.1\n",
        "                break\n",
        "\n",
        "            dt /= 10\n",
        "\n",
        "            print(\"[{} +{}] [dt={:.1e} dgrad={:.1e} dout={:.1e}]\".format(step, step - step_change_dt, dt, dgrad, dout), flush=True)\n",
        "            step_change_dt = step\n",
        "            f.load_state_dict(state[0])\n",
        "            optimizer.load_state_dict(state[1])\n",
        "            t = state[2]\n",
        "\n",
        "        out = new_out\n",
        "        grad = new_grad\n",
        "\n",
        "        save = False\n",
        "\n",
        "        if step == checkpoint:\n",
        "            checkpoint = next(checkpoint_generator)\n",
        "            assert checkpoint > step\n",
        "            save = True\n",
        "\n",
        "        if (alpha * (out - out0) * y >= 1).all() and not converged:\n",
        "            converged = True\n",
        "            save = True\n",
        "\n",
        "        if save:\n",
        "            state = {\n",
        "                'step': step,\n",
        "                'wall': perf_counter() - wall,\n",
        "                't': t,\n",
        "                'dt': current_dt,\n",
        "                'dgrad': dgrad,\n",
        "                'dout': dout,\n",
        "                'norm': sum(p.norm().pow(2) for p in f.parameters()).sqrt().item(),\n",
        "                'dnorm': sum((p0 - p).norm().pow(2) for p0, p in zip(f0.parameters(), f.parameters())).sqrt().item(),\n",
        "                'grad_norm': grad.norm().item(),\n",
        "            }\n",
        "\n",
        "            yield f, state, converged\n",
        "\n",
        "        if converged:\n",
        "            break\n",
        "\n",
        "        if perf_counter() > wall + max_walltime:\n",
        "            break\n",
        "\n",
        "        if torch.isnan(out).any():\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "def train_kernel(ktrtr, ytr, tau, max_walltime, alpha, loss_prim, max_dgrad=math.inf, max_dout=math.inf):\n",
        "    otr = ktrtr.new_zeros(len(ytr))\n",
        "    velo = otr.clone()\n",
        "\n",
        "    dt = 1\n",
        "    step_change_dt = 0\n",
        "\n",
        "    checkpoint_generator = loglinspace(0.01, 100)\n",
        "    checkpoint = next(checkpoint_generator)\n",
        "    wall = perf_counter()\n",
        "    t = 0\n",
        "    converged = False\n",
        "\n",
        "    lprim = loss_prim(otr * ytr) * ytr\n",
        "    grad = ktrtr @ lprim / len(ytr)\n",
        "\n",
        "    for step in itertools.count():\n",
        "\n",
        "        state = copy.deepcopy((otr, velo, t))\n",
        "\n",
        "        while True:\n",
        "\n",
        "            if tau > 0:\n",
        "                x = math.exp(-dt / tau)\n",
        "                velo.mul_(x).add_(-(1 - x), grad)\n",
        "            elif tau < 0:\n",
        "                mu = -tau\n",
        "                x = (t / (t + dt)) ** mu\n",
        "                velo.mul_(x).add_(-(1 - x), grad)\n",
        "            else:\n",
        "                velo.copy_(-grad)\n",
        "            otr.add_(dt, velo)\n",
        "\n",
        "            t += dt\n",
        "            current_dt = dt\n",
        "\n",
        "            lprim = loss_prim(otr * ytr) * ytr\n",
        "            new_grad = ktrtr @ lprim / len(ytr)\n",
        "\n",
        "            dout = velo.mul(dt * alpha).abs().max().item()\n",
        "            if grad.norm() == 0 or new_grad.norm() == 0:\n",
        "                dgrad = 0\n",
        "            else:\n",
        "                dgrad = (grad - new_grad).norm().pow(2).div(grad.norm() * new_grad.norm()).item()\n",
        "\n",
        "            if dgrad < max_dgrad and dout < max_dout:\n",
        "                if dgrad < 0.1 * max_dgrad and dout < 0.1 * max_dout:\n",
        "                    dt *= 1.1\n",
        "                break\n",
        "\n",
        "            dt /= 10\n",
        "\n",
        "            print(\"[{} +{}] [dt={:.1e} dgrad={:.1e} dout={:.1e}]\".format(step, step - step_change_dt, dt, dgrad, dout), flush=True)\n",
        "            step_change_dt = step\n",
        "            otr.copy_(state[0])\n",
        "            velo.copy_(state[1])\n",
        "            t = state[2]\n",
        "\n",
        "        grad = new_grad\n",
        "\n",
        "        save = False\n",
        "\n",
        "        if step == checkpoint:\n",
        "            checkpoint = next(checkpoint_generator)\n",
        "            assert checkpoint > step\n",
        "            save = True\n",
        "\n",
        "        if (alpha * otr * ytr >= 1).all() and not converged:\n",
        "            converged = True\n",
        "            save = True\n",
        "\n",
        "        if save:\n",
        "            state = {\n",
        "                'step': step,\n",
        "                'wall': perf_counter() - wall,\n",
        "                't': t,\n",
        "                'dt': current_dt,\n",
        "                'dgrad': dgrad,\n",
        "                'dout': dout,\n",
        "                'grad_norm': grad.norm().item(),\n",
        "            }\n",
        "\n",
        "            yield otr, velo, grad, state, converged\n",
        "\n",
        "        if converged:\n",
        "            break\n",
        "\n",
        "        if perf_counter() > wall + max_walltime:\n",
        "            break\n",
        "\n",
        "        if torch.isnan(otr).any():\n",
        "            break"
      ],
      "metadata": {
        "id": "fQjP5tVTMbPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# カーネル"
      ],
      "metadata": {
        "id": "uyPICO2aM5cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pylint: disable=no-member, C, not-callable\n",
        "\"\"\"\n",
        "Computes the Gram matrix of a given model\n",
        "\"\"\"\n",
        "\n",
        "def compute_kernels(f, xtr, xte):\n",
        "    # from hessian import gradient\n",
        "\n",
        "    ktrtr = xtr.new_zeros(len(xtr), len(xtr))\n",
        "    ktetr = xtr.new_zeros(len(xte), len(xtr))\n",
        "    ktete = xtr.new_zeros(len(xte), len(xte))\n",
        "\n",
        "    params = []\n",
        "    current = []\n",
        "    for p in sorted(f.parameters(), key=lambda p: p.numel(), reverse=True):\n",
        "        current.append(p)\n",
        "        if sum(p.numel() for p in current) > 2e9 // (8 * (len(xtr) + len(xte))):\n",
        "            if len(current) > 1:\n",
        "                params.append(current[:-1])\n",
        "                current = current[-1:]\n",
        "            else:\n",
        "                params.append(current)\n",
        "                current = []\n",
        "    if len(current) > 0:\n",
        "        params.append(current)\n",
        "\n",
        "    for i, p in enumerate(params):\n",
        "        print(\"[{}/{}] [len={} numel={}]\".format(i, len(params), len(p), sum(x.numel() for x in p)), flush=True)\n",
        "\n",
        "        jtr = xtr.new_empty(len(xtr), sum(u.numel() for u in p))  # (P, N~)\n",
        "        jte = xte.new_empty(len(xte), sum(u.numel() for u in p))  # (P, N~)\n",
        "\n",
        "        for j, x in enumerate(xtr):\n",
        "            jtr[j] = gradient(f(x[None]), p)  # (N~)\n",
        "\n",
        "        for j, x in enumerate(xte):\n",
        "            jte[j] = gradient(f(x[None]), p)  # (N~)\n",
        "\n",
        "        ktrtr.add_(jtr @ jtr.t())\n",
        "        ktetr.add_(jte @ jtr.t())\n",
        "        ktete.add_(jte @ jte.t())\n",
        "        del jtr, jte\n",
        "\n",
        "    return ktrtr, ktetr, ktete"
      ],
      "metadata": {
        "id": "z7lXqLT0M4UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# メイン（GPUを使うべき）"
      ],
      "metadata": {
        "id": "IOA6y6xyfb5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py\n",
        "# pylint: disable=C, R, bare-except, arguments-differ, no-member, undefined-loop-variable\n",
        "import argparse\n",
        "import math\n",
        "import os\n",
        "import subprocess\n",
        "from functools import partial\n",
        "from time import perf_counter\n",
        "\n",
        "import torch\n",
        "\n",
        "# from archi import CV, FC, Wide_ResNet\n",
        "# from dataset import get_binary_dataset, get_binary_pca_dataset\n",
        "# from dynamics import train_kernel, train_regular\n",
        "# from kernels import compute_kernels\n",
        "\n",
        "\n",
        "def loss_func(args, fy):\n",
        "    if args.loss == 'softhinge':\n",
        "        sp = partial(torch.nn.functional.softplus, beta=args.lossbeta)\n",
        "        return sp(1 - args.alpha * fy) / args.alpha\n",
        "    if args.loss == 'qhinge':\n",
        "        return 0.5 * (1 - args.alpha * fy).relu().pow(2) / args.alpha\n",
        "\n",
        "\n",
        "def loss_func_prime(args, fy):\n",
        "    if args.loss == 'softhinge':\n",
        "        return -torch.sigmoid(args.lossbeta * (1 - args.alpha * fy)).mul(args.lossbeta)\n",
        "    if args.loss == 'qhinge':\n",
        "        return -(1 - args.alpha * fy).relu()\n",
        "\n",
        "\n",
        "class SplitEval(torch.nn.Module):\n",
        "    def __init__(self, f, size):\n",
        "        super().__init__()\n",
        "        self.f = f\n",
        "        self.size = size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat([self.f(x[i: i + self.size]) for i in range(0, len(x), self.size)])\n",
        "\n",
        "\n",
        "def run_kernel(args, ktrtr, ktetr, ktete, f, xtr, ytr, xte, yte):\n",
        "    assert args.f0 == 1\n",
        "\n",
        "    dynamics = []\n",
        "\n",
        "    tau = args.tau_over_h * args.h\n",
        "    if args.tau_alpha_crit is not None:\n",
        "        tau *= min(1, args.tau_alpha_crit / args.alpha)\n",
        "\n",
        "    for otr, _velo, _grad, state, _converged in train_kernel(ktrtr, ytr, tau, args.train_time, args.alpha, partial(loss_func_prime, args), args.max_dgrad, args.max_dout):\n",
        "        state['train'] = {\n",
        "            'loss': loss_func(args, otr * ytr).mean().item(),\n",
        "            'aloss': args.alpha * loss_func(args, otr * ytr).mean().item(),\n",
        "            'err': (otr * ytr <= 0).double().mean().item(),\n",
        "            'nd': (args.alpha * otr * ytr < 1).long().sum().item(),\n",
        "            'dfnorm': otr.pow(2).mean().sqrt(),\n",
        "            'outputs': otr if args.save_outputs else None,\n",
        "            'labels': ytr if args.save_outputs else None,\n",
        "        }\n",
        "\n",
        "        print(\"[i={d[step]:d} t={d[t]:.2e} wall={d[wall]:.0f}] [dt={d[dt]:.1e} dgrad={d[dgrad]:.1e} dout={d[dout]:.1e}] [train aL={d[train][aloss]:.2e} err={d[train][err]:.2f} nd={d[train][nd]}]\".format(d=state), flush=True)\n",
        "        dynamics.append(state)\n",
        "\n",
        "    c = torch.lstsq(otr.view(-1, 1), ktrtr).solution.flatten()\n",
        "\n",
        "    if len(xte) > len(xtr):\n",
        "        # from hessian import gradient\n",
        "        a = gradient(f(xtr) @ c, f.parameters())\n",
        "        ote = torch.stack([gradient(f(x[None]), f.parameters()) @ a for x in xte])\n",
        "    else:\n",
        "        ote = ktetr @ c\n",
        "\n",
        "    out = {\n",
        "        'dynamics': dynamics,\n",
        "        'train': {\n",
        "            'outputs': otr,\n",
        "            'labels': ytr,\n",
        "        },\n",
        "        'test': {\n",
        "            'outputs': ote,\n",
        "            'labels': yte,\n",
        "        },\n",
        "        'kernel': {\n",
        "            'train': {\n",
        "                'value': ktrtr.cpu() if args.store_kernel == 1 else None,\n",
        "                'diag': ktrtr.diag(),\n",
        "                'mean': ktrtr.mean(),\n",
        "                'std': ktrtr.std(),\n",
        "                'norm': ktrtr.norm(),\n",
        "            },\n",
        "            'test': {\n",
        "                'value': ktete.cpu() if args.store_kernel == 1 else None,\n",
        "                'diag': ktete.diag(),\n",
        "                'mean': ktete.mean(),\n",
        "                'std': ktete.std(),\n",
        "                'norm': ktete.norm(),\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def run_regular(args, f0, xtr, ytr, xte, yte):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        otr0 = f0(xtr)\n",
        "        ote0 = f0(xte)\n",
        "\n",
        "    if args.f0 == 0:\n",
        "        otr0 = torch.zeros_like(otr0)\n",
        "        ote0 = torch.zeros_like(ote0)\n",
        "\n",
        "    j = torch.randperm(min(len(xte), len(xtr)))[:10 * args.chunk]\n",
        "    ytrj = ytr[j]\n",
        "    ytej = yte[j]\n",
        "\n",
        "    t = perf_counter()\n",
        "\n",
        "    tau = args.tau_over_h * args.h\n",
        "    if args.tau_alpha_crit is not None:\n",
        "        tau *= min(1, args.tau_alpha_crit / args.alpha)\n",
        "\n",
        "    dynamics = []\n",
        "    for f, state, done in train_regular(f0, xtr, ytr, tau, args.train_time, args.alpha, partial(loss_func, args), bool(args.f0), args.max_dgrad, args.max_dout):\n",
        "        with torch.no_grad():\n",
        "            otr = f(xtr[j]) - otr0[j]\n",
        "            ote = f(xte[j]) - ote0[j]\n",
        "\n",
        "        if args.arch.split('_')[0] == 'fc':\n",
        "            def getw(f, i):\n",
        "                return torch.cat(list(getattr(f.f, \"W{}\".format(i))))\n",
        "            state['wnorm'] = [getw(f, i).norm().item() for i in range(f.f.L + 1)]\n",
        "            state['dwnorm'] = [(getw(f, i) - getw(f0, i)).norm().item() for i in range(f.f.L + 1)]\n",
        "\n",
        "        state['train'] = {\n",
        "            'loss': loss_func(args, otr * ytrj).mean().item(),\n",
        "            'aloss': args.alpha * loss_func(args, otr * ytrj).mean().item(),\n",
        "            'err': (otr * ytr[j] <= 0).double().mean().item(),\n",
        "            'nd': (args.alpha * otr * ytr[j] < 1).long().sum().item(),\n",
        "            'dfnorm': otr.pow(2).mean().sqrt(),\n",
        "            'fnorm': (otr + otr0[j]).pow(2).mean().sqrt(),\n",
        "            'outputs': otr if args.save_outputs else None,\n",
        "            'labels': ytrj if args.save_outputs else None,\n",
        "        }\n",
        "        state['test'] = {\n",
        "            'loss': loss_func(args, ote * ytej).mean().item(),\n",
        "            'aloss': args.alpha * loss_func(args, ote * ytej).mean().item(),\n",
        "            'err': (ote * yte[j] <= 0).double().mean().item(),\n",
        "            'nd': (args.alpha * ote * yte[j] < 1).long().sum().item(),\n",
        "            'dfnorm': ote.pow(2).mean().sqrt(),\n",
        "            'fnorm': (ote + ote0[j]).pow(2).mean().sqrt(),\n",
        "            'outputs': ote if args.save_outputs else None,\n",
        "            'labels': ytej if args.save_outputs else None,\n",
        "        }\n",
        "        print(\"[i={d[step]:d} t={d[t]:.2e} wall={d[wall]:.0f}] [dt={d[dt]:.1e} dgrad={d[dgrad]:.1e} dout={d[dout]:.1e}] [train aL={d[train][aloss]:.2e} err={d[train][err]:.2f} nd={d[train][nd]}/{p}] [test aL={d[test][aloss]:.2e} err={d[test][err]:.2f}]\".format(d=state, p=len(j)), flush=True)\n",
        "        dynamics.append(state)\n",
        "\n",
        "        if done or perf_counter() - t > 120:\n",
        "            t = perf_counter()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                otr = f(xtr) - otr0\n",
        "                ote = f(xte) - ote0\n",
        "\n",
        "            out = {\n",
        "                'dynamics': dynamics,\n",
        "                'train': {\n",
        "                    'f0': otr0,\n",
        "                    'outputs': otr,\n",
        "                    'labels': ytr,\n",
        "                },\n",
        "                'test': {\n",
        "                    'f0': ote0,\n",
        "                    'outputs': ote,\n",
        "                    'labels': yte,\n",
        "                }\n",
        "            }\n",
        "            yield f, out\n",
        "\n",
        "\n",
        "def run_exp(args, f0, xtr, ytr, xte, yte):\n",
        "    run = {\n",
        "        'args': args,\n",
        "        'N': sum(p.numel() for p in f0.parameters()),\n",
        "    }\n",
        "\n",
        "    if args.delta_kernel == 1 or args.init_kernel == 1:\n",
        "        init_kernel = compute_kernels(f0, xtr, xte[:len(xtr)])\n",
        "\n",
        "    if args.init_kernel == 1:\n",
        "        run['init_kernel'] = run_kernel(args, *init_kernel, f0, xtr, ytr, xte, yte)\n",
        "\n",
        "    if args.delta_kernel == 1:\n",
        "        init_kernel = (init_kernel[0].cpu(), init_kernel[2].cpu())\n",
        "    elif args.init_kernel == 1:\n",
        "        del init_kernel\n",
        "\n",
        "    if args.regular == 1:\n",
        "        for f, out in run_regular(args, f0, xtr, ytr, xte, yte):\n",
        "            run['regular'] = out\n",
        "            yield run\n",
        "\n",
        "        if args.delta_kernel == 1 or args.final_kernel == 1:\n",
        "            final_kernel = compute_kernels(f, xtr, xte[:len(xtr)])\n",
        "\n",
        "        if args.final_kernel == 1:\n",
        "            run['final_kernel'] = run_kernel(args, *final_kernel, f, xtr, ytr, xte, yte)\n",
        "\n",
        "        if args.delta_kernel == 1:\n",
        "            final_kernel = (final_kernel[0].cpu(), final_kernel[2].cpu())\n",
        "            run['delta_kernel'] = {\n",
        "                'train': (init_kernel[0] - final_kernel[0]).norm().item(),\n",
        "                'test': (init_kernel[1] - final_kernel[1]).norm().item(),\n",
        "            }\n",
        "\n",
        "    yield run\n",
        "\n",
        "\n",
        "def execute(args):\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # Check if CUDA is available and set the device accordingly\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        if args.dtype == 'float64':\n",
        "            torch.set_default_dtype(torch.float64)\n",
        "        if args.dtype == 'float32':\n",
        "            torch.set_default_dtype(torch.float32)\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print(\"CUDA is not available. Running on CPU.\")\n",
        "        if args.dtype == 'float64':\n",
        "            torch.set_default_dtype(torch.float64)\n",
        "        if args.dtype == 'float32':\n",
        "            torch.set_default_dtype(torch.float32)\n",
        "\n",
        "    if args.d is None or args.d == 0:\n",
        "        (xtr, ytr), (xte, yte) = get_binary_dataset(args.dataset, args.ptr, args.data_seed, device)\n",
        "    else:\n",
        "        (xtr, ytr), (xte, yte) = get_binary_pca_dataset(args.dataset, args.ptr, args.d, args.whitening, args.data_seed, device)\n",
        "\n",
        "    xtr = xtr.type(torch.get_default_dtype())\n",
        "    xte = xte.type(torch.get_default_dtype())\n",
        "    ytr = ytr.type(torch.get_default_dtype())\n",
        "    yte = yte.type(torch.get_default_dtype())\n",
        "\n",
        "    assert len(xte) >= args.pte\n",
        "    xte = xte[:args.pte]\n",
        "    yte = yte[:args.pte]\n",
        "\n",
        "    torch.manual_seed(args.init_seed + hash(args.alpha))\n",
        "\n",
        "    arch, act = args.arch.split('_')\n",
        "    if act == 'relu':\n",
        "        act = lambda x: 2 ** 0.5 * torch.relu(x)\n",
        "    elif act == 'tanh':\n",
        "        act = torch.tanh\n",
        "    elif act == 'softplus':\n",
        "        factor = torch.nn.functional.softplus(torch.randn(100000, dtype=torch.float64), args.spbeta).pow(2).mean().rsqrt().item()\n",
        "        act = lambda x: torch.nn.functional.softplus(x, beta=args.spbeta).mul(factor)\n",
        "    else:\n",
        "        raise ValueError('act not specified')\n",
        "\n",
        "    if arch == 'fc':\n",
        "        assert args.L is not None\n",
        "        xtr = xtr.flatten(1)\n",
        "        xte = xte.flatten(1)\n",
        "        f = FC(xtr.size(1), args.h, args.L, act, args.bias).to(device)\n",
        "    elif arch == 'cv':\n",
        "        assert args.bias == 0\n",
        "        f = CV(xtr.size(1), args.h, L1=args.cv_L1, L2=args.cv_L2, act=act, h_base=args.cv_h_base, fsz=args.cv_fsz, pad=args.cv_pad, stride_first=args.cv_stride_first).to(device)\n",
        "    elif arch == 'resnet':\n",
        "        assert args.bias == 0\n",
        "        f = Wide_ResNet(xtr.size(1), 28, args.h, act, 1, args.mix_angle).to(device)\n",
        "    else:\n",
        "        raise ValueError('arch not specified')\n",
        "\n",
        "    f = SplitEval(f, args.chunk)\n",
        "\n",
        "    torch.manual_seed(args.batch_seed)\n",
        "    for run in run_exp(args, f, xtr, ytr, xte, yte):\n",
        "        yield run\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Git情報の取得\n",
        "    git = {\n",
        "        'log': subprocess.getoutput('git log --format=\"%H\" -n 1 -z'),\n",
        "        'status': subprocess.getoutput('git status -z'),\n",
        "    }\n",
        "\n",
        "    # コマンドライン引数の設定\n",
        "    args = argparse.Namespace(\n",
        "        device='cuda',\n",
        "        dtype='float64',\n",
        "\n",
        "        init_seed=0,\n",
        "        data_seed=0,\n",
        "        batch_seed=0,\n",
        "\n",
        "        dataset='fashion',\n",
        "        ptr=10000,\n",
        "        pte=50000,\n",
        "        d=None,\n",
        "        whitening=1,\n",
        "\n",
        "        arch='fc_softplus',\n",
        "        bias=0,\n",
        "        L=3,\n",
        "        h=100,\n",
        "        mix_angle=45,\n",
        "        spbeta=5.0,\n",
        "        cv_L1=2,\n",
        "        cv_L2=2,\n",
        "        cv_h_base=1,\n",
        "        cv_fsz=5,\n",
        "        cv_pad=1,\n",
        "        cv_stride_first=1,\n",
        "\n",
        "        init_kernel=0,\n",
        "        regular=1,\n",
        "        final_kernel=0,\n",
        "        store_kernel=0,\n",
        "        delta_kernel=0,\n",
        "        save_outputs=0,\n",
        "\n",
        "        alpha=1e-4,\n",
        "        f0=1,\n",
        "\n",
        "        tau_over_h=1e-3,\n",
        "        tau_alpha_crit=1e3,\n",
        "\n",
        "        train_time=10, # 18000\n",
        "        chunk=None,\n",
        "        max_dgrad=1e-4,\n",
        "        max_dout=1e-1,\n",
        "\n",
        "        loss='softhinge',\n",
        "        lossbeta=20.0,\n",
        "\n",
        "        directory='F10k3Lsp_alpha',\n",
        "        pickle='F10k3Lsp_alpha.pkl'\n",
        "    )\n",
        "\n",
        "    # ディレクトリの作成\n",
        "    if not os.path.exists(args.directory):\n",
        "        os.makedirs(args.directory)\n",
        "\n",
        "    # pickleファイルのパスをディレクトリに基づいて変更\n",
        "    pickle_path = os.path.join(args.directory, args.pickle)\n",
        "\n",
        "    if args.pte is None:\n",
        "        args.pte = args.ptr\n",
        "\n",
        "    if args.chunk is None:\n",
        "        args.chunk = args.ptr\n",
        "\n",
        "    # 引数をpickleファイルに保存\n",
        "    torch.save(args, pickle_path)\n",
        "    try:\n",
        "        for res in execute(args):\n",
        "            res['git'] = git\n",
        "            # 結果をpickleファイルに追加で保存\n",
        "            with open(pickle_path, 'wb') as f:\n",
        "                torch.save(args, f)\n",
        "                torch.save(res, f)\n",
        "    except:\n",
        "        os.remove(pickle_path)\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJgpsMjnFNaV",
        "outputId": "048c107e-6a88-41a4-aa68-e256f2b18272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is not available. Running on CPU.\n",
            "[i=0 t=1.00e+00 wall=1] [dt=1.0e+00 dgrad=5.5e-05 dout=3.9e-07] [train aL=1.00e+00 err=0.18 nd=10000/10000] [test aL=1.00e+00 err=0.18]\n",
            "[i=1 t=2.00e+00 wall=1] [dt=1.0e+00 dgrad=5.5e-05 dout=3.9e-07] [train aL=1.00e+00 err=0.18 nd=10000/10000] [test aL=1.00e+00 err=0.18]\n",
            "[i=2 t=3.00e+00 wall=2] [dt=1.0e+00 dgrad=5.5e-05 dout=3.9e-07] [train aL=1.00e+00 err=0.18 nd=10000/10000] [test aL=1.00e+00 err=0.18]\n",
            "[i=3 t=4.00e+00 wall=2] [dt=1.0e+00 dgrad=5.5e-05 dout=3.9e-07] [train aL=1.00e+00 err=0.18 nd=10000/10000] [test aL=1.00e+00 err=0.18]\n",
            "[i=4 t=5.00e+00 wall=3] [dt=1.0e+00 dgrad=5.5e-05 dout=3.8e-07] [train aL=1.00e+00 err=0.18 nd=10000/10000] [test aL=1.00e+00 err=0.18]\n",
            "[i=5 t=6.00e+00 wall=3] [dt=1.0e+00 dgrad=5.5e-05 dout=3.8e-07] [train aL=1.00e+00 err=0.18 nd=10000/10000] [test aL=1.00e+00 err=0.18]\n",
            "[i=6 t=7.00e+00 wall=4] [dt=1.0e+00 dgrad=5.5e-05 dout=3.8e-07] [train aL=1.00e+00 err=0.18 nd=10000/10000] [test aL=1.00e+00 err=0.18]\n",
            "[i=7 t=8.00e+00 wall=5] [dt=1.0e+00 dgrad=5.5e-05 dout=3.8e-07] [train aL=1.00e+00 err=0.18 nd=10000/10000] [test aL=1.00e+00 err=0.18]\n",
            "[i=8 t=9.00e+00 wall=5] [dt=1.0e+00 dgrad=5.5e-05 dout=3.8e-07] [train aL=1.00e+00 err=0.18 nd=10000/10000] [test aL=1.00e+00 err=0.18]\n",
            "[i=9 t=1.00e+01 wall=6] [dt=1.0e+00 dgrad=5.5e-05 dout=3.8e-07] [train aL=1.00e+00 err=0.18 nd=10000/10000] [test aL=1.00e+00 err=0.18]\n",
            "[i=10 t=1.10e+01 wall=6] [dt=1.0e+00 dgrad=5.5e-05 dout=3.8e-07] [train aL=1.00e+00 err=0.18 nd=10000/10000] [test aL=1.00e+00 err=0.18]\n",
            "[i=11 t=1.20e+01 wall=7] [dt=1.0e+00 dgrad=5.5e-05 dout=3.8e-07] [train aL=1.00e+00 err=0.18 nd=10000/10000] [test aL=1.00e+00 err=0.18]\n",
            "[i=12 t=1.30e+01 wall=7] [dt=1.0e+00 dgrad=5.5e-05 dout=3.8e-07] [train aL=1.00e+00 err=0.18 nd=10000/10000] [test aL=1.00e+00 err=0.18]\n",
            "[i=13 t=1.40e+01 wall=8] [dt=1.0e+00 dgrad=5.4e-05 dout=3.7e-07] [train aL=1.00e+00 err=0.18 nd=10000/10000] [test aL=1.00e+00 err=0.18]\n",
            "[i=14 t=1.50e+01 wall=9] [dt=1.0e+00 dgrad=5.4e-05 dout=3.7e-07] [train aL=1.00e+00 err=0.18 nd=10000/10000] [test aL=1.00e+00 err=0.18]\n",
            "[i=15 t=1.60e+01 wall=10] [dt=1.0e+00 dgrad=5.4e-05 dout=3.7e-07] [train aL=1.00e+00 err=0.18 nd=10000/10000] [test aL=1.00e+00 err=0.18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main_adam"
      ],
      "metadata": {
        "id": "Tmq13o4LjN_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# main_adam.py\n",
        "# pylint: disable=bare-except, arguments-differ, no-member, missing-docstring, invalid-name, line-too-long\n",
        "import copy\n",
        "import itertools\n",
        "import os\n",
        "import subprocess\n",
        "import argparse\n",
        "from time import perf_counter\n",
        "\n",
        "import torch\n",
        "\n",
        "# from archi import CV, FC, Wide_ResNet\n",
        "# from dataset import get_binary_dataset, get_binary_pca_dataset\n",
        "# from dynamics import loglinspace\n",
        "\n",
        "\n",
        "class SplitEval(torch.nn.Module):\n",
        "    def __init__(self, f, size):\n",
        "        super().__init__()\n",
        "        self.f = f\n",
        "        self.size = size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat([self.f(x[i: i + self.size]) for i in range(0, len(x), self.size)])\n",
        "\n",
        "\n",
        "def hinge(out, y, alpha):\n",
        "    return (1 - alpha * out * y).relu().mean() / alpha\n",
        "\n",
        "\n",
        "def quad_hinge(out, y, alpha):\n",
        "    return 0.5 * (1 - alpha * out * y).relu().pow(2).mean() / alpha ** 2\n",
        "\n",
        "\n",
        "def mse(out, y, alpha):\n",
        "    return 0.5 * (1.1 - alpha * out * y).pow(2).mean() / alpha ** 2\n",
        "\n",
        "\n",
        "def run_regular(args, f0, loss, xtr, ytr, xte, yte):\n",
        "    with torch.no_grad():\n",
        "        otr0 = f0(xtr)\n",
        "        ote0 = f0(xte)\n",
        "\n",
        "    f = copy.deepcopy(f0)\n",
        "    optimizer = torch.optim.Adam(f.parameters(), args.lr)\n",
        "\n",
        "    dynamics = []\n",
        "    checkpoint_generator = loglinspace(0.1, 1000)\n",
        "    checkpoint = next(checkpoint_generator)\n",
        "    wall = perf_counter()\n",
        "\n",
        "    for step in itertools.count():\n",
        "        batch = torch.randperm(len(xtr))[:args.bs]\n",
        "        xb = xtr[batch]\n",
        "\n",
        "        loss_value = loss(f(xb) - otr0[batch], ytr[batch], args.alpha)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_value.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        save = False\n",
        "\n",
        "        if step == checkpoint:\n",
        "            checkpoint = next(checkpoint_generator)\n",
        "            assert checkpoint > step\n",
        "            save = True\n",
        "\n",
        "        if save:\n",
        "            assert len(xtr) < len(xte)\n",
        "            j = torch.randperm(len(xtr))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                otr = f(xtr[j]) - otr0[j]\n",
        "                ote = f(xte[j]) - ote0[j]\n",
        "\n",
        "            state = {\n",
        "                'step': step,\n",
        "                'wall': perf_counter() - wall,\n",
        "                'batch_loss': loss_value.item(),\n",
        "                'norm': sum(p.norm().pow(2) for p in f.parameters()).sqrt().item(),\n",
        "                'dnorm': sum((p0 - p).norm().pow(2) for p0, p in zip(f0.parameters(), f.parameters())).sqrt().item(),\n",
        "                'train': {\n",
        "                    'loss': loss(otr, ytr[j], args.alpha).item(),\n",
        "                    'aloss': args.alpha * loss(otr, ytr[j], args.alpha).item(),\n",
        "                    'aaloss': args.alpha ** 2 * loss(otr, ytr[j], args.alpha).item(),\n",
        "                    'err': (otr * ytr[j] <= 0).double().mean().item(),\n",
        "                    'nd': (args.alpha * otr * ytr[j] < 1).long().sum().item(),\n",
        "                    'dfnorm': otr.pow(2).mean().sqrt(),\n",
        "                    'fnorm': (otr + otr0[j]).pow(2).mean().sqrt(),\n",
        "                },\n",
        "                'test': {\n",
        "                    'loss': loss(ote, yte[j], args.alpha).item(),\n",
        "                    'aloss': args.alpha * loss(ote, yte[j], args.alpha).item(),\n",
        "                    'aaloss': args.alpha ** 2 * loss(ote, yte[j], args.alpha).item(),\n",
        "                    'err': (ote * yte[j] <= 0).double().mean().item(),\n",
        "                    'nd': (args.alpha * ote * yte[j] < 1).long().sum().item(),\n",
        "                    'dfnorm': ote.pow(2).mean().sqrt(),\n",
        "                    'fnorm': (ote + ote0[j]).pow(2).mean().sqrt(),\n",
        "                },\n",
        "            }\n",
        "\n",
        "            if args.arch.split('_')[0] == 'fc':\n",
        "                def getw(f, i):\n",
        "                    return torch.cat(list(getattr(f.f, \"W{}\".format(i))))\n",
        "                state['wnorm'] = [getw(f, i).norm().item() for i in range(f.f.L + 1)]\n",
        "                state['dwnorm'] = [(getw(f, i) - getw(f0, i)).norm().item() for i in range(f.f.L + 1)]\n",
        "\n",
        "            print(\"[i={d[step]:d} wall={d[wall]:.0f}] [train aL={d[train][aloss]:.2e} err={d[train][err]:.2f} nd={d[train][nd]}/{p}] [test aL={d[test][aloss]:.2e} err={d[test][err]:.2f}]\".format(d=state, p=len(j)), flush=True)\n",
        "\n",
        "            dynamics.append(state)\n",
        "\n",
        "            if state['train']['nd'] == 0:\n",
        "                break\n",
        "\n",
        "        if perf_counter() > wall + args.train_time:\n",
        "            break\n",
        "\n",
        "    with torch.no_grad():\n",
        "        otr = f(xtr) - otr0\n",
        "        ote = f(xte) - ote0\n",
        "\n",
        "    out = {\n",
        "        'dynamics': dynamics,\n",
        "        'train': {\n",
        "            'f0': otr0,\n",
        "            'outputs': otr,\n",
        "            'labels': ytr,\n",
        "        },\n",
        "        'test': {\n",
        "            'f0': ote0,\n",
        "            'outputs': ote,\n",
        "            'labels': yte,\n",
        "        }\n",
        "    }\n",
        "    return f, out\n",
        "\n",
        "\n",
        "def run_exp(args, f0, xtr, ytr, xte, yte):\n",
        "    run = {\n",
        "        'args': args,\n",
        "        'N': sum(p.numel() for p in f0.parameters()),\n",
        "    }\n",
        "\n",
        "    if args.loss == 'hinge':\n",
        "        loss = hinge\n",
        "    elif args.loss == 'quad_hinge':\n",
        "        loss = quad_hinge\n",
        "    elif args.loss == 'mse':\n",
        "        loss = mse\n",
        "    else:\n",
        "        raise ValueError('Invalid loss function')\n",
        "\n",
        "    _f, out = run_regular(args, f0, loss, xtr, ytr, xte, yte)\n",
        "    run['regular'] = out\n",
        "\n",
        "    return run\n",
        "\n",
        "\n",
        "def execute(args):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print(\"CUDA is available. Running on GPU.\")\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print(\"CUDA is not available. Running on CPU.\")\n",
        "\n",
        "\n",
        "    if args.dtype == 'float64':\n",
        "        torch.set_default_dtype(torch.float64)\n",
        "    elif args.dtype == 'float32':\n",
        "        torch.set_default_dtype(torch.float32)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported dtype specified\")\n",
        "\n",
        "\n",
        "    if args.d is None or args.d == 0:\n",
        "        (xtr, ytr), (xte, yte) = get_binary_dataset(args.dataset, args.ptr, args.data_seed, device)\n",
        "    else:\n",
        "        (xtr, ytr), (xte, yte) = get_binary_pca_dataset(args.dataset, args.ptr, args.d, args.whitening, args.data_seed, device)\n",
        "\n",
        "    xtr = xtr.type(torch.get_default_dtype())\n",
        "    xte = xte.type(torch.get_default_dtype())\n",
        "    ytr = ytr.type(torch.get_default_dtype())\n",
        "    yte = yte.type(torch.get_default_dtype())\n",
        "\n",
        "    assert len(xte) >= args.pte\n",
        "    xte = xte[:args.pte]\n",
        "    yte = yte[:args.pte]\n",
        "\n",
        "    torch.manual_seed(args.init_seed + hash(args.alpha))\n",
        "\n",
        "\n",
        "    arch, act = args.arch.split('_')\n",
        "    if act == 'relu':\n",
        "        act = lambda x: 2 ** 0.5 * torch.relu(x)\n",
        "    elif act == 'tanh':\n",
        "        act = torch.tanh\n",
        "    elif act == 'softplus':\n",
        "        factor = torch.nn.functional.softplus(torch.randn(100000, dtype=torch.float64), args.spbeta).pow(2).mean().rsqrt().item()\n",
        "        act = lambda x: torch.nn.functional.softplus(x, beta=args.spbeta).mul(factor)\n",
        "    else:\n",
        "        raise ValueError('act not specified')\n",
        "\n",
        "    if arch == 'fc':\n",
        "        assert args.L is not None\n",
        "        xtr = xtr.flatten(1)\n",
        "        xte = xte.flatten(1)\n",
        "        f = FC(xtr.size(1), args.h, args.L, act).to(device)\n",
        "    elif arch == 'cv':\n",
        "        f = CV(xtr.size(1), args.h, h_base=1, L1=2, L2=2, act=act, fsz=5, pad=1, stride_first=True).to(device)\n",
        "    elif arch == 'resnet':\n",
        "        f = Wide_ResNet(xtr.size(1), 28, args.h, act, 1, args.mix_angle).to(device)\n",
        "    else:\n",
        "        raise ValueError('arch not specified')\n",
        "\n",
        "    f = SplitEval(f, args.chunk)\n",
        "\n",
        "    torch.manual_seed(args.batch_seed)\n",
        "    run = run_exp(args, f, xtr, ytr, xte, yte)\n",
        "\n",
        "    return run\n",
        "\n",
        "\n",
        "def main():\n",
        "    git = {\n",
        "        'log': subprocess.getoutput('git log --format=\"%H\" -n 1 -z'),\n",
        "        'status': subprocess.getoutput('git status -sb -uall'),\n",
        "    }\n",
        "\n",
        "    args = argparse.Namespace(\n",
        "        dataset='fashion',\n",
        "        arch='fc_softplus',\n",
        "        h=100,\n",
        "        L=3,\n",
        "        spbeta=5,\n",
        "        p=50000,\n",
        "        ptr=10000,\n",
        "        pte=50000,\n",
        "        train_time=10, # 18000\n",
        "        max_dout=0.1,\n",
        "        max_dgrad=1e-4,\n",
        "        lossbeta=20,\n",
        "        alpha=1,\n",
        "        init_seed=0,\n",
        "        dtype='float32',\n",
        "        d=None,\n",
        "        whitening=False,\n",
        "        mix_angle=None,\n",
        "        chunk=1000,\n",
        "        bs=5000,\n",
        "        lr=0.001,\n",
        "        device='cuda',\n",
        "        loss='hinge',\n",
        "        data_seed=0,\n",
        "        batch_seed=0,\n",
        "        init_kernel=1,\n",
        "        final_kernel=0,\n",
        "        regular=0,\n",
        "        seed=0,\n",
        "        directory='F10k3Lsp_adam',\n",
        "        pickle='F10k3Lsp_adam.pkl'\n",
        "    )\n",
        "\n",
        "    # ディレクトリの作成\n",
        "    if not os.path.exists(args.directory):\n",
        "        os.makedirs(args.directory)\n",
        "\n",
        "    # pickleファイルのパスをディレクトリに基づいて変更\n",
        "    pickle_path = os.path.join(args.directory, args.pickle)\n",
        "\n",
        "    if args.pte is None:\n",
        "        args.pte = args.ptr\n",
        "\n",
        "    if args.chunk is None:\n",
        "        args.chunk = args.ptr\n",
        "\n",
        "    # 引数をpickleファイルに保存\n",
        "    torch.save(args, pickle_path)\n",
        "    try:\n",
        "        result = execute(args)\n",
        "        if isinstance(result, dict):  # Check if the result is a dictionary\n",
        "            result['git'] = git\n",
        "            with open(pickle_path, 'wb') as f:\n",
        "                torch.save(args, f)\n",
        "                torch.save(result, f)\n",
        "        else:\n",
        "            raise TypeError(\"Expected a dictionary from execute, but got: {}\".format(type(result)))\n",
        "    except Exception as e:\n",
        "        os.remove(pickle_path)\n",
        "        raise e\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17WF2RfWhrbE",
        "outputId": "8db8c7eb-a16a-465e-f348-9a763db3188b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is not available. Running on CPU.\n",
            "[i=0 wall=0] [train aL=9.95e-01 err=0.14 nd=10000/10000] [test aL=9.95e-01 err=0.14]\n",
            "[i=1 wall=1] [train aL=9.90e-01 err=0.14 nd=10000/10000] [test aL=9.90e-01 err=0.14]\n",
            "[i=2 wall=1] [train aL=9.85e-01 err=0.14 nd=10000/10000] [test aL=9.85e-01 err=0.14]\n",
            "[i=3 wall=2] [train aL=9.80e-01 err=0.14 nd=10000/10000] [test aL=9.80e-01 err=0.14]\n",
            "[i=4 wall=2] [train aL=9.75e-01 err=0.14 nd=10000/10000] [test aL=9.75e-01 err=0.14]\n",
            "[i=5 wall=2] [train aL=9.70e-01 err=0.14 nd=10000/10000] [test aL=9.70e-01 err=0.14]\n",
            "[i=6 wall=3] [train aL=9.65e-01 err=0.14 nd=10000/10000] [test aL=9.65e-01 err=0.14]\n",
            "[i=7 wall=3] [train aL=9.60e-01 err=0.14 nd=10000/10000] [test aL=9.60e-01 err=0.14]\n",
            "[i=8 wall=3] [train aL=9.55e-01 err=0.14 nd=10000/10000] [test aL=9.55e-01 err=0.14]\n",
            "[i=9 wall=4] [train aL=9.50e-01 err=0.14 nd=10000/10000] [test aL=9.50e-01 err=0.14]\n",
            "[i=10 wall=4] [train aL=9.45e-01 err=0.14 nd=10000/10000] [test aL=9.45e-01 err=0.14]\n",
            "[i=11 wall=4] [train aL=9.40e-01 err=0.14 nd=10000/10000] [test aL=9.40e-01 err=0.14]\n",
            "[i=13 wall=4] [train aL=9.30e-01 err=0.14 nd=10000/10000] [test aL=9.30e-01 err=0.14]\n",
            "[i=15 wall=5] [train aL=9.20e-01 err=0.14 nd=10000/10000] [test aL=9.20e-01 err=0.14]\n",
            "[i=17 wall=5] [train aL=9.09e-01 err=0.14 nd=10000/10000] [test aL=9.10e-01 err=0.14]\n",
            "[i=19 wall=5] [train aL=8.98e-01 err=0.14 nd=10000/10000] [test aL=8.99e-01 err=0.14]\n",
            "[i=21 wall=6] [train aL=8.87e-01 err=0.14 nd=10000/10000] [test aL=8.88e-01 err=0.14]\n",
            "[i=24 wall=6] [train aL=8.70e-01 err=0.14 nd=10000/10000] [test aL=8.71e-01 err=0.14]\n",
            "[i=27 wall=7] [train aL=8.52e-01 err=0.14 nd=10000/10000] [test aL=8.53e-01 err=0.14]\n",
            "[i=30 wall=7] [train aL=8.32e-01 err=0.14 nd=10000/10000] [test aL=8.34e-01 err=0.14]\n",
            "[i=33 wall=7] [train aL=8.12e-01 err=0.14 nd=10000/10000] [test aL=8.13e-01 err=0.14]\n",
            "[i=37 wall=8] [train aL=7.82e-01 err=0.14 nd=10000/10000] [test aL=7.83e-01 err=0.14]\n",
            "[i=41 wall=8] [train aL=7.49e-01 err=0.14 nd=10000/10000] [test aL=7.50e-01 err=0.14]\n",
            "[i=46 wall=9] [train aL=7.03e-01 err=0.14 nd=10000/10000] [test aL=7.04e-01 err=0.14]\n",
            "[i=51 wall=9] [train aL=6.51e-01 err=0.14 nd=9993/10000] [test aL=6.53e-01 err=0.14]\n",
            "[i=57 wall=10] [train aL=5.84e-01 err=0.14 nd=9468/10000] [test aL=5.85e-01 err=0.14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notation\n",
        "\n",
        "The the code and in the article, the conventions differ.\n",
        "\n",
        "change 1\n",
        "- code: `loss = 1/alpha etc`\n",
        "- article: `loss = 1/alpha^2 etc`\n",
        "\n",
        "change 2\n",
        "- code: `1/h` at the end of the network\n",
        "- article: `1/sqrt(h)` at the end of the network\n",
        "\n",
        "```\n",
        "alpha_code = sqrt(h) alpha_article\n",
        "\n",
        "t_code = sqrt(h) / alpha_article * t_article\n",
        "t_article = alpha_code / h * t_code\n",
        "\n",
        "t_code / h = t_article / (sqrt(h) alpha_article)\n",
        "```"
      ],
      "metadata": {
        "id": "9fDsIAiDk9p0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import glob\n",
        "import functools\n",
        "import pickle\n",
        "import math\n",
        "import numpy as np\n",
        "import itertools\n",
        "# from grid import load, print_info\n",
        "\n",
        "####################################################################################################\n",
        "from collections import defaultdict, namedtuple\n",
        "\n",
        "Run = namedtuple(\"Run\", \"file, ctime, args, data\")\n",
        "GLOBALCACHE = defaultdict(dict)\n",
        "\n",
        "def deepmap(fun, data):\n",
        "    if isinstance(data, (list, tuple, set, frozenset)):\n",
        "        return type(data)(deepmap(fun, x) for x in data)\n",
        "\n",
        "    if isinstance(data, dict):\n",
        "        return {key: deepmap(fun, x) for key, x in data.items()}\n",
        "\n",
        "    return fun(data)\n",
        "\n",
        "def torch_to_numpy(data):\n",
        "    import torch\n",
        "\n",
        "    def fun(x):\n",
        "        if isinstance(x, torch.Tensor):\n",
        "            return x.numpy()\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    return deepmap(fun, data)\n",
        "\n",
        "def identity(x):\n",
        "    return x\n",
        "\n",
        "def to_dict(a):\n",
        "    if not isinstance(a, dict):\n",
        "        return a.__dict__\n",
        "    return a\n",
        "\n",
        "def load_file(f):\n",
        "    with open(f, \"rb\") as rb:\n",
        "        yield to_dict(pickle.load(rb))\n",
        "        yield pickle.load(rb)\n",
        "\n",
        "def _load_iter(\n",
        "    directory,\n",
        "    pred_args=None,\n",
        "    pred_run=None,\n",
        "    cache=True,\n",
        "    extractor=None,\n",
        "    convertion=None,\n",
        "    tqdm=identity,\n",
        "):\n",
        "    if extractor is not None:\n",
        "        cache = False\n",
        "\n",
        "    directory = os.path.normpath(directory)\n",
        "\n",
        "    if not os.path.isdir(directory):\n",
        "        raise NotADirectoryError(\"{} does not exists\".format(directory))\n",
        "\n",
        "    cache_runs = GLOBALCACHE[(directory, convertion)] if cache else dict()\n",
        "\n",
        "    for file in tqdm(sorted(glob.glob(os.path.join(directory, \"*.pk\")))):\n",
        "        ctime = os.path.getctime(file)\n",
        "\n",
        "        if file in cache_runs and ctime == cache_runs[file].ctime:\n",
        "            x = cache_runs[file]\n",
        "\n",
        "            if pred_args is not None and not pred_args(x.args):\n",
        "                continue\n",
        "\n",
        "            if pred_run is not None and not pred_run(x.data):\n",
        "                continue\n",
        "\n",
        "            yield (x.args, x.data)\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            f = load_file(file)\n",
        "            args = next(f)\n",
        "\n",
        "            if pred_args is not None and not pred_args(args):\n",
        "                continue\n",
        "\n",
        "            data = next(f)\n",
        "        except (pickle.PickleError, FileNotFoundError, EOFError):\n",
        "            continue\n",
        "\n",
        "        if extractor is not None:\n",
        "            data = extractor(data)\n",
        "\n",
        "        if pred_run is not None and not pred_run(data):\n",
        "            continue\n",
        "\n",
        "        if convertion == \"torch_to_numpy\":\n",
        "            data = torch_to_numpy(data)\n",
        "        elif convertion == \"args\":\n",
        "            data = args\n",
        "        elif convertion == \"file_args\":\n",
        "            data = (file, args)\n",
        "        else:\n",
        "            assert convertion is None\n",
        "\n",
        "        x = Run(file=file, ctime=ctime, args=args, data=data)\n",
        "        cache_runs[file] = x\n",
        "\n",
        "        yield (x.args, x.data)\n",
        "\n",
        "def load_iter(\n",
        "    directory,\n",
        "    pred_args=None,\n",
        "    pred_run=None,\n",
        "    cache=True,\n",
        "    extractor=None,\n",
        "    convertion=None,\n",
        "    tqdm=identity,\n",
        "    with_args=False,\n",
        "):\n",
        "    for d in directory.split(\":\"):\n",
        "        for a, r in _load_iter(d, pred_args, pred_run, cache, extractor, convertion, tqdm):\n",
        "            if with_args:\n",
        "                yield a, r\n",
        "            else:\n",
        "                yield r\n",
        "\n",
        "def load(\n",
        "    directory,\n",
        "    pred_args=None,\n",
        "    pred_run=None,\n",
        "    cache=True,\n",
        "    extractor=None,\n",
        "    convertion=None,\n",
        "    tqdm=identity,\n",
        "    with_args=False,\n",
        "):\n",
        "    return list(load_iter(directory, pred_args, pred_run, cache, extractor, convertion, tqdm=tqdm, with_args=with_args))\n",
        "####################################################################################################\n",
        "\n",
        "def mean(x):\n",
        "    x = list(x)\n",
        "    return sum(x) / len(x)\n",
        "\n",
        "def median(x):\n",
        "    x = sorted(list(x))\n",
        "    return x[len(x) // 2]\n",
        "\n",
        "def triangle(a, b, c, d=None, slope=None, other=False, color=None, fmt=\"{:.2f}\", textpos=None):\n",
        "    import math\n",
        "\n",
        "    if slope is not None and d is None:\n",
        "        d = math.exp(math.log(c) + slope * (math.log(b) - math.log(a)))\n",
        "    if slope is not None and c is None:\n",
        "        c = math.exp(math.log(d) - slope * (math.log(b) - math.log(a)))\n",
        "    if color is None:\n",
        "        color = 'k'\n",
        "\n",
        "    plt.plot([a, b], [c, d], color=color)\n",
        "    if other:\n",
        "        plt.plot([a, b], [c, c], color=color)\n",
        "        plt.plot([b, b], [c, d], color=color)\n",
        "    else:\n",
        "        plt.plot([a, b], [d, d], color=color)\n",
        "        plt.plot([a, a], [c, d], color=color)\n",
        "\n",
        "    s = (math.log(d) - math.log(c)) / (math.log(b) - math.log(a))\n",
        "    if other:\n",
        "        x = math.exp(0.7 * math.log(b) + 0.3 * math.log(a))\n",
        "        y = math.exp(0.7 * math.log(c) + 0.3 * math.log(d))\n",
        "    else:\n",
        "        x = math.exp(0.7 * math.log(a) + 0.3 * math.log(b))\n",
        "        y = math.exp(0.7 * math.log(d) + 0.3 * math.log(c))\n",
        "    if textpos:\n",
        "        x = textpos[0]\n",
        "        y = textpos[1]\n",
        "    plt.annotate(fmt.format(s), (x, y), horizontalalignment='center', verticalalignment='center')\n",
        "    return s\n",
        "\n",
        "def nd(x, a):\n",
        "    assert not torch.isnan(x['outputs']).any()\n",
        "    return (a * x['outputs'] * x['labels'] < 1).nonzero().numel()\n",
        "\n",
        "def err(x):\n",
        "    assert not torch.isnan(x['outputs']).any()\n",
        "    return (x['outputs'] * x['labels'] <= 0).double().mean().item()\n",
        "\n",
        "def enserr(xs):\n",
        "    f = mean(x['outputs'] for x in xs)\n",
        "    y = xs[0]['labels']\n",
        "    assert all((x['labels'] == y).all() for x in xs)\n",
        "    return (f * y <= 0).double().mean().item()\n",
        "\n",
        "def var(outs, alpha):\n",
        "    otr = alpha * torch.stack(outs)\n",
        "    return otr.sub(otr.mean(0)).pow(2).mean(1).sum(0).item() / (otr.size(0) - 1)\n",
        "\n",
        "def texnum(x, mfmt='{}'):\n",
        "    m, e = \"{:e}\".format(x).split('e')\n",
        "    m, e = float(m), int(e)\n",
        "    mx = mfmt.format(m)\n",
        "    if e == 0:\n",
        "        if m == 1:\n",
        "            return \"1\"\n",
        "        return mx\n",
        "    ex = \"10^{{{}}}\".format(e)\n",
        "    if m == 1:\n",
        "        return ex\n",
        "    return \"{}\\;{}\".format(mx, ex)\n",
        "\n",
        "def logfilter(x, y, num):\n",
        "    import numpy as np\n",
        "    import scipy.ndimage\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "    x = np.log(x)\n",
        "    xi = np.linspace(min(x), max(x), num)\n",
        "    yi = np.interp(xi, x, y)\n",
        "    yf = scipy.ndimage.filters.gaussian_filter1d(yi, 2)\n",
        "    return np.exp(xi), yf\n",
        "\n",
        "def yavg(xi, x, y):\n",
        "    import numpy as np\n",
        "    xi = np.array(xi)\n",
        "    xmin = min(np.min(x) for x in x)\n",
        "    xmax = min(np.max(x) for x in x)\n",
        "    xi = xi[np.logical_and(xmin < xi, xi < xmax)]\n",
        "    y = [np.interp(xi, np.array(x), np.array(y)) for x, y in zip(x, y)]\n",
        "    y = np.mean(y, axis=0)\n",
        "    return xi, y\n",
        "\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "@ticker.FuncFormatter\n",
        "def format_percent(x, pos=None):\n",
        "    x = 100 * x\n",
        "    if x % 1 > 0.05:\n",
        "        return r\"${:.1f}\\%$\".format(x)\n",
        "    else:\n",
        "        return r\"${:.0f}\\%$\".format(x)"
      ],
      "metadata": {
        "id": "xWhqtA5DlNNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "ZUQJ-YYvo2jT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax1 = plt.subplots(1, 1, figsize=(2.3, 2), dpi=130)\n",
        "\n",
        "\n",
        "plt.sca(ax1)\n",
        "x = torch.linspace(-0.7, 1.5, 200)\n",
        "plt.plot(x, x.neg().add(1).relu(), label='hinge')\n",
        "plt.plot(x, torch.nn.functional.softplus(x.neg().add(1), beta=20), label=r'soft-hinge $\\beta=20$')\n",
        "plt.plot(x, torch.nn.functional.softplus(x.neg().add(1), beta=5), label=r'soft-hinge $\\beta=5$')\n",
        "plt.plot(x, torch.nn.functional.softplus(x.neg().add(1), beta=1), label=r'soft-hinge $\\beta=1$')\n",
        "\n",
        "plt.legend(handlelength=1, labelspacing=0, frameon=False)\n",
        "plt.xlabel(r'$fy$')\n",
        "plt.ylabel(r'$\\ell(fy)$')\n",
        "plt.xlim(min(x), max(x))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('loss.pdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "aDpHhTg_o5MY",
        "outputId": "67b99d79-2ca0-46a9-c3e3-66c535cc2a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 299x260 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Disentangling feature learning versus lazy learning from performance"
      ],
      "metadata": {
        "id": "pgYSKN_Oo_D8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load(\"F10k3Lsp_alpha\")\n",
        "load(\"F10k3Lsp_adam\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXbuAikrxpuF",
        "outputId": "f97c4bfa-19f9-477f-e158-b73249034334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, [[ax1, ax2], [ax3, ax4]] = plt.subplots(2, 2, figsize=(6, 5), dpi=130)\n",
        "\n",
        "\n",
        "\n",
        "plt.sca(ax1)\n",
        "x1, x2 = 20, 10000\n",
        "y1, y2 = 20 ** -0.5, 10000 ** -0.5\n",
        "plt.plot([x1, x2], [y1, y2], 'k', linewidth=2)\n",
        "x = torch.linspace(10, 20, 20)\n",
        "plt.plot(x, torch.exp(5*(x.log() - math.log(x1)) ** 2 + (math.log(y2)-math.log(y1))/(math.log(x2)-math.log(x1)) * (x.log()-math.log(x1)) + math.log(y1)), 'k--', linewidth=2)\n",
        "\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.xlim(6, 10000)\n",
        "plt.ylim(1e-6, 1e7)\n",
        "\n",
        "plt.annotate(r\"feature\", (3e1, 1.5e-3), horizontalalignment='center', verticalalignment='center')\n",
        "plt.annotate(r\"lazy\", (3e1, 1e1), horizontalalignment='center', verticalalignment='center')\n",
        "\n",
        "plt.annotate(\"NTK\\n(lazy)\", xy=(9e3, 1e3), xytext=(1.8e3, 1e3), fontsize=7, arrowprops=dict(arrowstyle=\"->\"), horizontalalignment='center', verticalalignment='center')\n",
        "# plt.annotate(\"MF-lazy\", xy=(9e3, 10 * 9e3 ** -0.5), xytext=(15e2, 10 * 15e2 ** -0.5), fontsize=7, arrowprops=dict(arrowstyle=\"->\"), horizontalalignment='center', verticalalignment='center')\n",
        "plt.annotate(\"MF-feaure\", xy=(9e3, 0.1 * 9e3 ** -0.5), xytext=(13e2, 0.1 * 13e2 ** -0.5), fontsize=7, arrowprops=dict(arrowstyle=\"->\"), horizontalalignment='center', verticalalignment='center')\n",
        "\n",
        "plt.plot([20, 1100], [1e-4 * 20 ** -0.5, 1e-4 * 1100 ** -0.5], '--k', linewidth=0.8)\n",
        "plt.plot([20, 1100], [1e4 * 20 ** -0.5, 1e4 * 1100 ** -0.5], '--k', linewidth=0.8)\n",
        "plt.plot([100, 100], [1e-4 * 100 ** -0.5, 1e6 * 100 ** -0.5], '--k', linewidth=0.8)\n",
        "plt.plot([1000, 1000], [1e-4 * 1000 ** -0.5, 1e6 * 1000 ** -0.5], '--k', linewidth=0.8)\n",
        "plt.annotate(r\"(b)\", (1.5e1, 2.5e3), fontsize=8, horizontalalignment='center', verticalalignment='center')\n",
        "plt.annotate(r\"(b)\", (1.5e1, 2.5e-5), fontsize=8, horizontalalignment='center', verticalalignment='center')\n",
        "plt.annotate(r\"(c-d)\", (1e2, 2e5), fontsize=8, horizontalalignment='center', verticalalignment='center')\n",
        "plt.annotate(r\"(c-d)\", (1e3, 7e4), fontsize=8, horizontalalignment='center', verticalalignment='center')\n",
        "\n",
        "plt.xlabel(r'$h$')\n",
        "plt.ylabel(r'$\\alpha$')\n",
        "plt.title('(a)')\n",
        "\n",
        "\n",
        "\n",
        "plt.sca(ax2)\n",
        "runs = load(\"F10k3Lsp_h_init\")\n",
        "runs = [r for r in runs if 'init_kernel' in r]\n",
        "runs = [r for r in runs if r['args'].tau_over_h == 0]\n",
        "runs = [r for r in runs if nd(r['init_kernel']['train'], r['args'].alpha) == 0]\n",
        "\n",
        "hs = sorted({r['args'].h for r in runs})\n",
        "vs = [mean(err(r['init_kernel']['test']) for r in runs if r['args'].h == h) for h in hs]\n",
        "plt.plot(hs, vs, label=r'init. ker.', color='k')\n",
        "\n",
        "runs = load(\"F10k3Lsp_h\", predicate=lambda args: args.alpha in [1e-4, 1e-2, 1e0, 1e4])\n",
        "runs = [r for r in runs if 'regular' in r]\n",
        "runs = [r for r in runs if nd(r['regular']['train'], r['args'].alpha) == 0]\n",
        "\n",
        "for a in sorted({r['args'].alpha for r in runs}, reverse=True):\n",
        "    rs = [r for r in runs if r['args'].alpha == a]\n",
        "\n",
        "    hs = sorted({r['args'].h for r in rs})\n",
        "    vs = [mean(err(r['regular']['test']) for r in rs if r['args'].h == h) for h in hs]\n",
        "    plt.plot(hs, vs, label=r'$\\sqrt{{h}} \\alpha = {}$'.format(texnum(a)))\n",
        "\n",
        "\n",
        "plt.yticks([0, 0.01, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045], ['0', '1%', '2%', '2.5%', '3%', '3.5%', '4%', '4.5%'])\n",
        "plt.xscale('log')\n",
        "plt.legend(labelspacing=0, frameon=False)\n",
        "plt.xlabel('$h$')\n",
        "plt.ylabel('test error')\n",
        "plt.ylim(0.025, 0.05)\n",
        "plt.xlim(10, 1390)\n",
        "plt.title('(b)')\n",
        "\n",
        "\n",
        "\n",
        "plt.sca(ax3)\n",
        "runs = load(\"F10k3Lsp_alpha\")\n",
        "runs = [r for r in runs if r['args'].tau_over_h == 0]\n",
        "runs = [r for r in runs if nd(r['regular']['train'], r['args'].alpha) == 0]\n",
        "hs = sorted({r['args'].h for r in runs})\n",
        "\n",
        "for h in hs:\n",
        "    rs = [r for r in runs if r['args'].h == h]\n",
        "    als = sorted({r['args'].alpha for r in rs})\n",
        "\n",
        "    xs = [a / h**0.5 for a in als]\n",
        "    vs = [mean(err(r['regular']['test']) for r in rs if r['args'].alpha == a) for a in als]\n",
        "    plt.plot(xs, vs, label=r'$h = {}$'.format(h))\n",
        "\n",
        "plt.xscale('log')\n",
        "plt.legend(labelspacing=0, frameon=False)\n",
        "plt.xlabel(r'$\\alpha$')\n",
        "plt.ylabel('test error')\n",
        "plt.yticks([0, 0.01, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045], ['0', '1%', '2%', '2.5%', '3%', '3.5%', '4%', '4.5%'])\n",
        "plt.xlim(4e-6, 1e6)\n",
        "plt.ylim(0.025, 0.035)\n",
        "plt.title('(c)')\n",
        "\n",
        "\n",
        "\n",
        "plt.sca(ax4)\n",
        "runs = load(\"F10k3Lsp_alpha\")\n",
        "runs = [r for r in runs if r['args'].tau_over_h == 0]\n",
        "runs = [r for r in runs if nd(r['regular']['train'], r['args'].alpha) == 0]\n",
        "hs = sorted({r['args'].h for r in runs})\n",
        "\n",
        "for h in hs:\n",
        "    rs = [r for r in runs if r['args'].h == h]\n",
        "    als = sorted({r['args'].alpha for r in rs})\n",
        "    als = [a for a in als if a > 1e-1]\n",
        "\n",
        "    vs = [mean(err(r['regular']['test']) for r in rs if r['args'].alpha == a) for a in als]\n",
        "    m1 = min(vs)\n",
        "    m2 = max(vs)\n",
        "    vs = [(x - m1) / (m2 - m1) for x in vs]\n",
        "    plt.plot(als, vs, label=r'$h = {}$'.format(h))\n",
        "\n",
        "plt.xscale('log')\n",
        "plt.legend(labelspacing=0, frameon=False)\n",
        "plt.xlabel(r'$\\sqrt{h} \\alpha$')\n",
        "plt.ylabel('rescaled test error')\n",
        "plt.xlim(min(als), max(als))\n",
        "plt.title('(d)')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('test_error.pgf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "G8wvbXTppAIt",
        "outputId": "581d1f74-aeb7-4c4c-d326-b528fbca583e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotADirectoryError",
          "evalue": "F10k3Lsp_h_init does not exists",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-5b714ea2e3ea>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mruns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F10k3Lsp_h_init\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mruns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mruns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'init_kernel'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mruns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mruns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'args'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau_over_h\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ce592b9e5126>\u001b[0m in \u001b[0;36mload\u001b[0;34m(directory, pred_args, pred_run, cache, extractor, convertion, tqdm, with_args)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mwith_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m ):\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvertion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;31m####################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ce592b9e5126>\u001b[0m in \u001b[0;36mload_iter\u001b[0;34m(directory, pred_args, pred_run, cache, extractor, convertion, tqdm, with_args)\u001b[0m\n\u001b[1;32m    125\u001b[0m ):\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_load_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvertion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ce592b9e5126>\u001b[0m in \u001b[0;36m_load_iter\u001b[0;34m(directory, pred_args, pred_run, cache, extractor, convertion, tqdm)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotADirectoryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} does not exists\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mcache_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGLOBALCACHE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvertion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: F10k3Lsp_h_init does not exists"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 780x650 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}