{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNHsQfrydkEitJuRNTotqHO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kodai-utsunomiya/memorization-and-generalization/blob/main/Grokking_Generalization_Beyond_Overfitting_on_Small_Algorithmic_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from torch import Tensor\n",
        "from einops import rearrange, repeat\n",
        "from math import ceil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define operations and data functions\n",
        "DIVISION_MODULO_OPERATIONS = {\n",
        "    \"x/y\": lambda x, y, p: (x * y % p, y, x),\n",
        "}\n",
        "\n",
        "ALL_MODULO_OPERATIONS = {\n",
        "    \"x+y\": lambda x, y, _: (x, y, x + y),\n",
        "    \"x-y\": lambda x, y, _: (x, y, x - y),\n",
        "    **DIVISION_MODULO_OPERATIONS,\n",
        "}\n",
        "\n",
        "ALL_OPERATIONS = {\n",
        "    **ALL_MODULO_OPERATIONS,\n",
        "}\n",
        "\n",
        "def operation_mod_p_data(operation: str, p: int, eq_token: int, op_token: int):\n",
        "    x = torch.arange(0, p)\n",
        "    y = torch.arange(0 if operation in DIVISION_MODULO_OPERATIONS else 1, p)\n",
        "    x, y = torch.cartesian_prod(x, y).T\n",
        "\n",
        "    eq = torch.ones_like(x) * eq_token\n",
        "    op = torch.ones_like(x) * op_token\n",
        "\n",
        "    x, y, labels = ALL_OPERATIONS[operation](x, y, p)\n",
        "\n",
        "    inputs = torch.stack([x, op, y, eq], dim=1)\n",
        "\n",
        "    return inputs, labels\n",
        "\n",
        "def get_data(operation: str, prime: int, training_fraction: float, batch_size: int):\n",
        "    inputs, labels = operation_mod_p_data(operation, prime, prime, prime+1)\n",
        "    dataset = TensorDataset(inputs, labels)\n",
        "\n",
        "    train_size = int(training_fraction * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    batch_size = min(batch_size, ceil(len(dataset) / 2))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "# Define the model\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, dim_model: int, n_heads: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn = nn.MultiheadAttention(dim_model, n_heads)\n",
        "        self.self_attn_norm = nn.LayerNorm(dim_model)\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(dim_model, dim_model * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim_model * 4, dim_model)\n",
        "        )\n",
        "        self.ffn_norm = nn.LayerNorm(dim_model)\n",
        "\n",
        "    def forward(self, x: Tensor):\n",
        "        attn_mask = torch.full(\n",
        "            (len(x), len(x)), -float(\"Inf\"), device=x.device, dtype=x.dtype\n",
        "        )\n",
        "        attn_mask = torch.triu(attn_mask, diagonal=1)\n",
        "\n",
        "        a1, _ = self.self_attn(x, x, x, attn_mask=attn_mask)\n",
        "        a1 = self.self_attn_norm(x + a1)\n",
        "        a2 = self.ffn(a1)\n",
        "        a2 = self.ffn_norm(a1 + a2)\n",
        "\n",
        "        return a2\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, num_layers: int, dim_model: int, num_heads: int, num_tokens: int, seq_len: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.token_embeddings = nn.Embedding(num_tokens, dim_model)\n",
        "        self.position_embeddings = nn.Embedding(seq_len, dim_model)\n",
        "        self.model = nn.Sequential(\n",
        "            *[DecoderBlock(dim_model, num_heads) for _ in range(num_layers)],\n",
        "            nn.LayerNorm(dim_model),\n",
        "            nn.Linear(dim_model, num_tokens)\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs: Tensor):\n",
        "        batch_size, context_len = inputs.shape\n",
        "\n",
        "        token_embedding = self.token_embeddings(inputs)\n",
        "\n",
        "        positions = repeat(torch.arange(context_len, device=inputs.device), \"p -> b p\", b=batch_size)\n",
        "        position_embedding = self.position_embeddings(positions)\n",
        "\n",
        "        embedding = token_embedding + position_embedding\n",
        "\n",
        "        embedding = rearrange(embedding, 'b s d -> s b d')\n",
        "\n",
        "        return self.model(embedding)\n",
        "\n",
        "# Training and evaluation functions\n",
        "def evaluate(model, data_loader, device, metrics, step=None):\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    correct = 0\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            inputs, labels = batch\n",
        "            output = model(inputs)[-1, :, :]\n",
        "            correct += (torch.argmax(output, dim=1) == labels).sum().item()\n",
        "            total_loss += criterion(output, labels).item() * len(labels)\n",
        "\n",
        "    accuracy = correct / len(data_loader.dataset)\n",
        "    loss = total_loss / len(data_loader.dataset)\n",
        "\n",
        "    if step is not None:\n",
        "        metrics['validation/accuracy'].append((step, accuracy))\n",
        "        metrics['validation/loss'].append((step, loss))\n",
        "    else:\n",
        "        metrics['validation/accuracy'].append(accuracy)\n",
        "        metrics['validation/loss'].append(loss)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def train(model, train_loader, optimizer, scheduler, val_loader, device, metrics, step, record_frequency, config):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    pbar = tqdm(total=len(train_loader.dataset), desc=\"Training Progress\", unit='sample')\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs, labels = batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)[-1, :, :]\n",
        "        loss = criterion(output, labels)\n",
        "        acc = (torch.argmax(output, dim=1) == labels).sum().item() / len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Update metrics at the end of each batch\n",
        "        if step % record_frequency == 0:\n",
        "            metrics['training/accuracy'].append((step, acc))\n",
        "            metrics['training/loss'].append((step, loss.item()))\n",
        "\n",
        "        pbar.update(inputs.size(0))\n",
        "\n",
        "        # Evaluate validation set every `record_frequency` steps\n",
        "        if step % record_frequency == 0:\n",
        "            metrics = evaluate(model, val_loader, device, metrics, step)\n",
        "\n",
        "        step += 1\n",
        "\n",
        "        # Check if max number of steps is reached\n",
        "        if step >= config['num_steps']:\n",
        "            break\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    return metrics, step\n",
        "\n",
        "# Execute the training and evaluation\n",
        "# Configuration\n",
        "config = {\n",
        "    'operation': 'x/y',\n",
        "    'training_fraction': 0.3,\n",
        "    'prime': 97,\n",
        "    'num_layers': 2,\n",
        "    'dim_model': 128,\n",
        "    'num_heads': 4,\n",
        "    'batch_size': 512,\n",
        "    'learning_rate': 1e-3,\n",
        "    'weight_decay': 1,\n",
        "    'num_steps': 10000,  # int(1e6)\n",
        "    'max_epochs': int(1e8),\n",
        "    'record_frequency': 10,  # Frequency of recording metrics\n",
        "    'show_progress_bar': False,\n",
        "    'device': 'cpu',\n",
        "}\n",
        "\n",
        "# Training and evaluation functions\n",
        "def train(model, train_loader, optimizer, scheduler, val_loader, device, metrics, step, record_frequency, config):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Conditional progress bar based on config\n",
        "    pbar = tqdm(total=len(train_loader.dataset), desc=\"Training Progress\", unit='sample') if config.get('show_progress_bar', True) else None\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs, labels = batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)[-1, :, :]\n",
        "        loss = criterion(output, labels)\n",
        "        acc = (torch.argmax(output, dim=1) == labels).sum().item() / len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Update metrics at the end of each batch\n",
        "        if step % record_frequency == 0:\n",
        "            metrics['training/accuracy'].append((step, acc))\n",
        "            metrics['training/loss'].append((step, loss.item()))\n",
        "\n",
        "        if pbar:\n",
        "            pbar.update(inputs.size(0))\n",
        "\n",
        "        # Evaluate validation set every `record_frequency` steps\n",
        "        if step % record_frequency == 0:\n",
        "            metrics = evaluate(model, val_loader, device, metrics, step)\n",
        "\n",
        "        step += 1\n",
        "\n",
        "        # Check if max number of steps is reached\n",
        "        if step >= config['num_steps']:\n",
        "            break\n",
        "\n",
        "    if pbar:\n",
        "        pbar.close()\n",
        "\n",
        "    return metrics, step\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "train_loader, val_loader = get_data(\n",
        "    config['operation'],\n",
        "    config['prime'],\n",
        "    config['training_fraction'],\n",
        "    config['batch_size']\n",
        ")\n",
        "model = Transformer(\n",
        "    num_layers=config['num_layers'],\n",
        "    dim_model=config['dim_model'],\n",
        "    num_heads=config['num_heads'],\n",
        "    num_tokens=config['prime'] + 2,\n",
        "    seq_len=5\n",
        ").to(device)\n",
        "optimizer = optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=config['learning_rate'],\n",
        "    betas=(0.9, 0.98),\n",
        "    weight_decay=config['weight_decay']\n",
        ")\n",
        "scheduler = optim.lr_scheduler.LinearLR(\n",
        "    optimizer, start_factor=0.1, total_iters=9\n",
        ")\n",
        "\n",
        "num_epochs = min(config['max_epochs'], ceil(config['num_steps'] / len(train_loader)))\n",
        "\n",
        "metrics = {\n",
        "    'training/accuracy': [],\n",
        "    'training/loss': [],\n",
        "    'validation/accuracy': [],\n",
        "    'validation/loss': []\n",
        "}\n",
        "\n",
        "step = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "    metrics, step = train(model, train_loader, optimizer, scheduler, val_loader, device, metrics, step, config['record_frequency'], config)\n",
        "\n",
        "    # Print metrics for the current epoch in a single line\n",
        "    train_acc = metrics['training/accuracy'][-1][1]\n",
        "    train_loss = metrics['training/loss'][-1][1]\n",
        "    val_acc = metrics['validation/accuracy'][-1][1] if len(metrics['validation/accuracy']) > 0 else 0\n",
        "    val_loss = metrics['validation/loss'][-1][1] if len(metrics['validation/loss']) > 0 else 0\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}: Training Accuracy = {train_acc:.4f}, Training Loss = {train_loss:.4f}, Validation Accuracy = {val_acc:.4f}, Validation Loss = {val_loss:.4f}\")\n",
        "\n",
        "    # Check if max number of steps is reached\n",
        "    if step >= config['num_steps']:\n",
        "        print(\"Stopping early as maximum number of steps has been reached.\")\n",
        "        break\n",
        "\n",
        "# Ensure the final step is evaluated for training metrics\n",
        "metrics['training/accuracy'].append((step, train_acc))\n",
        "metrics['training/loss'].append((step, train_loss))\n",
        "metrics = evaluate(model, val_loader, device, metrics, step)\n",
        "\n",
        "# Plot metrics\n",
        "training_steps, training_accuracy = zip(*metrics['training/accuracy'])\n",
        "training_steps, training_loss = zip(*metrics['training/loss'])\n",
        "val_steps, validation_accuracy = zip(*metrics['validation/accuracy'])\n",
        "val_steps, validation_loss = zip(*metrics['validation/loss'])\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.semilogx(training_steps, [acc * 100 for acc in training_accuracy], color='red', label='Train')\n",
        "plt.semilogx(val_steps, [acc * 100 for acc in validation_accuracy], color='green', label='Val')\n",
        "plt.xlabel('Optimization Steps')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.title(f'Modular Division (training on {int(config[\"training_fraction\"] * 100)}% of data)')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.semilogx(training_steps, training_loss, color='red', label='Train')\n",
        "plt.semilogx(val_steps, validation_loss, color='green', label='Val')\n",
        "plt.xlabel('Optimization Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title(f'Modular Division (training on {int(config[\"training_fraction\"] * 100)}% of data)')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nkLMOPOaR7_j",
        "outputId": "273ba067-7b1d-4bfe-9ee4-ff9fed88a130"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Epoch 1/1667\n",
            "Epoch 1: Training Accuracy = 0.0039, Training Loss = 4.7578, Validation Accuracy = 0.0115, Validation Loss = 4.7427\n",
            "Epoch 2/1667\n",
            "Epoch 2: Training Accuracy = 0.0176, Training Loss = 4.5966, Validation Accuracy = 0.0164, Validation Loss = 4.6245\n",
            "Epoch 3/1667\n",
            "Epoch 3: Training Accuracy = 0.0176, Training Loss = 4.5966, Validation Accuracy = 0.0164, Validation Loss = 4.6245\n",
            "Epoch 4/1667\n",
            "Epoch 4: Training Accuracy = 0.0332, Training Loss = 4.5177, Validation Accuracy = 0.0150, Validation Loss = 4.6192\n",
            "Epoch 5/1667\n",
            "Epoch 5: Training Accuracy = 0.0332, Training Loss = 4.5177, Validation Accuracy = 0.0150, Validation Loss = 4.6192\n",
            "Epoch 6/1667\n",
            "Epoch 6: Training Accuracy = 0.0352, Training Loss = 4.4769, Validation Accuracy = 0.0140, Validation Loss = 4.6015\n",
            "Epoch 7/1667\n",
            "Epoch 7: Training Accuracy = 0.0371, Training Loss = 4.3991, Validation Accuracy = 0.0137, Validation Loss = 4.6792\n",
            "Epoch 8/1667\n",
            "Epoch 8: Training Accuracy = 0.0371, Training Loss = 4.3991, Validation Accuracy = 0.0137, Validation Loss = 4.6792\n",
            "Epoch 9/1667\n",
            "Epoch 9: Training Accuracy = 0.0488, Training Loss = 4.2687, Validation Accuracy = 0.0117, Validation Loss = 4.8282\n",
            "Epoch 10/1667\n",
            "Epoch 10: Training Accuracy = 0.0488, Training Loss = 4.2687, Validation Accuracy = 0.0117, Validation Loss = 4.8282\n",
            "Epoch 11/1667\n",
            "Epoch 11: Training Accuracy = 0.0918, Training Loss = 4.0754, Validation Accuracy = 0.0108, Validation Loss = 4.9904\n",
            "Epoch 12/1667\n",
            "Epoch 12: Training Accuracy = 0.0586, Training Loss = 4.0646, Validation Accuracy = 0.0105, Validation Loss = 5.0645\n",
            "Epoch 13/1667\n",
            "Epoch 13: Training Accuracy = 0.0586, Training Loss = 4.0646, Validation Accuracy = 0.0105, Validation Loss = 5.0645\n",
            "Epoch 14/1667\n",
            "Epoch 14: Training Accuracy = 0.1094, Training Loss = 3.8543, Validation Accuracy = 0.0109, Validation Loss = 5.1233\n",
            "Epoch 15/1667\n",
            "Epoch 15: Training Accuracy = 0.1094, Training Loss = 3.8543, Validation Accuracy = 0.0109, Validation Loss = 5.1233\n",
            "Epoch 16/1667\n",
            "Epoch 16: Training Accuracy = 0.1113, Training Loss = 3.7694, Validation Accuracy = 0.0103, Validation Loss = 5.1750\n",
            "Epoch 17/1667\n",
            "Epoch 17: Training Accuracy = 0.1211, Training Loss = 3.6942, Validation Accuracy = 0.0106, Validation Loss = 5.2462\n",
            "Epoch 18/1667\n",
            "Epoch 18: Training Accuracy = 0.1211, Training Loss = 3.6942, Validation Accuracy = 0.0106, Validation Loss = 5.2462\n",
            "Epoch 19/1667\n",
            "Epoch 19: Training Accuracy = 0.1523, Training Loss = 3.5243, Validation Accuracy = 0.0103, Validation Loss = 5.3086\n",
            "Epoch 20/1667\n",
            "Epoch 20: Training Accuracy = 0.1523, Training Loss = 3.5243, Validation Accuracy = 0.0103, Validation Loss = 5.3086\n",
            "Epoch 21/1667\n",
            "Epoch 21: Training Accuracy = 0.2168, Training Loss = 3.4164, Validation Accuracy = 0.0102, Validation Loss = 5.3662\n",
            "Epoch 22/1667\n",
            "Epoch 22: Training Accuracy = 0.2129, Training Loss = 3.3532, Validation Accuracy = 0.0102, Validation Loss = 5.4299\n",
            "Epoch 23/1667\n",
            "Epoch 23: Training Accuracy = 0.2129, Training Loss = 3.3532, Validation Accuracy = 0.0102, Validation Loss = 5.4299\n",
            "Epoch 24/1667\n",
            "Epoch 24: Training Accuracy = 0.2734, Training Loss = 3.1533, Validation Accuracy = 0.0105, Validation Loss = 5.4999\n",
            "Epoch 25/1667\n",
            "Epoch 25: Training Accuracy = 0.2734, Training Loss = 3.1533, Validation Accuracy = 0.0105, Validation Loss = 5.4999\n",
            "Epoch 26/1667\n",
            "Epoch 26: Training Accuracy = 0.3457, Training Loss = 3.0099, Validation Accuracy = 0.0100, Validation Loss = 5.5552\n",
            "Epoch 27/1667\n",
            "Epoch 27: Training Accuracy = 0.3262, Training Loss = 2.9504, Validation Accuracy = 0.0103, Validation Loss = 5.6260\n",
            "Epoch 28/1667\n",
            "Epoch 28: Training Accuracy = 0.3262, Training Loss = 2.9504, Validation Accuracy = 0.0103, Validation Loss = 5.6260\n",
            "Epoch 29/1667\n",
            "Epoch 29: Training Accuracy = 0.3828, Training Loss = 2.7802, Validation Accuracy = 0.0105, Validation Loss = 5.7050\n",
            "Epoch 30/1667\n",
            "Epoch 30: Training Accuracy = 0.3828, Training Loss = 2.7802, Validation Accuracy = 0.0105, Validation Loss = 5.7050\n",
            "Epoch 31/1667\n",
            "Epoch 31: Training Accuracy = 0.4492, Training Loss = 2.5418, Validation Accuracy = 0.0102, Validation Loss = 5.7825\n",
            "Epoch 32/1667\n",
            "Epoch 32: Training Accuracy = 0.4336, Training Loss = 2.5958, Validation Accuracy = 0.0102, Validation Loss = 5.8566\n",
            "Epoch 33/1667\n",
            "Epoch 33: Training Accuracy = 0.4336, Training Loss = 2.5958, Validation Accuracy = 0.0102, Validation Loss = 5.8566\n",
            "Epoch 34/1667\n",
            "Epoch 34: Training Accuracy = 0.4707, Training Loss = 2.4012, Validation Accuracy = 0.0094, Validation Loss = 5.9248\n",
            "Epoch 35/1667\n",
            "Epoch 35: Training Accuracy = 0.4707, Training Loss = 2.4012, Validation Accuracy = 0.0094, Validation Loss = 5.9248\n",
            "Epoch 36/1667\n",
            "Epoch 36: Training Accuracy = 0.5625, Training Loss = 2.2114, Validation Accuracy = 0.0099, Validation Loss = 5.9995\n",
            "Epoch 37/1667\n",
            "Epoch 37: Training Accuracy = 0.5664, Training Loss = 2.1977, Validation Accuracy = 0.0102, Validation Loss = 6.0649\n",
            "Epoch 38/1667\n",
            "Epoch 38: Training Accuracy = 0.5664, Training Loss = 2.1977, Validation Accuracy = 0.0102, Validation Loss = 6.0649\n",
            "Epoch 39/1667\n",
            "Epoch 39: Training Accuracy = 0.6074, Training Loss = 2.0024, Validation Accuracy = 0.0102, Validation Loss = 6.1581\n",
            "Epoch 40/1667\n",
            "Epoch 40: Training Accuracy = 0.6074, Training Loss = 2.0024, Validation Accuracy = 0.0102, Validation Loss = 6.1581\n",
            "Epoch 41/1667\n",
            "Epoch 41: Training Accuracy = 0.6738, Training Loss = 1.8504, Validation Accuracy = 0.0105, Validation Loss = 6.2331\n",
            "Epoch 42/1667\n",
            "Epoch 42: Training Accuracy = 0.6270, Training Loss = 1.8884, Validation Accuracy = 0.0103, Validation Loss = 6.3146\n",
            "Epoch 43/1667\n",
            "Epoch 43: Training Accuracy = 0.6270, Training Loss = 1.8884, Validation Accuracy = 0.0103, Validation Loss = 6.3146\n",
            "Epoch 44/1667\n",
            "Epoch 44: Training Accuracy = 0.7031, Training Loss = 1.6599, Validation Accuracy = 0.0105, Validation Loss = 6.3836\n",
            "Epoch 45/1667\n",
            "Epoch 45: Training Accuracy = 0.7031, Training Loss = 1.6599, Validation Accuracy = 0.0105, Validation Loss = 6.3836\n",
            "Epoch 46/1667\n",
            "Epoch 46: Training Accuracy = 0.7656, Training Loss = 1.4713, Validation Accuracy = 0.0100, Validation Loss = 6.4641\n",
            "Epoch 47/1667\n",
            "Epoch 47: Training Accuracy = 0.8047, Training Loss = 1.3976, Validation Accuracy = 0.0097, Validation Loss = 6.5388\n",
            "Epoch 48/1667\n",
            "Epoch 48: Training Accuracy = 0.8047, Training Loss = 1.3976, Validation Accuracy = 0.0097, Validation Loss = 6.5388\n",
            "Epoch 49/1667\n",
            "Epoch 49: Training Accuracy = 0.8594, Training Loss = 1.2545, Validation Accuracy = 0.0099, Validation Loss = 6.6187\n",
            "Epoch 50/1667\n",
            "Epoch 50: Training Accuracy = 0.8594, Training Loss = 1.2545, Validation Accuracy = 0.0099, Validation Loss = 6.6187\n",
            "Epoch 51/1667\n",
            "Epoch 51: Training Accuracy = 0.9102, Training Loss = 1.0695, Validation Accuracy = 0.0099, Validation Loss = 6.7054\n",
            "Epoch 52/1667\n",
            "Epoch 52: Training Accuracy = 0.8984, Training Loss = 1.0830, Validation Accuracy = 0.0100, Validation Loss = 6.7668\n",
            "Epoch 53/1667\n",
            "Epoch 53: Training Accuracy = 0.8984, Training Loss = 1.0830, Validation Accuracy = 0.0100, Validation Loss = 6.7668\n",
            "Epoch 54/1667\n",
            "Epoch 54: Training Accuracy = 0.9414, Training Loss = 0.8923, Validation Accuracy = 0.0097, Validation Loss = 6.8592\n",
            "Epoch 55/1667\n",
            "Epoch 55: Training Accuracy = 0.9414, Training Loss = 0.8923, Validation Accuracy = 0.0097, Validation Loss = 6.8592\n",
            "Epoch 56/1667\n",
            "Epoch 56: Training Accuracy = 0.9570, Training Loss = 0.8033, Validation Accuracy = 0.0096, Validation Loss = 6.9157\n",
            "Epoch 57/1667\n",
            "Epoch 57: Training Accuracy = 0.9336, Training Loss = 0.8413, Validation Accuracy = 0.0102, Validation Loss = 7.0007\n",
            "Epoch 58/1667\n",
            "Epoch 58: Training Accuracy = 0.9336, Training Loss = 0.8413, Validation Accuracy = 0.0102, Validation Loss = 7.0007\n",
            "Epoch 59/1667\n",
            "Epoch 59: Training Accuracy = 0.9551, Training Loss = 0.7515, Validation Accuracy = 0.0102, Validation Loss = 7.0585\n",
            "Epoch 60/1667\n",
            "Epoch 60: Training Accuracy = 0.9551, Training Loss = 0.7515, Validation Accuracy = 0.0102, Validation Loss = 7.0585\n",
            "Epoch 61/1667\n",
            "Epoch 61: Training Accuracy = 0.9688, Training Loss = 0.6503, Validation Accuracy = 0.0097, Validation Loss = 7.1215\n",
            "Epoch 62/1667\n",
            "Epoch 62: Training Accuracy = 0.9707, Training Loss = 0.5972, Validation Accuracy = 0.0105, Validation Loss = 7.1959\n",
            "Epoch 63/1667\n",
            "Epoch 63: Training Accuracy = 0.9707, Training Loss = 0.5972, Validation Accuracy = 0.0105, Validation Loss = 7.1959\n",
            "Epoch 64/1667\n",
            "Epoch 64: Training Accuracy = 0.9727, Training Loss = 0.5287, Validation Accuracy = 0.0100, Validation Loss = 7.2672\n",
            "Epoch 65/1667\n",
            "Epoch 65: Training Accuracy = 0.9727, Training Loss = 0.5287, Validation Accuracy = 0.0100, Validation Loss = 7.2672\n",
            "Epoch 66/1667\n",
            "Epoch 66: Training Accuracy = 0.9922, Training Loss = 0.4037, Validation Accuracy = 0.0103, Validation Loss = 7.3037\n",
            "Epoch 67/1667\n",
            "Epoch 67: Training Accuracy = 0.9863, Training Loss = 0.3978, Validation Accuracy = 0.0105, Validation Loss = 7.3883\n",
            "Epoch 68/1667\n",
            "Epoch 68: Training Accuracy = 0.9863, Training Loss = 0.3978, Validation Accuracy = 0.0105, Validation Loss = 7.3883\n",
            "Epoch 69/1667\n",
            "Epoch 69: Training Accuracy = 0.9785, Training Loss = 0.3850, Validation Accuracy = 0.0100, Validation Loss = 7.3985\n",
            "Epoch 70/1667\n",
            "Epoch 70: Training Accuracy = 0.9785, Training Loss = 0.3850, Validation Accuracy = 0.0100, Validation Loss = 7.3985\n",
            "Epoch 71/1667\n",
            "Epoch 71: Training Accuracy = 0.9844, Training Loss = 0.3389, Validation Accuracy = 0.0100, Validation Loss = 7.4799\n",
            "Epoch 72/1667\n",
            "Epoch 72: Training Accuracy = 0.9883, Training Loss = 0.3280, Validation Accuracy = 0.0105, Validation Loss = 7.5297\n",
            "Epoch 73/1667\n",
            "Epoch 73: Training Accuracy = 0.9883, Training Loss = 0.3280, Validation Accuracy = 0.0105, Validation Loss = 7.5297\n",
            "Epoch 74/1667\n",
            "Epoch 74: Training Accuracy = 0.9863, Training Loss = 0.3138, Validation Accuracy = 0.0102, Validation Loss = 7.5756\n",
            "Epoch 75/1667\n",
            "Epoch 75: Training Accuracy = 0.9863, Training Loss = 0.3138, Validation Accuracy = 0.0102, Validation Loss = 7.5756\n",
            "Epoch 76/1667\n",
            "Epoch 76: Training Accuracy = 0.9844, Training Loss = 0.2785, Validation Accuracy = 0.0102, Validation Loss = 7.6041\n",
            "Epoch 77/1667\n",
            "Epoch 77: Training Accuracy = 0.9941, Training Loss = 0.2295, Validation Accuracy = 0.0097, Validation Loss = 7.6426\n",
            "Epoch 78/1667\n",
            "Epoch 78: Training Accuracy = 0.9941, Training Loss = 0.2295, Validation Accuracy = 0.0097, Validation Loss = 7.6426\n",
            "Epoch 79/1667\n",
            "Epoch 79: Training Accuracy = 0.9941, Training Loss = 0.2016, Validation Accuracy = 0.0100, Validation Loss = 7.6620\n",
            "Epoch 80/1667\n",
            "Epoch 80: Training Accuracy = 0.9941, Training Loss = 0.2016, Validation Accuracy = 0.0100, Validation Loss = 7.6620\n",
            "Epoch 81/1667\n",
            "Epoch 81: Training Accuracy = 0.9824, Training Loss = 0.2195, Validation Accuracy = 0.0100, Validation Loss = 7.7498\n",
            "Epoch 82/1667\n",
            "Epoch 82: Training Accuracy = 0.9922, Training Loss = 0.2055, Validation Accuracy = 0.0103, Validation Loss = 7.7532\n",
            "Epoch 83/1667\n",
            "Epoch 83: Training Accuracy = 0.9922, Training Loss = 0.2055, Validation Accuracy = 0.0103, Validation Loss = 7.7532\n",
            "Epoch 84/1667\n",
            "Epoch 84: Training Accuracy = 0.9922, Training Loss = 0.1887, Validation Accuracy = 0.0103, Validation Loss = 7.7603\n",
            "Epoch 85/1667\n",
            "Epoch 85: Training Accuracy = 0.9922, Training Loss = 0.1887, Validation Accuracy = 0.0103, Validation Loss = 7.7603\n",
            "Epoch 86/1667\n",
            "Epoch 86: Training Accuracy = 0.9902, Training Loss = 0.1635, Validation Accuracy = 0.0097, Validation Loss = 7.7839\n",
            "Epoch 87/1667\n",
            "Epoch 87: Training Accuracy = 0.9883, Training Loss = 0.1921, Validation Accuracy = 0.0097, Validation Loss = 7.8649\n",
            "Epoch 88/1667\n",
            "Epoch 88: Training Accuracy = 0.9883, Training Loss = 0.1921, Validation Accuracy = 0.0097, Validation Loss = 7.8649\n",
            "Epoch 89/1667\n",
            "Epoch 89: Training Accuracy = 0.9902, Training Loss = 0.1730, Validation Accuracy = 0.0099, Validation Loss = 7.8863\n",
            "Epoch 90/1667\n",
            "Epoch 90: Training Accuracy = 0.9902, Training Loss = 0.1730, Validation Accuracy = 0.0099, Validation Loss = 7.8863\n",
            "Epoch 91/1667\n",
            "Epoch 91: Training Accuracy = 0.9844, Training Loss = 0.1706, Validation Accuracy = 0.0099, Validation Loss = 7.9100\n",
            "Epoch 92/1667\n",
            "Epoch 92: Training Accuracy = 0.9863, Training Loss = 0.1727, Validation Accuracy = 0.0102, Validation Loss = 7.9516\n",
            "Epoch 93/1667\n",
            "Epoch 93: Training Accuracy = 0.9863, Training Loss = 0.1727, Validation Accuracy = 0.0102, Validation Loss = 7.9516\n",
            "Epoch 94/1667\n",
            "Epoch 94: Training Accuracy = 0.9941, Training Loss = 0.1222, Validation Accuracy = 0.0099, Validation Loss = 7.9886\n",
            "Epoch 95/1667\n",
            "Epoch 95: Training Accuracy = 0.9941, Training Loss = 0.1222, Validation Accuracy = 0.0099, Validation Loss = 7.9886\n",
            "Epoch 96/1667\n",
            "Epoch 96: Training Accuracy = 0.9883, Training Loss = 0.1623, Validation Accuracy = 0.0106, Validation Loss = 8.0087\n",
            "Epoch 97/1667\n",
            "Epoch 97: Training Accuracy = 0.9395, Training Loss = 0.4005, Validation Accuracy = 0.0100, Validation Loss = 8.0403\n",
            "Epoch 98/1667\n",
            "Epoch 98: Training Accuracy = 0.9395, Training Loss = 0.4005, Validation Accuracy = 0.0100, Validation Loss = 8.0403\n",
            "Epoch 99/1667\n",
            "Epoch 99: Training Accuracy = 0.9746, Training Loss = 0.3343, Validation Accuracy = 0.0103, Validation Loss = 7.9811\n",
            "Epoch 100/1667\n",
            "Epoch 100: Training Accuracy = 0.9746, Training Loss = 0.3343, Validation Accuracy = 0.0103, Validation Loss = 7.9811\n",
            "Epoch 101/1667\n",
            "Epoch 101: Training Accuracy = 0.9844, Training Loss = 0.2118, Validation Accuracy = 0.0100, Validation Loss = 8.1209\n",
            "Epoch 102/1667\n",
            "Epoch 102: Training Accuracy = 0.9863, Training Loss = 0.1685, Validation Accuracy = 0.0106, Validation Loss = 8.1659\n",
            "Epoch 103/1667\n",
            "Epoch 103: Training Accuracy = 0.9863, Training Loss = 0.1685, Validation Accuracy = 0.0106, Validation Loss = 8.1659\n",
            "Epoch 104/1667\n",
            "Epoch 104: Training Accuracy = 0.9844, Training Loss = 0.1353, Validation Accuracy = 0.0100, Validation Loss = 8.1860\n",
            "Epoch 105/1667\n",
            "Epoch 105: Training Accuracy = 0.9844, Training Loss = 0.1353, Validation Accuracy = 0.0100, Validation Loss = 8.1860\n",
            "Epoch 106/1667\n",
            "Epoch 106: Training Accuracy = 0.9922, Training Loss = 0.0898, Validation Accuracy = 0.0097, Validation Loss = 8.1924\n",
            "Epoch 107/1667\n",
            "Epoch 107: Training Accuracy = 0.9883, Training Loss = 0.1067, Validation Accuracy = 0.0099, Validation Loss = 8.1960\n",
            "Epoch 108/1667\n",
            "Epoch 108: Training Accuracy = 0.9883, Training Loss = 0.1067, Validation Accuracy = 0.0099, Validation Loss = 8.1960\n",
            "Epoch 109/1667\n",
            "Epoch 109: Training Accuracy = 0.9941, Training Loss = 0.0752, Validation Accuracy = 0.0103, Validation Loss = 8.1734\n",
            "Epoch 110/1667\n",
            "Epoch 110: Training Accuracy = 0.9941, Training Loss = 0.0752, Validation Accuracy = 0.0103, Validation Loss = 8.1734\n",
            "Epoch 111/1667\n",
            "Epoch 111: Training Accuracy = 0.9902, Training Loss = 0.0882, Validation Accuracy = 0.0102, Validation Loss = 8.1713\n",
            "Epoch 112/1667\n",
            "Epoch 112: Training Accuracy = 0.9805, Training Loss = 0.1306, Validation Accuracy = 0.0102, Validation Loss = 8.1425\n",
            "Epoch 113/1667\n",
            "Epoch 113: Training Accuracy = 0.9805, Training Loss = 0.1306, Validation Accuracy = 0.0102, Validation Loss = 8.1425\n",
            "Epoch 114/1667\n",
            "Epoch 114: Training Accuracy = 0.9883, Training Loss = 0.1013, Validation Accuracy = 0.0105, Validation Loss = 8.1278\n",
            "Epoch 115/1667\n",
            "Epoch 115: Training Accuracy = 0.9883, Training Loss = 0.1013, Validation Accuracy = 0.0105, Validation Loss = 8.1278\n",
            "Epoch 116/1667\n",
            "Epoch 116: Training Accuracy = 0.9844, Training Loss = 0.1119, Validation Accuracy = 0.0102, Validation Loss = 8.1423\n",
            "Epoch 117/1667\n",
            "Epoch 117: Training Accuracy = 0.9883, Training Loss = 0.1090, Validation Accuracy = 0.0105, Validation Loss = 8.1746\n",
            "Epoch 118/1667\n",
            "Epoch 118: Training Accuracy = 0.9883, Training Loss = 0.1090, Validation Accuracy = 0.0105, Validation Loss = 8.1746\n",
            "Epoch 119/1667\n",
            "Epoch 119: Training Accuracy = 0.9922, Training Loss = 0.0892, Validation Accuracy = 0.0102, Validation Loss = 8.1866\n",
            "Epoch 120/1667\n",
            "Epoch 120: Training Accuracy = 0.9922, Training Loss = 0.0892, Validation Accuracy = 0.0102, Validation Loss = 8.1866\n",
            "Epoch 121/1667\n",
            "Epoch 121: Training Accuracy = 0.8145, Training Loss = 0.7581, Validation Accuracy = 0.0114, Validation Loss = 9.1630\n",
            "Epoch 122/1667\n",
            "Epoch 122: Training Accuracy = 0.5547, Training Loss = 1.9411, Validation Accuracy = 0.0106, Validation Loss = 7.4365\n",
            "Epoch 123/1667\n",
            "Epoch 123: Training Accuracy = 0.5547, Training Loss = 1.9411, Validation Accuracy = 0.0106, Validation Loss = 7.4365\n",
            "Epoch 124/1667\n",
            "Epoch 124: Training Accuracy = 0.8945, Training Loss = 0.6850, Validation Accuracy = 0.0099, Validation Loss = 7.8346\n",
            "Epoch 125/1667\n",
            "Epoch 125: Training Accuracy = 0.8945, Training Loss = 0.6850, Validation Accuracy = 0.0099, Validation Loss = 7.8346\n",
            "Epoch 126/1667\n",
            "Epoch 126: Training Accuracy = 0.9668, Training Loss = 0.3904, Validation Accuracy = 0.0100, Validation Loss = 8.0346\n",
            "Epoch 127/1667\n",
            "Epoch 127: Training Accuracy = 0.9863, Training Loss = 0.2514, Validation Accuracy = 0.0100, Validation Loss = 8.0697\n",
            "Epoch 128/1667\n",
            "Epoch 128: Training Accuracy = 0.9863, Training Loss = 0.2514, Validation Accuracy = 0.0100, Validation Loss = 8.0697\n",
            "Epoch 129/1667\n",
            "Epoch 129: Training Accuracy = 0.9941, Training Loss = 0.1671, Validation Accuracy = 0.0105, Validation Loss = 8.0528\n",
            "Epoch 130/1667\n",
            "Epoch 130: Training Accuracy = 0.9941, Training Loss = 0.1671, Validation Accuracy = 0.0105, Validation Loss = 8.0528\n",
            "Epoch 131/1667\n",
            "Epoch 131: Training Accuracy = 0.9824, Training Loss = 0.1660, Validation Accuracy = 0.0102, Validation Loss = 8.0858\n",
            "Epoch 132/1667\n",
            "Epoch 132: Training Accuracy = 0.9824, Training Loss = 0.1645, Validation Accuracy = 0.0102, Validation Loss = 8.0607\n",
            "Epoch 133/1667\n",
            "Epoch 133: Training Accuracy = 0.9824, Training Loss = 0.1645, Validation Accuracy = 0.0102, Validation Loss = 8.0607\n",
            "Epoch 134/1667\n",
            "Epoch 134: Training Accuracy = 0.9883, Training Loss = 0.1296, Validation Accuracy = 0.0105, Validation Loss = 8.0362\n",
            "Epoch 135/1667\n",
            "Epoch 135: Training Accuracy = 0.9883, Training Loss = 0.1296, Validation Accuracy = 0.0105, Validation Loss = 8.0362\n",
            "Epoch 136/1667\n",
            "Epoch 136: Training Accuracy = 0.9922, Training Loss = 0.1069, Validation Accuracy = 0.0106, Validation Loss = 8.0066\n",
            "Epoch 137/1667\n",
            "Epoch 137: Training Accuracy = 0.9727, Training Loss = 0.1931, Validation Accuracy = 0.0105, Validation Loss = 7.9646\n",
            "Epoch 138/1667\n",
            "Epoch 138: Training Accuracy = 0.9727, Training Loss = 0.1931, Validation Accuracy = 0.0105, Validation Loss = 7.9646\n",
            "Epoch 139/1667\n",
            "Epoch 139: Training Accuracy = 0.9863, Training Loss = 0.1331, Validation Accuracy = 0.0106, Validation Loss = 7.9640\n",
            "Epoch 140/1667\n",
            "Epoch 140: Training Accuracy = 0.9863, Training Loss = 0.1331, Validation Accuracy = 0.0106, Validation Loss = 7.9640\n",
            "Epoch 141/1667\n",
            "Epoch 141: Training Accuracy = 0.9844, Training Loss = 0.1353, Validation Accuracy = 0.0105, Validation Loss = 7.9140\n",
            "Epoch 142/1667\n",
            "Epoch 142: Training Accuracy = 0.9902, Training Loss = 0.1256, Validation Accuracy = 0.0102, Validation Loss = 7.9254\n",
            "Epoch 143/1667\n",
            "Epoch 143: Training Accuracy = 0.9902, Training Loss = 0.1256, Validation Accuracy = 0.0102, Validation Loss = 7.9254\n",
            "Epoch 144/1667\n",
            "Epoch 144: Training Accuracy = 0.9883, Training Loss = 0.1249, Validation Accuracy = 0.0108, Validation Loss = 7.9146\n",
            "Epoch 145/1667\n",
            "Epoch 145: Training Accuracy = 0.9883, Training Loss = 0.1249, Validation Accuracy = 0.0108, Validation Loss = 7.9146\n",
            "Epoch 146/1667\n",
            "Epoch 146: Training Accuracy = 0.9863, Training Loss = 0.1467, Validation Accuracy = 0.0106, Validation Loss = 7.9540\n",
            "Epoch 147/1667\n",
            "Epoch 147: Training Accuracy = 0.9844, Training Loss = 0.1696, Validation Accuracy = 0.0103, Validation Loss = 7.9446\n",
            "Epoch 148/1667\n",
            "Epoch 148: Training Accuracy = 0.9844, Training Loss = 0.1696, Validation Accuracy = 0.0103, Validation Loss = 7.9446\n",
            "Epoch 149/1667\n",
            "Epoch 149: Training Accuracy = 0.9824, Training Loss = 0.1841, Validation Accuracy = 0.0103, Validation Loss = 7.9090\n",
            "Epoch 150/1667\n",
            "Epoch 150: Training Accuracy = 0.9824, Training Loss = 0.1841, Validation Accuracy = 0.0103, Validation Loss = 7.9090\n",
            "Epoch 151/1667\n",
            "Epoch 151: Training Accuracy = 0.9785, Training Loss = 0.2793, Validation Accuracy = 0.0100, Validation Loss = 7.9722\n",
            "Epoch 152/1667\n",
            "Epoch 152: Training Accuracy = 0.9629, Training Loss = 0.3473, Validation Accuracy = 0.0105, Validation Loss = 8.0539\n",
            "Epoch 153/1667\n",
            "Epoch 153: Training Accuracy = 0.9629, Training Loss = 0.3473, Validation Accuracy = 0.0105, Validation Loss = 8.0539\n",
            "Epoch 154/1667\n",
            "Epoch 154: Training Accuracy = 0.9844, Training Loss = 0.2313, Validation Accuracy = 0.0105, Validation Loss = 8.1397\n",
            "Epoch 155/1667\n",
            "Epoch 155: Training Accuracy = 0.9844, Training Loss = 0.2313, Validation Accuracy = 0.0105, Validation Loss = 8.1397\n",
            "Epoch 156/1667\n",
            "Epoch 156: Training Accuracy = 0.9824, Training Loss = 0.1839, Validation Accuracy = 0.0106, Validation Loss = 8.1093\n",
            "Epoch 157/1667\n",
            "Epoch 157: Training Accuracy = 0.9883, Training Loss = 0.1368, Validation Accuracy = 0.0102, Validation Loss = 8.1741\n",
            "Epoch 158/1667\n",
            "Epoch 158: Training Accuracy = 0.9883, Training Loss = 0.1368, Validation Accuracy = 0.0102, Validation Loss = 8.1741\n",
            "Epoch 159/1667\n",
            "Epoch 159: Training Accuracy = 0.9883, Training Loss = 0.1132, Validation Accuracy = 0.0099, Validation Loss = 8.2341\n",
            "Epoch 160/1667\n",
            "Epoch 160: Training Accuracy = 0.9883, Training Loss = 0.1132, Validation Accuracy = 0.0099, Validation Loss = 8.2341\n",
            "Epoch 161/1667\n",
            "Epoch 161: Training Accuracy = 0.9922, Training Loss = 0.0783, Validation Accuracy = 0.0106, Validation Loss = 8.2008\n",
            "Epoch 162/1667\n",
            "Epoch 162: Training Accuracy = 0.9902, Training Loss = 0.0874, Validation Accuracy = 0.0105, Validation Loss = 8.1964\n",
            "Epoch 163/1667\n",
            "Epoch 163: Training Accuracy = 0.9902, Training Loss = 0.0874, Validation Accuracy = 0.0105, Validation Loss = 8.1964\n",
            "Epoch 164/1667\n",
            "Epoch 164: Training Accuracy = 0.9902, Training Loss = 0.0842, Validation Accuracy = 0.0102, Validation Loss = 8.1713\n",
            "Epoch 165/1667\n",
            "Epoch 165: Training Accuracy = 0.9902, Training Loss = 0.0842, Validation Accuracy = 0.0102, Validation Loss = 8.1713\n",
            "Epoch 166/1667\n",
            "Epoch 166: Training Accuracy = 0.9902, Training Loss = 0.0854, Validation Accuracy = 0.0102, Validation Loss = 8.1309\n",
            "Epoch 167/1667\n",
            "Epoch 167: Training Accuracy = 0.9863, Training Loss = 0.1071, Validation Accuracy = 0.0105, Validation Loss = 8.0944\n",
            "Epoch 168/1667\n",
            "Epoch 168: Training Accuracy = 0.9863, Training Loss = 0.1071, Validation Accuracy = 0.0105, Validation Loss = 8.0944\n",
            "Epoch 169/1667\n",
            "Epoch 169: Training Accuracy = 0.9902, Training Loss = 0.0893, Validation Accuracy = 0.0105, Validation Loss = 8.1216\n",
            "Epoch 170/1667\n",
            "Epoch 170: Training Accuracy = 0.9902, Training Loss = 0.0893, Validation Accuracy = 0.0105, Validation Loss = 8.1216\n",
            "Epoch 171/1667\n",
            "Epoch 171: Training Accuracy = 0.9941, Training Loss = 0.0904, Validation Accuracy = 0.0105, Validation Loss = 8.0672\n",
            "Epoch 172/1667\n",
            "Epoch 172: Training Accuracy = 0.2578, Training Loss = 3.2977, Validation Accuracy = 0.0102, Validation Loss = 6.1782\n",
            "Epoch 173/1667\n",
            "Epoch 173: Training Accuracy = 0.2578, Training Loss = 3.2977, Validation Accuracy = 0.0102, Validation Loss = 6.1782\n",
            "Epoch 174/1667\n",
            "Epoch 174: Training Accuracy = 0.6074, Training Loss = 1.5719, Validation Accuracy = 0.0102, Validation Loss = 7.7634\n",
            "Epoch 175/1667\n",
            "Epoch 175: Training Accuracy = 0.6074, Training Loss = 1.5719, Validation Accuracy = 0.0102, Validation Loss = 7.7634\n",
            "Epoch 176/1667\n",
            "Epoch 176: Training Accuracy = 0.9023, Training Loss = 0.7021, Validation Accuracy = 0.0115, Validation Loss = 7.7623\n",
            "Epoch 177/1667\n",
            "Epoch 177: Training Accuracy = 0.9688, Training Loss = 0.4111, Validation Accuracy = 0.0100, Validation Loss = 7.9140\n",
            "Epoch 178/1667\n",
            "Epoch 178: Training Accuracy = 0.9688, Training Loss = 0.4111, Validation Accuracy = 0.0100, Validation Loss = 7.9140\n",
            "Epoch 179/1667\n",
            "Epoch 179: Training Accuracy = 0.9805, Training Loss = 0.2598, Validation Accuracy = 0.0103, Validation Loss = 7.9133\n",
            "Epoch 180/1667\n",
            "Epoch 180: Training Accuracy = 0.9805, Training Loss = 0.2598, Validation Accuracy = 0.0103, Validation Loss = 7.9133\n",
            "Epoch 181/1667\n",
            "Epoch 181: Training Accuracy = 0.9922, Training Loss = 0.1575, Validation Accuracy = 0.0105, Validation Loss = 8.0100\n",
            "Epoch 182/1667\n",
            "Epoch 182: Training Accuracy = 0.9922, Training Loss = 0.1388, Validation Accuracy = 0.0106, Validation Loss = 7.9818\n",
            "Epoch 183/1667\n",
            "Epoch 183: Training Accuracy = 0.9922, Training Loss = 0.1388, Validation Accuracy = 0.0106, Validation Loss = 7.9818\n",
            "Epoch 184/1667\n",
            "Epoch 184: Training Accuracy = 0.9805, Training Loss = 0.1650, Validation Accuracy = 0.0106, Validation Loss = 7.9679\n",
            "Epoch 185/1667\n",
            "Epoch 185: Training Accuracy = 0.9805, Training Loss = 0.1650, Validation Accuracy = 0.0106, Validation Loss = 7.9679\n",
            "Epoch 186/1667\n",
            "Epoch 186: Training Accuracy = 0.9883, Training Loss = 0.1264, Validation Accuracy = 0.0108, Validation Loss = 7.9457\n",
            "Epoch 187/1667\n",
            "Epoch 187: Training Accuracy = 0.9883, Training Loss = 0.1378, Validation Accuracy = 0.0105, Validation Loss = 7.9102\n",
            "Epoch 188/1667\n",
            "Epoch 188: Training Accuracy = 0.9883, Training Loss = 0.1378, Validation Accuracy = 0.0105, Validation Loss = 7.9102\n",
            "Epoch 189/1667\n",
            "Epoch 189: Training Accuracy = 0.9883, Training Loss = 0.1310, Validation Accuracy = 0.0106, Validation Loss = 7.8462\n",
            "Epoch 190/1667\n",
            "Epoch 190: Training Accuracy = 0.9883, Training Loss = 0.1310, Validation Accuracy = 0.0106, Validation Loss = 7.8462\n",
            "Epoch 191/1667\n",
            "Epoch 191: Training Accuracy = 0.9883, Training Loss = 0.1388, Validation Accuracy = 0.0114, Validation Loss = 7.8654\n",
            "Epoch 192/1667\n",
            "Epoch 192: Training Accuracy = 0.9902, Training Loss = 0.1456, Validation Accuracy = 0.0103, Validation Loss = 7.8279\n",
            "Epoch 193/1667\n",
            "Epoch 193: Training Accuracy = 0.9902, Training Loss = 0.1456, Validation Accuracy = 0.0103, Validation Loss = 7.8279\n",
            "Epoch 194/1667\n",
            "Epoch 194: Training Accuracy = 0.9863, Training Loss = 0.1684, Validation Accuracy = 0.0102, Validation Loss = 7.8734\n",
            "Epoch 195/1667\n",
            "Epoch 195: Training Accuracy = 0.9863, Training Loss = 0.1684, Validation Accuracy = 0.0102, Validation Loss = 7.8734\n",
            "Epoch 196/1667\n",
            "Epoch 196: Training Accuracy = 0.6992, Training Loss = 1.2069, Validation Accuracy = 0.0111, Validation Loss = 7.6045\n",
            "Epoch 197/1667\n",
            "Epoch 197: Training Accuracy = 0.8691, Training Loss = 0.7166, Validation Accuracy = 0.0108, Validation Loss = 7.6374\n",
            "Epoch 198/1667\n",
            "Epoch 198: Training Accuracy = 0.8691, Training Loss = 0.7166, Validation Accuracy = 0.0108, Validation Loss = 7.6374\n",
            "Epoch 199/1667\n",
            "Epoch 199: Training Accuracy = 0.9785, Training Loss = 0.3423, Validation Accuracy = 0.0102, Validation Loss = 7.7602\n",
            "Epoch 200/1667\n",
            "Epoch 200: Training Accuracy = 0.9785, Training Loss = 0.3423, Validation Accuracy = 0.0102, Validation Loss = 7.7602\n",
            "Epoch 201/1667\n",
            "Epoch 201: Training Accuracy = 0.9902, Training Loss = 0.1913, Validation Accuracy = 0.0100, Validation Loss = 7.9339\n",
            "Epoch 202/1667\n",
            "Epoch 202: Training Accuracy = 0.9844, Training Loss = 0.1900, Validation Accuracy = 0.0096, Validation Loss = 7.9700\n",
            "Epoch 203/1667\n",
            "Epoch 203: Training Accuracy = 0.9844, Training Loss = 0.1900, Validation Accuracy = 0.0096, Validation Loss = 7.9700\n",
            "Epoch 204/1667\n",
            "Epoch 204: Training Accuracy = 0.9766, Training Loss = 0.1785, Validation Accuracy = 0.0102, Validation Loss = 7.9517\n",
            "Epoch 205/1667\n",
            "Epoch 205: Training Accuracy = 0.9766, Training Loss = 0.1785, Validation Accuracy = 0.0102, Validation Loss = 7.9517\n",
            "Epoch 206/1667\n",
            "Epoch 206: Training Accuracy = 0.9902, Training Loss = 0.1136, Validation Accuracy = 0.0108, Validation Loss = 7.9293\n",
            "Epoch 207/1667\n",
            "Epoch 207: Training Accuracy = 0.9785, Training Loss = 0.1528, Validation Accuracy = 0.0103, Validation Loss = 7.9247\n",
            "Epoch 208/1667\n",
            "Epoch 208: Training Accuracy = 0.9785, Training Loss = 0.1528, Validation Accuracy = 0.0103, Validation Loss = 7.9247\n",
            "Epoch 209/1667\n",
            "Epoch 209: Training Accuracy = 0.9902, Training Loss = 0.1081, Validation Accuracy = 0.0102, Validation Loss = 7.8924\n",
            "Epoch 210/1667\n",
            "Epoch 210: Training Accuracy = 0.9902, Training Loss = 0.1081, Validation Accuracy = 0.0102, Validation Loss = 7.8924\n",
            "Epoch 211/1667\n",
            "Epoch 211: Training Accuracy = 0.9941, Training Loss = 0.0927, Validation Accuracy = 0.0108, Validation Loss = 7.8676\n",
            "Epoch 212/1667\n",
            "Epoch 212: Training Accuracy = 0.9922, Training Loss = 0.1100, Validation Accuracy = 0.0103, Validation Loss = 7.8753\n",
            "Epoch 213/1667\n",
            "Epoch 213: Training Accuracy = 0.9922, Training Loss = 0.1100, Validation Accuracy = 0.0103, Validation Loss = 7.8753\n",
            "Epoch 214/1667\n",
            "Epoch 214: Training Accuracy = 0.9844, Training Loss = 0.1330, Validation Accuracy = 0.0103, Validation Loss = 7.8544\n",
            "Epoch 215/1667\n",
            "Epoch 215: Training Accuracy = 0.9844, Training Loss = 0.1330, Validation Accuracy = 0.0103, Validation Loss = 7.8544\n",
            "Epoch 216/1667\n",
            "Epoch 216: Training Accuracy = 0.9922, Training Loss = 0.1450, Validation Accuracy = 0.0106, Validation Loss = 7.7565\n",
            "Epoch 217/1667\n",
            "Epoch 217: Training Accuracy = 0.7578, Training Loss = 1.0996, Validation Accuracy = 0.0124, Validation Loss = 7.5367\n",
            "Epoch 218/1667\n",
            "Epoch 218: Training Accuracy = 0.7578, Training Loss = 1.0996, Validation Accuracy = 0.0124, Validation Loss = 7.5367\n",
            "Epoch 219/1667\n",
            "Epoch 219: Training Accuracy = 0.9414, Training Loss = 0.4782, Validation Accuracy = 0.0109, Validation Loss = 7.7778\n",
            "Epoch 220/1667\n",
            "Epoch 220: Training Accuracy = 0.9414, Training Loss = 0.4782, Validation Accuracy = 0.0109, Validation Loss = 7.7778\n",
            "Epoch 221/1667\n",
            "Epoch 221: Training Accuracy = 0.9746, Training Loss = 0.3127, Validation Accuracy = 0.0105, Validation Loss = 7.9109\n",
            "Epoch 222/1667\n",
            "Epoch 222: Training Accuracy = 0.9844, Training Loss = 0.2117, Validation Accuracy = 0.0111, Validation Loss = 7.9567\n",
            "Epoch 223/1667\n",
            "Epoch 223: Training Accuracy = 0.9844, Training Loss = 0.2117, Validation Accuracy = 0.0111, Validation Loss = 7.9567\n",
            "Epoch 224/1667\n",
            "Epoch 224: Training Accuracy = 0.9902, Training Loss = 0.1359, Validation Accuracy = 0.0105, Validation Loss = 8.0233\n",
            "Epoch 225/1667\n",
            "Epoch 225: Training Accuracy = 0.9902, Training Loss = 0.1359, Validation Accuracy = 0.0105, Validation Loss = 8.0233\n",
            "Epoch 226/1667\n",
            "Epoch 226: Training Accuracy = 0.9902, Training Loss = 0.1026, Validation Accuracy = 0.0102, Validation Loss = 8.0118\n",
            "Epoch 227/1667\n",
            "Epoch 227: Training Accuracy = 0.9902, Training Loss = 0.1059, Validation Accuracy = 0.0103, Validation Loss = 8.0202\n",
            "Epoch 228/1667\n",
            "Epoch 228: Training Accuracy = 0.9902, Training Loss = 0.1059, Validation Accuracy = 0.0103, Validation Loss = 8.0202\n",
            "Epoch 229/1667\n",
            "Epoch 229: Training Accuracy = 0.9883, Training Loss = 0.1012, Validation Accuracy = 0.0109, Validation Loss = 7.9867\n",
            "Epoch 230/1667\n",
            "Epoch 230: Training Accuracy = 0.9883, Training Loss = 0.1012, Validation Accuracy = 0.0109, Validation Loss = 7.9867\n",
            "Epoch 231/1667\n",
            "Epoch 231: Training Accuracy = 0.9785, Training Loss = 0.1328, Validation Accuracy = 0.0108, Validation Loss = 7.9734\n",
            "Epoch 232/1667\n",
            "Epoch 232: Training Accuracy = 0.9805, Training Loss = 0.1388, Validation Accuracy = 0.0105, Validation Loss = 7.9228\n",
            "Epoch 233/1667\n",
            "Epoch 233: Training Accuracy = 0.9805, Training Loss = 0.1388, Validation Accuracy = 0.0105, Validation Loss = 7.9228\n",
            "Epoch 234/1667\n",
            "Epoch 234: Training Accuracy = 0.9922, Training Loss = 0.0923, Validation Accuracy = 0.0103, Validation Loss = 7.8416\n",
            "Epoch 235/1667\n",
            "Epoch 235: Training Accuracy = 0.9922, Training Loss = 0.0923, Validation Accuracy = 0.0103, Validation Loss = 7.8416\n",
            "Epoch 236/1667\n",
            "Epoch 236: Training Accuracy = 0.9902, Training Loss = 0.1094, Validation Accuracy = 0.0108, Validation Loss = 7.8229\n",
            "Epoch 237/1667\n",
            "Epoch 237: Training Accuracy = 0.4043, Training Loss = 2.0688, Validation Accuracy = 0.0135, Validation Loss = 7.1604\n",
            "Epoch 238/1667\n",
            "Epoch 238: Training Accuracy = 0.4043, Training Loss = 2.0688, Validation Accuracy = 0.0135, Validation Loss = 7.1604\n",
            "Epoch 239/1667\n",
            "Epoch 239: Training Accuracy = 0.7422, Training Loss = 1.1603, Validation Accuracy = 0.0103, Validation Loss = 7.5387\n",
            "Epoch 240/1667\n",
            "Epoch 240: Training Accuracy = 0.7422, Training Loss = 1.1603, Validation Accuracy = 0.0103, Validation Loss = 7.5387\n",
            "Epoch 241/1667\n",
            "Epoch 241: Training Accuracy = 0.9434, Training Loss = 0.5315, Validation Accuracy = 0.0115, Validation Loss = 7.6668\n",
            "Epoch 242/1667\n",
            "Epoch 242: Training Accuracy = 0.9805, Training Loss = 0.3153, Validation Accuracy = 0.0111, Validation Loss = 7.7920\n",
            "Epoch 243/1667\n",
            "Epoch 243: Training Accuracy = 0.9805, Training Loss = 0.3153, Validation Accuracy = 0.0111, Validation Loss = 7.7920\n",
            "Epoch 244/1667\n",
            "Epoch 244: Training Accuracy = 0.9902, Training Loss = 0.1920, Validation Accuracy = 0.0100, Validation Loss = 7.9230\n",
            "Epoch 245/1667\n",
            "Epoch 245: Training Accuracy = 0.9902, Training Loss = 0.1920, Validation Accuracy = 0.0100, Validation Loss = 7.9230\n",
            "Epoch 246/1667\n",
            "Epoch 246: Training Accuracy = 0.9902, Training Loss = 0.1467, Validation Accuracy = 0.0102, Validation Loss = 7.9125\n",
            "Epoch 247/1667\n",
            "Epoch 247: Training Accuracy = 0.9824, Training Loss = 0.1569, Validation Accuracy = 0.0105, Validation Loss = 7.9318\n",
            "Epoch 248/1667\n",
            "Epoch 248: Training Accuracy = 0.9824, Training Loss = 0.1569, Validation Accuracy = 0.0105, Validation Loss = 7.9318\n",
            "Epoch 249/1667\n",
            "Epoch 249: Training Accuracy = 0.9805, Training Loss = 0.1574, Validation Accuracy = 0.0103, Validation Loss = 7.8987\n",
            "Epoch 250/1667\n",
            "Epoch 250: Training Accuracy = 0.9805, Training Loss = 0.1574, Validation Accuracy = 0.0103, Validation Loss = 7.8987\n",
            "Epoch 251/1667\n",
            "Epoch 251: Training Accuracy = 0.9922, Training Loss = 0.1052, Validation Accuracy = 0.0106, Validation Loss = 7.8632\n",
            "Epoch 252/1667\n",
            "Epoch 252: Training Accuracy = 0.9844, Training Loss = 0.1415, Validation Accuracy = 0.0108, Validation Loss = 7.8066\n",
            "Epoch 253/1667\n",
            "Epoch 253: Training Accuracy = 0.9844, Training Loss = 0.1415, Validation Accuracy = 0.0108, Validation Loss = 7.8066\n",
            "Epoch 254/1667\n",
            "Epoch 254: Training Accuracy = 0.9922, Training Loss = 0.1114, Validation Accuracy = 0.0102, Validation Loss = 7.7820\n",
            "Epoch 255/1667\n",
            "Epoch 255: Training Accuracy = 0.9922, Training Loss = 0.1114, Validation Accuracy = 0.0102, Validation Loss = 7.7820\n",
            "Epoch 256/1667\n",
            "Epoch 256: Training Accuracy = 0.9844, Training Loss = 0.1600, Validation Accuracy = 0.0105, Validation Loss = 7.7325\n",
            "Epoch 257/1667\n",
            "Epoch 257: Training Accuracy = 0.6699, Training Loss = 1.4785, Validation Accuracy = 0.0111, Validation Loss = 7.1935\n",
            "Epoch 258/1667\n",
            "Epoch 258: Training Accuracy = 0.6699, Training Loss = 1.4785, Validation Accuracy = 0.0111, Validation Loss = 7.1935\n",
            "Epoch 259/1667\n",
            "Epoch 259: Training Accuracy = 0.8750, Training Loss = 0.7639, Validation Accuracy = 0.0100, Validation Loss = 7.4469\n",
            "Epoch 260/1667\n",
            "Epoch 260: Training Accuracy = 0.8750, Training Loss = 0.7639, Validation Accuracy = 0.0100, Validation Loss = 7.4469\n",
            "Epoch 261/1667\n",
            "Epoch 261: Training Accuracy = 0.9824, Training Loss = 0.3560, Validation Accuracy = 0.0105, Validation Loss = 7.6170\n",
            "Epoch 262/1667\n",
            "Epoch 262: Training Accuracy = 0.9883, Training Loss = 0.2646, Validation Accuracy = 0.0097, Validation Loss = 7.7704\n",
            "Epoch 263/1667\n",
            "Epoch 263: Training Accuracy = 0.9883, Training Loss = 0.2646, Validation Accuracy = 0.0097, Validation Loss = 7.7704\n",
            "Epoch 264/1667\n",
            "Epoch 264: Training Accuracy = 0.9902, Training Loss = 0.1810, Validation Accuracy = 0.0106, Validation Loss = 7.8238\n",
            "Epoch 265/1667\n",
            "Epoch 265: Training Accuracy = 0.9902, Training Loss = 0.1810, Validation Accuracy = 0.0106, Validation Loss = 7.8238\n",
            "Epoch 266/1667\n",
            "Epoch 266: Training Accuracy = 0.9941, Training Loss = 0.1311, Validation Accuracy = 0.0100, Validation Loss = 7.8103\n",
            "Epoch 267/1667\n",
            "Epoch 267: Training Accuracy = 0.9902, Training Loss = 0.1298, Validation Accuracy = 0.0105, Validation Loss = 7.8334\n",
            "Epoch 268/1667\n",
            "Epoch 268: Training Accuracy = 0.9902, Training Loss = 0.1298, Validation Accuracy = 0.0105, Validation Loss = 7.8334\n",
            "Epoch 269/1667\n",
            "Epoch 269: Training Accuracy = 0.9883, Training Loss = 0.1290, Validation Accuracy = 0.0102, Validation Loss = 7.7802\n",
            "Epoch 270/1667\n",
            "Epoch 270: Training Accuracy = 0.9883, Training Loss = 0.1290, Validation Accuracy = 0.0102, Validation Loss = 7.7802\n",
            "Epoch 271/1667\n",
            "Epoch 271: Training Accuracy = 0.9922, Training Loss = 0.1201, Validation Accuracy = 0.0100, Validation Loss = 7.7695\n",
            "Epoch 272/1667\n",
            "Epoch 272: Training Accuracy = 0.9902, Training Loss = 0.1292, Validation Accuracy = 0.0105, Validation Loss = 7.7248\n",
            "Epoch 273/1667\n",
            "Epoch 273: Training Accuracy = 0.9902, Training Loss = 0.1292, Validation Accuracy = 0.0105, Validation Loss = 7.7248\n",
            "Epoch 274/1667\n",
            "Epoch 274: Training Accuracy = 0.9902, Training Loss = 0.1223, Validation Accuracy = 0.0108, Validation Loss = 7.7416\n",
            "Epoch 275/1667\n",
            "Epoch 275: Training Accuracy = 0.9902, Training Loss = 0.1223, Validation Accuracy = 0.0108, Validation Loss = 7.7416\n",
            "Epoch 276/1667\n",
            "Epoch 276: Training Accuracy = 0.9883, Training Loss = 0.1521, Validation Accuracy = 0.0106, Validation Loss = 7.5809\n",
            "Epoch 277/1667\n",
            "Epoch 277: Training Accuracy = 0.7578, Training Loss = 1.0700, Validation Accuracy = 0.0103, Validation Loss = 7.3516\n",
            "Epoch 278/1667\n",
            "Epoch 278: Training Accuracy = 0.7578, Training Loss = 1.0700, Validation Accuracy = 0.0103, Validation Loss = 7.3516\n",
            "Epoch 279/1667\n",
            "Epoch 279: Training Accuracy = 0.9688, Training Loss = 0.4138, Validation Accuracy = 0.0108, Validation Loss = 7.5423\n",
            "Epoch 280/1667\n",
            "Epoch 280: Training Accuracy = 0.9688, Training Loss = 0.4138, Validation Accuracy = 0.0108, Validation Loss = 7.5423\n",
            "Epoch 281/1667\n",
            "Epoch 281: Training Accuracy = 0.9824, Training Loss = 0.2879, Validation Accuracy = 0.0106, Validation Loss = 7.7234\n",
            "Epoch 282/1667\n",
            "Epoch 282: Training Accuracy = 0.9844, Training Loss = 0.2226, Validation Accuracy = 0.0103, Validation Loss = 7.7523\n",
            "Epoch 283/1667\n",
            "Epoch 283: Training Accuracy = 0.9844, Training Loss = 0.2226, Validation Accuracy = 0.0103, Validation Loss = 7.7523\n",
            "Epoch 284/1667\n",
            "Epoch 284: Training Accuracy = 0.9961, Training Loss = 0.1262, Validation Accuracy = 0.0100, Validation Loss = 7.8131\n",
            "Epoch 285/1667\n",
            "Epoch 285: Training Accuracy = 0.9961, Training Loss = 0.1262, Validation Accuracy = 0.0100, Validation Loss = 7.8131\n",
            "Epoch 286/1667\n",
            "Epoch 286: Training Accuracy = 0.9785, Training Loss = 0.1657, Validation Accuracy = 0.0099, Validation Loss = 7.8601\n",
            "Epoch 287/1667\n",
            "Epoch 287: Training Accuracy = 0.9941, Training Loss = 0.1029, Validation Accuracy = 0.0105, Validation Loss = 7.8116\n",
            "Epoch 288/1667\n",
            "Epoch 288: Training Accuracy = 0.9941, Training Loss = 0.1029, Validation Accuracy = 0.0105, Validation Loss = 7.8116\n",
            "Epoch 289/1667\n",
            "Epoch 289: Training Accuracy = 0.9844, Training Loss = 0.1334, Validation Accuracy = 0.0099, Validation Loss = 7.7981\n",
            "Epoch 290/1667\n",
            "Epoch 290: Training Accuracy = 0.9844, Training Loss = 0.1334, Validation Accuracy = 0.0099, Validation Loss = 7.7981\n",
            "Epoch 291/1667\n",
            "Epoch 291: Training Accuracy = 0.9902, Training Loss = 0.1041, Validation Accuracy = 0.0097, Validation Loss = 7.7562\n",
            "Epoch 292/1667\n",
            "Epoch 292: Training Accuracy = 0.9941, Training Loss = 0.1096, Validation Accuracy = 0.0105, Validation Loss = 7.6965\n",
            "Epoch 293/1667\n",
            "Epoch 293: Training Accuracy = 0.9941, Training Loss = 0.1096, Validation Accuracy = 0.0105, Validation Loss = 7.6965\n",
            "Epoch 294/1667\n",
            "Epoch 294: Training Accuracy = 0.9805, Training Loss = 0.2605, Validation Accuracy = 0.0111, Validation Loss = 7.4695\n",
            "Epoch 295/1667\n",
            "Epoch 295: Training Accuracy = 0.9805, Training Loss = 0.2605, Validation Accuracy = 0.0111, Validation Loss = 7.4695\n",
            "Epoch 296/1667\n",
            "Epoch 296: Training Accuracy = 0.7930, Training Loss = 1.0186, Validation Accuracy = 0.0117, Validation Loss = 7.2286\n",
            "Epoch 297/1667\n",
            "Epoch 297: Training Accuracy = 0.9473, Training Loss = 0.5375, Validation Accuracy = 0.0105, Validation Loss = 7.5065\n",
            "Epoch 298/1667\n",
            "Epoch 298: Training Accuracy = 0.9473, Training Loss = 0.5375, Validation Accuracy = 0.0105, Validation Loss = 7.5065\n",
            "Epoch 299/1667\n",
            "Epoch 299: Training Accuracy = 0.9688, Training Loss = 0.3274, Validation Accuracy = 0.0103, Validation Loss = 7.6770\n",
            "Epoch 300/1667\n",
            "Epoch 300: Training Accuracy = 0.9688, Training Loss = 0.3274, Validation Accuracy = 0.0103, Validation Loss = 7.6770\n",
            "Epoch 301/1667\n",
            "Epoch 301: Training Accuracy = 0.9844, Training Loss = 0.2450, Validation Accuracy = 0.0108, Validation Loss = 7.7322\n",
            "Epoch 302/1667\n",
            "Epoch 302: Training Accuracy = 0.9844, Training Loss = 0.1899, Validation Accuracy = 0.0099, Validation Loss = 7.8004\n",
            "Epoch 303/1667\n",
            "Epoch 303: Training Accuracy = 0.9844, Training Loss = 0.1899, Validation Accuracy = 0.0099, Validation Loss = 7.8004\n",
            "Epoch 304/1667\n",
            "Epoch 304: Training Accuracy = 0.9941, Training Loss = 0.1229, Validation Accuracy = 0.0102, Validation Loss = 7.8109\n",
            "Epoch 305/1667\n",
            "Epoch 305: Training Accuracy = 0.9941, Training Loss = 0.1229, Validation Accuracy = 0.0102, Validation Loss = 7.8109\n",
            "Epoch 306/1667\n",
            "Epoch 306: Training Accuracy = 0.9922, Training Loss = 0.1167, Validation Accuracy = 0.0102, Validation Loss = 7.7912\n",
            "Epoch 307/1667\n",
            "Epoch 307: Training Accuracy = 0.9883, Training Loss = 0.1295, Validation Accuracy = 0.0102, Validation Loss = 7.7808\n",
            "Epoch 308/1667\n",
            "Epoch 308: Training Accuracy = 0.9883, Training Loss = 0.1295, Validation Accuracy = 0.0102, Validation Loss = 7.7808\n",
            "Epoch 309/1667\n",
            "Epoch 309: Training Accuracy = 0.9902, Training Loss = 0.1166, Validation Accuracy = 0.0102, Validation Loss = 7.7368\n",
            "Epoch 310/1667\n",
            "Epoch 310: Training Accuracy = 0.9902, Training Loss = 0.1166, Validation Accuracy = 0.0102, Validation Loss = 7.7368\n",
            "Epoch 311/1667\n",
            "Epoch 311: Training Accuracy = 0.9941, Training Loss = 0.0978, Validation Accuracy = 0.0103, Validation Loss = 7.7025\n",
            "Epoch 312/1667\n",
            "Epoch 312: Training Accuracy = 0.9863, Training Loss = 0.1414, Validation Accuracy = 0.0109, Validation Loss = 7.6808\n",
            "Epoch 313/1667\n",
            "Epoch 313: Training Accuracy = 0.9863, Training Loss = 0.1414, Validation Accuracy = 0.0109, Validation Loss = 7.6808\n",
            "Epoch 314/1667\n",
            "Epoch 314: Training Accuracy = 0.7891, Training Loss = 1.1248, Validation Accuracy = 0.0111, Validation Loss = 7.1779\n",
            "Epoch 315/1667\n",
            "Epoch 315: Training Accuracy = 0.7891, Training Loss = 1.1248, Validation Accuracy = 0.0111, Validation Loss = 7.1779\n",
            "Epoch 316/1667\n",
            "Epoch 316: Training Accuracy = 0.9355, Training Loss = 0.5607, Validation Accuracy = 0.0108, Validation Loss = 7.4550\n",
            "Epoch 317/1667\n",
            "Epoch 317: Training Accuracy = 0.9668, Training Loss = 0.4248, Validation Accuracy = 0.0102, Validation Loss = 7.7110\n",
            "Epoch 318/1667\n",
            "Epoch 318: Training Accuracy = 0.9668, Training Loss = 0.4248, Validation Accuracy = 0.0102, Validation Loss = 7.7110\n",
            "Epoch 319/1667\n",
            "Epoch 319: Training Accuracy = 0.9941, Training Loss = 0.1968, Validation Accuracy = 0.0099, Validation Loss = 7.7755\n",
            "Epoch 320/1667\n",
            "Epoch 320: Training Accuracy = 0.9941, Training Loss = 0.1968, Validation Accuracy = 0.0099, Validation Loss = 7.7755\n",
            "Epoch 321/1667\n",
            "Epoch 321: Training Accuracy = 0.9844, Training Loss = 0.1688, Validation Accuracy = 0.0103, Validation Loss = 7.8042\n",
            "Epoch 322/1667\n",
            "Epoch 322: Training Accuracy = 0.9902, Training Loss = 0.1277, Validation Accuracy = 0.0103, Validation Loss = 7.8385\n",
            "Epoch 323/1667\n",
            "Epoch 323: Training Accuracy = 0.9902, Training Loss = 0.1277, Validation Accuracy = 0.0103, Validation Loss = 7.8385\n",
            "Epoch 324/1667\n",
            "Epoch 324: Training Accuracy = 0.9902, Training Loss = 0.1127, Validation Accuracy = 0.0100, Validation Loss = 7.8342\n",
            "Epoch 325/1667\n",
            "Epoch 325: Training Accuracy = 0.9902, Training Loss = 0.1127, Validation Accuracy = 0.0100, Validation Loss = 7.8342\n",
            "Epoch 326/1667\n",
            "Epoch 326: Training Accuracy = 0.9961, Training Loss = 0.0788, Validation Accuracy = 0.0105, Validation Loss = 7.8258\n",
            "Epoch 327/1667\n",
            "Epoch 327: Training Accuracy = 0.9922, Training Loss = 0.0977, Validation Accuracy = 0.0100, Validation Loss = 7.8155\n",
            "Epoch 328/1667\n",
            "Epoch 328: Training Accuracy = 0.9922, Training Loss = 0.0977, Validation Accuracy = 0.0100, Validation Loss = 7.8155\n",
            "Epoch 329/1667\n",
            "Epoch 329: Training Accuracy = 0.9805, Training Loss = 0.1471, Validation Accuracy = 0.0102, Validation Loss = 7.7302\n",
            "Epoch 330/1667\n",
            "Epoch 330: Training Accuracy = 0.9805, Training Loss = 0.1471, Validation Accuracy = 0.0102, Validation Loss = 7.7302\n",
            "Epoch 331/1667\n",
            "Epoch 331: Training Accuracy = 0.9824, Training Loss = 0.2394, Validation Accuracy = 0.0105, Validation Loss = 7.2066\n",
            "Epoch 332/1667\n",
            "Epoch 332: Training Accuracy = 0.7832, Training Loss = 0.9929, Validation Accuracy = 0.0105, Validation Loss = 7.1719\n",
            "Epoch 333/1667\n",
            "Epoch 333: Training Accuracy = 0.7832, Training Loss = 0.9929, Validation Accuracy = 0.0105, Validation Loss = 7.1719\n",
            "Epoch 334/1667\n",
            "Epoch 334: Training Accuracy = 0.9746, Training Loss = 0.3793, Validation Accuracy = 0.0103, Validation Loss = 7.5776\n",
            "Epoch 335/1667\n",
            "Epoch 335: Training Accuracy = 0.9746, Training Loss = 0.3793, Validation Accuracy = 0.0103, Validation Loss = 7.5776\n",
            "Epoch 336/1667\n",
            "Epoch 336: Training Accuracy = 0.9883, Training Loss = 0.2409, Validation Accuracy = 0.0105, Validation Loss = 7.7464\n",
            "Epoch 337/1667\n",
            "Epoch 337: Training Accuracy = 0.9922, Training Loss = 0.1860, Validation Accuracy = 0.0105, Validation Loss = 7.7648\n",
            "Epoch 338/1667\n",
            "Epoch 338: Training Accuracy = 0.9922, Training Loss = 0.1860, Validation Accuracy = 0.0105, Validation Loss = 7.7648\n",
            "Epoch 339/1667\n",
            "Epoch 339: Training Accuracy = 0.9863, Training Loss = 0.1484, Validation Accuracy = 0.0102, Validation Loss = 7.8680\n",
            "Epoch 340/1667\n",
            "Epoch 340: Training Accuracy = 0.9863, Training Loss = 0.1484, Validation Accuracy = 0.0102, Validation Loss = 7.8680\n",
            "Epoch 341/1667\n",
            "Epoch 341: Training Accuracy = 0.9922, Training Loss = 0.1017, Validation Accuracy = 0.0111, Validation Loss = 7.8046\n",
            "Epoch 342/1667\n",
            "Epoch 342: Training Accuracy = 0.9902, Training Loss = 0.1152, Validation Accuracy = 0.0106, Validation Loss = 7.8246\n",
            "Epoch 343/1667\n",
            "Epoch 343: Training Accuracy = 0.9902, Training Loss = 0.1152, Validation Accuracy = 0.0106, Validation Loss = 7.8246\n",
            "Epoch 344/1667\n",
            "Epoch 344: Training Accuracy = 0.9805, Training Loss = 0.1400, Validation Accuracy = 0.0097, Validation Loss = 7.8033\n",
            "Epoch 345/1667\n",
            "Epoch 345: Training Accuracy = 0.9805, Training Loss = 0.1400, Validation Accuracy = 0.0097, Validation Loss = 7.8033\n",
            "Epoch 346/1667\n",
            "Epoch 346: Training Accuracy = 0.9961, Training Loss = 0.0775, Validation Accuracy = 0.0109, Validation Loss = 7.7409\n",
            "Epoch 347/1667\n",
            "Epoch 347: Training Accuracy = 0.9883, Training Loss = 0.2761, Validation Accuracy = 0.0115, Validation Loss = 7.0714\n",
            "Epoch 348/1667\n",
            "Epoch 348: Training Accuracy = 0.9883, Training Loss = 0.2761, Validation Accuracy = 0.0115, Validation Loss = 7.0714\n",
            "Epoch 349/1667\n",
            "Epoch 349: Training Accuracy = 0.8574, Training Loss = 0.8189, Validation Accuracy = 0.0109, Validation Loss = 7.3575\n",
            "Epoch 350/1667\n",
            "Epoch 350: Training Accuracy = 0.8574, Training Loss = 0.8189, Validation Accuracy = 0.0109, Validation Loss = 7.3575\n",
            "Epoch 351/1667\n",
            "Epoch 351: Training Accuracy = 0.9863, Training Loss = 0.3538, Validation Accuracy = 0.0106, Validation Loss = 7.5136\n",
            "Epoch 352/1667\n",
            "Epoch 352: Training Accuracy = 0.9824, Training Loss = 0.2588, Validation Accuracy = 0.0105, Validation Loss = 7.7154\n",
            "Epoch 353/1667\n",
            "Epoch 353: Training Accuracy = 0.9824, Training Loss = 0.2588, Validation Accuracy = 0.0105, Validation Loss = 7.7154\n",
            "Epoch 354/1667\n",
            "Epoch 354: Training Accuracy = 0.9785, Training Loss = 0.2071, Validation Accuracy = 0.0100, Validation Loss = 7.8410\n",
            "Epoch 355/1667\n",
            "Epoch 355: Training Accuracy = 0.9785, Training Loss = 0.2071, Validation Accuracy = 0.0100, Validation Loss = 7.8410\n",
            "Epoch 356/1667\n",
            "Epoch 356: Training Accuracy = 0.9863, Training Loss = 0.1366, Validation Accuracy = 0.0106, Validation Loss = 7.8171\n",
            "Epoch 357/1667\n",
            "Epoch 357: Training Accuracy = 0.9863, Training Loss = 0.1320, Validation Accuracy = 0.0103, Validation Loss = 7.8173\n",
            "Epoch 358/1667\n",
            "Epoch 358: Training Accuracy = 0.9863, Training Loss = 0.1320, Validation Accuracy = 0.0103, Validation Loss = 7.8173\n",
            "Epoch 359/1667\n",
            "Epoch 359: Training Accuracy = 0.9941, Training Loss = 0.0899, Validation Accuracy = 0.0096, Validation Loss = 7.8292\n",
            "Epoch 360/1667\n",
            "Epoch 360: Training Accuracy = 0.9941, Training Loss = 0.0899, Validation Accuracy = 0.0096, Validation Loss = 7.8292\n",
            "Epoch 361/1667\n",
            "Epoch 361: Training Accuracy = 0.9883, Training Loss = 0.1086, Validation Accuracy = 0.0103, Validation Loss = 7.7445\n",
            "Epoch 362/1667\n",
            "Epoch 362: Training Accuracy = 0.9922, Training Loss = 0.1113, Validation Accuracy = 0.0105, Validation Loss = 7.7359\n",
            "Epoch 363/1667\n",
            "Epoch 363: Training Accuracy = 0.9922, Training Loss = 0.1113, Validation Accuracy = 0.0105, Validation Loss = 7.7359\n",
            "Epoch 364/1667\n",
            "Epoch 364: Training Accuracy = 0.9941, Training Loss = 0.0922, Validation Accuracy = 0.0100, Validation Loss = 7.7341\n",
            "Epoch 365/1667\n",
            "Epoch 365: Training Accuracy = 0.9941, Training Loss = 0.0922, Validation Accuracy = 0.0100, Validation Loss = 7.7341\n",
            "Epoch 366/1667\n",
            "Epoch 366: Training Accuracy = 0.9805, Training Loss = 0.1834, Validation Accuracy = 0.0099, Validation Loss = 7.5652\n",
            "Epoch 367/1667\n",
            "Epoch 367: Training Accuracy = 0.6074, Training Loss = 1.5915, Validation Accuracy = 0.0117, Validation Loss = 7.1968\n",
            "Epoch 368/1667\n",
            "Epoch 368: Training Accuracy = 0.6074, Training Loss = 1.5915, Validation Accuracy = 0.0117, Validation Loss = 7.1968\n",
            "Epoch 369/1667\n",
            "Epoch 369: Training Accuracy = 0.8223, Training Loss = 0.9424, Validation Accuracy = 0.0106, Validation Loss = 7.3571\n",
            "Epoch 370/1667\n",
            "Epoch 370: Training Accuracy = 0.8223, Training Loss = 0.9424, Validation Accuracy = 0.0106, Validation Loss = 7.3571\n",
            "Epoch 371/1667\n",
            "Epoch 371: Training Accuracy = 0.9629, Training Loss = 0.4382, Validation Accuracy = 0.0108, Validation Loss = 7.5382\n",
            "Epoch 372/1667\n",
            "Epoch 372: Training Accuracy = 0.9883, Training Loss = 0.3137, Validation Accuracy = 0.0105, Validation Loss = 7.6486\n",
            "Epoch 373/1667\n",
            "Epoch 373: Training Accuracy = 0.9883, Training Loss = 0.3137, Validation Accuracy = 0.0105, Validation Loss = 7.6486\n",
            "Epoch 374/1667\n",
            "Epoch 374: Training Accuracy = 0.9902, Training Loss = 0.1871, Validation Accuracy = 0.0105, Validation Loss = 7.7103\n",
            "Epoch 375/1667\n",
            "Epoch 375: Training Accuracy = 0.9902, Training Loss = 0.1871, Validation Accuracy = 0.0105, Validation Loss = 7.7103\n",
            "Epoch 376/1667\n",
            "Epoch 376: Training Accuracy = 0.9863, Training Loss = 0.1525, Validation Accuracy = 0.0108, Validation Loss = 7.7453\n",
            "Epoch 377/1667\n",
            "Epoch 377: Training Accuracy = 0.9863, Training Loss = 0.1487, Validation Accuracy = 0.0112, Validation Loss = 7.7779\n",
            "Epoch 378/1667\n",
            "Epoch 378: Training Accuracy = 0.9863, Training Loss = 0.1487, Validation Accuracy = 0.0112, Validation Loss = 7.7779\n",
            "Epoch 379/1667\n",
            "Epoch 379: Training Accuracy = 0.9922, Training Loss = 0.1161, Validation Accuracy = 0.0106, Validation Loss = 7.7378\n",
            "Epoch 380/1667\n",
            "Epoch 380: Training Accuracy = 0.9922, Training Loss = 0.1161, Validation Accuracy = 0.0106, Validation Loss = 7.7378\n",
            "Epoch 381/1667\n",
            "Epoch 381: Training Accuracy = 0.9883, Training Loss = 0.1286, Validation Accuracy = 0.0103, Validation Loss = 7.6806\n",
            "Epoch 382/1667\n",
            "Epoch 382: Training Accuracy = 0.9824, Training Loss = 0.1473, Validation Accuracy = 0.0105, Validation Loss = 7.6876\n",
            "Epoch 383/1667\n",
            "Epoch 383: Training Accuracy = 0.9824, Training Loss = 0.1473, Validation Accuracy = 0.0105, Validation Loss = 7.6876\n",
            "Epoch 384/1667\n",
            "Epoch 384: Training Accuracy = 0.9902, Training Loss = 0.1166, Validation Accuracy = 0.0105, Validation Loss = 7.6133\n",
            "Epoch 385/1667\n",
            "Epoch 385: Training Accuracy = 0.9902, Training Loss = 0.1166, Validation Accuracy = 0.0105, Validation Loss = 7.6133\n",
            "Epoch 386/1667\n",
            "Epoch 386: Training Accuracy = 0.9883, Training Loss = 0.1525, Validation Accuracy = 0.0111, Validation Loss = 7.4936\n",
            "Epoch 387/1667\n",
            "Epoch 387: Training Accuracy = 0.7520, Training Loss = 1.2033, Validation Accuracy = 0.0120, Validation Loss = 7.0279\n",
            "Epoch 388/1667\n",
            "Epoch 388: Training Accuracy = 0.7520, Training Loss = 1.2033, Validation Accuracy = 0.0120, Validation Loss = 7.0279\n",
            "Epoch 389/1667\n",
            "Epoch 389: Training Accuracy = 0.9316, Training Loss = 0.5393, Validation Accuracy = 0.0111, Validation Loss = 7.3462\n",
            "Epoch 390/1667\n",
            "Epoch 390: Training Accuracy = 0.9316, Training Loss = 0.5393, Validation Accuracy = 0.0111, Validation Loss = 7.3462\n",
            "Epoch 391/1667\n",
            "Epoch 391: Training Accuracy = 0.9844, Training Loss = 0.3057, Validation Accuracy = 0.0102, Validation Loss = 7.5252\n",
            "Epoch 392/1667\n",
            "Epoch 392: Training Accuracy = 0.9824, Training Loss = 0.2486, Validation Accuracy = 0.0105, Validation Loss = 7.6403\n",
            "Epoch 393/1667\n",
            "Epoch 393: Training Accuracy = 0.9824, Training Loss = 0.2486, Validation Accuracy = 0.0105, Validation Loss = 7.6403\n",
            "Epoch 394/1667\n",
            "Epoch 394: Training Accuracy = 0.9902, Training Loss = 0.1582, Validation Accuracy = 0.0106, Validation Loss = 7.6976\n",
            "Epoch 395/1667\n",
            "Epoch 395: Training Accuracy = 0.9902, Training Loss = 0.1582, Validation Accuracy = 0.0106, Validation Loss = 7.6976\n",
            "Epoch 396/1667\n",
            "Epoch 396: Training Accuracy = 0.9805, Training Loss = 0.1649, Validation Accuracy = 0.0108, Validation Loss = 7.6722\n",
            "Epoch 397/1667\n",
            "Epoch 397: Training Accuracy = 0.9824, Training Loss = 0.1529, Validation Accuracy = 0.0105, Validation Loss = 7.6792\n",
            "Epoch 398/1667\n",
            "Epoch 398: Training Accuracy = 0.9824, Training Loss = 0.1529, Validation Accuracy = 0.0105, Validation Loss = 7.6792\n",
            "Epoch 399/1667\n",
            "Epoch 399: Training Accuracy = 0.9883, Training Loss = 0.1226, Validation Accuracy = 0.0103, Validation Loss = 7.6557\n",
            "Epoch 400/1667\n",
            "Epoch 400: Training Accuracy = 0.9883, Training Loss = 0.1226, Validation Accuracy = 0.0103, Validation Loss = 7.6557\n",
            "Epoch 401/1667\n",
            "Epoch 401: Training Accuracy = 0.9824, Training Loss = 0.1436, Validation Accuracy = 0.0109, Validation Loss = 7.6159\n",
            "Epoch 402/1667\n",
            "Epoch 402: Training Accuracy = 0.9863, Training Loss = 0.1423, Validation Accuracy = 0.0100, Validation Loss = 7.5963\n",
            "Epoch 403/1667\n",
            "Epoch 403: Training Accuracy = 0.9863, Training Loss = 0.1423, Validation Accuracy = 0.0100, Validation Loss = 7.5963\n",
            "Epoch 404/1667\n",
            "Epoch 404: Training Accuracy = 0.9844, Training Loss = 0.2259, Validation Accuracy = 0.0114, Validation Loss = 7.4354\n",
            "Epoch 405/1667\n",
            "Epoch 405: Training Accuracy = 0.9844, Training Loss = 0.2259, Validation Accuracy = 0.0114, Validation Loss = 7.4354\n",
            "Epoch 406/1667\n",
            "Epoch 406: Training Accuracy = 0.9375, Training Loss = 0.5314, Validation Accuracy = 0.0100, Validation Loss = 7.2771\n",
            "Epoch 407/1667\n",
            "Epoch 407: Training Accuracy = 0.9746, Training Loss = 0.3987, Validation Accuracy = 0.0108, Validation Loss = 7.5019\n",
            "Epoch 408/1667\n",
            "Epoch 408: Training Accuracy = 0.9746, Training Loss = 0.3987, Validation Accuracy = 0.0108, Validation Loss = 7.5019\n",
            "Epoch 409/1667\n",
            "Epoch 409: Training Accuracy = 0.9961, Training Loss = 0.1941, Validation Accuracy = 0.0108, Validation Loss = 7.6633\n",
            "Epoch 410/1667\n",
            "Epoch 410: Training Accuracy = 0.9961, Training Loss = 0.1941, Validation Accuracy = 0.0108, Validation Loss = 7.6633\n",
            "Epoch 411/1667\n",
            "Epoch 411: Training Accuracy = 0.9844, Training Loss = 0.1682, Validation Accuracy = 0.0106, Validation Loss = 7.7325\n",
            "Epoch 412/1667\n",
            "Epoch 412: Training Accuracy = 0.9902, Training Loss = 0.1301, Validation Accuracy = 0.0108, Validation Loss = 7.7285\n",
            "Epoch 413/1667\n",
            "Epoch 413: Training Accuracy = 0.9902, Training Loss = 0.1301, Validation Accuracy = 0.0108, Validation Loss = 7.7285\n",
            "Epoch 414/1667\n",
            "Epoch 414: Training Accuracy = 0.9883, Training Loss = 0.1186, Validation Accuracy = 0.0108, Validation Loss = 7.7403\n",
            "Epoch 415/1667\n",
            "Epoch 415: Training Accuracy = 0.9883, Training Loss = 0.1186, Validation Accuracy = 0.0108, Validation Loss = 7.7403\n",
            "Epoch 416/1667\n",
            "Epoch 416: Training Accuracy = 0.9805, Training Loss = 0.1406, Validation Accuracy = 0.0109, Validation Loss = 7.7502\n",
            "Epoch 417/1667\n",
            "Epoch 417: Training Accuracy = 0.9824, Training Loss = 0.1422, Validation Accuracy = 0.0108, Validation Loss = 7.6889\n",
            "Epoch 418/1667\n",
            "Epoch 418: Training Accuracy = 0.9824, Training Loss = 0.1422, Validation Accuracy = 0.0108, Validation Loss = 7.6889\n",
            "Epoch 419/1667\n",
            "Epoch 419: Training Accuracy = 0.9902, Training Loss = 0.1075, Validation Accuracy = 0.0103, Validation Loss = 7.6322\n",
            "Epoch 420/1667\n",
            "Epoch 420: Training Accuracy = 0.9902, Training Loss = 0.1075, Validation Accuracy = 0.0103, Validation Loss = 7.6322\n",
            "Epoch 421/1667\n",
            "Epoch 421: Training Accuracy = 0.9863, Training Loss = 0.1245, Validation Accuracy = 0.0105, Validation Loss = 7.6230\n",
            "Epoch 422/1667\n",
            "Epoch 422: Training Accuracy = 0.6328, Training Loss = 1.4315, Validation Accuracy = 0.0123, Validation Loss = 6.6002\n",
            "Epoch 423/1667\n",
            "Epoch 423: Training Accuracy = 0.6328, Training Loss = 1.4315, Validation Accuracy = 0.0123, Validation Loss = 6.6002\n",
            "Epoch 424/1667\n",
            "Epoch 424: Training Accuracy = 0.8438, Training Loss = 0.8896, Validation Accuracy = 0.0120, Validation Loss = 7.3135\n",
            "Epoch 425/1667\n",
            "Epoch 425: Training Accuracy = 0.8438, Training Loss = 0.8896, Validation Accuracy = 0.0120, Validation Loss = 7.3135\n",
            "Epoch 426/1667\n",
            "Epoch 426: Training Accuracy = 0.9688, Training Loss = 0.4211, Validation Accuracy = 0.0108, Validation Loss = 7.4347\n",
            "Epoch 427/1667\n",
            "Epoch 427: Training Accuracy = 0.9883, Training Loss = 0.2544, Validation Accuracy = 0.0111, Validation Loss = 7.5861\n",
            "Epoch 428/1667\n",
            "Epoch 428: Training Accuracy = 0.9883, Training Loss = 0.2544, Validation Accuracy = 0.0111, Validation Loss = 7.5861\n",
            "Epoch 429/1667\n",
            "Epoch 429: Training Accuracy = 0.9922, Training Loss = 0.1702, Validation Accuracy = 0.0108, Validation Loss = 7.6961\n",
            "Epoch 430/1667\n",
            "Epoch 430: Training Accuracy = 0.9922, Training Loss = 0.1702, Validation Accuracy = 0.0108, Validation Loss = 7.6961\n",
            "Epoch 431/1667\n",
            "Epoch 431: Training Accuracy = 0.9902, Training Loss = 0.1337, Validation Accuracy = 0.0109, Validation Loss = 7.7125\n",
            "Epoch 432/1667\n",
            "Epoch 432: Training Accuracy = 0.9863, Training Loss = 0.1339, Validation Accuracy = 0.0111, Validation Loss = 7.7391\n",
            "Epoch 433/1667\n",
            "Epoch 433: Training Accuracy = 0.9863, Training Loss = 0.1339, Validation Accuracy = 0.0111, Validation Loss = 7.7391\n",
            "Epoch 434/1667\n",
            "Epoch 434: Training Accuracy = 0.9941, Training Loss = 0.0922, Validation Accuracy = 0.0105, Validation Loss = 7.7261\n",
            "Epoch 435/1667\n",
            "Epoch 435: Training Accuracy = 0.9941, Training Loss = 0.0922, Validation Accuracy = 0.0105, Validation Loss = 7.7261\n",
            "Epoch 436/1667\n",
            "Epoch 436: Training Accuracy = 0.9941, Training Loss = 0.0864, Validation Accuracy = 0.0106, Validation Loss = 7.6716\n",
            "Epoch 437/1667\n",
            "Epoch 437: Training Accuracy = 0.9941, Training Loss = 0.0965, Validation Accuracy = 0.0109, Validation Loss = 7.6537\n",
            "Epoch 438/1667\n",
            "Epoch 438: Training Accuracy = 0.9941, Training Loss = 0.0965, Validation Accuracy = 0.0109, Validation Loss = 7.6537\n",
            "Epoch 439/1667\n",
            "Epoch 439: Training Accuracy = 0.9883, Training Loss = 0.1160, Validation Accuracy = 0.0109, Validation Loss = 7.6012\n",
            "Epoch 440/1667\n",
            "Epoch 440: Training Accuracy = 0.9883, Training Loss = 0.1160, Validation Accuracy = 0.0109, Validation Loss = 7.6012\n",
            "Epoch 441/1667\n",
            "Epoch 441: Training Accuracy = 0.9902, Training Loss = 0.1338, Validation Accuracy = 0.0120, Validation Loss = 7.5335\n",
            "Epoch 442/1667\n",
            "Epoch 442: Training Accuracy = 0.8691, Training Loss = 1.0717, Validation Accuracy = 0.0112, Validation Loss = 7.0252\n",
            "Epoch 443/1667\n",
            "Epoch 443: Training Accuracy = 0.8691, Training Loss = 1.0717, Validation Accuracy = 0.0112, Validation Loss = 7.0252\n",
            "Epoch 444/1667\n",
            "Epoch 444: Training Accuracy = 0.9414, Training Loss = 0.5210, Validation Accuracy = 0.0106, Validation Loss = 7.4507\n",
            "Epoch 445/1667\n",
            "Epoch 445: Training Accuracy = 0.9414, Training Loss = 0.5210, Validation Accuracy = 0.0106, Validation Loss = 7.4507\n",
            "Epoch 446/1667\n",
            "Epoch 446: Training Accuracy = 0.9863, Training Loss = 0.2608, Validation Accuracy = 0.0111, Validation Loss = 7.5271\n",
            "Epoch 447/1667\n",
            "Epoch 447: Training Accuracy = 0.9844, Training Loss = 0.2095, Validation Accuracy = 0.0111, Validation Loss = 7.6129\n",
            "Epoch 448/1667\n",
            "Epoch 448: Training Accuracy = 0.9844, Training Loss = 0.2095, Validation Accuracy = 0.0111, Validation Loss = 7.6129\n",
            "Epoch 449/1667\n",
            "Epoch 449: Training Accuracy = 0.9883, Training Loss = 0.1540, Validation Accuracy = 0.0108, Validation Loss = 7.7080\n",
            "Epoch 450/1667\n",
            "Epoch 450: Training Accuracy = 0.9883, Training Loss = 0.1540, Validation Accuracy = 0.0108, Validation Loss = 7.7080\n",
            "Epoch 451/1667\n",
            "Epoch 451: Training Accuracy = 0.9902, Training Loss = 0.1200, Validation Accuracy = 0.0105, Validation Loss = 7.6954\n",
            "Epoch 452/1667\n",
            "Epoch 452: Training Accuracy = 0.9863, Training Loss = 0.1321, Validation Accuracy = 0.0106, Validation Loss = 7.6555\n",
            "Epoch 453/1667\n",
            "Epoch 453: Training Accuracy = 0.9863, Training Loss = 0.1321, Validation Accuracy = 0.0106, Validation Loss = 7.6555\n",
            "Epoch 454/1667\n",
            "Epoch 454: Training Accuracy = 0.9883, Training Loss = 0.1080, Validation Accuracy = 0.0109, Validation Loss = 7.6556\n",
            "Epoch 455/1667\n",
            "Epoch 455: Training Accuracy = 0.9883, Training Loss = 0.1080, Validation Accuracy = 0.0109, Validation Loss = 7.6556\n",
            "Epoch 456/1667\n",
            "Epoch 456: Training Accuracy = 0.9922, Training Loss = 0.0849, Validation Accuracy = 0.0103, Validation Loss = 7.6525\n",
            "Epoch 457/1667\n",
            "Epoch 457: Training Accuracy = 0.9883, Training Loss = 0.1214, Validation Accuracy = 0.0111, Validation Loss = 7.6382\n",
            "Epoch 458/1667\n",
            "Epoch 458: Training Accuracy = 0.9883, Training Loss = 0.1214, Validation Accuracy = 0.0111, Validation Loss = 7.6382\n",
            "Epoch 459/1667\n",
            "Epoch 459: Training Accuracy = 0.9863, Training Loss = 0.1310, Validation Accuracy = 0.0111, Validation Loss = 7.5447\n",
            "Epoch 460/1667\n",
            "Epoch 460: Training Accuracy = 0.9863, Training Loss = 0.1310, Validation Accuracy = 0.0111, Validation Loss = 7.5447\n",
            "Epoch 461/1667\n",
            "Epoch 461: Training Accuracy = 0.7559, Training Loss = 1.2057, Validation Accuracy = 0.0115, Validation Loss = 6.7022\n",
            "Epoch 462/1667\n",
            "Epoch 462: Training Accuracy = 0.7559, Training Loss = 1.2259, Validation Accuracy = 0.0105, Validation Loss = 7.0807\n",
            "Epoch 463/1667\n",
            "Epoch 463: Training Accuracy = 0.7559, Training Loss = 1.2259, Validation Accuracy = 0.0105, Validation Loss = 7.0807\n",
            "Epoch 464/1667\n",
            "Epoch 464: Training Accuracy = 0.9414, Training Loss = 0.5274, Validation Accuracy = 0.0114, Validation Loss = 7.2854\n",
            "Epoch 465/1667\n",
            "Epoch 465: Training Accuracy = 0.9414, Training Loss = 0.5274, Validation Accuracy = 0.0114, Validation Loss = 7.2854\n",
            "Epoch 466/1667\n",
            "Epoch 466: Training Accuracy = 0.9824, Training Loss = 0.2585, Validation Accuracy = 0.0109, Validation Loss = 7.5507\n",
            "Epoch 467/1667\n",
            "Epoch 467: Training Accuracy = 0.9902, Training Loss = 0.1912, Validation Accuracy = 0.0112, Validation Loss = 7.6297\n",
            "Epoch 468/1667\n",
            "Epoch 468: Training Accuracy = 0.9902, Training Loss = 0.1912, Validation Accuracy = 0.0112, Validation Loss = 7.6297\n",
            "Epoch 469/1667\n",
            "Epoch 469: Training Accuracy = 0.9883, Training Loss = 0.1567, Validation Accuracy = 0.0106, Validation Loss = 7.6383\n",
            "Epoch 470/1667\n",
            "Epoch 470: Training Accuracy = 0.9883, Training Loss = 0.1567, Validation Accuracy = 0.0106, Validation Loss = 7.6383\n",
            "Epoch 471/1667\n",
            "Epoch 471: Training Accuracy = 0.9902, Training Loss = 0.1146, Validation Accuracy = 0.0111, Validation Loss = 7.6784\n",
            "Epoch 472/1667\n",
            "Epoch 472: Training Accuracy = 0.9805, Training Loss = 0.1523, Validation Accuracy = 0.0106, Validation Loss = 7.6343\n",
            "Epoch 473/1667\n",
            "Epoch 473: Training Accuracy = 0.9805, Training Loss = 0.1523, Validation Accuracy = 0.0106, Validation Loss = 7.6343\n",
            "Epoch 474/1667\n",
            "Epoch 474: Training Accuracy = 0.9766, Training Loss = 0.1531, Validation Accuracy = 0.0108, Validation Loss = 7.6248\n",
            "Epoch 475/1667\n",
            "Epoch 475: Training Accuracy = 0.9766, Training Loss = 0.1531, Validation Accuracy = 0.0108, Validation Loss = 7.6248\n",
            "Epoch 476/1667\n",
            "Epoch 476: Training Accuracy = 0.9922, Training Loss = 0.0967, Validation Accuracy = 0.0109, Validation Loss = 7.5761\n",
            "Epoch 477/1667\n",
            "Epoch 477: Training Accuracy = 0.9980, Training Loss = 0.0866, Validation Accuracy = 0.0112, Validation Loss = 7.4926\n",
            "Epoch 478/1667\n",
            "Epoch 478: Training Accuracy = 0.9980, Training Loss = 0.0866, Validation Accuracy = 0.0112, Validation Loss = 7.4926\n",
            "Epoch 479/1667\n",
            "Epoch 479: Training Accuracy = 0.8105, Training Loss = 1.1617, Validation Accuracy = 0.0134, Validation Loss = 6.7513\n",
            "Epoch 480/1667\n",
            "Epoch 480: Training Accuracy = 0.8105, Training Loss = 1.1617, Validation Accuracy = 0.0134, Validation Loss = 6.7513\n",
            "Epoch 481/1667\n",
            "Epoch 481: Training Accuracy = 0.9473, Training Loss = 0.5763, Validation Accuracy = 0.0109, Validation Loss = 7.1548\n",
            "Epoch 482/1667\n",
            "Epoch 482: Training Accuracy = 0.9609, Training Loss = 0.4268, Validation Accuracy = 0.0117, Validation Loss = 7.3814\n",
            "Epoch 483/1667\n",
            "Epoch 483: Training Accuracy = 0.9609, Training Loss = 0.4268, Validation Accuracy = 0.0117, Validation Loss = 7.3814\n",
            "Epoch 484/1667\n",
            "Epoch 484: Training Accuracy = 0.9824, Training Loss = 0.2452, Validation Accuracy = 0.0105, Validation Loss = 7.4754\n",
            "Epoch 485/1667\n",
            "Epoch 485: Training Accuracy = 0.9824, Training Loss = 0.2452, Validation Accuracy = 0.0105, Validation Loss = 7.4754\n",
            "Epoch 486/1667\n",
            "Epoch 486: Training Accuracy = 0.9844, Training Loss = 0.1733, Validation Accuracy = 0.0123, Validation Loss = 7.5568\n",
            "Epoch 487/1667\n",
            "Epoch 487: Training Accuracy = 0.9863, Training Loss = 0.1466, Validation Accuracy = 0.0114, Validation Loss = 7.5815\n",
            "Epoch 488/1667\n",
            "Epoch 488: Training Accuracy = 0.9863, Training Loss = 0.1466, Validation Accuracy = 0.0114, Validation Loss = 7.5815\n",
            "Epoch 489/1667\n",
            "Epoch 489: Training Accuracy = 0.9902, Training Loss = 0.1260, Validation Accuracy = 0.0103, Validation Loss = 7.6318\n",
            "Epoch 490/1667\n",
            "Epoch 490: Training Accuracy = 0.9902, Training Loss = 0.1260, Validation Accuracy = 0.0103, Validation Loss = 7.6318\n",
            "Epoch 491/1667\n",
            "Epoch 491: Training Accuracy = 0.9844, Training Loss = 0.1272, Validation Accuracy = 0.0112, Validation Loss = 7.5799\n",
            "Epoch 492/1667\n",
            "Epoch 492: Training Accuracy = 0.9824, Training Loss = 0.1404, Validation Accuracy = 0.0108, Validation Loss = 7.5692\n",
            "Epoch 493/1667\n",
            "Epoch 493: Training Accuracy = 0.9824, Training Loss = 0.1404, Validation Accuracy = 0.0108, Validation Loss = 7.5692\n",
            "Epoch 494/1667\n",
            "Epoch 494: Training Accuracy = 0.9805, Training Loss = 0.1431, Validation Accuracy = 0.0111, Validation Loss = 7.5263\n",
            "Epoch 495/1667\n",
            "Epoch 495: Training Accuracy = 0.9805, Training Loss = 0.1431, Validation Accuracy = 0.0111, Validation Loss = 7.5263\n",
            "Epoch 496/1667\n",
            "Epoch 496: Training Accuracy = 0.9824, Training Loss = 0.1300, Validation Accuracy = 0.0114, Validation Loss = 7.4984\n",
            "Epoch 497/1667\n",
            "Epoch 497: Training Accuracy = 0.9902, Training Loss = 0.1325, Validation Accuracy = 0.0108, Validation Loss = 7.4921\n",
            "Epoch 498/1667\n",
            "Epoch 498: Training Accuracy = 0.9902, Training Loss = 0.1325, Validation Accuracy = 0.0108, Validation Loss = 7.4921\n",
            "Epoch 499/1667\n",
            "Epoch 499: Training Accuracy = 0.6719, Training Loss = 1.5514, Validation Accuracy = 0.0124, Validation Loss = 6.8809\n",
            "Epoch 500/1667\n",
            "Epoch 500: Training Accuracy = 0.6719, Training Loss = 1.5514, Validation Accuracy = 0.0124, Validation Loss = 6.8809\n",
            "Epoch 501/1667\n",
            "Epoch 501: Training Accuracy = 0.9473, Training Loss = 0.5969, Validation Accuracy = 0.0115, Validation Loss = 7.1549\n",
            "Epoch 502/1667\n",
            "Epoch 502: Training Accuracy = 0.9570, Training Loss = 0.4772, Validation Accuracy = 0.0111, Validation Loss = 7.3689\n",
            "Epoch 503/1667\n",
            "Epoch 503: Training Accuracy = 0.9570, Training Loss = 0.4772, Validation Accuracy = 0.0111, Validation Loss = 7.3689\n",
            "Epoch 504/1667\n",
            "Epoch 504: Training Accuracy = 0.9863, Training Loss = 0.2411, Validation Accuracy = 0.0112, Validation Loss = 7.4995\n",
            "Epoch 505/1667\n",
            "Epoch 505: Training Accuracy = 0.9863, Training Loss = 0.2411, Validation Accuracy = 0.0112, Validation Loss = 7.4995\n",
            "Epoch 506/1667\n",
            "Epoch 506: Training Accuracy = 0.9883, Training Loss = 0.1592, Validation Accuracy = 0.0118, Validation Loss = 7.5757\n",
            "Epoch 507/1667\n",
            "Epoch 507: Training Accuracy = 0.9844, Training Loss = 0.1555, Validation Accuracy = 0.0114, Validation Loss = 7.6189\n",
            "Epoch 508/1667\n",
            "Epoch 508: Training Accuracy = 0.9844, Training Loss = 0.1555, Validation Accuracy = 0.0114, Validation Loss = 7.6189\n",
            "Epoch 509/1667\n",
            "Epoch 509: Training Accuracy = 0.9863, Training Loss = 0.1211, Validation Accuracy = 0.0112, Validation Loss = 7.6369\n",
            "Epoch 510/1667\n",
            "Epoch 510: Training Accuracy = 0.9863, Training Loss = 0.1211, Validation Accuracy = 0.0112, Validation Loss = 7.6369\n",
            "Epoch 511/1667\n",
            "Epoch 511: Training Accuracy = 0.9863, Training Loss = 0.1061, Validation Accuracy = 0.0109, Validation Loss = 7.6012\n",
            "Epoch 512/1667\n",
            "Epoch 512: Training Accuracy = 0.9883, Training Loss = 0.1051, Validation Accuracy = 0.0106, Validation Loss = 7.5837\n",
            "Epoch 513/1667\n",
            "Epoch 513: Training Accuracy = 0.9883, Training Loss = 0.1051, Validation Accuracy = 0.0106, Validation Loss = 7.5837\n",
            "Epoch 514/1667\n",
            "Epoch 514: Training Accuracy = 0.9883, Training Loss = 0.1032, Validation Accuracy = 0.0109, Validation Loss = 7.5286\n",
            "Epoch 515/1667\n",
            "Epoch 515: Training Accuracy = 0.9883, Training Loss = 0.1032, Validation Accuracy = 0.0109, Validation Loss = 7.5286\n",
            "Epoch 516/1667\n",
            "Epoch 516: Training Accuracy = 0.9805, Training Loss = 0.1271, Validation Accuracy = 0.0112, Validation Loss = 7.4897\n",
            "Epoch 517/1667\n",
            "Epoch 517: Training Accuracy = 0.9922, Training Loss = 0.1078, Validation Accuracy = 0.0117, Validation Loss = 7.4649\n",
            "Epoch 518/1667\n",
            "Epoch 518: Training Accuracy = 0.9922, Training Loss = 0.1078, Validation Accuracy = 0.0117, Validation Loss = 7.4649\n",
            "Epoch 519/1667\n",
            "Epoch 519: Training Accuracy = 0.8574, Training Loss = 0.9126, Validation Accuracy = 0.0121, Validation Loss = 7.0806\n",
            "Epoch 520/1667\n",
            "Epoch 520: Training Accuracy = 0.8574, Training Loss = 0.9126, Validation Accuracy = 0.0121, Validation Loss = 7.0806\n",
            "Epoch 521/1667\n",
            "Epoch 521: Training Accuracy = 0.9688, Training Loss = 0.3926, Validation Accuracy = 0.0112, Validation Loss = 7.1722\n",
            "Epoch 522/1667\n",
            "Epoch 522: Training Accuracy = 0.9824, Training Loss = 0.3233, Validation Accuracy = 0.0120, Validation Loss = 7.3973\n",
            "Epoch 523/1667\n",
            "Epoch 523: Training Accuracy = 0.9824, Training Loss = 0.3233, Validation Accuracy = 0.0120, Validation Loss = 7.3973\n",
            "Epoch 524/1667\n",
            "Epoch 524: Training Accuracy = 0.9805, Training Loss = 0.2164, Validation Accuracy = 0.0108, Validation Loss = 7.5212\n",
            "Epoch 525/1667\n",
            "Epoch 525: Training Accuracy = 0.9805, Training Loss = 0.2164, Validation Accuracy = 0.0108, Validation Loss = 7.5212\n",
            "Epoch 526/1667\n",
            "Epoch 526: Training Accuracy = 0.9922, Training Loss = 0.1301, Validation Accuracy = 0.0112, Validation Loss = 7.5461\n",
            "Epoch 527/1667\n",
            "Epoch 527: Training Accuracy = 0.9883, Training Loss = 0.1291, Validation Accuracy = 0.0106, Validation Loss = 7.5444\n",
            "Epoch 528/1667\n",
            "Epoch 528: Training Accuracy = 0.9883, Training Loss = 0.1291, Validation Accuracy = 0.0106, Validation Loss = 7.5444\n",
            "Epoch 529/1667\n",
            "Epoch 529: Training Accuracy = 0.9844, Training Loss = 0.1189, Validation Accuracy = 0.0123, Validation Loss = 7.5721\n",
            "Epoch 530/1667\n",
            "Epoch 530: Training Accuracy = 0.9844, Training Loss = 0.1189, Validation Accuracy = 0.0123, Validation Loss = 7.5721\n",
            "Epoch 531/1667\n",
            "Epoch 531: Training Accuracy = 0.9980, Training Loss = 0.0610, Validation Accuracy = 0.0111, Validation Loss = 7.5606\n",
            "Epoch 532/1667\n",
            "Epoch 532: Training Accuracy = 0.9863, Training Loss = 0.1138, Validation Accuracy = 0.0115, Validation Loss = 7.5056\n",
            "Epoch 533/1667\n",
            "Epoch 533: Training Accuracy = 0.9863, Training Loss = 0.1138, Validation Accuracy = 0.0115, Validation Loss = 7.5056\n",
            "Epoch 534/1667\n",
            "Epoch 534: Training Accuracy = 0.9883, Training Loss = 0.1091, Validation Accuracy = 0.0108, Validation Loss = 7.4638\n",
            "Epoch 535/1667\n",
            "Epoch 535: Training Accuracy = 0.9883, Training Loss = 0.1091, Validation Accuracy = 0.0108, Validation Loss = 7.4638\n",
            "Epoch 536/1667\n",
            "Epoch 536: Training Accuracy = 0.9922, Training Loss = 0.0946, Validation Accuracy = 0.0115, Validation Loss = 7.4057\n",
            "Epoch 537/1667\n",
            "Epoch 537: Training Accuracy = 0.9902, Training Loss = 0.1973, Validation Accuracy = 0.0123, Validation Loss = 7.2339\n",
            "Epoch 538/1667\n",
            "Epoch 538: Training Accuracy = 0.9902, Training Loss = 0.1973, Validation Accuracy = 0.0123, Validation Loss = 7.2339\n",
            "Epoch 539/1667\n",
            "Epoch 539: Training Accuracy = 0.9004, Training Loss = 0.6968, Validation Accuracy = 0.0114, Validation Loss = 7.1082\n",
            "Epoch 540/1667\n",
            "Epoch 540: Training Accuracy = 0.9004, Training Loss = 0.6968, Validation Accuracy = 0.0114, Validation Loss = 7.1082\n",
            "Epoch 541/1667\n",
            "Epoch 541: Training Accuracy = 0.9805, Training Loss = 0.3196, Validation Accuracy = 0.0114, Validation Loss = 7.3086\n",
            "Epoch 542/1667\n",
            "Epoch 542: Training Accuracy = 0.9824, Training Loss = 0.2499, Validation Accuracy = 0.0106, Validation Loss = 7.4298\n",
            "Epoch 543/1667\n",
            "Epoch 543: Training Accuracy = 0.9824, Training Loss = 0.2499, Validation Accuracy = 0.0106, Validation Loss = 7.4298\n",
            "Epoch 544/1667\n",
            "Epoch 544: Training Accuracy = 0.9824, Training Loss = 0.1837, Validation Accuracy = 0.0115, Validation Loss = 7.4870\n",
            "Epoch 545/1667\n",
            "Epoch 545: Training Accuracy = 0.9824, Training Loss = 0.1837, Validation Accuracy = 0.0115, Validation Loss = 7.4870\n",
            "Epoch 546/1667\n",
            "Epoch 546: Training Accuracy = 0.9766, Training Loss = 0.1586, Validation Accuracy = 0.0111, Validation Loss = 7.5540\n",
            "Epoch 547/1667\n",
            "Epoch 547: Training Accuracy = 0.9805, Training Loss = 0.1432, Validation Accuracy = 0.0114, Validation Loss = 7.5375\n",
            "Epoch 548/1667\n",
            "Epoch 548: Training Accuracy = 0.9805, Training Loss = 0.1432, Validation Accuracy = 0.0114, Validation Loss = 7.5375\n",
            "Epoch 549/1667\n",
            "Epoch 549: Training Accuracy = 0.9844, Training Loss = 0.1128, Validation Accuracy = 0.0103, Validation Loss = 7.5591\n",
            "Epoch 550/1667\n",
            "Epoch 550: Training Accuracy = 0.9844, Training Loss = 0.1128, Validation Accuracy = 0.0103, Validation Loss = 7.5591\n",
            "Epoch 551/1667\n",
            "Epoch 551: Training Accuracy = 0.9902, Training Loss = 0.0841, Validation Accuracy = 0.0109, Validation Loss = 7.5043\n",
            "Epoch 552/1667\n",
            "Epoch 552: Training Accuracy = 0.9922, Training Loss = 0.0864, Validation Accuracy = 0.0117, Validation Loss = 7.4721\n",
            "Epoch 553/1667\n",
            "Epoch 553: Training Accuracy = 0.9922, Training Loss = 0.0864, Validation Accuracy = 0.0117, Validation Loss = 7.4721\n",
            "Epoch 554/1667\n",
            "Epoch 554: Training Accuracy = 0.9902, Training Loss = 0.0923, Validation Accuracy = 0.0105, Validation Loss = 7.4283\n",
            "Epoch 555/1667\n",
            "Epoch 555: Training Accuracy = 0.9902, Training Loss = 0.0923, Validation Accuracy = 0.0105, Validation Loss = 7.4283\n",
            "Epoch 556/1667\n",
            "Epoch 556: Training Accuracy = 0.9863, Training Loss = 0.1081, Validation Accuracy = 0.0121, Validation Loss = 7.3123\n",
            "Epoch 557/1667\n",
            "Epoch 557: Training Accuracy = 0.5645, Training Loss = 1.8472, Validation Accuracy = 0.0129, Validation Loss = 6.6985\n",
            "Epoch 558/1667\n",
            "Epoch 558: Training Accuracy = 0.5645, Training Loss = 1.8472, Validation Accuracy = 0.0129, Validation Loss = 6.6985\n",
            "Epoch 559/1667\n",
            "Epoch 559: Training Accuracy = 0.8750, Training Loss = 0.7524, Validation Accuracy = 0.0115, Validation Loss = 7.1309\n",
            "Epoch 560/1667\n",
            "Epoch 560: Training Accuracy = 0.8750, Training Loss = 0.7524, Validation Accuracy = 0.0115, Validation Loss = 7.1309\n",
            "Epoch 561/1667\n",
            "Epoch 561: Training Accuracy = 0.9707, Training Loss = 0.3875, Validation Accuracy = 0.0117, Validation Loss = 7.2600\n",
            "Epoch 562/1667\n",
            "Epoch 562: Training Accuracy = 0.9785, Training Loss = 0.3018, Validation Accuracy = 0.0114, Validation Loss = 7.3056\n",
            "Epoch 563/1667\n",
            "Epoch 563: Training Accuracy = 0.9785, Training Loss = 0.3018, Validation Accuracy = 0.0114, Validation Loss = 7.3056\n",
            "Epoch 564/1667\n",
            "Epoch 564: Training Accuracy = 0.9883, Training Loss = 0.1667, Validation Accuracy = 0.0111, Validation Loss = 7.4338\n",
            "Epoch 565/1667\n",
            "Epoch 565: Training Accuracy = 0.9883, Training Loss = 0.1667, Validation Accuracy = 0.0111, Validation Loss = 7.4338\n",
            "Epoch 566/1667\n",
            "Epoch 566: Training Accuracy = 0.9922, Training Loss = 0.1129, Validation Accuracy = 0.0106, Validation Loss = 7.4908\n",
            "Epoch 567/1667\n",
            "Epoch 567: Training Accuracy = 0.9941, Training Loss = 0.0938, Validation Accuracy = 0.0114, Validation Loss = 7.4724\n",
            "Epoch 568/1667\n",
            "Epoch 568: Training Accuracy = 0.9941, Training Loss = 0.0938, Validation Accuracy = 0.0114, Validation Loss = 7.4724\n",
            "Epoch 569/1667\n",
            "Epoch 569: Training Accuracy = 0.9980, Training Loss = 0.0663, Validation Accuracy = 0.0109, Validation Loss = 7.4346\n",
            "Epoch 570/1667\n",
            "Epoch 570: Training Accuracy = 0.9980, Training Loss = 0.0663, Validation Accuracy = 0.0109, Validation Loss = 7.4346\n",
            "Epoch 571/1667\n",
            "Epoch 571: Training Accuracy = 0.9922, Training Loss = 0.0802, Validation Accuracy = 0.0112, Validation Loss = 7.4275\n",
            "Epoch 572/1667\n",
            "Epoch 572: Training Accuracy = 0.9863, Training Loss = 0.1197, Validation Accuracy = 0.0112, Validation Loss = 7.3691\n",
            "Epoch 573/1667\n",
            "Epoch 573: Training Accuracy = 0.9863, Training Loss = 0.1197, Validation Accuracy = 0.0112, Validation Loss = 7.3691\n",
            "Epoch 574/1667\n",
            "Epoch 574: Training Accuracy = 0.9922, Training Loss = 0.0925, Validation Accuracy = 0.0114, Validation Loss = 7.3158\n",
            "Epoch 575/1667\n",
            "Epoch 575: Training Accuracy = 0.9922, Training Loss = 0.0925, Validation Accuracy = 0.0114, Validation Loss = 7.3158\n",
            "Epoch 576/1667\n",
            "Epoch 576: Training Accuracy = 0.9785, Training Loss = 0.1584, Validation Accuracy = 0.0106, Validation Loss = 7.3047\n",
            "Epoch 577/1667\n",
            "Epoch 577: Training Accuracy = 0.7188, Training Loss = 1.2713, Validation Accuracy = 0.0118, Validation Loss = 6.7189\n",
            "Epoch 578/1667\n",
            "Epoch 578: Training Accuracy = 0.7188, Training Loss = 1.2713, Validation Accuracy = 0.0118, Validation Loss = 6.7189\n",
            "Epoch 579/1667\n",
            "Epoch 579: Training Accuracy = 0.9492, Training Loss = 0.5248, Validation Accuracy = 0.0128, Validation Loss = 6.9992\n",
            "Epoch 580/1667\n",
            "Epoch 580: Training Accuracy = 0.9492, Training Loss = 0.5248, Validation Accuracy = 0.0128, Validation Loss = 6.9992\n",
            "Epoch 581/1667\n",
            "Epoch 581: Training Accuracy = 0.9727, Training Loss = 0.3139, Validation Accuracy = 0.0121, Validation Loss = 7.2756\n",
            "Epoch 582/1667\n",
            "Epoch 582: Training Accuracy = 0.9863, Training Loss = 0.2096, Validation Accuracy = 0.0109, Validation Loss = 7.3345\n",
            "Epoch 583/1667\n",
            "Epoch 583: Training Accuracy = 0.9863, Training Loss = 0.2096, Validation Accuracy = 0.0109, Validation Loss = 7.3345\n",
            "Epoch 584/1667\n",
            "Epoch 584: Training Accuracy = 0.9844, Training Loss = 0.1584, Validation Accuracy = 0.0115, Validation Loss = 7.3668\n",
            "Epoch 585/1667\n",
            "Epoch 585: Training Accuracy = 0.9844, Training Loss = 0.1584, Validation Accuracy = 0.0115, Validation Loss = 7.3668\n",
            "Epoch 586/1667\n",
            "Epoch 586: Training Accuracy = 0.9941, Training Loss = 0.0886, Validation Accuracy = 0.0115, Validation Loss = 7.4410\n",
            "Epoch 587/1667\n",
            "Epoch 587: Training Accuracy = 0.9961, Training Loss = 0.0826, Validation Accuracy = 0.0115, Validation Loss = 7.4253\n",
            "Epoch 588/1667\n",
            "Epoch 588: Training Accuracy = 0.9961, Training Loss = 0.0826, Validation Accuracy = 0.0115, Validation Loss = 7.4253\n",
            "Epoch 589/1667\n",
            "Epoch 589: Training Accuracy = 0.9785, Training Loss = 0.1311, Validation Accuracy = 0.0111, Validation Loss = 7.4035\n",
            "Epoch 590/1667\n",
            "Epoch 590: Training Accuracy = 0.9785, Training Loss = 0.1311, Validation Accuracy = 0.0111, Validation Loss = 7.4035\n",
            "Epoch 591/1667\n",
            "Epoch 591: Training Accuracy = 0.9922, Training Loss = 0.0826, Validation Accuracy = 0.0123, Validation Loss = 7.3592\n",
            "Epoch 592/1667\n",
            "Epoch 592: Training Accuracy = 0.9863, Training Loss = 0.1168, Validation Accuracy = 0.0118, Validation Loss = 7.3355\n",
            "Epoch 593/1667\n",
            "Epoch 593: Training Accuracy = 0.9863, Training Loss = 0.1168, Validation Accuracy = 0.0118, Validation Loss = 7.3355\n",
            "Epoch 594/1667\n",
            "Epoch 594: Training Accuracy = 0.9883, Training Loss = 0.1109, Validation Accuracy = 0.0112, Validation Loss = 7.2832\n",
            "Epoch 595/1667\n",
            "Epoch 595: Training Accuracy = 0.9883, Training Loss = 0.1109, Validation Accuracy = 0.0112, Validation Loss = 7.2832\n",
            "Epoch 596/1667\n",
            "Epoch 596: Training Accuracy = 0.9883, Training Loss = 0.1323, Validation Accuracy = 0.0120, Validation Loss = 7.0782\n",
            "Epoch 597/1667\n",
            "Epoch 597: Training Accuracy = 0.7852, Training Loss = 1.0837, Validation Accuracy = 0.0115, Validation Loss = 6.8603\n",
            "Epoch 598/1667\n",
            "Epoch 598: Training Accuracy = 0.7852, Training Loss = 1.0837, Validation Accuracy = 0.0115, Validation Loss = 6.8603\n",
            "Epoch 599/1667\n",
            "Epoch 599: Training Accuracy = 0.9551, Training Loss = 0.5095, Validation Accuracy = 0.0109, Validation Loss = 7.0129\n",
            "Epoch 600/1667\n",
            "Epoch 600: Training Accuracy = 0.9551, Training Loss = 0.5095, Validation Accuracy = 0.0109, Validation Loss = 7.0129\n",
            "Epoch 601/1667\n",
            "Epoch 601: Training Accuracy = 0.9844, Training Loss = 0.2573, Validation Accuracy = 0.0105, Validation Loss = 7.1854\n",
            "Epoch 602/1667\n",
            "Epoch 602: Training Accuracy = 0.9922, Training Loss = 0.1577, Validation Accuracy = 0.0112, Validation Loss = 7.3497\n",
            "Epoch 603/1667\n",
            "Epoch 603: Training Accuracy = 0.9922, Training Loss = 0.1577, Validation Accuracy = 0.0112, Validation Loss = 7.3497\n",
            "Epoch 604/1667\n",
            "Epoch 604: Training Accuracy = 0.9902, Training Loss = 0.1184, Validation Accuracy = 0.0115, Validation Loss = 7.3483\n",
            "Epoch 605/1667\n",
            "Epoch 605: Training Accuracy = 0.9902, Training Loss = 0.1184, Validation Accuracy = 0.0115, Validation Loss = 7.3483\n",
            "Epoch 606/1667\n",
            "Epoch 606: Training Accuracy = 0.9863, Training Loss = 0.1133, Validation Accuracy = 0.0111, Validation Loss = 7.3928\n",
            "Epoch 607/1667\n",
            "Epoch 607: Training Accuracy = 0.9805, Training Loss = 0.1359, Validation Accuracy = 0.0109, Validation Loss = 7.3608\n",
            "Epoch 608/1667\n",
            "Epoch 608: Training Accuracy = 0.9805, Training Loss = 0.1359, Validation Accuracy = 0.0109, Validation Loss = 7.3608\n",
            "Epoch 609/1667\n",
            "Epoch 609: Training Accuracy = 0.9922, Training Loss = 0.0826, Validation Accuracy = 0.0114, Validation Loss = 7.3495\n",
            "Epoch 610/1667\n",
            "Epoch 610: Training Accuracy = 0.9922, Training Loss = 0.0826, Validation Accuracy = 0.0114, Validation Loss = 7.3495\n",
            "Epoch 611/1667\n",
            "Epoch 611: Training Accuracy = 0.9883, Training Loss = 0.0930, Validation Accuracy = 0.0115, Validation Loss = 7.3064\n",
            "Epoch 612/1667\n",
            "Epoch 612: Training Accuracy = 0.9863, Training Loss = 0.1113, Validation Accuracy = 0.0115, Validation Loss = 7.2849\n",
            "Epoch 613/1667\n",
            "Epoch 613: Training Accuracy = 0.9863, Training Loss = 0.1113, Validation Accuracy = 0.0115, Validation Loss = 7.2849\n",
            "Epoch 614/1667\n",
            "Epoch 614: Training Accuracy = 0.9863, Training Loss = 0.1172, Validation Accuracy = 0.0115, Validation Loss = 7.2200\n",
            "Epoch 615/1667\n",
            "Epoch 615: Training Accuracy = 0.9863, Training Loss = 0.1172, Validation Accuracy = 0.0115, Validation Loss = 7.2200\n",
            "Epoch 616/1667\n",
            "Epoch 616: Training Accuracy = 0.8164, Training Loss = 0.9833, Validation Accuracy = 0.0111, Validation Loss = 6.8012\n",
            "Epoch 617/1667\n",
            "Epoch 617: Training Accuracy = 0.9414, Training Loss = 0.5745, Validation Accuracy = 0.0120, Validation Loss = 7.0057\n",
            "Epoch 618/1667\n",
            "Epoch 618: Training Accuracy = 0.9414, Training Loss = 0.5745, Validation Accuracy = 0.0120, Validation Loss = 7.0057\n",
            "Epoch 619/1667\n",
            "Epoch 619: Training Accuracy = 0.9707, Training Loss = 0.3170, Validation Accuracy = 0.0115, Validation Loss = 7.1046\n",
            "Epoch 620/1667\n",
            "Epoch 620: Training Accuracy = 0.9707, Training Loss = 0.3170, Validation Accuracy = 0.0115, Validation Loss = 7.1046\n",
            "Epoch 621/1667\n",
            "Epoch 621: Training Accuracy = 0.9785, Training Loss = 0.2131, Validation Accuracy = 0.0121, Validation Loss = 7.2203\n",
            "Epoch 622/1667\n",
            "Epoch 622: Training Accuracy = 0.9863, Training Loss = 0.1644, Validation Accuracy = 0.0118, Validation Loss = 7.2369\n",
            "Epoch 623/1667\n",
            "Epoch 623: Training Accuracy = 0.9863, Training Loss = 0.1644, Validation Accuracy = 0.0118, Validation Loss = 7.2369\n",
            "Epoch 624/1667\n",
            "Epoch 624: Training Accuracy = 0.9844, Training Loss = 0.1377, Validation Accuracy = 0.0120, Validation Loss = 7.3092\n",
            "Epoch 625/1667\n",
            "Epoch 625: Training Accuracy = 0.9844, Training Loss = 0.1377, Validation Accuracy = 0.0120, Validation Loss = 7.3092\n",
            "Epoch 626/1667\n",
            "Epoch 626: Training Accuracy = 0.9844, Training Loss = 0.1147, Validation Accuracy = 0.0114, Validation Loss = 7.2937\n",
            "Epoch 627/1667\n",
            "Epoch 627: Training Accuracy = 0.9922, Training Loss = 0.0931, Validation Accuracy = 0.0121, Validation Loss = 7.2837\n",
            "Epoch 628/1667\n",
            "Epoch 628: Training Accuracy = 0.9922, Training Loss = 0.0931, Validation Accuracy = 0.0121, Validation Loss = 7.2837\n",
            "Epoch 629/1667\n",
            "Epoch 629: Training Accuracy = 0.9902, Training Loss = 0.0903, Validation Accuracy = 0.0120, Validation Loss = 7.2378\n",
            "Epoch 630/1667\n",
            "Epoch 630: Training Accuracy = 0.9902, Training Loss = 0.0903, Validation Accuracy = 0.0120, Validation Loss = 7.2378\n",
            "Epoch 631/1667\n",
            "Epoch 631: Training Accuracy = 0.9941, Training Loss = 0.0762, Validation Accuracy = 0.0117, Validation Loss = 7.2341\n",
            "Epoch 632/1667\n",
            "Epoch 632: Training Accuracy = 0.9883, Training Loss = 0.1099, Validation Accuracy = 0.0117, Validation Loss = 7.1733\n",
            "Epoch 633/1667\n",
            "Epoch 633: Training Accuracy = 0.9883, Training Loss = 0.1099, Validation Accuracy = 0.0117, Validation Loss = 7.1733\n",
            "Epoch 634/1667\n",
            "Epoch 634: Training Accuracy = 0.9883, Training Loss = 0.1472, Validation Accuracy = 0.0120, Validation Loss = 7.0282\n",
            "Epoch 635/1667\n",
            "Epoch 635: Training Accuracy = 0.9883, Training Loss = 0.1472, Validation Accuracy = 0.0120, Validation Loss = 7.0282\n",
            "Epoch 636/1667\n",
            "Epoch 636: Training Accuracy = 0.9375, Training Loss = 0.5534, Validation Accuracy = 0.0128, Validation Loss = 6.8104\n",
            "Epoch 637/1667\n",
            "Epoch 637: Training Accuracy = 0.9316, Training Loss = 0.5586, Validation Accuracy = 0.0114, Validation Loss = 6.8645\n",
            "Epoch 638/1667\n",
            "Epoch 638: Training Accuracy = 0.9316, Training Loss = 0.5586, Validation Accuracy = 0.0114, Validation Loss = 6.8645\n",
            "Epoch 639/1667\n",
            "Epoch 639: Training Accuracy = 0.9688, Training Loss = 0.3199, Validation Accuracy = 0.0120, Validation Loss = 7.0802\n",
            "Epoch 640/1667\n",
            "Epoch 640: Training Accuracy = 0.9688, Training Loss = 0.3199, Validation Accuracy = 0.0120, Validation Loss = 7.0802\n",
            "Epoch 641/1667\n",
            "Epoch 641: Training Accuracy = 0.9961, Training Loss = 0.1339, Validation Accuracy = 0.0126, Validation Loss = 7.1701\n",
            "Epoch 642/1667\n",
            "Epoch 642: Training Accuracy = 0.9844, Training Loss = 0.1560, Validation Accuracy = 0.0112, Validation Loss = 7.2114\n",
            "Epoch 643/1667\n",
            "Epoch 643: Training Accuracy = 0.9844, Training Loss = 0.1560, Validation Accuracy = 0.0112, Validation Loss = 7.2114\n",
            "Epoch 644/1667\n",
            "Epoch 644: Training Accuracy = 0.9883, Training Loss = 0.1216, Validation Accuracy = 0.0120, Validation Loss = 7.2595\n",
            "Epoch 645/1667\n",
            "Epoch 645: Training Accuracy = 0.9883, Training Loss = 0.1216, Validation Accuracy = 0.0120, Validation Loss = 7.2595\n",
            "Epoch 646/1667\n",
            "Epoch 646: Training Accuracy = 0.9902, Training Loss = 0.0889, Validation Accuracy = 0.0123, Validation Loss = 7.2571\n",
            "Epoch 647/1667\n",
            "Epoch 647: Training Accuracy = 0.9883, Training Loss = 0.1031, Validation Accuracy = 0.0112, Validation Loss = 7.2260\n",
            "Epoch 648/1667\n",
            "Epoch 648: Training Accuracy = 0.9883, Training Loss = 0.1031, Validation Accuracy = 0.0112, Validation Loss = 7.2260\n",
            "Epoch 649/1667\n",
            "Epoch 649: Training Accuracy = 0.9902, Training Loss = 0.0884, Validation Accuracy = 0.0123, Validation Loss = 7.2057\n",
            "Epoch 650/1667\n",
            "Epoch 650: Training Accuracy = 0.9902, Training Loss = 0.0884, Validation Accuracy = 0.0123, Validation Loss = 7.2057\n",
            "Epoch 651/1667\n",
            "Epoch 651: Training Accuracy = 0.9844, Training Loss = 0.1092, Validation Accuracy = 0.0115, Validation Loss = 7.1905\n",
            "Epoch 652/1667\n",
            "Epoch 652: Training Accuracy = 0.9883, Training Loss = 0.1114, Validation Accuracy = 0.0124, Validation Loss = 7.1397\n",
            "Epoch 653/1667\n",
            "Epoch 653: Training Accuracy = 0.9883, Training Loss = 0.1114, Validation Accuracy = 0.0124, Validation Loss = 7.1397\n",
            "Epoch 654/1667\n",
            "Epoch 654: Training Accuracy = 0.9883, Training Loss = 0.1305, Validation Accuracy = 0.0124, Validation Loss = 7.0628\n",
            "Epoch 655/1667\n",
            "Epoch 655: Training Accuracy = 0.9883, Training Loss = 0.1305, Validation Accuracy = 0.0124, Validation Loss = 7.0628\n",
            "Epoch 656/1667\n",
            "Epoch 656: Training Accuracy = 0.9004, Training Loss = 0.6521, Validation Accuracy = 0.0126, Validation Loss = 6.6956\n",
            "Epoch 657/1667\n",
            "Epoch 657: Training Accuracy = 0.9492, Training Loss = 0.4463, Validation Accuracy = 0.0124, Validation Loss = 6.9447\n",
            "Epoch 658/1667\n",
            "Epoch 658: Training Accuracy = 0.9492, Training Loss = 0.4463, Validation Accuracy = 0.0124, Validation Loss = 6.9447\n",
            "Epoch 659/1667\n",
            "Epoch 659: Training Accuracy = 0.9785, Training Loss = 0.2746, Validation Accuracy = 0.0117, Validation Loss = 7.1165\n",
            "Epoch 660/1667\n",
            "Epoch 660: Training Accuracy = 0.9785, Training Loss = 0.2746, Validation Accuracy = 0.0117, Validation Loss = 7.1165\n",
            "Epoch 661/1667\n",
            "Epoch 661: Training Accuracy = 0.9941, Training Loss = 0.1414, Validation Accuracy = 0.0117, Validation Loss = 7.1373\n",
            "Epoch 662/1667\n",
            "Epoch 662: Training Accuracy = 0.9844, Training Loss = 0.1496, Validation Accuracy = 0.0111, Validation Loss = 7.2453\n",
            "Epoch 663/1667\n",
            "Epoch 663: Training Accuracy = 0.9844, Training Loss = 0.1496, Validation Accuracy = 0.0111, Validation Loss = 7.2453\n",
            "Epoch 664/1667\n",
            "Epoch 664: Training Accuracy = 0.9844, Training Loss = 0.1154, Validation Accuracy = 0.0112, Validation Loss = 7.2498\n",
            "Epoch 665/1667\n",
            "Epoch 665: Training Accuracy = 0.9844, Training Loss = 0.1154, Validation Accuracy = 0.0112, Validation Loss = 7.2498\n",
            "Epoch 666/1667\n",
            "Epoch 666: Training Accuracy = 0.9844, Training Loss = 0.1102, Validation Accuracy = 0.0123, Validation Loss = 7.2240\n",
            "Epoch 667/1667\n",
            "Epoch 667: Training Accuracy = 0.9941, Training Loss = 0.0758, Validation Accuracy = 0.0118, Validation Loss = 7.1990\n",
            "Epoch 668/1667\n",
            "Epoch 668: Training Accuracy = 0.9941, Training Loss = 0.0758, Validation Accuracy = 0.0118, Validation Loss = 7.1990\n",
            "Epoch 669/1667\n",
            "Epoch 669: Training Accuracy = 0.9883, Training Loss = 0.0897, Validation Accuracy = 0.0115, Validation Loss = 7.1598\n",
            "Epoch 670/1667\n",
            "Epoch 670: Training Accuracy = 0.9883, Training Loss = 0.0897, Validation Accuracy = 0.0115, Validation Loss = 7.1598\n",
            "Epoch 671/1667\n",
            "Epoch 671: Training Accuracy = 0.9844, Training Loss = 0.1036, Validation Accuracy = 0.0126, Validation Loss = 7.1229\n",
            "Epoch 672/1667\n",
            "Epoch 672: Training Accuracy = 0.9844, Training Loss = 0.1307, Validation Accuracy = 0.0123, Validation Loss = 7.0627\n",
            "Epoch 673/1667\n",
            "Epoch 673: Training Accuracy = 0.9844, Training Loss = 0.1307, Validation Accuracy = 0.0123, Validation Loss = 7.0627\n",
            "Epoch 674/1667\n",
            "Epoch 674: Training Accuracy = 0.9883, Training Loss = 0.1105, Validation Accuracy = 0.0121, Validation Loss = 7.0578\n",
            "Epoch 675/1667\n",
            "Epoch 675: Training Accuracy = 0.9883, Training Loss = 0.1105, Validation Accuracy = 0.0121, Validation Loss = 7.0578\n",
            "Epoch 676/1667\n",
            "Epoch 676: Training Accuracy = 0.8926, Training Loss = 0.9153, Validation Accuracy = 0.0131, Validation Loss = 6.5186\n",
            "Epoch 677/1667\n",
            "Epoch 677: Training Accuracy = 0.9180, Training Loss = 0.6177, Validation Accuracy = 0.0121, Validation Loss = 6.7935\n",
            "Epoch 678/1667\n",
            "Epoch 678: Training Accuracy = 0.9180, Training Loss = 0.6177, Validation Accuracy = 0.0121, Validation Loss = 6.7935\n",
            "Epoch 679/1667\n",
            "Epoch 679: Training Accuracy = 0.9844, Training Loss = 0.3094, Validation Accuracy = 0.0118, Validation Loss = 6.9091\n",
            "Epoch 680/1667\n",
            "Epoch 680: Training Accuracy = 0.9844, Training Loss = 0.3094, Validation Accuracy = 0.0118, Validation Loss = 6.9091\n",
            "Epoch 681/1667\n",
            "Epoch 681: Training Accuracy = 0.9766, Training Loss = 0.2267, Validation Accuracy = 0.0124, Validation Loss = 7.0920\n",
            "Epoch 682/1667\n",
            "Epoch 682: Training Accuracy = 0.9902, Training Loss = 0.1315, Validation Accuracy = 0.0115, Validation Loss = 7.1026\n",
            "Epoch 683/1667\n",
            "Epoch 683: Training Accuracy = 0.9902, Training Loss = 0.1315, Validation Accuracy = 0.0115, Validation Loss = 7.1026\n",
            "Epoch 684/1667\n",
            "Epoch 684: Training Accuracy = 0.9902, Training Loss = 0.1032, Validation Accuracy = 0.0120, Validation Loss = 7.1356\n",
            "Epoch 685/1667\n",
            "Epoch 685: Training Accuracy = 0.9902, Training Loss = 0.1032, Validation Accuracy = 0.0120, Validation Loss = 7.1356\n",
            "Epoch 686/1667\n",
            "Epoch 686: Training Accuracy = 0.9922, Training Loss = 0.0783, Validation Accuracy = 0.0121, Validation Loss = 7.1337\n",
            "Epoch 687/1667\n",
            "Epoch 687: Training Accuracy = 0.9805, Training Loss = 0.1302, Validation Accuracy = 0.0129, Validation Loss = 7.1215\n",
            "Epoch 688/1667\n",
            "Epoch 688: Training Accuracy = 0.9805, Training Loss = 0.1302, Validation Accuracy = 0.0129, Validation Loss = 7.1215\n",
            "Epoch 689/1667\n",
            "Epoch 689: Training Accuracy = 0.9883, Training Loss = 0.0968, Validation Accuracy = 0.0128, Validation Loss = 7.0768\n",
            "Epoch 690/1667\n",
            "Epoch 690: Training Accuracy = 0.9883, Training Loss = 0.0968, Validation Accuracy = 0.0128, Validation Loss = 7.0768\n",
            "Epoch 691/1667\n",
            "Epoch 691: Training Accuracy = 0.9883, Training Loss = 0.0904, Validation Accuracy = 0.0124, Validation Loss = 7.0399\n",
            "Epoch 692/1667\n",
            "Epoch 692: Training Accuracy = 0.9863, Training Loss = 0.1124, Validation Accuracy = 0.0126, Validation Loss = 7.0194\n",
            "Epoch 693/1667\n",
            "Epoch 693: Training Accuracy = 0.9863, Training Loss = 0.1124, Validation Accuracy = 0.0126, Validation Loss = 7.0194\n",
            "Epoch 694/1667\n",
            "Epoch 694: Training Accuracy = 0.4238, Training Loss = 2.3901, Validation Accuracy = 0.0165, Validation Loss = 5.8094\n",
            "Epoch 695/1667\n",
            "Epoch 695: Training Accuracy = 0.4238, Training Loss = 2.3901, Validation Accuracy = 0.0165, Validation Loss = 5.8094\n",
            "Epoch 696/1667\n",
            "Epoch 696: Training Accuracy = 0.9258, Training Loss = 0.6563, Validation Accuracy = 0.0126, Validation Loss = 6.6406\n",
            "Epoch 697/1667\n",
            "Epoch 697: Training Accuracy = 0.9707, Training Loss = 0.4016, Validation Accuracy = 0.0132, Validation Loss = 6.7658\n",
            "Epoch 698/1667\n",
            "Epoch 698: Training Accuracy = 0.9707, Training Loss = 0.4016, Validation Accuracy = 0.0132, Validation Loss = 6.7658\n",
            "Epoch 699/1667\n",
            "Epoch 699: Training Accuracy = 0.9785, Training Loss = 0.2327, Validation Accuracy = 0.0129, Validation Loss = 6.9570\n",
            "Epoch 700/1667\n",
            "Epoch 700: Training Accuracy = 0.9785, Training Loss = 0.2327, Validation Accuracy = 0.0129, Validation Loss = 6.9570\n",
            "Epoch 701/1667\n",
            "Epoch 701: Training Accuracy = 0.9902, Training Loss = 0.1336, Validation Accuracy = 0.0128, Validation Loss = 6.9880\n",
            "Epoch 702/1667\n",
            "Epoch 702: Training Accuracy = 0.9805, Training Loss = 0.1606, Validation Accuracy = 0.0123, Validation Loss = 7.0188\n",
            "Epoch 703/1667\n",
            "Epoch 703: Training Accuracy = 0.9805, Training Loss = 0.1606, Validation Accuracy = 0.0123, Validation Loss = 7.0188\n",
            "Epoch 704/1667\n",
            "Epoch 704: Training Accuracy = 0.9902, Training Loss = 0.1019, Validation Accuracy = 0.0124, Validation Loss = 7.0268\n",
            "Epoch 705/1667\n",
            "Epoch 705: Training Accuracy = 0.9902, Training Loss = 0.1019, Validation Accuracy = 0.0124, Validation Loss = 7.0268\n",
            "Epoch 706/1667\n",
            "Epoch 706: Training Accuracy = 0.9766, Training Loss = 0.1390, Validation Accuracy = 0.0132, Validation Loss = 6.9691\n",
            "Epoch 707/1667\n",
            "Epoch 707: Training Accuracy = 0.9844, Training Loss = 0.1182, Validation Accuracy = 0.0123, Validation Loss = 6.9507\n",
            "Epoch 708/1667\n",
            "Epoch 708: Training Accuracy = 0.9844, Training Loss = 0.1182, Validation Accuracy = 0.0123, Validation Loss = 6.9507\n",
            "Epoch 709/1667\n",
            "Epoch 709: Training Accuracy = 0.9883, Training Loss = 0.0945, Validation Accuracy = 0.0120, Validation Loss = 6.9361\n",
            "Epoch 710/1667\n",
            "Epoch 710: Training Accuracy = 0.9883, Training Loss = 0.0945, Validation Accuracy = 0.0120, Validation Loss = 6.9361\n",
            "Epoch 711/1667\n",
            "Epoch 711: Training Accuracy = 0.9805, Training Loss = 0.1242, Validation Accuracy = 0.0131, Validation Loss = 6.9108\n",
            "Epoch 712/1667\n",
            "Epoch 712: Training Accuracy = 0.9883, Training Loss = 0.1163, Validation Accuracy = 0.0143, Validation Loss = 6.8589\n",
            "Epoch 713/1667\n",
            "Epoch 713: Training Accuracy = 0.9883, Training Loss = 0.1163, Validation Accuracy = 0.0143, Validation Loss = 6.8589\n",
            "Epoch 714/1667\n",
            "Epoch 714: Training Accuracy = 0.9844, Training Loss = 0.1778, Validation Accuracy = 0.0140, Validation Loss = 6.4691\n",
            "Epoch 715/1667\n",
            "Epoch 715: Training Accuracy = 0.9844, Training Loss = 0.1778, Validation Accuracy = 0.0140, Validation Loss = 6.4691\n",
            "Epoch 716/1667\n",
            "Epoch 716: Training Accuracy = 0.9023, Training Loss = 0.6798, Validation Accuracy = 0.0135, Validation Loss = 6.5471\n",
            "Epoch 717/1667\n",
            "Epoch 717: Training Accuracy = 0.9453, Training Loss = 0.4860, Validation Accuracy = 0.0121, Validation Loss = 6.6795\n",
            "Epoch 718/1667\n",
            "Epoch 718: Training Accuracy = 0.9453, Training Loss = 0.4860, Validation Accuracy = 0.0121, Validation Loss = 6.6795\n",
            "Epoch 719/1667\n",
            "Epoch 719: Training Accuracy = 0.9883, Training Loss = 0.2346, Validation Accuracy = 0.0129, Validation Loss = 6.8151\n",
            "Epoch 720/1667\n",
            "Epoch 720: Training Accuracy = 0.9883, Training Loss = 0.2346, Validation Accuracy = 0.0129, Validation Loss = 6.8151\n",
            "Epoch 721/1667\n",
            "Epoch 721: Training Accuracy = 0.9805, Training Loss = 0.1800, Validation Accuracy = 0.0132, Validation Loss = 6.8869\n",
            "Epoch 722/1667\n",
            "Epoch 722: Training Accuracy = 0.9824, Training Loss = 0.1511, Validation Accuracy = 0.0120, Validation Loss = 6.9214\n",
            "Epoch 723/1667\n",
            "Epoch 723: Training Accuracy = 0.9824, Training Loss = 0.1511, Validation Accuracy = 0.0120, Validation Loss = 6.9214\n",
            "Epoch 724/1667\n",
            "Epoch 724: Training Accuracy = 0.9766, Training Loss = 0.1570, Validation Accuracy = 0.0131, Validation Loss = 6.9415\n",
            "Epoch 725/1667\n",
            "Epoch 725: Training Accuracy = 0.9766, Training Loss = 0.1570, Validation Accuracy = 0.0131, Validation Loss = 6.9415\n",
            "Epoch 726/1667\n",
            "Epoch 726: Training Accuracy = 0.9922, Training Loss = 0.0767, Validation Accuracy = 0.0118, Validation Loss = 6.9286\n",
            "Epoch 727/1667\n",
            "Epoch 727: Training Accuracy = 0.9844, Training Loss = 0.1110, Validation Accuracy = 0.0129, Validation Loss = 6.9016\n",
            "Epoch 728/1667\n",
            "Epoch 728: Training Accuracy = 0.9844, Training Loss = 0.1110, Validation Accuracy = 0.0129, Validation Loss = 6.9016\n",
            "Epoch 729/1667\n",
            "Epoch 729: Training Accuracy = 0.9863, Training Loss = 0.1016, Validation Accuracy = 0.0131, Validation Loss = 6.8582\n",
            "Epoch 730/1667\n",
            "Epoch 730: Training Accuracy = 0.9863, Training Loss = 0.1016, Validation Accuracy = 0.0131, Validation Loss = 6.8582\n",
            "Epoch 731/1667\n",
            "Epoch 731: Training Accuracy = 0.9863, Training Loss = 0.1023, Validation Accuracy = 0.0132, Validation Loss = 6.8224\n",
            "Epoch 732/1667\n",
            "Epoch 732: Training Accuracy = 0.9883, Training Loss = 0.1110, Validation Accuracy = 0.0124, Validation Loss = 6.7902\n",
            "Epoch 733/1667\n",
            "Epoch 733: Training Accuracy = 0.9883, Training Loss = 0.1110, Validation Accuracy = 0.0124, Validation Loss = 6.7902\n",
            "Epoch 734/1667\n",
            "Epoch 734: Training Accuracy = 0.5762, Training Loss = 1.9190, Validation Accuracy = 0.0149, Validation Loss = 6.1387\n",
            "Epoch 735/1667\n",
            "Epoch 735: Training Accuracy = 0.5762, Training Loss = 1.9190, Validation Accuracy = 0.0149, Validation Loss = 6.1387\n",
            "Epoch 736/1667\n",
            "Epoch 736: Training Accuracy = 0.9492, Training Loss = 0.5408, Validation Accuracy = 0.0132, Validation Loss = 6.5045\n",
            "Epoch 737/1667\n",
            "Epoch 737: Training Accuracy = 0.9648, Training Loss = 0.3922, Validation Accuracy = 0.0147, Validation Loss = 6.6642\n",
            "Epoch 738/1667\n",
            "Epoch 738: Training Accuracy = 0.9648, Training Loss = 0.3922, Validation Accuracy = 0.0147, Validation Loss = 6.6642\n",
            "Epoch 739/1667\n",
            "Epoch 739: Training Accuracy = 0.9863, Training Loss = 0.2371, Validation Accuracy = 0.0131, Validation Loss = 6.7776\n",
            "Epoch 740/1667\n",
            "Epoch 740: Training Accuracy = 0.9863, Training Loss = 0.2371, Validation Accuracy = 0.0131, Validation Loss = 6.7776\n",
            "Epoch 741/1667\n",
            "Epoch 741: Training Accuracy = 0.9961, Training Loss = 0.1137, Validation Accuracy = 0.0121, Validation Loss = 6.8223\n",
            "Epoch 742/1667\n",
            "Epoch 742: Training Accuracy = 0.9863, Training Loss = 0.1447, Validation Accuracy = 0.0134, Validation Loss = 6.8618\n",
            "Epoch 743/1667\n",
            "Epoch 743: Training Accuracy = 0.9863, Training Loss = 0.1447, Validation Accuracy = 0.0134, Validation Loss = 6.8618\n",
            "Epoch 744/1667\n",
            "Epoch 744: Training Accuracy = 0.9883, Training Loss = 0.1087, Validation Accuracy = 0.0135, Validation Loss = 6.8349\n",
            "Epoch 745/1667\n",
            "Epoch 745: Training Accuracy = 0.9883, Training Loss = 0.1087, Validation Accuracy = 0.0135, Validation Loss = 6.8349\n",
            "Epoch 746/1667\n",
            "Epoch 746: Training Accuracy = 0.9824, Training Loss = 0.1130, Validation Accuracy = 0.0132, Validation Loss = 6.8542\n",
            "Epoch 747/1667\n",
            "Epoch 747: Training Accuracy = 0.9863, Training Loss = 0.1123, Validation Accuracy = 0.0129, Validation Loss = 6.8371\n",
            "Epoch 748/1667\n",
            "Epoch 748: Training Accuracy = 0.9863, Training Loss = 0.1123, Validation Accuracy = 0.0129, Validation Loss = 6.8371\n",
            "Epoch 749/1667\n",
            "Epoch 749: Training Accuracy = 0.9844, Training Loss = 0.1059, Validation Accuracy = 0.0131, Validation Loss = 6.8007\n",
            "Epoch 750/1667\n",
            "Epoch 750: Training Accuracy = 0.9844, Training Loss = 0.1059, Validation Accuracy = 0.0131, Validation Loss = 6.8007\n",
            "Epoch 751/1667\n",
            "Epoch 751: Training Accuracy = 0.9941, Training Loss = 0.0718, Validation Accuracy = 0.0134, Validation Loss = 6.7759\n",
            "Epoch 752/1667\n",
            "Epoch 752: Training Accuracy = 0.9844, Training Loss = 0.1366, Validation Accuracy = 0.0146, Validation Loss = 6.7286\n",
            "Epoch 753/1667\n",
            "Epoch 753: Training Accuracy = 0.9844, Training Loss = 0.1366, Validation Accuracy = 0.0146, Validation Loss = 6.7286\n",
            "Epoch 754/1667\n",
            "Epoch 754: Training Accuracy = 0.9844, Training Loss = 0.1658, Validation Accuracy = 0.0131, Validation Loss = 6.6929\n",
            "Epoch 755/1667\n",
            "Epoch 755: Training Accuracy = 0.9844, Training Loss = 0.1658, Validation Accuracy = 0.0131, Validation Loss = 6.6929\n",
            "Epoch 756/1667\n",
            "Epoch 756: Training Accuracy = 0.8984, Training Loss = 0.7379, Validation Accuracy = 0.0153, Validation Loss = 6.5000\n",
            "Epoch 757/1667\n",
            "Epoch 757: Training Accuracy = 0.9375, Training Loss = 0.5090, Validation Accuracy = 0.0140, Validation Loss = 6.4586\n",
            "Epoch 758/1667\n",
            "Epoch 758: Training Accuracy = 0.9375, Training Loss = 0.5090, Validation Accuracy = 0.0140, Validation Loss = 6.4586\n",
            "Epoch 759/1667\n",
            "Epoch 759: Training Accuracy = 0.9824, Training Loss = 0.2611, Validation Accuracy = 0.0143, Validation Loss = 6.5822\n",
            "Epoch 760/1667\n",
            "Epoch 760: Training Accuracy = 0.9824, Training Loss = 0.2611, Validation Accuracy = 0.0143, Validation Loss = 6.5822\n",
            "Epoch 761/1667\n",
            "Epoch 761: Training Accuracy = 0.9844, Training Loss = 0.1615, Validation Accuracy = 0.0146, Validation Loss = 6.7111\n",
            "Epoch 762/1667\n",
            "Epoch 762: Training Accuracy = 0.9863, Training Loss = 0.1438, Validation Accuracy = 0.0138, Validation Loss = 6.7508\n",
            "Epoch 763/1667\n",
            "Epoch 763: Training Accuracy = 0.9863, Training Loss = 0.1438, Validation Accuracy = 0.0138, Validation Loss = 6.7508\n",
            "Epoch 764/1667\n",
            "Epoch 764: Training Accuracy = 0.9883, Training Loss = 0.1083, Validation Accuracy = 0.0135, Validation Loss = 6.7504\n",
            "Epoch 765/1667\n",
            "Epoch 765: Training Accuracy = 0.9883, Training Loss = 0.1083, Validation Accuracy = 0.0135, Validation Loss = 6.7504\n",
            "Epoch 766/1667\n",
            "Epoch 766: Training Accuracy = 0.9922, Training Loss = 0.0776, Validation Accuracy = 0.0140, Validation Loss = 6.7593\n",
            "Epoch 767/1667\n",
            "Epoch 767: Training Accuracy = 0.9902, Training Loss = 0.0864, Validation Accuracy = 0.0150, Validation Loss = 6.7479\n",
            "Epoch 768/1667\n",
            "Epoch 768: Training Accuracy = 0.9902, Training Loss = 0.0864, Validation Accuracy = 0.0150, Validation Loss = 6.7479\n",
            "Epoch 769/1667\n",
            "Epoch 769: Training Accuracy = 0.9941, Training Loss = 0.0682, Validation Accuracy = 0.0149, Validation Loss = 6.7259\n",
            "Epoch 770/1667\n",
            "Epoch 770: Training Accuracy = 0.9941, Training Loss = 0.0682, Validation Accuracy = 0.0149, Validation Loss = 6.7259\n",
            "Epoch 771/1667\n",
            "Epoch 771: Training Accuracy = 0.9844, Training Loss = 0.1028, Validation Accuracy = 0.0138, Validation Loss = 6.6855\n",
            "Epoch 772/1667\n",
            "Epoch 772: Training Accuracy = 0.9805, Training Loss = 0.1339, Validation Accuracy = 0.0147, Validation Loss = 6.6545\n",
            "Epoch 773/1667\n",
            "Epoch 773: Training Accuracy = 0.9805, Training Loss = 0.1339, Validation Accuracy = 0.0147, Validation Loss = 6.6545\n",
            "Epoch 774/1667\n",
            "Epoch 774: Training Accuracy = 0.9922, Training Loss = 0.0942, Validation Accuracy = 0.0140, Validation Loss = 6.6279\n",
            "Epoch 775/1667\n",
            "Epoch 775: Training Accuracy = 0.9922, Training Loss = 0.0942, Validation Accuracy = 0.0140, Validation Loss = 6.6279\n",
            "Epoch 776/1667\n",
            "Epoch 776: Training Accuracy = 0.8672, Training Loss = 0.9697, Validation Accuracy = 0.0152, Validation Loss = 6.3816\n",
            "Epoch 777/1667\n",
            "Epoch 777: Training Accuracy = 0.9355, Training Loss = 0.5607, Validation Accuracy = 0.0149, Validation Loss = 6.3355\n",
            "Epoch 778/1667\n",
            "Epoch 778: Training Accuracy = 0.9355, Training Loss = 0.5607, Validation Accuracy = 0.0149, Validation Loss = 6.3355\n",
            "Epoch 779/1667\n",
            "Epoch 779: Training Accuracy = 0.9805, Training Loss = 0.2983, Validation Accuracy = 0.0149, Validation Loss = 6.5226\n",
            "Epoch 780/1667\n",
            "Epoch 780: Training Accuracy = 0.9805, Training Loss = 0.2983, Validation Accuracy = 0.0149, Validation Loss = 6.5226\n",
            "Epoch 781/1667\n",
            "Epoch 781: Training Accuracy = 0.9863, Training Loss = 0.1809, Validation Accuracy = 0.0147, Validation Loss = 6.5580\n",
            "Epoch 782/1667\n",
            "Epoch 782: Training Accuracy = 0.9883, Training Loss = 0.1516, Validation Accuracy = 0.0137, Validation Loss = 6.6660\n",
            "Epoch 783/1667\n",
            "Epoch 783: Training Accuracy = 0.9883, Training Loss = 0.1516, Validation Accuracy = 0.0137, Validation Loss = 6.6660\n",
            "Epoch 784/1667\n",
            "Epoch 784: Training Accuracy = 0.9844, Training Loss = 0.1242, Validation Accuracy = 0.0137, Validation Loss = 6.6784\n",
            "Epoch 785/1667\n",
            "Epoch 785: Training Accuracy = 0.9844, Training Loss = 0.1242, Validation Accuracy = 0.0137, Validation Loss = 6.6784\n",
            "Epoch 786/1667\n",
            "Epoch 786: Training Accuracy = 0.9824, Training Loss = 0.1150, Validation Accuracy = 0.0155, Validation Loss = 6.6830\n",
            "Epoch 787/1667\n",
            "Epoch 787: Training Accuracy = 0.9844, Training Loss = 0.1082, Validation Accuracy = 0.0137, Validation Loss = 6.6751\n",
            "Epoch 788/1667\n",
            "Epoch 788: Training Accuracy = 0.9844, Training Loss = 0.1082, Validation Accuracy = 0.0137, Validation Loss = 6.6751\n",
            "Epoch 789/1667\n",
            "Epoch 789: Training Accuracy = 0.9922, Training Loss = 0.0729, Validation Accuracy = 0.0143, Validation Loss = 6.6551\n",
            "Epoch 790/1667\n",
            "Epoch 790: Training Accuracy = 0.9922, Training Loss = 0.0729, Validation Accuracy = 0.0143, Validation Loss = 6.6551\n",
            "Epoch 791/1667\n",
            "Epoch 791: Training Accuracy = 0.9941, Training Loss = 0.0647, Validation Accuracy = 0.0138, Validation Loss = 6.6125\n",
            "Epoch 792/1667\n",
            "Epoch 792: Training Accuracy = 0.9785, Training Loss = 0.1322, Validation Accuracy = 0.0155, Validation Loss = 6.6035\n",
            "Epoch 793/1667\n",
            "Epoch 793: Training Accuracy = 0.9785, Training Loss = 0.1322, Validation Accuracy = 0.0155, Validation Loss = 6.6035\n",
            "Epoch 794/1667\n",
            "Epoch 794: Training Accuracy = 0.9883, Training Loss = 0.1026, Validation Accuracy = 0.0150, Validation Loss = 6.5569\n",
            "Epoch 795/1667\n",
            "Epoch 795: Training Accuracy = 0.9883, Training Loss = 0.1026, Validation Accuracy = 0.0150, Validation Loss = 6.5569\n",
            "Epoch 796/1667\n",
            "Epoch 796: Training Accuracy = 0.7188, Training Loss = 1.3495, Validation Accuracy = 0.0143, Validation Loss = 6.2860\n",
            "Epoch 797/1667\n",
            "Epoch 797: Training Accuracy = 0.9043, Training Loss = 0.6584, Validation Accuracy = 0.0162, Validation Loss = 6.2361\n",
            "Epoch 798/1667\n",
            "Epoch 798: Training Accuracy = 0.9043, Training Loss = 0.6584, Validation Accuracy = 0.0162, Validation Loss = 6.2361\n",
            "Epoch 799/1667\n",
            "Epoch 799: Training Accuracy = 0.9629, Training Loss = 0.3503, Validation Accuracy = 0.0155, Validation Loss = 6.3746\n",
            "Epoch 800/1667\n",
            "Epoch 800: Training Accuracy = 0.9629, Training Loss = 0.3503, Validation Accuracy = 0.0155, Validation Loss = 6.3746\n",
            "Epoch 801/1667\n",
            "Epoch 801: Training Accuracy = 0.9844, Training Loss = 0.1805, Validation Accuracy = 0.0155, Validation Loss = 6.4895\n",
            "Epoch 802/1667\n",
            "Epoch 802: Training Accuracy = 0.9902, Training Loss = 0.1464, Validation Accuracy = 0.0147, Validation Loss = 6.5059\n",
            "Epoch 803/1667\n",
            "Epoch 803: Training Accuracy = 0.9902, Training Loss = 0.1464, Validation Accuracy = 0.0147, Validation Loss = 6.5059\n",
            "Epoch 804/1667\n",
            "Epoch 804: Training Accuracy = 0.9844, Training Loss = 0.1242, Validation Accuracy = 0.0161, Validation Loss = 6.5540\n",
            "Epoch 805/1667\n",
            "Epoch 805: Training Accuracy = 0.9844, Training Loss = 0.1242, Validation Accuracy = 0.0161, Validation Loss = 6.5540\n",
            "Epoch 806/1667\n",
            "Epoch 806: Training Accuracy = 0.9902, Training Loss = 0.0877, Validation Accuracy = 0.0158, Validation Loss = 6.5674\n",
            "Epoch 807/1667\n",
            "Epoch 807: Training Accuracy = 0.9961, Training Loss = 0.0623, Validation Accuracy = 0.0164, Validation Loss = 6.5404\n",
            "Epoch 808/1667\n",
            "Epoch 808: Training Accuracy = 0.9961, Training Loss = 0.0623, Validation Accuracy = 0.0164, Validation Loss = 6.5404\n",
            "Epoch 809/1667\n",
            "Epoch 809: Training Accuracy = 0.9941, Training Loss = 0.0662, Validation Accuracy = 0.0156, Validation Loss = 6.5474\n",
            "Epoch 810/1667\n",
            "Epoch 810: Training Accuracy = 0.9941, Training Loss = 0.0662, Validation Accuracy = 0.0156, Validation Loss = 6.5474\n",
            "Epoch 811/1667\n",
            "Epoch 811: Training Accuracy = 0.9883, Training Loss = 0.0848, Validation Accuracy = 0.0161, Validation Loss = 6.4923\n",
            "Epoch 812/1667\n",
            "Epoch 812: Training Accuracy = 0.9922, Training Loss = 0.0797, Validation Accuracy = 0.0169, Validation Loss = 6.4659\n",
            "Epoch 813/1667\n",
            "Epoch 813: Training Accuracy = 0.9922, Training Loss = 0.0797, Validation Accuracy = 0.0169, Validation Loss = 6.4659\n",
            "Epoch 814/1667\n",
            "Epoch 814: Training Accuracy = 0.9844, Training Loss = 0.1036, Validation Accuracy = 0.0161, Validation Loss = 6.4376\n",
            "Epoch 815/1667\n",
            "Epoch 815: Training Accuracy = 0.9844, Training Loss = 0.1036, Validation Accuracy = 0.0161, Validation Loss = 6.4376\n",
            "Epoch 816/1667\n",
            "Epoch 816: Training Accuracy = 0.9883, Training Loss = 0.1338, Validation Accuracy = 0.0169, Validation Loss = 6.3499\n",
            "Epoch 817/1667\n",
            "Epoch 817: Training Accuracy = 0.7031, Training Loss = 1.3008, Validation Accuracy = 0.0167, Validation Loss = 6.1613\n",
            "Epoch 818/1667\n",
            "Epoch 818: Training Accuracy = 0.7031, Training Loss = 1.3008, Validation Accuracy = 0.0167, Validation Loss = 6.1613\n",
            "Epoch 819/1667\n",
            "Epoch 819: Training Accuracy = 0.9238, Training Loss = 0.5382, Validation Accuracy = 0.0184, Validation Loss = 6.0823\n",
            "Epoch 820/1667\n",
            "Epoch 820: Training Accuracy = 0.9238, Training Loss = 0.5382, Validation Accuracy = 0.0184, Validation Loss = 6.0823\n",
            "Epoch 821/1667\n",
            "Epoch 821: Training Accuracy = 0.9844, Training Loss = 0.2560, Validation Accuracy = 0.0149, Validation Loss = 6.2400\n",
            "Epoch 822/1667\n",
            "Epoch 822: Training Accuracy = 0.9902, Training Loss = 0.1809, Validation Accuracy = 0.0159, Validation Loss = 6.2869\n",
            "Epoch 823/1667\n",
            "Epoch 823: Training Accuracy = 0.9902, Training Loss = 0.1809, Validation Accuracy = 0.0159, Validation Loss = 6.2869\n",
            "Epoch 824/1667\n",
            "Epoch 824: Training Accuracy = 0.9902, Training Loss = 0.1251, Validation Accuracy = 0.0169, Validation Loss = 6.3212\n",
            "Epoch 825/1667\n",
            "Epoch 825: Training Accuracy = 0.9902, Training Loss = 0.1251, Validation Accuracy = 0.0169, Validation Loss = 6.3212\n",
            "Epoch 826/1667\n",
            "Epoch 826: Training Accuracy = 0.9902, Training Loss = 0.0986, Validation Accuracy = 0.0162, Validation Loss = 6.3329\n",
            "Epoch 827/1667\n",
            "Epoch 827: Training Accuracy = 0.9941, Training Loss = 0.0820, Validation Accuracy = 0.0169, Validation Loss = 6.3104\n",
            "Epoch 828/1667\n",
            "Epoch 828: Training Accuracy = 0.9941, Training Loss = 0.0820, Validation Accuracy = 0.0169, Validation Loss = 6.3104\n",
            "Epoch 829/1667\n",
            "Epoch 829: Training Accuracy = 0.9844, Training Loss = 0.1102, Validation Accuracy = 0.0167, Validation Loss = 6.3024\n",
            "Epoch 830/1667\n",
            "Epoch 830: Training Accuracy = 0.9844, Training Loss = 0.1102, Validation Accuracy = 0.0167, Validation Loss = 6.3024\n",
            "Epoch 831/1667\n",
            "Epoch 831: Training Accuracy = 0.9785, Training Loss = 0.1298, Validation Accuracy = 0.0161, Validation Loss = 6.2772\n",
            "Epoch 832/1667\n",
            "Epoch 832: Training Accuracy = 0.9941, Training Loss = 0.0843, Validation Accuracy = 0.0184, Validation Loss = 6.2248\n",
            "Epoch 833/1667\n",
            "Epoch 833: Training Accuracy = 0.9941, Training Loss = 0.0843, Validation Accuracy = 0.0184, Validation Loss = 6.2248\n",
            "Epoch 834/1667\n",
            "Epoch 834: Training Accuracy = 0.9902, Training Loss = 0.0905, Validation Accuracy = 0.0187, Validation Loss = 6.2222\n",
            "Epoch 835/1667\n",
            "Epoch 835: Training Accuracy = 0.9902, Training Loss = 0.0905, Validation Accuracy = 0.0187, Validation Loss = 6.2222\n",
            "Epoch 836/1667\n",
            "Epoch 836: Training Accuracy = 0.9844, Training Loss = 0.1163, Validation Accuracy = 0.0184, Validation Loss = 6.1798\n",
            "Epoch 837/1667\n",
            "Epoch 837: Training Accuracy = 0.7441, Training Loss = 1.2358, Validation Accuracy = 0.0144, Validation Loss = 6.0454\n",
            "Epoch 838/1667\n",
            "Epoch 838: Training Accuracy = 0.7441, Training Loss = 1.2358, Validation Accuracy = 0.0144, Validation Loss = 6.0454\n",
            "Epoch 839/1667\n",
            "Epoch 839: Training Accuracy = 0.9121, Training Loss = 0.6717, Validation Accuracy = 0.0188, Validation Loss = 5.9074\n",
            "Epoch 840/1667\n",
            "Epoch 840: Training Accuracy = 0.9121, Training Loss = 0.6717, Validation Accuracy = 0.0188, Validation Loss = 5.9074\n",
            "Epoch 841/1667\n",
            "Epoch 841: Training Accuracy = 0.9707, Training Loss = 0.3201, Validation Accuracy = 0.0187, Validation Loss = 6.0170\n",
            "Epoch 842/1667\n",
            "Epoch 842: Training Accuracy = 0.9824, Training Loss = 0.2354, Validation Accuracy = 0.0181, Validation Loss = 6.0547\n",
            "Epoch 843/1667\n",
            "Epoch 843: Training Accuracy = 0.9824, Training Loss = 0.2354, Validation Accuracy = 0.0181, Validation Loss = 6.0547\n",
            "Epoch 844/1667\n",
            "Epoch 844: Training Accuracy = 0.9883, Training Loss = 0.1603, Validation Accuracy = 0.0191, Validation Loss = 6.1185\n",
            "Epoch 845/1667\n",
            "Epoch 845: Training Accuracy = 0.9883, Training Loss = 0.1603, Validation Accuracy = 0.0191, Validation Loss = 6.1185\n",
            "Epoch 846/1667\n",
            "Epoch 846: Training Accuracy = 0.9844, Training Loss = 0.1232, Validation Accuracy = 0.0181, Validation Loss = 6.1180\n",
            "Epoch 847/1667\n",
            "Epoch 847: Training Accuracy = 0.9844, Training Loss = 0.1259, Validation Accuracy = 0.0184, Validation Loss = 6.1020\n",
            "Epoch 848/1667\n",
            "Epoch 848: Training Accuracy = 0.9844, Training Loss = 0.1259, Validation Accuracy = 0.0184, Validation Loss = 6.1020\n",
            "Epoch 849/1667\n",
            "Epoch 849: Training Accuracy = 0.9902, Training Loss = 0.0946, Validation Accuracy = 0.0185, Validation Loss = 6.1065\n",
            "Epoch 850/1667\n",
            "Epoch 850: Training Accuracy = 0.9902, Training Loss = 0.0946, Validation Accuracy = 0.0185, Validation Loss = 6.1065\n",
            "Epoch 851/1667\n",
            "Epoch 851: Training Accuracy = 0.9922, Training Loss = 0.0826, Validation Accuracy = 0.0179, Validation Loss = 6.0894\n",
            "Epoch 852/1667\n",
            "Epoch 852: Training Accuracy = 0.9766, Training Loss = 0.1507, Validation Accuracy = 0.0194, Validation Loss = 6.0713\n",
            "Epoch 853/1667\n",
            "Epoch 853: Training Accuracy = 0.9766, Training Loss = 0.1507, Validation Accuracy = 0.0194, Validation Loss = 6.0713\n",
            "Epoch 854/1667\n",
            "Epoch 854: Training Accuracy = 0.9883, Training Loss = 0.1009, Validation Accuracy = 0.0194, Validation Loss = 6.0406\n",
            "Epoch 855/1667\n",
            "Epoch 855: Training Accuracy = 0.9883, Training Loss = 0.1009, Validation Accuracy = 0.0194, Validation Loss = 6.0406\n",
            "Epoch 856/1667\n",
            "Epoch 856: Training Accuracy = 0.9824, Training Loss = 0.1172, Validation Accuracy = 0.0203, Validation Loss = 6.0372\n",
            "Epoch 857/1667\n",
            "Epoch 857: Training Accuracy = 0.9746, Training Loss = 0.2038, Validation Accuracy = 0.0213, Validation Loss = 5.8905\n",
            "Epoch 858/1667\n",
            "Epoch 858: Training Accuracy = 0.9746, Training Loss = 0.2038, Validation Accuracy = 0.0213, Validation Loss = 5.8905\n",
            "Epoch 859/1667\n",
            "Epoch 859: Training Accuracy = 0.8027, Training Loss = 0.9734, Validation Accuracy = 0.0170, Validation Loss = 5.7287\n",
            "Epoch 860/1667\n",
            "Epoch 860: Training Accuracy = 0.8027, Training Loss = 0.9734, Validation Accuracy = 0.0170, Validation Loss = 5.7287\n",
            "Epoch 861/1667\n",
            "Epoch 861: Training Accuracy = 0.9473, Training Loss = 0.4482, Validation Accuracy = 0.0210, Validation Loss = 5.7861\n",
            "Epoch 862/1667\n",
            "Epoch 862: Training Accuracy = 0.9844, Training Loss = 0.3088, Validation Accuracy = 0.0217, Validation Loss = 5.8286\n",
            "Epoch 863/1667\n",
            "Epoch 863: Training Accuracy = 0.9844, Training Loss = 0.3088, Validation Accuracy = 0.0217, Validation Loss = 5.8286\n",
            "Epoch 864/1667\n",
            "Epoch 864: Training Accuracy = 0.9824, Training Loss = 0.1944, Validation Accuracy = 0.0216, Validation Loss = 5.8314\n",
            "Epoch 865/1667\n",
            "Epoch 865: Training Accuracy = 0.9824, Training Loss = 0.1944, Validation Accuracy = 0.0216, Validation Loss = 5.8314\n",
            "Epoch 866/1667\n",
            "Epoch 866: Training Accuracy = 0.9863, Training Loss = 0.1395, Validation Accuracy = 0.0211, Validation Loss = 5.8830\n",
            "Epoch 867/1667\n",
            "Epoch 867: Training Accuracy = 0.9922, Training Loss = 0.1024, Validation Accuracy = 0.0232, Validation Loss = 5.9070\n",
            "Epoch 868/1667\n",
            "Epoch 868: Training Accuracy = 0.9922, Training Loss = 0.1024, Validation Accuracy = 0.0232, Validation Loss = 5.9070\n",
            "Epoch 869/1667\n",
            "Epoch 869: Training Accuracy = 0.9922, Training Loss = 0.0879, Validation Accuracy = 0.0210, Validation Loss = 5.9094\n",
            "Epoch 870/1667\n",
            "Epoch 870: Training Accuracy = 0.9922, Training Loss = 0.0879, Validation Accuracy = 0.0210, Validation Loss = 5.9094\n",
            "Epoch 871/1667\n",
            "Epoch 871: Training Accuracy = 0.9844, Training Loss = 0.1156, Validation Accuracy = 0.0223, Validation Loss = 5.8761\n",
            "Epoch 872/1667\n",
            "Epoch 872: Training Accuracy = 0.9863, Training Loss = 0.1109, Validation Accuracy = 0.0223, Validation Loss = 5.8758\n",
            "Epoch 873/1667\n",
            "Epoch 873: Training Accuracy = 0.9863, Training Loss = 0.1109, Validation Accuracy = 0.0223, Validation Loss = 5.8758\n",
            "Epoch 874/1667\n",
            "Epoch 874: Training Accuracy = 0.9844, Training Loss = 0.1134, Validation Accuracy = 0.0213, Validation Loss = 5.8577\n",
            "Epoch 875/1667\n",
            "Epoch 875: Training Accuracy = 0.9844, Training Loss = 0.1134, Validation Accuracy = 0.0213, Validation Loss = 5.8577\n",
            "Epoch 876/1667\n",
            "Epoch 876: Training Accuracy = 0.9922, Training Loss = 0.0836, Validation Accuracy = 0.0234, Validation Loss = 5.8235\n",
            "Epoch 877/1667\n",
            "Epoch 877: Training Accuracy = 0.9824, Training Loss = 0.1387, Validation Accuracy = 0.0235, Validation Loss = 5.7819\n",
            "Epoch 878/1667\n",
            "Epoch 878: Training Accuracy = 0.9824, Training Loss = 0.1387, Validation Accuracy = 0.0235, Validation Loss = 5.7819\n",
            "Epoch 879/1667\n",
            "Epoch 879: Training Accuracy = 0.9902, Training Loss = 0.1405, Validation Accuracy = 0.0222, Validation Loss = 5.8208\n",
            "Epoch 880/1667\n",
            "Epoch 880: Training Accuracy = 0.9902, Training Loss = 0.1405, Validation Accuracy = 0.0222, Validation Loss = 5.8208\n",
            "Epoch 881/1667\n",
            "Epoch 881: Training Accuracy = 0.8984, Training Loss = 0.6283, Validation Accuracy = 0.0211, Validation Loss = 5.7378\n",
            "Epoch 882/1667\n",
            "Epoch 882: Training Accuracy = 0.9531, Training Loss = 0.4597, Validation Accuracy = 0.0226, Validation Loss = 5.6101\n",
            "Epoch 883/1667\n",
            "Epoch 883: Training Accuracy = 0.9531, Training Loss = 0.4597, Validation Accuracy = 0.0226, Validation Loss = 5.6101\n",
            "Epoch 884/1667\n",
            "Epoch 884: Training Accuracy = 0.9863, Training Loss = 0.2500, Validation Accuracy = 0.0243, Validation Loss = 5.6754\n",
            "Epoch 885/1667\n",
            "Epoch 885: Training Accuracy = 0.9863, Training Loss = 0.2500, Validation Accuracy = 0.0243, Validation Loss = 5.6754\n",
            "Epoch 886/1667\n",
            "Epoch 886: Training Accuracy = 0.9863, Training Loss = 0.1770, Validation Accuracy = 0.0281, Validation Loss = 5.6992\n",
            "Epoch 887/1667\n",
            "Epoch 887: Training Accuracy = 0.9941, Training Loss = 0.1235, Validation Accuracy = 0.0250, Validation Loss = 5.7031\n",
            "Epoch 888/1667\n",
            "Epoch 888: Training Accuracy = 0.9941, Training Loss = 0.1235, Validation Accuracy = 0.0250, Validation Loss = 5.7031\n",
            "Epoch 889/1667\n",
            "Epoch 889: Training Accuracy = 0.9844, Training Loss = 0.1184, Validation Accuracy = 0.0266, Validation Loss = 5.6989\n",
            "Epoch 890/1667\n",
            "Epoch 890: Training Accuracy = 0.9844, Training Loss = 0.1184, Validation Accuracy = 0.0266, Validation Loss = 5.6989\n",
            "Epoch 891/1667\n",
            "Epoch 891: Training Accuracy = 0.9922, Training Loss = 0.0760, Validation Accuracy = 0.0273, Validation Loss = 5.7065\n",
            "Epoch 892/1667\n",
            "Epoch 892: Training Accuracy = 0.9863, Training Loss = 0.1012, Validation Accuracy = 0.0276, Validation Loss = 5.6995\n",
            "Epoch 893/1667\n",
            "Epoch 893: Training Accuracy = 0.9863, Training Loss = 0.1012, Validation Accuracy = 0.0276, Validation Loss = 5.6995\n",
            "Epoch 894/1667\n",
            "Epoch 894: Training Accuracy = 0.9902, Training Loss = 0.0783, Validation Accuracy = 0.0267, Validation Loss = 5.6734\n",
            "Epoch 895/1667\n",
            "Epoch 895: Training Accuracy = 0.9902, Training Loss = 0.0783, Validation Accuracy = 0.0267, Validation Loss = 5.6734\n",
            "Epoch 896/1667\n",
            "Epoch 896: Training Accuracy = 0.9863, Training Loss = 0.0955, Validation Accuracy = 0.0267, Validation Loss = 5.6702\n",
            "Epoch 897/1667\n",
            "Epoch 897: Training Accuracy = 0.9902, Training Loss = 0.0930, Validation Accuracy = 0.0282, Validation Loss = 5.6488\n",
            "Epoch 898/1667\n",
            "Epoch 898: Training Accuracy = 0.9902, Training Loss = 0.0930, Validation Accuracy = 0.0282, Validation Loss = 5.6488\n",
            "Epoch 899/1667\n",
            "Epoch 899: Training Accuracy = 0.9824, Training Loss = 0.1255, Validation Accuracy = 0.0258, Validation Loss = 5.6197\n",
            "Epoch 900/1667\n",
            "Epoch 900: Training Accuracy = 0.9824, Training Loss = 0.1255, Validation Accuracy = 0.0258, Validation Loss = 5.6197\n",
            "Epoch 901/1667\n",
            "Epoch 901: Training Accuracy = 0.8926, Training Loss = 0.8113, Validation Accuracy = 0.0290, Validation Loss = 5.4521\n",
            "Epoch 902/1667\n",
            "Epoch 902: Training Accuracy = 0.8789, Training Loss = 0.7279, Validation Accuracy = 0.0279, Validation Loss = 5.3694\n",
            "Epoch 903/1667\n",
            "Epoch 903: Training Accuracy = 0.8789, Training Loss = 0.7279, Validation Accuracy = 0.0279, Validation Loss = 5.3694\n",
            "Epoch 904/1667\n",
            "Epoch 904: Training Accuracy = 0.9688, Training Loss = 0.3854, Validation Accuracy = 0.0296, Validation Loss = 5.3262\n",
            "Epoch 905/1667\n",
            "Epoch 905: Training Accuracy = 0.9688, Training Loss = 0.3854, Validation Accuracy = 0.0296, Validation Loss = 5.3262\n",
            "Epoch 906/1667\n",
            "Epoch 906: Training Accuracy = 0.9863, Training Loss = 0.1948, Validation Accuracy = 0.0287, Validation Loss = 5.3964\n",
            "Epoch 907/1667\n",
            "Epoch 907: Training Accuracy = 0.9844, Training Loss = 0.2021, Validation Accuracy = 0.0290, Validation Loss = 5.3852\n",
            "Epoch 908/1667\n",
            "Epoch 908: Training Accuracy = 0.9844, Training Loss = 0.2021, Validation Accuracy = 0.0290, Validation Loss = 5.3852\n",
            "Epoch 909/1667\n",
            "Epoch 909: Training Accuracy = 0.9844, Training Loss = 0.1391, Validation Accuracy = 0.0307, Validation Loss = 5.3974\n",
            "Epoch 910/1667\n",
            "Epoch 910: Training Accuracy = 0.9844, Training Loss = 0.1391, Validation Accuracy = 0.0307, Validation Loss = 5.3974\n",
            "Epoch 911/1667\n",
            "Epoch 911: Training Accuracy = 0.9863, Training Loss = 0.1024, Validation Accuracy = 0.0307, Validation Loss = 5.4178\n",
            "Epoch 912/1667\n",
            "Epoch 912: Training Accuracy = 0.9766, Training Loss = 0.1373, Validation Accuracy = 0.0293, Validation Loss = 5.3815\n",
            "Epoch 913/1667\n",
            "Epoch 913: Training Accuracy = 0.9766, Training Loss = 0.1373, Validation Accuracy = 0.0293, Validation Loss = 5.3815\n",
            "Epoch 914/1667\n",
            "Epoch 914: Training Accuracy = 0.9863, Training Loss = 0.0929, Validation Accuracy = 0.0317, Validation Loss = 5.3917\n",
            "Epoch 915/1667\n",
            "Epoch 915: Training Accuracy = 0.9863, Training Loss = 0.0929, Validation Accuracy = 0.0317, Validation Loss = 5.3917\n",
            "Epoch 916/1667\n",
            "Epoch 916: Training Accuracy = 0.9824, Training Loss = 0.1049, Validation Accuracy = 0.0302, Validation Loss = 5.4049\n",
            "Epoch 917/1667\n",
            "Epoch 917: Training Accuracy = 0.9844, Training Loss = 0.1084, Validation Accuracy = 0.0320, Validation Loss = 5.3550\n",
            "Epoch 918/1667\n",
            "Epoch 918: Training Accuracy = 0.9844, Training Loss = 0.1084, Validation Accuracy = 0.0320, Validation Loss = 5.3550\n",
            "Epoch 919/1667\n",
            "Epoch 919: Training Accuracy = 0.9844, Training Loss = 0.1033, Validation Accuracy = 0.0320, Validation Loss = 5.3464\n",
            "Epoch 920/1667\n",
            "Epoch 920: Training Accuracy = 0.9844, Training Loss = 0.1033, Validation Accuracy = 0.0320, Validation Loss = 5.3464\n",
            "Epoch 921/1667\n",
            "Epoch 921: Training Accuracy = 0.9883, Training Loss = 0.0933, Validation Accuracy = 0.0305, Validation Loss = 5.3277\n",
            "Epoch 922/1667\n",
            "Epoch 922: Training Accuracy = 0.9883, Training Loss = 0.1326, Validation Accuracy = 0.0305, Validation Loss = 5.2713\n",
            "Epoch 923/1667\n",
            "Epoch 923: Training Accuracy = 0.9883, Training Loss = 0.1326, Validation Accuracy = 0.0305, Validation Loss = 5.2713\n",
            "Epoch 924/1667\n",
            "Epoch 924: Training Accuracy = 0.7266, Training Loss = 1.1536, Validation Accuracy = 0.0279, Validation Loss = 5.2918\n",
            "Epoch 925/1667\n",
            "Epoch 925: Training Accuracy = 0.7266, Training Loss = 1.1536, Validation Accuracy = 0.0279, Validation Loss = 5.2918\n",
            "Epoch 926/1667\n",
            "Epoch 926: Training Accuracy = 0.9453, Training Loss = 0.5034, Validation Accuracy = 0.0387, Validation Loss = 4.9013\n",
            "Epoch 927/1667\n",
            "Epoch 927: Training Accuracy = 0.9785, Training Loss = 0.3330, Validation Accuracy = 0.0367, Validation Loss = 4.8762\n",
            "Epoch 928/1667\n",
            "Epoch 928: Training Accuracy = 0.9785, Training Loss = 0.3330, Validation Accuracy = 0.0367, Validation Loss = 4.8762\n",
            "Epoch 929/1667\n",
            "Epoch 929: Training Accuracy = 0.9922, Training Loss = 0.1779, Validation Accuracy = 0.0422, Validation Loss = 4.9193\n",
            "Epoch 930/1667\n",
            "Epoch 930: Training Accuracy = 0.9922, Training Loss = 0.1779, Validation Accuracy = 0.0422, Validation Loss = 4.9193\n",
            "Epoch 931/1667\n",
            "Epoch 931: Training Accuracy = 0.9922, Training Loss = 0.1199, Validation Accuracy = 0.0399, Validation Loss = 4.9091\n",
            "Epoch 932/1667\n",
            "Epoch 932: Training Accuracy = 0.9766, Training Loss = 0.1602, Validation Accuracy = 0.0408, Validation Loss = 4.9460\n",
            "Epoch 933/1667\n",
            "Epoch 933: Training Accuracy = 0.9766, Training Loss = 0.1602, Validation Accuracy = 0.0408, Validation Loss = 4.9460\n",
            "Epoch 934/1667\n",
            "Epoch 934: Training Accuracy = 0.9863, Training Loss = 0.1061, Validation Accuracy = 0.0437, Validation Loss = 4.9692\n",
            "Epoch 935/1667\n",
            "Epoch 935: Training Accuracy = 0.9863, Training Loss = 0.1061, Validation Accuracy = 0.0437, Validation Loss = 4.9692\n",
            "Epoch 936/1667\n",
            "Epoch 936: Training Accuracy = 0.9883, Training Loss = 0.0849, Validation Accuracy = 0.0396, Validation Loss = 4.9732\n",
            "Epoch 937/1667\n",
            "Epoch 937: Training Accuracy = 0.9883, Training Loss = 0.0950, Validation Accuracy = 0.0414, Validation Loss = 4.9513\n",
            "Epoch 938/1667\n",
            "Epoch 938: Training Accuracy = 0.9883, Training Loss = 0.0950, Validation Accuracy = 0.0414, Validation Loss = 4.9513\n",
            "Epoch 939/1667\n",
            "Epoch 939: Training Accuracy = 0.9844, Training Loss = 0.1063, Validation Accuracy = 0.0416, Validation Loss = 4.9360\n",
            "Epoch 940/1667\n",
            "Epoch 940: Training Accuracy = 0.9844, Training Loss = 0.1063, Validation Accuracy = 0.0416, Validation Loss = 4.9360\n",
            "Epoch 941/1667\n",
            "Epoch 941: Training Accuracy = 0.9922, Training Loss = 0.0804, Validation Accuracy = 0.0433, Validation Loss = 4.9119\n",
            "Epoch 942/1667\n",
            "Epoch 942: Training Accuracy = 0.9883, Training Loss = 0.1066, Validation Accuracy = 0.0416, Validation Loss = 4.9227\n",
            "Epoch 943/1667\n",
            "Epoch 943: Training Accuracy = 0.9883, Training Loss = 0.1066, Validation Accuracy = 0.0416, Validation Loss = 4.9227\n",
            "Epoch 944/1667\n",
            "Epoch 944: Training Accuracy = 0.9883, Training Loss = 0.1063, Validation Accuracy = 0.0421, Validation Loss = 4.8786\n",
            "Epoch 945/1667\n",
            "Epoch 945: Training Accuracy = 0.9883, Training Loss = 0.1063, Validation Accuracy = 0.0421, Validation Loss = 4.8786\n",
            "Epoch 946/1667\n",
            "Epoch 946: Training Accuracy = 0.9883, Training Loss = 0.1193, Validation Accuracy = 0.0437, Validation Loss = 4.8855\n",
            "Epoch 947/1667\n",
            "Epoch 947: Training Accuracy = 0.7285, Training Loss = 1.2873, Validation Accuracy = 0.0311, Validation Loss = 5.1670\n",
            "Epoch 948/1667\n",
            "Epoch 948: Training Accuracy = 0.7285, Training Loss = 1.2873, Validation Accuracy = 0.0311, Validation Loss = 5.1670\n",
            "Epoch 949/1667\n",
            "Epoch 949: Training Accuracy = 0.9355, Training Loss = 0.5219, Validation Accuracy = 0.0468, Validation Loss = 4.7575\n",
            "Epoch 950/1667\n",
            "Epoch 950: Training Accuracy = 0.9355, Training Loss = 0.5219, Validation Accuracy = 0.0468, Validation Loss = 4.7575\n",
            "Epoch 951/1667\n",
            "Epoch 951: Training Accuracy = 0.9727, Training Loss = 0.3319, Validation Accuracy = 0.0496, Validation Loss = 4.5967\n",
            "Epoch 952/1667\n",
            "Epoch 952: Training Accuracy = 0.9824, Training Loss = 0.2196, Validation Accuracy = 0.0516, Validation Loss = 4.6200\n",
            "Epoch 953/1667\n",
            "Epoch 953: Training Accuracy = 0.9824, Training Loss = 0.2196, Validation Accuracy = 0.0516, Validation Loss = 4.6200\n",
            "Epoch 954/1667\n",
            "Epoch 954: Training Accuracy = 0.9902, Training Loss = 0.1241, Validation Accuracy = 0.0536, Validation Loss = 4.5962\n",
            "Epoch 955/1667\n",
            "Epoch 955: Training Accuracy = 0.9902, Training Loss = 0.1241, Validation Accuracy = 0.0536, Validation Loss = 4.5962\n",
            "Epoch 956/1667\n",
            "Epoch 956: Training Accuracy = 0.9902, Training Loss = 0.1076, Validation Accuracy = 0.0569, Validation Loss = 4.5812\n",
            "Epoch 957/1667\n",
            "Epoch 957: Training Accuracy = 0.9863, Training Loss = 0.1070, Validation Accuracy = 0.0559, Validation Loss = 4.5742\n",
            "Epoch 958/1667\n",
            "Epoch 958: Training Accuracy = 0.9863, Training Loss = 0.1070, Validation Accuracy = 0.0559, Validation Loss = 4.5742\n",
            "Epoch 959/1667\n",
            "Epoch 959: Training Accuracy = 0.9883, Training Loss = 0.0923, Validation Accuracy = 0.0568, Validation Loss = 4.5715\n",
            "Epoch 960/1667\n",
            "Epoch 960: Training Accuracy = 0.9883, Training Loss = 0.0923, Validation Accuracy = 0.0568, Validation Loss = 4.5715\n",
            "Epoch 961/1667\n",
            "Epoch 961: Training Accuracy = 0.9902, Training Loss = 0.0766, Validation Accuracy = 0.0551, Validation Loss = 4.5783\n",
            "Epoch 962/1667\n",
            "Epoch 962: Training Accuracy = 0.9824, Training Loss = 0.1175, Validation Accuracy = 0.0566, Validation Loss = 4.5645\n",
            "Epoch 963/1667\n",
            "Epoch 963: Training Accuracy = 0.9824, Training Loss = 0.1175, Validation Accuracy = 0.0566, Validation Loss = 4.5645\n",
            "Epoch 964/1667\n",
            "Epoch 964: Training Accuracy = 0.9941, Training Loss = 0.0653, Validation Accuracy = 0.0589, Validation Loss = 4.5426\n",
            "Epoch 965/1667\n",
            "Epoch 965: Training Accuracy = 0.9941, Training Loss = 0.0653, Validation Accuracy = 0.0589, Validation Loss = 4.5426\n",
            "Epoch 966/1667\n",
            "Epoch 966: Training Accuracy = 0.9883, Training Loss = 0.0889, Validation Accuracy = 0.0583, Validation Loss = 4.5205\n",
            "Epoch 967/1667\n",
            "Epoch 967: Training Accuracy = 0.9902, Training Loss = 0.1015, Validation Accuracy = 0.0554, Validation Loss = 4.5170\n",
            "Epoch 968/1667\n",
            "Epoch 968: Training Accuracy = 0.9902, Training Loss = 0.1015, Validation Accuracy = 0.0554, Validation Loss = 4.5170\n",
            "Epoch 969/1667\n",
            "Epoch 969: Training Accuracy = 0.6758, Training Loss = 1.4055, Validation Accuracy = 0.0414, Validation Loss = 4.8167\n",
            "Epoch 970/1667\n",
            "Epoch 970: Training Accuracy = 0.6758, Training Loss = 1.4055, Validation Accuracy = 0.0414, Validation Loss = 4.8167\n",
            "Epoch 971/1667\n",
            "Epoch 971: Training Accuracy = 0.9512, Training Loss = 0.4674, Validation Accuracy = 0.0659, Validation Loss = 4.1971\n",
            "Epoch 972/1667\n",
            "Epoch 972: Training Accuracy = 0.9668, Training Loss = 0.3538, Validation Accuracy = 0.0830, Validation Loss = 3.9878\n",
            "Epoch 973/1667\n",
            "Epoch 973: Training Accuracy = 0.9668, Training Loss = 0.3538, Validation Accuracy = 0.0830, Validation Loss = 3.9878\n",
            "Epoch 974/1667\n",
            "Epoch 974: Training Accuracy = 0.9941, Training Loss = 0.1683, Validation Accuracy = 0.0865, Validation Loss = 3.9632\n",
            "Epoch 975/1667\n",
            "Epoch 975: Training Accuracy = 0.9941, Training Loss = 0.1683, Validation Accuracy = 0.0865, Validation Loss = 3.9632\n",
            "Epoch 976/1667\n",
            "Epoch 976: Training Accuracy = 0.9961, Training Loss = 0.0966, Validation Accuracy = 0.0861, Validation Loss = 3.9692\n",
            "Epoch 977/1667\n",
            "Epoch 977: Training Accuracy = 0.9805, Training Loss = 0.1370, Validation Accuracy = 0.0899, Validation Loss = 3.9746\n",
            "Epoch 978/1667\n",
            "Epoch 978: Training Accuracy = 0.9805, Training Loss = 0.1370, Validation Accuracy = 0.0899, Validation Loss = 3.9746\n",
            "Epoch 979/1667\n",
            "Epoch 979: Training Accuracy = 0.9824, Training Loss = 0.1199, Validation Accuracy = 0.0867, Validation Loss = 4.0313\n",
            "Epoch 980/1667\n",
            "Epoch 980: Training Accuracy = 0.9824, Training Loss = 0.1199, Validation Accuracy = 0.0867, Validation Loss = 4.0313\n",
            "Epoch 981/1667\n",
            "Epoch 981: Training Accuracy = 0.9844, Training Loss = 0.0978, Validation Accuracy = 0.0882, Validation Loss = 4.0095\n",
            "Epoch 982/1667\n",
            "Epoch 982: Training Accuracy = 0.9824, Training Loss = 0.1118, Validation Accuracy = 0.0856, Validation Loss = 4.0307\n",
            "Epoch 983/1667\n",
            "Epoch 983: Training Accuracy = 0.9824, Training Loss = 0.1118, Validation Accuracy = 0.0856, Validation Loss = 4.0307\n",
            "Epoch 984/1667\n",
            "Epoch 984: Training Accuracy = 0.9922, Training Loss = 0.0685, Validation Accuracy = 0.0885, Validation Loss = 4.0058\n",
            "Epoch 985/1667\n",
            "Epoch 985: Training Accuracy = 0.9922, Training Loss = 0.0685, Validation Accuracy = 0.0885, Validation Loss = 4.0058\n",
            "Epoch 986/1667\n",
            "Epoch 986: Training Accuracy = 0.9922, Training Loss = 0.0750, Validation Accuracy = 0.0853, Validation Loss = 4.0357\n",
            "Epoch 987/1667\n",
            "Epoch 987: Training Accuracy = 0.9941, Training Loss = 0.0747, Validation Accuracy = 0.0846, Validation Loss = 4.0333\n",
            "Epoch 988/1667\n",
            "Epoch 988: Training Accuracy = 0.9941, Training Loss = 0.0747, Validation Accuracy = 0.0846, Validation Loss = 4.0333\n",
            "Epoch 989/1667\n",
            "Epoch 989: Training Accuracy = 0.9863, Training Loss = 0.1030, Validation Accuracy = 0.0874, Validation Loss = 3.9847\n",
            "Epoch 990/1667\n",
            "Epoch 990: Training Accuracy = 0.9863, Training Loss = 0.1030, Validation Accuracy = 0.0874, Validation Loss = 3.9847\n",
            "Epoch 991/1667\n",
            "Epoch 991: Training Accuracy = 0.9863, Training Loss = 0.1109, Validation Accuracy = 0.0862, Validation Loss = 4.0162\n",
            "Epoch 992/1667\n",
            "Epoch 992: Training Accuracy = 0.8281, Training Loss = 1.0130, Validation Accuracy = 0.0581, Validation Loss = 4.4763\n",
            "Epoch 993/1667\n",
            "Epoch 993: Training Accuracy = 0.8281, Training Loss = 1.0130, Validation Accuracy = 0.0581, Validation Loss = 4.4763\n",
            "Epoch 994/1667\n",
            "Epoch 994: Training Accuracy = 0.9199, Training Loss = 0.6105, Validation Accuracy = 0.1070, Validation Loss = 3.6790\n",
            "Epoch 995/1667\n",
            "Epoch 995: Training Accuracy = 0.9199, Training Loss = 0.6105, Validation Accuracy = 0.1070, Validation Loss = 3.6790\n",
            "Epoch 996/1667\n",
            "Epoch 996: Training Accuracy = 0.9824, Training Loss = 0.2754, Validation Accuracy = 0.1215, Validation Loss = 3.5840\n",
            "Epoch 997/1667\n",
            "Epoch 997: Training Accuracy = 0.9785, Training Loss = 0.2292, Validation Accuracy = 0.1277, Validation Loss = 3.4397\n",
            "Epoch 998/1667\n",
            "Epoch 998: Training Accuracy = 0.9785, Training Loss = 0.2292, Validation Accuracy = 0.1277, Validation Loss = 3.4397\n",
            "Epoch 999/1667\n",
            "Epoch 999: Training Accuracy = 0.9805, Training Loss = 0.1617, Validation Accuracy = 0.1375, Validation Loss = 3.4429\n",
            "Epoch 1000/1667\n",
            "Epoch 1000: Training Accuracy = 0.9805, Training Loss = 0.1617, Validation Accuracy = 0.1375, Validation Loss = 3.4429\n",
            "Epoch 1001/1667\n",
            "Epoch 1001: Training Accuracy = 0.9941, Training Loss = 0.0821, Validation Accuracy = 0.1330, Validation Loss = 3.4411\n",
            "Epoch 1002/1667\n",
            "Epoch 1002: Training Accuracy = 0.9824, Training Loss = 0.1161, Validation Accuracy = 0.1391, Validation Loss = 3.4021\n",
            "Epoch 1003/1667\n",
            "Epoch 1003: Training Accuracy = 0.9824, Training Loss = 0.1161, Validation Accuracy = 0.1391, Validation Loss = 3.4021\n",
            "Epoch 1004/1667\n",
            "Epoch 1004: Training Accuracy = 0.9883, Training Loss = 0.0903, Validation Accuracy = 0.1403, Validation Loss = 3.4231\n",
            "Epoch 1005/1667\n",
            "Epoch 1005: Training Accuracy = 0.9883, Training Loss = 0.0903, Validation Accuracy = 0.1403, Validation Loss = 3.4231\n",
            "Epoch 1006/1667\n",
            "Epoch 1006: Training Accuracy = 0.9902, Training Loss = 0.0759, Validation Accuracy = 0.1359, Validation Loss = 3.4285\n",
            "Epoch 1007/1667\n",
            "Epoch 1007: Training Accuracy = 0.9922, Training Loss = 0.0786, Validation Accuracy = 0.1403, Validation Loss = 3.4268\n",
            "Epoch 1008/1667\n",
            "Epoch 1008: Training Accuracy = 0.9922, Training Loss = 0.0786, Validation Accuracy = 0.1403, Validation Loss = 3.4268\n",
            "Epoch 1009/1667\n",
            "Epoch 1009: Training Accuracy = 0.9941, Training Loss = 0.0631, Validation Accuracy = 0.1345, Validation Loss = 3.4439\n",
            "Epoch 1010/1667\n",
            "Epoch 1010: Training Accuracy = 0.9941, Training Loss = 0.0631, Validation Accuracy = 0.1345, Validation Loss = 3.4439\n",
            "Epoch 1011/1667\n",
            "Epoch 1011: Training Accuracy = 0.9863, Training Loss = 0.0935, Validation Accuracy = 0.1395, Validation Loss = 3.4197\n",
            "Epoch 1012/1667\n",
            "Epoch 1012: Training Accuracy = 0.9883, Training Loss = 0.1003, Validation Accuracy = 0.1385, Validation Loss = 3.4130\n",
            "Epoch 1013/1667\n",
            "Epoch 1013: Training Accuracy = 0.9883, Training Loss = 0.1003, Validation Accuracy = 0.1385, Validation Loss = 3.4130\n",
            "Epoch 1014/1667\n",
            "Epoch 1014: Training Accuracy = 0.9844, Training Loss = 0.1232, Validation Accuracy = 0.1309, Validation Loss = 3.4795\n",
            "Epoch 1015/1667\n",
            "Epoch 1015: Training Accuracy = 0.9844, Training Loss = 0.1232, Validation Accuracy = 0.1309, Validation Loss = 3.4795\n",
            "Epoch 1016/1667\n",
            "Epoch 1016: Training Accuracy = 0.9727, Training Loss = 0.3200, Validation Accuracy = 0.0963, Validation Loss = 4.0065\n",
            "Epoch 1017/1667\n",
            "Epoch 1017: Training Accuracy = 0.9160, Training Loss = 0.6097, Validation Accuracy = 0.1495, Validation Loss = 3.2462\n",
            "Epoch 1018/1667\n",
            "Epoch 1018: Training Accuracy = 0.9160, Training Loss = 0.6097, Validation Accuracy = 0.1495, Validation Loss = 3.2462\n",
            "Epoch 1019/1667\n",
            "Epoch 1019: Training Accuracy = 0.9629, Training Loss = 0.3580, Validation Accuracy = 0.1884, Validation Loss = 3.0012\n",
            "Epoch 1020/1667\n",
            "Epoch 1020: Training Accuracy = 0.9629, Training Loss = 0.3580, Validation Accuracy = 0.1884, Validation Loss = 3.0012\n",
            "Epoch 1021/1667\n",
            "Epoch 1021: Training Accuracy = 0.9883, Training Loss = 0.1838, Validation Accuracy = 0.2077, Validation Loss = 2.8633\n",
            "Epoch 1022/1667\n",
            "Epoch 1022: Training Accuracy = 0.9922, Training Loss = 0.1241, Validation Accuracy = 0.2153, Validation Loss = 2.8280\n",
            "Epoch 1023/1667\n",
            "Epoch 1023: Training Accuracy = 0.9922, Training Loss = 0.1241, Validation Accuracy = 0.2153, Validation Loss = 2.8280\n",
            "Epoch 1024/1667\n",
            "Epoch 1024: Training Accuracy = 0.9883, Training Loss = 0.1071, Validation Accuracy = 0.2212, Validation Loss = 2.8157\n",
            "Epoch 1025/1667\n",
            "Epoch 1025: Training Accuracy = 0.9883, Training Loss = 0.1071, Validation Accuracy = 0.2212, Validation Loss = 2.8157\n",
            "Epoch 1026/1667\n",
            "Epoch 1026: Training Accuracy = 0.9961, Training Loss = 0.0609, Validation Accuracy = 0.2244, Validation Loss = 2.8072\n",
            "Epoch 1027/1667\n",
            "Epoch 1027: Training Accuracy = 0.9805, Training Loss = 0.1150, Validation Accuracy = 0.2244, Validation Loss = 2.8186\n",
            "Epoch 1028/1667\n",
            "Epoch 1028: Training Accuracy = 0.9805, Training Loss = 0.1150, Validation Accuracy = 0.2244, Validation Loss = 2.8186\n",
            "Epoch 1029/1667\n",
            "Epoch 1029: Training Accuracy = 0.9941, Training Loss = 0.0562, Validation Accuracy = 0.2253, Validation Loss = 2.8317\n",
            "Epoch 1030/1667\n",
            "Epoch 1030: Training Accuracy = 0.9941, Training Loss = 0.0562, Validation Accuracy = 0.2253, Validation Loss = 2.8317\n",
            "Epoch 1031/1667\n",
            "Epoch 1031: Training Accuracy = 0.9863, Training Loss = 0.0842, Validation Accuracy = 0.2226, Validation Loss = 2.8212\n",
            "Epoch 1032/1667\n",
            "Epoch 1032: Training Accuracy = 0.9922, Training Loss = 0.0689, Validation Accuracy = 0.2218, Validation Loss = 2.8406\n",
            "Epoch 1033/1667\n",
            "Epoch 1033: Training Accuracy = 0.9922, Training Loss = 0.0689, Validation Accuracy = 0.2218, Validation Loss = 2.8406\n",
            "Epoch 1034/1667\n",
            "Epoch 1034: Training Accuracy = 0.9863, Training Loss = 0.0899, Validation Accuracy = 0.2156, Validation Loss = 2.8627\n",
            "Epoch 1035/1667\n",
            "Epoch 1035: Training Accuracy = 0.9863, Training Loss = 0.0899, Validation Accuracy = 0.2156, Validation Loss = 2.8627\n",
            "Epoch 1036/1667\n",
            "Epoch 1036: Training Accuracy = 0.9883, Training Loss = 0.0841, Validation Accuracy = 0.2185, Validation Loss = 2.8575\n",
            "Epoch 1037/1667\n",
            "Epoch 1037: Training Accuracy = 0.9785, Training Loss = 0.1478, Validation Accuracy = 0.2171, Validation Loss = 2.8735\n",
            "Epoch 1038/1667\n",
            "Epoch 1038: Training Accuracy = 0.9785, Training Loss = 0.1478, Validation Accuracy = 0.2171, Validation Loss = 2.8735\n",
            "Epoch 1039/1667\n",
            "Epoch 1039: Training Accuracy = 0.7520, Training Loss = 1.2390, Validation Accuracy = 0.0956, Validation Loss = 3.9369\n",
            "Epoch 1040/1667\n",
            "Epoch 1040: Training Accuracy = 0.7520, Training Loss = 1.2390, Validation Accuracy = 0.0956, Validation Loss = 3.9369\n",
            "Epoch 1041/1667\n",
            "Epoch 1041: Training Accuracy = 0.9531, Training Loss = 0.4987, Validation Accuracy = 0.2317, Validation Loss = 2.7842\n",
            "Epoch 1042/1667\n",
            "Epoch 1042: Training Accuracy = 0.9844, Training Loss = 0.3059, Validation Accuracy = 0.2985, Validation Loss = 2.3923\n",
            "Epoch 1043/1667\n",
            "Epoch 1043: Training Accuracy = 0.9844, Training Loss = 0.3059, Validation Accuracy = 0.2985, Validation Loss = 2.3923\n",
            "Epoch 1044/1667\n",
            "Epoch 1044: Training Accuracy = 0.9844, Training Loss = 0.1820, Validation Accuracy = 0.3112, Validation Loss = 2.3166\n",
            "Epoch 1045/1667\n",
            "Epoch 1045: Training Accuracy = 0.9844, Training Loss = 0.1820, Validation Accuracy = 0.3112, Validation Loss = 2.3166\n",
            "Epoch 1046/1667\n",
            "Epoch 1046: Training Accuracy = 0.9941, Training Loss = 0.1075, Validation Accuracy = 0.3375, Validation Loss = 2.2385\n",
            "Epoch 1047/1667\n",
            "Epoch 1047: Training Accuracy = 0.9863, Training Loss = 0.1174, Validation Accuracy = 0.3411, Validation Loss = 2.2203\n",
            "Epoch 1048/1667\n",
            "Epoch 1048: Training Accuracy = 0.9863, Training Loss = 0.1174, Validation Accuracy = 0.3411, Validation Loss = 2.2203\n",
            "Epoch 1049/1667\n",
            "Epoch 1049: Training Accuracy = 0.9922, Training Loss = 0.0783, Validation Accuracy = 0.3422, Validation Loss = 2.2114\n",
            "Epoch 1050/1667\n",
            "Epoch 1050: Training Accuracy = 0.9922, Training Loss = 0.0783, Validation Accuracy = 0.3422, Validation Loss = 2.2114\n",
            "Epoch 1051/1667\n",
            "Epoch 1051: Training Accuracy = 0.9883, Training Loss = 0.0857, Validation Accuracy = 0.3376, Validation Loss = 2.2292\n",
            "Epoch 1052/1667\n",
            "Epoch 1052: Training Accuracy = 0.9883, Training Loss = 0.0909, Validation Accuracy = 0.3464, Validation Loss = 2.2289\n",
            "Epoch 1053/1667\n",
            "Epoch 1053: Training Accuracy = 0.9883, Training Loss = 0.0909, Validation Accuracy = 0.3464, Validation Loss = 2.2289\n",
            "Epoch 1054/1667\n",
            "Epoch 1054: Training Accuracy = 0.9824, Training Loss = 0.1059, Validation Accuracy = 0.3425, Validation Loss = 2.2416\n",
            "Epoch 1055/1667\n",
            "Epoch 1055: Training Accuracy = 0.9824, Training Loss = 0.1059, Validation Accuracy = 0.3425, Validation Loss = 2.2416\n",
            "Epoch 1056/1667\n",
            "Epoch 1056: Training Accuracy = 0.9922, Training Loss = 0.0764, Validation Accuracy = 0.3348, Validation Loss = 2.2541\n",
            "Epoch 1057/1667\n",
            "Epoch 1057: Training Accuracy = 0.9844, Training Loss = 0.1109, Validation Accuracy = 0.3422, Validation Loss = 2.2398\n",
            "Epoch 1058/1667\n",
            "Epoch 1058: Training Accuracy = 0.9844, Training Loss = 0.1109, Validation Accuracy = 0.3422, Validation Loss = 2.2398\n",
            "Epoch 1059/1667\n",
            "Epoch 1059: Training Accuracy = 0.9902, Training Loss = 0.0851, Validation Accuracy = 0.3378, Validation Loss = 2.2535\n",
            "Epoch 1060/1667\n",
            "Epoch 1060: Training Accuracy = 0.9902, Training Loss = 0.0851, Validation Accuracy = 0.3378, Validation Loss = 2.2535\n",
            "Epoch 1061/1667\n",
            "Epoch 1061: Training Accuracy = 0.9863, Training Loss = 0.1010, Validation Accuracy = 0.3446, Validation Loss = 2.2498\n",
            "Epoch 1062/1667\n",
            "Epoch 1062: Training Accuracy = 0.9902, Training Loss = 0.1048, Validation Accuracy = 0.3130, Validation Loss = 2.3668\n",
            "Epoch 1063/1667\n",
            "Epoch 1063: Training Accuracy = 0.9902, Training Loss = 0.1048, Validation Accuracy = 0.3130, Validation Loss = 2.3668\n",
            "Epoch 1064/1667\n",
            "Epoch 1064: Training Accuracy = 0.8320, Training Loss = 0.8684, Validation Accuracy = 0.2039, Validation Loss = 2.8405\n",
            "Epoch 1065/1667\n",
            "Epoch 1065: Training Accuracy = 0.8320, Training Loss = 0.8684, Validation Accuracy = 0.2039, Validation Loss = 2.8405\n",
            "Epoch 1066/1667\n",
            "Epoch 1066: Training Accuracy = 0.9570, Training Loss = 0.3942, Validation Accuracy = 0.3234, Validation Loss = 2.2360\n",
            "Epoch 1067/1667\n",
            "Epoch 1067: Training Accuracy = 0.9805, Training Loss = 0.2392, Validation Accuracy = 0.4006, Validation Loss = 1.9488\n",
            "Epoch 1068/1667\n",
            "Epoch 1068: Training Accuracy = 0.9805, Training Loss = 0.2392, Validation Accuracy = 0.4006, Validation Loss = 1.9488\n",
            "Epoch 1069/1667\n",
            "Epoch 1069: Training Accuracy = 0.9863, Training Loss = 0.1792, Validation Accuracy = 0.4339, Validation Loss = 1.8392\n",
            "Epoch 1070/1667\n",
            "Epoch 1070: Training Accuracy = 0.9863, Training Loss = 0.1792, Validation Accuracy = 0.4339, Validation Loss = 1.8392\n",
            "Epoch 1071/1667\n",
            "Epoch 1071: Training Accuracy = 0.9902, Training Loss = 0.1128, Validation Accuracy = 0.4462, Validation Loss = 1.7869\n",
            "Epoch 1072/1667\n",
            "Epoch 1072: Training Accuracy = 0.9844, Training Loss = 0.1247, Validation Accuracy = 0.4700, Validation Loss = 1.7299\n",
            "Epoch 1073/1667\n",
            "Epoch 1073: Training Accuracy = 0.9844, Training Loss = 0.1247, Validation Accuracy = 0.4700, Validation Loss = 1.7299\n",
            "Epoch 1074/1667\n",
            "Epoch 1074: Training Accuracy = 0.9805, Training Loss = 0.1350, Validation Accuracy = 0.4743, Validation Loss = 1.7211\n",
            "Epoch 1075/1667\n",
            "Epoch 1075: Training Accuracy = 0.9805, Training Loss = 0.1350, Validation Accuracy = 0.4743, Validation Loss = 1.7211\n",
            "Epoch 1076/1667\n",
            "Epoch 1076: Training Accuracy = 0.9902, Training Loss = 0.0844, Validation Accuracy = 0.4770, Validation Loss = 1.7052\n",
            "Epoch 1077/1667\n",
            "Epoch 1077: Training Accuracy = 0.9883, Training Loss = 0.0967, Validation Accuracy = 0.4855, Validation Loss = 1.7012\n",
            "Epoch 1078/1667\n",
            "Epoch 1078: Training Accuracy = 0.9883, Training Loss = 0.0967, Validation Accuracy = 0.4855, Validation Loss = 1.7012\n",
            "Epoch 1079/1667\n",
            "Epoch 1079: Training Accuracy = 0.9844, Training Loss = 0.1094, Validation Accuracy = 0.4772, Validation Loss = 1.7304\n",
            "Epoch 1080/1667\n",
            "Epoch 1080: Training Accuracy = 0.9844, Training Loss = 0.1094, Validation Accuracy = 0.4772, Validation Loss = 1.7304\n",
            "Epoch 1081/1667\n",
            "Epoch 1081: Training Accuracy = 0.9844, Training Loss = 0.1053, Validation Accuracy = 0.4852, Validation Loss = 1.7057\n",
            "Epoch 1082/1667\n",
            "Epoch 1082: Training Accuracy = 0.9805, Training Loss = 0.1252, Validation Accuracy = 0.4838, Validation Loss = 1.7072\n",
            "Epoch 1083/1667\n",
            "Epoch 1083: Training Accuracy = 0.9805, Training Loss = 0.1252, Validation Accuracy = 0.4838, Validation Loss = 1.7072\n",
            "Epoch 1084/1667\n",
            "Epoch 1084: Training Accuracy = 0.9883, Training Loss = 0.1069, Validation Accuracy = 0.4822, Validation Loss = 1.7124\n",
            "Epoch 1085/1667\n",
            "Epoch 1085: Training Accuracy = 0.9883, Training Loss = 0.1069, Validation Accuracy = 0.4822, Validation Loss = 1.7124\n",
            "Epoch 1086/1667\n",
            "Epoch 1086: Training Accuracy = 0.9961, Training Loss = 0.0725, Validation Accuracy = 0.4825, Validation Loss = 1.7183\n",
            "Epoch 1087/1667\n",
            "Epoch 1087: Training Accuracy = 0.9863, Training Loss = 0.1211, Validation Accuracy = 0.4794, Validation Loss = 1.7315\n",
            "Epoch 1088/1667\n",
            "Epoch 1088: Training Accuracy = 0.9863, Training Loss = 0.1211, Validation Accuracy = 0.4794, Validation Loss = 1.7315\n",
            "Epoch 1089/1667\n",
            "Epoch 1089: Training Accuracy = 0.9824, Training Loss = 0.1783, Validation Accuracy = 0.4535, Validation Loss = 1.8622\n",
            "Epoch 1090/1667\n",
            "Epoch 1090: Training Accuracy = 0.9824, Training Loss = 0.1783, Validation Accuracy = 0.4535, Validation Loss = 1.8622\n",
            "Epoch 1091/1667\n",
            "Epoch 1091: Training Accuracy = 0.9551, Training Loss = 0.4182, Validation Accuracy = 0.3738, Validation Loss = 2.1063\n",
            "Epoch 1092/1667\n",
            "Epoch 1092: Training Accuracy = 0.9648, Training Loss = 0.3071, Validation Accuracy = 0.4901, Validation Loss = 1.6909\n",
            "Epoch 1093/1667\n",
            "Epoch 1093: Training Accuracy = 0.9648, Training Loss = 0.3071, Validation Accuracy = 0.4901, Validation Loss = 1.6909\n",
            "Epoch 1094/1667\n",
            "Epoch 1094: Training Accuracy = 0.9805, Training Loss = 0.1876, Validation Accuracy = 0.5503, Validation Loss = 1.4954\n",
            "Epoch 1095/1667\n",
            "Epoch 1095: Training Accuracy = 0.9805, Training Loss = 0.1876, Validation Accuracy = 0.5503, Validation Loss = 1.4954\n",
            "Epoch 1096/1667\n",
            "Epoch 1096: Training Accuracy = 0.9922, Training Loss = 0.1019, Validation Accuracy = 0.5945, Validation Loss = 1.3667\n",
            "Epoch 1097/1667\n",
            "Epoch 1097: Training Accuracy = 0.9902, Training Loss = 0.0883, Validation Accuracy = 0.6291, Validation Loss = 1.2839\n",
            "Epoch 1098/1667\n",
            "Epoch 1098: Training Accuracy = 0.9902, Training Loss = 0.0883, Validation Accuracy = 0.6291, Validation Loss = 1.2839\n",
            "Epoch 1099/1667\n",
            "Epoch 1099: Training Accuracy = 0.9922, Training Loss = 0.0725, Validation Accuracy = 0.6467, Validation Loss = 1.2255\n",
            "Epoch 1100/1667\n",
            "Epoch 1100: Training Accuracy = 0.9922, Training Loss = 0.0725, Validation Accuracy = 0.6467, Validation Loss = 1.2255\n",
            "Epoch 1101/1667\n",
            "Epoch 1101: Training Accuracy = 0.9902, Training Loss = 0.0736, Validation Accuracy = 0.6504, Validation Loss = 1.2111\n",
            "Epoch 1102/1667\n",
            "Epoch 1102: Training Accuracy = 0.9805, Training Loss = 0.1130, Validation Accuracy = 0.6540, Validation Loss = 1.2126\n",
            "Epoch 1103/1667\n",
            "Epoch 1103: Training Accuracy = 0.9805, Training Loss = 0.1130, Validation Accuracy = 0.6540, Validation Loss = 1.2126\n",
            "Epoch 1104/1667\n",
            "Epoch 1104: Training Accuracy = 0.9922, Training Loss = 0.0671, Validation Accuracy = 0.6484, Validation Loss = 1.2256\n",
            "Epoch 1105/1667\n",
            "Epoch 1105: Training Accuracy = 0.9922, Training Loss = 0.0671, Validation Accuracy = 0.6484, Validation Loss = 1.2256\n",
            "Epoch 1106/1667\n",
            "Epoch 1106: Training Accuracy = 0.9844, Training Loss = 0.0900, Validation Accuracy = 0.6496, Validation Loss = 1.2226\n",
            "Epoch 1107/1667\n",
            "Epoch 1107: Training Accuracy = 0.9844, Training Loss = 0.0961, Validation Accuracy = 0.6630, Validation Loss = 1.2029\n",
            "Epoch 1108/1667\n",
            "Epoch 1108: Training Accuracy = 0.9844, Training Loss = 0.0961, Validation Accuracy = 0.6630, Validation Loss = 1.2029\n",
            "Epoch 1109/1667\n",
            "Epoch 1109: Training Accuracy = 0.9922, Training Loss = 0.0661, Validation Accuracy = 0.6425, Validation Loss = 1.2609\n",
            "Epoch 1110/1667\n",
            "Epoch 1110: Training Accuracy = 0.9922, Training Loss = 0.0661, Validation Accuracy = 0.6425, Validation Loss = 1.2609\n",
            "Epoch 1111/1667\n",
            "Epoch 1111: Training Accuracy = 0.9922, Training Loss = 0.0660, Validation Accuracy = 0.6625, Validation Loss = 1.2221\n",
            "Epoch 1112/1667\n",
            "Epoch 1112: Training Accuracy = 0.9883, Training Loss = 0.0922, Validation Accuracy = 0.6555, Validation Loss = 1.2223\n",
            "Epoch 1113/1667\n",
            "Epoch 1113: Training Accuracy = 0.9883, Training Loss = 0.0922, Validation Accuracy = 0.6555, Validation Loss = 1.2223\n",
            "Epoch 1114/1667\n",
            "Epoch 1114: Training Accuracy = 0.9824, Training Loss = 0.1357, Validation Accuracy = 0.6136, Validation Loss = 1.3609\n",
            "Epoch 1115/1667\n",
            "Epoch 1115: Training Accuracy = 0.9824, Training Loss = 0.1357, Validation Accuracy = 0.6136, Validation Loss = 1.3609\n",
            "Epoch 1116/1667\n",
            "Epoch 1116: Training Accuracy = 0.9824, Training Loss = 0.1707, Validation Accuracy = 0.5959, Validation Loss = 1.4033\n",
            "Epoch 1117/1667\n",
            "Epoch 1117: Training Accuracy = 0.9844, Training Loss = 0.1788, Validation Accuracy = 0.6220, Validation Loss = 1.3149\n",
            "Epoch 1118/1667\n",
            "Epoch 1118: Training Accuracy = 0.9844, Training Loss = 0.1788, Validation Accuracy = 0.6220, Validation Loss = 1.3149\n",
            "Epoch 1119/1667\n",
            "Epoch 1119: Training Accuracy = 0.9902, Training Loss = 0.1235, Validation Accuracy = 0.6772, Validation Loss = 1.1664\n",
            "Epoch 1120/1667\n",
            "Epoch 1120: Training Accuracy = 0.9902, Training Loss = 0.1235, Validation Accuracy = 0.6772, Validation Loss = 1.1664\n",
            "Epoch 1121/1667\n",
            "Epoch 1121: Training Accuracy = 0.9902, Training Loss = 0.0996, Validation Accuracy = 0.6818, Validation Loss = 1.1203\n",
            "Epoch 1122/1667\n",
            "Epoch 1122: Training Accuracy = 0.9883, Training Loss = 0.0977, Validation Accuracy = 0.7445, Validation Loss = 0.9518\n",
            "Epoch 1123/1667\n",
            "Epoch 1123: Training Accuracy = 0.9883, Training Loss = 0.0977, Validation Accuracy = 0.7445, Validation Loss = 0.9518\n",
            "Epoch 1124/1667\n",
            "Epoch 1124: Training Accuracy = 0.9844, Training Loss = 0.0956, Validation Accuracy = 0.7779, Validation Loss = 0.8650\n",
            "Epoch 1125/1667\n",
            "Epoch 1125: Training Accuracy = 0.9844, Training Loss = 0.0956, Validation Accuracy = 0.7779, Validation Loss = 0.8650\n",
            "Epoch 1126/1667\n",
            "Epoch 1126: Training Accuracy = 0.9883, Training Loss = 0.0747, Validation Accuracy = 0.7922, Validation Loss = 0.8284\n",
            "Epoch 1127/1667\n",
            "Epoch 1127: Training Accuracy = 0.9824, Training Loss = 0.0936, Validation Accuracy = 0.7985, Validation Loss = 0.7940\n",
            "Epoch 1128/1667\n",
            "Epoch 1128: Training Accuracy = 0.9824, Training Loss = 0.0936, Validation Accuracy = 0.7985, Validation Loss = 0.7940\n",
            "Epoch 1129/1667\n",
            "Epoch 1129: Training Accuracy = 0.9863, Training Loss = 0.0754, Validation Accuracy = 0.8124, Validation Loss = 0.7758\n",
            "Epoch 1130/1667\n",
            "Epoch 1130: Training Accuracy = 0.9863, Training Loss = 0.0754, Validation Accuracy = 0.8124, Validation Loss = 0.7758\n",
            "Epoch 1131/1667\n",
            "Epoch 1131: Training Accuracy = 0.9922, Training Loss = 0.0497, Validation Accuracy = 0.8168, Validation Loss = 0.7600\n",
            "Epoch 1132/1667\n",
            "Epoch 1132: Training Accuracy = 0.9844, Training Loss = 0.0843, Validation Accuracy = 0.8052, Validation Loss = 0.7861\n",
            "Epoch 1133/1667\n",
            "Epoch 1133: Training Accuracy = 0.9844, Training Loss = 0.0843, Validation Accuracy = 0.8052, Validation Loss = 0.7861\n",
            "Epoch 1134/1667\n",
            "Epoch 1134: Training Accuracy = 0.9844, Training Loss = 0.0794, Validation Accuracy = 0.8031, Validation Loss = 0.8011\n",
            "Epoch 1135/1667\n",
            "Epoch 1135: Training Accuracy = 0.9844, Training Loss = 0.0794, Validation Accuracy = 0.8031, Validation Loss = 0.8011\n",
            "Epoch 1136/1667\n",
            "Epoch 1136: Training Accuracy = 0.9824, Training Loss = 0.0946, Validation Accuracy = 0.8072, Validation Loss = 0.7785\n",
            "Epoch 1137/1667\n",
            "Epoch 1137: Training Accuracy = 0.9902, Training Loss = 0.0744, Validation Accuracy = 0.7919, Validation Loss = 0.8411\n",
            "Epoch 1138/1667\n",
            "Epoch 1138: Training Accuracy = 0.9902, Training Loss = 0.0744, Validation Accuracy = 0.7919, Validation Loss = 0.8411\n",
            "Epoch 1139/1667\n",
            "Epoch 1139: Training Accuracy = 0.6797, Training Loss = 1.3578, Validation Accuracy = 0.3698, Validation Loss = 2.2743\n",
            "Epoch 1140/1667\n",
            "Epoch 1140: Training Accuracy = 0.6797, Training Loss = 1.3578, Validation Accuracy = 0.3698, Validation Loss = 2.2743\n",
            "Epoch 1141/1667\n",
            "Epoch 1141: Training Accuracy = 0.9570, Training Loss = 0.3517, Validation Accuracy = 0.6505, Validation Loss = 1.2617\n",
            "Epoch 1142/1667\n",
            "Epoch 1142: Training Accuracy = 0.9922, Training Loss = 0.1805, Validation Accuracy = 0.8108, Validation Loss = 0.8290\n",
            "Epoch 1143/1667\n",
            "Epoch 1143: Training Accuracy = 0.9922, Training Loss = 0.1805, Validation Accuracy = 0.8108, Validation Loss = 0.8290\n",
            "Epoch 1144/1667\n",
            "Epoch 1144: Training Accuracy = 0.9902, Training Loss = 0.1154, Validation Accuracy = 0.8785, Validation Loss = 0.6398\n",
            "Epoch 1145/1667\n",
            "Epoch 1145: Training Accuracy = 0.9902, Training Loss = 0.1154, Validation Accuracy = 0.8785, Validation Loss = 0.6398\n",
            "Epoch 1146/1667\n",
            "Epoch 1146: Training Accuracy = 0.9863, Training Loss = 0.0981, Validation Accuracy = 0.9050, Validation Loss = 0.5554\n",
            "Epoch 1147/1667\n",
            "Epoch 1147: Training Accuracy = 0.9941, Training Loss = 0.0645, Validation Accuracy = 0.9194, Validation Loss = 0.5126\n",
            "Epoch 1148/1667\n",
            "Epoch 1148: Training Accuracy = 0.9941, Training Loss = 0.0645, Validation Accuracy = 0.9194, Validation Loss = 0.5126\n",
            "Epoch 1149/1667\n",
            "Epoch 1149: Training Accuracy = 0.9961, Training Loss = 0.0512, Validation Accuracy = 0.9229, Validation Loss = 0.4949\n",
            "Epoch 1150/1667\n",
            "Epoch 1150: Training Accuracy = 0.9961, Training Loss = 0.0512, Validation Accuracy = 0.9229, Validation Loss = 0.4949\n",
            "Epoch 1151/1667\n",
            "Epoch 1151: Training Accuracy = 0.9863, Training Loss = 0.0835, Validation Accuracy = 0.9217, Validation Loss = 0.4952\n",
            "Epoch 1152/1667\n",
            "Epoch 1152: Training Accuracy = 0.9844, Training Loss = 0.0929, Validation Accuracy = 0.9262, Validation Loss = 0.4870\n",
            "Epoch 1153/1667\n",
            "Epoch 1153: Training Accuracy = 0.9844, Training Loss = 0.0929, Validation Accuracy = 0.9262, Validation Loss = 0.4870\n",
            "Epoch 1154/1667\n",
            "Epoch 1154: Training Accuracy = 0.9883, Training Loss = 0.0817, Validation Accuracy = 0.9268, Validation Loss = 0.4869\n",
            "Epoch 1155/1667\n",
            "Epoch 1155: Training Accuracy = 0.9883, Training Loss = 0.0817, Validation Accuracy = 0.9268, Validation Loss = 0.4869\n",
            "Epoch 1156/1667\n",
            "Epoch 1156: Training Accuracy = 0.9902, Training Loss = 0.0670, Validation Accuracy = 0.9291, Validation Loss = 0.4885\n",
            "Epoch 1157/1667\n",
            "Epoch 1157: Training Accuracy = 0.9863, Training Loss = 0.0888, Validation Accuracy = 0.9245, Validation Loss = 0.4941\n",
            "Epoch 1158/1667\n",
            "Epoch 1158: Training Accuracy = 0.9863, Training Loss = 0.0888, Validation Accuracy = 0.9245, Validation Loss = 0.4941\n",
            "Epoch 1159/1667\n",
            "Epoch 1159: Training Accuracy = 0.9824, Training Loss = 0.1023, Validation Accuracy = 0.9265, Validation Loss = 0.4853\n",
            "Epoch 1160/1667\n",
            "Epoch 1160: Training Accuracy = 0.9824, Training Loss = 0.1023, Validation Accuracy = 0.9265, Validation Loss = 0.4853\n",
            "Epoch 1161/1667\n",
            "Epoch 1161: Training Accuracy = 0.9883, Training Loss = 0.0762, Validation Accuracy = 0.9323, Validation Loss = 0.4776\n",
            "Epoch 1162/1667\n",
            "Epoch 1162: Training Accuracy = 0.9902, Training Loss = 0.0715, Validation Accuracy = 0.9299, Validation Loss = 0.4823\n",
            "Epoch 1163/1667\n",
            "Epoch 1163: Training Accuracy = 0.9902, Training Loss = 0.0715, Validation Accuracy = 0.9299, Validation Loss = 0.4823\n",
            "Epoch 1164/1667\n",
            "Epoch 1164: Training Accuracy = 0.9844, Training Loss = 0.0921, Validation Accuracy = 0.9306, Validation Loss = 0.4881\n",
            "Epoch 1165/1667\n",
            "Epoch 1165: Training Accuracy = 0.9844, Training Loss = 0.0921, Validation Accuracy = 0.9306, Validation Loss = 0.4881\n",
            "Epoch 1166/1667\n",
            "Epoch 1166: Training Accuracy = 0.9902, Training Loss = 0.0681, Validation Accuracy = 0.9390, Validation Loss = 0.4634\n",
            "Epoch 1167/1667\n",
            "Epoch 1167: Training Accuracy = 0.9902, Training Loss = 0.0776, Validation Accuracy = 0.9332, Validation Loss = 0.4633\n",
            "Epoch 1168/1667\n",
            "Epoch 1168: Training Accuracy = 0.9902, Training Loss = 0.0776, Validation Accuracy = 0.9332, Validation Loss = 0.4633\n",
            "Epoch 1169/1667\n",
            "Epoch 1169: Training Accuracy = 0.9863, Training Loss = 0.0991, Validation Accuracy = 0.9220, Validation Loss = 0.5120\n",
            "Epoch 1170/1667\n",
            "Epoch 1170: Training Accuracy = 0.9863, Training Loss = 0.0991, Validation Accuracy = 0.9220, Validation Loss = 0.5120\n",
            "Epoch 1171/1667\n",
            "Epoch 1171: Training Accuracy = 0.8770, Training Loss = 0.6830, Validation Accuracy = 0.6678, Validation Loss = 1.3138\n",
            "Epoch 1172/1667\n",
            "Epoch 1172: Training Accuracy = 0.9805, Training Loss = 0.2665, Validation Accuracy = 0.8974, Validation Loss = 0.6389\n",
            "Epoch 1173/1667\n",
            "Epoch 1173: Training Accuracy = 0.9805, Training Loss = 0.2665, Validation Accuracy = 0.8974, Validation Loss = 0.6389\n",
            "Epoch 1174/1667\n",
            "Epoch 1174: Training Accuracy = 0.9824, Training Loss = 0.1734, Validation Accuracy = 0.9488, Validation Loss = 0.4643\n",
            "Epoch 1175/1667\n",
            "Epoch 1175: Training Accuracy = 0.9824, Training Loss = 0.1734, Validation Accuracy = 0.9488, Validation Loss = 0.4643\n",
            "Epoch 1176/1667\n",
            "Epoch 1176: Training Accuracy = 0.9922, Training Loss = 0.0894, Validation Accuracy = 0.9619, Validation Loss = 0.3713\n",
            "Epoch 1177/1667\n",
            "Epoch 1177: Training Accuracy = 0.9805, Training Loss = 0.1215, Validation Accuracy = 0.9750, Validation Loss = 0.3205\n",
            "Epoch 1178/1667\n",
            "Epoch 1178: Training Accuracy = 0.9805, Training Loss = 0.1215, Validation Accuracy = 0.9750, Validation Loss = 0.3205\n",
            "Epoch 1179/1667\n",
            "Epoch 1179: Training Accuracy = 0.9902, Training Loss = 0.0748, Validation Accuracy = 0.9769, Validation Loss = 0.3007\n",
            "Epoch 1180/1667\n",
            "Epoch 1180: Training Accuracy = 0.9902, Training Loss = 0.0748, Validation Accuracy = 0.9769, Validation Loss = 0.3007\n",
            "Epoch 1181/1667\n",
            "Epoch 1181: Training Accuracy = 0.9941, Training Loss = 0.0560, Validation Accuracy = 0.9774, Validation Loss = 0.2948\n",
            "Epoch 1182/1667\n",
            "Epoch 1182: Training Accuracy = 0.9922, Training Loss = 0.0624, Validation Accuracy = 0.9771, Validation Loss = 0.2922\n",
            "Epoch 1183/1667\n",
            "Epoch 1183: Training Accuracy = 0.9922, Training Loss = 0.0624, Validation Accuracy = 0.9771, Validation Loss = 0.2922\n",
            "Epoch 1184/1667\n",
            "Epoch 1184: Training Accuracy = 0.9941, Training Loss = 0.0553, Validation Accuracy = 0.9765, Validation Loss = 0.2967\n",
            "Epoch 1185/1667\n",
            "Epoch 1185: Training Accuracy = 0.9941, Training Loss = 0.0553, Validation Accuracy = 0.9765, Validation Loss = 0.2967\n",
            "Epoch 1186/1667\n",
            "Epoch 1186: Training Accuracy = 0.9941, Training Loss = 0.0538, Validation Accuracy = 0.9783, Validation Loss = 0.2940\n",
            "Epoch 1187/1667\n",
            "Epoch 1187: Training Accuracy = 0.9922, Training Loss = 0.0640, Validation Accuracy = 0.9725, Validation Loss = 0.3044\n",
            "Epoch 1188/1667\n",
            "Epoch 1188: Training Accuracy = 0.9922, Training Loss = 0.0640, Validation Accuracy = 0.9725, Validation Loss = 0.3044\n",
            "Epoch 1189/1667\n",
            "Epoch 1189: Training Accuracy = 0.9863, Training Loss = 0.0858, Validation Accuracy = 0.9768, Validation Loss = 0.3021\n",
            "Epoch 1190/1667\n",
            "Epoch 1190: Training Accuracy = 0.9863, Training Loss = 0.0858, Validation Accuracy = 0.9768, Validation Loss = 0.3021\n",
            "Epoch 1191/1667\n",
            "Epoch 1191: Training Accuracy = 0.9902, Training Loss = 0.0705, Validation Accuracy = 0.9771, Validation Loss = 0.2968\n",
            "Epoch 1192/1667\n",
            "Epoch 1192: Training Accuracy = 0.9805, Training Loss = 0.1106, Validation Accuracy = 0.9743, Validation Loss = 0.3087\n",
            "Epoch 1193/1667\n",
            "Epoch 1193: Training Accuracy = 0.9805, Training Loss = 0.1106, Validation Accuracy = 0.9743, Validation Loss = 0.3087\n",
            "Epoch 1194/1667\n",
            "Epoch 1194: Training Accuracy = 0.9941, Training Loss = 0.0566, Validation Accuracy = 0.9777, Validation Loss = 0.2847\n",
            "Epoch 1195/1667\n",
            "Epoch 1195: Training Accuracy = 0.9941, Training Loss = 0.0566, Validation Accuracy = 0.9777, Validation Loss = 0.2847\n",
            "Epoch 1196/1667\n",
            "Epoch 1196: Training Accuracy = 0.9902, Training Loss = 0.0726, Validation Accuracy = 0.9731, Validation Loss = 0.2972\n",
            "Epoch 1197/1667\n",
            "Epoch 1197: Training Accuracy = 0.9902, Training Loss = 0.0746, Validation Accuracy = 0.9781, Validation Loss = 0.2811\n",
            "Epoch 1198/1667\n",
            "Epoch 1198: Training Accuracy = 0.9902, Training Loss = 0.0746, Validation Accuracy = 0.9781, Validation Loss = 0.2811\n",
            "Epoch 1199/1667\n",
            "Epoch 1199: Training Accuracy = 0.9883, Training Loss = 0.0824, Validation Accuracy = 0.9651, Validation Loss = 0.3261\n",
            "Epoch 1200/1667\n",
            "Epoch 1200: Training Accuracy = 0.9883, Training Loss = 0.0824, Validation Accuracy = 0.9651, Validation Loss = 0.3261\n",
            "Epoch 1201/1667\n",
            "Epoch 1201: Training Accuracy = 0.8105, Training Loss = 0.9470, Validation Accuracy = 0.6656, Validation Loss = 1.3976\n",
            "Epoch 1202/1667\n",
            "Epoch 1202: Training Accuracy = 0.9648, Training Loss = 0.3743, Validation Accuracy = 0.9112, Validation Loss = 0.6036\n",
            "Epoch 1203/1667\n",
            "Epoch 1203: Training Accuracy = 0.9648, Training Loss = 0.3743, Validation Accuracy = 0.9112, Validation Loss = 0.6036\n",
            "Epoch 1204/1667\n",
            "Epoch 1204: Training Accuracy = 0.9824, Training Loss = 0.2103, Validation Accuracy = 0.9707, Validation Loss = 0.3775\n",
            "Epoch 1205/1667\n",
            "Epoch 1205: Training Accuracy = 0.9824, Training Loss = 0.2103, Validation Accuracy = 0.9707, Validation Loss = 0.3775\n",
            "Epoch 1206/1667\n",
            "Epoch 1206: Training Accuracy = 0.9844, Training Loss = 0.1413, Validation Accuracy = 0.9828, Validation Loss = 0.2837\n",
            "Epoch 1207/1667\n",
            "Epoch 1207: Training Accuracy = 0.9922, Training Loss = 0.0843, Validation Accuracy = 0.9876, Validation Loss = 0.2302\n",
            "Epoch 1208/1667\n",
            "Epoch 1208: Training Accuracy = 0.9922, Training Loss = 0.0843, Validation Accuracy = 0.9876, Validation Loss = 0.2302\n",
            "Epoch 1209/1667\n",
            "Epoch 1209: Training Accuracy = 0.9941, Training Loss = 0.0646, Validation Accuracy = 0.9883, Validation Loss = 0.2146\n",
            "Epoch 1210/1667\n",
            "Epoch 1210: Training Accuracy = 0.9941, Training Loss = 0.0646, Validation Accuracy = 0.9883, Validation Loss = 0.2146\n",
            "Epoch 1211/1667\n",
            "Epoch 1211: Training Accuracy = 0.9941, Training Loss = 0.0575, Validation Accuracy = 0.9882, Validation Loss = 0.2006\n",
            "Epoch 1212/1667\n",
            "Epoch 1212: Training Accuracy = 0.9863, Training Loss = 0.0944, Validation Accuracy = 0.9889, Validation Loss = 0.1933\n",
            "Epoch 1213/1667\n",
            "Epoch 1213: Training Accuracy = 0.9863, Training Loss = 0.0944, Validation Accuracy = 0.9889, Validation Loss = 0.1933\n",
            "Epoch 1214/1667\n",
            "Epoch 1214: Training Accuracy = 0.9883, Training Loss = 0.0792, Validation Accuracy = 0.9889, Validation Loss = 0.1925\n",
            "Epoch 1215/1667\n",
            "Epoch 1215: Training Accuracy = 0.9883, Training Loss = 0.0792, Validation Accuracy = 0.9889, Validation Loss = 0.1925\n",
            "Epoch 1216/1667\n",
            "Epoch 1216: Training Accuracy = 0.9883, Training Loss = 0.0767, Validation Accuracy = 0.9888, Validation Loss = 0.1950\n",
            "Epoch 1217/1667\n",
            "Epoch 1217: Training Accuracy = 0.9844, Training Loss = 0.0917, Validation Accuracy = 0.9894, Validation Loss = 0.1897\n",
            "Epoch 1218/1667\n",
            "Epoch 1218: Training Accuracy = 0.9844, Training Loss = 0.0917, Validation Accuracy = 0.9894, Validation Loss = 0.1897\n",
            "Epoch 1219/1667\n",
            "Epoch 1219: Training Accuracy = 0.9941, Training Loss = 0.0543, Validation Accuracy = 0.9900, Validation Loss = 0.1863\n",
            "Epoch 1220/1667\n",
            "Epoch 1220: Training Accuracy = 0.9941, Training Loss = 0.0543, Validation Accuracy = 0.9900, Validation Loss = 0.1863\n",
            "Epoch 1221/1667\n",
            "Epoch 1221: Training Accuracy = 0.9922, Training Loss = 0.0625, Validation Accuracy = 0.9898, Validation Loss = 0.1835\n",
            "Epoch 1222/1667\n",
            "Epoch 1222: Training Accuracy = 0.9961, Training Loss = 0.0485, Validation Accuracy = 0.9898, Validation Loss = 0.1853\n",
            "Epoch 1223/1667\n",
            "Epoch 1223: Training Accuracy = 0.9961, Training Loss = 0.0485, Validation Accuracy = 0.9898, Validation Loss = 0.1853\n",
            "Epoch 1224/1667\n",
            "Epoch 1224: Training Accuracy = 0.9922, Training Loss = 0.0617, Validation Accuracy = 0.9895, Validation Loss = 0.1822\n",
            "Epoch 1225/1667\n",
            "Epoch 1225: Training Accuracy = 0.9922, Training Loss = 0.0617, Validation Accuracy = 0.9895, Validation Loss = 0.1822\n",
            "Epoch 1226/1667\n",
            "Epoch 1226: Training Accuracy = 0.9844, Training Loss = 0.0893, Validation Accuracy = 0.9900, Validation Loss = 0.1804\n",
            "Epoch 1227/1667\n",
            "Epoch 1227: Training Accuracy = 0.9883, Training Loss = 0.0807, Validation Accuracy = 0.9891, Validation Loss = 0.1974\n",
            "Epoch 1228/1667\n",
            "Epoch 1228: Training Accuracy = 0.9883, Training Loss = 0.0807, Validation Accuracy = 0.9891, Validation Loss = 0.1974\n",
            "Epoch 1229/1667\n",
            "Epoch 1229: Training Accuracy = 0.8008, Training Loss = 1.2552, Validation Accuracy = 0.6643, Validation Loss = 1.4700\n",
            "Epoch 1230/1667\n",
            "Epoch 1230: Training Accuracy = 0.8008, Training Loss = 1.2552, Validation Accuracy = 0.6643, Validation Loss = 1.4700\n",
            "Epoch 1231/1667\n",
            "Epoch 1231: Training Accuracy = 0.9844, Training Loss = 0.3279, Validation Accuracy = 0.9494, Validation Loss = 0.5048\n",
            "Epoch 1232/1667\n",
            "Epoch 1232: Training Accuracy = 0.9844, Training Loss = 0.1857, Validation Accuracy = 0.9853, Validation Loss = 0.2849\n",
            "Epoch 1233/1667\n",
            "Epoch 1233: Training Accuracy = 0.9844, Training Loss = 0.1857, Validation Accuracy = 0.9853, Validation Loss = 0.2849\n",
            "Epoch 1234/1667\n",
            "Epoch 1234: Training Accuracy = 0.9844, Training Loss = 0.1242, Validation Accuracy = 0.9894, Validation Loss = 0.1962\n",
            "Epoch 1235/1667\n",
            "Epoch 1235: Training Accuracy = 0.9844, Training Loss = 0.1242, Validation Accuracy = 0.9894, Validation Loss = 0.1962\n",
            "Epoch 1236/1667\n",
            "Epoch 1236: Training Accuracy = 0.9902, Training Loss = 0.0796, Validation Accuracy = 0.9901, Validation Loss = 0.1550\n",
            "Epoch 1237/1667\n",
            "Epoch 1237: Training Accuracy = 0.9824, Training Loss = 0.1072, Validation Accuracy = 0.9904, Validation Loss = 0.1410\n",
            "Epoch 1238/1667\n",
            "Epoch 1238: Training Accuracy = 0.9824, Training Loss = 0.1072, Validation Accuracy = 0.9904, Validation Loss = 0.1410\n",
            "Epoch 1239/1667\n",
            "Epoch 1239: Training Accuracy = 0.9941, Training Loss = 0.0532, Validation Accuracy = 0.9901, Validation Loss = 0.1381\n",
            "Epoch 1240/1667\n",
            "Epoch 1240: Training Accuracy = 0.9941, Training Loss = 0.0532, Validation Accuracy = 0.9901, Validation Loss = 0.1381\n",
            "Epoch 1241/1667\n",
            "Epoch 1241: Training Accuracy = 0.9883, Training Loss = 0.0767, Validation Accuracy = 0.9904, Validation Loss = 0.1359\n",
            "Epoch 1242/1667\n",
            "Epoch 1242: Training Accuracy = 0.9824, Training Loss = 0.0991, Validation Accuracy = 0.9903, Validation Loss = 0.1335\n",
            "Epoch 1243/1667\n",
            "Epoch 1243: Training Accuracy = 0.9824, Training Loss = 0.0991, Validation Accuracy = 0.9903, Validation Loss = 0.1335\n",
            "Epoch 1244/1667\n",
            "Epoch 1244: Training Accuracy = 0.9902, Training Loss = 0.0690, Validation Accuracy = 0.9904, Validation Loss = 0.1324\n",
            "Epoch 1245/1667\n",
            "Epoch 1245: Training Accuracy = 0.9902, Training Loss = 0.0690, Validation Accuracy = 0.9904, Validation Loss = 0.1324\n",
            "Epoch 1246/1667\n",
            "Epoch 1246: Training Accuracy = 0.9883, Training Loss = 0.0803, Validation Accuracy = 0.9904, Validation Loss = 0.1316\n",
            "Epoch 1247/1667\n",
            "Epoch 1247: Training Accuracy = 0.9844, Training Loss = 0.0887, Validation Accuracy = 0.9904, Validation Loss = 0.1320\n",
            "Epoch 1248/1667\n",
            "Epoch 1248: Training Accuracy = 0.9844, Training Loss = 0.0887, Validation Accuracy = 0.9904, Validation Loss = 0.1320\n",
            "Epoch 1249/1667\n",
            "Epoch 1249: Training Accuracy = 0.9922, Training Loss = 0.0618, Validation Accuracy = 0.9904, Validation Loss = 0.1310\n",
            "Epoch 1250/1667\n",
            "Epoch 1250: Training Accuracy = 0.9922, Training Loss = 0.0618, Validation Accuracy = 0.9904, Validation Loss = 0.1310\n",
            "Epoch 1251/1667\n",
            "Epoch 1251: Training Accuracy = 0.9883, Training Loss = 0.0705, Validation Accuracy = 0.9904, Validation Loss = 0.1307\n",
            "Epoch 1252/1667\n",
            "Epoch 1252: Training Accuracy = 0.9824, Training Loss = 0.0978, Validation Accuracy = 0.9904, Validation Loss = 0.1252\n",
            "Epoch 1253/1667\n",
            "Epoch 1253: Training Accuracy = 0.9824, Training Loss = 0.0978, Validation Accuracy = 0.9904, Validation Loss = 0.1252\n",
            "Epoch 1254/1667\n",
            "Epoch 1254: Training Accuracy = 0.9824, Training Loss = 0.1006, Validation Accuracy = 0.9904, Validation Loss = 0.1303\n",
            "Epoch 1255/1667\n",
            "Epoch 1255: Training Accuracy = 0.9824, Training Loss = 0.1006, Validation Accuracy = 0.9904, Validation Loss = 0.1303\n",
            "Epoch 1256/1667\n",
            "Epoch 1256: Training Accuracy = 0.9883, Training Loss = 0.0699, Validation Accuracy = 0.9904, Validation Loss = 0.1247\n",
            "Epoch 1257/1667\n",
            "Epoch 1257: Training Accuracy = 0.9863, Training Loss = 0.0874, Validation Accuracy = 0.9903, Validation Loss = 0.1643\n",
            "Epoch 1258/1667\n",
            "Epoch 1258: Training Accuracy = 0.9863, Training Loss = 0.0874, Validation Accuracy = 0.9903, Validation Loss = 0.1643\n",
            "Epoch 1259/1667\n",
            "Epoch 1259: Training Accuracy = 0.9434, Training Loss = 0.5828, Validation Accuracy = 0.9353, Validation Loss = 0.6905\n",
            "Epoch 1260/1667\n",
            "Epoch 1260: Training Accuracy = 0.9434, Training Loss = 0.5828, Validation Accuracy = 0.9353, Validation Loss = 0.6905\n",
            "Epoch 1261/1667\n",
            "Epoch 1261: Training Accuracy = 0.9863, Training Loss = 0.2127, Validation Accuracy = 0.9844, Validation Loss = 0.3186\n",
            "Epoch 1262/1667\n",
            "Epoch 1262: Training Accuracy = 0.9922, Training Loss = 0.1053, Validation Accuracy = 0.9889, Validation Loss = 0.1908\n",
            "Epoch 1263/1667\n",
            "Epoch 1263: Training Accuracy = 0.9922, Training Loss = 0.1053, Validation Accuracy = 0.9889, Validation Loss = 0.1908\n",
            "Epoch 1264/1667\n",
            "Epoch 1264: Training Accuracy = 0.9844, Training Loss = 0.1061, Validation Accuracy = 0.9903, Validation Loss = 0.1433\n",
            "Epoch 1265/1667\n",
            "Epoch 1265: Training Accuracy = 0.9844, Training Loss = 0.1061, Validation Accuracy = 0.9903, Validation Loss = 0.1433\n",
            "Epoch 1266/1667\n",
            "Epoch 1266: Training Accuracy = 0.9922, Training Loss = 0.0672, Validation Accuracy = 0.9904, Validation Loss = 0.1219\n",
            "Epoch 1267/1667\n",
            "Epoch 1267: Training Accuracy = 0.9922, Training Loss = 0.0605, Validation Accuracy = 0.9904, Validation Loss = 0.1132\n",
            "Epoch 1268/1667\n",
            "Epoch 1268: Training Accuracy = 0.9922, Training Loss = 0.0605, Validation Accuracy = 0.9904, Validation Loss = 0.1132\n",
            "Epoch 1269/1667\n",
            "Epoch 1269: Training Accuracy = 0.9922, Training Loss = 0.0565, Validation Accuracy = 0.9904, Validation Loss = 0.1110\n",
            "Epoch 1270/1667\n",
            "Epoch 1270: Training Accuracy = 0.9922, Training Loss = 0.0565, Validation Accuracy = 0.9904, Validation Loss = 0.1110\n",
            "Epoch 1271/1667\n",
            "Epoch 1271: Training Accuracy = 0.9863, Training Loss = 0.0776, Validation Accuracy = 0.9904, Validation Loss = 0.1124\n",
            "Epoch 1272/1667\n",
            "Epoch 1272: Training Accuracy = 0.9941, Training Loss = 0.0508, Validation Accuracy = 0.9904, Validation Loss = 0.1118\n",
            "Epoch 1273/1667\n",
            "Epoch 1273: Training Accuracy = 0.9941, Training Loss = 0.0508, Validation Accuracy = 0.9904, Validation Loss = 0.1118\n",
            "Epoch 1274/1667\n",
            "Epoch 1274: Training Accuracy = 0.9883, Training Loss = 0.0712, Validation Accuracy = 0.9904, Validation Loss = 0.1112\n",
            "Epoch 1275/1667\n",
            "Epoch 1275: Training Accuracy = 0.9883, Training Loss = 0.0712, Validation Accuracy = 0.9904, Validation Loss = 0.1112\n",
            "Epoch 1276/1667\n",
            "Epoch 1276: Training Accuracy = 0.9980, Training Loss = 0.0350, Validation Accuracy = 0.9904, Validation Loss = 0.1114\n",
            "Epoch 1277/1667\n",
            "Epoch 1277: Training Accuracy = 0.9883, Training Loss = 0.0739, Validation Accuracy = 0.9904, Validation Loss = 0.1108\n",
            "Epoch 1278/1667\n",
            "Epoch 1278: Training Accuracy = 0.9883, Training Loss = 0.0739, Validation Accuracy = 0.9904, Validation Loss = 0.1108\n",
            "Epoch 1279/1667\n",
            "Epoch 1279: Training Accuracy = 0.9863, Training Loss = 0.0802, Validation Accuracy = 0.9904, Validation Loss = 0.1108\n",
            "Epoch 1280/1667\n",
            "Epoch 1280: Training Accuracy = 0.9863, Training Loss = 0.0802, Validation Accuracy = 0.9904, Validation Loss = 0.1108\n",
            "Epoch 1281/1667\n",
            "Epoch 1281: Training Accuracy = 0.9785, Training Loss = 0.1052, Validation Accuracy = 0.9904, Validation Loss = 0.1102\n",
            "Epoch 1282/1667\n",
            "Epoch 1282: Training Accuracy = 0.9922, Training Loss = 0.0542, Validation Accuracy = 0.9904, Validation Loss = 0.1074\n",
            "Epoch 1283/1667\n",
            "Epoch 1283: Training Accuracy = 0.9922, Training Loss = 0.0542, Validation Accuracy = 0.9904, Validation Loss = 0.1074\n",
            "Epoch 1284/1667\n",
            "Epoch 1284: Training Accuracy = 0.9941, Training Loss = 0.0568, Validation Accuracy = 0.9904, Validation Loss = 0.1087\n",
            "Epoch 1285/1667\n",
            "Epoch 1285: Training Accuracy = 0.9941, Training Loss = 0.0568, Validation Accuracy = 0.9904, Validation Loss = 0.1087\n",
            "Epoch 1286/1667\n",
            "Epoch 1286: Training Accuracy = 0.9863, Training Loss = 0.0845, Validation Accuracy = 0.9904, Validation Loss = 0.1159\n",
            "Epoch 1287/1667\n",
            "Epoch 1287: Training Accuracy = 0.9883, Training Loss = 0.0702, Validation Accuracy = 0.9904, Validation Loss = 0.1113\n",
            "Epoch 1288/1667\n",
            "Epoch 1288: Training Accuracy = 0.9883, Training Loss = 0.0702, Validation Accuracy = 0.9904, Validation Loss = 0.1113\n",
            "Epoch 1289/1667\n",
            "Epoch 1289: Training Accuracy = 0.9844, Training Loss = 0.0886, Validation Accuracy = 0.9904, Validation Loss = 0.1056\n",
            "Epoch 1290/1667\n",
            "Epoch 1290: Training Accuracy = 0.9844, Training Loss = 0.0886, Validation Accuracy = 0.9904, Validation Loss = 0.1056\n",
            "Epoch 1291/1667\n",
            "Epoch 1291: Training Accuracy = 0.9883, Training Loss = 0.0651, Validation Accuracy = 0.9904, Validation Loss = 0.1075\n",
            "Epoch 1292/1667\n",
            "Epoch 1292: Training Accuracy = 0.9844, Training Loss = 0.0829, Validation Accuracy = 0.9904, Validation Loss = 0.1082\n",
            "Epoch 1293/1667\n",
            "Epoch 1293: Training Accuracy = 0.9844, Training Loss = 0.0829, Validation Accuracy = 0.9904, Validation Loss = 0.1082\n",
            "Epoch 1294/1667\n",
            "Epoch 1294: Training Accuracy = 0.9805, Training Loss = 0.0973, Validation Accuracy = 0.9904, Validation Loss = 0.1105\n",
            "Epoch 1295/1667\n",
            "Epoch 1295: Training Accuracy = 0.9805, Training Loss = 0.0973, Validation Accuracy = 0.9904, Validation Loss = 0.1105\n",
            "Epoch 1296/1667\n",
            "Epoch 1296: Training Accuracy = 0.9941, Training Loss = 0.0583, Validation Accuracy = 0.9904, Validation Loss = 0.1434\n",
            "Epoch 1297/1667\n",
            "Epoch 1297: Training Accuracy = 0.8926, Training Loss = 0.6654, Validation Accuracy = 0.9104, Validation Loss = 0.6825\n",
            "Epoch 1298/1667\n",
            "Epoch 1298: Training Accuracy = 0.8926, Training Loss = 0.6654, Validation Accuracy = 0.9104, Validation Loss = 0.6825\n",
            "Epoch 1299/1667\n",
            "Epoch 1299: Training Accuracy = 0.9902, Training Loss = 0.2235, Validation Accuracy = 0.9781, Validation Loss = 0.3333\n",
            "Epoch 1300/1667\n",
            "Epoch 1300: Training Accuracy = 0.9902, Training Loss = 0.2235, Validation Accuracy = 0.9781, Validation Loss = 0.3333\n",
            "Epoch 1301/1667\n",
            "Epoch 1301: Training Accuracy = 0.9824, Training Loss = 0.1483, Validation Accuracy = 0.9901, Validation Loss = 0.1792\n",
            "Epoch 1302/1667\n",
            "Epoch 1302: Training Accuracy = 0.9902, Training Loss = 0.0866, Validation Accuracy = 0.9904, Validation Loss = 0.1275\n",
            "Epoch 1303/1667\n",
            "Epoch 1303: Training Accuracy = 0.9902, Training Loss = 0.0866, Validation Accuracy = 0.9904, Validation Loss = 0.1275\n",
            "Epoch 1304/1667\n",
            "Epoch 1304: Training Accuracy = 0.9902, Training Loss = 0.0660, Validation Accuracy = 0.9904, Validation Loss = 0.1125\n",
            "Epoch 1305/1667\n",
            "Epoch 1305: Training Accuracy = 0.9902, Training Loss = 0.0660, Validation Accuracy = 0.9904, Validation Loss = 0.1125\n",
            "Epoch 1306/1667\n",
            "Epoch 1306: Training Accuracy = 0.9883, Training Loss = 0.0715, Validation Accuracy = 0.9904, Validation Loss = 0.1029\n",
            "Epoch 1307/1667\n",
            "Epoch 1307: Training Accuracy = 0.9902, Training Loss = 0.0624, Validation Accuracy = 0.9904, Validation Loss = 0.0995\n",
            "Epoch 1308/1667\n",
            "Epoch 1308: Training Accuracy = 0.9902, Training Loss = 0.0624, Validation Accuracy = 0.9904, Validation Loss = 0.0995\n",
            "Epoch 1309/1667\n",
            "Epoch 1309: Training Accuracy = 0.9902, Training Loss = 0.0607, Validation Accuracy = 0.9904, Validation Loss = 0.1004\n",
            "Epoch 1310/1667\n",
            "Epoch 1310: Training Accuracy = 0.9902, Training Loss = 0.0607, Validation Accuracy = 0.9904, Validation Loss = 0.1004\n",
            "Epoch 1311/1667\n",
            "Epoch 1311: Training Accuracy = 0.9941, Training Loss = 0.0460, Validation Accuracy = 0.9904, Validation Loss = 0.0999\n",
            "Epoch 1312/1667\n",
            "Epoch 1312: Training Accuracy = 0.9824, Training Loss = 0.0915, Validation Accuracy = 0.9904, Validation Loss = 0.0988\n",
            "Epoch 1313/1667\n",
            "Epoch 1313: Training Accuracy = 0.9824, Training Loss = 0.0915, Validation Accuracy = 0.9904, Validation Loss = 0.0988\n",
            "Epoch 1314/1667\n",
            "Epoch 1314: Training Accuracy = 0.9863, Training Loss = 0.0753, Validation Accuracy = 0.9904, Validation Loss = 0.1001\n",
            "Epoch 1315/1667\n",
            "Epoch 1315: Training Accuracy = 0.9863, Training Loss = 0.0753, Validation Accuracy = 0.9904, Validation Loss = 0.1001\n",
            "Epoch 1316/1667\n",
            "Epoch 1316: Training Accuracy = 0.9883, Training Loss = 0.0701, Validation Accuracy = 0.9904, Validation Loss = 0.0999\n",
            "Epoch 1317/1667\n",
            "Epoch 1317: Training Accuracy = 0.9922, Training Loss = 0.0538, Validation Accuracy = 0.9904, Validation Loss = 0.0997\n",
            "Epoch 1318/1667\n",
            "Epoch 1318: Training Accuracy = 0.9922, Training Loss = 0.0538, Validation Accuracy = 0.9904, Validation Loss = 0.0997\n",
            "Epoch 1319/1667\n",
            "Epoch 1319: Training Accuracy = 0.9883, Training Loss = 0.0676, Validation Accuracy = 0.9904, Validation Loss = 0.0988\n",
            "Epoch 1320/1667\n",
            "Epoch 1320: Training Accuracy = 0.9883, Training Loss = 0.0676, Validation Accuracy = 0.9904, Validation Loss = 0.0988\n",
            "Epoch 1321/1667\n",
            "Epoch 1321: Training Accuracy = 0.9922, Training Loss = 0.0532, Validation Accuracy = 0.9904, Validation Loss = 0.0971\n",
            "Epoch 1322/1667\n",
            "Epoch 1322: Training Accuracy = 0.9961, Training Loss = 0.0385, Validation Accuracy = 0.9904, Validation Loss = 0.0963\n",
            "Epoch 1323/1667\n",
            "Epoch 1323: Training Accuracy = 0.9961, Training Loss = 0.0385, Validation Accuracy = 0.9904, Validation Loss = 0.0963\n",
            "Epoch 1324/1667\n",
            "Epoch 1324: Training Accuracy = 0.9863, Training Loss = 0.0721, Validation Accuracy = 0.9904, Validation Loss = 0.0983\n",
            "Epoch 1325/1667\n",
            "Epoch 1325: Training Accuracy = 0.9863, Training Loss = 0.0721, Validation Accuracy = 0.9904, Validation Loss = 0.0983\n",
            "Epoch 1326/1667\n",
            "Epoch 1326: Training Accuracy = 0.9863, Training Loss = 0.0703, Validation Accuracy = 0.9904, Validation Loss = 0.0954\n",
            "Epoch 1327/1667\n",
            "Epoch 1327: Training Accuracy = 0.9863, Training Loss = 0.0797, Validation Accuracy = 0.9904, Validation Loss = 0.0957\n",
            "Epoch 1328/1667\n",
            "Epoch 1328: Training Accuracy = 0.9863, Training Loss = 0.0797, Validation Accuracy = 0.9904, Validation Loss = 0.0957\n",
            "Epoch 1329/1667\n",
            "Epoch 1329: Training Accuracy = 0.3887, Training Loss = 2.2824, Validation Accuracy = 0.2740, Validation Loss = 2.9732\n",
            "Epoch 1330/1667\n",
            "Epoch 1330: Training Accuracy = 0.3887, Training Loss = 2.2824, Validation Accuracy = 0.2740, Validation Loss = 2.9732\n",
            "Epoch 1331/1667\n",
            "Epoch 1331: Training Accuracy = 0.9023, Training Loss = 0.6854, Validation Accuracy = 0.8764, Validation Loss = 0.8295\n",
            "Epoch 1332/1667\n",
            "Epoch 1332: Training Accuracy = 0.9844, Training Loss = 0.2648, Validation Accuracy = 0.9789, Validation Loss = 0.3269\n",
            "Epoch 1333/1667\n",
            "Epoch 1333: Training Accuracy = 0.9844, Training Loss = 0.2648, Validation Accuracy = 0.9789, Validation Loss = 0.3269\n",
            "Epoch 1334/1667\n",
            "Epoch 1334: Training Accuracy = 0.9863, Training Loss = 0.1438, Validation Accuracy = 0.9903, Validation Loss = 0.1858\n",
            "Epoch 1335/1667\n",
            "Epoch 1335: Training Accuracy = 0.9863, Training Loss = 0.1438, Validation Accuracy = 0.9903, Validation Loss = 0.1858\n",
            "Epoch 1336/1667\n",
            "Epoch 1336: Training Accuracy = 0.9844, Training Loss = 0.1071, Validation Accuracy = 0.9904, Validation Loss = 0.1289\n",
            "Epoch 1337/1667\n",
            "Epoch 1337: Training Accuracy = 0.9844, Training Loss = 0.0967, Validation Accuracy = 0.9904, Validation Loss = 0.1129\n",
            "Epoch 1338/1667\n",
            "Epoch 1338: Training Accuracy = 0.9844, Training Loss = 0.0967, Validation Accuracy = 0.9904, Validation Loss = 0.1129\n",
            "Epoch 1339/1667\n",
            "Epoch 1339: Training Accuracy = 0.9902, Training Loss = 0.0688, Validation Accuracy = 0.9904, Validation Loss = 0.1063\n",
            "Epoch 1340/1667\n",
            "Epoch 1340: Training Accuracy = 0.9902, Training Loss = 0.0688, Validation Accuracy = 0.9904, Validation Loss = 0.1063\n",
            "Epoch 1341/1667\n",
            "Epoch 1341: Training Accuracy = 0.9883, Training Loss = 0.0752, Validation Accuracy = 0.9904, Validation Loss = 0.1015\n",
            "Epoch 1342/1667\n",
            "Epoch 1342: Training Accuracy = 0.9883, Training Loss = 0.0742, Validation Accuracy = 0.9904, Validation Loss = 0.1006\n",
            "Epoch 1343/1667\n",
            "Epoch 1343: Training Accuracy = 0.9883, Training Loss = 0.0742, Validation Accuracy = 0.9904, Validation Loss = 0.1006\n",
            "Epoch 1344/1667\n",
            "Epoch 1344: Training Accuracy = 0.9883, Training Loss = 0.0750, Validation Accuracy = 0.9904, Validation Loss = 0.1025\n",
            "Epoch 1345/1667\n",
            "Epoch 1345: Training Accuracy = 0.9883, Training Loss = 0.0750, Validation Accuracy = 0.9904, Validation Loss = 0.1025\n",
            "Epoch 1346/1667\n",
            "Epoch 1346: Training Accuracy = 0.9863, Training Loss = 0.0807, Validation Accuracy = 0.9904, Validation Loss = 0.1017\n",
            "Epoch 1347/1667\n",
            "Epoch 1347: Training Accuracy = 0.9941, Training Loss = 0.0528, Validation Accuracy = 0.9904, Validation Loss = 0.1013\n",
            "Epoch 1348/1667\n",
            "Epoch 1348: Training Accuracy = 0.9941, Training Loss = 0.0528, Validation Accuracy = 0.9904, Validation Loss = 0.1013\n",
            "Epoch 1349/1667\n",
            "Epoch 1349: Training Accuracy = 0.9805, Training Loss = 0.1031, Validation Accuracy = 0.9904, Validation Loss = 0.1024\n",
            "Epoch 1350/1667\n",
            "Epoch 1350: Training Accuracy = 0.9805, Training Loss = 0.1031, Validation Accuracy = 0.9904, Validation Loss = 0.1024\n",
            "Epoch 1351/1667\n",
            "Epoch 1351: Training Accuracy = 0.9863, Training Loss = 0.0818, Validation Accuracy = 0.9904, Validation Loss = 0.1027\n",
            "Epoch 1352/1667\n",
            "Epoch 1352: Training Accuracy = 0.9844, Training Loss = 0.0916, Validation Accuracy = 0.9904, Validation Loss = 0.1005\n",
            "Epoch 1353/1667\n",
            "Epoch 1353: Training Accuracy = 0.9844, Training Loss = 0.0916, Validation Accuracy = 0.9904, Validation Loss = 0.1005\n",
            "Epoch 1354/1667\n",
            "Epoch 1354: Training Accuracy = 0.9961, Training Loss = 0.0423, Validation Accuracy = 0.9904, Validation Loss = 0.0988\n",
            "Epoch 1355/1667\n",
            "Epoch 1355: Training Accuracy = 0.9961, Training Loss = 0.0423, Validation Accuracy = 0.9904, Validation Loss = 0.0988\n",
            "Epoch 1356/1667\n",
            "Epoch 1356: Training Accuracy = 0.9824, Training Loss = 0.0932, Validation Accuracy = 0.9904, Validation Loss = 0.0990\n",
            "Epoch 1357/1667\n",
            "Epoch 1357: Training Accuracy = 0.9883, Training Loss = 0.0744, Validation Accuracy = 0.9904, Validation Loss = 0.0988\n",
            "Epoch 1358/1667\n",
            "Epoch 1358: Training Accuracy = 0.9883, Training Loss = 0.0744, Validation Accuracy = 0.9904, Validation Loss = 0.0988\n",
            "Epoch 1359/1667\n",
            "Epoch 1359: Training Accuracy = 0.9863, Training Loss = 0.0815, Validation Accuracy = 0.9904, Validation Loss = 0.0985\n",
            "Epoch 1360/1667\n",
            "Epoch 1360: Training Accuracy = 0.9863, Training Loss = 0.0815, Validation Accuracy = 0.9904, Validation Loss = 0.0985\n",
            "Epoch 1361/1667\n",
            "Epoch 1361: Training Accuracy = 0.9863, Training Loss = 0.0757, Validation Accuracy = 0.9904, Validation Loss = 0.0981\n",
            "Epoch 1362/1667\n",
            "Epoch 1362: Training Accuracy = 0.9922, Training Loss = 0.0608, Validation Accuracy = 0.9904, Validation Loss = 0.1000\n",
            "Epoch 1363/1667\n",
            "Epoch 1363: Training Accuracy = 0.9922, Training Loss = 0.0608, Validation Accuracy = 0.9904, Validation Loss = 0.1000\n",
            "Epoch 1364/1667\n",
            "Epoch 1364: Training Accuracy = 0.8730, Training Loss = 0.9528, Validation Accuracy = 0.8300, Validation Loss = 1.0302\n",
            "Epoch 1365/1667\n",
            "Epoch 1365: Training Accuracy = 0.8730, Training Loss = 0.9528, Validation Accuracy = 0.8300, Validation Loss = 1.0302\n",
            "Epoch 1366/1667\n",
            "Epoch 1366: Training Accuracy = 0.9824, Training Loss = 0.3509, Validation Accuracy = 0.9686, Validation Loss = 0.4069\n",
            "Epoch 1367/1667\n",
            "Epoch 1367: Training Accuracy = 0.9805, Training Loss = 0.1875, Validation Accuracy = 0.9894, Validation Loss = 0.1995\n",
            "Epoch 1368/1667\n",
            "Epoch 1368: Training Accuracy = 0.9805, Training Loss = 0.1875, Validation Accuracy = 0.9894, Validation Loss = 0.1995\n",
            "Epoch 1369/1667\n",
            "Epoch 1369: Training Accuracy = 0.9922, Training Loss = 0.0910, Validation Accuracy = 0.9903, Validation Loss = 0.1323\n",
            "Epoch 1370/1667\n",
            "Epoch 1370: Training Accuracy = 0.9922, Training Loss = 0.0910, Validation Accuracy = 0.9903, Validation Loss = 0.1323\n",
            "Epoch 1371/1667\n",
            "Epoch 1371: Training Accuracy = 0.9844, Training Loss = 0.1008, Validation Accuracy = 0.9904, Validation Loss = 0.1070\n",
            "Epoch 1372/1667\n",
            "Epoch 1372: Training Accuracy = 0.9902, Training Loss = 0.0684, Validation Accuracy = 0.9904, Validation Loss = 0.0995\n",
            "Epoch 1373/1667\n",
            "Epoch 1373: Training Accuracy = 0.9902, Training Loss = 0.0684, Validation Accuracy = 0.9904, Validation Loss = 0.0995\n",
            "Epoch 1374/1667\n",
            "Epoch 1374: Training Accuracy = 0.9883, Training Loss = 0.0733, Validation Accuracy = 0.9904, Validation Loss = 0.0976\n",
            "Epoch 1375/1667\n",
            "Epoch 1375: Training Accuracy = 0.9883, Training Loss = 0.0733, Validation Accuracy = 0.9904, Validation Loss = 0.0976\n",
            "Epoch 1376/1667\n",
            "Epoch 1376: Training Accuracy = 0.9902, Training Loss = 0.0636, Validation Accuracy = 0.9904, Validation Loss = 0.0962\n",
            "Epoch 1377/1667\n",
            "Epoch 1377: Training Accuracy = 0.9922, Training Loss = 0.0601, Validation Accuracy = 0.9904, Validation Loss = 0.0975\n",
            "Epoch 1378/1667\n",
            "Epoch 1378: Training Accuracy = 0.9922, Training Loss = 0.0601, Validation Accuracy = 0.9904, Validation Loss = 0.0975\n",
            "Epoch 1379/1667\n",
            "Epoch 1379: Training Accuracy = 0.9844, Training Loss = 0.0882, Validation Accuracy = 0.9904, Validation Loss = 0.0969\n",
            "Epoch 1380/1667\n",
            "Epoch 1380: Training Accuracy = 0.9844, Training Loss = 0.0882, Validation Accuracy = 0.9904, Validation Loss = 0.0969\n",
            "Epoch 1381/1667\n",
            "Epoch 1381: Training Accuracy = 0.9922, Training Loss = 0.0577, Validation Accuracy = 0.9904, Validation Loss = 0.0972\n",
            "Epoch 1382/1667\n",
            "Epoch 1382: Training Accuracy = 0.9883, Training Loss = 0.0808, Validation Accuracy = 0.9904, Validation Loss = 0.0971\n",
            "Epoch 1383/1667\n",
            "Epoch 1383: Training Accuracy = 0.9883, Training Loss = 0.0808, Validation Accuracy = 0.9904, Validation Loss = 0.0971\n",
            "Epoch 1384/1667\n",
            "Epoch 1384: Training Accuracy = 0.9844, Training Loss = 0.0871, Validation Accuracy = 0.9904, Validation Loss = 0.0965\n",
            "Epoch 1385/1667\n",
            "Epoch 1385: Training Accuracy = 0.9844, Training Loss = 0.0871, Validation Accuracy = 0.9904, Validation Loss = 0.0965\n",
            "Epoch 1386/1667\n",
            "Epoch 1386: Training Accuracy = 0.9883, Training Loss = 0.0709, Validation Accuracy = 0.9904, Validation Loss = 0.0967\n",
            "Epoch 1387/1667\n",
            "Epoch 1387: Training Accuracy = 0.9863, Training Loss = 0.0793, Validation Accuracy = 0.9904, Validation Loss = 0.0995\n",
            "Epoch 1388/1667\n",
            "Epoch 1388: Training Accuracy = 0.9863, Training Loss = 0.0793, Validation Accuracy = 0.9904, Validation Loss = 0.0995\n",
            "Epoch 1389/1667\n",
            "Epoch 1389: Training Accuracy = 0.9902, Training Loss = 0.0736, Validation Accuracy = 0.9904, Validation Loss = 0.0984\n",
            "Epoch 1390/1667\n",
            "Epoch 1390: Training Accuracy = 0.9902, Training Loss = 0.0736, Validation Accuracy = 0.9904, Validation Loss = 0.0984\n",
            "Epoch 1391/1667\n",
            "Epoch 1391: Training Accuracy = 0.9883, Training Loss = 0.0776, Validation Accuracy = 0.9904, Validation Loss = 0.0994\n",
            "Epoch 1392/1667\n",
            "Epoch 1392: Training Accuracy = 0.9883, Training Loss = 0.0741, Validation Accuracy = 0.9904, Validation Loss = 0.0948\n",
            "Epoch 1393/1667\n",
            "Epoch 1393: Training Accuracy = 0.9883, Training Loss = 0.0741, Validation Accuracy = 0.9904, Validation Loss = 0.0948\n",
            "Epoch 1394/1667\n",
            "Epoch 1394: Training Accuracy = 0.9824, Training Loss = 0.0967, Validation Accuracy = 0.9904, Validation Loss = 0.0991\n",
            "Epoch 1395/1667\n",
            "Epoch 1395: Training Accuracy = 0.9824, Training Loss = 0.0967, Validation Accuracy = 0.9904, Validation Loss = 0.0991\n",
            "Epoch 1396/1667\n",
            "Epoch 1396: Training Accuracy = 0.9844, Training Loss = 0.0864, Validation Accuracy = 0.9904, Validation Loss = 0.0978\n",
            "Epoch 1397/1667\n",
            "Epoch 1397: Training Accuracy = 0.5195, Training Loss = 1.9526, Validation Accuracy = 0.1990, Validation Loss = 3.1211\n",
            "Epoch 1398/1667\n",
            "Epoch 1398: Training Accuracy = 0.5195, Training Loss = 1.9526, Validation Accuracy = 0.1990, Validation Loss = 3.1211\n",
            "Epoch 1399/1667\n",
            "Epoch 1399: Training Accuracy = 0.8125, Training Loss = 0.9869, Validation Accuracy = 0.8204, Validation Loss = 0.9967\n",
            "Epoch 1400/1667\n",
            "Epoch 1400: Training Accuracy = 0.8125, Training Loss = 0.9869, Validation Accuracy = 0.8204, Validation Loss = 0.9967\n",
            "Epoch 1401/1667\n",
            "Epoch 1401: Training Accuracy = 0.9785, Training Loss = 0.3328, Validation Accuracy = 0.9604, Validation Loss = 0.4070\n",
            "Epoch 1402/1667\n",
            "Epoch 1402: Training Accuracy = 0.9922, Training Loss = 0.1561, Validation Accuracy = 0.9886, Validation Loss = 0.1981\n",
            "Epoch 1403/1667\n",
            "Epoch 1403: Training Accuracy = 0.9922, Training Loss = 0.1561, Validation Accuracy = 0.9886, Validation Loss = 0.1981\n",
            "Epoch 1404/1667\n",
            "Epoch 1404: Training Accuracy = 0.9844, Training Loss = 0.1084, Validation Accuracy = 0.9904, Validation Loss = 0.1251\n",
            "Epoch 1405/1667\n",
            "Epoch 1405: Training Accuracy = 0.9844, Training Loss = 0.1084, Validation Accuracy = 0.9904, Validation Loss = 0.1251\n",
            "Epoch 1406/1667\n",
            "Epoch 1406: Training Accuracy = 0.9922, Training Loss = 0.0675, Validation Accuracy = 0.9904, Validation Loss = 0.1040\n",
            "Epoch 1407/1667\n",
            "Epoch 1407: Training Accuracy = 0.9902, Training Loss = 0.0755, Validation Accuracy = 0.9904, Validation Loss = 0.0966\n",
            "Epoch 1408/1667\n",
            "Epoch 1408: Training Accuracy = 0.9902, Training Loss = 0.0755, Validation Accuracy = 0.9904, Validation Loss = 0.0966\n",
            "Epoch 1409/1667\n",
            "Epoch 1409: Training Accuracy = 0.9844, Training Loss = 0.0878, Validation Accuracy = 0.9904, Validation Loss = 0.0937\n",
            "Epoch 1410/1667\n",
            "Epoch 1410: Training Accuracy = 0.9844, Training Loss = 0.0878, Validation Accuracy = 0.9904, Validation Loss = 0.0937\n",
            "Epoch 1411/1667\n",
            "Epoch 1411: Training Accuracy = 0.9922, Training Loss = 0.0646, Validation Accuracy = 0.9904, Validation Loss = 0.0946\n",
            "Epoch 1412/1667\n",
            "Epoch 1412: Training Accuracy = 0.9863, Training Loss = 0.0823, Validation Accuracy = 0.9904, Validation Loss = 0.0950\n",
            "Epoch 1413/1667\n",
            "Epoch 1413: Training Accuracy = 0.9863, Training Loss = 0.0823, Validation Accuracy = 0.9904, Validation Loss = 0.0950\n",
            "Epoch 1414/1667\n",
            "Epoch 1414: Training Accuracy = 0.9824, Training Loss = 0.0999, Validation Accuracy = 0.9904, Validation Loss = 0.0951\n",
            "Epoch 1415/1667\n",
            "Epoch 1415: Training Accuracy = 0.9824, Training Loss = 0.0999, Validation Accuracy = 0.9904, Validation Loss = 0.0951\n",
            "Epoch 1416/1667\n",
            "Epoch 1416: Training Accuracy = 0.9824, Training Loss = 0.0957, Validation Accuracy = 0.9904, Validation Loss = 0.0957\n",
            "Epoch 1417/1667\n",
            "Epoch 1417: Training Accuracy = 0.9863, Training Loss = 0.0845, Validation Accuracy = 0.9904, Validation Loss = 0.0964\n",
            "Epoch 1418/1667\n",
            "Epoch 1418: Training Accuracy = 0.9863, Training Loss = 0.0845, Validation Accuracy = 0.9904, Validation Loss = 0.0964\n",
            "Epoch 1419/1667\n",
            "Epoch 1419: Training Accuracy = 0.9863, Training Loss = 0.0800, Validation Accuracy = 0.9904, Validation Loss = 0.0968\n",
            "Epoch 1420/1667\n",
            "Epoch 1420: Training Accuracy = 0.9863, Training Loss = 0.0800, Validation Accuracy = 0.9904, Validation Loss = 0.0968\n",
            "Epoch 1421/1667\n",
            "Epoch 1421: Training Accuracy = 0.9941, Training Loss = 0.0516, Validation Accuracy = 0.9904, Validation Loss = 0.0959\n",
            "Epoch 1422/1667\n",
            "Epoch 1422: Training Accuracy = 0.9824, Training Loss = 0.0977, Validation Accuracy = 0.9904, Validation Loss = 0.0955\n",
            "Epoch 1423/1667\n",
            "Epoch 1423: Training Accuracy = 0.9824, Training Loss = 0.0977, Validation Accuracy = 0.9904, Validation Loss = 0.0955\n",
            "Epoch 1424/1667\n",
            "Epoch 1424: Training Accuracy = 0.9844, Training Loss = 0.0879, Validation Accuracy = 0.9904, Validation Loss = 0.0965\n",
            "Epoch 1425/1667\n",
            "Epoch 1425: Training Accuracy = 0.9844, Training Loss = 0.0879, Validation Accuracy = 0.9904, Validation Loss = 0.0965\n",
            "Epoch 1426/1667\n",
            "Epoch 1426: Training Accuracy = 0.9922, Training Loss = 0.0586, Validation Accuracy = 0.9904, Validation Loss = 0.0936\n",
            "Epoch 1427/1667\n",
            "Epoch 1427: Training Accuracy = 0.9922, Training Loss = 0.0631, Validation Accuracy = 0.9904, Validation Loss = 0.0948\n",
            "Epoch 1428/1667\n",
            "Epoch 1428: Training Accuracy = 0.9922, Training Loss = 0.0631, Validation Accuracy = 0.9904, Validation Loss = 0.0948\n",
            "Epoch 1429/1667\n",
            "Epoch 1429: Training Accuracy = 0.9922, Training Loss = 0.0544, Validation Accuracy = 0.9904, Validation Loss = 0.0985\n",
            "Epoch 1430/1667\n",
            "Epoch 1430: Training Accuracy = 0.9922, Training Loss = 0.0544, Validation Accuracy = 0.9904, Validation Loss = 0.0985\n",
            "Epoch 1431/1667\n",
            "Epoch 1431: Training Accuracy = 0.9766, Training Loss = 0.1295, Validation Accuracy = 0.9904, Validation Loss = 0.1039\n",
            "Epoch 1432/1667\n",
            "Epoch 1432: Training Accuracy = 0.6680, Training Loss = 1.4240, Validation Accuracy = 0.7075, Validation Loss = 1.3169\n",
            "Epoch 1433/1667\n",
            "Epoch 1433: Training Accuracy = 0.6680, Training Loss = 1.4240, Validation Accuracy = 0.7075, Validation Loss = 1.3169\n",
            "Epoch 1434/1667\n",
            "Epoch 1434: Training Accuracy = 0.9551, Training Loss = 0.4601, Validation Accuracy = 0.9575, Validation Loss = 0.4882\n",
            "Epoch 1435/1667\n",
            "Epoch 1435: Training Accuracy = 0.9551, Training Loss = 0.4601, Validation Accuracy = 0.9575, Validation Loss = 0.4882\n",
            "Epoch 1436/1667\n",
            "Epoch 1436: Training Accuracy = 0.9863, Training Loss = 0.2175, Validation Accuracy = 0.9851, Validation Loss = 0.2553\n",
            "Epoch 1437/1667\n",
            "Epoch 1437: Training Accuracy = 0.9922, Training Loss = 0.1170, Validation Accuracy = 0.9903, Validation Loss = 0.1573\n",
            "Epoch 1438/1667\n",
            "Epoch 1438: Training Accuracy = 0.9922, Training Loss = 0.1170, Validation Accuracy = 0.9903, Validation Loss = 0.1573\n",
            "Epoch 1439/1667\n",
            "Epoch 1439: Training Accuracy = 0.9941, Training Loss = 0.0796, Validation Accuracy = 0.9904, Validation Loss = 0.1307\n",
            "Epoch 1440/1667\n",
            "Epoch 1440: Training Accuracy = 0.9941, Training Loss = 0.0796, Validation Accuracy = 0.9904, Validation Loss = 0.1307\n",
            "Epoch 1441/1667\n",
            "Epoch 1441: Training Accuracy = 0.9883, Training Loss = 0.0880, Validation Accuracy = 0.9904, Validation Loss = 0.1178\n",
            "Epoch 1442/1667\n",
            "Epoch 1442: Training Accuracy = 0.9883, Training Loss = 0.0862, Validation Accuracy = 0.9904, Validation Loss = 0.1117\n",
            "Epoch 1443/1667\n",
            "Epoch 1443: Training Accuracy = 0.9883, Training Loss = 0.0862, Validation Accuracy = 0.9904, Validation Loss = 0.1117\n",
            "Epoch 1444/1667\n",
            "Epoch 1444: Training Accuracy = 0.9863, Training Loss = 0.0931, Validation Accuracy = 0.9904, Validation Loss = 0.1114\n",
            "Epoch 1445/1667\n",
            "Epoch 1445: Training Accuracy = 0.9863, Training Loss = 0.0931, Validation Accuracy = 0.9904, Validation Loss = 0.1114\n",
            "Epoch 1446/1667\n",
            "Epoch 1446: Training Accuracy = 0.9824, Training Loss = 0.1064, Validation Accuracy = 0.9904, Validation Loss = 0.1113\n",
            "Epoch 1447/1667\n",
            "Epoch 1447: Training Accuracy = 0.9902, Training Loss = 0.0772, Validation Accuracy = 0.9904, Validation Loss = 0.1100\n",
            "Epoch 1448/1667\n",
            "Epoch 1448: Training Accuracy = 0.9902, Training Loss = 0.0772, Validation Accuracy = 0.9904, Validation Loss = 0.1100\n",
            "Epoch 1449/1667\n",
            "Epoch 1449: Training Accuracy = 0.9902, Training Loss = 0.0762, Validation Accuracy = 0.9904, Validation Loss = 0.1094\n",
            "Epoch 1450/1667\n",
            "Epoch 1450: Training Accuracy = 0.9902, Training Loss = 0.0762, Validation Accuracy = 0.9904, Validation Loss = 0.1094\n",
            "Epoch 1451/1667\n",
            "Epoch 1451: Training Accuracy = 0.9922, Training Loss = 0.0698, Validation Accuracy = 0.9904, Validation Loss = 0.1106\n",
            "Epoch 1452/1667\n",
            "Epoch 1452: Training Accuracy = 0.9844, Training Loss = 0.0993, Validation Accuracy = 0.9904, Validation Loss = 0.1095\n",
            "Epoch 1453/1667\n",
            "Epoch 1453: Training Accuracy = 0.9844, Training Loss = 0.0993, Validation Accuracy = 0.9904, Validation Loss = 0.1095\n",
            "Epoch 1454/1667\n",
            "Epoch 1454: Training Accuracy = 0.9844, Training Loss = 0.0943, Validation Accuracy = 0.9904, Validation Loss = 0.1103\n",
            "Epoch 1455/1667\n",
            "Epoch 1455: Training Accuracy = 0.9844, Training Loss = 0.0943, Validation Accuracy = 0.9904, Validation Loss = 0.1103\n",
            "Epoch 1456/1667\n",
            "Epoch 1456: Training Accuracy = 0.9941, Training Loss = 0.0584, Validation Accuracy = 0.9904, Validation Loss = 0.1089\n",
            "Epoch 1457/1667\n",
            "Epoch 1457: Training Accuracy = 0.9824, Training Loss = 0.1034, Validation Accuracy = 0.9904, Validation Loss = 0.1081\n",
            "Epoch 1458/1667\n",
            "Epoch 1458: Training Accuracy = 0.9824, Training Loss = 0.1034, Validation Accuracy = 0.9904, Validation Loss = 0.1081\n",
            "Epoch 1459/1667\n",
            "Epoch 1459: Training Accuracy = 0.9863, Training Loss = 0.0864, Validation Accuracy = 0.9904, Validation Loss = 0.1052\n",
            "Epoch 1460/1667\n",
            "Epoch 1460: Training Accuracy = 0.9863, Training Loss = 0.0864, Validation Accuracy = 0.9904, Validation Loss = 0.1052\n",
            "Epoch 1461/1667\n",
            "Epoch 1461: Training Accuracy = 0.9844, Training Loss = 0.0918, Validation Accuracy = 0.9904, Validation Loss = 0.1054\n",
            "Epoch 1462/1667\n",
            "Epoch 1462: Training Accuracy = 0.9883, Training Loss = 0.0795, Validation Accuracy = 0.9904, Validation Loss = 0.1056\n",
            "Epoch 1463/1667\n",
            "Epoch 1463: Training Accuracy = 0.9883, Training Loss = 0.0795, Validation Accuracy = 0.9904, Validation Loss = 0.1056\n",
            "Epoch 1464/1667\n",
            "Epoch 1464: Training Accuracy = 0.9902, Training Loss = 0.0699, Validation Accuracy = 0.9904, Validation Loss = 0.1014\n",
            "Epoch 1465/1667\n",
            "Epoch 1465: Training Accuracy = 0.9902, Training Loss = 0.0699, Validation Accuracy = 0.9904, Validation Loss = 0.1014\n",
            "Epoch 1466/1667\n",
            "Epoch 1466: Training Accuracy = 0.9941, Training Loss = 0.0582, Validation Accuracy = 0.9904, Validation Loss = 0.1023\n",
            "Epoch 1467/1667\n",
            "Epoch 1467: Training Accuracy = 0.9883, Training Loss = 0.1488, Validation Accuracy = 0.5963, Validation Loss = 1.5582\n",
            "Epoch 1468/1667\n",
            "Epoch 1468: Training Accuracy = 0.9883, Training Loss = 0.1488, Validation Accuracy = 0.5963, Validation Loss = 1.5582\n",
            "Epoch 1469/1667\n",
            "Epoch 1469: Training Accuracy = 0.6816, Training Loss = 1.5118, Validation Accuracy = 0.7471, Validation Loss = 1.2759\n",
            "Epoch 1470/1667\n",
            "Epoch 1470: Training Accuracy = 0.6816, Training Loss = 1.5118, Validation Accuracy = 0.7471, Validation Loss = 1.2759\n",
            "Epoch 1471/1667\n",
            "Epoch 1471: Training Accuracy = 0.9648, Training Loss = 0.4284, Validation Accuracy = 0.9610, Validation Loss = 0.4360\n",
            "Epoch 1472/1667\n",
            "Epoch 1472: Training Accuracy = 0.9805, Training Loss = 0.2076, Validation Accuracy = 0.9895, Validation Loss = 0.2216\n",
            "Epoch 1473/1667\n",
            "Epoch 1473: Training Accuracy = 0.9805, Training Loss = 0.2076, Validation Accuracy = 0.9895, Validation Loss = 0.2216\n",
            "Epoch 1474/1667\n",
            "Epoch 1474: Training Accuracy = 0.9844, Training Loss = 0.1356, Validation Accuracy = 0.9904, Validation Loss = 0.1574\n",
            "Epoch 1475/1667\n",
            "Epoch 1475: Training Accuracy = 0.9844, Training Loss = 0.1356, Validation Accuracy = 0.9904, Validation Loss = 0.1574\n",
            "Epoch 1476/1667\n",
            "Epoch 1476: Training Accuracy = 0.9883, Training Loss = 0.1001, Validation Accuracy = 0.9904, Validation Loss = 0.1246\n",
            "Epoch 1477/1667\n",
            "Epoch 1477: Training Accuracy = 0.9863, Training Loss = 0.1018, Validation Accuracy = 0.9904, Validation Loss = 0.1131\n",
            "Epoch 1478/1667\n",
            "Epoch 1478: Training Accuracy = 0.9863, Training Loss = 0.1018, Validation Accuracy = 0.9904, Validation Loss = 0.1131\n",
            "Epoch 1479/1667\n",
            "Epoch 1479: Training Accuracy = 0.9922, Training Loss = 0.0708, Validation Accuracy = 0.9904, Validation Loss = 0.1102\n",
            "Epoch 1480/1667\n",
            "Epoch 1480: Training Accuracy = 0.9922, Training Loss = 0.0708, Validation Accuracy = 0.9904, Validation Loss = 0.1102\n",
            "Epoch 1481/1667\n",
            "Epoch 1481: Training Accuracy = 0.9883, Training Loss = 0.0834, Validation Accuracy = 0.9904, Validation Loss = 0.1100\n",
            "Epoch 1482/1667\n",
            "Epoch 1482: Training Accuracy = 0.9902, Training Loss = 0.0766, Validation Accuracy = 0.9904, Validation Loss = 0.1079\n",
            "Epoch 1483/1667\n",
            "Epoch 1483: Training Accuracy = 0.9902, Training Loss = 0.0766, Validation Accuracy = 0.9904, Validation Loss = 0.1079\n",
            "Epoch 1484/1667\n",
            "Epoch 1484: Training Accuracy = 0.9922, Training Loss = 0.0691, Validation Accuracy = 0.9904, Validation Loss = 0.1076\n",
            "Epoch 1485/1667\n",
            "Epoch 1485: Training Accuracy = 0.9922, Training Loss = 0.0691, Validation Accuracy = 0.9904, Validation Loss = 0.1076\n",
            "Epoch 1486/1667\n",
            "Epoch 1486: Training Accuracy = 0.9902, Training Loss = 0.0807, Validation Accuracy = 0.9904, Validation Loss = 0.1072\n",
            "Epoch 1487/1667\n",
            "Epoch 1487: Training Accuracy = 0.9824, Training Loss = 0.1038, Validation Accuracy = 0.9904, Validation Loss = 0.1057\n",
            "Epoch 1488/1667\n",
            "Epoch 1488: Training Accuracy = 0.9824, Training Loss = 0.1038, Validation Accuracy = 0.9904, Validation Loss = 0.1057\n",
            "Epoch 1489/1667\n",
            "Epoch 1489: Training Accuracy = 0.9824, Training Loss = 0.1000, Validation Accuracy = 0.9904, Validation Loss = 0.1055\n",
            "Epoch 1490/1667\n",
            "Epoch 1490: Training Accuracy = 0.9824, Training Loss = 0.1000, Validation Accuracy = 0.9904, Validation Loss = 0.1055\n",
            "Epoch 1491/1667\n",
            "Epoch 1491: Training Accuracy = 0.9805, Training Loss = 0.1079, Validation Accuracy = 0.9904, Validation Loss = 0.1023\n",
            "Epoch 1492/1667\n",
            "Epoch 1492: Training Accuracy = 0.9902, Training Loss = 0.0705, Validation Accuracy = 0.9904, Validation Loss = 0.0993\n",
            "Epoch 1493/1667\n",
            "Epoch 1493: Training Accuracy = 0.9902, Training Loss = 0.0705, Validation Accuracy = 0.9904, Validation Loss = 0.0993\n",
            "Epoch 1494/1667\n",
            "Epoch 1494: Training Accuracy = 0.9824, Training Loss = 0.0963, Validation Accuracy = 0.9904, Validation Loss = 0.0971\n",
            "Epoch 1495/1667\n",
            "Epoch 1495: Training Accuracy = 0.9824, Training Loss = 0.0963, Validation Accuracy = 0.9904, Validation Loss = 0.0971\n",
            "Epoch 1496/1667\n",
            "Epoch 1496: Training Accuracy = 0.9766, Training Loss = 0.1160, Validation Accuracy = 0.9904, Validation Loss = 0.0968\n",
            "Epoch 1497/1667\n",
            "Epoch 1497: Training Accuracy = 0.9902, Training Loss = 0.0677, Validation Accuracy = 0.9904, Validation Loss = 0.0990\n",
            "Epoch 1498/1667\n",
            "Epoch 1498: Training Accuracy = 0.9902, Training Loss = 0.0677, Validation Accuracy = 0.9904, Validation Loss = 0.0990\n",
            "Epoch 1499/1667\n",
            "Epoch 1499: Training Accuracy = 0.6289, Training Loss = 1.4462, Validation Accuracy = 0.7521, Validation Loss = 1.1795\n",
            "Epoch 1500/1667\n",
            "Epoch 1500: Training Accuracy = 0.6289, Training Loss = 1.4462, Validation Accuracy = 0.7521, Validation Loss = 1.1795\n",
            "Epoch 1501/1667\n",
            "Epoch 1501: Training Accuracy = 0.9551, Training Loss = 0.4338, Validation Accuracy = 0.9633, Validation Loss = 0.4768\n",
            "Epoch 1502/1667\n",
            "Epoch 1502: Training Accuracy = 0.9922, Training Loss = 0.1889, Validation Accuracy = 0.9885, Validation Loss = 0.2246\n",
            "Epoch 1503/1667\n",
            "Epoch 1503: Training Accuracy = 0.9922, Training Loss = 0.1889, Validation Accuracy = 0.9885, Validation Loss = 0.2246\n",
            "Epoch 1504/1667\n",
            "Epoch 1504: Training Accuracy = 0.9805, Training Loss = 0.1479, Validation Accuracy = 0.9904, Validation Loss = 0.1488\n",
            "Epoch 1505/1667\n",
            "Epoch 1505: Training Accuracy = 0.9805, Training Loss = 0.1479, Validation Accuracy = 0.9904, Validation Loss = 0.1488\n",
            "Epoch 1506/1667\n",
            "Epoch 1506: Training Accuracy = 0.9805, Training Loss = 0.1280, Validation Accuracy = 0.9904, Validation Loss = 0.1190\n",
            "Epoch 1507/1667\n",
            "Epoch 1507: Training Accuracy = 0.9844, Training Loss = 0.1027, Validation Accuracy = 0.9904, Validation Loss = 0.1096\n",
            "Epoch 1508/1667\n",
            "Epoch 1508: Training Accuracy = 0.9844, Training Loss = 0.1027, Validation Accuracy = 0.9904, Validation Loss = 0.1096\n",
            "Epoch 1509/1667\n",
            "Epoch 1509: Training Accuracy = 0.9883, Training Loss = 0.0818, Validation Accuracy = 0.9904, Validation Loss = 0.1047\n",
            "Epoch 1510/1667\n",
            "Epoch 1510: Training Accuracy = 0.9883, Training Loss = 0.0818, Validation Accuracy = 0.9904, Validation Loss = 0.1047\n",
            "Epoch 1511/1667\n",
            "Epoch 1511: Training Accuracy = 0.9785, Training Loss = 0.1147, Validation Accuracy = 0.9904, Validation Loss = 0.1042\n",
            "Epoch 1512/1667\n",
            "Epoch 1512: Training Accuracy = 0.9824, Training Loss = 0.1041, Validation Accuracy = 0.9904, Validation Loss = 0.1036\n",
            "Epoch 1513/1667\n",
            "Epoch 1513: Training Accuracy = 0.9824, Training Loss = 0.1041, Validation Accuracy = 0.9904, Validation Loss = 0.1036\n",
            "Epoch 1514/1667\n",
            "Epoch 1514: Training Accuracy = 0.9844, Training Loss = 0.1002, Validation Accuracy = 0.9904, Validation Loss = 0.1045\n",
            "Epoch 1515/1667\n",
            "Epoch 1515: Training Accuracy = 0.9844, Training Loss = 0.1002, Validation Accuracy = 0.9904, Validation Loss = 0.1045\n",
            "Epoch 1516/1667\n",
            "Epoch 1516: Training Accuracy = 0.9883, Training Loss = 0.0813, Validation Accuracy = 0.9904, Validation Loss = 0.1031\n",
            "Epoch 1517/1667\n",
            "Epoch 1517: Training Accuracy = 0.9844, Training Loss = 0.0968, Validation Accuracy = 0.9904, Validation Loss = 0.1012\n",
            "Epoch 1518/1667\n",
            "Epoch 1518: Training Accuracy = 0.9844, Training Loss = 0.0968, Validation Accuracy = 0.9904, Validation Loss = 0.1012\n",
            "Epoch 1519/1667\n",
            "Epoch 1519: Training Accuracy = 0.9883, Training Loss = 0.0801, Validation Accuracy = 0.9904, Validation Loss = 0.1027\n",
            "Epoch 1520/1667\n",
            "Epoch 1520: Training Accuracy = 0.9883, Training Loss = 0.0801, Validation Accuracy = 0.9904, Validation Loss = 0.1027\n",
            "Epoch 1521/1667\n",
            "Epoch 1521: Training Accuracy = 0.9941, Training Loss = 0.0583, Validation Accuracy = 0.9904, Validation Loss = 0.1023\n",
            "Epoch 1522/1667\n",
            "Epoch 1522: Training Accuracy = 0.9824, Training Loss = 0.1024, Validation Accuracy = 0.9904, Validation Loss = 0.0991\n",
            "Epoch 1523/1667\n",
            "Epoch 1523: Training Accuracy = 0.9824, Training Loss = 0.1024, Validation Accuracy = 0.9904, Validation Loss = 0.0991\n",
            "Epoch 1524/1667\n",
            "Epoch 1524: Training Accuracy = 0.9805, Training Loss = 0.1070, Validation Accuracy = 0.9904, Validation Loss = 0.0979\n",
            "Epoch 1525/1667\n",
            "Epoch 1525: Training Accuracy = 0.9805, Training Loss = 0.1070, Validation Accuracy = 0.9904, Validation Loss = 0.0979\n",
            "Epoch 1526/1667\n",
            "Epoch 1526: Training Accuracy = 0.9941, Training Loss = 0.0541, Validation Accuracy = 0.9904, Validation Loss = 0.0973\n",
            "Epoch 1527/1667\n",
            "Epoch 1527: Training Accuracy = 0.9863, Training Loss = 0.0856, Validation Accuracy = 0.9904, Validation Loss = 0.0991\n",
            "Epoch 1528/1667\n",
            "Epoch 1528: Training Accuracy = 0.9863, Training Loss = 0.0856, Validation Accuracy = 0.9904, Validation Loss = 0.0991\n",
            "Epoch 1529/1667\n",
            "Epoch 1529: Training Accuracy = 0.7539, Training Loss = 1.1688, Validation Accuracy = 0.4679, Validation Loss = 2.0551\n",
            "Epoch 1530/1667\n",
            "Epoch 1530: Training Accuracy = 0.7539, Training Loss = 1.1688, Validation Accuracy = 0.4679, Validation Loss = 2.0551\n",
            "Epoch 1531/1667\n",
            "Epoch 1531: Training Accuracy = 0.8848, Training Loss = 0.7007, Validation Accuracy = 0.8717, Validation Loss = 0.7411\n",
            "Epoch 1532/1667\n",
            "Epoch 1532: Training Accuracy = 0.9941, Training Loss = 0.2316, Validation Accuracy = 0.9774, Validation Loss = 0.3100\n",
            "Epoch 1533/1667\n",
            "Epoch 1533: Training Accuracy = 0.9941, Training Loss = 0.2316, Validation Accuracy = 0.9774, Validation Loss = 0.3100\n",
            "Epoch 1534/1667\n",
            "Epoch 1534: Training Accuracy = 0.9863, Training Loss = 0.1562, Validation Accuracy = 0.9904, Validation Loss = 0.1817\n",
            "Epoch 1535/1667\n",
            "Epoch 1535: Training Accuracy = 0.9863, Training Loss = 0.1562, Validation Accuracy = 0.9904, Validation Loss = 0.1817\n",
            "Epoch 1536/1667\n",
            "Epoch 1536: Training Accuracy = 0.9902, Training Loss = 0.1130, Validation Accuracy = 0.9901, Validation Loss = 0.1533\n",
            "Epoch 1537/1667\n",
            "Epoch 1537: Training Accuracy = 0.9941, Training Loss = 0.0762, Validation Accuracy = 0.9904, Validation Loss = 0.1248\n",
            "Epoch 1538/1667\n",
            "Epoch 1538: Training Accuracy = 0.9941, Training Loss = 0.0762, Validation Accuracy = 0.9904, Validation Loss = 0.1248\n",
            "Epoch 1539/1667\n",
            "Epoch 1539: Training Accuracy = 0.9902, Training Loss = 0.0830, Validation Accuracy = 0.9904, Validation Loss = 0.1163\n",
            "Epoch 1540/1667\n",
            "Epoch 1540: Training Accuracy = 0.9902, Training Loss = 0.0830, Validation Accuracy = 0.9904, Validation Loss = 0.1163\n",
            "Epoch 1541/1667\n",
            "Epoch 1541: Training Accuracy = 0.9941, Training Loss = 0.0725, Validation Accuracy = 0.9904, Validation Loss = 0.1136\n",
            "Epoch 1542/1667\n",
            "Epoch 1542: Training Accuracy = 0.9844, Training Loss = 0.1028, Validation Accuracy = 0.9904, Validation Loss = 0.1114\n",
            "Epoch 1543/1667\n",
            "Epoch 1543: Training Accuracy = 0.9844, Training Loss = 0.1028, Validation Accuracy = 0.9904, Validation Loss = 0.1114\n",
            "Epoch 1544/1667\n",
            "Epoch 1544: Training Accuracy = 0.9863, Training Loss = 0.0949, Validation Accuracy = 0.9904, Validation Loss = 0.1119\n",
            "Epoch 1545/1667\n",
            "Epoch 1545: Training Accuracy = 0.9863, Training Loss = 0.0949, Validation Accuracy = 0.9904, Validation Loss = 0.1119\n",
            "Epoch 1546/1667\n",
            "Epoch 1546: Training Accuracy = 0.9863, Training Loss = 0.0918, Validation Accuracy = 0.9904, Validation Loss = 0.1106\n",
            "Epoch 1547/1667\n",
            "Epoch 1547: Training Accuracy = 0.9844, Training Loss = 0.1030, Validation Accuracy = 0.9904, Validation Loss = 0.1107\n",
            "Epoch 1548/1667\n",
            "Epoch 1548: Training Accuracy = 0.9844, Training Loss = 0.1030, Validation Accuracy = 0.9904, Validation Loss = 0.1107\n",
            "Epoch 1549/1667\n",
            "Epoch 1549: Training Accuracy = 0.9883, Training Loss = 0.0853, Validation Accuracy = 0.9904, Validation Loss = 0.1086\n",
            "Epoch 1550/1667\n",
            "Epoch 1550: Training Accuracy = 0.9883, Training Loss = 0.0853, Validation Accuracy = 0.9904, Validation Loss = 0.1086\n",
            "Epoch 1551/1667\n",
            "Epoch 1551: Training Accuracy = 0.9863, Training Loss = 0.0888, Validation Accuracy = 0.9904, Validation Loss = 0.1064\n",
            "Epoch 1552/1667\n",
            "Epoch 1552: Training Accuracy = 0.9902, Training Loss = 0.0728, Validation Accuracy = 0.9904, Validation Loss = 0.1045\n",
            "Epoch 1553/1667\n",
            "Epoch 1553: Training Accuracy = 0.9902, Training Loss = 0.0728, Validation Accuracy = 0.9904, Validation Loss = 0.1045\n",
            "Epoch 1554/1667\n",
            "Epoch 1554: Training Accuracy = 0.9844, Training Loss = 0.0941, Validation Accuracy = 0.9904, Validation Loss = 0.1037\n",
            "Epoch 1555/1667\n",
            "Epoch 1555: Training Accuracy = 0.9844, Training Loss = 0.0941, Validation Accuracy = 0.9904, Validation Loss = 0.1037\n",
            "Epoch 1556/1667\n",
            "Epoch 1556: Training Accuracy = 0.9883, Training Loss = 0.0780, Validation Accuracy = 0.9904, Validation Loss = 0.1036\n",
            "Epoch 1557/1667\n",
            "Epoch 1557: Training Accuracy = 0.9883, Training Loss = 0.0924, Validation Accuracy = 0.9904, Validation Loss = 0.1260\n",
            "Epoch 1558/1667\n",
            "Epoch 1558: Training Accuracy = 0.9883, Training Loss = 0.0924, Validation Accuracy = 0.9904, Validation Loss = 0.1260\n",
            "Epoch 1559/1667\n",
            "Epoch 1559: Training Accuracy = 0.9902, Training Loss = 0.0814, Validation Accuracy = 0.9904, Validation Loss = 0.1176\n",
            "Epoch 1560/1667\n",
            "Epoch 1560: Training Accuracy = 0.9902, Training Loss = 0.0814, Validation Accuracy = 0.9904, Validation Loss = 0.1176\n",
            "Epoch 1561/1667\n",
            "Epoch 1561: Training Accuracy = 0.9883, Training Loss = 0.1198, Validation Accuracy = 0.9528, Validation Loss = 0.4362\n",
            "Epoch 1562/1667\n",
            "Epoch 1562: Training Accuracy = 0.8145, Training Loss = 0.9108, Validation Accuracy = 0.7448, Validation Loss = 1.1339\n",
            "Epoch 1563/1667\n",
            "Epoch 1563: Training Accuracy = 0.8145, Training Loss = 0.9108, Validation Accuracy = 0.7448, Validation Loss = 1.1339\n",
            "Epoch 1564/1667\n",
            "Epoch 1564: Training Accuracy = 0.9668, Training Loss = 0.3747, Validation Accuracy = 0.9725, Validation Loss = 0.3912\n",
            "Epoch 1565/1667\n",
            "Epoch 1565: Training Accuracy = 0.9668, Training Loss = 0.3747, Validation Accuracy = 0.9725, Validation Loss = 0.3912\n",
            "Epoch 1566/1667\n",
            "Epoch 1566: Training Accuracy = 0.9980, Training Loss = 0.1380, Validation Accuracy = 0.9891, Validation Loss = 0.2069\n",
            "Epoch 1567/1667\n",
            "Epoch 1567: Training Accuracy = 0.9902, Training Loss = 0.1024, Validation Accuracy = 0.9904, Validation Loss = 0.1408\n",
            "Epoch 1568/1667\n",
            "Epoch 1568: Training Accuracy = 0.9902, Training Loss = 0.1024, Validation Accuracy = 0.9904, Validation Loss = 0.1408\n",
            "Epoch 1569/1667\n",
            "Epoch 1569: Training Accuracy = 0.9844, Training Loss = 0.1049, Validation Accuracy = 0.9904, Validation Loss = 0.1130\n",
            "Epoch 1570/1667\n",
            "Epoch 1570: Training Accuracy = 0.9844, Training Loss = 0.1049, Validation Accuracy = 0.9904, Validation Loss = 0.1130\n",
            "Epoch 1571/1667\n",
            "Epoch 1571: Training Accuracy = 0.9922, Training Loss = 0.0671, Validation Accuracy = 0.9904, Validation Loss = 0.1041\n",
            "Epoch 1572/1667\n",
            "Epoch 1572: Training Accuracy = 0.9902, Training Loss = 0.0721, Validation Accuracy = 0.9904, Validation Loss = 0.1019\n",
            "Epoch 1573/1667\n",
            "Epoch 1573: Training Accuracy = 0.9902, Training Loss = 0.0721, Validation Accuracy = 0.9904, Validation Loss = 0.1019\n",
            "Epoch 1574/1667\n",
            "Epoch 1574: Training Accuracy = 0.9863, Training Loss = 0.0856, Validation Accuracy = 0.9904, Validation Loss = 0.1007\n",
            "Epoch 1575/1667\n",
            "Epoch 1575: Training Accuracy = 0.9863, Training Loss = 0.0856, Validation Accuracy = 0.9904, Validation Loss = 0.1007\n",
            "Epoch 1576/1667\n",
            "Epoch 1576: Training Accuracy = 0.9805, Training Loss = 0.1044, Validation Accuracy = 0.9904, Validation Loss = 0.1011\n",
            "Epoch 1577/1667\n",
            "Epoch 1577: Training Accuracy = 0.9922, Training Loss = 0.0658, Validation Accuracy = 0.9904, Validation Loss = 0.1020\n",
            "Epoch 1578/1667\n",
            "Epoch 1578: Training Accuracy = 0.9922, Training Loss = 0.0658, Validation Accuracy = 0.9904, Validation Loss = 0.1020\n",
            "Epoch 1579/1667\n",
            "Epoch 1579: Training Accuracy = 0.9902, Training Loss = 0.0724, Validation Accuracy = 0.9904, Validation Loss = 0.1014\n",
            "Epoch 1580/1667\n",
            "Epoch 1580: Training Accuracy = 0.9902, Training Loss = 0.0724, Validation Accuracy = 0.9904, Validation Loss = 0.1014\n",
            "Epoch 1581/1667\n",
            "Epoch 1581: Training Accuracy = 0.9883, Training Loss = 0.0762, Validation Accuracy = 0.9904, Validation Loss = 0.1008\n",
            "Epoch 1582/1667\n",
            "Epoch 1582: Training Accuracy = 0.9902, Training Loss = 0.0761, Validation Accuracy = 0.9904, Validation Loss = 0.0995\n",
            "Epoch 1583/1667\n",
            "Epoch 1583: Training Accuracy = 0.9902, Training Loss = 0.0761, Validation Accuracy = 0.9904, Validation Loss = 0.0995\n",
            "Epoch 1584/1667\n",
            "Epoch 1584: Training Accuracy = 0.9922, Training Loss = 0.0689, Validation Accuracy = 0.9904, Validation Loss = 0.1014\n",
            "Epoch 1585/1667\n",
            "Epoch 1585: Training Accuracy = 0.9922, Training Loss = 0.0689, Validation Accuracy = 0.9904, Validation Loss = 0.1014\n",
            "Epoch 1586/1667\n",
            "Epoch 1586: Training Accuracy = 0.9902, Training Loss = 0.0688, Validation Accuracy = 0.9904, Validation Loss = 0.1001\n",
            "Epoch 1587/1667\n",
            "Epoch 1587: Training Accuracy = 0.9844, Training Loss = 0.0944, Validation Accuracy = 0.9904, Validation Loss = 0.0984\n",
            "Epoch 1588/1667\n",
            "Epoch 1588: Training Accuracy = 0.9844, Training Loss = 0.0944, Validation Accuracy = 0.9904, Validation Loss = 0.0984\n",
            "Epoch 1589/1667\n",
            "Epoch 1589: Training Accuracy = 0.9824, Training Loss = 0.1013, Validation Accuracy = 0.9904, Validation Loss = 0.1069\n",
            "Epoch 1590/1667\n",
            "Epoch 1590: Training Accuracy = 0.9824, Training Loss = 0.1013, Validation Accuracy = 0.9904, Validation Loss = 0.1069\n",
            "Epoch 1591/1667\n",
            "Epoch 1591: Training Accuracy = 0.6738, Training Loss = 1.4079, Validation Accuracy = 0.7293, Validation Loss = 1.2390\n",
            "Epoch 1592/1667\n",
            "Epoch 1592: Training Accuracy = 0.9531, Training Loss = 0.3979, Validation Accuracy = 0.9622, Validation Loss = 0.4887\n",
            "Epoch 1593/1667\n",
            "Epoch 1593: Training Accuracy = 0.9531, Training Loss = 0.3979, Validation Accuracy = 0.9622, Validation Loss = 0.4887\n",
            "Epoch 1594/1667\n",
            "Epoch 1594: Training Accuracy = 0.9844, Training Loss = 0.1855, Validation Accuracy = 0.9882, Validation Loss = 0.2271\n",
            "Epoch 1595/1667\n",
            "Epoch 1595: Training Accuracy = 0.9844, Training Loss = 0.1855, Validation Accuracy = 0.9882, Validation Loss = 0.2271\n",
            "Epoch 1596/1667\n",
            "Epoch 1596: Training Accuracy = 0.9863, Training Loss = 0.1213, Validation Accuracy = 0.9903, Validation Loss = 0.1475\n",
            "Epoch 1597/1667\n",
            "Epoch 1597: Training Accuracy = 0.9863, Training Loss = 0.0975, Validation Accuracy = 0.9904, Validation Loss = 0.1143\n",
            "Epoch 1598/1667\n",
            "Epoch 1598: Training Accuracy = 0.9863, Training Loss = 0.0975, Validation Accuracy = 0.9904, Validation Loss = 0.1143\n",
            "Epoch 1599/1667\n",
            "Epoch 1599: Training Accuracy = 0.9863, Training Loss = 0.0891, Validation Accuracy = 0.9904, Validation Loss = 0.1042\n",
            "Epoch 1600/1667\n",
            "Epoch 1600: Training Accuracy = 0.9863, Training Loss = 0.0891, Validation Accuracy = 0.9904, Validation Loss = 0.1042\n",
            "Epoch 1601/1667\n",
            "Epoch 1601: Training Accuracy = 0.9902, Training Loss = 0.0758, Validation Accuracy = 0.9904, Validation Loss = 0.1009\n",
            "Epoch 1602/1667\n",
            "Epoch 1602: Training Accuracy = 0.9922, Training Loss = 0.0632, Validation Accuracy = 0.9904, Validation Loss = 0.1003\n",
            "Epoch 1603/1667\n",
            "Epoch 1603: Training Accuracy = 0.9922, Training Loss = 0.0632, Validation Accuracy = 0.9904, Validation Loss = 0.1003\n",
            "Epoch 1604/1667\n",
            "Epoch 1604: Training Accuracy = 0.9902, Training Loss = 0.0717, Validation Accuracy = 0.9904, Validation Loss = 0.1010\n",
            "Epoch 1605/1667\n",
            "Epoch 1605: Training Accuracy = 0.9902, Training Loss = 0.0717, Validation Accuracy = 0.9904, Validation Loss = 0.1010\n",
            "Epoch 1606/1667\n",
            "Epoch 1606: Training Accuracy = 0.9961, Training Loss = 0.0554, Validation Accuracy = 0.9904, Validation Loss = 0.1010\n",
            "Epoch 1607/1667\n",
            "Epoch 1607: Training Accuracy = 0.9883, Training Loss = 0.0791, Validation Accuracy = 0.9904, Validation Loss = 0.1014\n",
            "Epoch 1608/1667\n",
            "Epoch 1608: Training Accuracy = 0.9883, Training Loss = 0.0791, Validation Accuracy = 0.9904, Validation Loss = 0.1014\n",
            "Epoch 1609/1667\n",
            "Epoch 1609: Training Accuracy = 0.9883, Training Loss = 0.0850, Validation Accuracy = 0.9904, Validation Loss = 0.1004\n",
            "Epoch 1610/1667\n",
            "Epoch 1610: Training Accuracy = 0.9883, Training Loss = 0.0850, Validation Accuracy = 0.9904, Validation Loss = 0.1004\n",
            "Epoch 1611/1667\n",
            "Epoch 1611: Training Accuracy = 0.9922, Training Loss = 0.0636, Validation Accuracy = 0.9904, Validation Loss = 0.0995\n",
            "Epoch 1612/1667\n",
            "Epoch 1612: Training Accuracy = 0.9922, Training Loss = 0.0640, Validation Accuracy = 0.9904, Validation Loss = 0.0993\n",
            "Epoch 1613/1667\n",
            "Epoch 1613: Training Accuracy = 0.9922, Training Loss = 0.0640, Validation Accuracy = 0.9904, Validation Loss = 0.0993\n",
            "Epoch 1614/1667\n",
            "Epoch 1614: Training Accuracy = 0.9883, Training Loss = 0.0782, Validation Accuracy = 0.9904, Validation Loss = 0.1004\n",
            "Epoch 1615/1667\n",
            "Epoch 1615: Training Accuracy = 0.9883, Training Loss = 0.0782, Validation Accuracy = 0.9904, Validation Loss = 0.1004\n",
            "Epoch 1616/1667\n",
            "Epoch 1616: Training Accuracy = 0.9902, Training Loss = 0.0691, Validation Accuracy = 0.9904, Validation Loss = 0.0979\n",
            "Epoch 1617/1667\n",
            "Epoch 1617: Training Accuracy = 0.9805, Training Loss = 0.1069, Validation Accuracy = 0.9904, Validation Loss = 0.0985\n",
            "Epoch 1618/1667\n",
            "Epoch 1618: Training Accuracy = 0.9805, Training Loss = 0.1069, Validation Accuracy = 0.9904, Validation Loss = 0.0985\n",
            "Epoch 1619/1667\n",
            "Epoch 1619: Training Accuracy = 0.9844, Training Loss = 0.0892, Validation Accuracy = 0.9904, Validation Loss = 0.1043\n",
            "Epoch 1620/1667\n",
            "Epoch 1620: Training Accuracy = 0.9844, Training Loss = 0.0892, Validation Accuracy = 0.9904, Validation Loss = 0.1043\n",
            "Epoch 1621/1667\n",
            "Epoch 1621: Training Accuracy = 0.6621, Training Loss = 1.5926, Validation Accuracy = 0.6437, Validation Loss = 1.5345\n",
            "Epoch 1622/1667\n",
            "Epoch 1622: Training Accuracy = 0.9629, Training Loss = 0.4690, Validation Accuracy = 0.9666, Validation Loss = 0.4915\n",
            "Epoch 1623/1667\n",
            "Epoch 1623: Training Accuracy = 0.9629, Training Loss = 0.4690, Validation Accuracy = 0.9666, Validation Loss = 0.4915\n",
            "Epoch 1624/1667\n",
            "Epoch 1624: Training Accuracy = 0.9844, Training Loss = 0.2467, Validation Accuracy = 0.9888, Validation Loss = 0.2567\n",
            "Epoch 1625/1667\n",
            "Epoch 1625: Training Accuracy = 0.9844, Training Loss = 0.2467, Validation Accuracy = 0.9888, Validation Loss = 0.2567\n",
            "Epoch 1626/1667\n",
            "Epoch 1626: Training Accuracy = 0.9922, Training Loss = 0.1314, Validation Accuracy = 0.9903, Validation Loss = 0.1674\n",
            "Epoch 1627/1667\n",
            "Epoch 1627: Training Accuracy = 0.9902, Training Loss = 0.1041, Validation Accuracy = 0.9904, Validation Loss = 0.1326\n",
            "Epoch 1628/1667\n",
            "Epoch 1628: Training Accuracy = 0.9902, Training Loss = 0.1041, Validation Accuracy = 0.9904, Validation Loss = 0.1326\n",
            "Epoch 1629/1667\n",
            "Epoch 1629: Training Accuracy = 0.9941, Training Loss = 0.0791, Validation Accuracy = 0.9904, Validation Loss = 0.1208\n",
            "Epoch 1630/1667\n",
            "Epoch 1630: Training Accuracy = 0.9941, Training Loss = 0.0791, Validation Accuracy = 0.9904, Validation Loss = 0.1208\n",
            "Epoch 1631/1667\n",
            "Epoch 1631: Training Accuracy = 0.9941, Training Loss = 0.0687, Validation Accuracy = 0.9904, Validation Loss = 0.1142\n",
            "Epoch 1632/1667\n",
            "Epoch 1632: Training Accuracy = 0.9941, Training Loss = 0.0701, Validation Accuracy = 0.9904, Validation Loss = 0.1130\n",
            "Epoch 1633/1667\n",
            "Epoch 1633: Training Accuracy = 0.9941, Training Loss = 0.0701, Validation Accuracy = 0.9904, Validation Loss = 0.1130\n",
            "Epoch 1634/1667\n",
            "Epoch 1634: Training Accuracy = 0.9844, Training Loss = 0.1056, Validation Accuracy = 0.9904, Validation Loss = 0.1110\n",
            "Epoch 1635/1667\n",
            "Epoch 1635: Training Accuracy = 0.9844, Training Loss = 0.1056, Validation Accuracy = 0.9904, Validation Loss = 0.1110\n",
            "Epoch 1636/1667\n",
            "Epoch 1636: Training Accuracy = 0.9863, Training Loss = 0.1016, Validation Accuracy = 0.9904, Validation Loss = 0.1104\n",
            "Epoch 1637/1667\n",
            "Epoch 1637: Training Accuracy = 0.9922, Training Loss = 0.0750, Validation Accuracy = 0.9904, Validation Loss = 0.1096\n",
            "Epoch 1638/1667\n",
            "Epoch 1638: Training Accuracy = 0.9922, Training Loss = 0.0750, Validation Accuracy = 0.9904, Validation Loss = 0.1096\n",
            "Epoch 1639/1667\n",
            "Epoch 1639: Training Accuracy = 0.9863, Training Loss = 0.0991, Validation Accuracy = 0.9904, Validation Loss = 0.1084\n",
            "Epoch 1640/1667\n",
            "Epoch 1640: Training Accuracy = 0.9863, Training Loss = 0.0991, Validation Accuracy = 0.9904, Validation Loss = 0.1084\n",
            "Epoch 1641/1667\n",
            "Epoch 1641: Training Accuracy = 0.9902, Training Loss = 0.0844, Validation Accuracy = 0.9904, Validation Loss = 0.1080\n",
            "Epoch 1642/1667\n",
            "Epoch 1642: Training Accuracy = 0.9863, Training Loss = 0.0923, Validation Accuracy = 0.9904, Validation Loss = 0.1046\n",
            "Epoch 1643/1667\n",
            "Epoch 1643: Training Accuracy = 0.9863, Training Loss = 0.0923, Validation Accuracy = 0.9904, Validation Loss = 0.1046\n",
            "Epoch 1644/1667\n",
            "Epoch 1644: Training Accuracy = 0.9902, Training Loss = 0.0769, Validation Accuracy = 0.9904, Validation Loss = 0.1072\n",
            "Epoch 1645/1667\n",
            "Epoch 1645: Training Accuracy = 0.9902, Training Loss = 0.0769, Validation Accuracy = 0.9904, Validation Loss = 0.1072\n",
            "Epoch 1646/1667\n",
            "Epoch 1646: Training Accuracy = 0.9902, Training Loss = 0.0766, Validation Accuracy = 0.9904, Validation Loss = 0.1032\n",
            "Epoch 1647/1667\n",
            "Epoch 1647: Training Accuracy = 0.9941, Training Loss = 0.0607, Validation Accuracy = 0.9904, Validation Loss = 0.1004\n",
            "Epoch 1648/1667\n",
            "Epoch 1648: Training Accuracy = 0.9941, Training Loss = 0.0607, Validation Accuracy = 0.9904, Validation Loss = 0.1004\n",
            "Epoch 1649/1667\n",
            "Epoch 1649: Training Accuracy = 0.9922, Training Loss = 0.0736, Validation Accuracy = 0.9904, Validation Loss = 0.1261\n",
            "Epoch 1650/1667\n",
            "Epoch 1650: Training Accuracy = 0.9922, Training Loss = 0.0736, Validation Accuracy = 0.9904, Validation Loss = 0.1261\n",
            "Epoch 1651/1667\n",
            "Epoch 1651: Training Accuracy = 0.7109, Training Loss = 1.3925, Validation Accuracy = 0.6528, Validation Loss = 1.5411\n",
            "Epoch 1652/1667\n",
            "Epoch 1652: Training Accuracy = 0.9414, Training Loss = 0.5208, Validation Accuracy = 0.9528, Validation Loss = 0.5191\n",
            "Epoch 1653/1667\n",
            "Epoch 1653: Training Accuracy = 0.9414, Training Loss = 0.5208, Validation Accuracy = 0.9528, Validation Loss = 0.5191\n",
            "Epoch 1654/1667\n",
            "Epoch 1654: Training Accuracy = 0.9863, Training Loss = 0.1842, Validation Accuracy = 0.9885, Validation Loss = 0.2286\n",
            "Epoch 1655/1667\n",
            "Epoch 1655: Training Accuracy = 0.9863, Training Loss = 0.1842, Validation Accuracy = 0.9885, Validation Loss = 0.2286\n",
            "Epoch 1656/1667\n",
            "Epoch 1656: Training Accuracy = 0.9883, Training Loss = 0.1242, Validation Accuracy = 0.9904, Validation Loss = 0.1544\n",
            "Epoch 1657/1667\n",
            "Epoch 1657: Training Accuracy = 0.9863, Training Loss = 0.1068, Validation Accuracy = 0.9904, Validation Loss = 0.1255\n",
            "Epoch 1658/1667\n",
            "Epoch 1658: Training Accuracy = 0.9863, Training Loss = 0.1068, Validation Accuracy = 0.9904, Validation Loss = 0.1255\n",
            "Epoch 1659/1667\n",
            "Epoch 1659: Training Accuracy = 0.9941, Training Loss = 0.0671, Validation Accuracy = 0.9904, Validation Loss = 0.1125\n",
            "Epoch 1660/1667\n",
            "Epoch 1660: Training Accuracy = 0.9941, Training Loss = 0.0671, Validation Accuracy = 0.9904, Validation Loss = 0.1125\n",
            "Epoch 1661/1667\n",
            "Epoch 1661: Training Accuracy = 0.9824, Training Loss = 0.1059, Validation Accuracy = 0.9904, Validation Loss = 0.1088\n",
            "Epoch 1662/1667\n",
            "Epoch 1662: Training Accuracy = 0.9922, Training Loss = 0.0712, Validation Accuracy = 0.9904, Validation Loss = 0.1080\n",
            "Epoch 1663/1667\n",
            "Epoch 1663: Training Accuracy = 0.9922, Training Loss = 0.0712, Validation Accuracy = 0.9904, Validation Loss = 0.1080\n",
            "Epoch 1664/1667\n",
            "Epoch 1664: Training Accuracy = 0.9922, Training Loss = 0.0700, Validation Accuracy = 0.9904, Validation Loss = 0.1066\n",
            "Epoch 1665/1667\n",
            "Epoch 1665: Training Accuracy = 0.9922, Training Loss = 0.0700, Validation Accuracy = 0.9904, Validation Loss = 0.1066\n",
            "Epoch 1666/1667\n",
            "Epoch 1666: Training Accuracy = 0.9883, Training Loss = 0.0827, Validation Accuracy = 0.9904, Validation Loss = 0.1064\n",
            "Epoch 1667/1667\n",
            "Epoch 1667: Training Accuracy = 0.9883, Training Loss = 0.0827, Validation Accuracy = 0.9904, Validation Loss = 0.1064\n",
            "Stopping early as maximum number of steps has been reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# バッチサイズを大きく"
      ],
      "metadata": {
        "id": "UziH_cLbXoch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from torch import Tensor\n",
        "from einops import rearrange, repeat\n",
        "from math import ceil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define operations and data functions\n",
        "DIVISION_MODULO_OPERATIONS = {\n",
        "    \"x/y\": lambda x, y, p: (x * y % p, y, x),\n",
        "}\n",
        "\n",
        "ALL_MODULO_OPERATIONS = {\n",
        "    \"x+y\": lambda x, y, _: (x, y, x + y),\n",
        "    \"x-y\": lambda x, y, _: (x, y, x - y),\n",
        "    **DIVISION_MODULO_OPERATIONS,\n",
        "}\n",
        "\n",
        "ALL_OPERATIONS = {\n",
        "    **ALL_MODULO_OPERATIONS,\n",
        "}\n",
        "\n",
        "def operation_mod_p_data(operation: str, p: int, eq_token: int, op_token: int):\n",
        "    x = torch.arange(0, p)\n",
        "    y = torch.arange(0 if operation in DIVISION_MODULO_OPERATIONS else 1, p)\n",
        "    x, y = torch.cartesian_prod(x, y).T\n",
        "\n",
        "    eq = torch.ones_like(x) * eq_token\n",
        "    op = torch.ones_like(x) * op_token\n",
        "\n",
        "    x, y, labels = ALL_OPERATIONS[operation](x, y, p)\n",
        "\n",
        "    inputs = torch.stack([x, op, y, eq], dim=1)\n",
        "\n",
        "    return inputs, labels\n",
        "\n",
        "def get_data(operation: str, prime: int, training_fraction: float, batch_size: int):\n",
        "    inputs, labels = operation_mod_p_data(operation, prime, prime, prime+1)\n",
        "    dataset = TensorDataset(inputs, labels)\n",
        "\n",
        "    train_size = int(training_fraction * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    batch_size = min(batch_size, ceil(len(dataset) / 2))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "# Define the model\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, dim_model: int, n_heads: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn = nn.MultiheadAttention(dim_model, n_heads)\n",
        "        self.self_attn_norm = nn.LayerNorm(dim_model)\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(dim_model, dim_model * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim_model * 4, dim_model)\n",
        "        )\n",
        "        self.ffn_norm = nn.LayerNorm(dim_model)\n",
        "\n",
        "    def forward(self, x: Tensor):\n",
        "        attn_mask = torch.full(\n",
        "            (len(x), len(x)), -float(\"Inf\"), device=x.device, dtype=x.dtype\n",
        "        )\n",
        "        attn_mask = torch.triu(attn_mask, diagonal=1)\n",
        "\n",
        "        a1, _ = self.self_attn(x, x, x, attn_mask=attn_mask)\n",
        "        a1 = self.self_attn_norm(x + a1)\n",
        "        a2 = self.ffn(a1)\n",
        "        a2 = self.ffn_norm(a1 + a2)\n",
        "\n",
        "        return a2\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, num_layers: int, dim_model: int, num_heads: int, num_tokens: int, seq_len: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.token_embeddings = nn.Embedding(num_tokens, dim_model)\n",
        "        self.position_embeddings = nn.Embedding(seq_len, dim_model)\n",
        "        self.model = nn.Sequential(\n",
        "            *[DecoderBlock(dim_model, num_heads) for _ in range(num_layers)],\n",
        "            nn.LayerNorm(dim_model),\n",
        "            nn.Linear(dim_model, num_tokens)\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs: Tensor):\n",
        "        batch_size, context_len = inputs.shape\n",
        "\n",
        "        token_embedding = self.token_embeddings(inputs)\n",
        "\n",
        "        positions = repeat(torch.arange(context_len, device=inputs.device), \"p -> b p\", b=batch_size)\n",
        "        position_embedding = self.position_embeddings(positions)\n",
        "\n",
        "        embedding = token_embedding + position_embedding\n",
        "\n",
        "        embedding = rearrange(embedding, 'b s d -> s b d')\n",
        "\n",
        "        return self.model(embedding)\n",
        "\n",
        "# Training and evaluation functions\n",
        "def evaluate(model, data_loader, device, metrics, step=None):\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    correct = 0\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            inputs, labels = batch\n",
        "            output = model(inputs)[-1, :, :]\n",
        "            correct += (torch.argmax(output, dim=1) == labels).sum().item()\n",
        "            total_loss += criterion(output, labels).item() * len(labels)\n",
        "\n",
        "    accuracy = correct / len(data_loader.dataset)\n",
        "    loss = total_loss / len(data_loader.dataset)\n",
        "\n",
        "    if step is not None:\n",
        "        metrics['validation/accuracy'].append((step, accuracy))\n",
        "        metrics['validation/loss'].append((step, loss))\n",
        "    else:\n",
        "        metrics['validation/accuracy'].append(accuracy)\n",
        "        metrics['validation/loss'].append(loss)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def train(model, train_loader, optimizer, scheduler, val_loader, device, metrics, step, record_frequency, config):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    pbar = tqdm(total=len(train_loader.dataset), desc=\"Training Progress\", unit='sample')\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs, labels = batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)[-1, :, :]\n",
        "        loss = criterion(output, labels)\n",
        "        acc = (torch.argmax(output, dim=1) == labels).sum().item() / len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Update metrics at the end of each batch\n",
        "        if step % record_frequency == 0:\n",
        "            metrics['training/accuracy'].append((step, acc))\n",
        "            metrics['training/loss'].append((step, loss.item()))\n",
        "\n",
        "        pbar.update(inputs.size(0))\n",
        "\n",
        "        # Evaluate validation set every `record_frequency` steps\n",
        "        if step % record_frequency == 0:\n",
        "            metrics = evaluate(model, val_loader, device, metrics, step)\n",
        "\n",
        "        step += 1\n",
        "\n",
        "        # Check if max number of steps is reached\n",
        "        if step >= config['num_steps']:\n",
        "            break\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    return metrics, step\n",
        "\n",
        "# Execute the training and evaluation\n",
        "# Configuration\n",
        "config = {\n",
        "    'operation': 'x/y',\n",
        "    'training_fraction': 0.3,\n",
        "    'prime': 97,\n",
        "    'num_layers': 2,\n",
        "    'dim_model': 128,\n",
        "    'num_heads': 4,\n",
        "    'batch_size': 1024,\n",
        "    'learning_rate': 1e-3,\n",
        "    'weight_decay': 1,\n",
        "    'num_steps': 10000,  # int(1e6)\n",
        "    'max_epochs': int(1e8),\n",
        "    'record_frequency': 10,  # Frequency of recording metrics\n",
        "    'show_progress_bar': False,\n",
        "    'device': 'cpu',\n",
        "}\n",
        "\n",
        "# Training and evaluation functions\n",
        "def train(model, train_loader, optimizer, scheduler, val_loader, device, metrics, step, record_frequency, config):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Conditional progress bar based on config\n",
        "    pbar = tqdm(total=len(train_loader.dataset), desc=\"Training Progress\", unit='sample') if config.get('show_progress_bar', True) else None\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs, labels = batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)[-1, :, :]\n",
        "        loss = criterion(output, labels)\n",
        "        acc = (torch.argmax(output, dim=1) == labels).sum().item() / len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Update metrics at the end of each batch\n",
        "        if step % record_frequency == 0:\n",
        "            metrics['training/accuracy'].append((step, acc))\n",
        "            metrics['training/loss'].append((step, loss.item()))\n",
        "\n",
        "        if pbar:\n",
        "            pbar.update(inputs.size(0))\n",
        "\n",
        "        # Evaluate validation set every `record_frequency` steps\n",
        "        if step % record_frequency == 0:\n",
        "            metrics = evaluate(model, val_loader, device, metrics, step)\n",
        "\n",
        "        step += 1\n",
        "\n",
        "        # Check if max number of steps is reached\n",
        "        if step >= config['num_steps']:\n",
        "            break\n",
        "\n",
        "    if pbar:\n",
        "        pbar.close()\n",
        "\n",
        "    return metrics, step\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "train_loader, val_loader = get_data(\n",
        "    config['operation'],\n",
        "    config['prime'],\n",
        "    config['training_fraction'],\n",
        "    config['batch_size']\n",
        ")\n",
        "model = Transformer(\n",
        "    num_layers=config['num_layers'],\n",
        "    dim_model=config['dim_model'],\n",
        "    num_heads=config['num_heads'],\n",
        "    num_tokens=config['prime'] + 2,\n",
        "    seq_len=5\n",
        ").to(device)\n",
        "optimizer = optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=config['learning_rate'],\n",
        "    betas=(0.9, 0.98),\n",
        "    weight_decay=config['weight_decay']\n",
        ")\n",
        "scheduler = optim.lr_scheduler.LinearLR(\n",
        "    optimizer, start_factor=0.1, total_iters=9\n",
        ")\n",
        "\n",
        "num_epochs = min(config['max_epochs'], ceil(config['num_steps'] / len(train_loader)))\n",
        "\n",
        "metrics = {\n",
        "    'training/accuracy': [],\n",
        "    'training/loss': [],\n",
        "    'validation/accuracy': [],\n",
        "    'validation/loss': []\n",
        "}\n",
        "\n",
        "step = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "    metrics, step = train(model, train_loader, optimizer, scheduler, val_loader, device, metrics, step, config['record_frequency'], config)\n",
        "\n",
        "    # Print metrics for the current epoch in a single line\n",
        "    train_acc = metrics['training/accuracy'][-1][1]\n",
        "    train_loss = metrics['training/loss'][-1][1]\n",
        "    val_acc = metrics['validation/accuracy'][-1][1] if len(metrics['validation/accuracy']) > 0 else 0\n",
        "    val_loss = metrics['validation/loss'][-1][1] if len(metrics['validation/loss']) > 0 else 0\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}: Training Accuracy = {train_acc:.4f}, Training Loss = {train_loss:.4f}, Validation Accuracy = {val_acc:.4f}, Validation Loss = {val_loss:.4f}\")\n",
        "\n",
        "    # Check if max number of steps is reached\n",
        "    if step >= config['num_steps']:\n",
        "        print(\"Stopping early as maximum number of steps has been reached.\")\n",
        "        break\n",
        "\n",
        "# Ensure the final step is evaluated for training metrics\n",
        "metrics['training/accuracy'].append((step, train_acc))\n",
        "metrics['training/loss'].append((step, train_loss))\n",
        "metrics = evaluate(model, val_loader, device, metrics, step)\n",
        "\n",
        "# Plot metrics\n",
        "training_steps, training_accuracy = zip(*metrics['training/accuracy'])\n",
        "training_steps, training_loss = zip(*metrics['training/loss'])\n",
        "val_steps, validation_accuracy = zip(*metrics['validation/accuracy'])\n",
        "val_steps, validation_loss = zip(*metrics['validation/loss'])\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.semilogx(training_steps, [acc * 100 for acc in training_accuracy], color='red', label='Train')\n",
        "plt.semilogx(val_steps, [acc * 100 for acc in validation_accuracy], color='green', label='Val')\n",
        "plt.xlabel('Optimization Steps')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.title(f'Modular Division (training on {int(config[\"training_fraction\"] * 100)}% of data)')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.semilogx(training_steps, training_loss, color='red', label='Train')\n",
        "plt.semilogx(val_steps, validation_loss, color='green', label='Val')\n",
        "plt.xlabel('Optimization Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title(f'Modular Division (training on {int(config[\"training_fraction\"] * 100)}% of data)')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2KFxthodW3Au",
        "outputId": "5ec3384a-bb22-4764-9def-82b66bec468e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "Epoch 835: Training Accuracy = 0.9746, Training Loss = 0.4070, Validation Accuracy = 0.0181, Validation Loss = 6.0677\n",
            "Epoch 836/3334\n",
            "Epoch 836: Training Accuracy = 0.9746, Training Loss = 0.4070, Validation Accuracy = 0.0181, Validation Loss = 6.0677\n",
            "Epoch 837/3334\n",
            "Epoch 837: Training Accuracy = 0.9845, Training Loss = 0.2359, Validation Accuracy = 0.0178, Validation Loss = 6.4284\n",
            "Epoch 838/3334\n",
            "Epoch 838: Training Accuracy = 0.9845, Training Loss = 0.2359, Validation Accuracy = 0.0178, Validation Loss = 6.4284\n",
            "Epoch 839/3334\n",
            "Epoch 839: Training Accuracy = 0.9845, Training Loss = 0.2359, Validation Accuracy = 0.0178, Validation Loss = 6.4284\n",
            "Epoch 840/3334\n",
            "Epoch 840: Training Accuracy = 0.9845, Training Loss = 0.2359, Validation Accuracy = 0.0178, Validation Loss = 6.4284\n",
            "Epoch 841/3334\n",
            "Epoch 841: Training Accuracy = 0.9922, Training Loss = 0.1266, Validation Accuracy = 0.0179, Validation Loss = 6.4794\n",
            "Epoch 842/3334\n",
            "Epoch 842: Training Accuracy = 0.9922, Training Loss = 0.1266, Validation Accuracy = 0.0179, Validation Loss = 6.4794\n",
            "Epoch 843/3334\n",
            "Epoch 843: Training Accuracy = 0.9922, Training Loss = 0.1266, Validation Accuracy = 0.0179, Validation Loss = 6.4794\n",
            "Epoch 844/3334\n",
            "Epoch 844: Training Accuracy = 0.9854, Training Loss = 0.1247, Validation Accuracy = 0.0185, Validation Loss = 6.4988\n",
            "Epoch 845/3334\n",
            "Epoch 845: Training Accuracy = 0.9854, Training Loss = 0.1247, Validation Accuracy = 0.0185, Validation Loss = 6.4988\n",
            "Epoch 846/3334\n",
            "Epoch 846: Training Accuracy = 0.9854, Training Loss = 0.1247, Validation Accuracy = 0.0185, Validation Loss = 6.4988\n",
            "Epoch 847/3334\n",
            "Epoch 847: Training Accuracy = 0.9961, Training Loss = 0.0757, Validation Accuracy = 0.0179, Validation Loss = 6.4924\n",
            "Epoch 848/3334\n",
            "Epoch 848: Training Accuracy = 0.9961, Training Loss = 0.0757, Validation Accuracy = 0.0179, Validation Loss = 6.4924\n",
            "Epoch 849/3334\n",
            "Epoch 849: Training Accuracy = 0.9961, Training Loss = 0.0757, Validation Accuracy = 0.0179, Validation Loss = 6.4924\n",
            "Epoch 850/3334\n",
            "Epoch 850: Training Accuracy = 0.9961, Training Loss = 0.0757, Validation Accuracy = 0.0179, Validation Loss = 6.4924\n",
            "Epoch 851/3334\n",
            "Epoch 851: Training Accuracy = 0.9854, Training Loss = 0.1087, Validation Accuracy = 0.0175, Validation Loss = 6.4792\n",
            "Epoch 852/3334\n",
            "Epoch 852: Training Accuracy = 0.9854, Training Loss = 0.1087, Validation Accuracy = 0.0175, Validation Loss = 6.4792\n",
            "Epoch 853/3334\n",
            "Epoch 853: Training Accuracy = 0.9854, Training Loss = 0.1087, Validation Accuracy = 0.0175, Validation Loss = 6.4792\n",
            "Epoch 854/3334\n",
            "Epoch 854: Training Accuracy = 0.9902, Training Loss = 0.0913, Validation Accuracy = 0.0176, Validation Loss = 6.4704\n",
            "Epoch 855/3334\n",
            "Epoch 855: Training Accuracy = 0.9902, Training Loss = 0.0913, Validation Accuracy = 0.0176, Validation Loss = 6.4704\n",
            "Epoch 856/3334\n",
            "Epoch 856: Training Accuracy = 0.9902, Training Loss = 0.0913, Validation Accuracy = 0.0176, Validation Loss = 6.4704\n",
            "Epoch 857/3334\n",
            "Epoch 857: Training Accuracy = 0.9871, Training Loss = 0.1038, Validation Accuracy = 0.0178, Validation Loss = 6.4576\n",
            "Epoch 858/3334\n",
            "Epoch 858: Training Accuracy = 0.9871, Training Loss = 0.1038, Validation Accuracy = 0.0178, Validation Loss = 6.4576\n",
            "Epoch 859/3334\n",
            "Epoch 859: Training Accuracy = 0.9871, Training Loss = 0.1038, Validation Accuracy = 0.0178, Validation Loss = 6.4576\n",
            "Epoch 860/3334\n",
            "Epoch 860: Training Accuracy = 0.9871, Training Loss = 0.1038, Validation Accuracy = 0.0178, Validation Loss = 6.4576\n",
            "Epoch 861/3334\n",
            "Epoch 861: Training Accuracy = 0.9922, Training Loss = 0.0843, Validation Accuracy = 0.0176, Validation Loss = 6.4238\n",
            "Epoch 862/3334\n",
            "Epoch 862: Training Accuracy = 0.9922, Training Loss = 0.0843, Validation Accuracy = 0.0176, Validation Loss = 6.4238\n",
            "Epoch 863/3334\n",
            "Epoch 863: Training Accuracy = 0.9922, Training Loss = 0.0843, Validation Accuracy = 0.0176, Validation Loss = 6.4238\n",
            "Epoch 864/3334\n",
            "Epoch 864: Training Accuracy = 0.9893, Training Loss = 0.1005, Validation Accuracy = 0.0182, Validation Loss = 6.4252\n",
            "Epoch 865/3334\n",
            "Epoch 865: Training Accuracy = 0.9893, Training Loss = 0.1005, Validation Accuracy = 0.0182, Validation Loss = 6.4252\n",
            "Epoch 866/3334\n",
            "Epoch 866: Training Accuracy = 0.9893, Training Loss = 0.1005, Validation Accuracy = 0.0182, Validation Loss = 6.4252\n",
            "Epoch 867/3334\n",
            "Epoch 867: Training Accuracy = 0.6227, Training Loss = 1.6481, Validation Accuracy = 0.0172, Validation Loss = 6.0859\n",
            "Epoch 868/3334\n",
            "Epoch 868: Training Accuracy = 0.6227, Training Loss = 1.6481, Validation Accuracy = 0.0172, Validation Loss = 6.0859\n",
            "Epoch 869/3334\n",
            "Epoch 869: Training Accuracy = 0.6227, Training Loss = 1.6481, Validation Accuracy = 0.0172, Validation Loss = 6.0859\n",
            "Epoch 870/3334\n",
            "Epoch 870: Training Accuracy = 0.6227, Training Loss = 1.6481, Validation Accuracy = 0.0172, Validation Loss = 6.0859\n",
            "Epoch 871/3334\n",
            "Epoch 871: Training Accuracy = 0.9707, Training Loss = 0.4486, Validation Accuracy = 0.0190, Validation Loss = 5.9875\n",
            "Epoch 872/3334\n",
            "Epoch 872: Training Accuracy = 0.9707, Training Loss = 0.4486, Validation Accuracy = 0.0190, Validation Loss = 5.9875\n",
            "Epoch 873/3334\n",
            "Epoch 873: Training Accuracy = 0.9707, Training Loss = 0.4486, Validation Accuracy = 0.0190, Validation Loss = 5.9875\n",
            "Epoch 874/3334\n",
            "Epoch 874: Training Accuracy = 0.9893, Training Loss = 0.2182, Validation Accuracy = 0.0181, Validation Loss = 6.3321\n",
            "Epoch 875/3334\n",
            "Epoch 875: Training Accuracy = 0.9893, Training Loss = 0.2182, Validation Accuracy = 0.0181, Validation Loss = 6.3321\n",
            "Epoch 876/3334\n",
            "Epoch 876: Training Accuracy = 0.9893, Training Loss = 0.2182, Validation Accuracy = 0.0181, Validation Loss = 6.3321\n",
            "Epoch 877/3334\n",
            "Epoch 877: Training Accuracy = 0.9858, Training Loss = 0.1644, Validation Accuracy = 0.0178, Validation Loss = 6.4397\n",
            "Epoch 878/3334\n",
            "Epoch 878: Training Accuracy = 0.9858, Training Loss = 0.1644, Validation Accuracy = 0.0178, Validation Loss = 6.4397\n",
            "Epoch 879/3334\n",
            "Epoch 879: Training Accuracy = 0.9858, Training Loss = 0.1644, Validation Accuracy = 0.0178, Validation Loss = 6.4397\n",
            "Epoch 880/3334\n",
            "Epoch 880: Training Accuracy = 0.9858, Training Loss = 0.1644, Validation Accuracy = 0.0178, Validation Loss = 6.4397\n",
            "Epoch 881/3334\n",
            "Epoch 881: Training Accuracy = 0.9922, Training Loss = 0.1046, Validation Accuracy = 0.0178, Validation Loss = 6.4500\n",
            "Epoch 882/3334\n",
            "Epoch 882: Training Accuracy = 0.9922, Training Loss = 0.1046, Validation Accuracy = 0.0178, Validation Loss = 6.4500\n",
            "Epoch 883/3334\n",
            "Epoch 883: Training Accuracy = 0.9922, Training Loss = 0.1046, Validation Accuracy = 0.0178, Validation Loss = 6.4500\n",
            "Epoch 884/3334\n",
            "Epoch 884: Training Accuracy = 0.9922, Training Loss = 0.0906, Validation Accuracy = 0.0182, Validation Loss = 6.4498\n",
            "Epoch 885/3334\n",
            "Epoch 885: Training Accuracy = 0.9922, Training Loss = 0.0906, Validation Accuracy = 0.0182, Validation Loss = 6.4498\n",
            "Epoch 886/3334\n",
            "Epoch 886: Training Accuracy = 0.9922, Training Loss = 0.0906, Validation Accuracy = 0.0182, Validation Loss = 6.4498\n",
            "Epoch 887/3334\n",
            "Epoch 887: Training Accuracy = 0.9871, Training Loss = 0.1085, Validation Accuracy = 0.0181, Validation Loss = 6.4471\n",
            "Epoch 888/3334\n",
            "Epoch 888: Training Accuracy = 0.9871, Training Loss = 0.1085, Validation Accuracy = 0.0181, Validation Loss = 6.4471\n",
            "Epoch 889/3334\n",
            "Epoch 889: Training Accuracy = 0.9871, Training Loss = 0.1085, Validation Accuracy = 0.0181, Validation Loss = 6.4471\n",
            "Epoch 890/3334\n",
            "Epoch 890: Training Accuracy = 0.9871, Training Loss = 0.1085, Validation Accuracy = 0.0181, Validation Loss = 6.4471\n",
            "Epoch 891/3334\n",
            "Epoch 891: Training Accuracy = 0.9902, Training Loss = 0.0927, Validation Accuracy = 0.0182, Validation Loss = 6.4270\n",
            "Epoch 892/3334\n",
            "Epoch 892: Training Accuracy = 0.9902, Training Loss = 0.0927, Validation Accuracy = 0.0182, Validation Loss = 6.4270\n",
            "Epoch 893/3334\n",
            "Epoch 893: Training Accuracy = 0.9902, Training Loss = 0.0927, Validation Accuracy = 0.0182, Validation Loss = 6.4270\n",
            "Epoch 894/3334\n",
            "Epoch 894: Training Accuracy = 0.9863, Training Loss = 0.1068, Validation Accuracy = 0.0178, Validation Loss = 6.4298\n",
            "Epoch 895/3334\n",
            "Epoch 895: Training Accuracy = 0.9863, Training Loss = 0.1068, Validation Accuracy = 0.0178, Validation Loss = 6.4298\n",
            "Epoch 896/3334\n",
            "Epoch 896: Training Accuracy = 0.9863, Training Loss = 0.1068, Validation Accuracy = 0.0178, Validation Loss = 6.4298\n",
            "Epoch 897/3334\n",
            "Epoch 897: Training Accuracy = 0.9910, Training Loss = 0.0937, Validation Accuracy = 0.0182, Validation Loss = 6.4164\n",
            "Epoch 898/3334\n",
            "Epoch 898: Training Accuracy = 0.9910, Training Loss = 0.0937, Validation Accuracy = 0.0182, Validation Loss = 6.4164\n",
            "Epoch 899/3334\n",
            "Epoch 899: Training Accuracy = 0.9910, Training Loss = 0.0937, Validation Accuracy = 0.0182, Validation Loss = 6.4164\n",
            "Epoch 900/3334\n",
            "Epoch 900: Training Accuracy = 0.9910, Training Loss = 0.0937, Validation Accuracy = 0.0182, Validation Loss = 6.4164\n",
            "Epoch 901/3334\n",
            "Epoch 901: Training Accuracy = 0.9883, Training Loss = 0.0937, Validation Accuracy = 0.0170, Validation Loss = 6.4017\n",
            "Epoch 902/3334\n",
            "Epoch 902: Training Accuracy = 0.9883, Training Loss = 0.0937, Validation Accuracy = 0.0170, Validation Loss = 6.4017\n",
            "Epoch 903/3334\n",
            "Epoch 903: Training Accuracy = 0.9883, Training Loss = 0.0937, Validation Accuracy = 0.0170, Validation Loss = 6.4017\n",
            "Epoch 904/3334\n",
            "Epoch 904: Training Accuracy = 0.6328, Training Loss = 1.8193, Validation Accuracy = 0.0167, Validation Loss = 6.0115\n",
            "Epoch 905/3334\n",
            "Epoch 905: Training Accuracy = 0.6328, Training Loss = 1.8193, Validation Accuracy = 0.0167, Validation Loss = 6.0115\n",
            "Epoch 906/3334\n",
            "Epoch 906: Training Accuracy = 0.6328, Training Loss = 1.8193, Validation Accuracy = 0.0167, Validation Loss = 6.0115\n",
            "Epoch 907/3334\n",
            "Epoch 907: Training Accuracy = 0.9457, Training Loss = 0.5783, Validation Accuracy = 0.0181, Validation Loss = 5.9028\n",
            "Epoch 908/3334\n",
            "Epoch 908: Training Accuracy = 0.9457, Training Loss = 0.5783, Validation Accuracy = 0.0181, Validation Loss = 5.9028\n",
            "Epoch 909/3334\n",
            "Epoch 909: Training Accuracy = 0.9457, Training Loss = 0.5783, Validation Accuracy = 0.0181, Validation Loss = 5.9028\n",
            "Epoch 910/3334\n",
            "Epoch 910: Training Accuracy = 0.9457, Training Loss = 0.5783, Validation Accuracy = 0.0181, Validation Loss = 5.9028\n",
            "Epoch 911/3334\n",
            "Epoch 911: Training Accuracy = 0.9893, Training Loss = 0.2452, Validation Accuracy = 0.0193, Validation Loss = 6.2718\n",
            "Epoch 912/3334\n",
            "Epoch 912: Training Accuracy = 0.9893, Training Loss = 0.2452, Validation Accuracy = 0.0193, Validation Loss = 6.2718\n",
            "Epoch 913/3334\n",
            "Epoch 913: Training Accuracy = 0.9893, Training Loss = 0.2452, Validation Accuracy = 0.0193, Validation Loss = 6.2718\n",
            "Epoch 914/3334\n",
            "Epoch 914: Training Accuracy = 0.9902, Training Loss = 0.1593, Validation Accuracy = 0.0187, Validation Loss = 6.3698\n",
            "Epoch 915/3334\n",
            "Epoch 915: Training Accuracy = 0.9902, Training Loss = 0.1593, Validation Accuracy = 0.0187, Validation Loss = 6.3698\n",
            "Epoch 916/3334\n",
            "Epoch 916: Training Accuracy = 0.9902, Training Loss = 0.1593, Validation Accuracy = 0.0187, Validation Loss = 6.3698\n",
            "Epoch 917/3334\n",
            "Epoch 917: Training Accuracy = 0.9910, Training Loss = 0.1235, Validation Accuracy = 0.0191, Validation Loss = 6.3609\n",
            "Epoch 918/3334\n",
            "Epoch 918: Training Accuracy = 0.9910, Training Loss = 0.1235, Validation Accuracy = 0.0191, Validation Loss = 6.3609\n",
            "Epoch 919/3334\n",
            "Epoch 919: Training Accuracy = 0.9910, Training Loss = 0.1235, Validation Accuracy = 0.0191, Validation Loss = 6.3609\n",
            "Epoch 920/3334\n",
            "Epoch 920: Training Accuracy = 0.9910, Training Loss = 0.1235, Validation Accuracy = 0.0191, Validation Loss = 6.3609\n",
            "Epoch 921/3334\n",
            "Epoch 921: Training Accuracy = 0.9863, Training Loss = 0.1194, Validation Accuracy = 0.0191, Validation Loss = 6.3765\n",
            "Epoch 922/3334\n",
            "Epoch 922: Training Accuracy = 0.9863, Training Loss = 0.1194, Validation Accuracy = 0.0191, Validation Loss = 6.3765\n",
            "Epoch 923/3334\n",
            "Epoch 923: Training Accuracy = 0.9863, Training Loss = 0.1194, Validation Accuracy = 0.0191, Validation Loss = 6.3765\n",
            "Epoch 924/3334\n",
            "Epoch 924: Training Accuracy = 0.9902, Training Loss = 0.1003, Validation Accuracy = 0.0181, Validation Loss = 6.3766\n",
            "Epoch 925/3334\n",
            "Epoch 925: Training Accuracy = 0.9902, Training Loss = 0.1003, Validation Accuracy = 0.0181, Validation Loss = 6.3766\n",
            "Epoch 926/3334\n",
            "Epoch 926: Training Accuracy = 0.9902, Training Loss = 0.1003, Validation Accuracy = 0.0181, Validation Loss = 6.3766\n",
            "Epoch 927/3334\n",
            "Epoch 927: Training Accuracy = 0.9935, Training Loss = 0.0864, Validation Accuracy = 0.0185, Validation Loss = 6.3684\n",
            "Epoch 928/3334\n",
            "Epoch 928: Training Accuracy = 0.9935, Training Loss = 0.0864, Validation Accuracy = 0.0185, Validation Loss = 6.3684\n",
            "Epoch 929/3334\n",
            "Epoch 929: Training Accuracy = 0.9935, Training Loss = 0.0864, Validation Accuracy = 0.0185, Validation Loss = 6.3684\n",
            "Epoch 930/3334\n",
            "Epoch 930: Training Accuracy = 0.9935, Training Loss = 0.0864, Validation Accuracy = 0.0185, Validation Loss = 6.3684\n",
            "Epoch 931/3334\n",
            "Epoch 931: Training Accuracy = 0.9902, Training Loss = 0.0932, Validation Accuracy = 0.0190, Validation Loss = 6.3486\n",
            "Epoch 932/3334\n",
            "Epoch 932: Training Accuracy = 0.9902, Training Loss = 0.0932, Validation Accuracy = 0.0190, Validation Loss = 6.3486\n",
            "Epoch 933/3334\n",
            "Epoch 933: Training Accuracy = 0.9902, Training Loss = 0.0932, Validation Accuracy = 0.0190, Validation Loss = 6.3486\n",
            "Epoch 934/3334\n",
            "Epoch 934: Training Accuracy = 0.9893, Training Loss = 0.0992, Validation Accuracy = 0.0190, Validation Loss = 6.3189\n",
            "Epoch 935/3334\n",
            "Epoch 935: Training Accuracy = 0.9893, Training Loss = 0.0992, Validation Accuracy = 0.0190, Validation Loss = 6.3189\n",
            "Epoch 936/3334\n",
            "Epoch 936: Training Accuracy = 0.9893, Training Loss = 0.0992, Validation Accuracy = 0.0190, Validation Loss = 6.3189\n",
            "Epoch 937/3334\n",
            "Epoch 937: Training Accuracy = 0.9910, Training Loss = 0.0963, Validation Accuracy = 0.0181, Validation Loss = 6.3394\n",
            "Epoch 938/3334\n",
            "Epoch 938: Training Accuracy = 0.9910, Training Loss = 0.0963, Validation Accuracy = 0.0181, Validation Loss = 6.3394\n",
            "Epoch 939/3334\n",
            "Epoch 939: Training Accuracy = 0.9910, Training Loss = 0.0963, Validation Accuracy = 0.0181, Validation Loss = 6.3394\n",
            "Epoch 940/3334\n",
            "Epoch 940: Training Accuracy = 0.9910, Training Loss = 0.0963, Validation Accuracy = 0.0181, Validation Loss = 6.3394\n",
            "Epoch 941/3334\n",
            "Epoch 941: Training Accuracy = 0.9902, Training Loss = 0.0957, Validation Accuracy = 0.0182, Validation Loss = 6.3277\n",
            "Epoch 942/3334\n",
            "Epoch 942: Training Accuracy = 0.9902, Training Loss = 0.0957, Validation Accuracy = 0.0182, Validation Loss = 6.3277\n",
            "Epoch 943/3334\n",
            "Epoch 943: Training Accuracy = 0.9902, Training Loss = 0.0957, Validation Accuracy = 0.0182, Validation Loss = 6.3277\n",
            "Epoch 944/3334\n",
            "Epoch 944: Training Accuracy = 0.9863, Training Loss = 0.1176, Validation Accuracy = 0.0185, Validation Loss = 6.3328\n",
            "Epoch 945/3334\n",
            "Epoch 945: Training Accuracy = 0.9863, Training Loss = 0.1176, Validation Accuracy = 0.0185, Validation Loss = 6.3328\n",
            "Epoch 946/3334\n",
            "Epoch 946: Training Accuracy = 0.9863, Training Loss = 0.1176, Validation Accuracy = 0.0185, Validation Loss = 6.3328\n",
            "Epoch 947/3334\n",
            "Epoch 947: Training Accuracy = 0.6240, Training Loss = 1.6272, Validation Accuracy = 0.0185, Validation Loss = 5.6613\n",
            "Epoch 948/3334\n",
            "Epoch 948: Training Accuracy = 0.6240, Training Loss = 1.6272, Validation Accuracy = 0.0185, Validation Loss = 5.6613\n",
            "Epoch 949/3334\n",
            "Epoch 949: Training Accuracy = 0.6240, Training Loss = 1.6272, Validation Accuracy = 0.0185, Validation Loss = 5.6613\n",
            "Epoch 950/3334\n",
            "Epoch 950: Training Accuracy = 0.6240, Training Loss = 1.6272, Validation Accuracy = 0.0185, Validation Loss = 5.6613\n",
            "Epoch 951/3334\n",
            "Epoch 951: Training Accuracy = 0.9590, Training Loss = 0.4774, Validation Accuracy = 0.0199, Validation Loss = 5.9188\n",
            "Epoch 952/3334\n",
            "Epoch 952: Training Accuracy = 0.9590, Training Loss = 0.4774, Validation Accuracy = 0.0199, Validation Loss = 5.9188\n",
            "Epoch 953/3334\n",
            "Epoch 953: Training Accuracy = 0.9590, Training Loss = 0.4774, Validation Accuracy = 0.0199, Validation Loss = 5.9188\n",
            "Epoch 954/3334\n",
            "Epoch 954: Training Accuracy = 0.9863, Training Loss = 0.2451, Validation Accuracy = 0.0173, Validation Loss = 6.2286\n",
            "Epoch 955/3334\n",
            "Epoch 955: Training Accuracy = 0.9863, Training Loss = 0.2451, Validation Accuracy = 0.0173, Validation Loss = 6.2286\n",
            "Epoch 956/3334\n",
            "Epoch 956: Training Accuracy = 0.9863, Training Loss = 0.2451, Validation Accuracy = 0.0173, Validation Loss = 6.2286\n",
            "Epoch 957/3334\n",
            "Epoch 957: Training Accuracy = 0.9884, Training Loss = 0.1554, Validation Accuracy = 0.0187, Validation Loss = 6.2906\n",
            "Epoch 958/3334\n",
            "Epoch 958: Training Accuracy = 0.9884, Training Loss = 0.1554, Validation Accuracy = 0.0187, Validation Loss = 6.2906\n",
            "Epoch 959/3334\n",
            "Epoch 959: Training Accuracy = 0.9884, Training Loss = 0.1554, Validation Accuracy = 0.0187, Validation Loss = 6.2906\n",
            "Epoch 960/3334\n",
            "Epoch 960: Training Accuracy = 0.9884, Training Loss = 0.1554, Validation Accuracy = 0.0187, Validation Loss = 6.2906\n",
            "Epoch 961/3334\n",
            "Epoch 961: Training Accuracy = 0.9863, Training Loss = 0.1242, Validation Accuracy = 0.0175, Validation Loss = 6.3102\n",
            "Epoch 962/3334\n",
            "Epoch 962: Training Accuracy = 0.9863, Training Loss = 0.1242, Validation Accuracy = 0.0175, Validation Loss = 6.3102\n",
            "Epoch 963/3334\n",
            "Epoch 963: Training Accuracy = 0.9863, Training Loss = 0.1242, Validation Accuracy = 0.0175, Validation Loss = 6.3102\n",
            "Epoch 964/3334\n",
            "Epoch 964: Training Accuracy = 0.9854, Training Loss = 0.1165, Validation Accuracy = 0.0184, Validation Loss = 6.3007\n",
            "Epoch 965/3334\n",
            "Epoch 965: Training Accuracy = 0.9854, Training Loss = 0.1165, Validation Accuracy = 0.0184, Validation Loss = 6.3007\n",
            "Epoch 966/3334\n",
            "Epoch 966: Training Accuracy = 0.9854, Training Loss = 0.1165, Validation Accuracy = 0.0184, Validation Loss = 6.3007\n",
            "Epoch 967/3334\n",
            "Epoch 967: Training Accuracy = 0.9871, Training Loss = 0.1078, Validation Accuracy = 0.0188, Validation Loss = 6.2971\n",
            "Epoch 968/3334\n",
            "Epoch 968: Training Accuracy = 0.9871, Training Loss = 0.1078, Validation Accuracy = 0.0188, Validation Loss = 6.2971\n",
            "Epoch 969/3334\n",
            "Epoch 969: Training Accuracy = 0.9871, Training Loss = 0.1078, Validation Accuracy = 0.0188, Validation Loss = 6.2971\n",
            "Epoch 970/3334\n",
            "Epoch 970: Training Accuracy = 0.9871, Training Loss = 0.1078, Validation Accuracy = 0.0188, Validation Loss = 6.2971\n",
            "Epoch 971/3334\n",
            "Epoch 971: Training Accuracy = 0.9932, Training Loss = 0.0822, Validation Accuracy = 0.0170, Validation Loss = 6.2918\n",
            "Epoch 972/3334\n",
            "Epoch 972: Training Accuracy = 0.9932, Training Loss = 0.0822, Validation Accuracy = 0.0170, Validation Loss = 6.2918\n",
            "Epoch 973/3334\n",
            "Epoch 973: Training Accuracy = 0.9932, Training Loss = 0.0822, Validation Accuracy = 0.0170, Validation Loss = 6.2918\n",
            "Epoch 974/3334\n",
            "Epoch 974: Training Accuracy = 0.9912, Training Loss = 0.0896, Validation Accuracy = 0.0185, Validation Loss = 6.2725\n",
            "Epoch 975/3334\n",
            "Epoch 975: Training Accuracy = 0.9912, Training Loss = 0.0896, Validation Accuracy = 0.0185, Validation Loss = 6.2725\n",
            "Epoch 976/3334\n",
            "Epoch 976: Training Accuracy = 0.9912, Training Loss = 0.0896, Validation Accuracy = 0.0185, Validation Loss = 6.2725\n",
            "Epoch 977/3334\n",
            "Epoch 977: Training Accuracy = 0.9858, Training Loss = 0.1104, Validation Accuracy = 0.0193, Validation Loss = 6.2618\n",
            "Epoch 978/3334\n",
            "Epoch 978: Training Accuracy = 0.9858, Training Loss = 0.1104, Validation Accuracy = 0.0193, Validation Loss = 6.2618\n",
            "Epoch 979/3334\n",
            "Epoch 979: Training Accuracy = 0.9858, Training Loss = 0.1104, Validation Accuracy = 0.0193, Validation Loss = 6.2618\n",
            "Epoch 980/3334\n",
            "Epoch 980: Training Accuracy = 0.9858, Training Loss = 0.1104, Validation Accuracy = 0.0193, Validation Loss = 6.2618\n",
            "Epoch 981/3334\n",
            "Epoch 981: Training Accuracy = 0.9844, Training Loss = 0.1117, Validation Accuracy = 0.0188, Validation Loss = 6.2581\n",
            "Epoch 982/3334\n",
            "Epoch 982: Training Accuracy = 0.9844, Training Loss = 0.1117, Validation Accuracy = 0.0188, Validation Loss = 6.2581\n",
            "Epoch 983/3334\n",
            "Epoch 983: Training Accuracy = 0.9844, Training Loss = 0.1117, Validation Accuracy = 0.0188, Validation Loss = 6.2581\n",
            "Epoch 984/3334\n",
            "Epoch 984: Training Accuracy = 0.9883, Training Loss = 0.1021, Validation Accuracy = 0.0190, Validation Loss = 6.2384\n",
            "Epoch 985/3334\n",
            "Epoch 985: Training Accuracy = 0.9883, Training Loss = 0.1021, Validation Accuracy = 0.0190, Validation Loss = 6.2384\n",
            "Epoch 986/3334\n",
            "Epoch 986: Training Accuracy = 0.9883, Training Loss = 0.1021, Validation Accuracy = 0.0190, Validation Loss = 6.2384\n",
            "Epoch 987/3334\n",
            "Epoch 987: Training Accuracy = 0.4858, Training Loss = 2.1564, Validation Accuracy = 0.0191, Validation Loss = 5.7499\n",
            "Epoch 988/3334\n",
            "Epoch 988: Training Accuracy = 0.4858, Training Loss = 2.1564, Validation Accuracy = 0.0191, Validation Loss = 5.7499\n",
            "Epoch 989/3334\n",
            "Epoch 989: Training Accuracy = 0.4858, Training Loss = 2.1564, Validation Accuracy = 0.0191, Validation Loss = 5.7499\n",
            "Epoch 990/3334\n",
            "Epoch 990: Training Accuracy = 0.4858, Training Loss = 2.1564, Validation Accuracy = 0.0191, Validation Loss = 5.7499\n",
            "Epoch 991/3334\n",
            "Epoch 991: Training Accuracy = 0.9775, Training Loss = 0.4194, Validation Accuracy = 0.0199, Validation Loss = 5.7893\n",
            "Epoch 992/3334\n",
            "Epoch 992: Training Accuracy = 0.9775, Training Loss = 0.4194, Validation Accuracy = 0.0199, Validation Loss = 5.7893\n",
            "Epoch 993/3334\n",
            "Epoch 993: Training Accuracy = 0.9775, Training Loss = 0.4194, Validation Accuracy = 0.0199, Validation Loss = 5.7893\n",
            "Epoch 994/3334\n",
            "Epoch 994: Training Accuracy = 0.9834, Training Loss = 0.2668, Validation Accuracy = 0.0181, Validation Loss = 6.1524\n",
            "Epoch 995/3334\n",
            "Epoch 995: Training Accuracy = 0.9834, Training Loss = 0.2668, Validation Accuracy = 0.0181, Validation Loss = 6.1524\n",
            "Epoch 996/3334\n",
            "Epoch 996: Training Accuracy = 0.9834, Training Loss = 0.2668, Validation Accuracy = 0.0181, Validation Loss = 6.1524\n",
            "Epoch 997/3334\n",
            "Epoch 997: Training Accuracy = 0.9858, Training Loss = 0.1675, Validation Accuracy = 0.0196, Validation Loss = 6.2252\n",
            "Epoch 998/3334\n",
            "Epoch 998: Training Accuracy = 0.9858, Training Loss = 0.1675, Validation Accuracy = 0.0196, Validation Loss = 6.2252\n",
            "Epoch 999/3334\n",
            "Epoch 999: Training Accuracy = 0.9858, Training Loss = 0.1675, Validation Accuracy = 0.0196, Validation Loss = 6.2252\n",
            "Epoch 1000/3334\n",
            "Epoch 1000: Training Accuracy = 0.9858, Training Loss = 0.1675, Validation Accuracy = 0.0196, Validation Loss = 6.2252\n",
            "Epoch 1001/3334\n",
            "Epoch 1001: Training Accuracy = 0.9971, Training Loss = 0.0884, Validation Accuracy = 0.0181, Validation Loss = 6.2282\n",
            "Epoch 1002/3334\n",
            "Epoch 1002: Training Accuracy = 0.9971, Training Loss = 0.0884, Validation Accuracy = 0.0181, Validation Loss = 6.2282\n",
            "Epoch 1003/3334\n",
            "Epoch 1003: Training Accuracy = 0.9971, Training Loss = 0.0884, Validation Accuracy = 0.0181, Validation Loss = 6.2282\n",
            "Epoch 1004/3334\n",
            "Epoch 1004: Training Accuracy = 0.9902, Training Loss = 0.0981, Validation Accuracy = 0.0179, Validation Loss = 6.2492\n",
            "Epoch 1005/3334\n",
            "Epoch 1005: Training Accuracy = 0.9902, Training Loss = 0.0981, Validation Accuracy = 0.0179, Validation Loss = 6.2492\n",
            "Epoch 1006/3334\n",
            "Epoch 1006: Training Accuracy = 0.9902, Training Loss = 0.0981, Validation Accuracy = 0.0179, Validation Loss = 6.2492\n",
            "Epoch 1007/3334\n",
            "Epoch 1007: Training Accuracy = 0.9884, Training Loss = 0.0991, Validation Accuracy = 0.0187, Validation Loss = 6.2520\n",
            "Epoch 1008/3334\n",
            "Epoch 1008: Training Accuracy = 0.9884, Training Loss = 0.0991, Validation Accuracy = 0.0187, Validation Loss = 6.2520\n",
            "Epoch 1009/3334\n",
            "Epoch 1009: Training Accuracy = 0.9884, Training Loss = 0.0991, Validation Accuracy = 0.0187, Validation Loss = 6.2520\n",
            "Epoch 1010/3334\n",
            "Epoch 1010: Training Accuracy = 0.9884, Training Loss = 0.0991, Validation Accuracy = 0.0187, Validation Loss = 6.2520\n",
            "Epoch 1011/3334\n",
            "Epoch 1011: Training Accuracy = 0.9912, Training Loss = 0.0856, Validation Accuracy = 0.0191, Validation Loss = 6.2452\n",
            "Epoch 1012/3334\n",
            "Epoch 1012: Training Accuracy = 0.9912, Training Loss = 0.0856, Validation Accuracy = 0.0191, Validation Loss = 6.2452\n",
            "Epoch 1013/3334\n",
            "Epoch 1013: Training Accuracy = 0.9912, Training Loss = 0.0856, Validation Accuracy = 0.0191, Validation Loss = 6.2452\n",
            "Epoch 1014/3334\n",
            "Epoch 1014: Training Accuracy = 0.9902, Training Loss = 0.0876, Validation Accuracy = 0.0190, Validation Loss = 6.2354\n",
            "Epoch 1015/3334\n",
            "Epoch 1015: Training Accuracy = 0.9902, Training Loss = 0.0876, Validation Accuracy = 0.0190, Validation Loss = 6.2354\n",
            "Epoch 1016/3334\n",
            "Epoch 1016: Training Accuracy = 0.9902, Training Loss = 0.0876, Validation Accuracy = 0.0190, Validation Loss = 6.2354\n",
            "Epoch 1017/3334\n",
            "Epoch 1017: Training Accuracy = 0.9871, Training Loss = 0.1068, Validation Accuracy = 0.0193, Validation Loss = 6.2226\n",
            "Epoch 1018/3334\n",
            "Epoch 1018: Training Accuracy = 0.9871, Training Loss = 0.1068, Validation Accuracy = 0.0193, Validation Loss = 6.2226\n",
            "Epoch 1019/3334\n",
            "Epoch 1019: Training Accuracy = 0.9871, Training Loss = 0.1068, Validation Accuracy = 0.0193, Validation Loss = 6.2226\n",
            "Epoch 1020/3334\n",
            "Epoch 1020: Training Accuracy = 0.9871, Training Loss = 0.1068, Validation Accuracy = 0.0193, Validation Loss = 6.2226\n",
            "Epoch 1021/3334\n",
            "Epoch 1021: Training Accuracy = 0.9893, Training Loss = 0.0959, Validation Accuracy = 0.0190, Validation Loss = 6.2065\n",
            "Epoch 1022/3334\n",
            "Epoch 1022: Training Accuracy = 0.9893, Training Loss = 0.0959, Validation Accuracy = 0.0190, Validation Loss = 6.2065\n",
            "Epoch 1023/3334\n",
            "Epoch 1023: Training Accuracy = 0.9893, Training Loss = 0.0959, Validation Accuracy = 0.0190, Validation Loss = 6.2065\n",
            "Epoch 1024/3334\n",
            "Epoch 1024: Training Accuracy = 0.9863, Training Loss = 0.1060, Validation Accuracy = 0.0197, Validation Loss = 6.2113\n",
            "Epoch 1025/3334\n",
            "Epoch 1025: Training Accuracy = 0.9863, Training Loss = 0.1060, Validation Accuracy = 0.0197, Validation Loss = 6.2113\n",
            "Epoch 1026/3334\n",
            "Epoch 1026: Training Accuracy = 0.9863, Training Loss = 0.1060, Validation Accuracy = 0.0197, Validation Loss = 6.2113\n",
            "Epoch 1027/3334\n",
            "Epoch 1027: Training Accuracy = 0.5607, Training Loss = 2.1755, Validation Accuracy = 0.0193, Validation Loss = 5.8462\n",
            "Epoch 1028/3334\n",
            "Epoch 1028: Training Accuracy = 0.5607, Training Loss = 2.1755, Validation Accuracy = 0.0193, Validation Loss = 5.8462\n",
            "Epoch 1029/3334\n",
            "Epoch 1029: Training Accuracy = 0.5607, Training Loss = 2.1755, Validation Accuracy = 0.0193, Validation Loss = 5.8462\n",
            "Epoch 1030/3334\n",
            "Epoch 1030: Training Accuracy = 0.5607, Training Loss = 2.1755, Validation Accuracy = 0.0193, Validation Loss = 5.8462\n",
            "Epoch 1031/3334\n",
            "Epoch 1031: Training Accuracy = 0.9395, Training Loss = 0.6089, Validation Accuracy = 0.0188, Validation Loss = 5.7196\n",
            "Epoch 1032/3334\n",
            "Epoch 1032: Training Accuracy = 0.9395, Training Loss = 0.6089, Validation Accuracy = 0.0188, Validation Loss = 5.7196\n",
            "Epoch 1033/3334\n",
            "Epoch 1033: Training Accuracy = 0.9395, Training Loss = 0.6089, Validation Accuracy = 0.0188, Validation Loss = 5.7196\n",
            "Epoch 1034/3334\n",
            "Epoch 1034: Training Accuracy = 0.9863, Training Loss = 0.2884, Validation Accuracy = 0.0185, Validation Loss = 6.0716\n",
            "Epoch 1035/3334\n",
            "Epoch 1035: Training Accuracy = 0.9863, Training Loss = 0.2884, Validation Accuracy = 0.0185, Validation Loss = 6.0716\n",
            "Epoch 1036/3334\n",
            "Epoch 1036: Training Accuracy = 0.9863, Training Loss = 0.2884, Validation Accuracy = 0.0185, Validation Loss = 6.0716\n",
            "Epoch 1037/3334\n",
            "Epoch 1037: Training Accuracy = 0.9832, Training Loss = 0.1979, Validation Accuracy = 0.0182, Validation Loss = 6.1440\n",
            "Epoch 1038/3334\n",
            "Epoch 1038: Training Accuracy = 0.9832, Training Loss = 0.1979, Validation Accuracy = 0.0182, Validation Loss = 6.1440\n",
            "Epoch 1039/3334\n",
            "Epoch 1039: Training Accuracy = 0.9832, Training Loss = 0.1979, Validation Accuracy = 0.0182, Validation Loss = 6.1440\n",
            "Epoch 1040/3334\n",
            "Epoch 1040: Training Accuracy = 0.9832, Training Loss = 0.1979, Validation Accuracy = 0.0182, Validation Loss = 6.1440\n",
            "Epoch 1041/3334\n",
            "Epoch 1041: Training Accuracy = 0.9863, Training Loss = 0.1343, Validation Accuracy = 0.0197, Validation Loss = 6.1534\n",
            "Epoch 1042/3334\n",
            "Epoch 1042: Training Accuracy = 0.9863, Training Loss = 0.1343, Validation Accuracy = 0.0197, Validation Loss = 6.1534\n",
            "Epoch 1043/3334\n",
            "Epoch 1043: Training Accuracy = 0.9863, Training Loss = 0.1343, Validation Accuracy = 0.0197, Validation Loss = 6.1534\n",
            "Epoch 1044/3334\n",
            "Epoch 1044: Training Accuracy = 0.9922, Training Loss = 0.0952, Validation Accuracy = 0.0191, Validation Loss = 6.1902\n",
            "Epoch 1045/3334\n",
            "Epoch 1045: Training Accuracy = 0.9922, Training Loss = 0.0952, Validation Accuracy = 0.0191, Validation Loss = 6.1902\n",
            "Epoch 1046/3334\n",
            "Epoch 1046: Training Accuracy = 0.9922, Training Loss = 0.0952, Validation Accuracy = 0.0191, Validation Loss = 6.1902\n",
            "Epoch 1047/3334\n",
            "Epoch 1047: Training Accuracy = 0.9922, Training Loss = 0.0885, Validation Accuracy = 0.0193, Validation Loss = 6.1915\n",
            "Epoch 1048/3334\n",
            "Epoch 1048: Training Accuracy = 0.9922, Training Loss = 0.0885, Validation Accuracy = 0.0193, Validation Loss = 6.1915\n",
            "Epoch 1049/3334\n",
            "Epoch 1049: Training Accuracy = 0.9922, Training Loss = 0.0885, Validation Accuracy = 0.0193, Validation Loss = 6.1915\n",
            "Epoch 1050/3334\n",
            "Epoch 1050: Training Accuracy = 0.9922, Training Loss = 0.0885, Validation Accuracy = 0.0193, Validation Loss = 6.1915\n",
            "Epoch 1051/3334\n",
            "Epoch 1051: Training Accuracy = 0.9893, Training Loss = 0.0933, Validation Accuracy = 0.0197, Validation Loss = 6.1728\n",
            "Epoch 1052/3334\n",
            "Epoch 1052: Training Accuracy = 0.9893, Training Loss = 0.0933, Validation Accuracy = 0.0197, Validation Loss = 6.1728\n",
            "Epoch 1053/3334\n",
            "Epoch 1053: Training Accuracy = 0.9893, Training Loss = 0.0933, Validation Accuracy = 0.0197, Validation Loss = 6.1728\n",
            "Epoch 1054/3334\n",
            "Epoch 1054: Training Accuracy = 0.9893, Training Loss = 0.0934, Validation Accuracy = 0.0194, Validation Loss = 6.1630\n",
            "Epoch 1055/3334\n",
            "Epoch 1055: Training Accuracy = 0.9893, Training Loss = 0.0934, Validation Accuracy = 0.0194, Validation Loss = 6.1630\n",
            "Epoch 1056/3334\n",
            "Epoch 1056: Training Accuracy = 0.9893, Training Loss = 0.0934, Validation Accuracy = 0.0194, Validation Loss = 6.1630\n",
            "Epoch 1057/3334\n",
            "Epoch 1057: Training Accuracy = 0.9910, Training Loss = 0.0919, Validation Accuracy = 0.0193, Validation Loss = 6.1510\n",
            "Epoch 1058/3334\n",
            "Epoch 1058: Training Accuracy = 0.9910, Training Loss = 0.0919, Validation Accuracy = 0.0193, Validation Loss = 6.1510\n",
            "Epoch 1059/3334\n",
            "Epoch 1059: Training Accuracy = 0.9910, Training Loss = 0.0919, Validation Accuracy = 0.0193, Validation Loss = 6.1510\n",
            "Epoch 1060/3334\n",
            "Epoch 1060: Training Accuracy = 0.9910, Training Loss = 0.0919, Validation Accuracy = 0.0193, Validation Loss = 6.1510\n",
            "Epoch 1061/3334\n",
            "Epoch 1061: Training Accuracy = 0.9912, Training Loss = 0.0862, Validation Accuracy = 0.0190, Validation Loss = 6.1369\n",
            "Epoch 1062/3334\n",
            "Epoch 1062: Training Accuracy = 0.9912, Training Loss = 0.0862, Validation Accuracy = 0.0190, Validation Loss = 6.1369\n",
            "Epoch 1063/3334\n",
            "Epoch 1063: Training Accuracy = 0.9912, Training Loss = 0.0862, Validation Accuracy = 0.0190, Validation Loss = 6.1369\n",
            "Epoch 1064/3334\n",
            "Epoch 1064: Training Accuracy = 0.9883, Training Loss = 0.1030, Validation Accuracy = 0.0196, Validation Loss = 6.1636\n",
            "Epoch 1065/3334\n",
            "Epoch 1065: Training Accuracy = 0.9883, Training Loss = 0.1030, Validation Accuracy = 0.0196, Validation Loss = 6.1636\n",
            "Epoch 1066/3334\n",
            "Epoch 1066: Training Accuracy = 0.9883, Training Loss = 0.1030, Validation Accuracy = 0.0196, Validation Loss = 6.1636\n",
            "Epoch 1067/3334\n",
            "Epoch 1067: Training Accuracy = 0.2274, Training Loss = 3.1544, Validation Accuracy = 0.0179, Validation Loss = 5.2031\n",
            "Epoch 1068/3334\n",
            "Epoch 1068: Training Accuracy = 0.2274, Training Loss = 3.1544, Validation Accuracy = 0.0179, Validation Loss = 5.2031\n",
            "Epoch 1069/3334\n",
            "Epoch 1069: Training Accuracy = 0.2274, Training Loss = 3.1544, Validation Accuracy = 0.0179, Validation Loss = 5.2031\n",
            "Epoch 1070/3334\n",
            "Epoch 1070: Training Accuracy = 0.2274, Training Loss = 3.1544, Validation Accuracy = 0.0179, Validation Loss = 5.2031\n",
            "Epoch 1071/3334\n",
            "Epoch 1071: Training Accuracy = 0.9375, Training Loss = 0.6703, Validation Accuracy = 0.0205, Validation Loss = 5.5452\n",
            "Epoch 1072/3334\n",
            "Epoch 1072: Training Accuracy = 0.9375, Training Loss = 0.6703, Validation Accuracy = 0.0205, Validation Loss = 5.5452\n",
            "Epoch 1073/3334\n",
            "Epoch 1073: Training Accuracy = 0.9375, Training Loss = 0.6703, Validation Accuracy = 0.0205, Validation Loss = 5.5452\n",
            "Epoch 1074/3334\n",
            "Epoch 1074: Training Accuracy = 0.9912, Training Loss = 0.2773, Validation Accuracy = 0.0190, Validation Loss = 5.9879\n",
            "Epoch 1075/3334\n",
            "Epoch 1075: Training Accuracy = 0.9912, Training Loss = 0.2773, Validation Accuracy = 0.0190, Validation Loss = 5.9879\n",
            "Epoch 1076/3334\n",
            "Epoch 1076: Training Accuracy = 0.9912, Training Loss = 0.2773, Validation Accuracy = 0.0190, Validation Loss = 5.9879\n",
            "Epoch 1077/3334\n",
            "Epoch 1077: Training Accuracy = 0.9845, Training Loss = 0.2023, Validation Accuracy = 0.0188, Validation Loss = 6.0802\n",
            "Epoch 1078/3334\n",
            "Epoch 1078: Training Accuracy = 0.9845, Training Loss = 0.2023, Validation Accuracy = 0.0188, Validation Loss = 6.0802\n",
            "Epoch 1079/3334\n",
            "Epoch 1079: Training Accuracy = 0.9845, Training Loss = 0.2023, Validation Accuracy = 0.0188, Validation Loss = 6.0802\n",
            "Epoch 1080/3334\n",
            "Epoch 1080: Training Accuracy = 0.9845, Training Loss = 0.2023, Validation Accuracy = 0.0188, Validation Loss = 6.0802\n",
            "Epoch 1081/3334\n",
            "Epoch 1081: Training Accuracy = 0.9932, Training Loss = 0.1124, Validation Accuracy = 0.0196, Validation Loss = 6.0807\n",
            "Epoch 1082/3334\n",
            "Epoch 1082: Training Accuracy = 0.9932, Training Loss = 0.1124, Validation Accuracy = 0.0196, Validation Loss = 6.0807\n",
            "Epoch 1083/3334\n",
            "Epoch 1083: Training Accuracy = 0.9932, Training Loss = 0.1124, Validation Accuracy = 0.0196, Validation Loss = 6.0807\n",
            "Epoch 1084/3334\n",
            "Epoch 1084: Training Accuracy = 0.9873, Training Loss = 0.1149, Validation Accuracy = 0.0200, Validation Loss = 6.0992\n",
            "Epoch 1085/3334\n",
            "Epoch 1085: Training Accuracy = 0.9873, Training Loss = 0.1149, Validation Accuracy = 0.0200, Validation Loss = 6.0992\n",
            "Epoch 1086/3334\n",
            "Epoch 1086: Training Accuracy = 0.9873, Training Loss = 0.1149, Validation Accuracy = 0.0200, Validation Loss = 6.0992\n",
            "Epoch 1087/3334\n",
            "Epoch 1087: Training Accuracy = 0.9871, Training Loss = 0.1075, Validation Accuracy = 0.0194, Validation Loss = 6.1273\n",
            "Epoch 1088/3334\n",
            "Epoch 1088: Training Accuracy = 0.9871, Training Loss = 0.1075, Validation Accuracy = 0.0194, Validation Loss = 6.1273\n",
            "Epoch 1089/3334\n",
            "Epoch 1089: Training Accuracy = 0.9871, Training Loss = 0.1075, Validation Accuracy = 0.0194, Validation Loss = 6.1273\n",
            "Epoch 1090/3334\n",
            "Epoch 1090: Training Accuracy = 0.9871, Training Loss = 0.1075, Validation Accuracy = 0.0194, Validation Loss = 6.1273\n",
            "Epoch 1091/3334\n",
            "Epoch 1091: Training Accuracy = 0.9854, Training Loss = 0.1076, Validation Accuracy = 0.0193, Validation Loss = 6.1116\n",
            "Epoch 1092/3334\n",
            "Epoch 1092: Training Accuracy = 0.9854, Training Loss = 0.1076, Validation Accuracy = 0.0193, Validation Loss = 6.1116\n",
            "Epoch 1093/3334\n",
            "Epoch 1093: Training Accuracy = 0.9854, Training Loss = 0.1076, Validation Accuracy = 0.0193, Validation Loss = 6.1116\n",
            "Epoch 1094/3334\n",
            "Epoch 1094: Training Accuracy = 0.9951, Training Loss = 0.0752, Validation Accuracy = 0.0185, Validation Loss = 6.1061\n",
            "Epoch 1095/3334\n",
            "Epoch 1095: Training Accuracy = 0.9951, Training Loss = 0.0752, Validation Accuracy = 0.0185, Validation Loss = 6.1061\n",
            "Epoch 1096/3334\n",
            "Epoch 1096: Training Accuracy = 0.9951, Training Loss = 0.0752, Validation Accuracy = 0.0185, Validation Loss = 6.1061\n",
            "Epoch 1097/3334\n",
            "Epoch 1097: Training Accuracy = 0.9935, Training Loss = 0.0843, Validation Accuracy = 0.0194, Validation Loss = 6.0915\n",
            "Epoch 1098/3334\n",
            "Epoch 1098: Training Accuracy = 0.9935, Training Loss = 0.0843, Validation Accuracy = 0.0194, Validation Loss = 6.0915\n",
            "Epoch 1099/3334\n",
            "Epoch 1099: Training Accuracy = 0.9935, Training Loss = 0.0843, Validation Accuracy = 0.0194, Validation Loss = 6.0915\n",
            "Epoch 1100/3334\n",
            "Epoch 1100: Training Accuracy = 0.9935, Training Loss = 0.0843, Validation Accuracy = 0.0194, Validation Loss = 6.0915\n",
            "Epoch 1101/3334\n",
            "Epoch 1101: Training Accuracy = 0.9863, Training Loss = 0.1085, Validation Accuracy = 0.0199, Validation Loss = 6.0869\n",
            "Epoch 1102/3334\n",
            "Epoch 1102: Training Accuracy = 0.9863, Training Loss = 0.1085, Validation Accuracy = 0.0199, Validation Loss = 6.0869\n",
            "Epoch 1103/3334\n",
            "Epoch 1103: Training Accuracy = 0.9863, Training Loss = 0.1085, Validation Accuracy = 0.0199, Validation Loss = 6.0869\n",
            "Epoch 1104/3334\n",
            "Epoch 1104: Training Accuracy = 0.9883, Training Loss = 0.0982, Validation Accuracy = 0.0196, Validation Loss = 6.0735\n",
            "Epoch 1105/3334\n",
            "Epoch 1105: Training Accuracy = 0.9883, Training Loss = 0.0982, Validation Accuracy = 0.0196, Validation Loss = 6.0735\n",
            "Epoch 1106/3334\n",
            "Epoch 1106: Training Accuracy = 0.9883, Training Loss = 0.0982, Validation Accuracy = 0.0196, Validation Loss = 6.0735\n",
            "Epoch 1107/3334\n",
            "Epoch 1107: Training Accuracy = 0.5917, Training Loss = 1.7707, Validation Accuracy = 0.0199, Validation Loss = 5.7538\n",
            "Epoch 1108/3334\n",
            "Epoch 1108: Training Accuracy = 0.5917, Training Loss = 1.7707, Validation Accuracy = 0.0199, Validation Loss = 5.7538\n",
            "Epoch 1109/3334\n",
            "Epoch 1109: Training Accuracy = 0.5917, Training Loss = 1.7707, Validation Accuracy = 0.0199, Validation Loss = 5.7538\n",
            "Epoch 1110/3334\n",
            "Epoch 1110: Training Accuracy = 0.5917, Training Loss = 1.7707, Validation Accuracy = 0.0199, Validation Loss = 5.7538\n",
            "Epoch 1111/3334\n",
            "Epoch 1111: Training Accuracy = 0.9473, Training Loss = 0.5748, Validation Accuracy = 0.0225, Validation Loss = 5.5544\n",
            "Epoch 1112/3334\n",
            "Epoch 1112: Training Accuracy = 0.9473, Training Loss = 0.5748, Validation Accuracy = 0.0225, Validation Loss = 5.5544\n",
            "Epoch 1113/3334\n",
            "Epoch 1113: Training Accuracy = 0.9473, Training Loss = 0.5748, Validation Accuracy = 0.0225, Validation Loss = 5.5544\n",
            "Epoch 1114/3334\n",
            "Epoch 1114: Training Accuracy = 0.9912, Training Loss = 0.2647, Validation Accuracy = 0.0185, Validation Loss = 5.9572\n",
            "Epoch 1115/3334\n",
            "Epoch 1115: Training Accuracy = 0.9912, Training Loss = 0.2647, Validation Accuracy = 0.0185, Validation Loss = 5.9572\n",
            "Epoch 1116/3334\n",
            "Epoch 1116: Training Accuracy = 0.9912, Training Loss = 0.2647, Validation Accuracy = 0.0185, Validation Loss = 5.9572\n",
            "Epoch 1117/3334\n",
            "Epoch 1117: Training Accuracy = 0.9845, Training Loss = 0.1925, Validation Accuracy = 0.0205, Validation Loss = 5.9699\n",
            "Epoch 1118/3334\n",
            "Epoch 1118: Training Accuracy = 0.9845, Training Loss = 0.1925, Validation Accuracy = 0.0205, Validation Loss = 5.9699\n",
            "Epoch 1119/3334\n",
            "Epoch 1119: Training Accuracy = 0.9845, Training Loss = 0.1925, Validation Accuracy = 0.0205, Validation Loss = 5.9699\n",
            "Epoch 1120/3334\n",
            "Epoch 1120: Training Accuracy = 0.9845, Training Loss = 0.1925, Validation Accuracy = 0.0205, Validation Loss = 5.9699\n",
            "Epoch 1121/3334\n",
            "Epoch 1121: Training Accuracy = 0.9902, Training Loss = 0.1230, Validation Accuracy = 0.0199, Validation Loss = 5.9628\n",
            "Epoch 1122/3334\n",
            "Epoch 1122: Training Accuracy = 0.9902, Training Loss = 0.1230, Validation Accuracy = 0.0199, Validation Loss = 5.9628\n",
            "Epoch 1123/3334\n",
            "Epoch 1123: Training Accuracy = 0.9902, Training Loss = 0.1230, Validation Accuracy = 0.0199, Validation Loss = 5.9628\n",
            "Epoch 1124/3334\n",
            "Epoch 1124: Training Accuracy = 0.9902, Training Loss = 0.1070, Validation Accuracy = 0.0199, Validation Loss = 5.9952\n",
            "Epoch 1125/3334\n",
            "Epoch 1125: Training Accuracy = 0.9902, Training Loss = 0.1070, Validation Accuracy = 0.0199, Validation Loss = 5.9952\n",
            "Epoch 1126/3334\n",
            "Epoch 1126: Training Accuracy = 0.9902, Training Loss = 0.1070, Validation Accuracy = 0.0199, Validation Loss = 5.9952\n",
            "Epoch 1127/3334\n",
            "Epoch 1127: Training Accuracy = 0.9897, Training Loss = 0.1052, Validation Accuracy = 0.0184, Validation Loss = 6.0061\n",
            "Epoch 1128/3334\n",
            "Epoch 1128: Training Accuracy = 0.9897, Training Loss = 0.1052, Validation Accuracy = 0.0184, Validation Loss = 6.0061\n",
            "Epoch 1129/3334\n",
            "Epoch 1129: Training Accuracy = 0.9897, Training Loss = 0.1052, Validation Accuracy = 0.0184, Validation Loss = 6.0061\n",
            "Epoch 1130/3334\n",
            "Epoch 1130: Training Accuracy = 0.9897, Training Loss = 0.1052, Validation Accuracy = 0.0184, Validation Loss = 6.0061\n",
            "Epoch 1131/3334\n",
            "Epoch 1131: Training Accuracy = 0.9932, Training Loss = 0.0893, Validation Accuracy = 0.0194, Validation Loss = 5.9920\n",
            "Epoch 1132/3334\n",
            "Epoch 1132: Training Accuracy = 0.9932, Training Loss = 0.0893, Validation Accuracy = 0.0194, Validation Loss = 5.9920\n",
            "Epoch 1133/3334\n",
            "Epoch 1133: Training Accuracy = 0.9932, Training Loss = 0.0893, Validation Accuracy = 0.0194, Validation Loss = 5.9920\n",
            "Epoch 1134/3334\n",
            "Epoch 1134: Training Accuracy = 0.9893, Training Loss = 0.1003, Validation Accuracy = 0.0199, Validation Loss = 5.9910\n",
            "Epoch 1135/3334\n",
            "Epoch 1135: Training Accuracy = 0.9893, Training Loss = 0.1003, Validation Accuracy = 0.0199, Validation Loss = 5.9910\n",
            "Epoch 1136/3334\n",
            "Epoch 1136: Training Accuracy = 0.9893, Training Loss = 0.1003, Validation Accuracy = 0.0199, Validation Loss = 5.9910\n",
            "Epoch 1137/3334\n",
            "Epoch 1137: Training Accuracy = 0.9897, Training Loss = 0.0986, Validation Accuracy = 0.0205, Validation Loss = 5.9680\n",
            "Epoch 1138/3334\n",
            "Epoch 1138: Training Accuracy = 0.9897, Training Loss = 0.0986, Validation Accuracy = 0.0205, Validation Loss = 5.9680\n",
            "Epoch 1139/3334\n",
            "Epoch 1139: Training Accuracy = 0.9897, Training Loss = 0.0986, Validation Accuracy = 0.0205, Validation Loss = 5.9680\n",
            "Epoch 1140/3334\n",
            "Epoch 1140: Training Accuracy = 0.9897, Training Loss = 0.0986, Validation Accuracy = 0.0205, Validation Loss = 5.9680\n",
            "Epoch 1141/3334\n",
            "Epoch 1141: Training Accuracy = 0.9873, Training Loss = 0.1061, Validation Accuracy = 0.0193, Validation Loss = 5.9839\n",
            "Epoch 1142/3334\n",
            "Epoch 1142: Training Accuracy = 0.9873, Training Loss = 0.1061, Validation Accuracy = 0.0193, Validation Loss = 5.9839\n",
            "Epoch 1143/3334\n",
            "Epoch 1143: Training Accuracy = 0.9873, Training Loss = 0.1061, Validation Accuracy = 0.0193, Validation Loss = 5.9839\n",
            "Epoch 1144/3334\n",
            "Epoch 1144: Training Accuracy = 0.6406, Training Loss = 1.7422, Validation Accuracy = 0.0210, Validation Loss = 5.7619\n",
            "Epoch 1145/3334\n",
            "Epoch 1145: Training Accuracy = 0.6406, Training Loss = 1.7422, Validation Accuracy = 0.0210, Validation Loss = 5.7619\n",
            "Epoch 1146/3334\n",
            "Epoch 1146: Training Accuracy = 0.6406, Training Loss = 1.7422, Validation Accuracy = 0.0210, Validation Loss = 5.7619\n",
            "Epoch 1147/3334\n",
            "Epoch 1147: Training Accuracy = 0.9432, Training Loss = 0.5677, Validation Accuracy = 0.0200, Validation Loss = 5.4498\n",
            "Epoch 1148/3334\n",
            "Epoch 1148: Training Accuracy = 0.9432, Training Loss = 0.5677, Validation Accuracy = 0.0200, Validation Loss = 5.4498\n",
            "Epoch 1149/3334\n",
            "Epoch 1149: Training Accuracy = 0.9432, Training Loss = 0.5677, Validation Accuracy = 0.0200, Validation Loss = 5.4498\n",
            "Epoch 1150/3334\n",
            "Epoch 1150: Training Accuracy = 0.9432, Training Loss = 0.5677, Validation Accuracy = 0.0200, Validation Loss = 5.4498\n",
            "Epoch 1151/3334\n",
            "Epoch 1151: Training Accuracy = 0.9873, Training Loss = 0.2356, Validation Accuracy = 0.0200, Validation Loss = 5.8241\n",
            "Epoch 1152/3334\n",
            "Epoch 1152: Training Accuracy = 0.9873, Training Loss = 0.2356, Validation Accuracy = 0.0200, Validation Loss = 5.8241\n",
            "Epoch 1153/3334\n",
            "Epoch 1153: Training Accuracy = 0.9873, Training Loss = 0.2356, Validation Accuracy = 0.0200, Validation Loss = 5.8241\n",
            "Epoch 1154/3334\n",
            "Epoch 1154: Training Accuracy = 0.9893, Training Loss = 0.1627, Validation Accuracy = 0.0223, Validation Loss = 5.9107\n",
            "Epoch 1155/3334\n",
            "Epoch 1155: Training Accuracy = 0.9893, Training Loss = 0.1627, Validation Accuracy = 0.0223, Validation Loss = 5.9107\n",
            "Epoch 1156/3334\n",
            "Epoch 1156: Training Accuracy = 0.9893, Training Loss = 0.1627, Validation Accuracy = 0.0223, Validation Loss = 5.9107\n",
            "Epoch 1157/3334\n",
            "Epoch 1157: Training Accuracy = 0.9897, Training Loss = 0.1258, Validation Accuracy = 0.0214, Validation Loss = 5.8842\n",
            "Epoch 1158/3334\n",
            "Epoch 1158: Training Accuracy = 0.9897, Training Loss = 0.1258, Validation Accuracy = 0.0214, Validation Loss = 5.8842\n",
            "Epoch 1159/3334\n",
            "Epoch 1159: Training Accuracy = 0.9897, Training Loss = 0.1258, Validation Accuracy = 0.0214, Validation Loss = 5.8842\n",
            "Epoch 1160/3334\n",
            "Epoch 1160: Training Accuracy = 0.9897, Training Loss = 0.1258, Validation Accuracy = 0.0214, Validation Loss = 5.8842\n",
            "Epoch 1161/3334\n",
            "Epoch 1161: Training Accuracy = 0.9902, Training Loss = 0.1055, Validation Accuracy = 0.0194, Validation Loss = 5.9026\n",
            "Epoch 1162/3334\n",
            "Epoch 1162: Training Accuracy = 0.9902, Training Loss = 0.1055, Validation Accuracy = 0.0194, Validation Loss = 5.9026\n",
            "Epoch 1163/3334\n",
            "Epoch 1163: Training Accuracy = 0.9902, Training Loss = 0.1055, Validation Accuracy = 0.0194, Validation Loss = 5.9026\n",
            "Epoch 1164/3334\n",
            "Epoch 1164: Training Accuracy = 0.9902, Training Loss = 0.0981, Validation Accuracy = 0.0194, Validation Loss = 5.9182\n",
            "Epoch 1165/3334\n",
            "Epoch 1165: Training Accuracy = 0.9902, Training Loss = 0.0981, Validation Accuracy = 0.0194, Validation Loss = 5.9182\n",
            "Epoch 1166/3334\n",
            "Epoch 1166: Training Accuracy = 0.9902, Training Loss = 0.0981, Validation Accuracy = 0.0194, Validation Loss = 5.9182\n",
            "Epoch 1167/3334\n",
            "Epoch 1167: Training Accuracy = 0.9858, Training Loss = 0.1158, Validation Accuracy = 0.0206, Validation Loss = 5.9106\n",
            "Epoch 1168/3334\n",
            "Epoch 1168: Training Accuracy = 0.9858, Training Loss = 0.1158, Validation Accuracy = 0.0206, Validation Loss = 5.9106\n",
            "Epoch 1169/3334\n",
            "Epoch 1169: Training Accuracy = 0.9858, Training Loss = 0.1158, Validation Accuracy = 0.0206, Validation Loss = 5.9106\n",
            "Epoch 1170/3334\n",
            "Epoch 1170: Training Accuracy = 0.9858, Training Loss = 0.1158, Validation Accuracy = 0.0206, Validation Loss = 5.9106\n",
            "Epoch 1171/3334\n",
            "Epoch 1171: Training Accuracy = 0.9893, Training Loss = 0.0986, Validation Accuracy = 0.0206, Validation Loss = 5.9010\n",
            "Epoch 1172/3334\n",
            "Epoch 1172: Training Accuracy = 0.9893, Training Loss = 0.0986, Validation Accuracy = 0.0206, Validation Loss = 5.9010\n",
            "Epoch 1173/3334\n",
            "Epoch 1173: Training Accuracy = 0.9893, Training Loss = 0.0986, Validation Accuracy = 0.0206, Validation Loss = 5.9010\n",
            "Epoch 1174/3334\n",
            "Epoch 1174: Training Accuracy = 0.9902, Training Loss = 0.0980, Validation Accuracy = 0.0200, Validation Loss = 5.8985\n",
            "Epoch 1175/3334\n",
            "Epoch 1175: Training Accuracy = 0.9902, Training Loss = 0.0980, Validation Accuracy = 0.0200, Validation Loss = 5.8985\n",
            "Epoch 1176/3334\n",
            "Epoch 1176: Training Accuracy = 0.9902, Training Loss = 0.0980, Validation Accuracy = 0.0200, Validation Loss = 5.8985\n",
            "Epoch 1177/3334\n",
            "Epoch 1177: Training Accuracy = 0.9884, Training Loss = 0.1098, Validation Accuracy = 0.0208, Validation Loss = 5.8906\n",
            "Epoch 1178/3334\n",
            "Epoch 1178: Training Accuracy = 0.9884, Training Loss = 0.1098, Validation Accuracy = 0.0208, Validation Loss = 5.8906\n",
            "Epoch 1179/3334\n",
            "Epoch 1179: Training Accuracy = 0.9884, Training Loss = 0.1098, Validation Accuracy = 0.0208, Validation Loss = 5.8906\n",
            "Epoch 1180/3334\n",
            "Epoch 1180: Training Accuracy = 0.9884, Training Loss = 0.1098, Validation Accuracy = 0.0208, Validation Loss = 5.8906\n",
            "Epoch 1181/3334\n",
            "Epoch 1181: Training Accuracy = 0.9932, Training Loss = 0.1088, Validation Accuracy = 0.0220, Validation Loss = 5.8834\n",
            "Epoch 1182/3334\n",
            "Epoch 1182: Training Accuracy = 0.9932, Training Loss = 0.1088, Validation Accuracy = 0.0220, Validation Loss = 5.8834\n",
            "Epoch 1183/3334\n",
            "Epoch 1183: Training Accuracy = 0.9932, Training Loss = 0.1088, Validation Accuracy = 0.0220, Validation Loss = 5.8834\n",
            "Epoch 1184/3334\n",
            "Epoch 1184: Training Accuracy = 0.9287, Training Loss = 0.6282, Validation Accuracy = 0.0208, Validation Loss = 5.4785\n",
            "Epoch 1185/3334\n",
            "Epoch 1185: Training Accuracy = 0.9287, Training Loss = 0.6282, Validation Accuracy = 0.0208, Validation Loss = 5.4785\n",
            "Epoch 1186/3334\n",
            "Epoch 1186: Training Accuracy = 0.9287, Training Loss = 0.6282, Validation Accuracy = 0.0208, Validation Loss = 5.4785\n",
            "Epoch 1187/3334\n",
            "Epoch 1187: Training Accuracy = 0.9897, Training Loss = 0.2770, Validation Accuracy = 0.0237, Validation Loss = 5.7253\n",
            "Epoch 1188/3334\n",
            "Epoch 1188: Training Accuracy = 0.9897, Training Loss = 0.2770, Validation Accuracy = 0.0237, Validation Loss = 5.7253\n",
            "Epoch 1189/3334\n",
            "Epoch 1189: Training Accuracy = 0.9897, Training Loss = 0.2770, Validation Accuracy = 0.0237, Validation Loss = 5.7253\n",
            "Epoch 1190/3334\n",
            "Epoch 1190: Training Accuracy = 0.9897, Training Loss = 0.2770, Validation Accuracy = 0.0237, Validation Loss = 5.7253\n",
            "Epoch 1191/3334\n",
            "Epoch 1191: Training Accuracy = 0.9932, Training Loss = 0.1522, Validation Accuracy = 0.0216, Validation Loss = 5.8743\n",
            "Epoch 1192/3334\n",
            "Epoch 1192: Training Accuracy = 0.9932, Training Loss = 0.1522, Validation Accuracy = 0.0216, Validation Loss = 5.8743\n",
            "Epoch 1193/3334\n",
            "Epoch 1193: Training Accuracy = 0.9932, Training Loss = 0.1522, Validation Accuracy = 0.0216, Validation Loss = 5.8743\n",
            "Epoch 1194/3334\n",
            "Epoch 1194: Training Accuracy = 0.9902, Training Loss = 0.1252, Validation Accuracy = 0.0222, Validation Loss = 5.8804\n",
            "Epoch 1195/3334\n",
            "Epoch 1195: Training Accuracy = 0.9902, Training Loss = 0.1252, Validation Accuracy = 0.0222, Validation Loss = 5.8804\n",
            "Epoch 1196/3334\n",
            "Epoch 1196: Training Accuracy = 0.9902, Training Loss = 0.1252, Validation Accuracy = 0.0222, Validation Loss = 5.8804\n",
            "Epoch 1197/3334\n",
            "Epoch 1197: Training Accuracy = 0.9884, Training Loss = 0.1097, Validation Accuracy = 0.0225, Validation Loss = 5.8914\n",
            "Epoch 1198/3334\n",
            "Epoch 1198: Training Accuracy = 0.9884, Training Loss = 0.1097, Validation Accuracy = 0.0225, Validation Loss = 5.8914\n",
            "Epoch 1199/3334\n",
            "Epoch 1199: Training Accuracy = 0.9884, Training Loss = 0.1097, Validation Accuracy = 0.0225, Validation Loss = 5.8914\n",
            "Epoch 1200/3334\n",
            "Epoch 1200: Training Accuracy = 0.9884, Training Loss = 0.1097, Validation Accuracy = 0.0225, Validation Loss = 5.8914\n",
            "Epoch 1201/3334\n",
            "Epoch 1201: Training Accuracy = 0.9912, Training Loss = 0.0868, Validation Accuracy = 0.0231, Validation Loss = 5.8854\n",
            "Epoch 1202/3334\n",
            "Epoch 1202: Training Accuracy = 0.9912, Training Loss = 0.0868, Validation Accuracy = 0.0231, Validation Loss = 5.8854\n",
            "Epoch 1203/3334\n",
            "Epoch 1203: Training Accuracy = 0.9912, Training Loss = 0.0868, Validation Accuracy = 0.0231, Validation Loss = 5.8854\n",
            "Epoch 1204/3334\n",
            "Epoch 1204: Training Accuracy = 0.9883, Training Loss = 0.1013, Validation Accuracy = 0.0220, Validation Loss = 5.8918\n",
            "Epoch 1205/3334\n",
            "Epoch 1205: Training Accuracy = 0.9883, Training Loss = 0.1013, Validation Accuracy = 0.0220, Validation Loss = 5.8918\n",
            "Epoch 1206/3334\n",
            "Epoch 1206: Training Accuracy = 0.9883, Training Loss = 0.1013, Validation Accuracy = 0.0220, Validation Loss = 5.8918\n",
            "Epoch 1207/3334\n",
            "Epoch 1207: Training Accuracy = 0.9922, Training Loss = 0.0826, Validation Accuracy = 0.0210, Validation Loss = 5.8899\n",
            "Epoch 1208/3334\n",
            "Epoch 1208: Training Accuracy = 0.9922, Training Loss = 0.0826, Validation Accuracy = 0.0210, Validation Loss = 5.8899\n",
            "Epoch 1209/3334\n",
            "Epoch 1209: Training Accuracy = 0.9922, Training Loss = 0.0826, Validation Accuracy = 0.0210, Validation Loss = 5.8899\n",
            "Epoch 1210/3334\n",
            "Epoch 1210: Training Accuracy = 0.9922, Training Loss = 0.0826, Validation Accuracy = 0.0210, Validation Loss = 5.8899\n",
            "Epoch 1211/3334\n",
            "Epoch 1211: Training Accuracy = 0.9883, Training Loss = 0.0965, Validation Accuracy = 0.0208, Validation Loss = 5.8862\n",
            "Epoch 1212/3334\n",
            "Epoch 1212: Training Accuracy = 0.9883, Training Loss = 0.0965, Validation Accuracy = 0.0208, Validation Loss = 5.8862\n",
            "Epoch 1213/3334\n",
            "Epoch 1213: Training Accuracy = 0.9883, Training Loss = 0.0965, Validation Accuracy = 0.0208, Validation Loss = 5.8862\n",
            "Epoch 1214/3334\n",
            "Epoch 1214: Training Accuracy = 0.9854, Training Loss = 0.1084, Validation Accuracy = 0.0232, Validation Loss = 5.8711\n",
            "Epoch 1215/3334\n",
            "Epoch 1215: Training Accuracy = 0.9854, Training Loss = 0.1084, Validation Accuracy = 0.0232, Validation Loss = 5.8711\n",
            "Epoch 1216/3334\n",
            "Epoch 1216: Training Accuracy = 0.9854, Training Loss = 0.1084, Validation Accuracy = 0.0232, Validation Loss = 5.8711\n",
            "Epoch 1217/3334\n",
            "Epoch 1217: Training Accuracy = 0.9910, Training Loss = 0.0912, Validation Accuracy = 0.0211, Validation Loss = 5.8615\n",
            "Epoch 1218/3334\n",
            "Epoch 1218: Training Accuracy = 0.9910, Training Loss = 0.0912, Validation Accuracy = 0.0211, Validation Loss = 5.8615\n",
            "Epoch 1219/3334\n",
            "Epoch 1219: Training Accuracy = 0.9910, Training Loss = 0.0912, Validation Accuracy = 0.0211, Validation Loss = 5.8615\n",
            "Epoch 1220/3334\n",
            "Epoch 1220: Training Accuracy = 0.9910, Training Loss = 0.0912, Validation Accuracy = 0.0211, Validation Loss = 5.8615\n",
            "Epoch 1221/3334\n",
            "Epoch 1221: Training Accuracy = 0.9883, Training Loss = 0.1230, Validation Accuracy = 0.0229, Validation Loss = 5.9546\n",
            "Epoch 1222/3334\n",
            "Epoch 1222: Training Accuracy = 0.9883, Training Loss = 0.1230, Validation Accuracy = 0.0229, Validation Loss = 5.9546\n",
            "Epoch 1223/3334\n",
            "Epoch 1223: Training Accuracy = 0.9883, Training Loss = 0.1230, Validation Accuracy = 0.0229, Validation Loss = 5.9546\n",
            "Epoch 1224/3334\n",
            "Epoch 1224: Training Accuracy = 0.7920, Training Loss = 0.9584, Validation Accuracy = 0.0237, Validation Loss = 5.3359\n",
            "Epoch 1225/3334\n",
            "Epoch 1225: Training Accuracy = 0.7920, Training Loss = 0.9584, Validation Accuracy = 0.0237, Validation Loss = 5.3359\n",
            "Epoch 1226/3334\n",
            "Epoch 1226: Training Accuracy = 0.7920, Training Loss = 0.9584, Validation Accuracy = 0.0237, Validation Loss = 5.3359\n",
            "Epoch 1227/3334\n",
            "Epoch 1227: Training Accuracy = 0.9716, Training Loss = 0.3918, Validation Accuracy = 0.0226, Validation Loss = 5.5976\n",
            "Epoch 1228/3334\n",
            "Epoch 1228: Training Accuracy = 0.9716, Training Loss = 0.3918, Validation Accuracy = 0.0226, Validation Loss = 5.5976\n",
            "Epoch 1229/3334\n",
            "Epoch 1229: Training Accuracy = 0.9716, Training Loss = 0.3918, Validation Accuracy = 0.0226, Validation Loss = 5.5976\n",
            "Epoch 1230/3334\n",
            "Epoch 1230: Training Accuracy = 0.9716, Training Loss = 0.3918, Validation Accuracy = 0.0226, Validation Loss = 5.5976\n",
            "Epoch 1231/3334\n",
            "Epoch 1231: Training Accuracy = 0.9902, Training Loss = 0.1886, Validation Accuracy = 0.0232, Validation Loss = 5.7440\n",
            "Epoch 1232/3334\n",
            "Epoch 1232: Training Accuracy = 0.9902, Training Loss = 0.1886, Validation Accuracy = 0.0232, Validation Loss = 5.7440\n",
            "Epoch 1233/3334\n",
            "Epoch 1233: Training Accuracy = 0.9902, Training Loss = 0.1886, Validation Accuracy = 0.0232, Validation Loss = 5.7440\n",
            "Epoch 1234/3334\n",
            "Epoch 1234: Training Accuracy = 0.9873, Training Loss = 0.1544, Validation Accuracy = 0.0220, Validation Loss = 5.7631\n",
            "Epoch 1235/3334\n",
            "Epoch 1235: Training Accuracy = 0.9873, Training Loss = 0.1544, Validation Accuracy = 0.0220, Validation Loss = 5.7631\n",
            "Epoch 1236/3334\n",
            "Epoch 1236: Training Accuracy = 0.9873, Training Loss = 0.1544, Validation Accuracy = 0.0220, Validation Loss = 5.7631\n",
            "Epoch 1237/3334\n",
            "Epoch 1237: Training Accuracy = 0.9858, Training Loss = 0.1281, Validation Accuracy = 0.0241, Validation Loss = 5.7816\n",
            "Epoch 1238/3334\n",
            "Epoch 1238: Training Accuracy = 0.9858, Training Loss = 0.1281, Validation Accuracy = 0.0241, Validation Loss = 5.7816\n",
            "Epoch 1239/3334\n",
            "Epoch 1239: Training Accuracy = 0.9858, Training Loss = 0.1281, Validation Accuracy = 0.0241, Validation Loss = 5.7816\n",
            "Epoch 1240/3334\n",
            "Epoch 1240: Training Accuracy = 0.9858, Training Loss = 0.1281, Validation Accuracy = 0.0241, Validation Loss = 5.7816\n",
            "Epoch 1241/3334\n",
            "Epoch 1241: Training Accuracy = 0.9863, Training Loss = 0.1110, Validation Accuracy = 0.0237, Validation Loss = 5.7880\n",
            "Epoch 1242/3334\n",
            "Epoch 1242: Training Accuracy = 0.9863, Training Loss = 0.1110, Validation Accuracy = 0.0237, Validation Loss = 5.7880\n",
            "Epoch 1243/3334\n",
            "Epoch 1243: Training Accuracy = 0.9863, Training Loss = 0.1110, Validation Accuracy = 0.0237, Validation Loss = 5.7880\n",
            "Epoch 1244/3334\n",
            "Epoch 1244: Training Accuracy = 0.9883, Training Loss = 0.1005, Validation Accuracy = 0.0237, Validation Loss = 5.7932\n",
            "Epoch 1245/3334\n",
            "Epoch 1245: Training Accuracy = 0.9883, Training Loss = 0.1005, Validation Accuracy = 0.0237, Validation Loss = 5.7932\n",
            "Epoch 1246/3334\n",
            "Epoch 1246: Training Accuracy = 0.9883, Training Loss = 0.1005, Validation Accuracy = 0.0237, Validation Loss = 5.7932\n",
            "Epoch 1247/3334\n",
            "Epoch 1247: Training Accuracy = 0.9871, Training Loss = 0.1053, Validation Accuracy = 0.0240, Validation Loss = 5.7881\n",
            "Epoch 1248/3334\n",
            "Epoch 1248: Training Accuracy = 0.9871, Training Loss = 0.1053, Validation Accuracy = 0.0240, Validation Loss = 5.7881\n",
            "Epoch 1249/3334\n",
            "Epoch 1249: Training Accuracy = 0.9871, Training Loss = 0.1053, Validation Accuracy = 0.0240, Validation Loss = 5.7881\n",
            "Epoch 1250/3334\n",
            "Epoch 1250: Training Accuracy = 0.9871, Training Loss = 0.1053, Validation Accuracy = 0.0240, Validation Loss = 5.7881\n",
            "Epoch 1251/3334\n",
            "Epoch 1251: Training Accuracy = 0.9912, Training Loss = 0.0880, Validation Accuracy = 0.0229, Validation Loss = 5.7745\n",
            "Epoch 1252/3334\n",
            "Epoch 1252: Training Accuracy = 0.9912, Training Loss = 0.0880, Validation Accuracy = 0.0229, Validation Loss = 5.7745\n",
            "Epoch 1253/3334\n",
            "Epoch 1253: Training Accuracy = 0.9912, Training Loss = 0.0880, Validation Accuracy = 0.0229, Validation Loss = 5.7745\n",
            "Epoch 1254/3334\n",
            "Epoch 1254: Training Accuracy = 0.9873, Training Loss = 0.1014, Validation Accuracy = 0.0234, Validation Loss = 5.7699\n",
            "Epoch 1255/3334\n",
            "Epoch 1255: Training Accuracy = 0.9873, Training Loss = 0.1014, Validation Accuracy = 0.0234, Validation Loss = 5.7699\n",
            "Epoch 1256/3334\n",
            "Epoch 1256: Training Accuracy = 0.9873, Training Loss = 0.1014, Validation Accuracy = 0.0234, Validation Loss = 5.7699\n",
            "Epoch 1257/3334\n",
            "Epoch 1257: Training Accuracy = 0.9922, Training Loss = 0.0894, Validation Accuracy = 0.0222, Validation Loss = 5.7810\n",
            "Epoch 1258/3334\n",
            "Epoch 1258: Training Accuracy = 0.9922, Training Loss = 0.0894, Validation Accuracy = 0.0222, Validation Loss = 5.7810\n",
            "Epoch 1259/3334\n",
            "Epoch 1259: Training Accuracy = 0.9922, Training Loss = 0.0894, Validation Accuracy = 0.0222, Validation Loss = 5.7810\n",
            "Epoch 1260/3334\n",
            "Epoch 1260: Training Accuracy = 0.9922, Training Loss = 0.0894, Validation Accuracy = 0.0222, Validation Loss = 5.7810\n",
            "Epoch 1261/3334\n",
            "Epoch 1261: Training Accuracy = 0.9951, Training Loss = 0.1849, Validation Accuracy = 0.0281, Validation Loss = 5.6801\n",
            "Epoch 1262/3334\n",
            "Epoch 1262: Training Accuracy = 0.9951, Training Loss = 0.1849, Validation Accuracy = 0.0281, Validation Loss = 5.6801\n",
            "Epoch 1263/3334\n",
            "Epoch 1263: Training Accuracy = 0.9951, Training Loss = 0.1849, Validation Accuracy = 0.0281, Validation Loss = 5.6801\n",
            "Epoch 1264/3334\n",
            "Epoch 1264: Training Accuracy = 0.8994, Training Loss = 0.7367, Validation Accuracy = 0.0229, Validation Loss = 5.3390\n",
            "Epoch 1265/3334\n",
            "Epoch 1265: Training Accuracy = 0.8994, Training Loss = 0.7367, Validation Accuracy = 0.0229, Validation Loss = 5.3390\n",
            "Epoch 1266/3334\n",
            "Epoch 1266: Training Accuracy = 0.8994, Training Loss = 0.7367, Validation Accuracy = 0.0229, Validation Loss = 5.3390\n",
            "Epoch 1267/3334\n",
            "Epoch 1267: Training Accuracy = 0.9793, Training Loss = 0.3436, Validation Accuracy = 0.0246, Validation Loss = 5.5379\n",
            "Epoch 1268/3334\n",
            "Epoch 1268: Training Accuracy = 0.9793, Training Loss = 0.3436, Validation Accuracy = 0.0246, Validation Loss = 5.5379\n",
            "Epoch 1269/3334\n",
            "Epoch 1269: Training Accuracy = 0.9793, Training Loss = 0.3436, Validation Accuracy = 0.0246, Validation Loss = 5.5379\n",
            "Epoch 1270/3334\n",
            "Epoch 1270: Training Accuracy = 0.9793, Training Loss = 0.3436, Validation Accuracy = 0.0246, Validation Loss = 5.5379\n",
            "Epoch 1271/3334\n",
            "Epoch 1271: Training Accuracy = 0.9863, Training Loss = 0.1902, Validation Accuracy = 0.0232, Validation Loss = 5.7020\n",
            "Epoch 1272/3334\n",
            "Epoch 1272: Training Accuracy = 0.9863, Training Loss = 0.1902, Validation Accuracy = 0.0232, Validation Loss = 5.7020\n",
            "Epoch 1273/3334\n",
            "Epoch 1273: Training Accuracy = 0.9863, Training Loss = 0.1902, Validation Accuracy = 0.0232, Validation Loss = 5.7020\n",
            "Epoch 1274/3334\n",
            "Epoch 1274: Training Accuracy = 0.9883, Training Loss = 0.1366, Validation Accuracy = 0.0237, Validation Loss = 5.6891\n",
            "Epoch 1275/3334\n",
            "Epoch 1275: Training Accuracy = 0.9883, Training Loss = 0.1366, Validation Accuracy = 0.0237, Validation Loss = 5.6891\n",
            "Epoch 1276/3334\n",
            "Epoch 1276: Training Accuracy = 0.9883, Training Loss = 0.1366, Validation Accuracy = 0.0237, Validation Loss = 5.6891\n",
            "Epoch 1277/3334\n",
            "Epoch 1277: Training Accuracy = 0.9884, Training Loss = 0.1185, Validation Accuracy = 0.0219, Validation Loss = 5.7067\n",
            "Epoch 1278/3334\n",
            "Epoch 1278: Training Accuracy = 0.9884, Training Loss = 0.1185, Validation Accuracy = 0.0219, Validation Loss = 5.7067\n",
            "Epoch 1279/3334\n",
            "Epoch 1279: Training Accuracy = 0.9884, Training Loss = 0.1185, Validation Accuracy = 0.0219, Validation Loss = 5.7067\n",
            "Epoch 1280/3334\n",
            "Epoch 1280: Training Accuracy = 0.9884, Training Loss = 0.1185, Validation Accuracy = 0.0219, Validation Loss = 5.7067\n",
            "Epoch 1281/3334\n",
            "Epoch 1281: Training Accuracy = 0.9863, Training Loss = 0.1092, Validation Accuracy = 0.0234, Validation Loss = 5.7234\n",
            "Epoch 1282/3334\n",
            "Epoch 1282: Training Accuracy = 0.9863, Training Loss = 0.1092, Validation Accuracy = 0.0234, Validation Loss = 5.7234\n",
            "Epoch 1283/3334\n",
            "Epoch 1283: Training Accuracy = 0.9863, Training Loss = 0.1092, Validation Accuracy = 0.0234, Validation Loss = 5.7234\n",
            "Epoch 1284/3334\n",
            "Epoch 1284: Training Accuracy = 0.9854, Training Loss = 0.1100, Validation Accuracy = 0.0235, Validation Loss = 5.7075\n",
            "Epoch 1285/3334\n",
            "Epoch 1285: Training Accuracy = 0.9854, Training Loss = 0.1100, Validation Accuracy = 0.0235, Validation Loss = 5.7075\n",
            "Epoch 1286/3334\n",
            "Epoch 1286: Training Accuracy = 0.9854, Training Loss = 0.1100, Validation Accuracy = 0.0235, Validation Loss = 5.7075\n",
            "Epoch 1287/3334\n",
            "Epoch 1287: Training Accuracy = 0.9871, Training Loss = 0.1059, Validation Accuracy = 0.0244, Validation Loss = 5.7036\n",
            "Epoch 1288/3334\n",
            "Epoch 1288: Training Accuracy = 0.9871, Training Loss = 0.1059, Validation Accuracy = 0.0244, Validation Loss = 5.7036\n",
            "Epoch 1289/3334\n",
            "Epoch 1289: Training Accuracy = 0.9871, Training Loss = 0.1059, Validation Accuracy = 0.0244, Validation Loss = 5.7036\n",
            "Epoch 1290/3334\n",
            "Epoch 1290: Training Accuracy = 0.9871, Training Loss = 0.1059, Validation Accuracy = 0.0244, Validation Loss = 5.7036\n",
            "Epoch 1291/3334\n",
            "Epoch 1291: Training Accuracy = 0.9893, Training Loss = 0.0945, Validation Accuracy = 0.0225, Validation Loss = 5.6978\n",
            "Epoch 1292/3334\n",
            "Epoch 1292: Training Accuracy = 0.9893, Training Loss = 0.0945, Validation Accuracy = 0.0225, Validation Loss = 5.6978\n",
            "Epoch 1293/3334\n",
            "Epoch 1293: Training Accuracy = 0.9893, Training Loss = 0.0945, Validation Accuracy = 0.0225, Validation Loss = 5.6978\n",
            "Epoch 1294/3334\n",
            "Epoch 1294: Training Accuracy = 0.9863, Training Loss = 0.1167, Validation Accuracy = 0.0247, Validation Loss = 5.6829\n",
            "Epoch 1295/3334\n",
            "Epoch 1295: Training Accuracy = 0.9863, Training Loss = 0.1167, Validation Accuracy = 0.0247, Validation Loss = 5.6829\n",
            "Epoch 1296/3334\n",
            "Epoch 1296: Training Accuracy = 0.9863, Training Loss = 0.1167, Validation Accuracy = 0.0247, Validation Loss = 5.6829\n",
            "Epoch 1297/3334\n",
            "Epoch 1297: Training Accuracy = 0.4522, Training Loss = 2.3327, Validation Accuracy = 0.0278, Validation Loss = 5.8465\n",
            "Epoch 1298/3334\n",
            "Epoch 1298: Training Accuracy = 0.4522, Training Loss = 2.3327, Validation Accuracy = 0.0278, Validation Loss = 5.8465\n",
            "Epoch 1299/3334\n",
            "Epoch 1299: Training Accuracy = 0.4522, Training Loss = 2.3327, Validation Accuracy = 0.0278, Validation Loss = 5.8465\n",
            "Epoch 1300/3334\n",
            "Epoch 1300: Training Accuracy = 0.4522, Training Loss = 2.3327, Validation Accuracy = 0.0278, Validation Loss = 5.8465\n",
            "Epoch 1301/3334\n",
            "Epoch 1301: Training Accuracy = 0.9307, Training Loss = 0.6571, Validation Accuracy = 0.0267, Validation Loss = 5.1298\n",
            "Epoch 1302/3334\n",
            "Epoch 1302: Training Accuracy = 0.9307, Training Loss = 0.6571, Validation Accuracy = 0.0267, Validation Loss = 5.1298\n",
            "Epoch 1303/3334\n",
            "Epoch 1303: Training Accuracy = 0.9307, Training Loss = 0.6571, Validation Accuracy = 0.0267, Validation Loss = 5.1298\n",
            "Epoch 1304/3334\n",
            "Epoch 1304: Training Accuracy = 0.9834, Training Loss = 0.3400, Validation Accuracy = 0.0287, Validation Loss = 5.4260\n",
            "Epoch 1305/3334\n",
            "Epoch 1305: Training Accuracy = 0.9834, Training Loss = 0.3400, Validation Accuracy = 0.0287, Validation Loss = 5.4260\n",
            "Epoch 1306/3334\n",
            "Epoch 1306: Training Accuracy = 0.9834, Training Loss = 0.3400, Validation Accuracy = 0.0287, Validation Loss = 5.4260\n",
            "Epoch 1307/3334\n",
            "Epoch 1307: Training Accuracy = 0.9922, Training Loss = 0.1842, Validation Accuracy = 0.0272, Validation Loss = 5.5300\n",
            "Epoch 1308/3334\n",
            "Epoch 1308: Training Accuracy = 0.9922, Training Loss = 0.1842, Validation Accuracy = 0.0272, Validation Loss = 5.5300\n",
            "Epoch 1309/3334\n",
            "Epoch 1309: Training Accuracy = 0.9922, Training Loss = 0.1842, Validation Accuracy = 0.0272, Validation Loss = 5.5300\n",
            "Epoch 1310/3334\n",
            "Epoch 1310: Training Accuracy = 0.9922, Training Loss = 0.1842, Validation Accuracy = 0.0272, Validation Loss = 5.5300\n",
            "Epoch 1311/3334\n",
            "Epoch 1311: Training Accuracy = 0.9902, Training Loss = 0.1313, Validation Accuracy = 0.0266, Validation Loss = 5.5664\n",
            "Epoch 1312/3334\n",
            "Epoch 1312: Training Accuracy = 0.9902, Training Loss = 0.1313, Validation Accuracy = 0.0266, Validation Loss = 5.5664\n",
            "Epoch 1313/3334\n",
            "Epoch 1313: Training Accuracy = 0.9902, Training Loss = 0.1313, Validation Accuracy = 0.0266, Validation Loss = 5.5664\n",
            "Epoch 1314/3334\n",
            "Epoch 1314: Training Accuracy = 0.9873, Training Loss = 0.1227, Validation Accuracy = 0.0270, Validation Loss = 5.5789\n",
            "Epoch 1315/3334\n",
            "Epoch 1315: Training Accuracy = 0.9873, Training Loss = 0.1227, Validation Accuracy = 0.0270, Validation Loss = 5.5789\n",
            "Epoch 1316/3334\n",
            "Epoch 1316: Training Accuracy = 0.9873, Training Loss = 0.1227, Validation Accuracy = 0.0270, Validation Loss = 5.5789\n",
            "Epoch 1317/3334\n",
            "Epoch 1317: Training Accuracy = 0.9871, Training Loss = 0.1132, Validation Accuracy = 0.0279, Validation Loss = 5.5883\n",
            "Epoch 1318/3334\n",
            "Epoch 1318: Training Accuracy = 0.9871, Training Loss = 0.1132, Validation Accuracy = 0.0279, Validation Loss = 5.5883\n",
            "Epoch 1319/3334\n",
            "Epoch 1319: Training Accuracy = 0.9871, Training Loss = 0.1132, Validation Accuracy = 0.0279, Validation Loss = 5.5883\n",
            "Epoch 1320/3334\n",
            "Epoch 1320: Training Accuracy = 0.9871, Training Loss = 0.1132, Validation Accuracy = 0.0279, Validation Loss = 5.5883\n",
            "Epoch 1321/3334\n",
            "Epoch 1321: Training Accuracy = 0.9883, Training Loss = 0.0989, Validation Accuracy = 0.0269, Validation Loss = 5.5844\n",
            "Epoch 1322/3334\n",
            "Epoch 1322: Training Accuracy = 0.9883, Training Loss = 0.0989, Validation Accuracy = 0.0269, Validation Loss = 5.5844\n",
            "Epoch 1323/3334\n",
            "Epoch 1323: Training Accuracy = 0.9883, Training Loss = 0.0989, Validation Accuracy = 0.0269, Validation Loss = 5.5844\n",
            "Epoch 1324/3334\n",
            "Epoch 1324: Training Accuracy = 0.9854, Training Loss = 0.1105, Validation Accuracy = 0.0273, Validation Loss = 5.5812\n",
            "Epoch 1325/3334\n",
            "Epoch 1325: Training Accuracy = 0.9854, Training Loss = 0.1105, Validation Accuracy = 0.0273, Validation Loss = 5.5812\n",
            "Epoch 1326/3334\n",
            "Epoch 1326: Training Accuracy = 0.9854, Training Loss = 0.1105, Validation Accuracy = 0.0273, Validation Loss = 5.5812\n",
            "Epoch 1327/3334\n",
            "Epoch 1327: Training Accuracy = 0.9910, Training Loss = 0.0916, Validation Accuracy = 0.0255, Validation Loss = 5.5848\n",
            "Epoch 1328/3334\n",
            "Epoch 1328: Training Accuracy = 0.9910, Training Loss = 0.0916, Validation Accuracy = 0.0255, Validation Loss = 5.5848\n",
            "Epoch 1329/3334\n",
            "Epoch 1329: Training Accuracy = 0.9910, Training Loss = 0.0916, Validation Accuracy = 0.0255, Validation Loss = 5.5848\n",
            "Epoch 1330/3334\n",
            "Epoch 1330: Training Accuracy = 0.9910, Training Loss = 0.0916, Validation Accuracy = 0.0255, Validation Loss = 5.5848\n",
            "Epoch 1331/3334\n",
            "Epoch 1331: Training Accuracy = 0.9912, Training Loss = 0.0881, Validation Accuracy = 0.0264, Validation Loss = 5.5703\n",
            "Epoch 1332/3334\n",
            "Epoch 1332: Training Accuracy = 0.9912, Training Loss = 0.0881, Validation Accuracy = 0.0264, Validation Loss = 5.5703\n",
            "Epoch 1333/3334\n",
            "Epoch 1333: Training Accuracy = 0.9912, Training Loss = 0.0881, Validation Accuracy = 0.0264, Validation Loss = 5.5703\n",
            "Epoch 1334/3334\n",
            "Epoch 1334: Training Accuracy = 0.9932, Training Loss = 0.0835, Validation Accuracy = 0.0266, Validation Loss = 5.5592\n",
            "Epoch 1335/3334\n",
            "Epoch 1335: Training Accuracy = 0.9932, Training Loss = 0.0835, Validation Accuracy = 0.0266, Validation Loss = 5.5592\n",
            "Epoch 1336/3334\n",
            "Epoch 1336: Training Accuracy = 0.9932, Training Loss = 0.0835, Validation Accuracy = 0.0266, Validation Loss = 5.5592\n",
            "Epoch 1337/3334\n",
            "Epoch 1337: Training Accuracy = 0.9819, Training Loss = 0.1438, Validation Accuracy = 0.0284, Validation Loss = 5.6037\n",
            "Epoch 1338/3334\n",
            "Epoch 1338: Training Accuracy = 0.9819, Training Loss = 0.1438, Validation Accuracy = 0.0284, Validation Loss = 5.6037\n",
            "Epoch 1339/3334\n",
            "Epoch 1339: Training Accuracy = 0.9819, Training Loss = 0.1438, Validation Accuracy = 0.0284, Validation Loss = 5.6037\n",
            "Epoch 1340/3334\n",
            "Epoch 1340: Training Accuracy = 0.9819, Training Loss = 0.1438, Validation Accuracy = 0.0284, Validation Loss = 5.6037\n",
            "Epoch 1341/3334\n",
            "Epoch 1341: Training Accuracy = 0.7920, Training Loss = 1.0389, Validation Accuracy = 0.0272, Validation Loss = 5.0985\n",
            "Epoch 1342/3334\n",
            "Epoch 1342: Training Accuracy = 0.7920, Training Loss = 1.0389, Validation Accuracy = 0.0272, Validation Loss = 5.0985\n",
            "Epoch 1343/3334\n",
            "Epoch 1343: Training Accuracy = 0.7920, Training Loss = 1.0389, Validation Accuracy = 0.0272, Validation Loss = 5.0985\n",
            "Epoch 1344/3334\n",
            "Epoch 1344: Training Accuracy = 0.9668, Training Loss = 0.4260, Validation Accuracy = 0.0287, Validation Loss = 5.1466\n",
            "Epoch 1345/3334\n",
            "Epoch 1345: Training Accuracy = 0.9668, Training Loss = 0.4260, Validation Accuracy = 0.0287, Validation Loss = 5.1466\n",
            "Epoch 1346/3334\n",
            "Epoch 1346: Training Accuracy = 0.9668, Training Loss = 0.4260, Validation Accuracy = 0.0287, Validation Loss = 5.1466\n",
            "Epoch 1347/3334\n",
            "Epoch 1347: Training Accuracy = 0.9832, Training Loss = 0.2505, Validation Accuracy = 0.0257, Validation Loss = 5.3928\n",
            "Epoch 1348/3334\n",
            "Epoch 1348: Training Accuracy = 0.9832, Training Loss = 0.2505, Validation Accuracy = 0.0257, Validation Loss = 5.3928\n",
            "Epoch 1349/3334\n",
            "Epoch 1349: Training Accuracy = 0.9832, Training Loss = 0.2505, Validation Accuracy = 0.0257, Validation Loss = 5.3928\n",
            "Epoch 1350/3334\n",
            "Epoch 1350: Training Accuracy = 0.9832, Training Loss = 0.2505, Validation Accuracy = 0.0257, Validation Loss = 5.3928\n",
            "Epoch 1351/3334\n",
            "Epoch 1351: Training Accuracy = 0.9883, Training Loss = 0.1527, Validation Accuracy = 0.0270, Validation Loss = 5.4093\n",
            "Epoch 1352/3334\n",
            "Epoch 1352: Training Accuracy = 0.9883, Training Loss = 0.1527, Validation Accuracy = 0.0270, Validation Loss = 5.4093\n",
            "Epoch 1353/3334\n",
            "Epoch 1353: Training Accuracy = 0.9883, Training Loss = 0.1527, Validation Accuracy = 0.0270, Validation Loss = 5.4093\n",
            "Epoch 1354/3334\n",
            "Epoch 1354: Training Accuracy = 0.9873, Training Loss = 0.1259, Validation Accuracy = 0.0287, Validation Loss = 5.4229\n",
            "Epoch 1355/3334\n",
            "Epoch 1355: Training Accuracy = 0.9873, Training Loss = 0.1259, Validation Accuracy = 0.0287, Validation Loss = 5.4229\n",
            "Epoch 1356/3334\n",
            "Epoch 1356: Training Accuracy = 0.9873, Training Loss = 0.1259, Validation Accuracy = 0.0287, Validation Loss = 5.4229\n",
            "Epoch 1357/3334\n",
            "Epoch 1357: Training Accuracy = 0.9897, Training Loss = 0.1092, Validation Accuracy = 0.0275, Validation Loss = 5.4373\n",
            "Epoch 1358/3334\n",
            "Epoch 1358: Training Accuracy = 0.9897, Training Loss = 0.1092, Validation Accuracy = 0.0275, Validation Loss = 5.4373\n",
            "Epoch 1359/3334\n",
            "Epoch 1359: Training Accuracy = 0.9897, Training Loss = 0.1092, Validation Accuracy = 0.0275, Validation Loss = 5.4373\n",
            "Epoch 1360/3334\n",
            "Epoch 1360: Training Accuracy = 0.9897, Training Loss = 0.1092, Validation Accuracy = 0.0275, Validation Loss = 5.4373\n",
            "Epoch 1361/3334\n",
            "Epoch 1361: Training Accuracy = 0.9834, Training Loss = 0.1182, Validation Accuracy = 0.0288, Validation Loss = 5.4440\n",
            "Epoch 1362/3334\n",
            "Epoch 1362: Training Accuracy = 0.9834, Training Loss = 0.1182, Validation Accuracy = 0.0288, Validation Loss = 5.4440\n",
            "Epoch 1363/3334\n",
            "Epoch 1363: Training Accuracy = 0.9834, Training Loss = 0.1182, Validation Accuracy = 0.0288, Validation Loss = 5.4440\n",
            "Epoch 1364/3334\n",
            "Epoch 1364: Training Accuracy = 0.9893, Training Loss = 0.0987, Validation Accuracy = 0.0284, Validation Loss = 5.4372\n",
            "Epoch 1365/3334\n",
            "Epoch 1365: Training Accuracy = 0.9893, Training Loss = 0.0987, Validation Accuracy = 0.0284, Validation Loss = 5.4372\n",
            "Epoch 1366/3334\n",
            "Epoch 1366: Training Accuracy = 0.9893, Training Loss = 0.0987, Validation Accuracy = 0.0284, Validation Loss = 5.4372\n",
            "Epoch 1367/3334\n",
            "Epoch 1367: Training Accuracy = 0.9910, Training Loss = 0.0926, Validation Accuracy = 0.0282, Validation Loss = 5.4185\n",
            "Epoch 1368/3334\n",
            "Epoch 1368: Training Accuracy = 0.9910, Training Loss = 0.0926, Validation Accuracy = 0.0282, Validation Loss = 5.4185\n",
            "Epoch 1369/3334\n",
            "Epoch 1369: Training Accuracy = 0.9910, Training Loss = 0.0926, Validation Accuracy = 0.0282, Validation Loss = 5.4185\n",
            "Epoch 1370/3334\n",
            "Epoch 1370: Training Accuracy = 0.9910, Training Loss = 0.0926, Validation Accuracy = 0.0282, Validation Loss = 5.4185\n",
            "Epoch 1371/3334\n",
            "Epoch 1371: Training Accuracy = 0.9902, Training Loss = 0.0911, Validation Accuracy = 0.0285, Validation Loss = 5.4182\n",
            "Epoch 1372/3334\n",
            "Epoch 1372: Training Accuracy = 0.9902, Training Loss = 0.0911, Validation Accuracy = 0.0285, Validation Loss = 5.4182\n",
            "Epoch 1373/3334\n",
            "Epoch 1373: Training Accuracy = 0.9902, Training Loss = 0.0911, Validation Accuracy = 0.0285, Validation Loss = 5.4182\n",
            "Epoch 1374/3334\n",
            "Epoch 1374: Training Accuracy = 0.9902, Training Loss = 0.0994, Validation Accuracy = 0.0281, Validation Loss = 5.4205\n",
            "Epoch 1375/3334\n",
            "Epoch 1375: Training Accuracy = 0.9902, Training Loss = 0.0994, Validation Accuracy = 0.0281, Validation Loss = 5.4205\n",
            "Epoch 1376/3334\n",
            "Epoch 1376: Training Accuracy = 0.9902, Training Loss = 0.0994, Validation Accuracy = 0.0281, Validation Loss = 5.4205\n",
            "Epoch 1377/3334\n",
            "Epoch 1377: Training Accuracy = 0.9871, Training Loss = 0.1175, Validation Accuracy = 0.0285, Validation Loss = 5.4191\n",
            "Epoch 1378/3334\n",
            "Epoch 1378: Training Accuracy = 0.9871, Training Loss = 0.1175, Validation Accuracy = 0.0285, Validation Loss = 5.4191\n",
            "Epoch 1379/3334\n",
            "Epoch 1379: Training Accuracy = 0.9871, Training Loss = 0.1175, Validation Accuracy = 0.0285, Validation Loss = 5.4191\n",
            "Epoch 1380/3334\n",
            "Epoch 1380: Training Accuracy = 0.9871, Training Loss = 0.1175, Validation Accuracy = 0.0285, Validation Loss = 5.4191\n",
            "Epoch 1381/3334\n",
            "Epoch 1381: Training Accuracy = 0.3867, Training Loss = 2.4777, Validation Accuracy = 0.0295, Validation Loss = 5.2570\n",
            "Epoch 1382/3334\n",
            "Epoch 1382: Training Accuracy = 0.3867, Training Loss = 2.4777, Validation Accuracy = 0.0295, Validation Loss = 5.2570\n",
            "Epoch 1383/3334\n",
            "Epoch 1383: Training Accuracy = 0.3867, Training Loss = 2.4777, Validation Accuracy = 0.0295, Validation Loss = 5.2570\n",
            "Epoch 1384/3334\n",
            "Epoch 1384: Training Accuracy = 0.9277, Training Loss = 0.6655, Validation Accuracy = 0.0291, Validation Loss = 5.0149\n",
            "Epoch 1385/3334\n",
            "Epoch 1385: Training Accuracy = 0.9277, Training Loss = 0.6655, Validation Accuracy = 0.0291, Validation Loss = 5.0149\n",
            "Epoch 1386/3334\n",
            "Epoch 1386: Training Accuracy = 0.9277, Training Loss = 0.6655, Validation Accuracy = 0.0291, Validation Loss = 5.0149\n",
            "Epoch 1387/3334\n",
            "Epoch 1387: Training Accuracy = 0.9858, Training Loss = 0.2982, Validation Accuracy = 0.0304, Validation Loss = 5.2089\n",
            "Epoch 1388/3334\n",
            "Epoch 1388: Training Accuracy = 0.9858, Training Loss = 0.2982, Validation Accuracy = 0.0304, Validation Loss = 5.2089\n",
            "Epoch 1389/3334\n",
            "Epoch 1389: Training Accuracy = 0.9858, Training Loss = 0.2982, Validation Accuracy = 0.0304, Validation Loss = 5.2089\n",
            "Epoch 1390/3334\n",
            "Epoch 1390: Training Accuracy = 0.9858, Training Loss = 0.2982, Validation Accuracy = 0.0304, Validation Loss = 5.2089\n",
            "Epoch 1391/3334\n",
            "Epoch 1391: Training Accuracy = 0.9902, Training Loss = 0.1656, Validation Accuracy = 0.0316, Validation Loss = 5.2854\n",
            "Epoch 1392/3334\n",
            "Epoch 1392: Training Accuracy = 0.9902, Training Loss = 0.1656, Validation Accuracy = 0.0316, Validation Loss = 5.2854\n",
            "Epoch 1393/3334\n",
            "Epoch 1393: Training Accuracy = 0.9902, Training Loss = 0.1656, Validation Accuracy = 0.0316, Validation Loss = 5.2854\n",
            "Epoch 1394/3334\n",
            "Epoch 1394: Training Accuracy = 0.9873, Training Loss = 0.1379, Validation Accuracy = 0.0326, Validation Loss = 5.2715\n",
            "Epoch 1395/3334\n",
            "Epoch 1395: Training Accuracy = 0.9873, Training Loss = 0.1379, Validation Accuracy = 0.0326, Validation Loss = 5.2715\n",
            "Epoch 1396/3334\n",
            "Epoch 1396: Training Accuracy = 0.9873, Training Loss = 0.1379, Validation Accuracy = 0.0326, Validation Loss = 5.2715\n",
            "Epoch 1397/3334\n",
            "Epoch 1397: Training Accuracy = 0.9871, Training Loss = 0.1197, Validation Accuracy = 0.0314, Validation Loss = 5.2975\n",
            "Epoch 1398/3334\n",
            "Epoch 1398: Training Accuracy = 0.9871, Training Loss = 0.1197, Validation Accuracy = 0.0314, Validation Loss = 5.2975\n",
            "Epoch 1399/3334\n",
            "Epoch 1399: Training Accuracy = 0.9871, Training Loss = 0.1197, Validation Accuracy = 0.0314, Validation Loss = 5.2975\n",
            "Epoch 1400/3334\n",
            "Epoch 1400: Training Accuracy = 0.9871, Training Loss = 0.1197, Validation Accuracy = 0.0314, Validation Loss = 5.2975\n",
            "Epoch 1401/3334\n",
            "Epoch 1401: Training Accuracy = 0.9902, Training Loss = 0.0938, Validation Accuracy = 0.0326, Validation Loss = 5.3035\n",
            "Epoch 1402/3334\n",
            "Epoch 1402: Training Accuracy = 0.9902, Training Loss = 0.0938, Validation Accuracy = 0.0326, Validation Loss = 5.3035\n",
            "Epoch 1403/3334\n",
            "Epoch 1403: Training Accuracy = 0.9902, Training Loss = 0.0938, Validation Accuracy = 0.0326, Validation Loss = 5.3035\n",
            "Epoch 1404/3334\n",
            "Epoch 1404: Training Accuracy = 0.9893, Training Loss = 0.0978, Validation Accuracy = 0.0320, Validation Loss = 5.3046\n",
            "Epoch 1405/3334\n",
            "Epoch 1405: Training Accuracy = 0.9893, Training Loss = 0.0978, Validation Accuracy = 0.0320, Validation Loss = 5.3046\n",
            "Epoch 1406/3334\n",
            "Epoch 1406: Training Accuracy = 0.9893, Training Loss = 0.0978, Validation Accuracy = 0.0320, Validation Loss = 5.3046\n",
            "Epoch 1407/3334\n",
            "Epoch 1407: Training Accuracy = 0.9910, Training Loss = 0.0932, Validation Accuracy = 0.0322, Validation Loss = 5.3003\n",
            "Epoch 1408/3334\n",
            "Epoch 1408: Training Accuracy = 0.9910, Training Loss = 0.0932, Validation Accuracy = 0.0322, Validation Loss = 5.3003\n",
            "Epoch 1409/3334\n",
            "Epoch 1409: Training Accuracy = 0.9910, Training Loss = 0.0932, Validation Accuracy = 0.0322, Validation Loss = 5.3003\n",
            "Epoch 1410/3334\n",
            "Epoch 1410: Training Accuracy = 0.9910, Training Loss = 0.0932, Validation Accuracy = 0.0322, Validation Loss = 5.3003\n",
            "Epoch 1411/3334\n",
            "Epoch 1411: Training Accuracy = 0.9893, Training Loss = 0.0984, Validation Accuracy = 0.0299, Validation Loss = 5.2944\n",
            "Epoch 1412/3334\n",
            "Epoch 1412: Training Accuracy = 0.9893, Training Loss = 0.0984, Validation Accuracy = 0.0299, Validation Loss = 5.2944\n",
            "Epoch 1413/3334\n",
            "Epoch 1413: Training Accuracy = 0.9893, Training Loss = 0.0984, Validation Accuracy = 0.0299, Validation Loss = 5.2944\n",
            "Epoch 1414/3334\n",
            "Epoch 1414: Training Accuracy = 0.9844, Training Loss = 0.1161, Validation Accuracy = 0.0311, Validation Loss = 5.2873\n",
            "Epoch 1415/3334\n",
            "Epoch 1415: Training Accuracy = 0.9844, Training Loss = 0.1161, Validation Accuracy = 0.0311, Validation Loss = 5.2873\n",
            "Epoch 1416/3334\n",
            "Epoch 1416: Training Accuracy = 0.9844, Training Loss = 0.1161, Validation Accuracy = 0.0311, Validation Loss = 5.2873\n",
            "Epoch 1417/3334\n",
            "Epoch 1417: Training Accuracy = 0.9832, Training Loss = 0.1293, Validation Accuracy = 0.0311, Validation Loss = 5.2746\n",
            "Epoch 1418/3334\n",
            "Epoch 1418: Training Accuracy = 0.9832, Training Loss = 0.1293, Validation Accuracy = 0.0311, Validation Loss = 5.2746\n",
            "Epoch 1419/3334\n",
            "Epoch 1419: Training Accuracy = 0.9832, Training Loss = 0.1293, Validation Accuracy = 0.0311, Validation Loss = 5.2746\n",
            "Epoch 1420/3334\n",
            "Epoch 1420: Training Accuracy = 0.9832, Training Loss = 0.1293, Validation Accuracy = 0.0311, Validation Loss = 5.2746\n",
            "Epoch 1421/3334\n",
            "Epoch 1421: Training Accuracy = 0.9893, Training Loss = 0.1140, Validation Accuracy = 0.0299, Validation Loss = 5.3327\n",
            "Epoch 1422/3334\n",
            "Epoch 1422: Training Accuracy = 0.9893, Training Loss = 0.1140, Validation Accuracy = 0.0299, Validation Loss = 5.3327\n",
            "Epoch 1423/3334\n",
            "Epoch 1423: Training Accuracy = 0.9893, Training Loss = 0.1140, Validation Accuracy = 0.0299, Validation Loss = 5.3327\n",
            "Epoch 1424/3334\n",
            "Epoch 1424: Training Accuracy = 0.8438, Training Loss = 0.9159, Validation Accuracy = 0.0340, Validation Loss = 4.7918\n",
            "Epoch 1425/3334\n",
            "Epoch 1425: Training Accuracy = 0.8438, Training Loss = 0.9159, Validation Accuracy = 0.0340, Validation Loss = 4.7918\n",
            "Epoch 1426/3334\n",
            "Epoch 1426: Training Accuracy = 0.8438, Training Loss = 0.9159, Validation Accuracy = 0.0340, Validation Loss = 4.7918\n",
            "Epoch 1427/3334\n",
            "Epoch 1427: Training Accuracy = 0.9638, Training Loss = 0.4595, Validation Accuracy = 0.0381, Validation Loss = 4.8972\n",
            "Epoch 1428/3334\n",
            "Epoch 1428: Training Accuracy = 0.9638, Training Loss = 0.4595, Validation Accuracy = 0.0381, Validation Loss = 4.8972\n",
            "Epoch 1429/3334\n",
            "Epoch 1429: Training Accuracy = 0.9638, Training Loss = 0.4595, Validation Accuracy = 0.0381, Validation Loss = 4.8972\n",
            "Epoch 1430/3334\n",
            "Epoch 1430: Training Accuracy = 0.9638, Training Loss = 0.4595, Validation Accuracy = 0.0381, Validation Loss = 4.8972\n",
            "Epoch 1431/3334\n",
            "Epoch 1431: Training Accuracy = 0.9863, Training Loss = 0.2176, Validation Accuracy = 0.0334, Validation Loss = 5.0528\n",
            "Epoch 1432/3334\n",
            "Epoch 1432: Training Accuracy = 0.9863, Training Loss = 0.2176, Validation Accuracy = 0.0334, Validation Loss = 5.0528\n",
            "Epoch 1433/3334\n",
            "Epoch 1433: Training Accuracy = 0.9863, Training Loss = 0.2176, Validation Accuracy = 0.0334, Validation Loss = 5.0528\n",
            "Epoch 1434/3334\n",
            "Epoch 1434: Training Accuracy = 0.9893, Training Loss = 0.1499, Validation Accuracy = 0.0334, Validation Loss = 5.0742\n",
            "Epoch 1435/3334\n",
            "Epoch 1435: Training Accuracy = 0.9893, Training Loss = 0.1499, Validation Accuracy = 0.0334, Validation Loss = 5.0742\n",
            "Epoch 1436/3334\n",
            "Epoch 1436: Training Accuracy = 0.9893, Training Loss = 0.1499, Validation Accuracy = 0.0334, Validation Loss = 5.0742\n",
            "Epoch 1437/3334\n",
            "Epoch 1437: Training Accuracy = 0.9871, Training Loss = 0.1295, Validation Accuracy = 0.0334, Validation Loss = 5.1053\n",
            "Epoch 1438/3334\n",
            "Epoch 1438: Training Accuracy = 0.9871, Training Loss = 0.1295, Validation Accuracy = 0.0334, Validation Loss = 5.1053\n",
            "Epoch 1439/3334\n",
            "Epoch 1439: Training Accuracy = 0.9871, Training Loss = 0.1295, Validation Accuracy = 0.0334, Validation Loss = 5.1053\n",
            "Epoch 1440/3334\n",
            "Epoch 1440: Training Accuracy = 0.9871, Training Loss = 0.1295, Validation Accuracy = 0.0334, Validation Loss = 5.1053\n",
            "Epoch 1441/3334\n",
            "Epoch 1441: Training Accuracy = 0.9863, Training Loss = 0.1162, Validation Accuracy = 0.0363, Validation Loss = 5.1246\n",
            "Epoch 1442/3334\n",
            "Epoch 1442: Training Accuracy = 0.9863, Training Loss = 0.1162, Validation Accuracy = 0.0363, Validation Loss = 5.1246\n",
            "Epoch 1443/3334\n",
            "Epoch 1443: Training Accuracy = 0.9863, Training Loss = 0.1162, Validation Accuracy = 0.0363, Validation Loss = 5.1246\n",
            "Epoch 1444/3334\n",
            "Epoch 1444: Training Accuracy = 0.9893, Training Loss = 0.1000, Validation Accuracy = 0.0354, Validation Loss = 5.1245\n",
            "Epoch 1445/3334\n",
            "Epoch 1445: Training Accuracy = 0.9893, Training Loss = 0.1000, Validation Accuracy = 0.0354, Validation Loss = 5.1245\n",
            "Epoch 1446/3334\n",
            "Epoch 1446: Training Accuracy = 0.9893, Training Loss = 0.1000, Validation Accuracy = 0.0354, Validation Loss = 5.1245\n",
            "Epoch 1447/3334\n",
            "Epoch 1447: Training Accuracy = 0.9922, Training Loss = 0.0904, Validation Accuracy = 0.0358, Validation Loss = 5.1199\n",
            "Epoch 1448/3334\n",
            "Epoch 1448: Training Accuracy = 0.9922, Training Loss = 0.0904, Validation Accuracy = 0.0358, Validation Loss = 5.1199\n",
            "Epoch 1449/3334\n",
            "Epoch 1449: Training Accuracy = 0.9922, Training Loss = 0.0904, Validation Accuracy = 0.0358, Validation Loss = 5.1199\n",
            "Epoch 1450/3334\n",
            "Epoch 1450: Training Accuracy = 0.9922, Training Loss = 0.0904, Validation Accuracy = 0.0358, Validation Loss = 5.1199\n",
            "Epoch 1451/3334\n",
            "Epoch 1451: Training Accuracy = 0.9893, Training Loss = 0.0950, Validation Accuracy = 0.0366, Validation Loss = 5.1188\n",
            "Epoch 1452/3334\n",
            "Epoch 1452: Training Accuracy = 0.9893, Training Loss = 0.0950, Validation Accuracy = 0.0366, Validation Loss = 5.1188\n",
            "Epoch 1453/3334\n",
            "Epoch 1453: Training Accuracy = 0.9893, Training Loss = 0.0950, Validation Accuracy = 0.0366, Validation Loss = 5.1188\n",
            "Epoch 1454/3334\n",
            "Epoch 1454: Training Accuracy = 0.9902, Training Loss = 0.0936, Validation Accuracy = 0.0367, Validation Loss = 5.1189\n",
            "Epoch 1455/3334\n",
            "Epoch 1455: Training Accuracy = 0.9902, Training Loss = 0.0936, Validation Accuracy = 0.0367, Validation Loss = 5.1189\n",
            "Epoch 1456/3334\n",
            "Epoch 1456: Training Accuracy = 0.9902, Training Loss = 0.0936, Validation Accuracy = 0.0367, Validation Loss = 5.1189\n",
            "Epoch 1457/3334\n",
            "Epoch 1457: Training Accuracy = 0.9897, Training Loss = 0.1002, Validation Accuracy = 0.0375, Validation Loss = 5.1066\n",
            "Epoch 1458/3334\n",
            "Epoch 1458: Training Accuracy = 0.9897, Training Loss = 0.1002, Validation Accuracy = 0.0375, Validation Loss = 5.1066\n",
            "Epoch 1459/3334\n",
            "Epoch 1459: Training Accuracy = 0.9897, Training Loss = 0.1002, Validation Accuracy = 0.0375, Validation Loss = 5.1066\n",
            "Epoch 1460/3334\n",
            "Epoch 1460: Training Accuracy = 0.9897, Training Loss = 0.1002, Validation Accuracy = 0.0375, Validation Loss = 5.1066\n",
            "Epoch 1461/3334\n",
            "Epoch 1461: Training Accuracy = 0.9873, Training Loss = 0.1476, Validation Accuracy = 0.0363, Validation Loss = 5.2143\n",
            "Epoch 1462/3334\n",
            "Epoch 1462: Training Accuracy = 0.9873, Training Loss = 0.1476, Validation Accuracy = 0.0363, Validation Loss = 5.2143\n",
            "Epoch 1463/3334\n",
            "Epoch 1463: Training Accuracy = 0.9873, Training Loss = 0.1476, Validation Accuracy = 0.0363, Validation Loss = 5.2143\n",
            "Epoch 1464/3334\n",
            "Epoch 1464: Training Accuracy = 0.8193, Training Loss = 0.9760, Validation Accuracy = 0.0384, Validation Loss = 4.6630\n",
            "Epoch 1465/3334\n",
            "Epoch 1465: Training Accuracy = 0.8193, Training Loss = 0.9760, Validation Accuracy = 0.0384, Validation Loss = 4.6630\n",
            "Epoch 1466/3334\n",
            "Epoch 1466: Training Accuracy = 0.8193, Training Loss = 0.9760, Validation Accuracy = 0.0384, Validation Loss = 4.6630\n",
            "Epoch 1467/3334\n",
            "Epoch 1467: Training Accuracy = 0.9703, Training Loss = 0.4394, Validation Accuracy = 0.0431, Validation Loss = 4.6197\n",
            "Epoch 1468/3334\n",
            "Epoch 1468: Training Accuracy = 0.9703, Training Loss = 0.4394, Validation Accuracy = 0.0431, Validation Loss = 4.6197\n",
            "Epoch 1469/3334\n",
            "Epoch 1469: Training Accuracy = 0.9703, Training Loss = 0.4394, Validation Accuracy = 0.0431, Validation Loss = 4.6197\n",
            "Epoch 1470/3334\n",
            "Epoch 1470: Training Accuracy = 0.9703, Training Loss = 0.4394, Validation Accuracy = 0.0431, Validation Loss = 4.6197\n",
            "Epoch 1471/3334\n",
            "Epoch 1471: Training Accuracy = 0.9922, Training Loss = 0.2000, Validation Accuracy = 0.0399, Validation Loss = 4.8020\n",
            "Epoch 1472/3334\n",
            "Epoch 1472: Training Accuracy = 0.9922, Training Loss = 0.2000, Validation Accuracy = 0.0399, Validation Loss = 4.8020\n",
            "Epoch 1473/3334\n",
            "Epoch 1473: Training Accuracy = 0.9922, Training Loss = 0.2000, Validation Accuracy = 0.0399, Validation Loss = 4.8020\n",
            "Epoch 1474/3334\n",
            "Epoch 1474: Training Accuracy = 0.9902, Training Loss = 0.1516, Validation Accuracy = 0.0430, Validation Loss = 4.8254\n",
            "Epoch 1475/3334\n",
            "Epoch 1475: Training Accuracy = 0.9902, Training Loss = 0.1516, Validation Accuracy = 0.0430, Validation Loss = 4.8254\n",
            "Epoch 1476/3334\n",
            "Epoch 1476: Training Accuracy = 0.9902, Training Loss = 0.1516, Validation Accuracy = 0.0430, Validation Loss = 4.8254\n",
            "Epoch 1477/3334\n",
            "Epoch 1477: Training Accuracy = 0.9910, Training Loss = 0.1194, Validation Accuracy = 0.0442, Validation Loss = 4.8681\n",
            "Epoch 1478/3334\n",
            "Epoch 1478: Training Accuracy = 0.9910, Training Loss = 0.1194, Validation Accuracy = 0.0442, Validation Loss = 4.8681\n",
            "Epoch 1479/3334\n",
            "Epoch 1479: Training Accuracy = 0.9910, Training Loss = 0.1194, Validation Accuracy = 0.0442, Validation Loss = 4.8681\n",
            "Epoch 1480/3334\n",
            "Epoch 1480: Training Accuracy = 0.9910, Training Loss = 0.1194, Validation Accuracy = 0.0442, Validation Loss = 4.8681\n",
            "Epoch 1481/3334\n",
            "Epoch 1481: Training Accuracy = 0.9912, Training Loss = 0.0981, Validation Accuracy = 0.0433, Validation Loss = 4.8934\n",
            "Epoch 1482/3334\n",
            "Epoch 1482: Training Accuracy = 0.9912, Training Loss = 0.0981, Validation Accuracy = 0.0433, Validation Loss = 4.8934\n",
            "Epoch 1483/3334\n",
            "Epoch 1483: Training Accuracy = 0.9912, Training Loss = 0.0981, Validation Accuracy = 0.0433, Validation Loss = 4.8934\n",
            "Epoch 1484/3334\n",
            "Epoch 1484: Training Accuracy = 0.9863, Training Loss = 0.1143, Validation Accuracy = 0.0425, Validation Loss = 4.9026\n",
            "Epoch 1485/3334\n",
            "Epoch 1485: Training Accuracy = 0.9863, Training Loss = 0.1143, Validation Accuracy = 0.0425, Validation Loss = 4.9026\n",
            "Epoch 1486/3334\n",
            "Epoch 1486: Training Accuracy = 0.9863, Training Loss = 0.1143, Validation Accuracy = 0.0425, Validation Loss = 4.9026\n",
            "Epoch 1487/3334\n",
            "Epoch 1487: Training Accuracy = 0.9922, Training Loss = 0.0900, Validation Accuracy = 0.0422, Validation Loss = 4.8991\n",
            "Epoch 1488/3334\n",
            "Epoch 1488: Training Accuracy = 0.9922, Training Loss = 0.0900, Validation Accuracy = 0.0422, Validation Loss = 4.8991\n",
            "Epoch 1489/3334\n",
            "Epoch 1489: Training Accuracy = 0.9922, Training Loss = 0.0900, Validation Accuracy = 0.0422, Validation Loss = 4.8991\n",
            "Epoch 1490/3334\n",
            "Epoch 1490: Training Accuracy = 0.9922, Training Loss = 0.0900, Validation Accuracy = 0.0422, Validation Loss = 4.8991\n",
            "Epoch 1491/3334\n",
            "Epoch 1491: Training Accuracy = 0.9883, Training Loss = 0.1009, Validation Accuracy = 0.0431, Validation Loss = 4.8906\n",
            "Epoch 1492/3334\n",
            "Epoch 1492: Training Accuracy = 0.9883, Training Loss = 0.1009, Validation Accuracy = 0.0431, Validation Loss = 4.8906\n",
            "Epoch 1493/3334\n",
            "Epoch 1493: Training Accuracy = 0.9883, Training Loss = 0.1009, Validation Accuracy = 0.0431, Validation Loss = 4.8906\n",
            "Epoch 1494/3334\n",
            "Epoch 1494: Training Accuracy = 0.9854, Training Loss = 0.1150, Validation Accuracy = 0.0437, Validation Loss = 4.9021\n",
            "Epoch 1495/3334\n",
            "Epoch 1495: Training Accuracy = 0.9854, Training Loss = 0.1150, Validation Accuracy = 0.0437, Validation Loss = 4.9021\n",
            "Epoch 1496/3334\n",
            "Epoch 1496: Training Accuracy = 0.9854, Training Loss = 0.1150, Validation Accuracy = 0.0437, Validation Loss = 4.9021\n",
            "Epoch 1497/3334\n",
            "Epoch 1497: Training Accuracy = 0.9858, Training Loss = 0.1148, Validation Accuracy = 0.0445, Validation Loss = 4.8900\n",
            "Epoch 1498/3334\n",
            "Epoch 1498: Training Accuracy = 0.9858, Training Loss = 0.1148, Validation Accuracy = 0.0445, Validation Loss = 4.8900\n",
            "Epoch 1499/3334\n",
            "Epoch 1499: Training Accuracy = 0.9858, Training Loss = 0.1148, Validation Accuracy = 0.0445, Validation Loss = 4.8900\n",
            "Epoch 1500/3334\n",
            "Epoch 1500: Training Accuracy = 0.9858, Training Loss = 0.1148, Validation Accuracy = 0.0445, Validation Loss = 4.8900\n",
            "Epoch 1501/3334\n",
            "Epoch 1501: Training Accuracy = 0.9863, Training Loss = 0.1258, Validation Accuracy = 0.0442, Validation Loss = 4.9618\n",
            "Epoch 1502/3334\n",
            "Epoch 1502: Training Accuracy = 0.9863, Training Loss = 0.1258, Validation Accuracy = 0.0442, Validation Loss = 4.9618\n",
            "Epoch 1503/3334\n",
            "Epoch 1503: Training Accuracy = 0.9863, Training Loss = 0.1258, Validation Accuracy = 0.0442, Validation Loss = 4.9618\n",
            "Epoch 1504/3334\n",
            "Epoch 1504: Training Accuracy = 0.7637, Training Loss = 1.1544, Validation Accuracy = 0.0419, Validation Loss = 4.4844\n",
            "Epoch 1505/3334\n",
            "Epoch 1505: Training Accuracy = 0.7637, Training Loss = 1.1544, Validation Accuracy = 0.0419, Validation Loss = 4.4844\n",
            "Epoch 1506/3334\n",
            "Epoch 1506: Training Accuracy = 0.7637, Training Loss = 1.1544, Validation Accuracy = 0.0419, Validation Loss = 4.4844\n",
            "Epoch 1507/3334\n",
            "Epoch 1507: Training Accuracy = 0.9651, Training Loss = 0.4964, Validation Accuracy = 0.0501, Validation Loss = 4.3831\n",
            "Epoch 1508/3334\n",
            "Epoch 1508: Training Accuracy = 0.9651, Training Loss = 0.4964, Validation Accuracy = 0.0501, Validation Loss = 4.3831\n",
            "Epoch 1509/3334\n",
            "Epoch 1509: Training Accuracy = 0.9651, Training Loss = 0.4964, Validation Accuracy = 0.0501, Validation Loss = 4.3831\n",
            "Epoch 1510/3334\n",
            "Epoch 1510: Training Accuracy = 0.9651, Training Loss = 0.4964, Validation Accuracy = 0.0501, Validation Loss = 4.3831\n",
            "Epoch 1511/3334\n",
            "Epoch 1511: Training Accuracy = 0.9854, Training Loss = 0.2780, Validation Accuracy = 0.0463, Validation Loss = 4.5614\n",
            "Epoch 1512/3334\n",
            "Epoch 1512: Training Accuracy = 0.9854, Training Loss = 0.2780, Validation Accuracy = 0.0463, Validation Loss = 4.5614\n",
            "Epoch 1513/3334\n",
            "Epoch 1513: Training Accuracy = 0.9854, Training Loss = 0.2780, Validation Accuracy = 0.0463, Validation Loss = 4.5614\n",
            "Epoch 1514/3334\n",
            "Epoch 1514: Training Accuracy = 0.9854, Training Loss = 0.1851, Validation Accuracy = 0.0489, Validation Loss = 4.5865\n",
            "Epoch 1515/3334\n",
            "Epoch 1515: Training Accuracy = 0.9854, Training Loss = 0.1851, Validation Accuracy = 0.0489, Validation Loss = 4.5865\n",
            "Epoch 1516/3334\n",
            "Epoch 1516: Training Accuracy = 0.9854, Training Loss = 0.1851, Validation Accuracy = 0.0489, Validation Loss = 4.5865\n",
            "Epoch 1517/3334\n",
            "Epoch 1517: Training Accuracy = 0.9832, Training Loss = 0.1641, Validation Accuracy = 0.0466, Validation Loss = 4.6064\n",
            "Epoch 1518/3334\n",
            "Epoch 1518: Training Accuracy = 0.9832, Training Loss = 0.1641, Validation Accuracy = 0.0466, Validation Loss = 4.6064\n",
            "Epoch 1519/3334\n",
            "Epoch 1519: Training Accuracy = 0.9832, Training Loss = 0.1641, Validation Accuracy = 0.0466, Validation Loss = 4.6064\n",
            "Epoch 1520/3334\n",
            "Epoch 1520: Training Accuracy = 0.9832, Training Loss = 0.1641, Validation Accuracy = 0.0466, Validation Loss = 4.6064\n",
            "Epoch 1521/3334\n",
            "Epoch 1521: Training Accuracy = 0.9883, Training Loss = 0.1176, Validation Accuracy = 0.0501, Validation Loss = 4.6312\n",
            "Epoch 1522/3334\n",
            "Epoch 1522: Training Accuracy = 0.9883, Training Loss = 0.1176, Validation Accuracy = 0.0501, Validation Loss = 4.6312\n",
            "Epoch 1523/3334\n",
            "Epoch 1523: Training Accuracy = 0.9883, Training Loss = 0.1176, Validation Accuracy = 0.0501, Validation Loss = 4.6312\n",
            "Epoch 1524/3334\n",
            "Epoch 1524: Training Accuracy = 0.9912, Training Loss = 0.1041, Validation Accuracy = 0.0524, Validation Loss = 4.6443\n",
            "Epoch 1525/3334\n",
            "Epoch 1525: Training Accuracy = 0.9912, Training Loss = 0.1041, Validation Accuracy = 0.0524, Validation Loss = 4.6443\n",
            "Epoch 1526/3334\n",
            "Epoch 1526: Training Accuracy = 0.9912, Training Loss = 0.1041, Validation Accuracy = 0.0524, Validation Loss = 4.6443\n",
            "Epoch 1527/3334\n",
            "Epoch 1527: Training Accuracy = 0.9910, Training Loss = 0.1017, Validation Accuracy = 0.0496, Validation Loss = 4.6469\n",
            "Epoch 1528/3334\n",
            "Epoch 1528: Training Accuracy = 0.9910, Training Loss = 0.1017, Validation Accuracy = 0.0496, Validation Loss = 4.6469\n",
            "Epoch 1529/3334\n",
            "Epoch 1529: Training Accuracy = 0.9910, Training Loss = 0.1017, Validation Accuracy = 0.0496, Validation Loss = 4.6469\n",
            "Epoch 1530/3334\n",
            "Epoch 1530: Training Accuracy = 0.9910, Training Loss = 0.1017, Validation Accuracy = 0.0496, Validation Loss = 4.6469\n",
            "Epoch 1531/3334\n",
            "Epoch 1531: Training Accuracy = 0.9893, Training Loss = 0.1040, Validation Accuracy = 0.0507, Validation Loss = 4.6465\n",
            "Epoch 1532/3334\n",
            "Epoch 1532: Training Accuracy = 0.9893, Training Loss = 0.1040, Validation Accuracy = 0.0507, Validation Loss = 4.6465\n",
            "Epoch 1533/3334\n",
            "Epoch 1533: Training Accuracy = 0.9893, Training Loss = 0.1040, Validation Accuracy = 0.0507, Validation Loss = 4.6465\n",
            "Epoch 1534/3334\n",
            "Epoch 1534: Training Accuracy = 0.9883, Training Loss = 0.1104, Validation Accuracy = 0.0495, Validation Loss = 4.6418\n",
            "Epoch 1535/3334\n",
            "Epoch 1535: Training Accuracy = 0.9883, Training Loss = 0.1104, Validation Accuracy = 0.0495, Validation Loss = 4.6418\n",
            "Epoch 1536/3334\n",
            "Epoch 1536: Training Accuracy = 0.9883, Training Loss = 0.1104, Validation Accuracy = 0.0495, Validation Loss = 4.6418\n",
            "Epoch 1537/3334\n",
            "Epoch 1537: Training Accuracy = 0.9858, Training Loss = 0.1224, Validation Accuracy = 0.0533, Validation Loss = 4.6470\n",
            "Epoch 1538/3334\n",
            "Epoch 1538: Training Accuracy = 0.9858, Training Loss = 0.1224, Validation Accuracy = 0.0533, Validation Loss = 4.6470\n",
            "Epoch 1539/3334\n",
            "Epoch 1539: Training Accuracy = 0.9858, Training Loss = 0.1224, Validation Accuracy = 0.0533, Validation Loss = 4.6470\n",
            "Epoch 1540/3334\n",
            "Epoch 1540: Training Accuracy = 0.9858, Training Loss = 0.1224, Validation Accuracy = 0.0533, Validation Loss = 4.6470\n",
            "Epoch 1541/3334\n",
            "Epoch 1541: Training Accuracy = 0.7207, Training Loss = 1.5413, Validation Accuracy = 0.0463, Validation Loss = 4.6068\n",
            "Epoch 1542/3334\n",
            "Epoch 1542: Training Accuracy = 0.7207, Training Loss = 1.5413, Validation Accuracy = 0.0463, Validation Loss = 4.6068\n",
            "Epoch 1543/3334\n",
            "Epoch 1543: Training Accuracy = 0.7207, Training Loss = 1.5413, Validation Accuracy = 0.0463, Validation Loss = 4.6068\n",
            "Epoch 1544/3334\n",
            "Epoch 1544: Training Accuracy = 0.9609, Training Loss = 0.5079, Validation Accuracy = 0.0556, Validation Loss = 4.2358\n",
            "Epoch 1545/3334\n",
            "Epoch 1545: Training Accuracy = 0.9609, Training Loss = 0.5079, Validation Accuracy = 0.0556, Validation Loss = 4.2358\n",
            "Epoch 1546/3334\n",
            "Epoch 1546: Training Accuracy = 0.9609, Training Loss = 0.5079, Validation Accuracy = 0.0556, Validation Loss = 4.2358\n",
            "Epoch 1547/3334\n",
            "Epoch 1547: Training Accuracy = 0.9884, Training Loss = 0.2737, Validation Accuracy = 0.0518, Validation Loss = 4.3519\n",
            "Epoch 1548/3334\n",
            "Epoch 1548: Training Accuracy = 0.9884, Training Loss = 0.2737, Validation Accuracy = 0.0518, Validation Loss = 4.3519\n",
            "Epoch 1549/3334\n",
            "Epoch 1549: Training Accuracy = 0.9884, Training Loss = 0.2737, Validation Accuracy = 0.0518, Validation Loss = 4.3519\n",
            "Epoch 1550/3334\n",
            "Epoch 1550: Training Accuracy = 0.9884, Training Loss = 0.2737, Validation Accuracy = 0.0518, Validation Loss = 4.3519\n",
            "Epoch 1551/3334\n",
            "Epoch 1551: Training Accuracy = 0.9902, Training Loss = 0.1604, Validation Accuracy = 0.0547, Validation Loss = 4.4118\n",
            "Epoch 1552/3334\n",
            "Epoch 1552: Training Accuracy = 0.9902, Training Loss = 0.1604, Validation Accuracy = 0.0547, Validation Loss = 4.4118\n",
            "Epoch 1553/3334\n",
            "Epoch 1553: Training Accuracy = 0.9902, Training Loss = 0.1604, Validation Accuracy = 0.0547, Validation Loss = 4.4118\n",
            "Epoch 1554/3334\n",
            "Epoch 1554: Training Accuracy = 0.9893, Training Loss = 0.1335, Validation Accuracy = 0.0571, Validation Loss = 4.4317\n",
            "Epoch 1555/3334\n",
            "Epoch 1555: Training Accuracy = 0.9893, Training Loss = 0.1335, Validation Accuracy = 0.0571, Validation Loss = 4.4317\n",
            "Epoch 1556/3334\n",
            "Epoch 1556: Training Accuracy = 0.9893, Training Loss = 0.1335, Validation Accuracy = 0.0571, Validation Loss = 4.4317\n",
            "Epoch 1557/3334\n",
            "Epoch 1557: Training Accuracy = 0.9884, Training Loss = 0.1172, Validation Accuracy = 0.0566, Validation Loss = 4.4538\n",
            "Epoch 1558/3334\n",
            "Epoch 1558: Training Accuracy = 0.9884, Training Loss = 0.1172, Validation Accuracy = 0.0566, Validation Loss = 4.4538\n",
            "Epoch 1559/3334\n",
            "Epoch 1559: Training Accuracy = 0.9884, Training Loss = 0.1172, Validation Accuracy = 0.0566, Validation Loss = 4.4538\n",
            "Epoch 1560/3334\n",
            "Epoch 1560: Training Accuracy = 0.9884, Training Loss = 0.1172, Validation Accuracy = 0.0566, Validation Loss = 4.4538\n",
            "Epoch 1561/3334\n",
            "Epoch 1561: Training Accuracy = 0.9912, Training Loss = 0.0986, Validation Accuracy = 0.0569, Validation Loss = 4.4566\n",
            "Epoch 1562/3334\n",
            "Epoch 1562: Training Accuracy = 0.9912, Training Loss = 0.0986, Validation Accuracy = 0.0569, Validation Loss = 4.4566\n",
            "Epoch 1563/3334\n",
            "Epoch 1563: Training Accuracy = 0.9912, Training Loss = 0.0986, Validation Accuracy = 0.0569, Validation Loss = 4.4566\n",
            "Epoch 1564/3334\n",
            "Epoch 1564: Training Accuracy = 0.9834, Training Loss = 0.1229, Validation Accuracy = 0.0574, Validation Loss = 4.4647\n",
            "Epoch 1565/3334\n",
            "Epoch 1565: Training Accuracy = 0.9834, Training Loss = 0.1229, Validation Accuracy = 0.0574, Validation Loss = 4.4647\n",
            "Epoch 1566/3334\n",
            "Epoch 1566: Training Accuracy = 0.9834, Training Loss = 0.1229, Validation Accuracy = 0.0574, Validation Loss = 4.4647\n",
            "Epoch 1567/3334\n",
            "Epoch 1567: Training Accuracy = 0.9793, Training Loss = 0.1405, Validation Accuracy = 0.0591, Validation Loss = 4.4534\n",
            "Epoch 1568/3334\n",
            "Epoch 1568: Training Accuracy = 0.9793, Training Loss = 0.1405, Validation Accuracy = 0.0591, Validation Loss = 4.4534\n",
            "Epoch 1569/3334\n",
            "Epoch 1569: Training Accuracy = 0.9793, Training Loss = 0.1405, Validation Accuracy = 0.0591, Validation Loss = 4.4534\n",
            "Epoch 1570/3334\n",
            "Epoch 1570: Training Accuracy = 0.9793, Training Loss = 0.1405, Validation Accuracy = 0.0591, Validation Loss = 4.4534\n",
            "Epoch 1571/3334\n",
            "Epoch 1571: Training Accuracy = 0.9854, Training Loss = 0.1156, Validation Accuracy = 0.0574, Validation Loss = 4.4659\n",
            "Epoch 1572/3334\n",
            "Epoch 1572: Training Accuracy = 0.9854, Training Loss = 0.1156, Validation Accuracy = 0.0574, Validation Loss = 4.4659\n",
            "Epoch 1573/3334\n",
            "Epoch 1573: Training Accuracy = 0.9854, Training Loss = 0.1156, Validation Accuracy = 0.0574, Validation Loss = 4.4659\n",
            "Epoch 1574/3334\n",
            "Epoch 1574: Training Accuracy = 0.9902, Training Loss = 0.0986, Validation Accuracy = 0.0581, Validation Loss = 4.4657\n",
            "Epoch 1575/3334\n",
            "Epoch 1575: Training Accuracy = 0.9902, Training Loss = 0.0986, Validation Accuracy = 0.0581, Validation Loss = 4.4657\n",
            "Epoch 1576/3334\n",
            "Epoch 1576: Training Accuracy = 0.9902, Training Loss = 0.0986, Validation Accuracy = 0.0581, Validation Loss = 4.4657\n",
            "Epoch 1577/3334\n",
            "Epoch 1577: Training Accuracy = 0.9897, Training Loss = 0.1608, Validation Accuracy = 0.0528, Validation Loss = 4.7617\n",
            "Epoch 1578/3334\n",
            "Epoch 1578: Training Accuracy = 0.9897, Training Loss = 0.1608, Validation Accuracy = 0.0528, Validation Loss = 4.7617\n",
            "Epoch 1579/3334\n",
            "Epoch 1579: Training Accuracy = 0.9897, Training Loss = 0.1608, Validation Accuracy = 0.0528, Validation Loss = 4.7617\n",
            "Epoch 1580/3334\n",
            "Epoch 1580: Training Accuracy = 0.9897, Training Loss = 0.1608, Validation Accuracy = 0.0528, Validation Loss = 4.7617\n",
            "Epoch 1581/3334\n",
            "Epoch 1581: Training Accuracy = 0.8730, Training Loss = 0.7725, Validation Accuracy = 0.0584, Validation Loss = 4.1980\n",
            "Epoch 1582/3334\n",
            "Epoch 1582: Training Accuracy = 0.8730, Training Loss = 0.7725, Validation Accuracy = 0.0584, Validation Loss = 4.1980\n",
            "Epoch 1583/3334\n",
            "Epoch 1583: Training Accuracy = 0.8730, Training Loss = 0.7725, Validation Accuracy = 0.0584, Validation Loss = 4.1980\n",
            "Epoch 1584/3334\n",
            "Epoch 1584: Training Accuracy = 0.9688, Training Loss = 0.4163, Validation Accuracy = 0.0633, Validation Loss = 4.0673\n",
            "Epoch 1585/3334\n",
            "Epoch 1585: Training Accuracy = 0.9688, Training Loss = 0.4163, Validation Accuracy = 0.0633, Validation Loss = 4.0673\n",
            "Epoch 1586/3334\n",
            "Epoch 1586: Training Accuracy = 0.9688, Training Loss = 0.4163, Validation Accuracy = 0.0633, Validation Loss = 4.0673\n",
            "Epoch 1587/3334\n",
            "Epoch 1587: Training Accuracy = 0.9884, Training Loss = 0.2316, Validation Accuracy = 0.0645, Validation Loss = 4.1552\n",
            "Epoch 1588/3334\n",
            "Epoch 1588: Training Accuracy = 0.9884, Training Loss = 0.2316, Validation Accuracy = 0.0645, Validation Loss = 4.1552\n",
            "Epoch 1589/3334\n",
            "Epoch 1589: Training Accuracy = 0.9884, Training Loss = 0.2316, Validation Accuracy = 0.0645, Validation Loss = 4.1552\n",
            "Epoch 1590/3334\n",
            "Epoch 1590: Training Accuracy = 0.9884, Training Loss = 0.2316, Validation Accuracy = 0.0645, Validation Loss = 4.1552\n",
            "Epoch 1591/3334\n",
            "Epoch 1591: Training Accuracy = 0.9893, Training Loss = 0.1541, Validation Accuracy = 0.0657, Validation Loss = 4.1802\n",
            "Epoch 1592/3334\n",
            "Epoch 1592: Training Accuracy = 0.9893, Training Loss = 0.1541, Validation Accuracy = 0.0657, Validation Loss = 4.1802\n",
            "Epoch 1593/3334\n",
            "Epoch 1593: Training Accuracy = 0.9893, Training Loss = 0.1541, Validation Accuracy = 0.0657, Validation Loss = 4.1802\n",
            "Epoch 1594/3334\n",
            "Epoch 1594: Training Accuracy = 0.9893, Training Loss = 0.1244, Validation Accuracy = 0.0668, Validation Loss = 4.2180\n",
            "Epoch 1595/3334\n",
            "Epoch 1595: Training Accuracy = 0.9893, Training Loss = 0.1244, Validation Accuracy = 0.0668, Validation Loss = 4.2180\n",
            "Epoch 1596/3334\n",
            "Epoch 1596: Training Accuracy = 0.9893, Training Loss = 0.1244, Validation Accuracy = 0.0668, Validation Loss = 4.2180\n",
            "Epoch 1597/3334\n",
            "Epoch 1597: Training Accuracy = 0.9884, Training Loss = 0.1162, Validation Accuracy = 0.0670, Validation Loss = 4.2410\n",
            "Epoch 1598/3334\n",
            "Epoch 1598: Training Accuracy = 0.9884, Training Loss = 0.1162, Validation Accuracy = 0.0670, Validation Loss = 4.2410\n",
            "Epoch 1599/3334\n",
            "Epoch 1599: Training Accuracy = 0.9884, Training Loss = 0.1162, Validation Accuracy = 0.0670, Validation Loss = 4.2410\n",
            "Epoch 1600/3334\n",
            "Epoch 1600: Training Accuracy = 0.9884, Training Loss = 0.1162, Validation Accuracy = 0.0670, Validation Loss = 4.2410\n",
            "Epoch 1601/3334\n",
            "Epoch 1601: Training Accuracy = 0.9902, Training Loss = 0.1020, Validation Accuracy = 0.0688, Validation Loss = 4.2398\n",
            "Epoch 1602/3334\n",
            "Epoch 1602: Training Accuracy = 0.9902, Training Loss = 0.1020, Validation Accuracy = 0.0688, Validation Loss = 4.2398\n",
            "Epoch 1603/3334\n",
            "Epoch 1603: Training Accuracy = 0.9902, Training Loss = 0.1020, Validation Accuracy = 0.0688, Validation Loss = 4.2398\n",
            "Epoch 1604/3334\n",
            "Epoch 1604: Training Accuracy = 0.9893, Training Loss = 0.1020, Validation Accuracy = 0.0686, Validation Loss = 4.2353\n",
            "Epoch 1605/3334\n",
            "Epoch 1605: Training Accuracy = 0.9893, Training Loss = 0.1020, Validation Accuracy = 0.0686, Validation Loss = 4.2353\n",
            "Epoch 1606/3334\n",
            "Epoch 1606: Training Accuracy = 0.9893, Training Loss = 0.1020, Validation Accuracy = 0.0686, Validation Loss = 4.2353\n",
            "Epoch 1607/3334\n",
            "Epoch 1607: Training Accuracy = 0.9871, Training Loss = 0.1121, Validation Accuracy = 0.0688, Validation Loss = 4.2346\n",
            "Epoch 1608/3334\n",
            "Epoch 1608: Training Accuracy = 0.9871, Training Loss = 0.1121, Validation Accuracy = 0.0688, Validation Loss = 4.2346\n",
            "Epoch 1609/3334\n",
            "Epoch 1609: Training Accuracy = 0.9871, Training Loss = 0.1121, Validation Accuracy = 0.0688, Validation Loss = 4.2346\n",
            "Epoch 1610/3334\n",
            "Epoch 1610: Training Accuracy = 0.9871, Training Loss = 0.1121, Validation Accuracy = 0.0688, Validation Loss = 4.2346\n",
            "Epoch 1611/3334\n",
            "Epoch 1611: Training Accuracy = 0.9893, Training Loss = 0.0990, Validation Accuracy = 0.0673, Validation Loss = 4.2323\n",
            "Epoch 1612/3334\n",
            "Epoch 1612: Training Accuracy = 0.9893, Training Loss = 0.0990, Validation Accuracy = 0.0673, Validation Loss = 4.2323\n",
            "Epoch 1613/3334\n",
            "Epoch 1613: Training Accuracy = 0.9893, Training Loss = 0.0990, Validation Accuracy = 0.0673, Validation Loss = 4.2323\n",
            "Epoch 1614/3334\n",
            "Epoch 1614: Training Accuracy = 0.9912, Training Loss = 0.0976, Validation Accuracy = 0.0697, Validation Loss = 4.2722\n",
            "Epoch 1615/3334\n",
            "Epoch 1615: Training Accuracy = 0.9912, Training Loss = 0.0976, Validation Accuracy = 0.0697, Validation Loss = 4.2722\n",
            "Epoch 1616/3334\n",
            "Epoch 1616: Training Accuracy = 0.9912, Training Loss = 0.0976, Validation Accuracy = 0.0697, Validation Loss = 4.2722\n",
            "Epoch 1617/3334\n",
            "Epoch 1617: Training Accuracy = 0.7481, Training Loss = 1.1346, Validation Accuracy = 0.0597, Validation Loss = 4.2160\n",
            "Epoch 1618/3334\n",
            "Epoch 1618: Training Accuracy = 0.7481, Training Loss = 1.1346, Validation Accuracy = 0.0597, Validation Loss = 4.2160\n",
            "Epoch 1619/3334\n",
            "Epoch 1619: Training Accuracy = 0.7481, Training Loss = 1.1346, Validation Accuracy = 0.0597, Validation Loss = 4.2160\n",
            "Epoch 1620/3334\n",
            "Epoch 1620: Training Accuracy = 0.7481, Training Loss = 1.1346, Validation Accuracy = 0.0597, Validation Loss = 4.2160\n",
            "Epoch 1621/3334\n",
            "Epoch 1621: Training Accuracy = 0.9775, Training Loss = 0.4403, Validation Accuracy = 0.0706, Validation Loss = 3.8260\n",
            "Epoch 1622/3334\n",
            "Epoch 1622: Training Accuracy = 0.9775, Training Loss = 0.4403, Validation Accuracy = 0.0706, Validation Loss = 3.8260\n",
            "Epoch 1623/3334\n",
            "Epoch 1623: Training Accuracy = 0.9775, Training Loss = 0.4403, Validation Accuracy = 0.0706, Validation Loss = 3.8260\n",
            "Epoch 1624/3334\n",
            "Epoch 1624: Training Accuracy = 0.9863, Training Loss = 0.2388, Validation Accuracy = 0.0700, Validation Loss = 4.0005\n",
            "Epoch 1625/3334\n",
            "Epoch 1625: Training Accuracy = 0.9863, Training Loss = 0.2388, Validation Accuracy = 0.0700, Validation Loss = 4.0005\n",
            "Epoch 1626/3334\n",
            "Epoch 1626: Training Accuracy = 0.9863, Training Loss = 0.2388, Validation Accuracy = 0.0700, Validation Loss = 4.0005\n",
            "Epoch 1627/3334\n",
            "Epoch 1627: Training Accuracy = 0.9871, Training Loss = 0.1784, Validation Accuracy = 0.0788, Validation Loss = 3.9882\n",
            "Epoch 1628/3334\n",
            "Epoch 1628: Training Accuracy = 0.9871, Training Loss = 0.1784, Validation Accuracy = 0.0788, Validation Loss = 3.9882\n",
            "Epoch 1629/3334\n",
            "Epoch 1629: Training Accuracy = 0.9871, Training Loss = 0.1784, Validation Accuracy = 0.0788, Validation Loss = 3.9882\n",
            "Epoch 1630/3334\n",
            "Epoch 1630: Training Accuracy = 0.9871, Training Loss = 0.1784, Validation Accuracy = 0.0788, Validation Loss = 3.9882\n",
            "Epoch 1631/3334\n",
            "Epoch 1631: Training Accuracy = 0.9863, Training Loss = 0.1389, Validation Accuracy = 0.0761, Validation Loss = 3.9876\n",
            "Epoch 1632/3334\n",
            "Epoch 1632: Training Accuracy = 0.9863, Training Loss = 0.1389, Validation Accuracy = 0.0761, Validation Loss = 3.9876\n",
            "Epoch 1633/3334\n",
            "Epoch 1633: Training Accuracy = 0.9863, Training Loss = 0.1389, Validation Accuracy = 0.0761, Validation Loss = 3.9876\n",
            "Epoch 1634/3334\n",
            "Epoch 1634: Training Accuracy = 0.9883, Training Loss = 0.1168, Validation Accuracy = 0.0802, Validation Loss = 4.0115\n",
            "Epoch 1635/3334\n",
            "Epoch 1635: Training Accuracy = 0.9883, Training Loss = 0.1168, Validation Accuracy = 0.0802, Validation Loss = 4.0115\n",
            "Epoch 1636/3334\n",
            "Epoch 1636: Training Accuracy = 0.9883, Training Loss = 0.1168, Validation Accuracy = 0.0802, Validation Loss = 4.0115\n",
            "Epoch 1637/3334\n",
            "Epoch 1637: Training Accuracy = 0.9897, Training Loss = 0.1056, Validation Accuracy = 0.0802, Validation Loss = 4.0077\n",
            "Epoch 1638/3334\n",
            "Epoch 1638: Training Accuracy = 0.9897, Training Loss = 0.1056, Validation Accuracy = 0.0802, Validation Loss = 4.0077\n",
            "Epoch 1639/3334\n",
            "Epoch 1639: Training Accuracy = 0.9897, Training Loss = 0.1056, Validation Accuracy = 0.0802, Validation Loss = 4.0077\n",
            "Epoch 1640/3334\n",
            "Epoch 1640: Training Accuracy = 0.9897, Training Loss = 0.1056, Validation Accuracy = 0.0802, Validation Loss = 4.0077\n",
            "Epoch 1641/3334\n",
            "Epoch 1641: Training Accuracy = 0.9893, Training Loss = 0.0996, Validation Accuracy = 0.0788, Validation Loss = 4.0128\n",
            "Epoch 1642/3334\n",
            "Epoch 1642: Training Accuracy = 0.9893, Training Loss = 0.0996, Validation Accuracy = 0.0788, Validation Loss = 4.0128\n",
            "Epoch 1643/3334\n",
            "Epoch 1643: Training Accuracy = 0.9893, Training Loss = 0.0996, Validation Accuracy = 0.0788, Validation Loss = 4.0128\n",
            "Epoch 1644/3334\n",
            "Epoch 1644: Training Accuracy = 0.9883, Training Loss = 0.1049, Validation Accuracy = 0.0800, Validation Loss = 4.0122\n",
            "Epoch 1645/3334\n",
            "Epoch 1645: Training Accuracy = 0.9883, Training Loss = 0.1049, Validation Accuracy = 0.0800, Validation Loss = 4.0122\n",
            "Epoch 1646/3334\n",
            "Epoch 1646: Training Accuracy = 0.9883, Training Loss = 0.1049, Validation Accuracy = 0.0800, Validation Loss = 4.0122\n",
            "Epoch 1647/3334\n",
            "Epoch 1647: Training Accuracy = 0.9871, Training Loss = 0.1107, Validation Accuracy = 0.0794, Validation Loss = 4.0197\n",
            "Epoch 1648/3334\n",
            "Epoch 1648: Training Accuracy = 0.9871, Training Loss = 0.1107, Validation Accuracy = 0.0794, Validation Loss = 4.0197\n",
            "Epoch 1649/3334\n",
            "Epoch 1649: Training Accuracy = 0.9871, Training Loss = 0.1107, Validation Accuracy = 0.0794, Validation Loss = 4.0197\n",
            "Epoch 1650/3334\n",
            "Epoch 1650: Training Accuracy = 0.9871, Training Loss = 0.1107, Validation Accuracy = 0.0794, Validation Loss = 4.0197\n",
            "Epoch 1651/3334\n",
            "Epoch 1651: Training Accuracy = 0.9893, Training Loss = 0.1001, Validation Accuracy = 0.0783, Validation Loss = 4.0056\n",
            "Epoch 1652/3334\n",
            "Epoch 1652: Training Accuracy = 0.9893, Training Loss = 0.1001, Validation Accuracy = 0.0783, Validation Loss = 4.0056\n",
            "Epoch 1653/3334\n",
            "Epoch 1653: Training Accuracy = 0.9893, Training Loss = 0.1001, Validation Accuracy = 0.0783, Validation Loss = 4.0056\n",
            "Epoch 1654/3334\n",
            "Epoch 1654: Training Accuracy = 0.9912, Training Loss = 0.0911, Validation Accuracy = 0.0826, Validation Loss = 4.0046\n",
            "Epoch 1655/3334\n",
            "Epoch 1655: Training Accuracy = 0.9912, Training Loss = 0.0911, Validation Accuracy = 0.0826, Validation Loss = 4.0046\n",
            "Epoch 1656/3334\n",
            "Epoch 1656: Training Accuracy = 0.9912, Training Loss = 0.0911, Validation Accuracy = 0.0826, Validation Loss = 4.0046\n",
            "Epoch 1657/3334\n",
            "Epoch 1657: Training Accuracy = 0.4587, Training Loss = 2.4690, Validation Accuracy = 0.0515, Validation Loss = 4.3506\n",
            "Epoch 1658/3334\n",
            "Epoch 1658: Training Accuracy = 0.4587, Training Loss = 2.4690, Validation Accuracy = 0.0515, Validation Loss = 4.3506\n",
            "Epoch 1659/3334\n",
            "Epoch 1659: Training Accuracy = 0.4587, Training Loss = 2.4690, Validation Accuracy = 0.0515, Validation Loss = 4.3506\n",
            "Epoch 1660/3334\n",
            "Epoch 1660: Training Accuracy = 0.4587, Training Loss = 2.4690, Validation Accuracy = 0.0515, Validation Loss = 4.3506\n",
            "Epoch 1661/3334\n",
            "Epoch 1661: Training Accuracy = 0.9434, Training Loss = 0.5854, Validation Accuracy = 0.0990, Validation Loss = 3.6722\n",
            "Epoch 1662/3334\n",
            "Epoch 1662: Training Accuracy = 0.9434, Training Loss = 0.5854, Validation Accuracy = 0.0990, Validation Loss = 3.6722\n",
            "Epoch 1663/3334\n",
            "Epoch 1663: Training Accuracy = 0.9434, Training Loss = 0.5854, Validation Accuracy = 0.0990, Validation Loss = 3.6722\n",
            "Epoch 1664/3334\n",
            "Epoch 1664: Training Accuracy = 0.9873, Training Loss = 0.2794, Validation Accuracy = 0.0990, Validation Loss = 3.6623\n",
            "Epoch 1665/3334\n",
            "Epoch 1665: Training Accuracy = 0.9873, Training Loss = 0.2794, Validation Accuracy = 0.0990, Validation Loss = 3.6623\n",
            "Epoch 1666/3334\n",
            "Epoch 1666: Training Accuracy = 0.9873, Training Loss = 0.2794, Validation Accuracy = 0.0990, Validation Loss = 3.6623\n",
            "Epoch 1667/3334\n",
            "Epoch 1667: Training Accuracy = 0.9845, Training Loss = 0.2045, Validation Accuracy = 0.1016, Validation Loss = 3.6307\n",
            "Epoch 1668/3334\n",
            "Epoch 1668: Training Accuracy = 0.9845, Training Loss = 0.2045, Validation Accuracy = 0.1016, Validation Loss = 3.6307\n",
            "Epoch 1669/3334\n",
            "Epoch 1669: Training Accuracy = 0.9845, Training Loss = 0.2045, Validation Accuracy = 0.1016, Validation Loss = 3.6307\n",
            "Epoch 1670/3334\n",
            "Epoch 1670: Training Accuracy = 0.9845, Training Loss = 0.2045, Validation Accuracy = 0.1016, Validation Loss = 3.6307\n",
            "Epoch 1671/3334\n",
            "Epoch 1671: Training Accuracy = 0.9932, Training Loss = 0.1199, Validation Accuracy = 0.1049, Validation Loss = 3.6701\n",
            "Epoch 1672/3334\n",
            "Epoch 1672: Training Accuracy = 0.9932, Training Loss = 0.1199, Validation Accuracy = 0.1049, Validation Loss = 3.6701\n",
            "Epoch 1673/3334\n",
            "Epoch 1673: Training Accuracy = 0.9932, Training Loss = 0.1199, Validation Accuracy = 0.1049, Validation Loss = 3.6701\n",
            "Epoch 1674/3334\n",
            "Epoch 1674: Training Accuracy = 0.9893, Training Loss = 0.1152, Validation Accuracy = 0.1049, Validation Loss = 3.6699\n",
            "Epoch 1675/3334\n",
            "Epoch 1675: Training Accuracy = 0.9893, Training Loss = 0.1152, Validation Accuracy = 0.1049, Validation Loss = 3.6699\n",
            "Epoch 1676/3334\n",
            "Epoch 1676: Training Accuracy = 0.9893, Training Loss = 0.1152, Validation Accuracy = 0.1049, Validation Loss = 3.6699\n",
            "Epoch 1677/3334\n",
            "Epoch 1677: Training Accuracy = 0.9897, Training Loss = 0.1067, Validation Accuracy = 0.1078, Validation Loss = 3.6715\n",
            "Epoch 1678/3334\n",
            "Epoch 1678: Training Accuracy = 0.9897, Training Loss = 0.1067, Validation Accuracy = 0.1078, Validation Loss = 3.6715\n",
            "Epoch 1679/3334\n",
            "Epoch 1679: Training Accuracy = 0.9897, Training Loss = 0.1067, Validation Accuracy = 0.1078, Validation Loss = 3.6715\n",
            "Epoch 1680/3334\n",
            "Epoch 1680: Training Accuracy = 0.9897, Training Loss = 0.1067, Validation Accuracy = 0.1078, Validation Loss = 3.6715\n",
            "Epoch 1681/3334\n",
            "Epoch 1681: Training Accuracy = 0.9932, Training Loss = 0.0883, Validation Accuracy = 0.1078, Validation Loss = 3.6742\n",
            "Epoch 1682/3334\n",
            "Epoch 1682: Training Accuracy = 0.9932, Training Loss = 0.0883, Validation Accuracy = 0.1078, Validation Loss = 3.6742\n",
            "Epoch 1683/3334\n",
            "Epoch 1683: Training Accuracy = 0.9932, Training Loss = 0.0883, Validation Accuracy = 0.1078, Validation Loss = 3.6742\n",
            "Epoch 1684/3334\n",
            "Epoch 1684: Training Accuracy = 0.9893, Training Loss = 0.0982, Validation Accuracy = 0.1067, Validation Loss = 3.6740\n",
            "Epoch 1685/3334\n",
            "Epoch 1685: Training Accuracy = 0.9893, Training Loss = 0.0982, Validation Accuracy = 0.1067, Validation Loss = 3.6740\n",
            "Epoch 1686/3334\n",
            "Epoch 1686: Training Accuracy = 0.9893, Training Loss = 0.0982, Validation Accuracy = 0.1067, Validation Loss = 3.6740\n",
            "Epoch 1687/3334\n",
            "Epoch 1687: Training Accuracy = 0.9884, Training Loss = 0.1026, Validation Accuracy = 0.1076, Validation Loss = 3.6729\n",
            "Epoch 1688/3334\n",
            "Epoch 1688: Training Accuracy = 0.9884, Training Loss = 0.1026, Validation Accuracy = 0.1076, Validation Loss = 3.6729\n",
            "Epoch 1689/3334\n",
            "Epoch 1689: Training Accuracy = 0.9884, Training Loss = 0.1026, Validation Accuracy = 0.1076, Validation Loss = 3.6729\n",
            "Epoch 1690/3334\n",
            "Epoch 1690: Training Accuracy = 0.9884, Training Loss = 0.1026, Validation Accuracy = 0.1076, Validation Loss = 3.6729\n",
            "Epoch 1691/3334\n",
            "Epoch 1691: Training Accuracy = 0.9893, Training Loss = 0.0945, Validation Accuracy = 0.1075, Validation Loss = 3.6981\n",
            "Epoch 1692/3334\n",
            "Epoch 1692: Training Accuracy = 0.9893, Training Loss = 0.0945, Validation Accuracy = 0.1075, Validation Loss = 3.6981\n",
            "Epoch 1693/3334\n",
            "Epoch 1693: Training Accuracy = 0.9893, Training Loss = 0.0945, Validation Accuracy = 0.1075, Validation Loss = 3.6981\n",
            "Epoch 1694/3334\n",
            "Epoch 1694: Training Accuracy = 0.9883, Training Loss = 0.1014, Validation Accuracy = 0.1111, Validation Loss = 3.6728\n",
            "Epoch 1695/3334\n",
            "Epoch 1695: Training Accuracy = 0.9883, Training Loss = 0.1014, Validation Accuracy = 0.1111, Validation Loss = 3.6728\n",
            "Epoch 1696/3334\n",
            "Epoch 1696: Training Accuracy = 0.9883, Training Loss = 0.1014, Validation Accuracy = 0.1111, Validation Loss = 3.6728\n",
            "Epoch 1697/3334\n",
            "Epoch 1697: Training Accuracy = 0.9884, Training Loss = 0.1259, Validation Accuracy = 0.1101, Validation Loss = 3.6864\n",
            "Epoch 1698/3334\n",
            "Epoch 1698: Training Accuracy = 0.9884, Training Loss = 0.1259, Validation Accuracy = 0.1101, Validation Loss = 3.6864\n",
            "Epoch 1699/3334\n",
            "Epoch 1699: Training Accuracy = 0.9884, Training Loss = 0.1259, Validation Accuracy = 0.1101, Validation Loss = 3.6864\n",
            "Epoch 1700/3334\n",
            "Epoch 1700: Training Accuracy = 0.9884, Training Loss = 0.1259, Validation Accuracy = 0.1101, Validation Loss = 3.6864\n",
            "Epoch 1701/3334\n",
            "Epoch 1701: Training Accuracy = 0.8018, Training Loss = 1.1199, Validation Accuracy = 0.0906, Validation Loss = 3.7453\n",
            "Epoch 1702/3334\n",
            "Epoch 1702: Training Accuracy = 0.8018, Training Loss = 1.1199, Validation Accuracy = 0.0906, Validation Loss = 3.7453\n",
            "Epoch 1703/3334\n",
            "Epoch 1703: Training Accuracy = 0.8018, Training Loss = 1.1199, Validation Accuracy = 0.0906, Validation Loss = 3.7453\n",
            "Epoch 1704/3334\n",
            "Epoch 1704: Training Accuracy = 0.9688, Training Loss = 0.4314, Validation Accuracy = 0.1322, Validation Loss = 3.3120\n",
            "Epoch 1705/3334\n",
            "Epoch 1705: Training Accuracy = 0.9688, Training Loss = 0.4314, Validation Accuracy = 0.1322, Validation Loss = 3.3120\n",
            "Epoch 1706/3334\n",
            "Epoch 1706: Training Accuracy = 0.9688, Training Loss = 0.4314, Validation Accuracy = 0.1322, Validation Loss = 3.3120\n",
            "Epoch 1707/3334\n",
            "Epoch 1707: Training Accuracy = 0.9922, Training Loss = 0.2295, Validation Accuracy = 0.1292, Validation Loss = 3.3881\n",
            "Epoch 1708/3334\n",
            "Epoch 1708: Training Accuracy = 0.9922, Training Loss = 0.2295, Validation Accuracy = 0.1292, Validation Loss = 3.3881\n",
            "Epoch 1709/3334\n",
            "Epoch 1709: Training Accuracy = 0.9922, Training Loss = 0.2295, Validation Accuracy = 0.1292, Validation Loss = 3.3881\n",
            "Epoch 1710/3334\n",
            "Epoch 1710: Training Accuracy = 0.9922, Training Loss = 0.2295, Validation Accuracy = 0.1292, Validation Loss = 3.3881\n",
            "Epoch 1711/3334\n",
            "Epoch 1711: Training Accuracy = 0.9893, Training Loss = 0.1504, Validation Accuracy = 0.1357, Validation Loss = 3.3346\n",
            "Epoch 1712/3334\n",
            "Epoch 1712: Training Accuracy = 0.9893, Training Loss = 0.1504, Validation Accuracy = 0.1357, Validation Loss = 3.3346\n",
            "Epoch 1713/3334\n",
            "Epoch 1713: Training Accuracy = 0.9893, Training Loss = 0.1504, Validation Accuracy = 0.1357, Validation Loss = 3.3346\n",
            "Epoch 1714/3334\n",
            "Epoch 1714: Training Accuracy = 0.9883, Training Loss = 0.1276, Validation Accuracy = 0.1366, Validation Loss = 3.3459\n",
            "Epoch 1715/3334\n",
            "Epoch 1715: Training Accuracy = 0.9883, Training Loss = 0.1276, Validation Accuracy = 0.1366, Validation Loss = 3.3459\n",
            "Epoch 1716/3334\n",
            "Epoch 1716: Training Accuracy = 0.9883, Training Loss = 0.1276, Validation Accuracy = 0.1366, Validation Loss = 3.3459\n",
            "Epoch 1717/3334\n",
            "Epoch 1717: Training Accuracy = 0.9910, Training Loss = 0.1026, Validation Accuracy = 0.1406, Validation Loss = 3.3289\n",
            "Epoch 1718/3334\n",
            "Epoch 1718: Training Accuracy = 0.9910, Training Loss = 0.1026, Validation Accuracy = 0.1406, Validation Loss = 3.3289\n",
            "Epoch 1719/3334\n",
            "Epoch 1719: Training Accuracy = 0.9910, Training Loss = 0.1026, Validation Accuracy = 0.1406, Validation Loss = 3.3289\n",
            "Epoch 1720/3334\n",
            "Epoch 1720: Training Accuracy = 0.9910, Training Loss = 0.1026, Validation Accuracy = 0.1406, Validation Loss = 3.3289\n",
            "Epoch 1721/3334\n",
            "Epoch 1721: Training Accuracy = 0.9912, Training Loss = 0.0914, Validation Accuracy = 0.1392, Validation Loss = 3.3326\n",
            "Epoch 1722/3334\n",
            "Epoch 1722: Training Accuracy = 0.9912, Training Loss = 0.0914, Validation Accuracy = 0.1392, Validation Loss = 3.3326\n",
            "Epoch 1723/3334\n",
            "Epoch 1723: Training Accuracy = 0.9912, Training Loss = 0.0914, Validation Accuracy = 0.1392, Validation Loss = 3.3326\n",
            "Epoch 1724/3334\n",
            "Epoch 1724: Training Accuracy = 0.9883, Training Loss = 0.1027, Validation Accuracy = 0.1413, Validation Loss = 3.3329\n",
            "Epoch 1725/3334\n",
            "Epoch 1725: Training Accuracy = 0.9883, Training Loss = 0.1027, Validation Accuracy = 0.1413, Validation Loss = 3.3329\n",
            "Epoch 1726/3334\n",
            "Epoch 1726: Training Accuracy = 0.9883, Training Loss = 0.1027, Validation Accuracy = 0.1413, Validation Loss = 3.3329\n",
            "Epoch 1727/3334\n",
            "Epoch 1727: Training Accuracy = 0.9845, Training Loss = 0.1124, Validation Accuracy = 0.1430, Validation Loss = 3.3198\n",
            "Epoch 1728/3334\n",
            "Epoch 1728: Training Accuracy = 0.9845, Training Loss = 0.1124, Validation Accuracy = 0.1430, Validation Loss = 3.3198\n",
            "Epoch 1729/3334\n",
            "Epoch 1729: Training Accuracy = 0.9845, Training Loss = 0.1124, Validation Accuracy = 0.1430, Validation Loss = 3.3198\n",
            "Epoch 1730/3334\n",
            "Epoch 1730: Training Accuracy = 0.9845, Training Loss = 0.1124, Validation Accuracy = 0.1430, Validation Loss = 3.3198\n",
            "Epoch 1731/3334\n",
            "Epoch 1731: Training Accuracy = 0.9893, Training Loss = 0.0954, Validation Accuracy = 0.1453, Validation Loss = 3.3198\n",
            "Epoch 1732/3334\n",
            "Epoch 1732: Training Accuracy = 0.9893, Training Loss = 0.0954, Validation Accuracy = 0.1453, Validation Loss = 3.3198\n",
            "Epoch 1733/3334\n",
            "Epoch 1733: Training Accuracy = 0.9893, Training Loss = 0.0954, Validation Accuracy = 0.1453, Validation Loss = 3.3198\n",
            "Epoch 1734/3334\n",
            "Epoch 1734: Training Accuracy = 0.9893, Training Loss = 0.0981, Validation Accuracy = 0.1488, Validation Loss = 3.3229\n",
            "Epoch 1735/3334\n",
            "Epoch 1735: Training Accuracy = 0.9893, Training Loss = 0.0981, Validation Accuracy = 0.1488, Validation Loss = 3.3229\n",
            "Epoch 1736/3334\n",
            "Epoch 1736: Training Accuracy = 0.9893, Training Loss = 0.0981, Validation Accuracy = 0.1488, Validation Loss = 3.3229\n",
            "Epoch 1737/3334\n",
            "Epoch 1737: Training Accuracy = 0.9897, Training Loss = 0.1066, Validation Accuracy = 0.1444, Validation Loss = 3.3446\n",
            "Epoch 1738/3334\n",
            "Epoch 1738: Training Accuracy = 0.9897, Training Loss = 0.1066, Validation Accuracy = 0.1444, Validation Loss = 3.3446\n",
            "Epoch 1739/3334\n",
            "Epoch 1739: Training Accuracy = 0.9897, Training Loss = 0.1066, Validation Accuracy = 0.1444, Validation Loss = 3.3446\n",
            "Epoch 1740/3334\n",
            "Epoch 1740: Training Accuracy = 0.9897, Training Loss = 0.1066, Validation Accuracy = 0.1444, Validation Loss = 3.3446\n",
            "Epoch 1741/3334\n",
            "Epoch 1741: Training Accuracy = 0.9814, Training Loss = 0.1316, Validation Accuracy = 0.1488, Validation Loss = 3.3393\n",
            "Epoch 1742/3334\n",
            "Epoch 1742: Training Accuracy = 0.9814, Training Loss = 0.1316, Validation Accuracy = 0.1488, Validation Loss = 3.3393\n",
            "Epoch 1743/3334\n",
            "Epoch 1743: Training Accuracy = 0.9814, Training Loss = 0.1316, Validation Accuracy = 0.1488, Validation Loss = 3.3393\n",
            "Epoch 1744/3334\n",
            "Epoch 1744: Training Accuracy = 0.9883, Training Loss = 0.1067, Validation Accuracy = 0.1603, Validation Loss = 3.2861\n",
            "Epoch 1745/3334\n",
            "Epoch 1745: Training Accuracy = 0.9883, Training Loss = 0.1067, Validation Accuracy = 0.1603, Validation Loss = 3.2861\n",
            "Epoch 1746/3334\n",
            "Epoch 1746: Training Accuracy = 0.9883, Training Loss = 0.1067, Validation Accuracy = 0.1603, Validation Loss = 3.2861\n",
            "Epoch 1747/3334\n",
            "Epoch 1747: Training Accuracy = 0.3773, Training Loss = 2.2051, Validation Accuracy = 0.0698, Validation Loss = 4.3076\n",
            "Epoch 1748/3334\n",
            "Epoch 1748: Training Accuracy = 0.3773, Training Loss = 2.2051, Validation Accuracy = 0.0698, Validation Loss = 4.3076\n",
            "Epoch 1749/3334\n",
            "Epoch 1749: Training Accuracy = 0.3773, Training Loss = 2.2051, Validation Accuracy = 0.0698, Validation Loss = 4.3076\n",
            "Epoch 1750/3334\n",
            "Epoch 1750: Training Accuracy = 0.3773, Training Loss = 2.2051, Validation Accuracy = 0.0698, Validation Loss = 4.3076\n",
            "Epoch 1751/3334\n",
            "Epoch 1751: Training Accuracy = 0.8945, Training Loss = 0.7324, Validation Accuracy = 0.1394, Validation Loss = 3.2965\n",
            "Epoch 1752/3334\n",
            "Epoch 1752: Training Accuracy = 0.8945, Training Loss = 0.7324, Validation Accuracy = 0.1394, Validation Loss = 3.2965\n",
            "Epoch 1753/3334\n",
            "Epoch 1753: Training Accuracy = 0.8945, Training Loss = 0.7324, Validation Accuracy = 0.1394, Validation Loss = 3.2965\n",
            "Epoch 1754/3334\n",
            "Epoch 1754: Training Accuracy = 0.9785, Training Loss = 0.3309, Validation Accuracy = 0.1770, Validation Loss = 3.0694\n",
            "Epoch 1755/3334\n",
            "Epoch 1755: Training Accuracy = 0.9785, Training Loss = 0.3309, Validation Accuracy = 0.1770, Validation Loss = 3.0694\n",
            "Epoch 1756/3334\n",
            "Epoch 1756: Training Accuracy = 0.9785, Training Loss = 0.3309, Validation Accuracy = 0.1770, Validation Loss = 3.0694\n",
            "Epoch 1757/3334\n",
            "Epoch 1757: Training Accuracy = 0.9897, Training Loss = 0.1843, Validation Accuracy = 0.1923, Validation Loss = 2.9644\n",
            "Epoch 1758/3334\n",
            "Epoch 1758: Training Accuracy = 0.9897, Training Loss = 0.1843, Validation Accuracy = 0.1923, Validation Loss = 2.9644\n",
            "Epoch 1759/3334\n",
            "Epoch 1759: Training Accuracy = 0.9897, Training Loss = 0.1843, Validation Accuracy = 0.1923, Validation Loss = 2.9644\n",
            "Epoch 1760/3334\n",
            "Epoch 1760: Training Accuracy = 0.9897, Training Loss = 0.1843, Validation Accuracy = 0.1923, Validation Loss = 2.9644\n",
            "Epoch 1761/3334\n",
            "Epoch 1761: Training Accuracy = 0.9932, Training Loss = 0.1159, Validation Accuracy = 0.2019, Validation Loss = 2.8797\n",
            "Epoch 1762/3334\n",
            "Epoch 1762: Training Accuracy = 0.9932, Training Loss = 0.1159, Validation Accuracy = 0.2019, Validation Loss = 2.8797\n",
            "Epoch 1763/3334\n",
            "Epoch 1763: Training Accuracy = 0.9932, Training Loss = 0.1159, Validation Accuracy = 0.2019, Validation Loss = 2.8797\n",
            "Epoch 1764/3334\n",
            "Epoch 1764: Training Accuracy = 0.9834, Training Loss = 0.1299, Validation Accuracy = 0.2054, Validation Loss = 2.8733\n",
            "Epoch 1765/3334\n",
            "Epoch 1765: Training Accuracy = 0.9834, Training Loss = 0.1299, Validation Accuracy = 0.2054, Validation Loss = 2.8733\n",
            "Epoch 1766/3334\n",
            "Epoch 1766: Training Accuracy = 0.9834, Training Loss = 0.1299, Validation Accuracy = 0.2054, Validation Loss = 2.8733\n",
            "Epoch 1767/3334\n",
            "Epoch 1767: Training Accuracy = 0.9832, Training Loss = 0.1263, Validation Accuracy = 0.2072, Validation Loss = 2.8706\n",
            "Epoch 1768/3334\n",
            "Epoch 1768: Training Accuracy = 0.9832, Training Loss = 0.1263, Validation Accuracy = 0.2072, Validation Loss = 2.8706\n",
            "Epoch 1769/3334\n",
            "Epoch 1769: Training Accuracy = 0.9832, Training Loss = 0.1263, Validation Accuracy = 0.2072, Validation Loss = 2.8706\n",
            "Epoch 1770/3334\n",
            "Epoch 1770: Training Accuracy = 0.9832, Training Loss = 0.1263, Validation Accuracy = 0.2072, Validation Loss = 2.8706\n",
            "Epoch 1771/3334\n",
            "Epoch 1771: Training Accuracy = 0.9912, Training Loss = 0.0885, Validation Accuracy = 0.2069, Validation Loss = 2.8718\n",
            "Epoch 1772/3334\n",
            "Epoch 1772: Training Accuracy = 0.9912, Training Loss = 0.0885, Validation Accuracy = 0.2069, Validation Loss = 2.8718\n",
            "Epoch 1773/3334\n",
            "Epoch 1773: Training Accuracy = 0.9912, Training Loss = 0.0885, Validation Accuracy = 0.2069, Validation Loss = 2.8718\n",
            "Epoch 1774/3334\n",
            "Epoch 1774: Training Accuracy = 0.9932, Training Loss = 0.0799, Validation Accuracy = 0.2084, Validation Loss = 2.8696\n",
            "Epoch 1775/3334\n",
            "Epoch 1775: Training Accuracy = 0.9932, Training Loss = 0.0799, Validation Accuracy = 0.2084, Validation Loss = 2.8696\n",
            "Epoch 1776/3334\n",
            "Epoch 1776: Training Accuracy = 0.9932, Training Loss = 0.0799, Validation Accuracy = 0.2084, Validation Loss = 2.8696\n",
            "Epoch 1777/3334\n",
            "Epoch 1777: Training Accuracy = 0.9832, Training Loss = 0.1166, Validation Accuracy = 0.2113, Validation Loss = 2.8594\n",
            "Epoch 1778/3334\n",
            "Epoch 1778: Training Accuracy = 0.9832, Training Loss = 0.1166, Validation Accuracy = 0.2113, Validation Loss = 2.8594\n",
            "Epoch 1779/3334\n",
            "Epoch 1779: Training Accuracy = 0.9832, Training Loss = 0.1166, Validation Accuracy = 0.2113, Validation Loss = 2.8594\n",
            "Epoch 1780/3334\n",
            "Epoch 1780: Training Accuracy = 0.9832, Training Loss = 0.1166, Validation Accuracy = 0.2113, Validation Loss = 2.8594\n",
            "Epoch 1781/3334\n",
            "Epoch 1781: Training Accuracy = 0.9883, Training Loss = 0.0965, Validation Accuracy = 0.2077, Validation Loss = 2.8704\n",
            "Epoch 1782/3334\n",
            "Epoch 1782: Training Accuracy = 0.9883, Training Loss = 0.0965, Validation Accuracy = 0.2077, Validation Loss = 2.8704\n",
            "Epoch 1783/3334\n",
            "Epoch 1783: Training Accuracy = 0.9883, Training Loss = 0.0965, Validation Accuracy = 0.2077, Validation Loss = 2.8704\n",
            "Epoch 1784/3334\n",
            "Epoch 1784: Training Accuracy = 0.9902, Training Loss = 0.0912, Validation Accuracy = 0.2095, Validation Loss = 2.8809\n",
            "Epoch 1785/3334\n",
            "Epoch 1785: Training Accuracy = 0.9902, Training Loss = 0.0912, Validation Accuracy = 0.2095, Validation Loss = 2.8809\n",
            "Epoch 1786/3334\n",
            "Epoch 1786: Training Accuracy = 0.9902, Training Loss = 0.0912, Validation Accuracy = 0.2095, Validation Loss = 2.8809\n",
            "Epoch 1787/3334\n",
            "Epoch 1787: Training Accuracy = 0.9845, Training Loss = 0.1237, Validation Accuracy = 0.2130, Validation Loss = 2.8825\n",
            "Epoch 1788/3334\n",
            "Epoch 1788: Training Accuracy = 0.9845, Training Loss = 0.1237, Validation Accuracy = 0.2130, Validation Loss = 2.8825\n",
            "Epoch 1789/3334\n",
            "Epoch 1789: Training Accuracy = 0.9845, Training Loss = 0.1237, Validation Accuracy = 0.2130, Validation Loss = 2.8825\n",
            "Epoch 1790/3334\n",
            "Epoch 1790: Training Accuracy = 0.9845, Training Loss = 0.1237, Validation Accuracy = 0.2130, Validation Loss = 2.8825\n",
            "Epoch 1791/3334\n",
            "Epoch 1791: Training Accuracy = 0.4658, Training Loss = 2.1936, Validation Accuracy = 0.0841, Validation Loss = 4.3912\n",
            "Epoch 1792/3334\n",
            "Epoch 1792: Training Accuracy = 0.4658, Training Loss = 2.1936, Validation Accuracy = 0.0841, Validation Loss = 4.3912\n",
            "Epoch 1793/3334\n",
            "Epoch 1793: Training Accuracy = 0.4658, Training Loss = 2.1936, Validation Accuracy = 0.0841, Validation Loss = 4.3912\n",
            "Epoch 1794/3334\n",
            "Epoch 1794: Training Accuracy = 0.9424, Training Loss = 0.5357, Validation Accuracy = 0.1843, Validation Loss = 2.9424\n",
            "Epoch 1795/3334\n",
            "Epoch 1795: Training Accuracy = 0.9424, Training Loss = 0.5357, Validation Accuracy = 0.1843, Validation Loss = 2.9424\n",
            "Epoch 1796/3334\n",
            "Epoch 1796: Training Accuracy = 0.9424, Training Loss = 0.5357, Validation Accuracy = 0.1843, Validation Loss = 2.9424\n",
            "Epoch 1797/3334\n",
            "Epoch 1797: Training Accuracy = 0.9819, Training Loss = 0.3101, Validation Accuracy = 0.2397, Validation Loss = 2.6604\n",
            "Epoch 1798/3334\n",
            "Epoch 1798: Training Accuracy = 0.9819, Training Loss = 0.3101, Validation Accuracy = 0.2397, Validation Loss = 2.6604\n",
            "Epoch 1799/3334\n",
            "Epoch 1799: Training Accuracy = 0.9819, Training Loss = 0.3101, Validation Accuracy = 0.2397, Validation Loss = 2.6604\n",
            "Epoch 1800/3334\n",
            "Epoch 1800: Training Accuracy = 0.9819, Training Loss = 0.3101, Validation Accuracy = 0.2397, Validation Loss = 2.6604\n",
            "Epoch 1801/3334\n",
            "Epoch 1801: Training Accuracy = 0.9902, Training Loss = 0.1642, Validation Accuracy = 0.2520, Validation Loss = 2.5885\n",
            "Epoch 1802/3334\n",
            "Epoch 1802: Training Accuracy = 0.9902, Training Loss = 0.1642, Validation Accuracy = 0.2520, Validation Loss = 2.5885\n",
            "Epoch 1803/3334\n",
            "Epoch 1803: Training Accuracy = 0.9902, Training Loss = 0.1642, Validation Accuracy = 0.2520, Validation Loss = 2.5885\n",
            "Epoch 1804/3334\n",
            "Epoch 1804: Training Accuracy = 0.9863, Training Loss = 0.1415, Validation Accuracy = 0.2602, Validation Loss = 2.5221\n",
            "Epoch 1805/3334\n",
            "Epoch 1805: Training Accuracy = 0.9863, Training Loss = 0.1415, Validation Accuracy = 0.2602, Validation Loss = 2.5221\n",
            "Epoch 1806/3334\n",
            "Epoch 1806: Training Accuracy = 0.9863, Training Loss = 0.1415, Validation Accuracy = 0.2602, Validation Loss = 2.5221\n",
            "Epoch 1807/3334\n",
            "Epoch 1807: Training Accuracy = 0.9922, Training Loss = 0.1005, Validation Accuracy = 0.2698, Validation Loss = 2.4958\n",
            "Epoch 1808/3334\n",
            "Epoch 1808: Training Accuracy = 0.9922, Training Loss = 0.1005, Validation Accuracy = 0.2698, Validation Loss = 2.4958\n",
            "Epoch 1809/3334\n",
            "Epoch 1809: Training Accuracy = 0.9922, Training Loss = 0.1005, Validation Accuracy = 0.2698, Validation Loss = 2.4958\n",
            "Epoch 1810/3334\n",
            "Epoch 1810: Training Accuracy = 0.9922, Training Loss = 0.1005, Validation Accuracy = 0.2698, Validation Loss = 2.4958\n",
            "Epoch 1811/3334\n",
            "Epoch 1811: Training Accuracy = 0.9873, Training Loss = 0.1086, Validation Accuracy = 0.2760, Validation Loss = 2.4934\n",
            "Epoch 1812/3334\n",
            "Epoch 1812: Training Accuracy = 0.9873, Training Loss = 0.1086, Validation Accuracy = 0.2760, Validation Loss = 2.4934\n",
            "Epoch 1813/3334\n",
            "Epoch 1813: Training Accuracy = 0.9873, Training Loss = 0.1086, Validation Accuracy = 0.2760, Validation Loss = 2.4934\n",
            "Epoch 1814/3334\n",
            "Epoch 1814: Training Accuracy = 0.9883, Training Loss = 0.1008, Validation Accuracy = 0.2819, Validation Loss = 2.4828\n",
            "Epoch 1815/3334\n",
            "Epoch 1815: Training Accuracy = 0.9883, Training Loss = 0.1008, Validation Accuracy = 0.2819, Validation Loss = 2.4828\n",
            "Epoch 1816/3334\n",
            "Epoch 1816: Training Accuracy = 0.9883, Training Loss = 0.1008, Validation Accuracy = 0.2819, Validation Loss = 2.4828\n",
            "Epoch 1817/3334\n",
            "Epoch 1817: Training Accuracy = 0.9884, Training Loss = 0.1005, Validation Accuracy = 0.2831, Validation Loss = 2.4816\n",
            "Epoch 1818/3334\n",
            "Epoch 1818: Training Accuracy = 0.9884, Training Loss = 0.1005, Validation Accuracy = 0.2831, Validation Loss = 2.4816\n",
            "Epoch 1819/3334\n",
            "Epoch 1819: Training Accuracy = 0.9884, Training Loss = 0.1005, Validation Accuracy = 0.2831, Validation Loss = 2.4816\n",
            "Epoch 1820/3334\n",
            "Epoch 1820: Training Accuracy = 0.9884, Training Loss = 0.1005, Validation Accuracy = 0.2831, Validation Loss = 2.4816\n",
            "Epoch 1821/3334\n",
            "Epoch 1821: Training Accuracy = 0.9922, Training Loss = 0.0834, Validation Accuracy = 0.2891, Validation Loss = 2.4550\n",
            "Epoch 1822/3334\n",
            "Epoch 1822: Training Accuracy = 0.9922, Training Loss = 0.0834, Validation Accuracy = 0.2891, Validation Loss = 2.4550\n",
            "Epoch 1823/3334\n",
            "Epoch 1823: Training Accuracy = 0.9922, Training Loss = 0.0834, Validation Accuracy = 0.2891, Validation Loss = 2.4550\n",
            "Epoch 1824/3334\n",
            "Epoch 1824: Training Accuracy = 0.9932, Training Loss = 0.0816, Validation Accuracy = 0.2883, Validation Loss = 2.4509\n",
            "Epoch 1825/3334\n",
            "Epoch 1825: Training Accuracy = 0.9932, Training Loss = 0.0816, Validation Accuracy = 0.2883, Validation Loss = 2.4509\n",
            "Epoch 1826/3334\n",
            "Epoch 1826: Training Accuracy = 0.9932, Training Loss = 0.0816, Validation Accuracy = 0.2883, Validation Loss = 2.4509\n",
            "Epoch 1827/3334\n",
            "Epoch 1827: Training Accuracy = 0.9910, Training Loss = 0.0964, Validation Accuracy = 0.2948, Validation Loss = 2.4518\n",
            "Epoch 1828/3334\n",
            "Epoch 1828: Training Accuracy = 0.9910, Training Loss = 0.0964, Validation Accuracy = 0.2948, Validation Loss = 2.4518\n",
            "Epoch 1829/3334\n",
            "Epoch 1829: Training Accuracy = 0.9910, Training Loss = 0.0964, Validation Accuracy = 0.2948, Validation Loss = 2.4518\n",
            "Epoch 1830/3334\n",
            "Epoch 1830: Training Accuracy = 0.9910, Training Loss = 0.0964, Validation Accuracy = 0.2948, Validation Loss = 2.4518\n",
            "Epoch 1831/3334\n",
            "Epoch 1831: Training Accuracy = 0.9893, Training Loss = 0.1050, Validation Accuracy = 0.2898, Validation Loss = 2.4611\n",
            "Epoch 1832/3334\n",
            "Epoch 1832: Training Accuracy = 0.9893, Training Loss = 0.1050, Validation Accuracy = 0.2898, Validation Loss = 2.4611\n",
            "Epoch 1833/3334\n",
            "Epoch 1833: Training Accuracy = 0.9893, Training Loss = 0.1050, Validation Accuracy = 0.2898, Validation Loss = 2.4611\n",
            "Epoch 1834/3334\n",
            "Epoch 1834: Training Accuracy = 0.7158, Training Loss = 1.3035, Validation Accuracy = 0.1586, Validation Loss = 3.3023\n",
            "Epoch 1835/3334\n",
            "Epoch 1835: Training Accuracy = 0.7158, Training Loss = 1.3035, Validation Accuracy = 0.1586, Validation Loss = 3.3023\n",
            "Epoch 1836/3334\n",
            "Epoch 1836: Training Accuracy = 0.7158, Training Loss = 1.3035, Validation Accuracy = 0.1586, Validation Loss = 3.3023\n",
            "Epoch 1837/3334\n",
            "Epoch 1837: Training Accuracy = 0.9651, Training Loss = 0.4436, Validation Accuracy = 0.2749, Validation Loss = 2.4624\n",
            "Epoch 1838/3334\n",
            "Epoch 1838: Training Accuracy = 0.9651, Training Loss = 0.4436, Validation Accuracy = 0.2749, Validation Loss = 2.4624\n",
            "Epoch 1839/3334\n",
            "Epoch 1839: Training Accuracy = 0.9651, Training Loss = 0.4436, Validation Accuracy = 0.2749, Validation Loss = 2.4624\n",
            "Epoch 1840/3334\n",
            "Epoch 1840: Training Accuracy = 0.9651, Training Loss = 0.4436, Validation Accuracy = 0.2749, Validation Loss = 2.4624\n",
            "Epoch 1841/3334\n",
            "Epoch 1841: Training Accuracy = 0.9922, Training Loss = 0.2059, Validation Accuracy = 0.3114, Validation Loss = 2.3355\n",
            "Epoch 1842/3334\n",
            "Epoch 1842: Training Accuracy = 0.9922, Training Loss = 0.2059, Validation Accuracy = 0.3114, Validation Loss = 2.3355\n",
            "Epoch 1843/3334\n",
            "Epoch 1843: Training Accuracy = 0.9922, Training Loss = 0.2059, Validation Accuracy = 0.3114, Validation Loss = 2.3355\n",
            "Epoch 1844/3334\n",
            "Epoch 1844: Training Accuracy = 0.9922, Training Loss = 0.1368, Validation Accuracy = 0.3360, Validation Loss = 2.2138\n",
            "Epoch 1845/3334\n",
            "Epoch 1845: Training Accuracy = 0.9922, Training Loss = 0.1368, Validation Accuracy = 0.3360, Validation Loss = 2.2138\n",
            "Epoch 1846/3334\n",
            "Epoch 1846: Training Accuracy = 0.9922, Training Loss = 0.1368, Validation Accuracy = 0.3360, Validation Loss = 2.2138\n",
            "Epoch 1847/3334\n",
            "Epoch 1847: Training Accuracy = 0.9897, Training Loss = 0.1131, Validation Accuracy = 0.3560, Validation Loss = 2.1623\n",
            "Epoch 1848/3334\n",
            "Epoch 1848: Training Accuracy = 0.9897, Training Loss = 0.1131, Validation Accuracy = 0.3560, Validation Loss = 2.1623\n",
            "Epoch 1849/3334\n",
            "Epoch 1849: Training Accuracy = 0.9897, Training Loss = 0.1131, Validation Accuracy = 0.3560, Validation Loss = 2.1623\n",
            "Epoch 1850/3334\n",
            "Epoch 1850: Training Accuracy = 0.9897, Training Loss = 0.1131, Validation Accuracy = 0.3560, Validation Loss = 2.1623\n",
            "Epoch 1851/3334\n",
            "Epoch 1851: Training Accuracy = 0.9883, Training Loss = 0.1012, Validation Accuracy = 0.3724, Validation Loss = 2.1158\n",
            "Epoch 1852/3334\n",
            "Epoch 1852: Training Accuracy = 0.9883, Training Loss = 0.1012, Validation Accuracy = 0.3724, Validation Loss = 2.1158\n",
            "Epoch 1853/3334\n",
            "Epoch 1853: Training Accuracy = 0.9883, Training Loss = 0.1012, Validation Accuracy = 0.3724, Validation Loss = 2.1158\n",
            "Epoch 1854/3334\n",
            "Epoch 1854: Training Accuracy = 0.9902, Training Loss = 0.0933, Validation Accuracy = 0.3768, Validation Loss = 2.0922\n",
            "Epoch 1855/3334\n",
            "Epoch 1855: Training Accuracy = 0.9902, Training Loss = 0.0933, Validation Accuracy = 0.3768, Validation Loss = 2.0922\n",
            "Epoch 1856/3334\n",
            "Epoch 1856: Training Accuracy = 0.9902, Training Loss = 0.0933, Validation Accuracy = 0.3768, Validation Loss = 2.0922\n",
            "Epoch 1857/3334\n",
            "Epoch 1857: Training Accuracy = 0.9935, Training Loss = 0.0753, Validation Accuracy = 0.3811, Validation Loss = 2.0781\n",
            "Epoch 1858/3334\n",
            "Epoch 1858: Training Accuracy = 0.9935, Training Loss = 0.0753, Validation Accuracy = 0.3811, Validation Loss = 2.0781\n",
            "Epoch 1859/3334\n",
            "Epoch 1859: Training Accuracy = 0.9935, Training Loss = 0.0753, Validation Accuracy = 0.3811, Validation Loss = 2.0781\n",
            "Epoch 1860/3334\n",
            "Epoch 1860: Training Accuracy = 0.9935, Training Loss = 0.0753, Validation Accuracy = 0.3811, Validation Loss = 2.0781\n",
            "Epoch 1861/3334\n",
            "Epoch 1861: Training Accuracy = 0.9893, Training Loss = 0.0902, Validation Accuracy = 0.3856, Validation Loss = 2.0726\n",
            "Epoch 1862/3334\n",
            "Epoch 1862: Training Accuracy = 0.9893, Training Loss = 0.0902, Validation Accuracy = 0.3856, Validation Loss = 2.0726\n",
            "Epoch 1863/3334\n",
            "Epoch 1863: Training Accuracy = 0.9893, Training Loss = 0.0902, Validation Accuracy = 0.3856, Validation Loss = 2.0726\n",
            "Epoch 1864/3334\n",
            "Epoch 1864: Training Accuracy = 0.9883, Training Loss = 0.0921, Validation Accuracy = 0.3935, Validation Loss = 2.0585\n",
            "Epoch 1865/3334\n",
            "Epoch 1865: Training Accuracy = 0.9883, Training Loss = 0.0921, Validation Accuracy = 0.3935, Validation Loss = 2.0585\n",
            "Epoch 1866/3334\n",
            "Epoch 1866: Training Accuracy = 0.9883, Training Loss = 0.0921, Validation Accuracy = 0.3935, Validation Loss = 2.0585\n",
            "Epoch 1867/3334\n",
            "Epoch 1867: Training Accuracy = 0.9871, Training Loss = 0.0986, Validation Accuracy = 0.3929, Validation Loss = 2.0670\n",
            "Epoch 1868/3334\n",
            "Epoch 1868: Training Accuracy = 0.9871, Training Loss = 0.0986, Validation Accuracy = 0.3929, Validation Loss = 2.0670\n",
            "Epoch 1869/3334\n",
            "Epoch 1869: Training Accuracy = 0.9871, Training Loss = 0.0986, Validation Accuracy = 0.3929, Validation Loss = 2.0670\n",
            "Epoch 1870/3334\n",
            "Epoch 1870: Training Accuracy = 0.9871, Training Loss = 0.0986, Validation Accuracy = 0.3929, Validation Loss = 2.0670\n",
            "Epoch 1871/3334\n",
            "Epoch 1871: Training Accuracy = 0.9863, Training Loss = 0.0970, Validation Accuracy = 0.4044, Validation Loss = 2.0300\n",
            "Epoch 1872/3334\n",
            "Epoch 1872: Training Accuracy = 0.9863, Training Loss = 0.0970, Validation Accuracy = 0.4044, Validation Loss = 2.0300\n",
            "Epoch 1873/3334\n",
            "Epoch 1873: Training Accuracy = 0.9863, Training Loss = 0.0970, Validation Accuracy = 0.4044, Validation Loss = 2.0300\n",
            "Epoch 1874/3334\n",
            "Epoch 1874: Training Accuracy = 0.9873, Training Loss = 0.0977, Validation Accuracy = 0.4031, Validation Loss = 2.0523\n",
            "Epoch 1875/3334\n",
            "Epoch 1875: Training Accuracy = 0.9873, Training Loss = 0.0977, Validation Accuracy = 0.4031, Validation Loss = 2.0523\n",
            "Epoch 1876/3334\n",
            "Epoch 1876: Training Accuracy = 0.9873, Training Loss = 0.0977, Validation Accuracy = 0.4031, Validation Loss = 2.0523\n",
            "Epoch 1877/3334\n",
            "Epoch 1877: Training Accuracy = 0.2300, Training Loss = 2.8654, Validation Accuracy = 0.0849, Validation Loss = 4.0714\n",
            "Epoch 1878/3334\n",
            "Epoch 1878: Training Accuracy = 0.2300, Training Loss = 2.8654, Validation Accuracy = 0.0849, Validation Loss = 4.0714\n",
            "Epoch 1879/3334\n",
            "Epoch 1879: Training Accuracy = 0.2300, Training Loss = 2.8654, Validation Accuracy = 0.0849, Validation Loss = 4.0714\n",
            "Epoch 1880/3334\n",
            "Epoch 1880: Training Accuracy = 0.2300, Training Loss = 2.8654, Validation Accuracy = 0.0849, Validation Loss = 4.0714\n",
            "Epoch 1881/3334\n",
            "Epoch 1881: Training Accuracy = 0.8760, Training Loss = 0.8331, Validation Accuracy = 0.2945, Validation Loss = 2.3838\n",
            "Epoch 1882/3334\n",
            "Epoch 1882: Training Accuracy = 0.8760, Training Loss = 0.8331, Validation Accuracy = 0.2945, Validation Loss = 2.3838\n",
            "Epoch 1883/3334\n",
            "Epoch 1883: Training Accuracy = 0.8760, Training Loss = 0.8331, Validation Accuracy = 0.2945, Validation Loss = 2.3838\n",
            "Epoch 1884/3334\n",
            "Epoch 1884: Training Accuracy = 0.9775, Training Loss = 0.3675, Validation Accuracy = 0.3722, Validation Loss = 2.0446\n",
            "Epoch 1885/3334\n",
            "Epoch 1885: Training Accuracy = 0.9775, Training Loss = 0.3675, Validation Accuracy = 0.3722, Validation Loss = 2.0446\n",
            "Epoch 1886/3334\n",
            "Epoch 1886: Training Accuracy = 0.9775, Training Loss = 0.3675, Validation Accuracy = 0.3722, Validation Loss = 2.0446\n",
            "Epoch 1887/3334\n",
            "Epoch 1887: Training Accuracy = 0.9858, Training Loss = 0.2280, Validation Accuracy = 0.4105, Validation Loss = 1.8962\n",
            "Epoch 1888/3334\n",
            "Epoch 1888: Training Accuracy = 0.9858, Training Loss = 0.2280, Validation Accuracy = 0.4105, Validation Loss = 1.8962\n",
            "Epoch 1889/3334\n",
            "Epoch 1889: Training Accuracy = 0.9858, Training Loss = 0.2280, Validation Accuracy = 0.4105, Validation Loss = 1.8962\n",
            "Epoch 1890/3334\n",
            "Epoch 1890: Training Accuracy = 0.9858, Training Loss = 0.2280, Validation Accuracy = 0.4105, Validation Loss = 1.8962\n",
            "Epoch 1891/3334\n",
            "Epoch 1891: Training Accuracy = 0.9873, Training Loss = 0.1589, Validation Accuracy = 0.4327, Validation Loss = 1.8211\n",
            "Epoch 1892/3334\n",
            "Epoch 1892: Training Accuracy = 0.9873, Training Loss = 0.1589, Validation Accuracy = 0.4327, Validation Loss = 1.8211\n",
            "Epoch 1893/3334\n",
            "Epoch 1893: Training Accuracy = 0.9873, Training Loss = 0.1589, Validation Accuracy = 0.4327, Validation Loss = 1.8211\n",
            "Epoch 1894/3334\n",
            "Epoch 1894: Training Accuracy = 0.9873, Training Loss = 0.1338, Validation Accuracy = 0.4559, Validation Loss = 1.7591\n",
            "Epoch 1895/3334\n",
            "Epoch 1895: Training Accuracy = 0.9873, Training Loss = 0.1338, Validation Accuracy = 0.4559, Validation Loss = 1.7591\n",
            "Epoch 1896/3334\n",
            "Epoch 1896: Training Accuracy = 0.9873, Training Loss = 0.1338, Validation Accuracy = 0.4559, Validation Loss = 1.7591\n",
            "Epoch 1897/3334\n",
            "Epoch 1897: Training Accuracy = 0.9871, Training Loss = 0.1224, Validation Accuracy = 0.4668, Validation Loss = 1.7391\n",
            "Epoch 1898/3334\n",
            "Epoch 1898: Training Accuracy = 0.9871, Training Loss = 0.1224, Validation Accuracy = 0.4668, Validation Loss = 1.7391\n",
            "Epoch 1899/3334\n",
            "Epoch 1899: Training Accuracy = 0.9871, Training Loss = 0.1224, Validation Accuracy = 0.4668, Validation Loss = 1.7391\n",
            "Epoch 1900/3334\n",
            "Epoch 1900: Training Accuracy = 0.9871, Training Loss = 0.1224, Validation Accuracy = 0.4668, Validation Loss = 1.7391\n",
            "Epoch 1901/3334\n",
            "Epoch 1901: Training Accuracy = 0.9941, Training Loss = 0.0882, Validation Accuracy = 0.4747, Validation Loss = 1.7210\n",
            "Epoch 1902/3334\n",
            "Epoch 1902: Training Accuracy = 0.9941, Training Loss = 0.0882, Validation Accuracy = 0.4747, Validation Loss = 1.7210\n",
            "Epoch 1903/3334\n",
            "Epoch 1903: Training Accuracy = 0.9941, Training Loss = 0.0882, Validation Accuracy = 0.4747, Validation Loss = 1.7210\n",
            "Epoch 1904/3334\n",
            "Epoch 1904: Training Accuracy = 0.9854, Training Loss = 0.1169, Validation Accuracy = 0.4873, Validation Loss = 1.6985\n",
            "Epoch 1905/3334\n",
            "Epoch 1905: Training Accuracy = 0.9854, Training Loss = 0.1169, Validation Accuracy = 0.4873, Validation Loss = 1.6985\n",
            "Epoch 1906/3334\n",
            "Epoch 1906: Training Accuracy = 0.9854, Training Loss = 0.1169, Validation Accuracy = 0.4873, Validation Loss = 1.6985\n",
            "Epoch 1907/3334\n",
            "Epoch 1907: Training Accuracy = 0.9897, Training Loss = 0.0973, Validation Accuracy = 0.4958, Validation Loss = 1.6858\n",
            "Epoch 1908/3334\n",
            "Epoch 1908: Training Accuracy = 0.9897, Training Loss = 0.0973, Validation Accuracy = 0.4958, Validation Loss = 1.6858\n",
            "Epoch 1909/3334\n",
            "Epoch 1909: Training Accuracy = 0.9897, Training Loss = 0.0973, Validation Accuracy = 0.4958, Validation Loss = 1.6858\n",
            "Epoch 1910/3334\n",
            "Epoch 1910: Training Accuracy = 0.9897, Training Loss = 0.0973, Validation Accuracy = 0.4958, Validation Loss = 1.6858\n",
            "Epoch 1911/3334\n",
            "Epoch 1911: Training Accuracy = 0.9844, Training Loss = 0.1134, Validation Accuracy = 0.4913, Validation Loss = 1.6843\n",
            "Epoch 1912/3334\n",
            "Epoch 1912: Training Accuracy = 0.9844, Training Loss = 0.1134, Validation Accuracy = 0.4913, Validation Loss = 1.6843\n",
            "Epoch 1913/3334\n",
            "Epoch 1913: Training Accuracy = 0.9844, Training Loss = 0.1134, Validation Accuracy = 0.4913, Validation Loss = 1.6843\n",
            "Epoch 1914/3334\n",
            "Epoch 1914: Training Accuracy = 0.9883, Training Loss = 0.1003, Validation Accuracy = 0.5045, Validation Loss = 1.6769\n",
            "Epoch 1915/3334\n",
            "Epoch 1915: Training Accuracy = 0.9883, Training Loss = 0.1003, Validation Accuracy = 0.5045, Validation Loss = 1.6769\n",
            "Epoch 1916/3334\n",
            "Epoch 1916: Training Accuracy = 0.9883, Training Loss = 0.1003, Validation Accuracy = 0.5045, Validation Loss = 1.6769\n",
            "Epoch 1917/3334\n",
            "Epoch 1917: Training Accuracy = 0.9884, Training Loss = 0.1061, Validation Accuracy = 0.5087, Validation Loss = 1.6721\n",
            "Epoch 1918/3334\n",
            "Epoch 1918: Training Accuracy = 0.9884, Training Loss = 0.1061, Validation Accuracy = 0.5087, Validation Loss = 1.6721\n",
            "Epoch 1919/3334\n",
            "Epoch 1919: Training Accuracy = 0.9884, Training Loss = 0.1061, Validation Accuracy = 0.5087, Validation Loss = 1.6721\n",
            "Epoch 1920/3334\n",
            "Epoch 1920: Training Accuracy = 0.9884, Training Loss = 0.1061, Validation Accuracy = 0.5087, Validation Loss = 1.6721\n",
            "Epoch 1921/3334\n",
            "Epoch 1921: Training Accuracy = 0.9873, Training Loss = 0.1783, Validation Accuracy = 0.2487, Validation Loss = 2.7784\n",
            "Epoch 1922/3334\n",
            "Epoch 1922: Training Accuracy = 0.9873, Training Loss = 0.1783, Validation Accuracy = 0.2487, Validation Loss = 2.7784\n",
            "Epoch 1923/3334\n",
            "Epoch 1923: Training Accuracy = 0.9873, Training Loss = 0.1783, Validation Accuracy = 0.2487, Validation Loss = 2.7784\n",
            "Epoch 1924/3334\n",
            "Epoch 1924: Training Accuracy = 0.8574, Training Loss = 0.8646, Validation Accuracy = 0.3505, Validation Loss = 2.2328\n",
            "Epoch 1925/3334\n",
            "Epoch 1925: Training Accuracy = 0.8574, Training Loss = 0.8646, Validation Accuracy = 0.3505, Validation Loss = 2.2328\n",
            "Epoch 1926/3334\n",
            "Epoch 1926: Training Accuracy = 0.8574, Training Loss = 0.8646, Validation Accuracy = 0.3505, Validation Loss = 2.2328\n",
            "Epoch 1927/3334\n",
            "Epoch 1927: Training Accuracy = 0.9884, Training Loss = 0.2895, Validation Accuracy = 0.4943, Validation Loss = 1.6920\n",
            "Epoch 1928/3334\n",
            "Epoch 1928: Training Accuracy = 0.9884, Training Loss = 0.2895, Validation Accuracy = 0.4943, Validation Loss = 1.6920\n",
            "Epoch 1929/3334\n",
            "Epoch 1929: Training Accuracy = 0.9884, Training Loss = 0.2895, Validation Accuracy = 0.4943, Validation Loss = 1.6920\n",
            "Epoch 1930/3334\n",
            "Epoch 1930: Training Accuracy = 0.9884, Training Loss = 0.2895, Validation Accuracy = 0.4943, Validation Loss = 1.6920\n",
            "Epoch 1931/3334\n",
            "Epoch 1931: Training Accuracy = 0.9902, Training Loss = 0.1814, Validation Accuracy = 0.5415, Validation Loss = 1.5468\n",
            "Epoch 1932/3334\n",
            "Epoch 1932: Training Accuracy = 0.9902, Training Loss = 0.1814, Validation Accuracy = 0.5415, Validation Loss = 1.5468\n",
            "Epoch 1933/3334\n",
            "Epoch 1933: Training Accuracy = 0.9902, Training Loss = 0.1814, Validation Accuracy = 0.5415, Validation Loss = 1.5468\n",
            "Epoch 1934/3334\n",
            "Epoch 1934: Training Accuracy = 0.9854, Training Loss = 0.1541, Validation Accuracy = 0.5764, Validation Loss = 1.4398\n",
            "Epoch 1935/3334\n",
            "Epoch 1935: Training Accuracy = 0.9854, Training Loss = 0.1541, Validation Accuracy = 0.5764, Validation Loss = 1.4398\n",
            "Epoch 1936/3334\n",
            "Epoch 1936: Training Accuracy = 0.9854, Training Loss = 0.1541, Validation Accuracy = 0.5764, Validation Loss = 1.4398\n",
            "Epoch 1937/3334\n",
            "Epoch 1937: Training Accuracy = 0.9845, Training Loss = 0.1383, Validation Accuracy = 0.5994, Validation Loss = 1.3912\n",
            "Epoch 1938/3334\n",
            "Epoch 1938: Training Accuracy = 0.9845, Training Loss = 0.1383, Validation Accuracy = 0.5994, Validation Loss = 1.3912\n",
            "Epoch 1939/3334\n",
            "Epoch 1939: Training Accuracy = 0.9845, Training Loss = 0.1383, Validation Accuracy = 0.5994, Validation Loss = 1.3912\n",
            "Epoch 1940/3334\n",
            "Epoch 1940: Training Accuracy = 0.9845, Training Loss = 0.1383, Validation Accuracy = 0.5994, Validation Loss = 1.3912\n",
            "Epoch 1941/3334\n",
            "Epoch 1941: Training Accuracy = 0.9912, Training Loss = 0.1041, Validation Accuracy = 0.6042, Validation Loss = 1.3672\n",
            "Epoch 1942/3334\n",
            "Epoch 1942: Training Accuracy = 0.9912, Training Loss = 0.1041, Validation Accuracy = 0.6042, Validation Loss = 1.3672\n",
            "Epoch 1943/3334\n",
            "Epoch 1943: Training Accuracy = 0.9912, Training Loss = 0.1041, Validation Accuracy = 0.6042, Validation Loss = 1.3672\n",
            "Epoch 1944/3334\n",
            "Epoch 1944: Training Accuracy = 0.9902, Training Loss = 0.1013, Validation Accuracy = 0.6095, Validation Loss = 1.3559\n",
            "Epoch 1945/3334\n",
            "Epoch 1945: Training Accuracy = 0.9902, Training Loss = 0.1013, Validation Accuracy = 0.6095, Validation Loss = 1.3559\n",
            "Epoch 1946/3334\n",
            "Epoch 1946: Training Accuracy = 0.9902, Training Loss = 0.1013, Validation Accuracy = 0.6095, Validation Loss = 1.3559\n",
            "Epoch 1947/3334\n",
            "Epoch 1947: Training Accuracy = 0.9910, Training Loss = 0.0961, Validation Accuracy = 0.6142, Validation Loss = 1.3515\n",
            "Epoch 1948/3334\n",
            "Epoch 1948: Training Accuracy = 0.9910, Training Loss = 0.0961, Validation Accuracy = 0.6142, Validation Loss = 1.3515\n",
            "Epoch 1949/3334\n",
            "Epoch 1949: Training Accuracy = 0.9910, Training Loss = 0.0961, Validation Accuracy = 0.6142, Validation Loss = 1.3515\n",
            "Epoch 1950/3334\n",
            "Epoch 1950: Training Accuracy = 0.9910, Training Loss = 0.0961, Validation Accuracy = 0.6142, Validation Loss = 1.3515\n",
            "Epoch 1951/3334\n",
            "Epoch 1951: Training Accuracy = 0.9893, Training Loss = 0.0974, Validation Accuracy = 0.6214, Validation Loss = 1.3415\n",
            "Epoch 1952/3334\n",
            "Epoch 1952: Training Accuracy = 0.9893, Training Loss = 0.0974, Validation Accuracy = 0.6214, Validation Loss = 1.3415\n",
            "Epoch 1953/3334\n",
            "Epoch 1953: Training Accuracy = 0.9893, Training Loss = 0.0974, Validation Accuracy = 0.6214, Validation Loss = 1.3415\n",
            "Epoch 1954/3334\n",
            "Epoch 1954: Training Accuracy = 0.9893, Training Loss = 0.1010, Validation Accuracy = 0.6200, Validation Loss = 1.3441\n",
            "Epoch 1955/3334\n",
            "Epoch 1955: Training Accuracy = 0.9893, Training Loss = 0.1010, Validation Accuracy = 0.6200, Validation Loss = 1.3441\n",
            "Epoch 1956/3334\n",
            "Epoch 1956: Training Accuracy = 0.9893, Training Loss = 0.1010, Validation Accuracy = 0.6200, Validation Loss = 1.3441\n",
            "Epoch 1957/3334\n",
            "Epoch 1957: Training Accuracy = 0.9845, Training Loss = 0.1153, Validation Accuracy = 0.6202, Validation Loss = 1.3352\n",
            "Epoch 1958/3334\n",
            "Epoch 1958: Training Accuracy = 0.9845, Training Loss = 0.1153, Validation Accuracy = 0.6202, Validation Loss = 1.3352\n",
            "Epoch 1959/3334\n",
            "Epoch 1959: Training Accuracy = 0.9845, Training Loss = 0.1153, Validation Accuracy = 0.6202, Validation Loss = 1.3352\n",
            "Epoch 1960/3334\n",
            "Epoch 1960: Training Accuracy = 0.9845, Training Loss = 0.1153, Validation Accuracy = 0.6202, Validation Loss = 1.3352\n",
            "Epoch 1961/3334\n",
            "Epoch 1961: Training Accuracy = 0.9883, Training Loss = 0.1032, Validation Accuracy = 0.6325, Validation Loss = 1.3128\n",
            "Epoch 1962/3334\n",
            "Epoch 1962: Training Accuracy = 0.9883, Training Loss = 0.1032, Validation Accuracy = 0.6325, Validation Loss = 1.3128\n",
            "Epoch 1963/3334\n",
            "Epoch 1963: Training Accuracy = 0.9883, Training Loss = 0.1032, Validation Accuracy = 0.6325, Validation Loss = 1.3128\n",
            "Epoch 1964/3334\n",
            "Epoch 1964: Training Accuracy = 0.9912, Training Loss = 0.0942, Validation Accuracy = 0.6224, Validation Loss = 1.3392\n",
            "Epoch 1965/3334\n",
            "Epoch 1965: Training Accuracy = 0.9912, Training Loss = 0.0942, Validation Accuracy = 0.6224, Validation Loss = 1.3392\n",
            "Epoch 1966/3334\n",
            "Epoch 1966: Training Accuracy = 0.9912, Training Loss = 0.0942, Validation Accuracy = 0.6224, Validation Loss = 1.3392\n",
            "Epoch 1967/3334\n",
            "Epoch 1967: Training Accuracy = 0.4225, Training Loss = 2.1356, Validation Accuracy = 0.1271, Validation Loss = 3.8153\n",
            "Epoch 1968/3334\n",
            "Epoch 1968: Training Accuracy = 0.4225, Training Loss = 2.1356, Validation Accuracy = 0.1271, Validation Loss = 3.8153\n",
            "Epoch 1969/3334\n",
            "Epoch 1969: Training Accuracy = 0.4225, Training Loss = 2.1356, Validation Accuracy = 0.1271, Validation Loss = 3.8153\n",
            "Epoch 1970/3334\n",
            "Epoch 1970: Training Accuracy = 0.4225, Training Loss = 2.1356, Validation Accuracy = 0.1271, Validation Loss = 3.8153\n",
            "Epoch 1971/3334\n",
            "Epoch 1971: Training Accuracy = 0.9219, Training Loss = 0.6231, Validation Accuracy = 0.4706, Validation Loss = 1.7948\n",
            "Epoch 1972/3334\n",
            "Epoch 1972: Training Accuracy = 0.9219, Training Loss = 0.6231, Validation Accuracy = 0.4706, Validation Loss = 1.7948\n",
            "Epoch 1973/3334\n",
            "Epoch 1973: Training Accuracy = 0.9219, Training Loss = 0.6231, Validation Accuracy = 0.4706, Validation Loss = 1.7948\n",
            "Epoch 1974/3334\n",
            "Epoch 1974: Training Accuracy = 0.9805, Training Loss = 0.2914, Validation Accuracy = 0.5811, Validation Loss = 1.4520\n",
            "Epoch 1975/3334\n",
            "Epoch 1975: Training Accuracy = 0.9805, Training Loss = 0.2914, Validation Accuracy = 0.5811, Validation Loss = 1.4520\n",
            "Epoch 1976/3334\n",
            "Epoch 1976: Training Accuracy = 0.9805, Training Loss = 0.2914, Validation Accuracy = 0.5811, Validation Loss = 1.4520\n",
            "Epoch 1977/3334\n",
            "Epoch 1977: Training Accuracy = 0.9910, Training Loss = 0.1582, Validation Accuracy = 0.6640, Validation Loss = 1.2274\n",
            "Epoch 1978/3334\n",
            "Epoch 1978: Training Accuracy = 0.9910, Training Loss = 0.1582, Validation Accuracy = 0.6640, Validation Loss = 1.2274\n",
            "Epoch 1979/3334\n",
            "Epoch 1979: Training Accuracy = 0.9910, Training Loss = 0.1582, Validation Accuracy = 0.6640, Validation Loss = 1.2274\n",
            "Epoch 1980/3334\n",
            "Epoch 1980: Training Accuracy = 0.9910, Training Loss = 0.1582, Validation Accuracy = 0.6640, Validation Loss = 1.2274\n",
            "Epoch 1981/3334\n",
            "Epoch 1981: Training Accuracy = 0.9912, Training Loss = 0.1191, Validation Accuracy = 0.6974, Validation Loss = 1.1252\n",
            "Epoch 1982/3334\n",
            "Epoch 1982: Training Accuracy = 0.9912, Training Loss = 0.1191, Validation Accuracy = 0.6974, Validation Loss = 1.1252\n",
            "Epoch 1983/3334\n",
            "Epoch 1983: Training Accuracy = 0.9912, Training Loss = 0.1191, Validation Accuracy = 0.6974, Validation Loss = 1.1252\n",
            "Epoch 1984/3334\n",
            "Epoch 1984: Training Accuracy = 0.9883, Training Loss = 0.1110, Validation Accuracy = 0.7155, Validation Loss = 1.0868\n",
            "Epoch 1985/3334\n",
            "Epoch 1985: Training Accuracy = 0.9883, Training Loss = 0.1110, Validation Accuracy = 0.7155, Validation Loss = 1.0868\n",
            "Epoch 1986/3334\n",
            "Epoch 1986: Training Accuracy = 0.9883, Training Loss = 0.1110, Validation Accuracy = 0.7155, Validation Loss = 1.0868\n",
            "Epoch 1987/3334\n",
            "Epoch 1987: Training Accuracy = 0.9922, Training Loss = 0.0918, Validation Accuracy = 0.7229, Validation Loss = 1.0581\n",
            "Epoch 1988/3334\n",
            "Epoch 1988: Training Accuracy = 0.9922, Training Loss = 0.0918, Validation Accuracy = 0.7229, Validation Loss = 1.0581\n",
            "Epoch 1989/3334\n",
            "Epoch 1989: Training Accuracy = 0.9922, Training Loss = 0.0918, Validation Accuracy = 0.7229, Validation Loss = 1.0581\n",
            "Epoch 1990/3334\n",
            "Epoch 1990: Training Accuracy = 0.9922, Training Loss = 0.0918, Validation Accuracy = 0.7229, Validation Loss = 1.0581\n",
            "Epoch 1991/3334\n",
            "Epoch 1991: Training Accuracy = 0.9834, Training Loss = 0.1168, Validation Accuracy = 0.7286, Validation Loss = 1.0432\n",
            "Epoch 1992/3334\n",
            "Epoch 1992: Training Accuracy = 0.9834, Training Loss = 0.1168, Validation Accuracy = 0.7286, Validation Loss = 1.0432\n",
            "Epoch 1993/3334\n",
            "Epoch 1993: Training Accuracy = 0.9834, Training Loss = 0.1168, Validation Accuracy = 0.7286, Validation Loss = 1.0432\n",
            "Epoch 1994/3334\n",
            "Epoch 1994: Training Accuracy = 0.9844, Training Loss = 0.1119, Validation Accuracy = 0.7351, Validation Loss = 1.0330\n",
            "Epoch 1995/3334\n",
            "Epoch 1995: Training Accuracy = 0.9844, Training Loss = 0.1119, Validation Accuracy = 0.7351, Validation Loss = 1.0330\n",
            "Epoch 1996/3334\n",
            "Epoch 1996: Training Accuracy = 0.9844, Training Loss = 0.1119, Validation Accuracy = 0.7351, Validation Loss = 1.0330\n",
            "Epoch 1997/3334\n",
            "Epoch 1997: Training Accuracy = 0.9871, Training Loss = 0.1069, Validation Accuracy = 0.7440, Validation Loss = 1.0148\n",
            "Epoch 1998/3334\n",
            "Epoch 1998: Training Accuracy = 0.9871, Training Loss = 0.1069, Validation Accuracy = 0.7440, Validation Loss = 1.0148\n",
            "Epoch 1999/3334\n",
            "Epoch 1999: Training Accuracy = 0.9871, Training Loss = 0.1069, Validation Accuracy = 0.7440, Validation Loss = 1.0148\n",
            "Epoch 2000/3334\n",
            "Epoch 2000: Training Accuracy = 0.9871, Training Loss = 0.1069, Validation Accuracy = 0.7440, Validation Loss = 1.0148\n",
            "Epoch 2001/3334\n",
            "Epoch 2001: Training Accuracy = 0.9883, Training Loss = 0.0965, Validation Accuracy = 0.7527, Validation Loss = 1.0092\n",
            "Epoch 2002/3334\n",
            "Epoch 2002: Training Accuracy = 0.9883, Training Loss = 0.0965, Validation Accuracy = 0.7527, Validation Loss = 1.0092\n",
            "Epoch 2003/3334\n",
            "Epoch 2003: Training Accuracy = 0.9883, Training Loss = 0.0965, Validation Accuracy = 0.7527, Validation Loss = 1.0092\n",
            "Epoch 2004/3334\n",
            "Epoch 2004: Training Accuracy = 0.9863, Training Loss = 0.1009, Validation Accuracy = 0.7504, Validation Loss = 1.0051\n",
            "Epoch 2005/3334\n",
            "Epoch 2005: Training Accuracy = 0.9863, Training Loss = 0.1009, Validation Accuracy = 0.7504, Validation Loss = 1.0051\n",
            "Epoch 2006/3334\n",
            "Epoch 2006: Training Accuracy = 0.9863, Training Loss = 0.1009, Validation Accuracy = 0.7504, Validation Loss = 1.0051\n",
            "Epoch 2007/3334\n",
            "Epoch 2007: Training Accuracy = 0.9897, Training Loss = 0.0978, Validation Accuracy = 0.7585, Validation Loss = 1.0064\n",
            "Epoch 2008/3334\n",
            "Epoch 2008: Training Accuracy = 0.9897, Training Loss = 0.0978, Validation Accuracy = 0.7585, Validation Loss = 1.0064\n",
            "Epoch 2009/3334\n",
            "Epoch 2009: Training Accuracy = 0.9897, Training Loss = 0.0978, Validation Accuracy = 0.7585, Validation Loss = 1.0064\n",
            "Epoch 2010/3334\n",
            "Epoch 2010: Training Accuracy = 0.9897, Training Loss = 0.0978, Validation Accuracy = 0.7585, Validation Loss = 1.0064\n",
            "Epoch 2011/3334\n",
            "Epoch 2011: Training Accuracy = 0.9883, Training Loss = 0.0983, Validation Accuracy = 0.7623, Validation Loss = 0.9924\n",
            "Epoch 2012/3334\n",
            "Epoch 2012: Training Accuracy = 0.9883, Training Loss = 0.0983, Validation Accuracy = 0.7623, Validation Loss = 0.9924\n",
            "Epoch 2013/3334\n",
            "Epoch 2013: Training Accuracy = 0.9883, Training Loss = 0.0983, Validation Accuracy = 0.7623, Validation Loss = 0.9924\n",
            "Epoch 2014/3334\n",
            "Epoch 2014: Training Accuracy = 0.9893, Training Loss = 0.1200, Validation Accuracy = 0.6829, Validation Loss = 1.2204\n",
            "Epoch 2015/3334\n",
            "Epoch 2015: Training Accuracy = 0.9893, Training Loss = 0.1200, Validation Accuracy = 0.6829, Validation Loss = 1.2204\n",
            "Epoch 2016/3334\n",
            "Epoch 2016: Training Accuracy = 0.9893, Training Loss = 0.1200, Validation Accuracy = 0.6829, Validation Loss = 1.2204\n",
            "Epoch 2017/3334\n",
            "Epoch 2017: Training Accuracy = 0.8488, Training Loss = 0.9779, Validation Accuracy = 0.4548, Validation Loss = 1.9395\n",
            "Epoch 2018/3334\n",
            "Epoch 2018: Training Accuracy = 0.8488, Training Loss = 0.9779, Validation Accuracy = 0.4548, Validation Loss = 1.9395\n",
            "Epoch 2019/3334\n",
            "Epoch 2019: Training Accuracy = 0.8488, Training Loss = 0.9779, Validation Accuracy = 0.4548, Validation Loss = 1.9395\n",
            "Epoch 2020/3334\n",
            "Epoch 2020: Training Accuracy = 0.8488, Training Loss = 0.9779, Validation Accuracy = 0.4548, Validation Loss = 1.9395\n",
            "Epoch 2021/3334\n",
            "Epoch 2021: Training Accuracy = 0.9707, Training Loss = 0.3807, Validation Accuracy = 0.6566, Validation Loss = 1.2590\n",
            "Epoch 2022/3334\n",
            "Epoch 2022: Training Accuracy = 0.9707, Training Loss = 0.3807, Validation Accuracy = 0.6566, Validation Loss = 1.2590\n",
            "Epoch 2023/3334\n",
            "Epoch 2023: Training Accuracy = 0.9707, Training Loss = 0.3807, Validation Accuracy = 0.6566, Validation Loss = 1.2590\n",
            "Epoch 2024/3334\n",
            "Epoch 2024: Training Accuracy = 0.9922, Training Loss = 0.1868, Validation Accuracy = 0.7615, Validation Loss = 0.9655\n",
            "Epoch 2025/3334\n",
            "Epoch 2025: Training Accuracy = 0.9922, Training Loss = 0.1868, Validation Accuracy = 0.7615, Validation Loss = 0.9655\n",
            "Epoch 2026/3334\n",
            "Epoch 2026: Training Accuracy = 0.9922, Training Loss = 0.1868, Validation Accuracy = 0.7615, Validation Loss = 0.9655\n",
            "Epoch 2027/3334\n",
            "Epoch 2027: Training Accuracy = 0.9819, Training Loss = 0.1657, Validation Accuracy = 0.8210, Validation Loss = 0.8064\n",
            "Epoch 2028/3334\n",
            "Epoch 2028: Training Accuracy = 0.9819, Training Loss = 0.1657, Validation Accuracy = 0.8210, Validation Loss = 0.8064\n",
            "Epoch 2029/3334\n",
            "Epoch 2029: Training Accuracy = 0.9819, Training Loss = 0.1657, Validation Accuracy = 0.8210, Validation Loss = 0.8064\n",
            "Epoch 2030/3334\n",
            "Epoch 2030: Training Accuracy = 0.9819, Training Loss = 0.1657, Validation Accuracy = 0.8210, Validation Loss = 0.8064\n",
            "Epoch 2031/3334\n",
            "Epoch 2031: Training Accuracy = 0.9863, Training Loss = 0.1196, Validation Accuracy = 0.8448, Validation Loss = 0.7312\n",
            "Epoch 2032/3334\n",
            "Epoch 2032: Training Accuracy = 0.9863, Training Loss = 0.1196, Validation Accuracy = 0.8448, Validation Loss = 0.7312\n",
            "Epoch 2033/3334\n",
            "Epoch 2033: Training Accuracy = 0.9863, Training Loss = 0.1196, Validation Accuracy = 0.8448, Validation Loss = 0.7312\n",
            "Epoch 2034/3334\n",
            "Epoch 2034: Training Accuracy = 0.9854, Training Loss = 0.1161, Validation Accuracy = 0.8558, Validation Loss = 0.7021\n",
            "Epoch 2035/3334\n",
            "Epoch 2035: Training Accuracy = 0.9854, Training Loss = 0.1161, Validation Accuracy = 0.8558, Validation Loss = 0.7021\n",
            "Epoch 2036/3334\n",
            "Epoch 2036: Training Accuracy = 0.9854, Training Loss = 0.1161, Validation Accuracy = 0.8558, Validation Loss = 0.7021\n",
            "Epoch 2037/3334\n",
            "Epoch 2037: Training Accuracy = 0.9884, Training Loss = 0.0988, Validation Accuracy = 0.8687, Validation Loss = 0.6734\n",
            "Epoch 2038/3334\n",
            "Epoch 2038: Training Accuracy = 0.9884, Training Loss = 0.0988, Validation Accuracy = 0.8687, Validation Loss = 0.6734\n",
            "Epoch 2039/3334\n",
            "Epoch 2039: Training Accuracy = 0.9884, Training Loss = 0.0988, Validation Accuracy = 0.8687, Validation Loss = 0.6734\n",
            "Epoch 2040/3334\n",
            "Epoch 2040: Training Accuracy = 0.9884, Training Loss = 0.0988, Validation Accuracy = 0.8687, Validation Loss = 0.6734\n",
            "Epoch 2041/3334\n",
            "Epoch 2041: Training Accuracy = 0.9883, Training Loss = 0.0950, Validation Accuracy = 0.8693, Validation Loss = 0.6698\n",
            "Epoch 2042/3334\n",
            "Epoch 2042: Training Accuracy = 0.9883, Training Loss = 0.0950, Validation Accuracy = 0.8693, Validation Loss = 0.6698\n",
            "Epoch 2043/3334\n",
            "Epoch 2043: Training Accuracy = 0.9883, Training Loss = 0.0950, Validation Accuracy = 0.8693, Validation Loss = 0.6698\n",
            "Epoch 2044/3334\n",
            "Epoch 2044: Training Accuracy = 0.9922, Training Loss = 0.0797, Validation Accuracy = 0.8746, Validation Loss = 0.6579\n",
            "Epoch 2045/3334\n",
            "Epoch 2045: Training Accuracy = 0.9922, Training Loss = 0.0797, Validation Accuracy = 0.8746, Validation Loss = 0.6579\n",
            "Epoch 2046/3334\n",
            "Epoch 2046: Training Accuracy = 0.9922, Training Loss = 0.0797, Validation Accuracy = 0.8746, Validation Loss = 0.6579\n",
            "Epoch 2047/3334\n",
            "Epoch 2047: Training Accuracy = 0.9884, Training Loss = 0.0950, Validation Accuracy = 0.8781, Validation Loss = 0.6621\n",
            "Epoch 2048/3334\n",
            "Epoch 2048: Training Accuracy = 0.9884, Training Loss = 0.0950, Validation Accuracy = 0.8781, Validation Loss = 0.6621\n",
            "Epoch 2049/3334\n",
            "Epoch 2049: Training Accuracy = 0.9884, Training Loss = 0.0950, Validation Accuracy = 0.8781, Validation Loss = 0.6621\n",
            "Epoch 2050/3334\n",
            "Epoch 2050: Training Accuracy = 0.9884, Training Loss = 0.0950, Validation Accuracy = 0.8781, Validation Loss = 0.6621\n",
            "Epoch 2051/3334\n",
            "Epoch 2051: Training Accuracy = 0.9951, Training Loss = 0.0685, Validation Accuracy = 0.8878, Validation Loss = 0.6365\n",
            "Epoch 2052/3334\n",
            "Epoch 2052: Training Accuracy = 0.9951, Training Loss = 0.0685, Validation Accuracy = 0.8878, Validation Loss = 0.6365\n",
            "Epoch 2053/3334\n",
            "Epoch 2053: Training Accuracy = 0.9951, Training Loss = 0.0685, Validation Accuracy = 0.8878, Validation Loss = 0.6365\n",
            "Epoch 2054/3334\n",
            "Epoch 2054: Training Accuracy = 0.9912, Training Loss = 0.0792, Validation Accuracy = 0.8902, Validation Loss = 0.6305\n",
            "Epoch 2055/3334\n",
            "Epoch 2055: Training Accuracy = 0.9912, Training Loss = 0.0792, Validation Accuracy = 0.8902, Validation Loss = 0.6305\n",
            "Epoch 2056/3334\n",
            "Epoch 2056: Training Accuracy = 0.9912, Training Loss = 0.0792, Validation Accuracy = 0.8902, Validation Loss = 0.6305\n",
            "Epoch 2057/3334\n",
            "Epoch 2057: Training Accuracy = 0.9935, Training Loss = 0.0742, Validation Accuracy = 0.8987, Validation Loss = 0.6189\n",
            "Epoch 2058/3334\n",
            "Epoch 2058: Training Accuracy = 0.9935, Training Loss = 0.0742, Validation Accuracy = 0.8987, Validation Loss = 0.6189\n",
            "Epoch 2059/3334\n",
            "Epoch 2059: Training Accuracy = 0.9935, Training Loss = 0.0742, Validation Accuracy = 0.8987, Validation Loss = 0.6189\n",
            "Epoch 2060/3334\n",
            "Epoch 2060: Training Accuracy = 0.9935, Training Loss = 0.0742, Validation Accuracy = 0.8987, Validation Loss = 0.6189\n",
            "Epoch 2061/3334\n",
            "Epoch 2061: Training Accuracy = 0.2939, Training Loss = 3.1523, Validation Accuracy = 0.1251, Validation Loss = 3.6005\n",
            "Epoch 2062/3334\n",
            "Epoch 2062: Training Accuracy = 0.2939, Training Loss = 3.1523, Validation Accuracy = 0.1251, Validation Loss = 3.6005\n",
            "Epoch 2063/3334\n",
            "Epoch 2063: Training Accuracy = 0.2939, Training Loss = 3.1523, Validation Accuracy = 0.1251, Validation Loss = 3.6005\n",
            "Epoch 2064/3334\n",
            "Epoch 2064: Training Accuracy = 0.8984, Training Loss = 0.7929, Validation Accuracy = 0.6211, Validation Loss = 1.4672\n",
            "Epoch 2065/3334\n",
            "Epoch 2065: Training Accuracy = 0.8984, Training Loss = 0.7929, Validation Accuracy = 0.6211, Validation Loss = 1.4672\n",
            "Epoch 2066/3334\n",
            "Epoch 2066: Training Accuracy = 0.8984, Training Loss = 0.7929, Validation Accuracy = 0.6211, Validation Loss = 1.4672\n",
            "Epoch 2067/3334\n",
            "Epoch 2067: Training Accuracy = 0.9845, Training Loss = 0.3145, Validation Accuracy = 0.8339, Validation Loss = 0.8805\n",
            "Epoch 2068/3334\n",
            "Epoch 2068: Training Accuracy = 0.9845, Training Loss = 0.3145, Validation Accuracy = 0.8339, Validation Loss = 0.8805\n",
            "Epoch 2069/3334\n",
            "Epoch 2069: Training Accuracy = 0.9845, Training Loss = 0.3145, Validation Accuracy = 0.8339, Validation Loss = 0.8805\n",
            "Epoch 2070/3334\n",
            "Epoch 2070: Training Accuracy = 0.9845, Training Loss = 0.3145, Validation Accuracy = 0.8339, Validation Loss = 0.8805\n",
            "Epoch 2071/3334\n",
            "Epoch 2071: Training Accuracy = 0.9873, Training Loss = 0.1872, Validation Accuracy = 0.8928, Validation Loss = 0.6555\n",
            "Epoch 2072/3334\n",
            "Epoch 2072: Training Accuracy = 0.9873, Training Loss = 0.1872, Validation Accuracy = 0.8928, Validation Loss = 0.6555\n",
            "Epoch 2073/3334\n",
            "Epoch 2073: Training Accuracy = 0.9873, Training Loss = 0.1872, Validation Accuracy = 0.8928, Validation Loss = 0.6555\n",
            "Epoch 2074/3334\n",
            "Epoch 2074: Training Accuracy = 0.9863, Training Loss = 0.1388, Validation Accuracy = 0.9279, Validation Loss = 0.5185\n",
            "Epoch 2075/3334\n",
            "Epoch 2075: Training Accuracy = 0.9863, Training Loss = 0.1388, Validation Accuracy = 0.9279, Validation Loss = 0.5185\n",
            "Epoch 2076/3334\n",
            "Epoch 2076: Training Accuracy = 0.9863, Training Loss = 0.1388, Validation Accuracy = 0.9279, Validation Loss = 0.5185\n",
            "Epoch 2077/3334\n",
            "Epoch 2077: Training Accuracy = 0.9910, Training Loss = 0.1056, Validation Accuracy = 0.9364, Validation Loss = 0.4722\n",
            "Epoch 2078/3334\n",
            "Epoch 2078: Training Accuracy = 0.9910, Training Loss = 0.1056, Validation Accuracy = 0.9364, Validation Loss = 0.4722\n",
            "Epoch 2079/3334\n",
            "Epoch 2079: Training Accuracy = 0.9910, Training Loss = 0.1056, Validation Accuracy = 0.9364, Validation Loss = 0.4722\n",
            "Epoch 2080/3334\n",
            "Epoch 2080: Training Accuracy = 0.9910, Training Loss = 0.1056, Validation Accuracy = 0.9364, Validation Loss = 0.4722\n",
            "Epoch 2081/3334\n",
            "Epoch 2081: Training Accuracy = 0.9893, Training Loss = 0.0989, Validation Accuracy = 0.9425, Validation Loss = 0.4497\n",
            "Epoch 2082/3334\n",
            "Epoch 2082: Training Accuracy = 0.9893, Training Loss = 0.0989, Validation Accuracy = 0.9425, Validation Loss = 0.4497\n",
            "Epoch 2083/3334\n",
            "Epoch 2083: Training Accuracy = 0.9893, Training Loss = 0.0989, Validation Accuracy = 0.9425, Validation Loss = 0.4497\n",
            "Epoch 2084/3334\n",
            "Epoch 2084: Training Accuracy = 0.9893, Training Loss = 0.0957, Validation Accuracy = 0.9444, Validation Loss = 0.4351\n",
            "Epoch 2085/3334\n",
            "Epoch 2085: Training Accuracy = 0.9893, Training Loss = 0.0957, Validation Accuracy = 0.9444, Validation Loss = 0.4351\n",
            "Epoch 2086/3334\n",
            "Epoch 2086: Training Accuracy = 0.9893, Training Loss = 0.0957, Validation Accuracy = 0.9444, Validation Loss = 0.4351\n",
            "Epoch 2087/3334\n",
            "Epoch 2087: Training Accuracy = 0.9884, Training Loss = 0.0972, Validation Accuracy = 0.9470, Validation Loss = 0.4277\n",
            "Epoch 2088/3334\n",
            "Epoch 2088: Training Accuracy = 0.9884, Training Loss = 0.0972, Validation Accuracy = 0.9470, Validation Loss = 0.4277\n",
            "Epoch 2089/3334\n",
            "Epoch 2089: Training Accuracy = 0.9884, Training Loss = 0.0972, Validation Accuracy = 0.9470, Validation Loss = 0.4277\n",
            "Epoch 2090/3334\n",
            "Epoch 2090: Training Accuracy = 0.9884, Training Loss = 0.0972, Validation Accuracy = 0.9470, Validation Loss = 0.4277\n",
            "Epoch 2091/3334\n",
            "Epoch 2091: Training Accuracy = 0.9893, Training Loss = 0.0923, Validation Accuracy = 0.9493, Validation Loss = 0.4239\n",
            "Epoch 2092/3334\n",
            "Epoch 2092: Training Accuracy = 0.9893, Training Loss = 0.0923, Validation Accuracy = 0.9493, Validation Loss = 0.4239\n",
            "Epoch 2093/3334\n",
            "Epoch 2093: Training Accuracy = 0.9893, Training Loss = 0.0923, Validation Accuracy = 0.9493, Validation Loss = 0.4239\n",
            "Epoch 2094/3334\n",
            "Epoch 2094: Training Accuracy = 0.9854, Training Loss = 0.1033, Validation Accuracy = 0.9499, Validation Loss = 0.4173\n",
            "Epoch 2095/3334\n",
            "Epoch 2095: Training Accuracy = 0.9854, Training Loss = 0.1033, Validation Accuracy = 0.9499, Validation Loss = 0.4173\n",
            "Epoch 2096/3334\n",
            "Epoch 2096: Training Accuracy = 0.9854, Training Loss = 0.1033, Validation Accuracy = 0.9499, Validation Loss = 0.4173\n",
            "Epoch 2097/3334\n",
            "Epoch 2097: Training Accuracy = 0.9806, Training Loss = 0.1200, Validation Accuracy = 0.9522, Validation Loss = 0.4166\n",
            "Epoch 2098/3334\n",
            "Epoch 2098: Training Accuracy = 0.9806, Training Loss = 0.1200, Validation Accuracy = 0.9522, Validation Loss = 0.4166\n",
            "Epoch 2099/3334\n",
            "Epoch 2099: Training Accuracy = 0.9806, Training Loss = 0.1200, Validation Accuracy = 0.9522, Validation Loss = 0.4166\n",
            "Epoch 2100/3334\n",
            "Epoch 2100: Training Accuracy = 0.9806, Training Loss = 0.1200, Validation Accuracy = 0.9522, Validation Loss = 0.4166\n",
            "Epoch 2101/3334\n",
            "Epoch 2101: Training Accuracy = 0.9902, Training Loss = 0.0846, Validation Accuracy = 0.9493, Validation Loss = 0.4100\n",
            "Epoch 2102/3334\n",
            "Epoch 2102: Training Accuracy = 0.9902, Training Loss = 0.0846, Validation Accuracy = 0.9493, Validation Loss = 0.4100\n",
            "Epoch 2103/3334\n",
            "Epoch 2103: Training Accuracy = 0.9902, Training Loss = 0.0846, Validation Accuracy = 0.9493, Validation Loss = 0.4100\n",
            "Epoch 2104/3334\n",
            "Epoch 2104: Training Accuracy = 0.9893, Training Loss = 0.0861, Validation Accuracy = 0.9567, Validation Loss = 0.3964\n",
            "Epoch 2105/3334\n",
            "Epoch 2105: Training Accuracy = 0.9893, Training Loss = 0.0861, Validation Accuracy = 0.9567, Validation Loss = 0.3964\n",
            "Epoch 2106/3334\n",
            "Epoch 2106: Training Accuracy = 0.9893, Training Loss = 0.0861, Validation Accuracy = 0.9567, Validation Loss = 0.3964\n",
            "Epoch 2107/3334\n",
            "Epoch 2107: Training Accuracy = 0.9897, Training Loss = 0.0844, Validation Accuracy = 0.9535, Validation Loss = 0.4042\n",
            "Epoch 2108/3334\n",
            "Epoch 2108: Training Accuracy = 0.9897, Training Loss = 0.0844, Validation Accuracy = 0.9535, Validation Loss = 0.4042\n",
            "Epoch 2109/3334\n",
            "Epoch 2109: Training Accuracy = 0.9897, Training Loss = 0.0844, Validation Accuracy = 0.9535, Validation Loss = 0.4042\n",
            "Epoch 2110/3334\n",
            "Epoch 2110: Training Accuracy = 0.9897, Training Loss = 0.0844, Validation Accuracy = 0.9535, Validation Loss = 0.4042\n",
            "Epoch 2111/3334\n",
            "Epoch 2111: Training Accuracy = 0.9912, Training Loss = 0.0810, Validation Accuracy = 0.9538, Validation Loss = 0.3868\n",
            "Epoch 2112/3334\n",
            "Epoch 2112: Training Accuracy = 0.9912, Training Loss = 0.0810, Validation Accuracy = 0.9538, Validation Loss = 0.3868\n",
            "Epoch 2113/3334\n",
            "Epoch 2113: Training Accuracy = 0.9912, Training Loss = 0.0810, Validation Accuracy = 0.9538, Validation Loss = 0.3868\n",
            "Epoch 2114/3334\n",
            "Epoch 2114: Training Accuracy = 0.4033, Training Loss = 2.1959, Validation Accuracy = 0.1413, Validation Loss = 3.5705\n",
            "Epoch 2115/3334\n",
            "Epoch 2115: Training Accuracy = 0.4033, Training Loss = 2.1959, Validation Accuracy = 0.1413, Validation Loss = 3.5705\n",
            "Epoch 2116/3334\n",
            "Epoch 2116: Training Accuracy = 0.4033, Training Loss = 2.1959, Validation Accuracy = 0.1413, Validation Loss = 3.5705\n",
            "Epoch 2117/3334\n",
            "Epoch 2117: Training Accuracy = 0.8992, Training Loss = 0.7051, Validation Accuracy = 0.7349, Validation Loss = 1.1586\n",
            "Epoch 2118/3334\n",
            "Epoch 2118: Training Accuracy = 0.8992, Training Loss = 0.7051, Validation Accuracy = 0.7349, Validation Loss = 1.1586\n",
            "Epoch 2119/3334\n",
            "Epoch 2119: Training Accuracy = 0.8992, Training Loss = 0.7051, Validation Accuracy = 0.7349, Validation Loss = 1.1586\n",
            "Epoch 2120/3334\n",
            "Epoch 2120: Training Accuracy = 0.8992, Training Loss = 0.7051, Validation Accuracy = 0.7349, Validation Loss = 1.1586\n",
            "Epoch 2121/3334\n",
            "Epoch 2121: Training Accuracy = 0.9863, Training Loss = 0.2569, Validation Accuracy = 0.9118, Validation Loss = 0.6556\n",
            "Epoch 2122/3334\n",
            "Epoch 2122: Training Accuracy = 0.9863, Training Loss = 0.2569, Validation Accuracy = 0.9118, Validation Loss = 0.6556\n",
            "Epoch 2123/3334\n",
            "Epoch 2123: Training Accuracy = 0.9863, Training Loss = 0.2569, Validation Accuracy = 0.9118, Validation Loss = 0.6556\n",
            "Epoch 2124/3334\n",
            "Epoch 2124: Training Accuracy = 0.9883, Training Loss = 0.1524, Validation Accuracy = 0.9476, Validation Loss = 0.4647\n",
            "Epoch 2125/3334\n",
            "Epoch 2125: Training Accuracy = 0.9883, Training Loss = 0.1524, Validation Accuracy = 0.9476, Validation Loss = 0.4647\n",
            "Epoch 2126/3334\n",
            "Epoch 2126: Training Accuracy = 0.9883, Training Loss = 0.1524, Validation Accuracy = 0.9476, Validation Loss = 0.4647\n",
            "Epoch 2127/3334\n",
            "Epoch 2127: Training Accuracy = 0.9922, Training Loss = 0.1029, Validation Accuracy = 0.9610, Validation Loss = 0.3707\n",
            "Epoch 2128/3334\n",
            "Epoch 2128: Training Accuracy = 0.9922, Training Loss = 0.1029, Validation Accuracy = 0.9610, Validation Loss = 0.3707\n",
            "Epoch 2129/3334\n",
            "Epoch 2129: Training Accuracy = 0.9922, Training Loss = 0.1029, Validation Accuracy = 0.9610, Validation Loss = 0.3707\n",
            "Epoch 2130/3334\n",
            "Epoch 2130: Training Accuracy = 0.9922, Training Loss = 0.1029, Validation Accuracy = 0.9610, Validation Loss = 0.3707\n",
            "Epoch 2131/3334\n",
            "Epoch 2131: Training Accuracy = 0.9824, Training Loss = 0.1195, Validation Accuracy = 0.9640, Validation Loss = 0.3324\n",
            "Epoch 2132/3334\n",
            "Epoch 2132: Training Accuracy = 0.9824, Training Loss = 0.1195, Validation Accuracy = 0.9640, Validation Loss = 0.3324\n",
            "Epoch 2133/3334\n",
            "Epoch 2133: Training Accuracy = 0.9824, Training Loss = 0.1195, Validation Accuracy = 0.9640, Validation Loss = 0.3324\n",
            "Epoch 2134/3334\n",
            "Epoch 2134: Training Accuracy = 0.9893, Training Loss = 0.0918, Validation Accuracy = 0.9639, Validation Loss = 0.3200\n",
            "Epoch 2135/3334\n",
            "Epoch 2135: Training Accuracy = 0.9893, Training Loss = 0.0918, Validation Accuracy = 0.9639, Validation Loss = 0.3200\n",
            "Epoch 2136/3334\n",
            "Epoch 2136: Training Accuracy = 0.9893, Training Loss = 0.0918, Validation Accuracy = 0.9639, Validation Loss = 0.3200\n",
            "Epoch 2137/3334\n",
            "Epoch 2137: Training Accuracy = 0.9897, Training Loss = 0.0913, Validation Accuracy = 0.9657, Validation Loss = 0.3130\n",
            "Epoch 2138/3334\n",
            "Epoch 2138: Training Accuracy = 0.9897, Training Loss = 0.0913, Validation Accuracy = 0.9657, Validation Loss = 0.3130\n",
            "Epoch 2139/3334\n",
            "Epoch 2139: Training Accuracy = 0.9897, Training Loss = 0.0913, Validation Accuracy = 0.9657, Validation Loss = 0.3130\n",
            "Epoch 2140/3334\n",
            "Epoch 2140: Training Accuracy = 0.9897, Training Loss = 0.0913, Validation Accuracy = 0.9657, Validation Loss = 0.3130\n",
            "Epoch 2141/3334\n",
            "Epoch 2141: Training Accuracy = 0.9902, Training Loss = 0.0854, Validation Accuracy = 0.9655, Validation Loss = 0.3095\n",
            "Epoch 2142/3334\n",
            "Epoch 2142: Training Accuracy = 0.9902, Training Loss = 0.0854, Validation Accuracy = 0.9655, Validation Loss = 0.3095\n",
            "Epoch 2143/3334\n",
            "Epoch 2143: Training Accuracy = 0.9902, Training Loss = 0.0854, Validation Accuracy = 0.9655, Validation Loss = 0.3095\n",
            "Epoch 2144/3334\n",
            "Epoch 2144: Training Accuracy = 0.9883, Training Loss = 0.0902, Validation Accuracy = 0.9669, Validation Loss = 0.3073\n",
            "Epoch 2145/3334\n",
            "Epoch 2145: Training Accuracy = 0.9883, Training Loss = 0.0902, Validation Accuracy = 0.9669, Validation Loss = 0.3073\n",
            "Epoch 2146/3334\n",
            "Epoch 2146: Training Accuracy = 0.9883, Training Loss = 0.0902, Validation Accuracy = 0.9669, Validation Loss = 0.3073\n",
            "Epoch 2147/3334\n",
            "Epoch 2147: Training Accuracy = 0.9871, Training Loss = 0.0948, Validation Accuracy = 0.9663, Validation Loss = 0.3021\n",
            "Epoch 2148/3334\n",
            "Epoch 2148: Training Accuracy = 0.9871, Training Loss = 0.0948, Validation Accuracy = 0.9663, Validation Loss = 0.3021\n",
            "Epoch 2149/3334\n",
            "Epoch 2149: Training Accuracy = 0.9871, Training Loss = 0.0948, Validation Accuracy = 0.9663, Validation Loss = 0.3021\n",
            "Epoch 2150/3334\n",
            "Epoch 2150: Training Accuracy = 0.9871, Training Loss = 0.0948, Validation Accuracy = 0.9663, Validation Loss = 0.3021\n",
            "Epoch 2151/3334\n",
            "Epoch 2151: Training Accuracy = 0.9883, Training Loss = 0.0903, Validation Accuracy = 0.9666, Validation Loss = 0.3013\n",
            "Epoch 2152/3334\n",
            "Epoch 2152: Training Accuracy = 0.9883, Training Loss = 0.0903, Validation Accuracy = 0.9666, Validation Loss = 0.3013\n",
            "Epoch 2153/3334\n",
            "Epoch 2153: Training Accuracy = 0.9883, Training Loss = 0.0903, Validation Accuracy = 0.9666, Validation Loss = 0.3013\n",
            "Epoch 2154/3334\n",
            "Epoch 2154: Training Accuracy = 0.9854, Training Loss = 0.0966, Validation Accuracy = 0.9668, Validation Loss = 0.2991\n",
            "Epoch 2155/3334\n",
            "Epoch 2155: Training Accuracy = 0.9854, Training Loss = 0.0966, Validation Accuracy = 0.9668, Validation Loss = 0.2991\n",
            "Epoch 2156/3334\n",
            "Epoch 2156: Training Accuracy = 0.9854, Training Loss = 0.0966, Validation Accuracy = 0.9668, Validation Loss = 0.2991\n",
            "Epoch 2157/3334\n",
            "Epoch 2157: Training Accuracy = 0.9884, Training Loss = 0.0891, Validation Accuracy = 0.9675, Validation Loss = 0.2910\n",
            "Epoch 2158/3334\n",
            "Epoch 2158: Training Accuracy = 0.9884, Training Loss = 0.0891, Validation Accuracy = 0.9675, Validation Loss = 0.2910\n",
            "Epoch 2159/3334\n",
            "Epoch 2159: Training Accuracy = 0.9884, Training Loss = 0.0891, Validation Accuracy = 0.9675, Validation Loss = 0.2910\n",
            "Epoch 2160/3334\n",
            "Epoch 2160: Training Accuracy = 0.9884, Training Loss = 0.0891, Validation Accuracy = 0.9675, Validation Loss = 0.2910\n",
            "Epoch 2161/3334\n",
            "Epoch 2161: Training Accuracy = 0.9863, Training Loss = 0.0927, Validation Accuracy = 0.9686, Validation Loss = 0.2933\n",
            "Epoch 2162/3334\n",
            "Epoch 2162: Training Accuracy = 0.9863, Training Loss = 0.0927, Validation Accuracy = 0.9686, Validation Loss = 0.2933\n",
            "Epoch 2163/3334\n",
            "Epoch 2163: Training Accuracy = 0.9863, Training Loss = 0.0927, Validation Accuracy = 0.9686, Validation Loss = 0.2933\n",
            "Epoch 2164/3334\n",
            "Epoch 2164: Training Accuracy = 0.9883, Training Loss = 0.0946, Validation Accuracy = 0.9645, Validation Loss = 0.3271\n",
            "Epoch 2165/3334\n",
            "Epoch 2165: Training Accuracy = 0.9883, Training Loss = 0.0946, Validation Accuracy = 0.9645, Validation Loss = 0.3271\n",
            "Epoch 2166/3334\n",
            "Epoch 2166: Training Accuracy = 0.9883, Training Loss = 0.0946, Validation Accuracy = 0.9645, Validation Loss = 0.3271\n",
            "Epoch 2167/3334\n",
            "Epoch 2167: Training Accuracy = 0.5775, Training Loss = 1.7833, Validation Accuracy = 0.4009, Validation Loss = 2.3423\n",
            "Epoch 2168/3334\n",
            "Epoch 2168: Training Accuracy = 0.5775, Training Loss = 1.7833, Validation Accuracy = 0.4009, Validation Loss = 2.3423\n",
            "Epoch 2169/3334\n",
            "Epoch 2169: Training Accuracy = 0.5775, Training Loss = 1.7833, Validation Accuracy = 0.4009, Validation Loss = 2.3423\n",
            "Epoch 2170/3334\n",
            "Epoch 2170: Training Accuracy = 0.5775, Training Loss = 1.7833, Validation Accuracy = 0.4009, Validation Loss = 2.3423\n",
            "Epoch 2171/3334\n",
            "Epoch 2171: Training Accuracy = 0.9551, Training Loss = 0.4491, Validation Accuracy = 0.8533, Validation Loss = 0.8382\n",
            "Epoch 2172/3334\n",
            "Epoch 2172: Training Accuracy = 0.9551, Training Loss = 0.4491, Validation Accuracy = 0.8533, Validation Loss = 0.8382\n",
            "Epoch 2173/3334\n",
            "Epoch 2173: Training Accuracy = 0.9551, Training Loss = 0.4491, Validation Accuracy = 0.8533, Validation Loss = 0.8382\n",
            "Epoch 2174/3334\n",
            "Epoch 2174: Training Accuracy = 0.9854, Training Loss = 0.2502, Validation Accuracy = 0.9428, Validation Loss = 0.5159\n",
            "Epoch 2175/3334\n",
            "Epoch 2175: Training Accuracy = 0.9854, Training Loss = 0.2502, Validation Accuracy = 0.9428, Validation Loss = 0.5159\n",
            "Epoch 2176/3334\n",
            "Epoch 2176: Training Accuracy = 0.9854, Training Loss = 0.2502, Validation Accuracy = 0.9428, Validation Loss = 0.5159\n",
            "Epoch 2177/3334\n",
            "Epoch 2177: Training Accuracy = 0.9845, Training Loss = 0.1599, Validation Accuracy = 0.9616, Validation Loss = 0.3702\n",
            "Epoch 2178/3334\n",
            "Epoch 2178: Training Accuracy = 0.9845, Training Loss = 0.1599, Validation Accuracy = 0.9616, Validation Loss = 0.3702\n",
            "Epoch 2179/3334\n",
            "Epoch 2179: Training Accuracy = 0.9845, Training Loss = 0.1599, Validation Accuracy = 0.9616, Validation Loss = 0.3702\n",
            "Epoch 2180/3334\n",
            "Epoch 2180: Training Accuracy = 0.9845, Training Loss = 0.1599, Validation Accuracy = 0.9616, Validation Loss = 0.3702\n",
            "Epoch 2181/3334\n",
            "Epoch 2181: Training Accuracy = 0.9932, Training Loss = 0.0931, Validation Accuracy = 0.9683, Validation Loss = 0.2989\n",
            "Epoch 2182/3334\n",
            "Epoch 2182: Training Accuracy = 0.9932, Training Loss = 0.0931, Validation Accuracy = 0.9683, Validation Loss = 0.2989\n",
            "Epoch 2183/3334\n",
            "Epoch 2183: Training Accuracy = 0.9932, Training Loss = 0.0931, Validation Accuracy = 0.9683, Validation Loss = 0.2989\n",
            "Epoch 2184/3334\n",
            "Epoch 2184: Training Accuracy = 0.9902, Training Loss = 0.0888, Validation Accuracy = 0.9698, Validation Loss = 0.2723\n",
            "Epoch 2185/3334\n",
            "Epoch 2185: Training Accuracy = 0.9902, Training Loss = 0.0888, Validation Accuracy = 0.9698, Validation Loss = 0.2723\n",
            "Epoch 2186/3334\n",
            "Epoch 2186: Training Accuracy = 0.9902, Training Loss = 0.0888, Validation Accuracy = 0.9698, Validation Loss = 0.2723\n",
            "Epoch 2187/3334\n",
            "Epoch 2187: Training Accuracy = 0.9858, Training Loss = 0.1014, Validation Accuracy = 0.9698, Validation Loss = 0.2569\n",
            "Epoch 2188/3334\n",
            "Epoch 2188: Training Accuracy = 0.9858, Training Loss = 0.1014, Validation Accuracy = 0.9698, Validation Loss = 0.2569\n",
            "Epoch 2189/3334\n",
            "Epoch 2189: Training Accuracy = 0.9858, Training Loss = 0.1014, Validation Accuracy = 0.9698, Validation Loss = 0.2569\n",
            "Epoch 2190/3334\n",
            "Epoch 2190: Training Accuracy = 0.9858, Training Loss = 0.1014, Validation Accuracy = 0.9698, Validation Loss = 0.2569\n",
            "Epoch 2191/3334\n",
            "Epoch 2191: Training Accuracy = 0.9902, Training Loss = 0.0819, Validation Accuracy = 0.9699, Validation Loss = 0.2504\n",
            "Epoch 2192/3334\n",
            "Epoch 2192: Training Accuracy = 0.9902, Training Loss = 0.0819, Validation Accuracy = 0.9699, Validation Loss = 0.2504\n",
            "Epoch 2193/3334\n",
            "Epoch 2193: Training Accuracy = 0.9902, Training Loss = 0.0819, Validation Accuracy = 0.9699, Validation Loss = 0.2504\n",
            "Epoch 2194/3334\n",
            "Epoch 2194: Training Accuracy = 0.9893, Training Loss = 0.0846, Validation Accuracy = 0.9705, Validation Loss = 0.2451\n",
            "Epoch 2195/3334\n",
            "Epoch 2195: Training Accuracy = 0.9893, Training Loss = 0.0846, Validation Accuracy = 0.9705, Validation Loss = 0.2451\n",
            "Epoch 2196/3334\n",
            "Epoch 2196: Training Accuracy = 0.9893, Training Loss = 0.0846, Validation Accuracy = 0.9705, Validation Loss = 0.2451\n",
            "Epoch 2197/3334\n",
            "Epoch 2197: Training Accuracy = 0.9871, Training Loss = 0.0939, Validation Accuracy = 0.9702, Validation Loss = 0.2448\n",
            "Epoch 2198/3334\n",
            "Epoch 2198: Training Accuracy = 0.9871, Training Loss = 0.0939, Validation Accuracy = 0.9702, Validation Loss = 0.2448\n",
            "Epoch 2199/3334\n",
            "Epoch 2199: Training Accuracy = 0.9871, Training Loss = 0.0939, Validation Accuracy = 0.9702, Validation Loss = 0.2448\n",
            "Epoch 2200/3334\n",
            "Epoch 2200: Training Accuracy = 0.9871, Training Loss = 0.0939, Validation Accuracy = 0.9702, Validation Loss = 0.2448\n",
            "Epoch 2201/3334\n",
            "Epoch 2201: Training Accuracy = 0.9873, Training Loss = 0.0920, Validation Accuracy = 0.9698, Validation Loss = 0.2443\n",
            "Epoch 2202/3334\n",
            "Epoch 2202: Training Accuracy = 0.9873, Training Loss = 0.0920, Validation Accuracy = 0.9698, Validation Loss = 0.2443\n",
            "Epoch 2203/3334\n",
            "Epoch 2203: Training Accuracy = 0.9873, Training Loss = 0.0920, Validation Accuracy = 0.9698, Validation Loss = 0.2443\n",
            "Epoch 2204/3334\n",
            "Epoch 2204: Training Accuracy = 0.9854, Training Loss = 0.0963, Validation Accuracy = 0.9701, Validation Loss = 0.2445\n",
            "Epoch 2205/3334\n",
            "Epoch 2205: Training Accuracy = 0.9854, Training Loss = 0.0963, Validation Accuracy = 0.9701, Validation Loss = 0.2445\n",
            "Epoch 2206/3334\n",
            "Epoch 2206: Training Accuracy = 0.9854, Training Loss = 0.0963, Validation Accuracy = 0.9701, Validation Loss = 0.2445\n",
            "Epoch 2207/3334\n",
            "Epoch 2207: Training Accuracy = 0.9858, Training Loss = 0.0970, Validation Accuracy = 0.9716, Validation Loss = 0.2493\n",
            "Epoch 2208/3334\n",
            "Epoch 2208: Training Accuracy = 0.9858, Training Loss = 0.0970, Validation Accuracy = 0.9716, Validation Loss = 0.2493\n",
            "Epoch 2209/3334\n",
            "Epoch 2209: Training Accuracy = 0.9858, Training Loss = 0.0970, Validation Accuracy = 0.9716, Validation Loss = 0.2493\n",
            "Epoch 2210/3334\n",
            "Epoch 2210: Training Accuracy = 0.9858, Training Loss = 0.0970, Validation Accuracy = 0.9716, Validation Loss = 0.2493\n",
            "Epoch 2211/3334\n",
            "Epoch 2211: Training Accuracy = 0.9863, Training Loss = 0.0998, Validation Accuracy = 0.9712, Validation Loss = 0.2454\n",
            "Epoch 2212/3334\n",
            "Epoch 2212: Training Accuracy = 0.9863, Training Loss = 0.0998, Validation Accuracy = 0.9712, Validation Loss = 0.2454\n",
            "Epoch 2213/3334\n",
            "Epoch 2213: Training Accuracy = 0.9863, Training Loss = 0.0998, Validation Accuracy = 0.9712, Validation Loss = 0.2454\n",
            "Epoch 2214/3334\n",
            "Epoch 2214: Training Accuracy = 0.9902, Training Loss = 0.0813, Validation Accuracy = 0.9707, Validation Loss = 0.2433\n",
            "Epoch 2215/3334\n",
            "Epoch 2215: Training Accuracy = 0.9902, Training Loss = 0.0813, Validation Accuracy = 0.9707, Validation Loss = 0.2433\n",
            "Epoch 2216/3334\n",
            "Epoch 2216: Training Accuracy = 0.9902, Training Loss = 0.0813, Validation Accuracy = 0.9707, Validation Loss = 0.2433\n",
            "Epoch 2217/3334\n",
            "Epoch 2217: Training Accuracy = 0.2313, Training Loss = 3.4152, Validation Accuracy = 0.3534, Validation Loss = 2.8415\n",
            "Epoch 2218/3334\n",
            "Epoch 2218: Training Accuracy = 0.2313, Training Loss = 3.4152, Validation Accuracy = 0.3534, Validation Loss = 2.8415\n",
            "Epoch 2219/3334\n",
            "Epoch 2219: Training Accuracy = 0.2313, Training Loss = 3.4152, Validation Accuracy = 0.3534, Validation Loss = 2.8415\n",
            "Epoch 2220/3334\n",
            "Epoch 2220: Training Accuracy = 0.2313, Training Loss = 3.4152, Validation Accuracy = 0.3534, Validation Loss = 2.8415\n",
            "Epoch 2221/3334\n",
            "Epoch 2221: Training Accuracy = 0.9229, Training Loss = 0.5954, Validation Accuracy = 0.8253, Validation Loss = 0.9004\n",
            "Epoch 2222/3334\n",
            "Epoch 2222: Training Accuracy = 0.9229, Training Loss = 0.5954, Validation Accuracy = 0.8253, Validation Loss = 0.9004\n",
            "Epoch 2223/3334\n",
            "Epoch 2223: Training Accuracy = 0.9229, Training Loss = 0.5954, Validation Accuracy = 0.8253, Validation Loss = 0.9004\n",
            "Epoch 2224/3334\n",
            "Epoch 2224: Training Accuracy = 0.9883, Training Loss = 0.2476, Validation Accuracy = 0.9347, Validation Loss = 0.5221\n",
            "Epoch 2225/3334\n",
            "Epoch 2225: Training Accuracy = 0.9883, Training Loss = 0.2476, Validation Accuracy = 0.9347, Validation Loss = 0.5221\n",
            "Epoch 2226/3334\n",
            "Epoch 2226: Training Accuracy = 0.9883, Training Loss = 0.2476, Validation Accuracy = 0.9347, Validation Loss = 0.5221\n",
            "Epoch 2227/3334\n",
            "Epoch 2227: Training Accuracy = 0.9806, Training Loss = 0.1860, Validation Accuracy = 0.9633, Validation Loss = 0.3472\n",
            "Epoch 2228/3334\n",
            "Epoch 2228: Training Accuracy = 0.9806, Training Loss = 0.1860, Validation Accuracy = 0.9633, Validation Loss = 0.3472\n",
            "Epoch 2229/3334\n",
            "Epoch 2229: Training Accuracy = 0.9806, Training Loss = 0.1860, Validation Accuracy = 0.9633, Validation Loss = 0.3472\n",
            "Epoch 2230/3334\n",
            "Epoch 2230: Training Accuracy = 0.9806, Training Loss = 0.1860, Validation Accuracy = 0.9633, Validation Loss = 0.3472\n",
            "Epoch 2231/3334\n",
            "Epoch 2231: Training Accuracy = 0.9902, Training Loss = 0.1055, Validation Accuracy = 0.9686, Validation Loss = 0.2749\n",
            "Epoch 2232/3334\n",
            "Epoch 2232: Training Accuracy = 0.9902, Training Loss = 0.1055, Validation Accuracy = 0.9686, Validation Loss = 0.2749\n",
            "Epoch 2233/3334\n",
            "Epoch 2233: Training Accuracy = 0.9902, Training Loss = 0.1055, Validation Accuracy = 0.9686, Validation Loss = 0.2749\n",
            "Epoch 2234/3334\n",
            "Epoch 2234: Training Accuracy = 0.9863, Training Loss = 0.1046, Validation Accuracy = 0.9710, Validation Loss = 0.2442\n",
            "Epoch 2235/3334\n",
            "Epoch 2235: Training Accuracy = 0.9863, Training Loss = 0.1046, Validation Accuracy = 0.9710, Validation Loss = 0.2442\n",
            "Epoch 2236/3334\n",
            "Epoch 2236: Training Accuracy = 0.9863, Training Loss = 0.1046, Validation Accuracy = 0.9710, Validation Loss = 0.2442\n",
            "Epoch 2237/3334\n",
            "Epoch 2237: Training Accuracy = 0.9871, Training Loss = 0.0974, Validation Accuracy = 0.9713, Validation Loss = 0.2310\n",
            "Epoch 2238/3334\n",
            "Epoch 2238: Training Accuracy = 0.9871, Training Loss = 0.0974, Validation Accuracy = 0.9713, Validation Loss = 0.2310\n",
            "Epoch 2239/3334\n",
            "Epoch 2239: Training Accuracy = 0.9871, Training Loss = 0.0974, Validation Accuracy = 0.9713, Validation Loss = 0.2310\n",
            "Epoch 2240/3334\n",
            "Epoch 2240: Training Accuracy = 0.9871, Training Loss = 0.0974, Validation Accuracy = 0.9713, Validation Loss = 0.2310\n",
            "Epoch 2241/3334\n",
            "Epoch 2241: Training Accuracy = 0.9912, Training Loss = 0.0799, Validation Accuracy = 0.9702, Validation Loss = 0.2265\n",
            "Epoch 2242/3334\n",
            "Epoch 2242: Training Accuracy = 0.9912, Training Loss = 0.0799, Validation Accuracy = 0.9702, Validation Loss = 0.2265\n",
            "Epoch 2243/3334\n",
            "Epoch 2243: Training Accuracy = 0.9912, Training Loss = 0.0799, Validation Accuracy = 0.9702, Validation Loss = 0.2265\n",
            "Epoch 2244/3334\n",
            "Epoch 2244: Training Accuracy = 0.9863, Training Loss = 0.0921, Validation Accuracy = 0.9724, Validation Loss = 0.2211\n",
            "Epoch 2245/3334\n",
            "Epoch 2245: Training Accuracy = 0.9863, Training Loss = 0.0921, Validation Accuracy = 0.9724, Validation Loss = 0.2211\n",
            "Epoch 2246/3334\n",
            "Epoch 2246: Training Accuracy = 0.9863, Training Loss = 0.0921, Validation Accuracy = 0.9724, Validation Loss = 0.2211\n",
            "Epoch 2247/3334\n",
            "Epoch 2247: Training Accuracy = 0.9884, Training Loss = 0.0867, Validation Accuracy = 0.9718, Validation Loss = 0.2197\n",
            "Epoch 2248/3334\n",
            "Epoch 2248: Training Accuracy = 0.9884, Training Loss = 0.0867, Validation Accuracy = 0.9718, Validation Loss = 0.2197\n",
            "Epoch 2249/3334\n",
            "Epoch 2249: Training Accuracy = 0.9884, Training Loss = 0.0867, Validation Accuracy = 0.9718, Validation Loss = 0.2197\n",
            "Epoch 2250/3334\n",
            "Epoch 2250: Training Accuracy = 0.9884, Training Loss = 0.0867, Validation Accuracy = 0.9718, Validation Loss = 0.2197\n",
            "Epoch 2251/3334\n",
            "Epoch 2251: Training Accuracy = 0.9922, Training Loss = 0.0708, Validation Accuracy = 0.9722, Validation Loss = 0.2184\n",
            "Epoch 2252/3334\n",
            "Epoch 2252: Training Accuracy = 0.9922, Training Loss = 0.0708, Validation Accuracy = 0.9722, Validation Loss = 0.2184\n",
            "Epoch 2253/3334\n",
            "Epoch 2253: Training Accuracy = 0.9922, Training Loss = 0.0708, Validation Accuracy = 0.9722, Validation Loss = 0.2184\n",
            "Epoch 2254/3334\n",
            "Epoch 2254: Training Accuracy = 0.9883, Training Loss = 0.0836, Validation Accuracy = 0.9721, Validation Loss = 0.2138\n",
            "Epoch 2255/3334\n",
            "Epoch 2255: Training Accuracy = 0.9883, Training Loss = 0.0836, Validation Accuracy = 0.9721, Validation Loss = 0.2138\n",
            "Epoch 2256/3334\n",
            "Epoch 2256: Training Accuracy = 0.9883, Training Loss = 0.0836, Validation Accuracy = 0.9721, Validation Loss = 0.2138\n",
            "Epoch 2257/3334\n",
            "Epoch 2257: Training Accuracy = 0.9897, Training Loss = 0.0826, Validation Accuracy = 0.9730, Validation Loss = 0.2174\n",
            "Epoch 2258/3334\n",
            "Epoch 2258: Training Accuracy = 0.9897, Training Loss = 0.0826, Validation Accuracy = 0.9730, Validation Loss = 0.2174\n",
            "Epoch 2259/3334\n",
            "Epoch 2259: Training Accuracy = 0.9897, Training Loss = 0.0826, Validation Accuracy = 0.9730, Validation Loss = 0.2174\n",
            "Epoch 2260/3334\n",
            "Epoch 2260: Training Accuracy = 0.9897, Training Loss = 0.0826, Validation Accuracy = 0.9730, Validation Loss = 0.2174\n",
            "Epoch 2261/3334\n",
            "Epoch 2261: Training Accuracy = 0.9854, Training Loss = 0.0959, Validation Accuracy = 0.9727, Validation Loss = 0.2160\n",
            "Epoch 2262/3334\n",
            "Epoch 2262: Training Accuracy = 0.9854, Training Loss = 0.0959, Validation Accuracy = 0.9727, Validation Loss = 0.2160\n",
            "Epoch 2263/3334\n",
            "Epoch 2263: Training Accuracy = 0.9854, Training Loss = 0.0959, Validation Accuracy = 0.9727, Validation Loss = 0.2160\n",
            "Epoch 2264/3334\n",
            "Epoch 2264: Training Accuracy = 0.9863, Training Loss = 0.0930, Validation Accuracy = 0.9692, Validation Loss = 0.2172\n",
            "Epoch 2265/3334\n",
            "Epoch 2265: Training Accuracy = 0.9863, Training Loss = 0.0930, Validation Accuracy = 0.9692, Validation Loss = 0.2172\n",
            "Epoch 2266/3334\n",
            "Epoch 2266: Training Accuracy = 0.9863, Training Loss = 0.0930, Validation Accuracy = 0.9692, Validation Loss = 0.2172\n",
            "Epoch 2267/3334\n",
            "Epoch 2267: Training Accuracy = 0.9483, Training Loss = 0.3786, Validation Accuracy = 0.3297, Validation Loss = 3.1496\n",
            "Epoch 2268/3334\n",
            "Epoch 2268: Training Accuracy = 0.9483, Training Loss = 0.3786, Validation Accuracy = 0.3297, Validation Loss = 3.1496\n",
            "Epoch 2269/3334\n",
            "Epoch 2269: Training Accuracy = 0.9483, Training Loss = 0.3786, Validation Accuracy = 0.3297, Validation Loss = 3.1496\n",
            "Epoch 2270/3334\n",
            "Epoch 2270: Training Accuracy = 0.9483, Training Loss = 0.3786, Validation Accuracy = 0.3297, Validation Loss = 3.1496\n",
            "Epoch 2271/3334\n",
            "Epoch 2271: Training Accuracy = 0.9043, Training Loss = 0.6974, Validation Accuracy = 0.8260, Validation Loss = 0.9376\n",
            "Epoch 2272/3334\n",
            "Epoch 2272: Training Accuracy = 0.9043, Training Loss = 0.6974, Validation Accuracy = 0.8260, Validation Loss = 0.9376\n",
            "Epoch 2273/3334\n",
            "Epoch 2273: Training Accuracy = 0.9043, Training Loss = 0.6974, Validation Accuracy = 0.8260, Validation Loss = 0.9376\n",
            "Epoch 2274/3334\n",
            "Epoch 2274: Training Accuracy = 0.9775, Training Loss = 0.2724, Validation Accuracy = 0.9523, Validation Loss = 0.4732\n",
            "Epoch 2275/3334\n",
            "Epoch 2275: Training Accuracy = 0.9775, Training Loss = 0.2724, Validation Accuracy = 0.9523, Validation Loss = 0.4732\n",
            "Epoch 2276/3334\n",
            "Epoch 2276: Training Accuracy = 0.9775, Training Loss = 0.2724, Validation Accuracy = 0.9523, Validation Loss = 0.4732\n",
            "Epoch 2277/3334\n",
            "Epoch 2277: Training Accuracy = 0.9910, Training Loss = 0.1456, Validation Accuracy = 0.9705, Validation Loss = 0.2893\n",
            "Epoch 2278/3334\n",
            "Epoch 2278: Training Accuracy = 0.9910, Training Loss = 0.1456, Validation Accuracy = 0.9705, Validation Loss = 0.2893\n",
            "Epoch 2279/3334\n",
            "Epoch 2279: Training Accuracy = 0.9910, Training Loss = 0.1456, Validation Accuracy = 0.9705, Validation Loss = 0.2893\n",
            "Epoch 2280/3334\n",
            "Epoch 2280: Training Accuracy = 0.9910, Training Loss = 0.1456, Validation Accuracy = 0.9705, Validation Loss = 0.2893\n",
            "Epoch 2281/3334\n",
            "Epoch 2281: Training Accuracy = 0.9912, Training Loss = 0.1008, Validation Accuracy = 0.9734, Validation Loss = 0.2280\n",
            "Epoch 2282/3334\n",
            "Epoch 2282: Training Accuracy = 0.9912, Training Loss = 0.1008, Validation Accuracy = 0.9734, Validation Loss = 0.2280\n",
            "Epoch 2283/3334\n",
            "Epoch 2283: Training Accuracy = 0.9912, Training Loss = 0.1008, Validation Accuracy = 0.9734, Validation Loss = 0.2280\n",
            "Epoch 2284/3334\n",
            "Epoch 2284: Training Accuracy = 0.9902, Training Loss = 0.0870, Validation Accuracy = 0.9742, Validation Loss = 0.2035\n",
            "Epoch 2285/3334\n",
            "Epoch 2285: Training Accuracy = 0.9902, Training Loss = 0.0870, Validation Accuracy = 0.9742, Validation Loss = 0.2035\n",
            "Epoch 2286/3334\n",
            "Epoch 2286: Training Accuracy = 0.9902, Training Loss = 0.0870, Validation Accuracy = 0.9742, Validation Loss = 0.2035\n",
            "Epoch 2287/3334\n",
            "Epoch 2287: Training Accuracy = 0.9897, Training Loss = 0.0841, Validation Accuracy = 0.9737, Validation Loss = 0.1958\n",
            "Epoch 2288/3334\n",
            "Epoch 2288: Training Accuracy = 0.9897, Training Loss = 0.0841, Validation Accuracy = 0.9737, Validation Loss = 0.1958\n",
            "Epoch 2289/3334\n",
            "Epoch 2289: Training Accuracy = 0.9897, Training Loss = 0.0841, Validation Accuracy = 0.9737, Validation Loss = 0.1958\n",
            "Epoch 2290/3334\n",
            "Epoch 2290: Training Accuracy = 0.9897, Training Loss = 0.0841, Validation Accuracy = 0.9737, Validation Loss = 0.1958\n",
            "Epoch 2291/3334\n",
            "Epoch 2291: Training Accuracy = 0.9883, Training Loss = 0.0854, Validation Accuracy = 0.9739, Validation Loss = 0.1927\n",
            "Epoch 2292/3334\n",
            "Epoch 2292: Training Accuracy = 0.9883, Training Loss = 0.0854, Validation Accuracy = 0.9739, Validation Loss = 0.1927\n",
            "Epoch 2293/3334\n",
            "Epoch 2293: Training Accuracy = 0.9883, Training Loss = 0.0854, Validation Accuracy = 0.9739, Validation Loss = 0.1927\n",
            "Epoch 2294/3334\n",
            "Epoch 2294: Training Accuracy = 0.9863, Training Loss = 0.0921, Validation Accuracy = 0.9734, Validation Loss = 0.1924\n",
            "Epoch 2295/3334\n",
            "Epoch 2295: Training Accuracy = 0.9863, Training Loss = 0.0921, Validation Accuracy = 0.9734, Validation Loss = 0.1924\n",
            "Epoch 2296/3334\n",
            "Epoch 2296: Training Accuracy = 0.9863, Training Loss = 0.0921, Validation Accuracy = 0.9734, Validation Loss = 0.1924\n",
            "Epoch 2297/3334\n",
            "Epoch 2297: Training Accuracy = 0.9845, Training Loss = 0.0988, Validation Accuracy = 0.9731, Validation Loss = 0.1909\n",
            "Epoch 2298/3334\n",
            "Epoch 2298: Training Accuracy = 0.9845, Training Loss = 0.0988, Validation Accuracy = 0.9731, Validation Loss = 0.1909\n",
            "Epoch 2299/3334\n",
            "Epoch 2299: Training Accuracy = 0.9845, Training Loss = 0.0988, Validation Accuracy = 0.9731, Validation Loss = 0.1909\n",
            "Epoch 2300/3334\n",
            "Epoch 2300: Training Accuracy = 0.9845, Training Loss = 0.0988, Validation Accuracy = 0.9731, Validation Loss = 0.1909\n",
            "Epoch 2301/3334\n",
            "Epoch 2301: Training Accuracy = 0.9883, Training Loss = 0.0837, Validation Accuracy = 0.9733, Validation Loss = 0.1916\n",
            "Epoch 2302/3334\n",
            "Epoch 2302: Training Accuracy = 0.9883, Training Loss = 0.0837, Validation Accuracy = 0.9733, Validation Loss = 0.1916\n",
            "Epoch 2303/3334\n",
            "Epoch 2303: Training Accuracy = 0.9883, Training Loss = 0.0837, Validation Accuracy = 0.9733, Validation Loss = 0.1916\n",
            "Epoch 2304/3334\n",
            "Epoch 2304: Training Accuracy = 0.9893, Training Loss = 0.0820, Validation Accuracy = 0.9728, Validation Loss = 0.1917\n",
            "Epoch 2305/3334\n",
            "Epoch 2305: Training Accuracy = 0.9893, Training Loss = 0.0820, Validation Accuracy = 0.9728, Validation Loss = 0.1917\n",
            "Epoch 2306/3334\n",
            "Epoch 2306: Training Accuracy = 0.9893, Training Loss = 0.0820, Validation Accuracy = 0.9728, Validation Loss = 0.1917\n",
            "Epoch 2307/3334\n",
            "Epoch 2307: Training Accuracy = 0.9910, Training Loss = 0.0756, Validation Accuracy = 0.9721, Validation Loss = 0.1937\n",
            "Epoch 2308/3334\n",
            "Epoch 2308: Training Accuracy = 0.9910, Training Loss = 0.0756, Validation Accuracy = 0.9721, Validation Loss = 0.1937\n",
            "Epoch 2309/3334\n",
            "Epoch 2309: Training Accuracy = 0.9910, Training Loss = 0.0756, Validation Accuracy = 0.9721, Validation Loss = 0.1937\n",
            "Epoch 2310/3334\n",
            "Epoch 2310: Training Accuracy = 0.9910, Training Loss = 0.0756, Validation Accuracy = 0.9721, Validation Loss = 0.1937\n",
            "Epoch 2311/3334\n",
            "Epoch 2311: Training Accuracy = 0.9883, Training Loss = 0.0829, Validation Accuracy = 0.9734, Validation Loss = 0.1879\n",
            "Epoch 2312/3334\n",
            "Epoch 2312: Training Accuracy = 0.9883, Training Loss = 0.0829, Validation Accuracy = 0.9734, Validation Loss = 0.1879\n",
            "Epoch 2313/3334\n",
            "Epoch 2313: Training Accuracy = 0.9883, Training Loss = 0.0829, Validation Accuracy = 0.9734, Validation Loss = 0.1879\n",
            "Epoch 2314/3334\n",
            "Epoch 2314: Training Accuracy = 0.9873, Training Loss = 0.0858, Validation Accuracy = 0.9731, Validation Loss = 0.1907\n",
            "Epoch 2315/3334\n",
            "Epoch 2315: Training Accuracy = 0.9873, Training Loss = 0.0858, Validation Accuracy = 0.9731, Validation Loss = 0.1907\n",
            "Epoch 2316/3334\n",
            "Epoch 2316: Training Accuracy = 0.9873, Training Loss = 0.0858, Validation Accuracy = 0.9731, Validation Loss = 0.1907\n",
            "Epoch 2317/3334\n",
            "Epoch 2317: Training Accuracy = 0.4819, Training Loss = 1.8444, Validation Accuracy = 0.1638, Validation Loss = 3.1073\n",
            "Epoch 2318/3334\n",
            "Epoch 2318: Training Accuracy = 0.4819, Training Loss = 1.8444, Validation Accuracy = 0.1638, Validation Loss = 3.1073\n",
            "Epoch 2319/3334\n",
            "Epoch 2319: Training Accuracy = 0.4819, Training Loss = 1.8444, Validation Accuracy = 0.1638, Validation Loss = 3.1073\n",
            "Epoch 2320/3334\n",
            "Epoch 2320: Training Accuracy = 0.4819, Training Loss = 1.8444, Validation Accuracy = 0.1638, Validation Loss = 3.1073\n",
            "Epoch 2321/3334\n",
            "Epoch 2321: Training Accuracy = 0.9297, Training Loss = 0.6105, Validation Accuracy = 0.8415, Validation Loss = 0.8970\n",
            "Epoch 2322/3334\n",
            "Epoch 2322: Training Accuracy = 0.9297, Training Loss = 0.6105, Validation Accuracy = 0.8415, Validation Loss = 0.8970\n",
            "Epoch 2323/3334\n",
            "Epoch 2323: Training Accuracy = 0.9297, Training Loss = 0.6105, Validation Accuracy = 0.8415, Validation Loss = 0.8970\n",
            "Epoch 2324/3334\n",
            "Epoch 2324: Training Accuracy = 0.9854, Training Loss = 0.2677, Validation Accuracy = 0.9579, Validation Loss = 0.4199\n",
            "Epoch 2325/3334\n",
            "Epoch 2325: Training Accuracy = 0.9854, Training Loss = 0.2677, Validation Accuracy = 0.9579, Validation Loss = 0.4199\n",
            "Epoch 2326/3334\n",
            "Epoch 2326: Training Accuracy = 0.9854, Training Loss = 0.2677, Validation Accuracy = 0.9579, Validation Loss = 0.4199\n",
            "Epoch 2327/3334\n",
            "Epoch 2327: Training Accuracy = 0.9897, Training Loss = 0.1549, Validation Accuracy = 0.9698, Validation Loss = 0.2815\n",
            "Epoch 2328/3334\n",
            "Epoch 2328: Training Accuracy = 0.9897, Training Loss = 0.1549, Validation Accuracy = 0.9698, Validation Loss = 0.2815\n",
            "Epoch 2329/3334\n",
            "Epoch 2329: Training Accuracy = 0.9897, Training Loss = 0.1549, Validation Accuracy = 0.9698, Validation Loss = 0.2815\n",
            "Epoch 2330/3334\n",
            "Epoch 2330: Training Accuracy = 0.9897, Training Loss = 0.1549, Validation Accuracy = 0.9698, Validation Loss = 0.2815\n",
            "Epoch 2331/3334\n",
            "Epoch 2331: Training Accuracy = 0.9922, Training Loss = 0.1025, Validation Accuracy = 0.9716, Validation Loss = 0.2315\n",
            "Epoch 2332/3334\n",
            "Epoch 2332: Training Accuracy = 0.9922, Training Loss = 0.1025, Validation Accuracy = 0.9716, Validation Loss = 0.2315\n",
            "Epoch 2333/3334\n",
            "Epoch 2333: Training Accuracy = 0.9922, Training Loss = 0.1025, Validation Accuracy = 0.9716, Validation Loss = 0.2315\n",
            "Epoch 2334/3334\n",
            "Epoch 2334: Training Accuracy = 0.9961, Training Loss = 0.0713, Validation Accuracy = 0.9733, Validation Loss = 0.2031\n",
            "Epoch 2335/3334\n",
            "Epoch 2335: Training Accuracy = 0.9961, Training Loss = 0.0713, Validation Accuracy = 0.9733, Validation Loss = 0.2031\n",
            "Epoch 2336/3334\n",
            "Epoch 2336: Training Accuracy = 0.9961, Training Loss = 0.0713, Validation Accuracy = 0.9733, Validation Loss = 0.2031\n",
            "Epoch 2337/3334\n",
            "Epoch 2337: Training Accuracy = 0.9897, Training Loss = 0.0860, Validation Accuracy = 0.9737, Validation Loss = 0.1903\n",
            "Epoch 2338/3334\n",
            "Epoch 2338: Training Accuracy = 0.9897, Training Loss = 0.0860, Validation Accuracy = 0.9737, Validation Loss = 0.1903\n",
            "Epoch 2339/3334\n",
            "Epoch 2339: Training Accuracy = 0.9897, Training Loss = 0.0860, Validation Accuracy = 0.9737, Validation Loss = 0.1903\n",
            "Epoch 2340/3334\n",
            "Epoch 2340: Training Accuracy = 0.9897, Training Loss = 0.0860, Validation Accuracy = 0.9737, Validation Loss = 0.1903\n",
            "Epoch 2341/3334\n",
            "Epoch 2341: Training Accuracy = 0.9883, Training Loss = 0.0909, Validation Accuracy = 0.9737, Validation Loss = 0.1885\n",
            "Epoch 2342/3334\n",
            "Epoch 2342: Training Accuracy = 0.9883, Training Loss = 0.0909, Validation Accuracy = 0.9737, Validation Loss = 0.1885\n",
            "Epoch 2343/3334\n",
            "Epoch 2343: Training Accuracy = 0.9883, Training Loss = 0.0909, Validation Accuracy = 0.9737, Validation Loss = 0.1885\n",
            "Epoch 2344/3334\n",
            "Epoch 2344: Training Accuracy = 0.9893, Training Loss = 0.0829, Validation Accuracy = 0.9737, Validation Loss = 0.1846\n",
            "Epoch 2345/3334\n",
            "Epoch 2345: Training Accuracy = 0.9893, Training Loss = 0.0829, Validation Accuracy = 0.9737, Validation Loss = 0.1846\n",
            "Epoch 2346/3334\n",
            "Epoch 2346: Training Accuracy = 0.9893, Training Loss = 0.0829, Validation Accuracy = 0.9737, Validation Loss = 0.1846\n",
            "Epoch 2347/3334\n",
            "Epoch 2347: Training Accuracy = 0.9871, Training Loss = 0.0927, Validation Accuracy = 0.9740, Validation Loss = 0.1845\n",
            "Epoch 2348/3334\n",
            "Epoch 2348: Training Accuracy = 0.9871, Training Loss = 0.0927, Validation Accuracy = 0.9740, Validation Loss = 0.1845\n",
            "Epoch 2349/3334\n",
            "Epoch 2349: Training Accuracy = 0.9871, Training Loss = 0.0927, Validation Accuracy = 0.9740, Validation Loss = 0.1845\n",
            "Epoch 2350/3334\n",
            "Epoch 2350: Training Accuracy = 0.9871, Training Loss = 0.0927, Validation Accuracy = 0.9740, Validation Loss = 0.1845\n",
            "Epoch 2351/3334\n",
            "Epoch 2351: Training Accuracy = 0.9873, Training Loss = 0.0891, Validation Accuracy = 0.9740, Validation Loss = 0.1831\n",
            "Epoch 2352/3334\n",
            "Epoch 2352: Training Accuracy = 0.9873, Training Loss = 0.0891, Validation Accuracy = 0.9740, Validation Loss = 0.1831\n",
            "Epoch 2353/3334\n",
            "Epoch 2353: Training Accuracy = 0.9873, Training Loss = 0.0891, Validation Accuracy = 0.9740, Validation Loss = 0.1831\n",
            "Epoch 2354/3334\n",
            "Epoch 2354: Training Accuracy = 0.9893, Training Loss = 0.0819, Validation Accuracy = 0.9730, Validation Loss = 0.1842\n",
            "Epoch 2355/3334\n",
            "Epoch 2355: Training Accuracy = 0.9893, Training Loss = 0.0819, Validation Accuracy = 0.9730, Validation Loss = 0.1842\n",
            "Epoch 2356/3334\n",
            "Epoch 2356: Training Accuracy = 0.9893, Training Loss = 0.0819, Validation Accuracy = 0.9730, Validation Loss = 0.1842\n",
            "Epoch 2357/3334\n",
            "Epoch 2357: Training Accuracy = 0.9884, Training Loss = 0.0863, Validation Accuracy = 0.9727, Validation Loss = 0.1811\n",
            "Epoch 2358/3334\n",
            "Epoch 2358: Training Accuracy = 0.9884, Training Loss = 0.0863, Validation Accuracy = 0.9727, Validation Loss = 0.1811\n",
            "Epoch 2359/3334\n",
            "Epoch 2359: Training Accuracy = 0.9884, Training Loss = 0.0863, Validation Accuracy = 0.9727, Validation Loss = 0.1811\n",
            "Epoch 2360/3334\n",
            "Epoch 2360: Training Accuracy = 0.9884, Training Loss = 0.0863, Validation Accuracy = 0.9727, Validation Loss = 0.1811\n",
            "Epoch 2361/3334\n",
            "Epoch 2361: Training Accuracy = 0.9844, Training Loss = 0.0993, Validation Accuracy = 0.9734, Validation Loss = 0.1883\n",
            "Epoch 2362/3334\n",
            "Epoch 2362: Training Accuracy = 0.9844, Training Loss = 0.0993, Validation Accuracy = 0.9734, Validation Loss = 0.1883\n",
            "Epoch 2363/3334\n",
            "Epoch 2363: Training Accuracy = 0.9844, Training Loss = 0.0993, Validation Accuracy = 0.9734, Validation Loss = 0.1883\n",
            "Epoch 2364/3334\n",
            "Epoch 2364: Training Accuracy = 0.9922, Training Loss = 0.0735, Validation Accuracy = 0.9719, Validation Loss = 0.1834\n",
            "Epoch 2365/3334\n",
            "Epoch 2365: Training Accuracy = 0.9922, Training Loss = 0.0735, Validation Accuracy = 0.9719, Validation Loss = 0.1834\n",
            "Epoch 2366/3334\n",
            "Epoch 2366: Training Accuracy = 0.9922, Training Loss = 0.0735, Validation Accuracy = 0.9719, Validation Loss = 0.1834\n",
            "Epoch 2367/3334\n",
            "Epoch 2367: Training Accuracy = 0.9832, Training Loss = 0.1091, Validation Accuracy = 0.9737, Validation Loss = 0.1904\n",
            "Epoch 2368/3334\n",
            "Epoch 2368: Training Accuracy = 0.9832, Training Loss = 0.1091, Validation Accuracy = 0.9737, Validation Loss = 0.1904\n",
            "Epoch 2369/3334\n",
            "Epoch 2369: Training Accuracy = 0.9832, Training Loss = 0.1091, Validation Accuracy = 0.9737, Validation Loss = 0.1904\n",
            "Epoch 2370/3334\n",
            "Epoch 2370: Training Accuracy = 0.9832, Training Loss = 0.1091, Validation Accuracy = 0.9737, Validation Loss = 0.1904\n",
            "Epoch 2371/3334\n",
            "Epoch 2371: Training Accuracy = 0.1992, Training Loss = 3.4920, Validation Accuracy = 0.2701, Validation Loss = 3.2981\n",
            "Epoch 2372/3334\n",
            "Epoch 2372: Training Accuracy = 0.1992, Training Loss = 3.4920, Validation Accuracy = 0.2701, Validation Loss = 3.2981\n",
            "Epoch 2373/3334\n",
            "Epoch 2373: Training Accuracy = 0.1992, Training Loss = 3.4920, Validation Accuracy = 0.2701, Validation Loss = 3.2981\n",
            "Epoch 2374/3334\n",
            "Epoch 2374: Training Accuracy = 0.8916, Training Loss = 0.8283, Validation Accuracy = 0.8303, Validation Loss = 0.9862\n",
            "Epoch 2375/3334\n",
            "Epoch 2375: Training Accuracy = 0.8916, Training Loss = 0.8283, Validation Accuracy = 0.8303, Validation Loss = 0.9862\n",
            "Epoch 2376/3334\n",
            "Epoch 2376: Training Accuracy = 0.8916, Training Loss = 0.8283, Validation Accuracy = 0.8303, Validation Loss = 0.9862\n",
            "Epoch 2377/3334\n",
            "Epoch 2377: Training Accuracy = 0.9755, Training Loss = 0.3244, Validation Accuracy = 0.9458, Validation Loss = 0.4872\n",
            "Epoch 2378/3334\n",
            "Epoch 2378: Training Accuracy = 0.9755, Training Loss = 0.3244, Validation Accuracy = 0.9458, Validation Loss = 0.4872\n",
            "Epoch 2379/3334\n",
            "Epoch 2379: Training Accuracy = 0.9755, Training Loss = 0.3244, Validation Accuracy = 0.9458, Validation Loss = 0.4872\n",
            "Epoch 2380/3334\n",
            "Epoch 2380: Training Accuracy = 0.9755, Training Loss = 0.3244, Validation Accuracy = 0.9458, Validation Loss = 0.4872\n",
            "Epoch 2381/3334\n",
            "Epoch 2381: Training Accuracy = 0.9844, Training Loss = 0.1931, Validation Accuracy = 0.9663, Validation Loss = 0.3201\n",
            "Epoch 2382/3334\n",
            "Epoch 2382: Training Accuracy = 0.9844, Training Loss = 0.1931, Validation Accuracy = 0.9663, Validation Loss = 0.3201\n",
            "Epoch 2383/3334\n",
            "Epoch 2383: Training Accuracy = 0.9844, Training Loss = 0.1931, Validation Accuracy = 0.9663, Validation Loss = 0.3201\n",
            "Epoch 2384/3334\n",
            "Epoch 2384: Training Accuracy = 0.9873, Training Loss = 0.1304, Validation Accuracy = 0.9715, Validation Loss = 0.2450\n",
            "Epoch 2385/3334\n",
            "Epoch 2385: Training Accuracy = 0.9873, Training Loss = 0.1304, Validation Accuracy = 0.9715, Validation Loss = 0.2450\n",
            "Epoch 2386/3334\n",
            "Epoch 2386: Training Accuracy = 0.9873, Training Loss = 0.1304, Validation Accuracy = 0.9715, Validation Loss = 0.2450\n",
            "Epoch 2387/3334\n",
            "Epoch 2387: Training Accuracy = 0.9910, Training Loss = 0.0996, Validation Accuracy = 0.9724, Validation Loss = 0.2110\n",
            "Epoch 2388/3334\n",
            "Epoch 2388: Training Accuracy = 0.9910, Training Loss = 0.0996, Validation Accuracy = 0.9724, Validation Loss = 0.2110\n",
            "Epoch 2389/3334\n",
            "Epoch 2389: Training Accuracy = 0.9910, Training Loss = 0.0996, Validation Accuracy = 0.9724, Validation Loss = 0.2110\n",
            "Epoch 2390/3334\n",
            "Epoch 2390: Training Accuracy = 0.9910, Training Loss = 0.0996, Validation Accuracy = 0.9724, Validation Loss = 0.2110\n",
            "Epoch 2391/3334\n",
            "Epoch 2391: Training Accuracy = 0.9902, Training Loss = 0.0924, Validation Accuracy = 0.9734, Validation Loss = 0.1927\n",
            "Epoch 2392/3334\n",
            "Epoch 2392: Training Accuracy = 0.9902, Training Loss = 0.0924, Validation Accuracy = 0.9734, Validation Loss = 0.1927\n",
            "Epoch 2393/3334\n",
            "Epoch 2393: Training Accuracy = 0.9902, Training Loss = 0.0924, Validation Accuracy = 0.9734, Validation Loss = 0.1927\n",
            "Epoch 2394/3334\n",
            "Epoch 2394: Training Accuracy = 0.9863, Training Loss = 0.0987, Validation Accuracy = 0.9731, Validation Loss = 0.1848\n",
            "Epoch 2395/3334\n",
            "Epoch 2395: Training Accuracy = 0.9863, Training Loss = 0.0987, Validation Accuracy = 0.9731, Validation Loss = 0.1848\n",
            "Epoch 2396/3334\n",
            "Epoch 2396: Training Accuracy = 0.9863, Training Loss = 0.0987, Validation Accuracy = 0.9731, Validation Loss = 0.1848\n",
            "Epoch 2397/3334\n",
            "Epoch 2397: Training Accuracy = 0.9910, Training Loss = 0.0825, Validation Accuracy = 0.9731, Validation Loss = 0.1809\n",
            "Epoch 2398/3334\n",
            "Epoch 2398: Training Accuracy = 0.9910, Training Loss = 0.0825, Validation Accuracy = 0.9731, Validation Loss = 0.1809\n",
            "Epoch 2399/3334\n",
            "Epoch 2399: Training Accuracy = 0.9910, Training Loss = 0.0825, Validation Accuracy = 0.9731, Validation Loss = 0.1809\n",
            "Epoch 2400/3334\n",
            "Epoch 2400: Training Accuracy = 0.9910, Training Loss = 0.0825, Validation Accuracy = 0.9731, Validation Loss = 0.1809\n",
            "Epoch 2401/3334\n",
            "Epoch 2401: Training Accuracy = 0.9883, Training Loss = 0.0918, Validation Accuracy = 0.9733, Validation Loss = 0.1813\n",
            "Epoch 2402/3334\n",
            "Epoch 2402: Training Accuracy = 0.9883, Training Loss = 0.0918, Validation Accuracy = 0.9733, Validation Loss = 0.1813\n",
            "Epoch 2403/3334\n",
            "Epoch 2403: Training Accuracy = 0.9883, Training Loss = 0.0918, Validation Accuracy = 0.9733, Validation Loss = 0.1813\n",
            "Epoch 2404/3334\n",
            "Epoch 2404: Training Accuracy = 0.9932, Training Loss = 0.0730, Validation Accuracy = 0.9734, Validation Loss = 0.1791\n",
            "Epoch 2405/3334\n",
            "Epoch 2405: Training Accuracy = 0.9932, Training Loss = 0.0730, Validation Accuracy = 0.9734, Validation Loss = 0.1791\n",
            "Epoch 2406/3334\n",
            "Epoch 2406: Training Accuracy = 0.9932, Training Loss = 0.0730, Validation Accuracy = 0.9734, Validation Loss = 0.1791\n",
            "Epoch 2407/3334\n",
            "Epoch 2407: Training Accuracy = 0.9922, Training Loss = 0.0764, Validation Accuracy = 0.9739, Validation Loss = 0.1779\n",
            "Epoch 2408/3334\n",
            "Epoch 2408: Training Accuracy = 0.9922, Training Loss = 0.0764, Validation Accuracy = 0.9739, Validation Loss = 0.1779\n",
            "Epoch 2409/3334\n",
            "Epoch 2409: Training Accuracy = 0.9922, Training Loss = 0.0764, Validation Accuracy = 0.9739, Validation Loss = 0.1779\n",
            "Epoch 2410/3334\n",
            "Epoch 2410: Training Accuracy = 0.9922, Training Loss = 0.0764, Validation Accuracy = 0.9739, Validation Loss = 0.1779\n",
            "Epoch 2411/3334\n",
            "Epoch 2411: Training Accuracy = 0.9883, Training Loss = 0.0876, Validation Accuracy = 0.9725, Validation Loss = 0.1832\n",
            "Epoch 2412/3334\n",
            "Epoch 2412: Training Accuracy = 0.9883, Training Loss = 0.0876, Validation Accuracy = 0.9725, Validation Loss = 0.1832\n",
            "Epoch 2413/3334\n",
            "Epoch 2413: Training Accuracy = 0.9883, Training Loss = 0.0876, Validation Accuracy = 0.9725, Validation Loss = 0.1832\n",
            "Epoch 2414/3334\n",
            "Epoch 2414: Training Accuracy = 0.9863, Training Loss = 0.0976, Validation Accuracy = 0.9740, Validation Loss = 0.1876\n",
            "Epoch 2415/3334\n",
            "Epoch 2415: Training Accuracy = 0.9863, Training Loss = 0.0976, Validation Accuracy = 0.9740, Validation Loss = 0.1876\n",
            "Epoch 2416/3334\n",
            "Epoch 2416: Training Accuracy = 0.9863, Training Loss = 0.0976, Validation Accuracy = 0.9740, Validation Loss = 0.1876\n",
            "Epoch 2417/3334\n",
            "Epoch 2417: Training Accuracy = 0.8165, Training Loss = 0.9712, Validation Accuracy = 0.7692, Validation Loss = 1.1489\n",
            "Epoch 2418/3334\n",
            "Epoch 2418: Training Accuracy = 0.8165, Training Loss = 0.9712, Validation Accuracy = 0.7692, Validation Loss = 1.1489\n",
            "Epoch 2419/3334\n",
            "Epoch 2419: Training Accuracy = 0.8165, Training Loss = 0.9712, Validation Accuracy = 0.7692, Validation Loss = 1.1489\n",
            "Epoch 2420/3334\n",
            "Epoch 2420: Training Accuracy = 0.8165, Training Loss = 0.9712, Validation Accuracy = 0.7692, Validation Loss = 1.1489\n",
            "Epoch 2421/3334\n",
            "Epoch 2421: Training Accuracy = 0.9629, Training Loss = 0.4051, Validation Accuracy = 0.9028, Validation Loss = 0.6194\n",
            "Epoch 2422/3334\n",
            "Epoch 2422: Training Accuracy = 0.9629, Training Loss = 0.4051, Validation Accuracy = 0.9028, Validation Loss = 0.6194\n",
            "Epoch 2423/3334\n",
            "Epoch 2423: Training Accuracy = 0.9629, Training Loss = 0.4051, Validation Accuracy = 0.9028, Validation Loss = 0.6194\n",
            "Epoch 2424/3334\n",
            "Epoch 2424: Training Accuracy = 0.9824, Training Loss = 0.2284, Validation Accuracy = 0.9570, Validation Loss = 0.3728\n",
            "Epoch 2425/3334\n",
            "Epoch 2425: Training Accuracy = 0.9824, Training Loss = 0.2284, Validation Accuracy = 0.9570, Validation Loss = 0.3728\n",
            "Epoch 2426/3334\n",
            "Epoch 2426: Training Accuracy = 0.9824, Training Loss = 0.2284, Validation Accuracy = 0.9570, Validation Loss = 0.3728\n",
            "Epoch 2427/3334\n",
            "Epoch 2427: Training Accuracy = 0.9948, Training Loss = 0.1284, Validation Accuracy = 0.9680, Validation Loss = 0.2770\n",
            "Epoch 2428/3334\n",
            "Epoch 2428: Training Accuracy = 0.9948, Training Loss = 0.1284, Validation Accuracy = 0.9680, Validation Loss = 0.2770\n",
            "Epoch 2429/3334\n",
            "Epoch 2429: Training Accuracy = 0.9948, Training Loss = 0.1284, Validation Accuracy = 0.9680, Validation Loss = 0.2770\n",
            "Epoch 2430/3334\n",
            "Epoch 2430: Training Accuracy = 0.9948, Training Loss = 0.1284, Validation Accuracy = 0.9680, Validation Loss = 0.2770\n",
            "Epoch 2431/3334\n",
            "Epoch 2431: Training Accuracy = 0.9922, Training Loss = 0.1092, Validation Accuracy = 0.9709, Validation Loss = 0.2332\n",
            "Epoch 2432/3334\n",
            "Epoch 2432: Training Accuracy = 0.9922, Training Loss = 0.1092, Validation Accuracy = 0.9709, Validation Loss = 0.2332\n",
            "Epoch 2433/3334\n",
            "Epoch 2433: Training Accuracy = 0.9922, Training Loss = 0.1092, Validation Accuracy = 0.9709, Validation Loss = 0.2332\n",
            "Epoch 2434/3334\n",
            "Epoch 2434: Training Accuracy = 0.9932, Training Loss = 0.0888, Validation Accuracy = 0.9722, Validation Loss = 0.2078\n",
            "Epoch 2435/3334\n",
            "Epoch 2435: Training Accuracy = 0.9932, Training Loss = 0.0888, Validation Accuracy = 0.9722, Validation Loss = 0.2078\n",
            "Epoch 2436/3334\n",
            "Epoch 2436: Training Accuracy = 0.9932, Training Loss = 0.0888, Validation Accuracy = 0.9722, Validation Loss = 0.2078\n",
            "Epoch 2437/3334\n",
            "Epoch 2437: Training Accuracy = 0.9897, Training Loss = 0.0992, Validation Accuracy = 0.9734, Validation Loss = 0.1956\n",
            "Epoch 2438/3334\n",
            "Epoch 2438: Training Accuracy = 0.9897, Training Loss = 0.0992, Validation Accuracy = 0.9734, Validation Loss = 0.1956\n",
            "Epoch 2439/3334\n",
            "Epoch 2439: Training Accuracy = 0.9897, Training Loss = 0.0992, Validation Accuracy = 0.9734, Validation Loss = 0.1956\n",
            "Epoch 2440/3334\n",
            "Epoch 2440: Training Accuracy = 0.9897, Training Loss = 0.0992, Validation Accuracy = 0.9734, Validation Loss = 0.1956\n",
            "Epoch 2441/3334\n",
            "Epoch 2441: Training Accuracy = 0.9932, Training Loss = 0.0809, Validation Accuracy = 0.9731, Validation Loss = 0.1889\n",
            "Epoch 2442/3334\n",
            "Epoch 2442: Training Accuracy = 0.9932, Training Loss = 0.0809, Validation Accuracy = 0.9731, Validation Loss = 0.1889\n",
            "Epoch 2443/3334\n",
            "Epoch 2443: Training Accuracy = 0.9932, Training Loss = 0.0809, Validation Accuracy = 0.9731, Validation Loss = 0.1889\n",
            "Epoch 2444/3334\n",
            "Epoch 2444: Training Accuracy = 0.9893, Training Loss = 0.0900, Validation Accuracy = 0.9731, Validation Loss = 0.1834\n",
            "Epoch 2445/3334\n",
            "Epoch 2445: Training Accuracy = 0.9893, Training Loss = 0.0900, Validation Accuracy = 0.9731, Validation Loss = 0.1834\n",
            "Epoch 2446/3334\n",
            "Epoch 2446: Training Accuracy = 0.9893, Training Loss = 0.0900, Validation Accuracy = 0.9731, Validation Loss = 0.1834\n",
            "Epoch 2447/3334\n",
            "Epoch 2447: Training Accuracy = 0.9961, Training Loss = 0.0685, Validation Accuracy = 0.9731, Validation Loss = 0.1823\n",
            "Epoch 2448/3334\n",
            "Epoch 2448: Training Accuracy = 0.9961, Training Loss = 0.0685, Validation Accuracy = 0.9731, Validation Loss = 0.1823\n",
            "Epoch 2449/3334\n",
            "Epoch 2449: Training Accuracy = 0.9961, Training Loss = 0.0685, Validation Accuracy = 0.9731, Validation Loss = 0.1823\n",
            "Epoch 2450/3334\n",
            "Epoch 2450: Training Accuracy = 0.9961, Training Loss = 0.0685, Validation Accuracy = 0.9731, Validation Loss = 0.1823\n",
            "Epoch 2451/3334\n",
            "Epoch 2451: Training Accuracy = 0.9883, Training Loss = 0.0897, Validation Accuracy = 0.9737, Validation Loss = 0.1781\n",
            "Epoch 2452/3334\n",
            "Epoch 2452: Training Accuracy = 0.9883, Training Loss = 0.0897, Validation Accuracy = 0.9737, Validation Loss = 0.1781\n",
            "Epoch 2453/3334\n",
            "Epoch 2453: Training Accuracy = 0.9883, Training Loss = 0.0897, Validation Accuracy = 0.9737, Validation Loss = 0.1781\n",
            "Epoch 2454/3334\n",
            "Epoch 2454: Training Accuracy = 0.9883, Training Loss = 0.0891, Validation Accuracy = 0.9728, Validation Loss = 0.1774\n",
            "Epoch 2455/3334\n",
            "Epoch 2455: Training Accuracy = 0.9883, Training Loss = 0.0891, Validation Accuracy = 0.9728, Validation Loss = 0.1774\n",
            "Epoch 2456/3334\n",
            "Epoch 2456: Training Accuracy = 0.9883, Training Loss = 0.0891, Validation Accuracy = 0.9728, Validation Loss = 0.1774\n",
            "Epoch 2457/3334\n",
            "Epoch 2457: Training Accuracy = 0.9897, Training Loss = 0.0860, Validation Accuracy = 0.9743, Validation Loss = 0.1754\n",
            "Epoch 2458/3334\n",
            "Epoch 2458: Training Accuracy = 0.9897, Training Loss = 0.0860, Validation Accuracy = 0.9743, Validation Loss = 0.1754\n",
            "Epoch 2459/3334\n",
            "Epoch 2459: Training Accuracy = 0.9897, Training Loss = 0.0860, Validation Accuracy = 0.9743, Validation Loss = 0.1754\n",
            "Epoch 2460/3334\n",
            "Epoch 2460: Training Accuracy = 0.9897, Training Loss = 0.0860, Validation Accuracy = 0.9743, Validation Loss = 0.1754\n",
            "Epoch 2461/3334\n",
            "Epoch 2461: Training Accuracy = 0.9883, Training Loss = 0.0917, Validation Accuracy = 0.9736, Validation Loss = 0.1756\n",
            "Epoch 2462/3334\n",
            "Epoch 2462: Training Accuracy = 0.9883, Training Loss = 0.0917, Validation Accuracy = 0.9736, Validation Loss = 0.1756\n",
            "Epoch 2463/3334\n",
            "Epoch 2463: Training Accuracy = 0.9883, Training Loss = 0.0917, Validation Accuracy = 0.9736, Validation Loss = 0.1756\n",
            "Epoch 2464/3334\n",
            "Epoch 2464: Training Accuracy = 0.9893, Training Loss = 0.0899, Validation Accuracy = 0.9731, Validation Loss = 0.1733\n",
            "Epoch 2465/3334\n",
            "Epoch 2465: Training Accuracy = 0.9893, Training Loss = 0.0899, Validation Accuracy = 0.9731, Validation Loss = 0.1733\n",
            "Epoch 2466/3334\n",
            "Epoch 2466: Training Accuracy = 0.9893, Training Loss = 0.0899, Validation Accuracy = 0.9731, Validation Loss = 0.1733\n",
            "Epoch 2467/3334\n",
            "Epoch 2467: Training Accuracy = 0.3863, Training Loss = 2.5793, Validation Accuracy = 0.6068, Validation Loss = 1.7881\n",
            "Epoch 2468/3334\n",
            "Epoch 2468: Training Accuracy = 0.3863, Training Loss = 2.5793, Validation Accuracy = 0.6068, Validation Loss = 1.7881\n",
            "Epoch 2469/3334\n",
            "Epoch 2469: Training Accuracy = 0.3863, Training Loss = 2.5793, Validation Accuracy = 0.6068, Validation Loss = 1.7881\n",
            "Epoch 2470/3334\n",
            "Epoch 2470: Training Accuracy = 0.3863, Training Loss = 2.5793, Validation Accuracy = 0.6068, Validation Loss = 1.7881\n",
            "Epoch 2471/3334\n",
            "Epoch 2471: Training Accuracy = 0.9561, Training Loss = 0.4512, Validation Accuracy = 0.8913, Validation Loss = 0.6660\n",
            "Epoch 2472/3334\n",
            "Epoch 2472: Training Accuracy = 0.9561, Training Loss = 0.4512, Validation Accuracy = 0.8913, Validation Loss = 0.6660\n",
            "Epoch 2473/3334\n",
            "Epoch 2473: Training Accuracy = 0.9561, Training Loss = 0.4512, Validation Accuracy = 0.8913, Validation Loss = 0.6660\n",
            "Epoch 2474/3334\n",
            "Epoch 2474: Training Accuracy = 0.9834, Training Loss = 0.2490, Validation Accuracy = 0.9587, Validation Loss = 0.3777\n",
            "Epoch 2475/3334\n",
            "Epoch 2475: Training Accuracy = 0.9834, Training Loss = 0.2490, Validation Accuracy = 0.9587, Validation Loss = 0.3777\n",
            "Epoch 2476/3334\n",
            "Epoch 2476: Training Accuracy = 0.9834, Training Loss = 0.2490, Validation Accuracy = 0.9587, Validation Loss = 0.3777\n",
            "Epoch 2477/3334\n",
            "Epoch 2477: Training Accuracy = 0.9845, Training Loss = 0.1736, Validation Accuracy = 0.9695, Validation Loss = 0.2835\n",
            "Epoch 2478/3334\n",
            "Epoch 2478: Training Accuracy = 0.9845, Training Loss = 0.1736, Validation Accuracy = 0.9695, Validation Loss = 0.2835\n",
            "Epoch 2479/3334\n",
            "Epoch 2479: Training Accuracy = 0.9845, Training Loss = 0.1736, Validation Accuracy = 0.9695, Validation Loss = 0.2835\n",
            "Epoch 2480/3334\n",
            "Epoch 2480: Training Accuracy = 0.9845, Training Loss = 0.1736, Validation Accuracy = 0.9695, Validation Loss = 0.2835\n",
            "Epoch 2481/3334\n",
            "Epoch 2481: Training Accuracy = 0.9883, Training Loss = 0.1350, Validation Accuracy = 0.9709, Validation Loss = 0.2386\n",
            "Epoch 2482/3334\n",
            "Epoch 2482: Training Accuracy = 0.9883, Training Loss = 0.1350, Validation Accuracy = 0.9709, Validation Loss = 0.2386\n",
            "Epoch 2483/3334\n",
            "Epoch 2483: Training Accuracy = 0.9883, Training Loss = 0.1350, Validation Accuracy = 0.9709, Validation Loss = 0.2386\n",
            "Epoch 2484/3334\n",
            "Epoch 2484: Training Accuracy = 0.9893, Training Loss = 0.1163, Validation Accuracy = 0.9721, Validation Loss = 0.2212\n",
            "Epoch 2485/3334\n",
            "Epoch 2485: Training Accuracy = 0.9893, Training Loss = 0.1163, Validation Accuracy = 0.9721, Validation Loss = 0.2212\n",
            "Epoch 2486/3334\n",
            "Epoch 2486: Training Accuracy = 0.9893, Training Loss = 0.1163, Validation Accuracy = 0.9721, Validation Loss = 0.2212\n",
            "Epoch 2487/3334\n",
            "Epoch 2487: Training Accuracy = 0.9871, Training Loss = 0.1149, Validation Accuracy = 0.9730, Validation Loss = 0.2132\n",
            "Epoch 2488/3334\n",
            "Epoch 2488: Training Accuracy = 0.9871, Training Loss = 0.1149, Validation Accuracy = 0.9730, Validation Loss = 0.2132\n",
            "Epoch 2489/3334\n",
            "Epoch 2489: Training Accuracy = 0.9871, Training Loss = 0.1149, Validation Accuracy = 0.9730, Validation Loss = 0.2132\n",
            "Epoch 2490/3334\n",
            "Epoch 2490: Training Accuracy = 0.9871, Training Loss = 0.1149, Validation Accuracy = 0.9730, Validation Loss = 0.2132\n",
            "Epoch 2491/3334\n",
            "Epoch 2491: Training Accuracy = 0.9873, Training Loss = 0.1074, Validation Accuracy = 0.9724, Validation Loss = 0.2054\n",
            "Epoch 2492/3334\n",
            "Epoch 2492: Training Accuracy = 0.9873, Training Loss = 0.1074, Validation Accuracy = 0.9724, Validation Loss = 0.2054\n",
            "Epoch 2493/3334\n",
            "Epoch 2493: Training Accuracy = 0.9873, Training Loss = 0.1074, Validation Accuracy = 0.9724, Validation Loss = 0.2054\n",
            "Epoch 2494/3334\n",
            "Epoch 2494: Training Accuracy = 0.9902, Training Loss = 0.0927, Validation Accuracy = 0.9739, Validation Loss = 0.2019\n",
            "Epoch 2495/3334\n",
            "Epoch 2495: Training Accuracy = 0.9902, Training Loss = 0.0927, Validation Accuracy = 0.9739, Validation Loss = 0.2019\n",
            "Epoch 2496/3334\n",
            "Epoch 2496: Training Accuracy = 0.9902, Training Loss = 0.0927, Validation Accuracy = 0.9739, Validation Loss = 0.2019\n",
            "Epoch 2497/3334\n",
            "Epoch 2497: Training Accuracy = 0.9884, Training Loss = 0.0984, Validation Accuracy = 0.9736, Validation Loss = 0.1964\n",
            "Epoch 2498/3334\n",
            "Epoch 2498: Training Accuracy = 0.9884, Training Loss = 0.0984, Validation Accuracy = 0.9736, Validation Loss = 0.1964\n",
            "Epoch 2499/3334\n",
            "Epoch 2499: Training Accuracy = 0.9884, Training Loss = 0.0984, Validation Accuracy = 0.9736, Validation Loss = 0.1964\n",
            "Epoch 2500/3334\n",
            "Epoch 2500: Training Accuracy = 0.9884, Training Loss = 0.0984, Validation Accuracy = 0.9736, Validation Loss = 0.1964\n",
            "Epoch 2501/3334\n",
            "Epoch 2501: Training Accuracy = 0.9883, Training Loss = 0.0915, Validation Accuracy = 0.9734, Validation Loss = 0.1915\n",
            "Epoch 2502/3334\n",
            "Epoch 2502: Training Accuracy = 0.9883, Training Loss = 0.0915, Validation Accuracy = 0.9734, Validation Loss = 0.1915\n",
            "Epoch 2503/3334\n",
            "Epoch 2503: Training Accuracy = 0.9883, Training Loss = 0.0915, Validation Accuracy = 0.9734, Validation Loss = 0.1915\n",
            "Epoch 2504/3334\n",
            "Epoch 2504: Training Accuracy = 0.9863, Training Loss = 0.0962, Validation Accuracy = 0.9742, Validation Loss = 0.1872\n",
            "Epoch 2505/3334\n",
            "Epoch 2505: Training Accuracy = 0.9863, Training Loss = 0.0962, Validation Accuracy = 0.9742, Validation Loss = 0.1872\n",
            "Epoch 2506/3334\n",
            "Epoch 2506: Training Accuracy = 0.9863, Training Loss = 0.0962, Validation Accuracy = 0.9742, Validation Loss = 0.1872\n",
            "Epoch 2507/3334\n",
            "Epoch 2507: Training Accuracy = 0.9897, Training Loss = 0.0840, Validation Accuracy = 0.9730, Validation Loss = 0.1796\n",
            "Epoch 2508/3334\n",
            "Epoch 2508: Training Accuracy = 0.9897, Training Loss = 0.0840, Validation Accuracy = 0.9730, Validation Loss = 0.1796\n",
            "Epoch 2509/3334\n",
            "Epoch 2509: Training Accuracy = 0.9897, Training Loss = 0.0840, Validation Accuracy = 0.9730, Validation Loss = 0.1796\n",
            "Epoch 2510/3334\n",
            "Epoch 2510: Training Accuracy = 0.9897, Training Loss = 0.0840, Validation Accuracy = 0.9730, Validation Loss = 0.1796\n",
            "Epoch 2511/3334\n",
            "Epoch 2511: Training Accuracy = 0.9883, Training Loss = 0.0876, Validation Accuracy = 0.9739, Validation Loss = 0.1787\n",
            "Epoch 2512/3334\n",
            "Epoch 2512: Training Accuracy = 0.9883, Training Loss = 0.0876, Validation Accuracy = 0.9739, Validation Loss = 0.1787\n",
            "Epoch 2513/3334\n",
            "Epoch 2513: Training Accuracy = 0.9883, Training Loss = 0.0876, Validation Accuracy = 0.9739, Validation Loss = 0.1787\n",
            "Epoch 2514/3334\n",
            "Epoch 2514: Training Accuracy = 0.9922, Training Loss = 0.0740, Validation Accuracy = 0.9734, Validation Loss = 0.1777\n",
            "Epoch 2515/3334\n",
            "Epoch 2515: Training Accuracy = 0.9922, Training Loss = 0.0740, Validation Accuracy = 0.9734, Validation Loss = 0.1777\n",
            "Epoch 2516/3334\n",
            "Epoch 2516: Training Accuracy = 0.9922, Training Loss = 0.0740, Validation Accuracy = 0.9734, Validation Loss = 0.1777\n",
            "Epoch 2517/3334\n",
            "Epoch 2517: Training Accuracy = 0.9845, Training Loss = 0.1077, Validation Accuracy = 0.9746, Validation Loss = 0.1863\n",
            "Epoch 2518/3334\n",
            "Epoch 2518: Training Accuracy = 0.9845, Training Loss = 0.1077, Validation Accuracy = 0.9746, Validation Loss = 0.1863\n",
            "Epoch 2519/3334\n",
            "Epoch 2519: Training Accuracy = 0.9845, Training Loss = 0.1077, Validation Accuracy = 0.9746, Validation Loss = 0.1863\n",
            "Epoch 2520/3334\n",
            "Epoch 2520: Training Accuracy = 0.9845, Training Loss = 0.1077, Validation Accuracy = 0.9746, Validation Loss = 0.1863\n",
            "Epoch 2521/3334\n",
            "Epoch 2521: Training Accuracy = 0.9893, Training Loss = 0.1266, Validation Accuracy = 0.4902, Validation Loss = 1.8354\n",
            "Epoch 2522/3334\n",
            "Epoch 2522: Training Accuracy = 0.9893, Training Loss = 0.1266, Validation Accuracy = 0.4902, Validation Loss = 1.8354\n",
            "Epoch 2523/3334\n",
            "Epoch 2523: Training Accuracy = 0.9893, Training Loss = 0.1266, Validation Accuracy = 0.4902, Validation Loss = 1.8354\n",
            "Epoch 2524/3334\n",
            "Epoch 2524: Training Accuracy = 0.8359, Training Loss = 0.8832, Validation Accuracy = 0.8040, Validation Loss = 0.9870\n",
            "Epoch 2525/3334\n",
            "Epoch 2525: Training Accuracy = 0.8359, Training Loss = 0.8832, Validation Accuracy = 0.8040, Validation Loss = 0.9870\n",
            "Epoch 2526/3334\n",
            "Epoch 2526: Training Accuracy = 0.8359, Training Loss = 0.8832, Validation Accuracy = 0.8040, Validation Loss = 0.9870\n",
            "Epoch 2527/3334\n",
            "Epoch 2527: Training Accuracy = 0.9755, Training Loss = 0.3295, Validation Accuracy = 0.9507, Validation Loss = 0.4467\n",
            "Epoch 2528/3334\n",
            "Epoch 2528: Training Accuracy = 0.9755, Training Loss = 0.3295, Validation Accuracy = 0.9507, Validation Loss = 0.4467\n",
            "Epoch 2529/3334\n",
            "Epoch 2529: Training Accuracy = 0.9755, Training Loss = 0.3295, Validation Accuracy = 0.9507, Validation Loss = 0.4467\n",
            "Epoch 2530/3334\n",
            "Epoch 2530: Training Accuracy = 0.9755, Training Loss = 0.3295, Validation Accuracy = 0.9507, Validation Loss = 0.4467\n",
            "Epoch 2531/3334\n",
            "Epoch 2531: Training Accuracy = 0.9805, Training Loss = 0.1992, Validation Accuracy = 0.9648, Validation Loss = 0.3050\n",
            "Epoch 2532/3334\n",
            "Epoch 2532: Training Accuracy = 0.9805, Training Loss = 0.1992, Validation Accuracy = 0.9648, Validation Loss = 0.3050\n",
            "Epoch 2533/3334\n",
            "Epoch 2533: Training Accuracy = 0.9805, Training Loss = 0.1992, Validation Accuracy = 0.9648, Validation Loss = 0.3050\n",
            "Epoch 2534/3334\n",
            "Epoch 2534: Training Accuracy = 0.9873, Training Loss = 0.1275, Validation Accuracy = 0.9712, Validation Loss = 0.2304\n",
            "Epoch 2535/3334\n",
            "Epoch 2535: Training Accuracy = 0.9873, Training Loss = 0.1275, Validation Accuracy = 0.9712, Validation Loss = 0.2304\n",
            "Epoch 2536/3334\n",
            "Epoch 2536: Training Accuracy = 0.9873, Training Loss = 0.1275, Validation Accuracy = 0.9712, Validation Loss = 0.2304\n",
            "Epoch 2537/3334\n",
            "Epoch 2537: Training Accuracy = 0.9897, Training Loss = 0.1020, Validation Accuracy = 0.9733, Validation Loss = 0.1943\n",
            "Epoch 2538/3334\n",
            "Epoch 2538: Training Accuracy = 0.9897, Training Loss = 0.1020, Validation Accuracy = 0.9733, Validation Loss = 0.1943\n",
            "Epoch 2539/3334\n",
            "Epoch 2539: Training Accuracy = 0.9897, Training Loss = 0.1020, Validation Accuracy = 0.9733, Validation Loss = 0.1943\n",
            "Epoch 2540/3334\n",
            "Epoch 2540: Training Accuracy = 0.9897, Training Loss = 0.1020, Validation Accuracy = 0.9733, Validation Loss = 0.1943\n",
            "Epoch 2541/3334\n",
            "Epoch 2541: Training Accuracy = 0.9922, Training Loss = 0.0804, Validation Accuracy = 0.9739, Validation Loss = 0.1828\n",
            "Epoch 2542/3334\n",
            "Epoch 2542: Training Accuracy = 0.9922, Training Loss = 0.0804, Validation Accuracy = 0.9739, Validation Loss = 0.1828\n",
            "Epoch 2543/3334\n",
            "Epoch 2543: Training Accuracy = 0.9922, Training Loss = 0.0804, Validation Accuracy = 0.9739, Validation Loss = 0.1828\n",
            "Epoch 2544/3334\n",
            "Epoch 2544: Training Accuracy = 0.9873, Training Loss = 0.0947, Validation Accuracy = 0.9740, Validation Loss = 0.1734\n",
            "Epoch 2545/3334\n",
            "Epoch 2545: Training Accuracy = 0.9873, Training Loss = 0.0947, Validation Accuracy = 0.9740, Validation Loss = 0.1734\n",
            "Epoch 2546/3334\n",
            "Epoch 2546: Training Accuracy = 0.9873, Training Loss = 0.0947, Validation Accuracy = 0.9740, Validation Loss = 0.1734\n",
            "Epoch 2547/3334\n",
            "Epoch 2547: Training Accuracy = 0.9897, Training Loss = 0.0836, Validation Accuracy = 0.9739, Validation Loss = 0.1695\n",
            "Epoch 2548/3334\n",
            "Epoch 2548: Training Accuracy = 0.9897, Training Loss = 0.0836, Validation Accuracy = 0.9739, Validation Loss = 0.1695\n",
            "Epoch 2549/3334\n",
            "Epoch 2549: Training Accuracy = 0.9897, Training Loss = 0.0836, Validation Accuracy = 0.9739, Validation Loss = 0.1695\n",
            "Epoch 2550/3334\n",
            "Epoch 2550: Training Accuracy = 0.9897, Training Loss = 0.0836, Validation Accuracy = 0.9739, Validation Loss = 0.1695\n",
            "Epoch 2551/3334\n",
            "Epoch 2551: Training Accuracy = 0.9844, Training Loss = 0.1041, Validation Accuracy = 0.9739, Validation Loss = 0.1689\n",
            "Epoch 2552/3334\n",
            "Epoch 2552: Training Accuracy = 0.9844, Training Loss = 0.1041, Validation Accuracy = 0.9739, Validation Loss = 0.1689\n",
            "Epoch 2553/3334\n",
            "Epoch 2553: Training Accuracy = 0.9844, Training Loss = 0.1041, Validation Accuracy = 0.9739, Validation Loss = 0.1689\n",
            "Epoch 2554/3334\n",
            "Epoch 2554: Training Accuracy = 0.9902, Training Loss = 0.0793, Validation Accuracy = 0.9734, Validation Loss = 0.1679\n",
            "Epoch 2555/3334\n",
            "Epoch 2555: Training Accuracy = 0.9902, Training Loss = 0.0793, Validation Accuracy = 0.9734, Validation Loss = 0.1679\n",
            "Epoch 2556/3334\n",
            "Epoch 2556: Training Accuracy = 0.9902, Training Loss = 0.0793, Validation Accuracy = 0.9734, Validation Loss = 0.1679\n",
            "Epoch 2557/3334\n",
            "Epoch 2557: Training Accuracy = 0.9922, Training Loss = 0.0714, Validation Accuracy = 0.9736, Validation Loss = 0.1662\n",
            "Epoch 2558/3334\n",
            "Epoch 2558: Training Accuracy = 0.9922, Training Loss = 0.0714, Validation Accuracy = 0.9736, Validation Loss = 0.1662\n",
            "Epoch 2559/3334\n",
            "Epoch 2559: Training Accuracy = 0.9922, Training Loss = 0.0714, Validation Accuracy = 0.9736, Validation Loss = 0.1662\n",
            "Epoch 2560/3334\n",
            "Epoch 2560: Training Accuracy = 0.9922, Training Loss = 0.0714, Validation Accuracy = 0.9736, Validation Loss = 0.1662\n",
            "Epoch 2561/3334\n",
            "Epoch 2561: Training Accuracy = 0.9922, Training Loss = 0.0702, Validation Accuracy = 0.9737, Validation Loss = 0.1696\n",
            "Epoch 2562/3334\n",
            "Epoch 2562: Training Accuracy = 0.9922, Training Loss = 0.0702, Validation Accuracy = 0.9737, Validation Loss = 0.1696\n",
            "Epoch 2563/3334\n",
            "Epoch 2563: Training Accuracy = 0.9922, Training Loss = 0.0702, Validation Accuracy = 0.9737, Validation Loss = 0.1696\n",
            "Epoch 2564/3334\n",
            "Epoch 2564: Training Accuracy = 0.9922, Training Loss = 0.0716, Validation Accuracy = 0.9733, Validation Loss = 0.1664\n",
            "Epoch 2565/3334\n",
            "Epoch 2565: Training Accuracy = 0.9922, Training Loss = 0.0716, Validation Accuracy = 0.9733, Validation Loss = 0.1664\n",
            "Epoch 2566/3334\n",
            "Epoch 2566: Training Accuracy = 0.9922, Training Loss = 0.0716, Validation Accuracy = 0.9733, Validation Loss = 0.1664\n",
            "Epoch 2567/3334\n",
            "Epoch 2567: Training Accuracy = 0.9897, Training Loss = 0.0844, Validation Accuracy = 0.9740, Validation Loss = 0.1677\n",
            "Epoch 2568/3334\n",
            "Epoch 2568: Training Accuracy = 0.9897, Training Loss = 0.0844, Validation Accuracy = 0.9740, Validation Loss = 0.1677\n",
            "Epoch 2569/3334\n",
            "Epoch 2569: Training Accuracy = 0.9897, Training Loss = 0.0844, Validation Accuracy = 0.9740, Validation Loss = 0.1677\n",
            "Epoch 2570/3334\n",
            "Epoch 2570: Training Accuracy = 0.9897, Training Loss = 0.0844, Validation Accuracy = 0.9740, Validation Loss = 0.1677\n",
            "Epoch 2571/3334\n",
            "Epoch 2571: Training Accuracy = 0.9932, Training Loss = 0.0701, Validation Accuracy = 0.9750, Validation Loss = 0.1660\n",
            "Epoch 2572/3334\n",
            "Epoch 2572: Training Accuracy = 0.9932, Training Loss = 0.0701, Validation Accuracy = 0.9750, Validation Loss = 0.1660\n",
            "Epoch 2573/3334\n",
            "Epoch 2573: Training Accuracy = 0.9932, Training Loss = 0.0701, Validation Accuracy = 0.9750, Validation Loss = 0.1660\n",
            "Epoch 2574/3334\n",
            "Epoch 2574: Training Accuracy = 0.3955, Training Loss = 2.3958, Validation Accuracy = 0.4573, Validation Loss = 2.2220\n",
            "Epoch 2575/3334\n",
            "Epoch 2575: Training Accuracy = 0.3955, Training Loss = 2.3958, Validation Accuracy = 0.4573, Validation Loss = 2.2220\n",
            "Epoch 2576/3334\n",
            "Epoch 2576: Training Accuracy = 0.3955, Training Loss = 2.3958, Validation Accuracy = 0.4573, Validation Loss = 2.2220\n",
            "Epoch 2577/3334\n",
            "Epoch 2577: Training Accuracy = 0.9070, Training Loss = 0.6671, Validation Accuracy = 0.8640, Validation Loss = 0.8047\n",
            "Epoch 2578/3334\n",
            "Epoch 2578: Training Accuracy = 0.9070, Training Loss = 0.6671, Validation Accuracy = 0.8640, Validation Loss = 0.8047\n",
            "Epoch 2579/3334\n",
            "Epoch 2579: Training Accuracy = 0.9070, Training Loss = 0.6671, Validation Accuracy = 0.8640, Validation Loss = 0.8047\n",
            "Epoch 2580/3334\n",
            "Epoch 2580: Training Accuracy = 0.9070, Training Loss = 0.6671, Validation Accuracy = 0.8640, Validation Loss = 0.8047\n",
            "Epoch 2581/3334\n",
            "Epoch 2581: Training Accuracy = 0.9912, Training Loss = 0.2509, Validation Accuracy = 0.9586, Validation Loss = 0.3979\n",
            "Epoch 2582/3334\n",
            "Epoch 2582: Training Accuracy = 0.9912, Training Loss = 0.2509, Validation Accuracy = 0.9586, Validation Loss = 0.3979\n",
            "Epoch 2583/3334\n",
            "Epoch 2583: Training Accuracy = 0.9912, Training Loss = 0.2509, Validation Accuracy = 0.9586, Validation Loss = 0.3979\n",
            "Epoch 2584/3334\n",
            "Epoch 2584: Training Accuracy = 0.9844, Training Loss = 0.1685, Validation Accuracy = 0.9728, Validation Loss = 0.2524\n",
            "Epoch 2585/3334\n",
            "Epoch 2585: Training Accuracy = 0.9844, Training Loss = 0.1685, Validation Accuracy = 0.9728, Validation Loss = 0.2524\n",
            "Epoch 2586/3334\n",
            "Epoch 2586: Training Accuracy = 0.9844, Training Loss = 0.1685, Validation Accuracy = 0.9728, Validation Loss = 0.2524\n",
            "Epoch 2587/3334\n",
            "Epoch 2587: Training Accuracy = 0.9845, Training Loss = 0.1349, Validation Accuracy = 0.9751, Validation Loss = 0.2063\n",
            "Epoch 2588/3334\n",
            "Epoch 2588: Training Accuracy = 0.9845, Training Loss = 0.1349, Validation Accuracy = 0.9751, Validation Loss = 0.2063\n",
            "Epoch 2589/3334\n",
            "Epoch 2589: Training Accuracy = 0.9845, Training Loss = 0.1349, Validation Accuracy = 0.9751, Validation Loss = 0.2063\n",
            "Epoch 2590/3334\n",
            "Epoch 2590: Training Accuracy = 0.9845, Training Loss = 0.1349, Validation Accuracy = 0.9751, Validation Loss = 0.2063\n",
            "Epoch 2591/3334\n",
            "Epoch 2591: Training Accuracy = 0.9844, Training Loss = 0.1174, Validation Accuracy = 0.9750, Validation Loss = 0.1883\n",
            "Epoch 2592/3334\n",
            "Epoch 2592: Training Accuracy = 0.9844, Training Loss = 0.1174, Validation Accuracy = 0.9750, Validation Loss = 0.1883\n",
            "Epoch 2593/3334\n",
            "Epoch 2593: Training Accuracy = 0.9844, Training Loss = 0.1174, Validation Accuracy = 0.9750, Validation Loss = 0.1883\n",
            "Epoch 2594/3334\n",
            "Epoch 2594: Training Accuracy = 0.9883, Training Loss = 0.0971, Validation Accuracy = 0.9743, Validation Loss = 0.1803\n",
            "Epoch 2595/3334\n",
            "Epoch 2595: Training Accuracy = 0.9883, Training Loss = 0.0971, Validation Accuracy = 0.9743, Validation Loss = 0.1803\n",
            "Epoch 2596/3334\n",
            "Epoch 2596: Training Accuracy = 0.9883, Training Loss = 0.0971, Validation Accuracy = 0.9743, Validation Loss = 0.1803\n",
            "Epoch 2597/3334\n",
            "Epoch 2597: Training Accuracy = 0.9884, Training Loss = 0.0934, Validation Accuracy = 0.9739, Validation Loss = 0.1745\n",
            "Epoch 2598/3334\n",
            "Epoch 2598: Training Accuracy = 0.9884, Training Loss = 0.0934, Validation Accuracy = 0.9739, Validation Loss = 0.1745\n",
            "Epoch 2599/3334\n",
            "Epoch 2599: Training Accuracy = 0.9884, Training Loss = 0.0934, Validation Accuracy = 0.9739, Validation Loss = 0.1745\n",
            "Epoch 2600/3334\n",
            "Epoch 2600: Training Accuracy = 0.9884, Training Loss = 0.0934, Validation Accuracy = 0.9739, Validation Loss = 0.1745\n",
            "Epoch 2601/3334\n",
            "Epoch 2601: Training Accuracy = 0.9873, Training Loss = 0.0977, Validation Accuracy = 0.9736, Validation Loss = 0.1728\n",
            "Epoch 2602/3334\n",
            "Epoch 2602: Training Accuracy = 0.9873, Training Loss = 0.0977, Validation Accuracy = 0.9736, Validation Loss = 0.1728\n",
            "Epoch 2603/3334\n",
            "Epoch 2603: Training Accuracy = 0.9873, Training Loss = 0.0977, Validation Accuracy = 0.9736, Validation Loss = 0.1728\n",
            "Epoch 2604/3334\n",
            "Epoch 2604: Training Accuracy = 0.9922, Training Loss = 0.0762, Validation Accuracy = 0.9740, Validation Loss = 0.1683\n",
            "Epoch 2605/3334\n",
            "Epoch 2605: Training Accuracy = 0.9922, Training Loss = 0.0762, Validation Accuracy = 0.9740, Validation Loss = 0.1683\n",
            "Epoch 2606/3334\n",
            "Epoch 2606: Training Accuracy = 0.9922, Training Loss = 0.0762, Validation Accuracy = 0.9740, Validation Loss = 0.1683\n",
            "Epoch 2607/3334\n",
            "Epoch 2607: Training Accuracy = 0.9884, Training Loss = 0.0914, Validation Accuracy = 0.9734, Validation Loss = 0.1663\n",
            "Epoch 2608/3334\n",
            "Epoch 2608: Training Accuracy = 0.9884, Training Loss = 0.0914, Validation Accuracy = 0.9734, Validation Loss = 0.1663\n",
            "Epoch 2609/3334\n",
            "Epoch 2609: Training Accuracy = 0.9884, Training Loss = 0.0914, Validation Accuracy = 0.9734, Validation Loss = 0.1663\n",
            "Epoch 2610/3334\n",
            "Epoch 2610: Training Accuracy = 0.9884, Training Loss = 0.0914, Validation Accuracy = 0.9734, Validation Loss = 0.1663\n",
            "Epoch 2611/3334\n",
            "Epoch 2611: Training Accuracy = 0.9912, Training Loss = 0.0801, Validation Accuracy = 0.9733, Validation Loss = 0.1669\n",
            "Epoch 2612/3334\n",
            "Epoch 2612: Training Accuracy = 0.9912, Training Loss = 0.0801, Validation Accuracy = 0.9733, Validation Loss = 0.1669\n",
            "Epoch 2613/3334\n",
            "Epoch 2613: Training Accuracy = 0.9912, Training Loss = 0.0801, Validation Accuracy = 0.9733, Validation Loss = 0.1669\n",
            "Epoch 2614/3334\n",
            "Epoch 2614: Training Accuracy = 0.9873, Training Loss = 0.0930, Validation Accuracy = 0.9737, Validation Loss = 0.1668\n",
            "Epoch 2615/3334\n",
            "Epoch 2615: Training Accuracy = 0.9873, Training Loss = 0.0930, Validation Accuracy = 0.9737, Validation Loss = 0.1668\n",
            "Epoch 2616/3334\n",
            "Epoch 2616: Training Accuracy = 0.9873, Training Loss = 0.0930, Validation Accuracy = 0.9737, Validation Loss = 0.1668\n",
            "Epoch 2617/3334\n",
            "Epoch 2617: Training Accuracy = 0.9884, Training Loss = 0.0891, Validation Accuracy = 0.9742, Validation Loss = 0.1717\n",
            "Epoch 2618/3334\n",
            "Epoch 2618: Training Accuracy = 0.9884, Training Loss = 0.0891, Validation Accuracy = 0.9742, Validation Loss = 0.1717\n",
            "Epoch 2619/3334\n",
            "Epoch 2619: Training Accuracy = 0.9884, Training Loss = 0.0891, Validation Accuracy = 0.9742, Validation Loss = 0.1717\n",
            "Epoch 2620/3334\n",
            "Epoch 2620: Training Accuracy = 0.9884, Training Loss = 0.0891, Validation Accuracy = 0.9742, Validation Loss = 0.1717\n",
            "Epoch 2621/3334\n",
            "Epoch 2621: Training Accuracy = 0.9873, Training Loss = 0.0959, Validation Accuracy = 0.9734, Validation Loss = 0.1662\n",
            "Epoch 2622/3334\n",
            "Epoch 2622: Training Accuracy = 0.9873, Training Loss = 0.0959, Validation Accuracy = 0.9734, Validation Loss = 0.1662\n",
            "Epoch 2623/3334\n",
            "Epoch 2623: Training Accuracy = 0.9873, Training Loss = 0.0959, Validation Accuracy = 0.9734, Validation Loss = 0.1662\n",
            "Epoch 2624/3334\n",
            "Epoch 2624: Training Accuracy = 0.9062, Training Loss = 0.5995, Validation Accuracy = 0.0937, Validation Loss = 4.4495\n",
            "Epoch 2625/3334\n",
            "Epoch 2625: Training Accuracy = 0.9062, Training Loss = 0.5995, Validation Accuracy = 0.0937, Validation Loss = 4.4495\n",
            "Epoch 2626/3334\n",
            "Epoch 2626: Training Accuracy = 0.9062, Training Loss = 0.5995, Validation Accuracy = 0.0937, Validation Loss = 4.4495\n",
            "Epoch 2627/3334\n",
            "Epoch 2627: Training Accuracy = 0.8953, Training Loss = 0.7234, Validation Accuracy = 0.8561, Validation Loss = 0.8300\n",
            "Epoch 2628/3334\n",
            "Epoch 2628: Training Accuracy = 0.8953, Training Loss = 0.7234, Validation Accuracy = 0.8561, Validation Loss = 0.8300\n",
            "Epoch 2629/3334\n",
            "Epoch 2629: Training Accuracy = 0.8953, Training Loss = 0.7234, Validation Accuracy = 0.8561, Validation Loss = 0.8300\n",
            "Epoch 2630/3334\n",
            "Epoch 2630: Training Accuracy = 0.8953, Training Loss = 0.7234, Validation Accuracy = 0.8561, Validation Loss = 0.8300\n",
            "Epoch 2631/3334\n",
            "Epoch 2631: Training Accuracy = 0.9805, Training Loss = 0.2872, Validation Accuracy = 0.9493, Validation Loss = 0.4258\n",
            "Epoch 2632/3334\n",
            "Epoch 2632: Training Accuracy = 0.9805, Training Loss = 0.2872, Validation Accuracy = 0.9493, Validation Loss = 0.4258\n",
            "Epoch 2633/3334\n",
            "Epoch 2633: Training Accuracy = 0.9805, Training Loss = 0.2872, Validation Accuracy = 0.9493, Validation Loss = 0.4258\n",
            "Epoch 2634/3334\n",
            "Epoch 2634: Training Accuracy = 0.9863, Training Loss = 0.1742, Validation Accuracy = 0.9643, Validation Loss = 0.2916\n",
            "Epoch 2635/3334\n",
            "Epoch 2635: Training Accuracy = 0.9863, Training Loss = 0.1742, Validation Accuracy = 0.9643, Validation Loss = 0.2916\n",
            "Epoch 2636/3334\n",
            "Epoch 2636: Training Accuracy = 0.9863, Training Loss = 0.1742, Validation Accuracy = 0.9643, Validation Loss = 0.2916\n",
            "Epoch 2637/3334\n",
            "Epoch 2637: Training Accuracy = 0.9858, Training Loss = 0.1465, Validation Accuracy = 0.9678, Validation Loss = 0.2342\n",
            "Epoch 2638/3334\n",
            "Epoch 2638: Training Accuracy = 0.9858, Training Loss = 0.1465, Validation Accuracy = 0.9678, Validation Loss = 0.2342\n",
            "Epoch 2639/3334\n",
            "Epoch 2639: Training Accuracy = 0.9858, Training Loss = 0.1465, Validation Accuracy = 0.9678, Validation Loss = 0.2342\n",
            "Epoch 2640/3334\n",
            "Epoch 2640: Training Accuracy = 0.9858, Training Loss = 0.1465, Validation Accuracy = 0.9678, Validation Loss = 0.2342\n",
            "Epoch 2641/3334\n",
            "Epoch 2641: Training Accuracy = 0.9912, Training Loss = 0.1077, Validation Accuracy = 0.9707, Validation Loss = 0.2115\n",
            "Epoch 2642/3334\n",
            "Epoch 2642: Training Accuracy = 0.9912, Training Loss = 0.1077, Validation Accuracy = 0.9707, Validation Loss = 0.2115\n",
            "Epoch 2643/3334\n",
            "Epoch 2643: Training Accuracy = 0.9912, Training Loss = 0.1077, Validation Accuracy = 0.9707, Validation Loss = 0.2115\n",
            "Epoch 2644/3334\n",
            "Epoch 2644: Training Accuracy = 0.9912, Training Loss = 0.0984, Validation Accuracy = 0.9696, Validation Loss = 0.1985\n",
            "Epoch 2645/3334\n",
            "Epoch 2645: Training Accuracy = 0.9912, Training Loss = 0.0984, Validation Accuracy = 0.9696, Validation Loss = 0.1985\n",
            "Epoch 2646/3334\n",
            "Epoch 2646: Training Accuracy = 0.9912, Training Loss = 0.0984, Validation Accuracy = 0.9696, Validation Loss = 0.1985\n",
            "Epoch 2647/3334\n",
            "Epoch 2647: Training Accuracy = 0.9897, Training Loss = 0.1014, Validation Accuracy = 0.9705, Validation Loss = 0.1947\n",
            "Epoch 2648/3334\n",
            "Epoch 2648: Training Accuracy = 0.9897, Training Loss = 0.1014, Validation Accuracy = 0.9705, Validation Loss = 0.1947\n",
            "Epoch 2649/3334\n",
            "Epoch 2649: Training Accuracy = 0.9897, Training Loss = 0.1014, Validation Accuracy = 0.9705, Validation Loss = 0.1947\n",
            "Epoch 2650/3334\n",
            "Epoch 2650: Training Accuracy = 0.9897, Training Loss = 0.1014, Validation Accuracy = 0.9705, Validation Loss = 0.1947\n",
            "Epoch 2651/3334\n",
            "Epoch 2651: Training Accuracy = 0.9922, Training Loss = 0.0884, Validation Accuracy = 0.9709, Validation Loss = 0.1902\n",
            "Epoch 2652/3334\n",
            "Epoch 2652: Training Accuracy = 0.9922, Training Loss = 0.0884, Validation Accuracy = 0.9709, Validation Loss = 0.1902\n",
            "Epoch 2653/3334\n",
            "Epoch 2653: Training Accuracy = 0.9922, Training Loss = 0.0884, Validation Accuracy = 0.9709, Validation Loss = 0.1902\n",
            "Epoch 2654/3334\n",
            "Epoch 2654: Training Accuracy = 0.9893, Training Loss = 0.0999, Validation Accuracy = 0.9713, Validation Loss = 0.1900\n",
            "Epoch 2655/3334\n",
            "Epoch 2655: Training Accuracy = 0.9893, Training Loss = 0.0999, Validation Accuracy = 0.9713, Validation Loss = 0.1900\n",
            "Epoch 2656/3334\n",
            "Epoch 2656: Training Accuracy = 0.9893, Training Loss = 0.0999, Validation Accuracy = 0.9713, Validation Loss = 0.1900\n",
            "Epoch 2657/3334\n",
            "Epoch 2657: Training Accuracy = 0.9922, Training Loss = 0.0883, Validation Accuracy = 0.9718, Validation Loss = 0.1894\n",
            "Epoch 2658/3334\n",
            "Epoch 2658: Training Accuracy = 0.9922, Training Loss = 0.0883, Validation Accuracy = 0.9718, Validation Loss = 0.1894\n",
            "Epoch 2659/3334\n",
            "Epoch 2659: Training Accuracy = 0.9922, Training Loss = 0.0883, Validation Accuracy = 0.9718, Validation Loss = 0.1894\n",
            "Epoch 2660/3334\n",
            "Epoch 2660: Training Accuracy = 0.9922, Training Loss = 0.0883, Validation Accuracy = 0.9718, Validation Loss = 0.1894\n",
            "Epoch 2661/3334\n",
            "Epoch 2661: Training Accuracy = 0.9893, Training Loss = 0.0923, Validation Accuracy = 0.9713, Validation Loss = 0.1854\n",
            "Epoch 2662/3334\n",
            "Epoch 2662: Training Accuracy = 0.9893, Training Loss = 0.0923, Validation Accuracy = 0.9713, Validation Loss = 0.1854\n",
            "Epoch 2663/3334\n",
            "Epoch 2663: Training Accuracy = 0.9893, Training Loss = 0.0923, Validation Accuracy = 0.9713, Validation Loss = 0.1854\n",
            "Epoch 2664/3334\n",
            "Epoch 2664: Training Accuracy = 0.9902, Training Loss = 0.0858, Validation Accuracy = 0.9719, Validation Loss = 0.1794\n",
            "Epoch 2665/3334\n",
            "Epoch 2665: Training Accuracy = 0.9902, Training Loss = 0.0858, Validation Accuracy = 0.9719, Validation Loss = 0.1794\n",
            "Epoch 2666/3334\n",
            "Epoch 2666: Training Accuracy = 0.9902, Training Loss = 0.0858, Validation Accuracy = 0.9719, Validation Loss = 0.1794\n",
            "Epoch 2667/3334\n",
            "Epoch 2667: Training Accuracy = 0.9871, Training Loss = 0.1009, Validation Accuracy = 0.9725, Validation Loss = 0.1789\n",
            "Epoch 2668/3334\n",
            "Epoch 2668: Training Accuracy = 0.9871, Training Loss = 0.1009, Validation Accuracy = 0.9725, Validation Loss = 0.1789\n",
            "Epoch 2669/3334\n",
            "Epoch 2669: Training Accuracy = 0.9871, Training Loss = 0.1009, Validation Accuracy = 0.9725, Validation Loss = 0.1789\n",
            "Epoch 2670/3334\n",
            "Epoch 2670: Training Accuracy = 0.9871, Training Loss = 0.1009, Validation Accuracy = 0.9725, Validation Loss = 0.1789\n",
            "Epoch 2671/3334\n",
            "Epoch 2671: Training Accuracy = 0.9912, Training Loss = 0.0797, Validation Accuracy = 0.9722, Validation Loss = 0.1775\n",
            "Epoch 2672/3334\n",
            "Epoch 2672: Training Accuracy = 0.9912, Training Loss = 0.0797, Validation Accuracy = 0.9722, Validation Loss = 0.1775\n",
            "Epoch 2673/3334\n",
            "Epoch 2673: Training Accuracy = 0.9912, Training Loss = 0.0797, Validation Accuracy = 0.9722, Validation Loss = 0.1775\n",
            "Epoch 2674/3334\n",
            "Epoch 2674: Training Accuracy = 0.9844, Training Loss = 0.1178, Validation Accuracy = 0.9660, Validation Loss = 0.3530\n",
            "Epoch 2675/3334\n",
            "Epoch 2675: Training Accuracy = 0.9844, Training Loss = 0.1178, Validation Accuracy = 0.9660, Validation Loss = 0.3530\n",
            "Epoch 2676/3334\n",
            "Epoch 2676: Training Accuracy = 0.9844, Training Loss = 0.1178, Validation Accuracy = 0.9660, Validation Loss = 0.3530\n",
            "Epoch 2677/3334\n",
            "Epoch 2677: Training Accuracy = 0.7649, Training Loss = 1.1616, Validation Accuracy = 0.6847, Validation Loss = 1.3679\n",
            "Epoch 2678/3334\n",
            "Epoch 2678: Training Accuracy = 0.7649, Training Loss = 1.1616, Validation Accuracy = 0.6847, Validation Loss = 1.3679\n",
            "Epoch 2679/3334\n",
            "Epoch 2679: Training Accuracy = 0.7649, Training Loss = 1.1616, Validation Accuracy = 0.6847, Validation Loss = 1.3679\n",
            "Epoch 2680/3334\n",
            "Epoch 2680: Training Accuracy = 0.7649, Training Loss = 1.1616, Validation Accuracy = 0.6847, Validation Loss = 1.3679\n",
            "Epoch 2681/3334\n",
            "Epoch 2681: Training Accuracy = 0.9482, Training Loss = 0.4526, Validation Accuracy = 0.9183, Validation Loss = 0.5637\n",
            "Epoch 2682/3334\n",
            "Epoch 2682: Training Accuracy = 0.9482, Training Loss = 0.4526, Validation Accuracy = 0.9183, Validation Loss = 0.5637\n",
            "Epoch 2683/3334\n",
            "Epoch 2683: Training Accuracy = 0.9482, Training Loss = 0.4526, Validation Accuracy = 0.9183, Validation Loss = 0.5637\n",
            "Epoch 2684/3334\n",
            "Epoch 2684: Training Accuracy = 0.9883, Training Loss = 0.2110, Validation Accuracy = 0.9671, Validation Loss = 0.3300\n",
            "Epoch 2685/3334\n",
            "Epoch 2685: Training Accuracy = 0.9883, Training Loss = 0.2110, Validation Accuracy = 0.9671, Validation Loss = 0.3300\n",
            "Epoch 2686/3334\n",
            "Epoch 2686: Training Accuracy = 0.9883, Training Loss = 0.2110, Validation Accuracy = 0.9671, Validation Loss = 0.3300\n",
            "Epoch 2687/3334\n",
            "Epoch 2687: Training Accuracy = 0.9845, Training Loss = 0.1554, Validation Accuracy = 0.9731, Validation Loss = 0.2409\n",
            "Epoch 2688/3334\n",
            "Epoch 2688: Training Accuracy = 0.9845, Training Loss = 0.1554, Validation Accuracy = 0.9731, Validation Loss = 0.2409\n",
            "Epoch 2689/3334\n",
            "Epoch 2689: Training Accuracy = 0.9845, Training Loss = 0.1554, Validation Accuracy = 0.9731, Validation Loss = 0.2409\n",
            "Epoch 2690/3334\n",
            "Epoch 2690: Training Accuracy = 0.9845, Training Loss = 0.1554, Validation Accuracy = 0.9731, Validation Loss = 0.2409\n",
            "Epoch 2691/3334\n",
            "Epoch 2691: Training Accuracy = 0.9834, Training Loss = 0.1317, Validation Accuracy = 0.9733, Validation Loss = 0.2035\n",
            "Epoch 2692/3334\n",
            "Epoch 2692: Training Accuracy = 0.9834, Training Loss = 0.1317, Validation Accuracy = 0.9733, Validation Loss = 0.2035\n",
            "Epoch 2693/3334\n",
            "Epoch 2693: Training Accuracy = 0.9834, Training Loss = 0.1317, Validation Accuracy = 0.9733, Validation Loss = 0.2035\n",
            "Epoch 2694/3334\n",
            "Epoch 2694: Training Accuracy = 0.9951, Training Loss = 0.0815, Validation Accuracy = 0.9743, Validation Loss = 0.1861\n",
            "Epoch 2695/3334\n",
            "Epoch 2695: Training Accuracy = 0.9951, Training Loss = 0.0815, Validation Accuracy = 0.9743, Validation Loss = 0.1861\n",
            "Epoch 2696/3334\n",
            "Epoch 2696: Training Accuracy = 0.9951, Training Loss = 0.0815, Validation Accuracy = 0.9743, Validation Loss = 0.1861\n",
            "Epoch 2697/3334\n",
            "Epoch 2697: Training Accuracy = 0.9922, Training Loss = 0.0875, Validation Accuracy = 0.9746, Validation Loss = 0.1774\n",
            "Epoch 2698/3334\n",
            "Epoch 2698: Training Accuracy = 0.9922, Training Loss = 0.0875, Validation Accuracy = 0.9746, Validation Loss = 0.1774\n",
            "Epoch 2699/3334\n",
            "Epoch 2699: Training Accuracy = 0.9922, Training Loss = 0.0875, Validation Accuracy = 0.9746, Validation Loss = 0.1774\n",
            "Epoch 2700/3334\n",
            "Epoch 2700: Training Accuracy = 0.9922, Training Loss = 0.0875, Validation Accuracy = 0.9746, Validation Loss = 0.1774\n",
            "Epoch 2701/3334\n",
            "Epoch 2701: Training Accuracy = 0.9883, Training Loss = 0.0938, Validation Accuracy = 0.9736, Validation Loss = 0.1741\n",
            "Epoch 2702/3334\n",
            "Epoch 2702: Training Accuracy = 0.9883, Training Loss = 0.0938, Validation Accuracy = 0.9736, Validation Loss = 0.1741\n",
            "Epoch 2703/3334\n",
            "Epoch 2703: Training Accuracy = 0.9883, Training Loss = 0.0938, Validation Accuracy = 0.9736, Validation Loss = 0.1741\n",
            "Epoch 2704/3334\n",
            "Epoch 2704: Training Accuracy = 0.9902, Training Loss = 0.0885, Validation Accuracy = 0.9734, Validation Loss = 0.1727\n",
            "Epoch 2705/3334\n",
            "Epoch 2705: Training Accuracy = 0.9902, Training Loss = 0.0885, Validation Accuracy = 0.9734, Validation Loss = 0.1727\n",
            "Epoch 2706/3334\n",
            "Epoch 2706: Training Accuracy = 0.9902, Training Loss = 0.0885, Validation Accuracy = 0.9734, Validation Loss = 0.1727\n",
            "Epoch 2707/3334\n",
            "Epoch 2707: Training Accuracy = 0.9884, Training Loss = 0.0937, Validation Accuracy = 0.9736, Validation Loss = 0.1723\n",
            "Epoch 2708/3334\n",
            "Epoch 2708: Training Accuracy = 0.9884, Training Loss = 0.0937, Validation Accuracy = 0.9736, Validation Loss = 0.1723\n",
            "Epoch 2709/3334\n",
            "Epoch 2709: Training Accuracy = 0.9884, Training Loss = 0.0937, Validation Accuracy = 0.9736, Validation Loss = 0.1723\n",
            "Epoch 2710/3334\n",
            "Epoch 2710: Training Accuracy = 0.9884, Training Loss = 0.0937, Validation Accuracy = 0.9736, Validation Loss = 0.1723\n",
            "Epoch 2711/3334\n",
            "Epoch 2711: Training Accuracy = 0.9883, Training Loss = 0.0962, Validation Accuracy = 0.9745, Validation Loss = 0.1696\n",
            "Epoch 2712/3334\n",
            "Epoch 2712: Training Accuracy = 0.9883, Training Loss = 0.0962, Validation Accuracy = 0.9745, Validation Loss = 0.1696\n",
            "Epoch 2713/3334\n",
            "Epoch 2713: Training Accuracy = 0.9883, Training Loss = 0.0962, Validation Accuracy = 0.9745, Validation Loss = 0.1696\n",
            "Epoch 2714/3334\n",
            "Epoch 2714: Training Accuracy = 0.9844, Training Loss = 0.1061, Validation Accuracy = 0.9740, Validation Loss = 0.1678\n",
            "Epoch 2715/3334\n",
            "Epoch 2715: Training Accuracy = 0.9844, Training Loss = 0.1061, Validation Accuracy = 0.9740, Validation Loss = 0.1678\n",
            "Epoch 2716/3334\n",
            "Epoch 2716: Training Accuracy = 0.9844, Training Loss = 0.1061, Validation Accuracy = 0.9740, Validation Loss = 0.1678\n",
            "Epoch 2717/3334\n",
            "Epoch 2717: Training Accuracy = 0.9922, Training Loss = 0.0807, Validation Accuracy = 0.9728, Validation Loss = 0.1671\n",
            "Epoch 2718/3334\n",
            "Epoch 2718: Training Accuracy = 0.9922, Training Loss = 0.0807, Validation Accuracy = 0.9728, Validation Loss = 0.1671\n",
            "Epoch 2719/3334\n",
            "Epoch 2719: Training Accuracy = 0.9922, Training Loss = 0.0807, Validation Accuracy = 0.9728, Validation Loss = 0.1671\n",
            "Epoch 2720/3334\n",
            "Epoch 2720: Training Accuracy = 0.9922, Training Loss = 0.0807, Validation Accuracy = 0.9728, Validation Loss = 0.1671\n",
            "Epoch 2721/3334\n",
            "Epoch 2721: Training Accuracy = 0.9873, Training Loss = 0.0950, Validation Accuracy = 0.9745, Validation Loss = 0.1686\n",
            "Epoch 2722/3334\n",
            "Epoch 2722: Training Accuracy = 0.9873, Training Loss = 0.0950, Validation Accuracy = 0.9745, Validation Loss = 0.1686\n",
            "Epoch 2723/3334\n",
            "Epoch 2723: Training Accuracy = 0.9873, Training Loss = 0.0950, Validation Accuracy = 0.9745, Validation Loss = 0.1686\n",
            "Epoch 2724/3334\n",
            "Epoch 2724: Training Accuracy = 0.9844, Training Loss = 0.1108, Validation Accuracy = 0.9731, Validation Loss = 0.1785\n",
            "Epoch 2725/3334\n",
            "Epoch 2725: Training Accuracy = 0.9844, Training Loss = 0.1108, Validation Accuracy = 0.9731, Validation Loss = 0.1785\n",
            "Epoch 2726/3334\n",
            "Epoch 2726: Training Accuracy = 0.9844, Training Loss = 0.1108, Validation Accuracy = 0.9731, Validation Loss = 0.1785\n",
            "Epoch 2727/3334\n",
            "Epoch 2727: Training Accuracy = 0.4393, Training Loss = 2.8018, Validation Accuracy = 0.4509, Validation Loss = 2.5252\n",
            "Epoch 2728/3334\n",
            "Epoch 2728: Training Accuracy = 0.4393, Training Loss = 2.8018, Validation Accuracy = 0.4509, Validation Loss = 2.5252\n",
            "Epoch 2729/3334\n",
            "Epoch 2729: Training Accuracy = 0.4393, Training Loss = 2.8018, Validation Accuracy = 0.4509, Validation Loss = 2.5252\n",
            "Epoch 2730/3334\n",
            "Epoch 2730: Training Accuracy = 0.4393, Training Loss = 2.8018, Validation Accuracy = 0.4509, Validation Loss = 2.5252\n",
            "Epoch 2731/3334\n",
            "Epoch 2731: Training Accuracy = 0.9570, Training Loss = 0.5455, Validation Accuracy = 0.8952, Validation Loss = 0.7334\n",
            "Epoch 2732/3334\n",
            "Epoch 2732: Training Accuracy = 0.9570, Training Loss = 0.5455, Validation Accuracy = 0.8952, Validation Loss = 0.7334\n",
            "Epoch 2733/3334\n",
            "Epoch 2733: Training Accuracy = 0.9570, Training Loss = 0.5455, Validation Accuracy = 0.8952, Validation Loss = 0.7334\n",
            "Epoch 2734/3334\n",
            "Epoch 2734: Training Accuracy = 0.9844, Training Loss = 0.2895, Validation Accuracy = 0.9625, Validation Loss = 0.3814\n",
            "Epoch 2735/3334\n",
            "Epoch 2735: Training Accuracy = 0.9844, Training Loss = 0.2895, Validation Accuracy = 0.9625, Validation Loss = 0.3814\n",
            "Epoch 2736/3334\n",
            "Epoch 2736: Training Accuracy = 0.9844, Training Loss = 0.2895, Validation Accuracy = 0.9625, Validation Loss = 0.3814\n",
            "Epoch 2737/3334\n",
            "Epoch 2737: Training Accuracy = 0.9922, Training Loss = 0.1459, Validation Accuracy = 0.9743, Validation Loss = 0.2528\n",
            "Epoch 2738/3334\n",
            "Epoch 2738: Training Accuracy = 0.9922, Training Loss = 0.1459, Validation Accuracy = 0.9743, Validation Loss = 0.2528\n",
            "Epoch 2739/3334\n",
            "Epoch 2739: Training Accuracy = 0.9922, Training Loss = 0.1459, Validation Accuracy = 0.9743, Validation Loss = 0.2528\n",
            "Epoch 2740/3334\n",
            "Epoch 2740: Training Accuracy = 0.9922, Training Loss = 0.1459, Validation Accuracy = 0.9743, Validation Loss = 0.2528\n",
            "Epoch 2741/3334\n",
            "Epoch 2741: Training Accuracy = 0.9873, Training Loss = 0.1258, Validation Accuracy = 0.9753, Validation Loss = 0.2046\n",
            "Epoch 2742/3334\n",
            "Epoch 2742: Training Accuracy = 0.9873, Training Loss = 0.1258, Validation Accuracy = 0.9753, Validation Loss = 0.2046\n",
            "Epoch 2743/3334\n",
            "Epoch 2743: Training Accuracy = 0.9873, Training Loss = 0.1258, Validation Accuracy = 0.9753, Validation Loss = 0.2046\n",
            "Epoch 2744/3334\n",
            "Epoch 2744: Training Accuracy = 0.9873, Training Loss = 0.1090, Validation Accuracy = 0.9748, Validation Loss = 0.1844\n",
            "Epoch 2745/3334\n",
            "Epoch 2745: Training Accuracy = 0.9873, Training Loss = 0.1090, Validation Accuracy = 0.9748, Validation Loss = 0.1844\n",
            "Epoch 2746/3334\n",
            "Epoch 2746: Training Accuracy = 0.9873, Training Loss = 0.1090, Validation Accuracy = 0.9748, Validation Loss = 0.1844\n",
            "Epoch 2747/3334\n",
            "Epoch 2747: Training Accuracy = 0.9910, Training Loss = 0.0929, Validation Accuracy = 0.9750, Validation Loss = 0.1755\n",
            "Epoch 2748/3334\n",
            "Epoch 2748: Training Accuracy = 0.9910, Training Loss = 0.0929, Validation Accuracy = 0.9750, Validation Loss = 0.1755\n",
            "Epoch 2749/3334\n",
            "Epoch 2749: Training Accuracy = 0.9910, Training Loss = 0.0929, Validation Accuracy = 0.9750, Validation Loss = 0.1755\n",
            "Epoch 2750/3334\n",
            "Epoch 2750: Training Accuracy = 0.9910, Training Loss = 0.0929, Validation Accuracy = 0.9750, Validation Loss = 0.1755\n",
            "Epoch 2751/3334\n",
            "Epoch 2751: Training Accuracy = 0.9873, Training Loss = 0.0993, Validation Accuracy = 0.9743, Validation Loss = 0.1728\n",
            "Epoch 2752/3334\n",
            "Epoch 2752: Training Accuracy = 0.9873, Training Loss = 0.0993, Validation Accuracy = 0.9743, Validation Loss = 0.1728\n",
            "Epoch 2753/3334\n",
            "Epoch 2753: Training Accuracy = 0.9873, Training Loss = 0.0993, Validation Accuracy = 0.9743, Validation Loss = 0.1728\n",
            "Epoch 2754/3334\n",
            "Epoch 2754: Training Accuracy = 0.9883, Training Loss = 0.0945, Validation Accuracy = 0.9740, Validation Loss = 0.1713\n",
            "Epoch 2755/3334\n",
            "Epoch 2755: Training Accuracy = 0.9883, Training Loss = 0.0945, Validation Accuracy = 0.9740, Validation Loss = 0.1713\n",
            "Epoch 2756/3334\n",
            "Epoch 2756: Training Accuracy = 0.9883, Training Loss = 0.0945, Validation Accuracy = 0.9740, Validation Loss = 0.1713\n",
            "Epoch 2757/3334\n",
            "Epoch 2757: Training Accuracy = 0.9871, Training Loss = 0.1023, Validation Accuracy = 0.9740, Validation Loss = 0.1676\n",
            "Epoch 2758/3334\n",
            "Epoch 2758: Training Accuracy = 0.9871, Training Loss = 0.1023, Validation Accuracy = 0.9740, Validation Loss = 0.1676\n",
            "Epoch 2759/3334\n",
            "Epoch 2759: Training Accuracy = 0.9871, Training Loss = 0.1023, Validation Accuracy = 0.9740, Validation Loss = 0.1676\n",
            "Epoch 2760/3334\n",
            "Epoch 2760: Training Accuracy = 0.9871, Training Loss = 0.1023, Validation Accuracy = 0.9740, Validation Loss = 0.1676\n",
            "Epoch 2761/3334\n",
            "Epoch 2761: Training Accuracy = 0.9912, Training Loss = 0.0842, Validation Accuracy = 0.9737, Validation Loss = 0.1659\n",
            "Epoch 2762/3334\n",
            "Epoch 2762: Training Accuracy = 0.9912, Training Loss = 0.0842, Validation Accuracy = 0.9737, Validation Loss = 0.1659\n",
            "Epoch 2763/3334\n",
            "Epoch 2763: Training Accuracy = 0.9912, Training Loss = 0.0842, Validation Accuracy = 0.9737, Validation Loss = 0.1659\n",
            "Epoch 2764/3334\n",
            "Epoch 2764: Training Accuracy = 0.9873, Training Loss = 0.0946, Validation Accuracy = 0.9737, Validation Loss = 0.1663\n",
            "Epoch 2765/3334\n",
            "Epoch 2765: Training Accuracy = 0.9873, Training Loss = 0.0946, Validation Accuracy = 0.9737, Validation Loss = 0.1663\n",
            "Epoch 2766/3334\n",
            "Epoch 2766: Training Accuracy = 0.9873, Training Loss = 0.0946, Validation Accuracy = 0.9737, Validation Loss = 0.1663\n",
            "Epoch 2767/3334\n",
            "Epoch 2767: Training Accuracy = 0.9897, Training Loss = 0.0871, Validation Accuracy = 0.9740, Validation Loss = 0.1640\n",
            "Epoch 2768/3334\n",
            "Epoch 2768: Training Accuracy = 0.9897, Training Loss = 0.0871, Validation Accuracy = 0.9740, Validation Loss = 0.1640\n",
            "Epoch 2769/3334\n",
            "Epoch 2769: Training Accuracy = 0.9897, Training Loss = 0.0871, Validation Accuracy = 0.9740, Validation Loss = 0.1640\n",
            "Epoch 2770/3334\n",
            "Epoch 2770: Training Accuracy = 0.9897, Training Loss = 0.0871, Validation Accuracy = 0.9740, Validation Loss = 0.1640\n",
            "Epoch 2771/3334\n",
            "Epoch 2771: Training Accuracy = 0.9873, Training Loss = 0.0959, Validation Accuracy = 0.9746, Validation Loss = 0.1660\n",
            "Epoch 2772/3334\n",
            "Epoch 2772: Training Accuracy = 0.9873, Training Loss = 0.0959, Validation Accuracy = 0.9746, Validation Loss = 0.1660\n",
            "Epoch 2773/3334\n",
            "Epoch 2773: Training Accuracy = 0.9873, Training Loss = 0.0959, Validation Accuracy = 0.9746, Validation Loss = 0.1660\n",
            "Epoch 2774/3334\n",
            "Epoch 2774: Training Accuracy = 0.9893, Training Loss = 0.0853, Validation Accuracy = 0.9750, Validation Loss = 0.1625\n",
            "Epoch 2775/3334\n",
            "Epoch 2775: Training Accuracy = 0.9893, Training Loss = 0.0853, Validation Accuracy = 0.9750, Validation Loss = 0.1625\n",
            "Epoch 2776/3334\n",
            "Epoch 2776: Training Accuracy = 0.9893, Training Loss = 0.0853, Validation Accuracy = 0.9750, Validation Loss = 0.1625\n",
            "Epoch 2777/3334\n",
            "Epoch 2777: Training Accuracy = 0.1163, Training Loss = 4.1487, Validation Accuracy = 0.2643, Validation Loss = 2.9433\n",
            "Epoch 2778/3334\n",
            "Epoch 2778: Training Accuracy = 0.1163, Training Loss = 4.1487, Validation Accuracy = 0.2643, Validation Loss = 2.9433\n",
            "Epoch 2779/3334\n",
            "Epoch 2779: Training Accuracy = 0.1163, Training Loss = 4.1487, Validation Accuracy = 0.2643, Validation Loss = 2.9433\n",
            "Epoch 2780/3334\n",
            "Epoch 2780: Training Accuracy = 0.1163, Training Loss = 4.1487, Validation Accuracy = 0.2643, Validation Loss = 2.9433\n",
            "Epoch 2781/3334\n",
            "Epoch 2781: Training Accuracy = 0.8818, Training Loss = 0.7331, Validation Accuracy = 0.8767, Validation Loss = 0.7711\n",
            "Epoch 2782/3334\n",
            "Epoch 2782: Training Accuracy = 0.8818, Training Loss = 0.7331, Validation Accuracy = 0.8767, Validation Loss = 0.7711\n",
            "Epoch 2783/3334\n",
            "Epoch 2783: Training Accuracy = 0.8818, Training Loss = 0.7331, Validation Accuracy = 0.8767, Validation Loss = 0.7711\n",
            "Epoch 2784/3334\n",
            "Epoch 2784: Training Accuracy = 0.9775, Training Loss = 0.3034, Validation Accuracy = 0.9543, Validation Loss = 0.4140\n",
            "Epoch 2785/3334\n",
            "Epoch 2785: Training Accuracy = 0.9775, Training Loss = 0.3034, Validation Accuracy = 0.9543, Validation Loss = 0.4140\n",
            "Epoch 2786/3334\n",
            "Epoch 2786: Training Accuracy = 0.9775, Training Loss = 0.3034, Validation Accuracy = 0.9543, Validation Loss = 0.4140\n",
            "Epoch 2787/3334\n",
            "Epoch 2787: Training Accuracy = 0.9858, Training Loss = 0.1950, Validation Accuracy = 0.9712, Validation Loss = 0.2916\n",
            "Epoch 2788/3334\n",
            "Epoch 2788: Training Accuracy = 0.9858, Training Loss = 0.1950, Validation Accuracy = 0.9712, Validation Loss = 0.2916\n",
            "Epoch 2789/3334\n",
            "Epoch 2789: Training Accuracy = 0.9858, Training Loss = 0.1950, Validation Accuracy = 0.9712, Validation Loss = 0.2916\n",
            "Epoch 2790/3334\n",
            "Epoch 2790: Training Accuracy = 0.9858, Training Loss = 0.1950, Validation Accuracy = 0.9712, Validation Loss = 0.2916\n",
            "Epoch 2791/3334\n",
            "Epoch 2791: Training Accuracy = 0.9912, Training Loss = 0.1294, Validation Accuracy = 0.9718, Validation Loss = 0.2369\n",
            "Epoch 2792/3334\n",
            "Epoch 2792: Training Accuracy = 0.9912, Training Loss = 0.1294, Validation Accuracy = 0.9718, Validation Loss = 0.2369\n",
            "Epoch 2793/3334\n",
            "Epoch 2793: Training Accuracy = 0.9912, Training Loss = 0.1294, Validation Accuracy = 0.9718, Validation Loss = 0.2369\n",
            "Epoch 2794/3334\n",
            "Epoch 2794: Training Accuracy = 0.9883, Training Loss = 0.1260, Validation Accuracy = 0.9734, Validation Loss = 0.2123\n",
            "Epoch 2795/3334\n",
            "Epoch 2795: Training Accuracy = 0.9883, Training Loss = 0.1260, Validation Accuracy = 0.9734, Validation Loss = 0.2123\n",
            "Epoch 2796/3334\n",
            "Epoch 2796: Training Accuracy = 0.9883, Training Loss = 0.1260, Validation Accuracy = 0.9734, Validation Loss = 0.2123\n",
            "Epoch 2797/3334\n",
            "Epoch 2797: Training Accuracy = 0.9922, Training Loss = 0.0981, Validation Accuracy = 0.9728, Validation Loss = 0.2052\n",
            "Epoch 2798/3334\n",
            "Epoch 2798: Training Accuracy = 0.9922, Training Loss = 0.0981, Validation Accuracy = 0.9728, Validation Loss = 0.2052\n",
            "Epoch 2799/3334\n",
            "Epoch 2799: Training Accuracy = 0.9922, Training Loss = 0.0981, Validation Accuracy = 0.9728, Validation Loss = 0.2052\n",
            "Epoch 2800/3334\n",
            "Epoch 2800: Training Accuracy = 0.9922, Training Loss = 0.0981, Validation Accuracy = 0.9728, Validation Loss = 0.2052\n",
            "Epoch 2801/3334\n",
            "Epoch 2801: Training Accuracy = 0.9883, Training Loss = 0.1064, Validation Accuracy = 0.9731, Validation Loss = 0.1994\n",
            "Epoch 2802/3334\n",
            "Epoch 2802: Training Accuracy = 0.9883, Training Loss = 0.1064, Validation Accuracy = 0.9731, Validation Loss = 0.1994\n",
            "Epoch 2803/3334\n",
            "Epoch 2803: Training Accuracy = 0.9883, Training Loss = 0.1064, Validation Accuracy = 0.9731, Validation Loss = 0.1994\n",
            "Epoch 2804/3334\n",
            "Epoch 2804: Training Accuracy = 0.9912, Training Loss = 0.0937, Validation Accuracy = 0.9721, Validation Loss = 0.1966\n",
            "Epoch 2805/3334\n",
            "Epoch 2805: Training Accuracy = 0.9912, Training Loss = 0.0937, Validation Accuracy = 0.9721, Validation Loss = 0.1966\n",
            "Epoch 2806/3334\n",
            "Epoch 2806: Training Accuracy = 0.9912, Training Loss = 0.0937, Validation Accuracy = 0.9721, Validation Loss = 0.1966\n",
            "Epoch 2807/3334\n",
            "Epoch 2807: Training Accuracy = 0.9858, Training Loss = 0.1178, Validation Accuracy = 0.9727, Validation Loss = 0.1944\n",
            "Epoch 2808/3334\n",
            "Epoch 2808: Training Accuracy = 0.9858, Training Loss = 0.1178, Validation Accuracy = 0.9727, Validation Loss = 0.1944\n",
            "Epoch 2809/3334\n",
            "Epoch 2809: Training Accuracy = 0.9858, Training Loss = 0.1178, Validation Accuracy = 0.9727, Validation Loss = 0.1944\n",
            "Epoch 2810/3334\n",
            "Epoch 2810: Training Accuracy = 0.9858, Training Loss = 0.1178, Validation Accuracy = 0.9727, Validation Loss = 0.1944\n",
            "Epoch 2811/3334\n",
            "Epoch 2811: Training Accuracy = 0.9863, Training Loss = 0.1105, Validation Accuracy = 0.9736, Validation Loss = 0.1927\n",
            "Epoch 2812/3334\n",
            "Epoch 2812: Training Accuracy = 0.9863, Training Loss = 0.1105, Validation Accuracy = 0.9736, Validation Loss = 0.1927\n",
            "Epoch 2813/3334\n",
            "Epoch 2813: Training Accuracy = 0.9863, Training Loss = 0.1105, Validation Accuracy = 0.9736, Validation Loss = 0.1927\n",
            "Epoch 2814/3334\n",
            "Epoch 2814: Training Accuracy = 0.9873, Training Loss = 0.1025, Validation Accuracy = 0.9740, Validation Loss = 0.1885\n",
            "Epoch 2815/3334\n",
            "Epoch 2815: Training Accuracy = 0.9873, Training Loss = 0.1025, Validation Accuracy = 0.9740, Validation Loss = 0.1885\n",
            "Epoch 2816/3334\n",
            "Epoch 2816: Training Accuracy = 0.9873, Training Loss = 0.1025, Validation Accuracy = 0.9740, Validation Loss = 0.1885\n",
            "Epoch 2817/3334\n",
            "Epoch 2817: Training Accuracy = 0.9910, Training Loss = 0.0852, Validation Accuracy = 0.9713, Validation Loss = 0.1896\n",
            "Epoch 2818/3334\n",
            "Epoch 2818: Training Accuracy = 0.9910, Training Loss = 0.0852, Validation Accuracy = 0.9713, Validation Loss = 0.1896\n",
            "Epoch 2819/3334\n",
            "Epoch 2819: Training Accuracy = 0.9910, Training Loss = 0.0852, Validation Accuracy = 0.9713, Validation Loss = 0.1896\n",
            "Epoch 2820/3334\n",
            "Epoch 2820: Training Accuracy = 0.9910, Training Loss = 0.0852, Validation Accuracy = 0.9713, Validation Loss = 0.1896\n",
            "Epoch 2821/3334\n",
            "Epoch 2821: Training Accuracy = 0.9912, Training Loss = 0.0845, Validation Accuracy = 0.9742, Validation Loss = 0.1741\n",
            "Epoch 2822/3334\n",
            "Epoch 2822: Training Accuracy = 0.9912, Training Loss = 0.0845, Validation Accuracy = 0.9742, Validation Loss = 0.1741\n",
            "Epoch 2823/3334\n",
            "Epoch 2823: Training Accuracy = 0.9912, Training Loss = 0.0845, Validation Accuracy = 0.9742, Validation Loss = 0.1741\n",
            "Epoch 2824/3334\n",
            "Epoch 2824: Training Accuracy = 0.9844, Training Loss = 0.1050, Validation Accuracy = 0.9743, Validation Loss = 0.1735\n",
            "Epoch 2825/3334\n",
            "Epoch 2825: Training Accuracy = 0.9844, Training Loss = 0.1050, Validation Accuracy = 0.9743, Validation Loss = 0.1735\n",
            "Epoch 2826/3334\n",
            "Epoch 2826: Training Accuracy = 0.9844, Training Loss = 0.1050, Validation Accuracy = 0.9743, Validation Loss = 0.1735\n",
            "Epoch 2827/3334\n",
            "Epoch 2827: Training Accuracy = 0.2997, Training Loss = 2.9093, Validation Accuracy = 0.5368, Validation Loss = 1.7255\n",
            "Epoch 2828/3334\n",
            "Epoch 2828: Training Accuracy = 0.2997, Training Loss = 2.9093, Validation Accuracy = 0.5368, Validation Loss = 1.7255\n",
            "Epoch 2829/3334\n",
            "Epoch 2829: Training Accuracy = 0.2997, Training Loss = 2.9093, Validation Accuracy = 0.5368, Validation Loss = 1.7255\n",
            "Epoch 2830/3334\n",
            "Epoch 2830: Training Accuracy = 0.2997, Training Loss = 2.9093, Validation Accuracy = 0.5368, Validation Loss = 1.7255\n",
            "Epoch 2831/3334\n",
            "Epoch 2831: Training Accuracy = 0.8271, Training Loss = 1.0457, Validation Accuracy = 0.7603, Validation Loss = 1.1699\n",
            "Epoch 2832/3334\n",
            "Epoch 2832: Training Accuracy = 0.8271, Training Loss = 1.0457, Validation Accuracy = 0.7603, Validation Loss = 1.1699\n",
            "Epoch 2833/3334\n",
            "Epoch 2833: Training Accuracy = 0.8271, Training Loss = 1.0457, Validation Accuracy = 0.7603, Validation Loss = 1.1699\n",
            "Epoch 2834/3334\n",
            "Epoch 2834: Training Accuracy = 0.9766, Training Loss = 0.3493, Validation Accuracy = 0.9229, Validation Loss = 0.5364\n",
            "Epoch 2835/3334\n",
            "Epoch 2835: Training Accuracy = 0.9766, Training Loss = 0.3493, Validation Accuracy = 0.9229, Validation Loss = 0.5364\n",
            "Epoch 2836/3334\n",
            "Epoch 2836: Training Accuracy = 0.9766, Training Loss = 0.3493, Validation Accuracy = 0.9229, Validation Loss = 0.5364\n",
            "Epoch 2837/3334\n",
            "Epoch 2837: Training Accuracy = 0.9922, Training Loss = 0.1835, Validation Accuracy = 0.9633, Validation Loss = 0.3026\n",
            "Epoch 2838/3334\n",
            "Epoch 2838: Training Accuracy = 0.9922, Training Loss = 0.1835, Validation Accuracy = 0.9633, Validation Loss = 0.3026\n",
            "Epoch 2839/3334\n",
            "Epoch 2839: Training Accuracy = 0.9922, Training Loss = 0.1835, Validation Accuracy = 0.9633, Validation Loss = 0.3026\n",
            "Epoch 2840/3334\n",
            "Epoch 2840: Training Accuracy = 0.9922, Training Loss = 0.1835, Validation Accuracy = 0.9633, Validation Loss = 0.3026\n",
            "Epoch 2841/3334\n",
            "Epoch 2841: Training Accuracy = 0.9912, Training Loss = 0.1178, Validation Accuracy = 0.9730, Validation Loss = 0.2201\n",
            "Epoch 2842/3334\n",
            "Epoch 2842: Training Accuracy = 0.9912, Training Loss = 0.1178, Validation Accuracy = 0.9730, Validation Loss = 0.2201\n",
            "Epoch 2843/3334\n",
            "Epoch 2843: Training Accuracy = 0.9912, Training Loss = 0.1178, Validation Accuracy = 0.9730, Validation Loss = 0.2201\n",
            "Epoch 2844/3334\n",
            "Epoch 2844: Training Accuracy = 0.9883, Training Loss = 0.1091, Validation Accuracy = 0.9733, Validation Loss = 0.1896\n",
            "Epoch 2845/3334\n",
            "Epoch 2845: Training Accuracy = 0.9883, Training Loss = 0.1091, Validation Accuracy = 0.9733, Validation Loss = 0.1896\n",
            "Epoch 2846/3334\n",
            "Epoch 2846: Training Accuracy = 0.9883, Training Loss = 0.1091, Validation Accuracy = 0.9733, Validation Loss = 0.1896\n",
            "Epoch 2847/3334\n",
            "Epoch 2847: Training Accuracy = 0.9884, Training Loss = 0.0998, Validation Accuracy = 0.9740, Validation Loss = 0.1763\n",
            "Epoch 2848/3334\n",
            "Epoch 2848: Training Accuracy = 0.9884, Training Loss = 0.0998, Validation Accuracy = 0.9740, Validation Loss = 0.1763\n",
            "Epoch 2849/3334\n",
            "Epoch 2849: Training Accuracy = 0.9884, Training Loss = 0.0998, Validation Accuracy = 0.9740, Validation Loss = 0.1763\n",
            "Epoch 2850/3334\n",
            "Epoch 2850: Training Accuracy = 0.9884, Training Loss = 0.0998, Validation Accuracy = 0.9740, Validation Loss = 0.1763\n",
            "Epoch 2851/3334\n",
            "Epoch 2851: Training Accuracy = 0.9883, Training Loss = 0.0952, Validation Accuracy = 0.9737, Validation Loss = 0.1713\n",
            "Epoch 2852/3334\n",
            "Epoch 2852: Training Accuracy = 0.9883, Training Loss = 0.0952, Validation Accuracy = 0.9737, Validation Loss = 0.1713\n",
            "Epoch 2853/3334\n",
            "Epoch 2853: Training Accuracy = 0.9883, Training Loss = 0.0952, Validation Accuracy = 0.9737, Validation Loss = 0.1713\n",
            "Epoch 2854/3334\n",
            "Epoch 2854: Training Accuracy = 0.9883, Training Loss = 0.0928, Validation Accuracy = 0.9740, Validation Loss = 0.1686\n",
            "Epoch 2855/3334\n",
            "Epoch 2855: Training Accuracy = 0.9883, Training Loss = 0.0928, Validation Accuracy = 0.9740, Validation Loss = 0.1686\n",
            "Epoch 2856/3334\n",
            "Epoch 2856: Training Accuracy = 0.9883, Training Loss = 0.0928, Validation Accuracy = 0.9740, Validation Loss = 0.1686\n",
            "Epoch 2857/3334\n",
            "Epoch 2857: Training Accuracy = 0.9819, Training Loss = 0.1201, Validation Accuracy = 0.9740, Validation Loss = 0.1693\n",
            "Epoch 2858/3334\n",
            "Epoch 2858: Training Accuracy = 0.9819, Training Loss = 0.1201, Validation Accuracy = 0.9740, Validation Loss = 0.1693\n",
            "Epoch 2859/3334\n",
            "Epoch 2859: Training Accuracy = 0.9819, Training Loss = 0.1201, Validation Accuracy = 0.9740, Validation Loss = 0.1693\n",
            "Epoch 2860/3334\n",
            "Epoch 2860: Training Accuracy = 0.9819, Training Loss = 0.1201, Validation Accuracy = 0.9740, Validation Loss = 0.1693\n",
            "Epoch 2861/3334\n",
            "Epoch 2861: Training Accuracy = 0.9854, Training Loss = 0.1000, Validation Accuracy = 0.9740, Validation Loss = 0.1675\n",
            "Epoch 2862/3334\n",
            "Epoch 2862: Training Accuracy = 0.9854, Training Loss = 0.1000, Validation Accuracy = 0.9740, Validation Loss = 0.1675\n",
            "Epoch 2863/3334\n",
            "Epoch 2863: Training Accuracy = 0.9854, Training Loss = 0.1000, Validation Accuracy = 0.9740, Validation Loss = 0.1675\n",
            "Epoch 2864/3334\n",
            "Epoch 2864: Training Accuracy = 0.9893, Training Loss = 0.0857, Validation Accuracy = 0.9742, Validation Loss = 0.1651\n",
            "Epoch 2865/3334\n",
            "Epoch 2865: Training Accuracy = 0.9893, Training Loss = 0.0857, Validation Accuracy = 0.9742, Validation Loss = 0.1651\n",
            "Epoch 2866/3334\n",
            "Epoch 2866: Training Accuracy = 0.9893, Training Loss = 0.0857, Validation Accuracy = 0.9742, Validation Loss = 0.1651\n",
            "Epoch 2867/3334\n",
            "Epoch 2867: Training Accuracy = 0.9884, Training Loss = 0.0904, Validation Accuracy = 0.9739, Validation Loss = 0.1655\n",
            "Epoch 2868/3334\n",
            "Epoch 2868: Training Accuracy = 0.9884, Training Loss = 0.0904, Validation Accuracy = 0.9739, Validation Loss = 0.1655\n",
            "Epoch 2869/3334\n",
            "Epoch 2869: Training Accuracy = 0.9884, Training Loss = 0.0904, Validation Accuracy = 0.9739, Validation Loss = 0.1655\n",
            "Epoch 2870/3334\n",
            "Epoch 2870: Training Accuracy = 0.9884, Training Loss = 0.0904, Validation Accuracy = 0.9739, Validation Loss = 0.1655\n",
            "Epoch 2871/3334\n",
            "Epoch 2871: Training Accuracy = 0.9902, Training Loss = 0.0819, Validation Accuracy = 0.9742, Validation Loss = 0.1672\n",
            "Epoch 2872/3334\n",
            "Epoch 2872: Training Accuracy = 0.9902, Training Loss = 0.0819, Validation Accuracy = 0.9742, Validation Loss = 0.1672\n",
            "Epoch 2873/3334\n",
            "Epoch 2873: Training Accuracy = 0.9902, Training Loss = 0.0819, Validation Accuracy = 0.9742, Validation Loss = 0.1672\n",
            "Epoch 2874/3334\n",
            "Epoch 2874: Training Accuracy = 0.9854, Training Loss = 0.1018, Validation Accuracy = 0.9743, Validation Loss = 0.1612\n",
            "Epoch 2875/3334\n",
            "Epoch 2875: Training Accuracy = 0.9854, Training Loss = 0.1018, Validation Accuracy = 0.9743, Validation Loss = 0.1612\n",
            "Epoch 2876/3334\n",
            "Epoch 2876: Training Accuracy = 0.9854, Training Loss = 0.1018, Validation Accuracy = 0.9743, Validation Loss = 0.1612\n",
            "Epoch 2877/3334\n",
            "Epoch 2877: Training Accuracy = 0.9897, Training Loss = 0.0842, Validation Accuracy = 0.9753, Validation Loss = 0.1610\n",
            "Epoch 2878/3334\n",
            "Epoch 2878: Training Accuracy = 0.9897, Training Loss = 0.0842, Validation Accuracy = 0.9753, Validation Loss = 0.1610\n",
            "Epoch 2879/3334\n",
            "Epoch 2879: Training Accuracy = 0.9897, Training Loss = 0.0842, Validation Accuracy = 0.9753, Validation Loss = 0.1610\n",
            "Epoch 2880/3334\n",
            "Epoch 2880: Training Accuracy = 0.9897, Training Loss = 0.0842, Validation Accuracy = 0.9753, Validation Loss = 0.1610\n",
            "Epoch 2881/3334\n",
            "Epoch 2881: Training Accuracy = 0.3594, Training Loss = 2.0640, Validation Accuracy = 0.1828, Validation Loss = 3.8500\n",
            "Epoch 2882/3334\n",
            "Epoch 2882: Training Accuracy = 0.3594, Training Loss = 2.0640, Validation Accuracy = 0.1828, Validation Loss = 3.8500\n",
            "Epoch 2883/3334\n",
            "Epoch 2883: Training Accuracy = 0.3594, Training Loss = 2.0640, Validation Accuracy = 0.1828, Validation Loss = 3.8500\n",
            "Epoch 2884/3334\n",
            "Epoch 2884: Training Accuracy = 0.8516, Training Loss = 0.8865, Validation Accuracy = 0.7831, Validation Loss = 1.0305\n",
            "Epoch 2885/3334\n",
            "Epoch 2885: Training Accuracy = 0.8516, Training Loss = 0.8865, Validation Accuracy = 0.7831, Validation Loss = 1.0305\n",
            "Epoch 2886/3334\n",
            "Epoch 2886: Training Accuracy = 0.8516, Training Loss = 0.8865, Validation Accuracy = 0.7831, Validation Loss = 1.0305\n",
            "Epoch 2887/3334\n",
            "Epoch 2887: Training Accuracy = 0.9664, Training Loss = 0.3888, Validation Accuracy = 0.9425, Validation Loss = 0.4919\n",
            "Epoch 2888/3334\n",
            "Epoch 2888: Training Accuracy = 0.9664, Training Loss = 0.3888, Validation Accuracy = 0.9425, Validation Loss = 0.4919\n",
            "Epoch 2889/3334\n",
            "Epoch 2889: Training Accuracy = 0.9664, Training Loss = 0.3888, Validation Accuracy = 0.9425, Validation Loss = 0.4919\n",
            "Epoch 2890/3334\n",
            "Epoch 2890: Training Accuracy = 0.9664, Training Loss = 0.3888, Validation Accuracy = 0.9425, Validation Loss = 0.4919\n",
            "Epoch 2891/3334\n",
            "Epoch 2891: Training Accuracy = 0.9824, Training Loss = 0.2129, Validation Accuracy = 0.9695, Validation Loss = 0.2991\n",
            "Epoch 2892/3334\n",
            "Epoch 2892: Training Accuracy = 0.9824, Training Loss = 0.2129, Validation Accuracy = 0.9695, Validation Loss = 0.2991\n",
            "Epoch 2893/3334\n",
            "Epoch 2893: Training Accuracy = 0.9824, Training Loss = 0.2129, Validation Accuracy = 0.9695, Validation Loss = 0.2991\n",
            "Epoch 2894/3334\n",
            "Epoch 2894: Training Accuracy = 0.9902, Training Loss = 0.1363, Validation Accuracy = 0.9718, Validation Loss = 0.2289\n",
            "Epoch 2895/3334\n",
            "Epoch 2895: Training Accuracy = 0.9902, Training Loss = 0.1363, Validation Accuracy = 0.9718, Validation Loss = 0.2289\n",
            "Epoch 2896/3334\n",
            "Epoch 2896: Training Accuracy = 0.9902, Training Loss = 0.1363, Validation Accuracy = 0.9718, Validation Loss = 0.2289\n",
            "Epoch 2897/3334\n",
            "Epoch 2897: Training Accuracy = 0.9871, Training Loss = 0.1232, Validation Accuracy = 0.9734, Validation Loss = 0.1994\n",
            "Epoch 2898/3334\n",
            "Epoch 2898: Training Accuracy = 0.9871, Training Loss = 0.1232, Validation Accuracy = 0.9734, Validation Loss = 0.1994\n",
            "Epoch 2899/3334\n",
            "Epoch 2899: Training Accuracy = 0.9871, Training Loss = 0.1232, Validation Accuracy = 0.9734, Validation Loss = 0.1994\n",
            "Epoch 2900/3334\n",
            "Epoch 2900: Training Accuracy = 0.9871, Training Loss = 0.1232, Validation Accuracy = 0.9734, Validation Loss = 0.1994\n",
            "Epoch 2901/3334\n",
            "Epoch 2901: Training Accuracy = 0.9883, Training Loss = 0.1018, Validation Accuracy = 0.9743, Validation Loss = 0.1854\n",
            "Epoch 2902/3334\n",
            "Epoch 2902: Training Accuracy = 0.9883, Training Loss = 0.1018, Validation Accuracy = 0.9743, Validation Loss = 0.1854\n",
            "Epoch 2903/3334\n",
            "Epoch 2903: Training Accuracy = 0.9883, Training Loss = 0.1018, Validation Accuracy = 0.9743, Validation Loss = 0.1854\n",
            "Epoch 2904/3334\n",
            "Epoch 2904: Training Accuracy = 0.9941, Training Loss = 0.0763, Validation Accuracy = 0.9750, Validation Loss = 0.1738\n",
            "Epoch 2905/3334\n",
            "Epoch 2905: Training Accuracy = 0.9941, Training Loss = 0.0763, Validation Accuracy = 0.9750, Validation Loss = 0.1738\n",
            "Epoch 2906/3334\n",
            "Epoch 2906: Training Accuracy = 0.9941, Training Loss = 0.0763, Validation Accuracy = 0.9750, Validation Loss = 0.1738\n",
            "Epoch 2907/3334\n",
            "Epoch 2907: Training Accuracy = 0.9935, Training Loss = 0.0732, Validation Accuracy = 0.9750, Validation Loss = 0.1688\n",
            "Epoch 2908/3334\n",
            "Epoch 2908: Training Accuracy = 0.9935, Training Loss = 0.0732, Validation Accuracy = 0.9750, Validation Loss = 0.1688\n",
            "Epoch 2909/3334\n",
            "Epoch 2909: Training Accuracy = 0.9935, Training Loss = 0.0732, Validation Accuracy = 0.9750, Validation Loss = 0.1688\n",
            "Epoch 2910/3334\n",
            "Epoch 2910: Training Accuracy = 0.9935, Training Loss = 0.0732, Validation Accuracy = 0.9750, Validation Loss = 0.1688\n",
            "Epoch 2911/3334\n",
            "Epoch 2911: Training Accuracy = 0.9893, Training Loss = 0.0895, Validation Accuracy = 0.9746, Validation Loss = 0.1659\n",
            "Epoch 2912/3334\n",
            "Epoch 2912: Training Accuracy = 0.9893, Training Loss = 0.0895, Validation Accuracy = 0.9746, Validation Loss = 0.1659\n",
            "Epoch 2913/3334\n",
            "Epoch 2913: Training Accuracy = 0.9893, Training Loss = 0.0895, Validation Accuracy = 0.9746, Validation Loss = 0.1659\n",
            "Epoch 2914/3334\n",
            "Epoch 2914: Training Accuracy = 0.9893, Training Loss = 0.0893, Validation Accuracy = 0.9737, Validation Loss = 0.1624\n",
            "Epoch 2915/3334\n",
            "Epoch 2915: Training Accuracy = 0.9893, Training Loss = 0.0893, Validation Accuracy = 0.9737, Validation Loss = 0.1624\n",
            "Epoch 2916/3334\n",
            "Epoch 2916: Training Accuracy = 0.9893, Training Loss = 0.0893, Validation Accuracy = 0.9737, Validation Loss = 0.1624\n",
            "Epoch 2917/3334\n",
            "Epoch 2917: Training Accuracy = 0.9884, Training Loss = 0.0903, Validation Accuracy = 0.9742, Validation Loss = 0.1617\n",
            "Epoch 2918/3334\n",
            "Epoch 2918: Training Accuracy = 0.9884, Training Loss = 0.0903, Validation Accuracy = 0.9742, Validation Loss = 0.1617\n",
            "Epoch 2919/3334\n",
            "Epoch 2919: Training Accuracy = 0.9884, Training Loss = 0.0903, Validation Accuracy = 0.9742, Validation Loss = 0.1617\n",
            "Epoch 2920/3334\n",
            "Epoch 2920: Training Accuracy = 0.9884, Training Loss = 0.0903, Validation Accuracy = 0.9742, Validation Loss = 0.1617\n",
            "Epoch 2921/3334\n",
            "Epoch 2921: Training Accuracy = 0.9922, Training Loss = 0.0757, Validation Accuracy = 0.9733, Validation Loss = 0.1640\n",
            "Epoch 2922/3334\n",
            "Epoch 2922: Training Accuracy = 0.9922, Training Loss = 0.0757, Validation Accuracy = 0.9733, Validation Loss = 0.1640\n",
            "Epoch 2923/3334\n",
            "Epoch 2923: Training Accuracy = 0.9922, Training Loss = 0.0757, Validation Accuracy = 0.9733, Validation Loss = 0.1640\n",
            "Epoch 2924/3334\n",
            "Epoch 2924: Training Accuracy = 0.9883, Training Loss = 0.0914, Validation Accuracy = 0.9734, Validation Loss = 0.1591\n",
            "Epoch 2925/3334\n",
            "Epoch 2925: Training Accuracy = 0.9883, Training Loss = 0.0914, Validation Accuracy = 0.9734, Validation Loss = 0.1591\n",
            "Epoch 2926/3334\n",
            "Epoch 2926: Training Accuracy = 0.9883, Training Loss = 0.0914, Validation Accuracy = 0.9734, Validation Loss = 0.1591\n",
            "Epoch 2927/3334\n",
            "Epoch 2927: Training Accuracy = 0.9884, Training Loss = 0.0922, Validation Accuracy = 0.9748, Validation Loss = 0.1606\n",
            "Epoch 2928/3334\n",
            "Epoch 2928: Training Accuracy = 0.9884, Training Loss = 0.0922, Validation Accuracy = 0.9748, Validation Loss = 0.1606\n",
            "Epoch 2929/3334\n",
            "Epoch 2929: Training Accuracy = 0.9884, Training Loss = 0.0922, Validation Accuracy = 0.9748, Validation Loss = 0.1606\n",
            "Epoch 2930/3334\n",
            "Epoch 2930: Training Accuracy = 0.9884, Training Loss = 0.0922, Validation Accuracy = 0.9748, Validation Loss = 0.1606\n",
            "Epoch 2931/3334\n",
            "Epoch 2931: Training Accuracy = 0.9902, Training Loss = 0.0801, Validation Accuracy = 0.9750, Validation Loss = 0.1627\n",
            "Epoch 2932/3334\n",
            "Epoch 2932: Training Accuracy = 0.9902, Training Loss = 0.0801, Validation Accuracy = 0.9750, Validation Loss = 0.1627\n",
            "Epoch 2933/3334\n",
            "Epoch 2933: Training Accuracy = 0.9902, Training Loss = 0.0801, Validation Accuracy = 0.9750, Validation Loss = 0.1627\n",
            "Epoch 2934/3334\n",
            "Epoch 2934: Training Accuracy = 0.9883, Training Loss = 0.1277, Validation Accuracy = 0.8212, Validation Loss = 0.7916\n",
            "Epoch 2935/3334\n",
            "Epoch 2935: Training Accuracy = 0.9883, Training Loss = 0.1277, Validation Accuracy = 0.8212, Validation Loss = 0.7916\n",
            "Epoch 2936/3334\n",
            "Epoch 2936: Training Accuracy = 0.9883, Training Loss = 0.1277, Validation Accuracy = 0.8212, Validation Loss = 0.7916\n",
            "Epoch 2937/3334\n",
            "Epoch 2937: Training Accuracy = 0.7765, Training Loss = 1.2070, Validation Accuracy = 0.6839, Validation Loss = 1.3785\n",
            "Epoch 2938/3334\n",
            "Epoch 2938: Training Accuracy = 0.7765, Training Loss = 1.2070, Validation Accuracy = 0.6839, Validation Loss = 1.3785\n",
            "Epoch 2939/3334\n",
            "Epoch 2939: Training Accuracy = 0.7765, Training Loss = 1.2070, Validation Accuracy = 0.6839, Validation Loss = 1.3785\n",
            "Epoch 2940/3334\n",
            "Epoch 2940: Training Accuracy = 0.7765, Training Loss = 1.2070, Validation Accuracy = 0.6839, Validation Loss = 1.3785\n",
            "Epoch 2941/3334\n",
            "Epoch 2941: Training Accuracy = 0.9541, Training Loss = 0.4900, Validation Accuracy = 0.9086, Validation Loss = 0.6203\n",
            "Epoch 2942/3334\n",
            "Epoch 2942: Training Accuracy = 0.9541, Training Loss = 0.4900, Validation Accuracy = 0.9086, Validation Loss = 0.6203\n",
            "Epoch 2943/3334\n",
            "Epoch 2943: Training Accuracy = 0.9541, Training Loss = 0.4900, Validation Accuracy = 0.9086, Validation Loss = 0.6203\n",
            "Epoch 2944/3334\n",
            "Epoch 2944: Training Accuracy = 0.9805, Training Loss = 0.2569, Validation Accuracy = 0.9608, Validation Loss = 0.3590\n",
            "Epoch 2945/3334\n",
            "Epoch 2945: Training Accuracy = 0.9805, Training Loss = 0.2569, Validation Accuracy = 0.9608, Validation Loss = 0.3590\n",
            "Epoch 2946/3334\n",
            "Epoch 2946: Training Accuracy = 0.9805, Training Loss = 0.2569, Validation Accuracy = 0.9608, Validation Loss = 0.3590\n",
            "Epoch 2947/3334\n",
            "Epoch 2947: Training Accuracy = 0.9871, Training Loss = 0.1591, Validation Accuracy = 0.9687, Validation Loss = 0.2586\n",
            "Epoch 2948/3334\n",
            "Epoch 2948: Training Accuracy = 0.9871, Training Loss = 0.1591, Validation Accuracy = 0.9687, Validation Loss = 0.2586\n",
            "Epoch 2949/3334\n",
            "Epoch 2949: Training Accuracy = 0.9871, Training Loss = 0.1591, Validation Accuracy = 0.9687, Validation Loss = 0.2586\n",
            "Epoch 2950/3334\n",
            "Epoch 2950: Training Accuracy = 0.9871, Training Loss = 0.1591, Validation Accuracy = 0.9687, Validation Loss = 0.2586\n",
            "Epoch 2951/3334\n",
            "Epoch 2951: Training Accuracy = 0.9912, Training Loss = 0.1212, Validation Accuracy = 0.9709, Validation Loss = 0.2200\n",
            "Epoch 2952/3334\n",
            "Epoch 2952: Training Accuracy = 0.9912, Training Loss = 0.1212, Validation Accuracy = 0.9709, Validation Loss = 0.2200\n",
            "Epoch 2953/3334\n",
            "Epoch 2953: Training Accuracy = 0.9912, Training Loss = 0.1212, Validation Accuracy = 0.9709, Validation Loss = 0.2200\n",
            "Epoch 2954/3334\n",
            "Epoch 2954: Training Accuracy = 0.9873, Training Loss = 0.1280, Validation Accuracy = 0.9710, Validation Loss = 0.2035\n",
            "Epoch 2955/3334\n",
            "Epoch 2955: Training Accuracy = 0.9873, Training Loss = 0.1280, Validation Accuracy = 0.9710, Validation Loss = 0.2035\n",
            "Epoch 2956/3334\n",
            "Epoch 2956: Training Accuracy = 0.9873, Training Loss = 0.1280, Validation Accuracy = 0.9710, Validation Loss = 0.2035\n",
            "Epoch 2957/3334\n",
            "Epoch 2957: Training Accuracy = 0.9884, Training Loss = 0.1190, Validation Accuracy = 0.9705, Validation Loss = 0.1964\n",
            "Epoch 2958/3334\n",
            "Epoch 2958: Training Accuracy = 0.9884, Training Loss = 0.1190, Validation Accuracy = 0.9705, Validation Loss = 0.1964\n",
            "Epoch 2959/3334\n",
            "Epoch 2959: Training Accuracy = 0.9884, Training Loss = 0.1190, Validation Accuracy = 0.9705, Validation Loss = 0.1964\n",
            "Epoch 2960/3334\n",
            "Epoch 2960: Training Accuracy = 0.9884, Training Loss = 0.1190, Validation Accuracy = 0.9705, Validation Loss = 0.1964\n",
            "Epoch 2961/3334\n",
            "Epoch 2961: Training Accuracy = 0.9902, Training Loss = 0.1007, Validation Accuracy = 0.9712, Validation Loss = 0.1938\n",
            "Epoch 2962/3334\n",
            "Epoch 2962: Training Accuracy = 0.9902, Training Loss = 0.1007, Validation Accuracy = 0.9712, Validation Loss = 0.1938\n",
            "Epoch 2963/3334\n",
            "Epoch 2963: Training Accuracy = 0.9902, Training Loss = 0.1007, Validation Accuracy = 0.9712, Validation Loss = 0.1938\n",
            "Epoch 2964/3334\n",
            "Epoch 2964: Training Accuracy = 0.9854, Training Loss = 0.1195, Validation Accuracy = 0.9710, Validation Loss = 0.1933\n",
            "Epoch 2965/3334\n",
            "Epoch 2965: Training Accuracy = 0.9854, Training Loss = 0.1195, Validation Accuracy = 0.9710, Validation Loss = 0.1933\n",
            "Epoch 2966/3334\n",
            "Epoch 2966: Training Accuracy = 0.9854, Training Loss = 0.1195, Validation Accuracy = 0.9710, Validation Loss = 0.1933\n",
            "Epoch 2967/3334\n",
            "Epoch 2967: Training Accuracy = 0.9858, Training Loss = 0.1183, Validation Accuracy = 0.9719, Validation Loss = 0.1907\n",
            "Epoch 2968/3334\n",
            "Epoch 2968: Training Accuracy = 0.9858, Training Loss = 0.1183, Validation Accuracy = 0.9719, Validation Loss = 0.1907\n",
            "Epoch 2969/3334\n",
            "Epoch 2969: Training Accuracy = 0.9858, Training Loss = 0.1183, Validation Accuracy = 0.9719, Validation Loss = 0.1907\n",
            "Epoch 2970/3334\n",
            "Epoch 2970: Training Accuracy = 0.9858, Training Loss = 0.1183, Validation Accuracy = 0.9719, Validation Loss = 0.1907\n",
            "Epoch 2971/3334\n",
            "Epoch 2971: Training Accuracy = 0.9854, Training Loss = 0.1150, Validation Accuracy = 0.9715, Validation Loss = 0.1912\n",
            "Epoch 2972/3334\n",
            "Epoch 2972: Training Accuracy = 0.9854, Training Loss = 0.1150, Validation Accuracy = 0.9715, Validation Loss = 0.1912\n",
            "Epoch 2973/3334\n",
            "Epoch 2973: Training Accuracy = 0.9854, Training Loss = 0.1150, Validation Accuracy = 0.9715, Validation Loss = 0.1912\n",
            "Epoch 2974/3334\n",
            "Epoch 2974: Training Accuracy = 0.9893, Training Loss = 0.1030, Validation Accuracy = 0.9719, Validation Loss = 0.1854\n",
            "Epoch 2975/3334\n",
            "Epoch 2975: Training Accuracy = 0.9893, Training Loss = 0.1030, Validation Accuracy = 0.9719, Validation Loss = 0.1854\n",
            "Epoch 2976/3334\n",
            "Epoch 2976: Training Accuracy = 0.9893, Training Loss = 0.1030, Validation Accuracy = 0.9719, Validation Loss = 0.1854\n",
            "Epoch 2977/3334\n",
            "Epoch 2977: Training Accuracy = 0.9884, Training Loss = 0.1004, Validation Accuracy = 0.9712, Validation Loss = 0.1850\n",
            "Epoch 2978/3334\n",
            "Epoch 2978: Training Accuracy = 0.9884, Training Loss = 0.1004, Validation Accuracy = 0.9712, Validation Loss = 0.1850\n",
            "Epoch 2979/3334\n",
            "Epoch 2979: Training Accuracy = 0.9884, Training Loss = 0.1004, Validation Accuracy = 0.9712, Validation Loss = 0.1850\n",
            "Epoch 2980/3334\n",
            "Epoch 2980: Training Accuracy = 0.9884, Training Loss = 0.1004, Validation Accuracy = 0.9712, Validation Loss = 0.1850\n",
            "Epoch 2981/3334\n",
            "Epoch 2981: Training Accuracy = 0.9873, Training Loss = 0.1042, Validation Accuracy = 0.9742, Validation Loss = 0.1861\n",
            "Epoch 2982/3334\n",
            "Epoch 2982: Training Accuracy = 0.9873, Training Loss = 0.1042, Validation Accuracy = 0.9742, Validation Loss = 0.1861\n",
            "Epoch 2983/3334\n",
            "Epoch 2983: Training Accuracy = 0.9873, Training Loss = 0.1042, Validation Accuracy = 0.9742, Validation Loss = 0.1861\n",
            "Epoch 2984/3334\n",
            "Epoch 2984: Training Accuracy = 0.9883, Training Loss = 0.1121, Validation Accuracy = 0.9628, Validation Loss = 0.2569\n",
            "Epoch 2985/3334\n",
            "Epoch 2985: Training Accuracy = 0.9883, Training Loss = 0.1121, Validation Accuracy = 0.9628, Validation Loss = 0.2569\n",
            "Epoch 2986/3334\n",
            "Epoch 2986: Training Accuracy = 0.9883, Training Loss = 0.1121, Validation Accuracy = 0.9628, Validation Loss = 0.2569\n",
            "Epoch 2987/3334\n",
            "Epoch 2987: Training Accuracy = 0.4302, Training Loss = 2.2017, Validation Accuracy = 0.4791, Validation Loss = 2.0912\n",
            "Epoch 2988/3334\n",
            "Epoch 2988: Training Accuracy = 0.4302, Training Loss = 2.2017, Validation Accuracy = 0.4791, Validation Loss = 2.0912\n",
            "Epoch 2989/3334\n",
            "Epoch 2989: Training Accuracy = 0.4302, Training Loss = 2.2017, Validation Accuracy = 0.4791, Validation Loss = 2.0912\n",
            "Epoch 2990/3334\n",
            "Epoch 2990: Training Accuracy = 0.4302, Training Loss = 2.2017, Validation Accuracy = 0.4791, Validation Loss = 2.0912\n",
            "Epoch 2991/3334\n",
            "Epoch 2991: Training Accuracy = 0.8623, Training Loss = 0.7377, Validation Accuracy = 0.8025, Validation Loss = 0.9074\n",
            "Epoch 2992/3334\n",
            "Epoch 2992: Training Accuracy = 0.8623, Training Loss = 0.7377, Validation Accuracy = 0.8025, Validation Loss = 0.9074\n",
            "Epoch 2993/3334\n",
            "Epoch 2993: Training Accuracy = 0.8623, Training Loss = 0.7377, Validation Accuracy = 0.8025, Validation Loss = 0.9074\n",
            "Epoch 2994/3334\n",
            "Epoch 2994: Training Accuracy = 0.9863, Training Loss = 0.2903, Validation Accuracy = 0.9476, Validation Loss = 0.4434\n",
            "Epoch 2995/3334\n",
            "Epoch 2995: Training Accuracy = 0.9863, Training Loss = 0.2903, Validation Accuracy = 0.9476, Validation Loss = 0.4434\n",
            "Epoch 2996/3334\n",
            "Epoch 2996: Training Accuracy = 0.9863, Training Loss = 0.2903, Validation Accuracy = 0.9476, Validation Loss = 0.4434\n",
            "Epoch 2997/3334\n",
            "Epoch 2997: Training Accuracy = 0.9884, Training Loss = 0.1892, Validation Accuracy = 0.9607, Validation Loss = 0.3072\n",
            "Epoch 2998/3334\n",
            "Epoch 2998: Training Accuracy = 0.9884, Training Loss = 0.1892, Validation Accuracy = 0.9607, Validation Loss = 0.3072\n",
            "Epoch 2999/3334\n",
            "Epoch 2999: Training Accuracy = 0.9884, Training Loss = 0.1892, Validation Accuracy = 0.9607, Validation Loss = 0.3072\n",
            "Epoch 3000/3334\n",
            "Epoch 3000: Training Accuracy = 0.9884, Training Loss = 0.1892, Validation Accuracy = 0.9607, Validation Loss = 0.3072\n",
            "Epoch 3001/3334\n",
            "Epoch 3001: Training Accuracy = 0.9922, Training Loss = 0.1331, Validation Accuracy = 0.9663, Validation Loss = 0.2511\n",
            "Epoch 3002/3334\n",
            "Epoch 3002: Training Accuracy = 0.9922, Training Loss = 0.1331, Validation Accuracy = 0.9663, Validation Loss = 0.2511\n",
            "Epoch 3003/3334\n",
            "Epoch 3003: Training Accuracy = 0.9922, Training Loss = 0.1331, Validation Accuracy = 0.9663, Validation Loss = 0.2511\n",
            "Epoch 3004/3334\n",
            "Epoch 3004: Training Accuracy = 0.9863, Training Loss = 0.1370, Validation Accuracy = 0.9699, Validation Loss = 0.2175\n",
            "Epoch 3005/3334\n",
            "Epoch 3005: Training Accuracy = 0.9863, Training Loss = 0.1370, Validation Accuracy = 0.9699, Validation Loss = 0.2175\n",
            "Epoch 3006/3334\n",
            "Epoch 3006: Training Accuracy = 0.9863, Training Loss = 0.1370, Validation Accuracy = 0.9699, Validation Loss = 0.2175\n",
            "Epoch 3007/3334\n",
            "Epoch 3007: Training Accuracy = 0.9897, Training Loss = 0.1103, Validation Accuracy = 0.9731, Validation Loss = 0.2014\n",
            "Epoch 3008/3334\n",
            "Epoch 3008: Training Accuracy = 0.9897, Training Loss = 0.1103, Validation Accuracy = 0.9731, Validation Loss = 0.2014\n",
            "Epoch 3009/3334\n",
            "Epoch 3009: Training Accuracy = 0.9897, Training Loss = 0.1103, Validation Accuracy = 0.9731, Validation Loss = 0.2014\n",
            "Epoch 3010/3334\n",
            "Epoch 3010: Training Accuracy = 0.9897, Training Loss = 0.1103, Validation Accuracy = 0.9731, Validation Loss = 0.2014\n",
            "Epoch 3011/3334\n",
            "Epoch 3011: Training Accuracy = 0.9873, Training Loss = 0.1084, Validation Accuracy = 0.9730, Validation Loss = 0.1909\n",
            "Epoch 3012/3334\n",
            "Epoch 3012: Training Accuracy = 0.9873, Training Loss = 0.1084, Validation Accuracy = 0.9730, Validation Loss = 0.1909\n",
            "Epoch 3013/3334\n",
            "Epoch 3013: Training Accuracy = 0.9873, Training Loss = 0.1084, Validation Accuracy = 0.9730, Validation Loss = 0.1909\n",
            "Epoch 3014/3334\n",
            "Epoch 3014: Training Accuracy = 0.9922, Training Loss = 0.0894, Validation Accuracy = 0.9728, Validation Loss = 0.1863\n",
            "Epoch 3015/3334\n",
            "Epoch 3015: Training Accuracy = 0.9922, Training Loss = 0.0894, Validation Accuracy = 0.9728, Validation Loss = 0.1863\n",
            "Epoch 3016/3334\n",
            "Epoch 3016: Training Accuracy = 0.9922, Training Loss = 0.0894, Validation Accuracy = 0.9728, Validation Loss = 0.1863\n",
            "Epoch 3017/3334\n",
            "Epoch 3017: Training Accuracy = 0.9884, Training Loss = 0.1017, Validation Accuracy = 0.9736, Validation Loss = 0.1792\n",
            "Epoch 3018/3334\n",
            "Epoch 3018: Training Accuracy = 0.9884, Training Loss = 0.1017, Validation Accuracy = 0.9736, Validation Loss = 0.1792\n",
            "Epoch 3019/3334\n",
            "Epoch 3019: Training Accuracy = 0.9884, Training Loss = 0.1017, Validation Accuracy = 0.9736, Validation Loss = 0.1792\n",
            "Epoch 3020/3334\n",
            "Epoch 3020: Training Accuracy = 0.9884, Training Loss = 0.1017, Validation Accuracy = 0.9736, Validation Loss = 0.1792\n",
            "Epoch 3021/3334\n",
            "Epoch 3021: Training Accuracy = 0.9893, Training Loss = 0.0937, Validation Accuracy = 0.9724, Validation Loss = 0.1801\n",
            "Epoch 3022/3334\n",
            "Epoch 3022: Training Accuracy = 0.9893, Training Loss = 0.0937, Validation Accuracy = 0.9724, Validation Loss = 0.1801\n",
            "Epoch 3023/3334\n",
            "Epoch 3023: Training Accuracy = 0.9893, Training Loss = 0.0937, Validation Accuracy = 0.9724, Validation Loss = 0.1801\n",
            "Epoch 3024/3334\n",
            "Epoch 3024: Training Accuracy = 0.9922, Training Loss = 0.0833, Validation Accuracy = 0.9722, Validation Loss = 0.1771\n",
            "Epoch 3025/3334\n",
            "Epoch 3025: Training Accuracy = 0.9922, Training Loss = 0.0833, Validation Accuracy = 0.9722, Validation Loss = 0.1771\n",
            "Epoch 3026/3334\n",
            "Epoch 3026: Training Accuracy = 0.9922, Training Loss = 0.0833, Validation Accuracy = 0.9722, Validation Loss = 0.1771\n",
            "Epoch 3027/3334\n",
            "Epoch 3027: Training Accuracy = 0.9871, Training Loss = 0.0994, Validation Accuracy = 0.9718, Validation Loss = 0.1743\n",
            "Epoch 3028/3334\n",
            "Epoch 3028: Training Accuracy = 0.9871, Training Loss = 0.0994, Validation Accuracy = 0.9718, Validation Loss = 0.1743\n",
            "Epoch 3029/3334\n",
            "Epoch 3029: Training Accuracy = 0.9871, Training Loss = 0.0994, Validation Accuracy = 0.9718, Validation Loss = 0.1743\n",
            "Epoch 3030/3334\n",
            "Epoch 3030: Training Accuracy = 0.9871, Training Loss = 0.0994, Validation Accuracy = 0.9718, Validation Loss = 0.1743\n",
            "Epoch 3031/3334\n",
            "Epoch 3031: Training Accuracy = 0.9844, Training Loss = 0.1092, Validation Accuracy = 0.9724, Validation Loss = 0.1712\n",
            "Epoch 3032/3334\n",
            "Epoch 3032: Training Accuracy = 0.9844, Training Loss = 0.1092, Validation Accuracy = 0.9724, Validation Loss = 0.1712\n",
            "Epoch 3033/3334\n",
            "Epoch 3033: Training Accuracy = 0.9844, Training Loss = 0.1092, Validation Accuracy = 0.9724, Validation Loss = 0.1712\n",
            "Epoch 3034/3334\n",
            "Epoch 3034: Training Accuracy = 0.9912, Training Loss = 0.0887, Validation Accuracy = 0.9731, Validation Loss = 0.1767\n",
            "Epoch 3035/3334\n",
            "Epoch 3035: Training Accuracy = 0.9912, Training Loss = 0.0887, Validation Accuracy = 0.9731, Validation Loss = 0.1767\n",
            "Epoch 3036/3334\n",
            "Epoch 3036: Training Accuracy = 0.9912, Training Loss = 0.0887, Validation Accuracy = 0.9731, Validation Loss = 0.1767\n",
            "Epoch 3037/3334\n",
            "Epoch 3037: Training Accuracy = 0.9935, Training Loss = 0.0804, Validation Accuracy = 0.9718, Validation Loss = 0.1833\n",
            "Epoch 3038/3334\n",
            "Epoch 3038: Training Accuracy = 0.9935, Training Loss = 0.0804, Validation Accuracy = 0.9718, Validation Loss = 0.1833\n",
            "Epoch 3039/3334\n",
            "Epoch 3039: Training Accuracy = 0.9935, Training Loss = 0.0804, Validation Accuracy = 0.9718, Validation Loss = 0.1833\n",
            "Epoch 3040/3334\n",
            "Epoch 3040: Training Accuracy = 0.9935, Training Loss = 0.0804, Validation Accuracy = 0.9718, Validation Loss = 0.1833\n",
            "Epoch 3041/3334\n",
            "Epoch 3041: Training Accuracy = 0.9854, Training Loss = 0.1051, Validation Accuracy = 0.9728, Validation Loss = 0.1772\n",
            "Epoch 3042/3334\n",
            "Epoch 3042: Training Accuracy = 0.9854, Training Loss = 0.1051, Validation Accuracy = 0.9728, Validation Loss = 0.1772\n",
            "Epoch 3043/3334\n",
            "Epoch 3043: Training Accuracy = 0.9854, Training Loss = 0.1051, Validation Accuracy = 0.9728, Validation Loss = 0.1772\n",
            "Epoch 3044/3334\n",
            "Epoch 3044: Training Accuracy = 0.9922, Training Loss = 0.0830, Validation Accuracy = 0.9722, Validation Loss = 0.1819\n",
            "Epoch 3045/3334\n",
            "Epoch 3045: Training Accuracy = 0.9922, Training Loss = 0.0830, Validation Accuracy = 0.9722, Validation Loss = 0.1819\n",
            "Epoch 3046/3334\n",
            "Epoch 3046: Training Accuracy = 0.9922, Training Loss = 0.0830, Validation Accuracy = 0.9722, Validation Loss = 0.1819\n",
            "Epoch 3047/3334\n",
            "Epoch 3047: Training Accuracy = 0.9897, Training Loss = 0.0890, Validation Accuracy = 0.9739, Validation Loss = 0.1693\n",
            "Epoch 3048/3334\n",
            "Epoch 3048: Training Accuracy = 0.9897, Training Loss = 0.0890, Validation Accuracy = 0.9739, Validation Loss = 0.1693\n",
            "Epoch 3049/3334\n",
            "Epoch 3049: Training Accuracy = 0.9897, Training Loss = 0.0890, Validation Accuracy = 0.9739, Validation Loss = 0.1693\n",
            "Epoch 3050/3334\n",
            "Epoch 3050: Training Accuracy = 0.9897, Training Loss = 0.0890, Validation Accuracy = 0.9739, Validation Loss = 0.1693\n",
            "Epoch 3051/3334\n",
            "Epoch 3051: Training Accuracy = 0.9893, Training Loss = 0.0887, Validation Accuracy = 0.9745, Validation Loss = 0.1839\n",
            "Epoch 3052/3334\n",
            "Epoch 3052: Training Accuracy = 0.9893, Training Loss = 0.0887, Validation Accuracy = 0.9745, Validation Loss = 0.1839\n",
            "Epoch 3053/3334\n",
            "Epoch 3053: Training Accuracy = 0.9893, Training Loss = 0.0887, Validation Accuracy = 0.9745, Validation Loss = 0.1839\n",
            "Epoch 3054/3334\n",
            "Epoch 3054: Training Accuracy = 0.6270, Training Loss = 1.5268, Validation Accuracy = 0.6121, Validation Loss = 1.5530\n",
            "Epoch 3055/3334\n",
            "Epoch 3055: Training Accuracy = 0.6270, Training Loss = 1.5268, Validation Accuracy = 0.6121, Validation Loss = 1.5530\n",
            "Epoch 3056/3334\n",
            "Epoch 3056: Training Accuracy = 0.6270, Training Loss = 1.5268, Validation Accuracy = 0.6121, Validation Loss = 1.5530\n",
            "Epoch 3057/3334\n",
            "Epoch 3057: Training Accuracy = 0.9548, Training Loss = 0.4652, Validation Accuracy = 0.9022, Validation Loss = 0.6419\n",
            "Epoch 3058/3334\n",
            "Epoch 3058: Training Accuracy = 0.9548, Training Loss = 0.4652, Validation Accuracy = 0.9022, Validation Loss = 0.6419\n",
            "Epoch 3059/3334\n",
            "Epoch 3059: Training Accuracy = 0.9548, Training Loss = 0.4652, Validation Accuracy = 0.9022, Validation Loss = 0.6419\n",
            "Epoch 3060/3334\n",
            "Epoch 3060: Training Accuracy = 0.9548, Training Loss = 0.4652, Validation Accuracy = 0.9022, Validation Loss = 0.6419\n",
            "Epoch 3061/3334\n",
            "Epoch 3061: Training Accuracy = 0.9834, Training Loss = 0.2244, Validation Accuracy = 0.9658, Validation Loss = 0.3254\n",
            "Epoch 3062/3334\n",
            "Epoch 3062: Training Accuracy = 0.9834, Training Loss = 0.2244, Validation Accuracy = 0.9658, Validation Loss = 0.3254\n",
            "Epoch 3063/3334\n",
            "Epoch 3063: Training Accuracy = 0.9834, Training Loss = 0.2244, Validation Accuracy = 0.9658, Validation Loss = 0.3254\n",
            "Epoch 3064/3334\n",
            "Epoch 3064: Training Accuracy = 0.9902, Training Loss = 0.1405, Validation Accuracy = 0.9702, Validation Loss = 0.2366\n",
            "Epoch 3065/3334\n",
            "Epoch 3065: Training Accuracy = 0.9902, Training Loss = 0.1405, Validation Accuracy = 0.9702, Validation Loss = 0.2366\n",
            "Epoch 3066/3334\n",
            "Epoch 3066: Training Accuracy = 0.9902, Training Loss = 0.1405, Validation Accuracy = 0.9702, Validation Loss = 0.2366\n",
            "Epoch 3067/3334\n",
            "Epoch 3067: Training Accuracy = 0.9884, Training Loss = 0.1159, Validation Accuracy = 0.9733, Validation Loss = 0.1973\n",
            "Epoch 3068/3334\n",
            "Epoch 3068: Training Accuracy = 0.9884, Training Loss = 0.1159, Validation Accuracy = 0.9733, Validation Loss = 0.1973\n",
            "Epoch 3069/3334\n",
            "Epoch 3069: Training Accuracy = 0.9884, Training Loss = 0.1159, Validation Accuracy = 0.9733, Validation Loss = 0.1973\n",
            "Epoch 3070/3334\n",
            "Epoch 3070: Training Accuracy = 0.9884, Training Loss = 0.1159, Validation Accuracy = 0.9733, Validation Loss = 0.1973\n",
            "Epoch 3071/3334\n",
            "Epoch 3071: Training Accuracy = 0.9902, Training Loss = 0.0947, Validation Accuracy = 0.9740, Validation Loss = 0.1821\n",
            "Epoch 3072/3334\n",
            "Epoch 3072: Training Accuracy = 0.9902, Training Loss = 0.0947, Validation Accuracy = 0.9740, Validation Loss = 0.1821\n",
            "Epoch 3073/3334\n",
            "Epoch 3073: Training Accuracy = 0.9902, Training Loss = 0.0947, Validation Accuracy = 0.9740, Validation Loss = 0.1821\n",
            "Epoch 3074/3334\n",
            "Epoch 3074: Training Accuracy = 0.9873, Training Loss = 0.1032, Validation Accuracy = 0.9742, Validation Loss = 0.1744\n",
            "Epoch 3075/3334\n",
            "Epoch 3075: Training Accuracy = 0.9873, Training Loss = 0.1032, Validation Accuracy = 0.9742, Validation Loss = 0.1744\n",
            "Epoch 3076/3334\n",
            "Epoch 3076: Training Accuracy = 0.9873, Training Loss = 0.1032, Validation Accuracy = 0.9742, Validation Loss = 0.1744\n",
            "Epoch 3077/3334\n",
            "Epoch 3077: Training Accuracy = 0.9858, Training Loss = 0.1046, Validation Accuracy = 0.9746, Validation Loss = 0.1712\n",
            "Epoch 3078/3334\n",
            "Epoch 3078: Training Accuracy = 0.9858, Training Loss = 0.1046, Validation Accuracy = 0.9746, Validation Loss = 0.1712\n",
            "Epoch 3079/3334\n",
            "Epoch 3079: Training Accuracy = 0.9858, Training Loss = 0.1046, Validation Accuracy = 0.9746, Validation Loss = 0.1712\n",
            "Epoch 3080/3334\n",
            "Epoch 3080: Training Accuracy = 0.9858, Training Loss = 0.1046, Validation Accuracy = 0.9746, Validation Loss = 0.1712\n",
            "Epoch 3081/3334\n",
            "Epoch 3081: Training Accuracy = 0.9834, Training Loss = 0.1131, Validation Accuracy = 0.9734, Validation Loss = 0.1688\n",
            "Epoch 3082/3334\n",
            "Epoch 3082: Training Accuracy = 0.9834, Training Loss = 0.1131, Validation Accuracy = 0.9734, Validation Loss = 0.1688\n",
            "Epoch 3083/3334\n",
            "Epoch 3083: Training Accuracy = 0.9834, Training Loss = 0.1131, Validation Accuracy = 0.9734, Validation Loss = 0.1688\n",
            "Epoch 3084/3334\n",
            "Epoch 3084: Training Accuracy = 0.9883, Training Loss = 0.0912, Validation Accuracy = 0.9737, Validation Loss = 0.1674\n",
            "Epoch 3085/3334\n",
            "Epoch 3085: Training Accuracy = 0.9883, Training Loss = 0.0912, Validation Accuracy = 0.9737, Validation Loss = 0.1674\n",
            "Epoch 3086/3334\n",
            "Epoch 3086: Training Accuracy = 0.9883, Training Loss = 0.0912, Validation Accuracy = 0.9737, Validation Loss = 0.1674\n",
            "Epoch 3087/3334\n",
            "Epoch 3087: Training Accuracy = 0.9871, Training Loss = 0.0967, Validation Accuracy = 0.9736, Validation Loss = 0.1654\n",
            "Epoch 3088/3334\n",
            "Epoch 3088: Training Accuracy = 0.9871, Training Loss = 0.0967, Validation Accuracy = 0.9736, Validation Loss = 0.1654\n",
            "Epoch 3089/3334\n",
            "Epoch 3089: Training Accuracy = 0.9871, Training Loss = 0.0967, Validation Accuracy = 0.9736, Validation Loss = 0.1654\n",
            "Epoch 3090/3334\n",
            "Epoch 3090: Training Accuracy = 0.9871, Training Loss = 0.0967, Validation Accuracy = 0.9736, Validation Loss = 0.1654\n",
            "Epoch 3091/3334\n",
            "Epoch 3091: Training Accuracy = 0.9893, Training Loss = 0.0868, Validation Accuracy = 0.9736, Validation Loss = 0.1630\n",
            "Epoch 3092/3334\n",
            "Epoch 3092: Training Accuracy = 0.9893, Training Loss = 0.0868, Validation Accuracy = 0.9736, Validation Loss = 0.1630\n",
            "Epoch 3093/3334\n",
            "Epoch 3093: Training Accuracy = 0.9893, Training Loss = 0.0868, Validation Accuracy = 0.9736, Validation Loss = 0.1630\n",
            "Epoch 3094/3334\n",
            "Epoch 3094: Training Accuracy = 0.9932, Training Loss = 0.0717, Validation Accuracy = 0.9742, Validation Loss = 0.1653\n",
            "Epoch 3095/3334\n",
            "Epoch 3095: Training Accuracy = 0.9932, Training Loss = 0.0717, Validation Accuracy = 0.9742, Validation Loss = 0.1653\n",
            "Epoch 3096/3334\n",
            "Epoch 3096: Training Accuracy = 0.9932, Training Loss = 0.0717, Validation Accuracy = 0.9742, Validation Loss = 0.1653\n",
            "Epoch 3097/3334\n",
            "Epoch 3097: Training Accuracy = 0.9832, Training Loss = 0.1083, Validation Accuracy = 0.9734, Validation Loss = 0.1648\n",
            "Epoch 3098/3334\n",
            "Epoch 3098: Training Accuracy = 0.9832, Training Loss = 0.1083, Validation Accuracy = 0.9734, Validation Loss = 0.1648\n",
            "Epoch 3099/3334\n",
            "Epoch 3099: Training Accuracy = 0.9832, Training Loss = 0.1083, Validation Accuracy = 0.9734, Validation Loss = 0.1648\n",
            "Epoch 3100/3334\n",
            "Epoch 3100: Training Accuracy = 0.9832, Training Loss = 0.1083, Validation Accuracy = 0.9734, Validation Loss = 0.1648\n",
            "Epoch 3101/3334\n",
            "Epoch 3101: Training Accuracy = 0.9932, Training Loss = 0.0705, Validation Accuracy = 0.9724, Validation Loss = 0.1652\n",
            "Epoch 3102/3334\n",
            "Epoch 3102: Training Accuracy = 0.9932, Training Loss = 0.0705, Validation Accuracy = 0.9724, Validation Loss = 0.1652\n",
            "Epoch 3103/3334\n",
            "Epoch 3103: Training Accuracy = 0.9932, Training Loss = 0.0705, Validation Accuracy = 0.9724, Validation Loss = 0.1652\n",
            "Epoch 3104/3334\n",
            "Epoch 3104: Training Accuracy = 0.9883, Training Loss = 0.0878, Validation Accuracy = 0.9730, Validation Loss = 0.1732\n",
            "Epoch 3105/3334\n",
            "Epoch 3105: Training Accuracy = 0.9883, Training Loss = 0.0878, Validation Accuracy = 0.9730, Validation Loss = 0.1732\n",
            "Epoch 3106/3334\n",
            "Epoch 3106: Training Accuracy = 0.9883, Training Loss = 0.0878, Validation Accuracy = 0.9730, Validation Loss = 0.1732\n",
            "Epoch 3107/3334\n",
            "Epoch 3107: Training Accuracy = 0.2933, Training Loss = 3.1254, Validation Accuracy = 0.3373, Validation Loss = 2.8854\n",
            "Epoch 3108/3334\n",
            "Epoch 3108: Training Accuracy = 0.2933, Training Loss = 3.1254, Validation Accuracy = 0.3373, Validation Loss = 2.8854\n",
            "Epoch 3109/3334\n",
            "Epoch 3109: Training Accuracy = 0.2933, Training Loss = 3.1254, Validation Accuracy = 0.3373, Validation Loss = 2.8854\n",
            "Epoch 3110/3334\n",
            "Epoch 3110: Training Accuracy = 0.2933, Training Loss = 3.1254, Validation Accuracy = 0.3373, Validation Loss = 2.8854\n",
            "Epoch 3111/3334\n",
            "Epoch 3111: Training Accuracy = 0.8604, Training Loss = 0.7609, Validation Accuracy = 0.8313, Validation Loss = 0.8461\n",
            "Epoch 3112/3334\n",
            "Epoch 3112: Training Accuracy = 0.8604, Training Loss = 0.7609, Validation Accuracy = 0.8313, Validation Loss = 0.8461\n",
            "Epoch 3113/3334\n",
            "Epoch 3113: Training Accuracy = 0.8604, Training Loss = 0.7609, Validation Accuracy = 0.8313, Validation Loss = 0.8461\n",
            "Epoch 3114/3334\n",
            "Epoch 3114: Training Accuracy = 0.9736, Training Loss = 0.3375, Validation Accuracy = 0.9592, Validation Loss = 0.4056\n",
            "Epoch 3115/3334\n",
            "Epoch 3115: Training Accuracy = 0.9736, Training Loss = 0.3375, Validation Accuracy = 0.9592, Validation Loss = 0.4056\n",
            "Epoch 3116/3334\n",
            "Epoch 3116: Training Accuracy = 0.9736, Training Loss = 0.3375, Validation Accuracy = 0.9592, Validation Loss = 0.4056\n",
            "Epoch 3117/3334\n",
            "Epoch 3117: Training Accuracy = 0.9910, Training Loss = 0.1819, Validation Accuracy = 0.9719, Validation Loss = 0.2754\n",
            "Epoch 3118/3334\n",
            "Epoch 3118: Training Accuracy = 0.9910, Training Loss = 0.1819, Validation Accuracy = 0.9719, Validation Loss = 0.2754\n",
            "Epoch 3119/3334\n",
            "Epoch 3119: Training Accuracy = 0.9910, Training Loss = 0.1819, Validation Accuracy = 0.9719, Validation Loss = 0.2754\n",
            "Epoch 3120/3334\n",
            "Epoch 3120: Training Accuracy = 0.9910, Training Loss = 0.1819, Validation Accuracy = 0.9719, Validation Loss = 0.2754\n",
            "Epoch 3121/3334\n",
            "Epoch 3121: Training Accuracy = 0.9873, Training Loss = 0.1368, Validation Accuracy = 0.9719, Validation Loss = 0.2173\n",
            "Epoch 3122/3334\n",
            "Epoch 3122: Training Accuracy = 0.9873, Training Loss = 0.1368, Validation Accuracy = 0.9719, Validation Loss = 0.2173\n",
            "Epoch 3123/3334\n",
            "Epoch 3123: Training Accuracy = 0.9873, Training Loss = 0.1368, Validation Accuracy = 0.9719, Validation Loss = 0.2173\n",
            "Epoch 3124/3334\n",
            "Epoch 3124: Training Accuracy = 0.9844, Training Loss = 0.1226, Validation Accuracy = 0.9745, Validation Loss = 0.1878\n",
            "Epoch 3125/3334\n",
            "Epoch 3125: Training Accuracy = 0.9844, Training Loss = 0.1226, Validation Accuracy = 0.9745, Validation Loss = 0.1878\n",
            "Epoch 3126/3334\n",
            "Epoch 3126: Training Accuracy = 0.9844, Training Loss = 0.1226, Validation Accuracy = 0.9745, Validation Loss = 0.1878\n",
            "Epoch 3127/3334\n",
            "Epoch 3127: Training Accuracy = 0.9858, Training Loss = 0.1070, Validation Accuracy = 0.9746, Validation Loss = 0.1751\n",
            "Epoch 3128/3334\n",
            "Epoch 3128: Training Accuracy = 0.9858, Training Loss = 0.1070, Validation Accuracy = 0.9746, Validation Loss = 0.1751\n",
            "Epoch 3129/3334\n",
            "Epoch 3129: Training Accuracy = 0.9858, Training Loss = 0.1070, Validation Accuracy = 0.9746, Validation Loss = 0.1751\n",
            "Epoch 3130/3334\n",
            "Epoch 3130: Training Accuracy = 0.9858, Training Loss = 0.1070, Validation Accuracy = 0.9746, Validation Loss = 0.1751\n",
            "Epoch 3131/3334\n",
            "Epoch 3131: Training Accuracy = 0.9873, Training Loss = 0.1017, Validation Accuracy = 0.9746, Validation Loss = 0.1696\n",
            "Epoch 3132/3334\n",
            "Epoch 3132: Training Accuracy = 0.9873, Training Loss = 0.1017, Validation Accuracy = 0.9746, Validation Loss = 0.1696\n",
            "Epoch 3133/3334\n",
            "Epoch 3133: Training Accuracy = 0.9873, Training Loss = 0.1017, Validation Accuracy = 0.9746, Validation Loss = 0.1696\n",
            "Epoch 3134/3334\n",
            "Epoch 3134: Training Accuracy = 0.9873, Training Loss = 0.0975, Validation Accuracy = 0.9742, Validation Loss = 0.1657\n",
            "Epoch 3135/3334\n",
            "Epoch 3135: Training Accuracy = 0.9873, Training Loss = 0.0975, Validation Accuracy = 0.9742, Validation Loss = 0.1657\n",
            "Epoch 3136/3334\n",
            "Epoch 3136: Training Accuracy = 0.9873, Training Loss = 0.0975, Validation Accuracy = 0.9742, Validation Loss = 0.1657\n",
            "Epoch 3137/3334\n",
            "Epoch 3137: Training Accuracy = 0.9858, Training Loss = 0.1008, Validation Accuracy = 0.9737, Validation Loss = 0.1634\n",
            "Epoch 3138/3334\n",
            "Epoch 3138: Training Accuracy = 0.9858, Training Loss = 0.1008, Validation Accuracy = 0.9737, Validation Loss = 0.1634\n",
            "Epoch 3139/3334\n",
            "Epoch 3139: Training Accuracy = 0.9858, Training Loss = 0.1008, Validation Accuracy = 0.9737, Validation Loss = 0.1634\n",
            "Epoch 3140/3334\n",
            "Epoch 3140: Training Accuracy = 0.9858, Training Loss = 0.1008, Validation Accuracy = 0.9737, Validation Loss = 0.1634\n",
            "Epoch 3141/3334\n",
            "Epoch 3141: Training Accuracy = 0.9873, Training Loss = 0.0940, Validation Accuracy = 0.9739, Validation Loss = 0.1635\n",
            "Epoch 3142/3334\n",
            "Epoch 3142: Training Accuracy = 0.9873, Training Loss = 0.0940, Validation Accuracy = 0.9739, Validation Loss = 0.1635\n",
            "Epoch 3143/3334\n",
            "Epoch 3143: Training Accuracy = 0.9873, Training Loss = 0.0940, Validation Accuracy = 0.9739, Validation Loss = 0.1635\n",
            "Epoch 3144/3334\n",
            "Epoch 3144: Training Accuracy = 0.9854, Training Loss = 0.1037, Validation Accuracy = 0.9743, Validation Loss = 0.1607\n",
            "Epoch 3145/3334\n",
            "Epoch 3145: Training Accuracy = 0.9854, Training Loss = 0.1037, Validation Accuracy = 0.9743, Validation Loss = 0.1607\n",
            "Epoch 3146/3334\n",
            "Epoch 3146: Training Accuracy = 0.9854, Training Loss = 0.1037, Validation Accuracy = 0.9743, Validation Loss = 0.1607\n",
            "Epoch 3147/3334\n",
            "Epoch 3147: Training Accuracy = 0.9832, Training Loss = 0.1068, Validation Accuracy = 0.9753, Validation Loss = 0.1601\n",
            "Epoch 3148/3334\n",
            "Epoch 3148: Training Accuracy = 0.9832, Training Loss = 0.1068, Validation Accuracy = 0.9753, Validation Loss = 0.1601\n",
            "Epoch 3149/3334\n",
            "Epoch 3149: Training Accuracy = 0.9832, Training Loss = 0.1068, Validation Accuracy = 0.9753, Validation Loss = 0.1601\n",
            "Epoch 3150/3334\n",
            "Epoch 3150: Training Accuracy = 0.9832, Training Loss = 0.1068, Validation Accuracy = 0.9753, Validation Loss = 0.1601\n",
            "Epoch 3151/3334\n",
            "Epoch 3151: Training Accuracy = 0.9893, Training Loss = 0.0845, Validation Accuracy = 0.9737, Validation Loss = 0.1620\n",
            "Epoch 3152/3334\n",
            "Epoch 3152: Training Accuracy = 0.9893, Training Loss = 0.0845, Validation Accuracy = 0.9737, Validation Loss = 0.1620\n",
            "Epoch 3153/3334\n",
            "Epoch 3153: Training Accuracy = 0.9893, Training Loss = 0.0845, Validation Accuracy = 0.9737, Validation Loss = 0.1620\n",
            "Epoch 3154/3334\n",
            "Epoch 3154: Training Accuracy = 0.9902, Training Loss = 0.0806, Validation Accuracy = 0.9733, Validation Loss = 0.1590\n",
            "Epoch 3155/3334\n",
            "Epoch 3155: Training Accuracy = 0.9902, Training Loss = 0.0806, Validation Accuracy = 0.9733, Validation Loss = 0.1590\n",
            "Epoch 3156/3334\n",
            "Epoch 3156: Training Accuracy = 0.9902, Training Loss = 0.0806, Validation Accuracy = 0.9733, Validation Loss = 0.1590\n",
            "Epoch 3157/3334\n",
            "Epoch 3157: Training Accuracy = 0.9845, Training Loss = 0.1040, Validation Accuracy = 0.9742, Validation Loss = 0.1634\n",
            "Epoch 3158/3334\n",
            "Epoch 3158: Training Accuracy = 0.9845, Training Loss = 0.1040, Validation Accuracy = 0.9742, Validation Loss = 0.1634\n",
            "Epoch 3159/3334\n",
            "Epoch 3159: Training Accuracy = 0.9845, Training Loss = 0.1040, Validation Accuracy = 0.9742, Validation Loss = 0.1634\n",
            "Epoch 3160/3334\n",
            "Epoch 3160: Training Accuracy = 0.9845, Training Loss = 0.1040, Validation Accuracy = 0.9742, Validation Loss = 0.1634\n",
            "Epoch 3161/3334\n",
            "Epoch 3161: Training Accuracy = 0.9912, Training Loss = 0.0951, Validation Accuracy = 0.9692, Validation Loss = 0.2119\n",
            "Epoch 3162/3334\n",
            "Epoch 3162: Training Accuracy = 0.9912, Training Loss = 0.0951, Validation Accuracy = 0.9692, Validation Loss = 0.2119\n",
            "Epoch 3163/3334\n",
            "Epoch 3163: Training Accuracy = 0.9912, Training Loss = 0.0951, Validation Accuracy = 0.9692, Validation Loss = 0.2119\n",
            "Epoch 3164/3334\n",
            "Epoch 3164: Training Accuracy = 0.7852, Training Loss = 1.1133, Validation Accuracy = 0.7185, Validation Loss = 1.2399\n",
            "Epoch 3165/3334\n",
            "Epoch 3165: Training Accuracy = 0.7852, Training Loss = 1.1133, Validation Accuracy = 0.7185, Validation Loss = 1.2399\n",
            "Epoch 3166/3334\n",
            "Epoch 3166: Training Accuracy = 0.7852, Training Loss = 1.1133, Validation Accuracy = 0.7185, Validation Loss = 1.2399\n",
            "Epoch 3167/3334\n",
            "Epoch 3167: Training Accuracy = 0.9638, Training Loss = 0.3884, Validation Accuracy = 0.9479, Validation Loss = 0.4621\n",
            "Epoch 3168/3334\n",
            "Epoch 3168: Training Accuracy = 0.9638, Training Loss = 0.3884, Validation Accuracy = 0.9479, Validation Loss = 0.4621\n",
            "Epoch 3169/3334\n",
            "Epoch 3169: Training Accuracy = 0.9638, Training Loss = 0.3884, Validation Accuracy = 0.9479, Validation Loss = 0.4621\n",
            "Epoch 3170/3334\n",
            "Epoch 3170: Training Accuracy = 0.9638, Training Loss = 0.3884, Validation Accuracy = 0.9479, Validation Loss = 0.4621\n",
            "Epoch 3171/3334\n",
            "Epoch 3171: Training Accuracy = 0.9873, Training Loss = 0.2125, Validation Accuracy = 0.9690, Validation Loss = 0.2960\n",
            "Epoch 3172/3334\n",
            "Epoch 3172: Training Accuracy = 0.9873, Training Loss = 0.2125, Validation Accuracy = 0.9690, Validation Loss = 0.2960\n",
            "Epoch 3173/3334\n",
            "Epoch 3173: Training Accuracy = 0.9873, Training Loss = 0.2125, Validation Accuracy = 0.9690, Validation Loss = 0.2960\n",
            "Epoch 3174/3334\n",
            "Epoch 3174: Training Accuracy = 0.9854, Training Loss = 0.1570, Validation Accuracy = 0.9730, Validation Loss = 0.2201\n",
            "Epoch 3175/3334\n",
            "Epoch 3175: Training Accuracy = 0.9854, Training Loss = 0.1570, Validation Accuracy = 0.9730, Validation Loss = 0.2201\n",
            "Epoch 3176/3334\n",
            "Epoch 3176: Training Accuracy = 0.9854, Training Loss = 0.1570, Validation Accuracy = 0.9730, Validation Loss = 0.2201\n",
            "Epoch 3177/3334\n",
            "Epoch 3177: Training Accuracy = 0.9819, Training Loss = 0.1439, Validation Accuracy = 0.9730, Validation Loss = 0.1945\n",
            "Epoch 3178/3334\n",
            "Epoch 3178: Training Accuracy = 0.9819, Training Loss = 0.1439, Validation Accuracy = 0.9730, Validation Loss = 0.1945\n",
            "Epoch 3179/3334\n",
            "Epoch 3179: Training Accuracy = 0.9819, Training Loss = 0.1439, Validation Accuracy = 0.9730, Validation Loss = 0.1945\n",
            "Epoch 3180/3334\n",
            "Epoch 3180: Training Accuracy = 0.9819, Training Loss = 0.1439, Validation Accuracy = 0.9730, Validation Loss = 0.1945\n",
            "Epoch 3181/3334\n",
            "Epoch 3181: Training Accuracy = 0.9834, Training Loss = 0.1244, Validation Accuracy = 0.9736, Validation Loss = 0.1812\n",
            "Epoch 3182/3334\n",
            "Epoch 3182: Training Accuracy = 0.9834, Training Loss = 0.1244, Validation Accuracy = 0.9736, Validation Loss = 0.1812\n",
            "Epoch 3183/3334\n",
            "Epoch 3183: Training Accuracy = 0.9834, Training Loss = 0.1244, Validation Accuracy = 0.9736, Validation Loss = 0.1812\n",
            "Epoch 3184/3334\n",
            "Epoch 3184: Training Accuracy = 0.9883, Training Loss = 0.0978, Validation Accuracy = 0.9750, Validation Loss = 0.1722\n",
            "Epoch 3185/3334\n",
            "Epoch 3185: Training Accuracy = 0.9883, Training Loss = 0.0978, Validation Accuracy = 0.9750, Validation Loss = 0.1722\n",
            "Epoch 3186/3334\n",
            "Epoch 3186: Training Accuracy = 0.9883, Training Loss = 0.0978, Validation Accuracy = 0.9750, Validation Loss = 0.1722\n",
            "Epoch 3187/3334\n",
            "Epoch 3187: Training Accuracy = 0.9832, Training Loss = 0.1125, Validation Accuracy = 0.9748, Validation Loss = 0.1657\n",
            "Epoch 3188/3334\n",
            "Epoch 3188: Training Accuracy = 0.9832, Training Loss = 0.1125, Validation Accuracy = 0.9748, Validation Loss = 0.1657\n",
            "Epoch 3189/3334\n",
            "Epoch 3189: Training Accuracy = 0.9832, Training Loss = 0.1125, Validation Accuracy = 0.9748, Validation Loss = 0.1657\n",
            "Epoch 3190/3334\n",
            "Epoch 3190: Training Accuracy = 0.9832, Training Loss = 0.1125, Validation Accuracy = 0.9748, Validation Loss = 0.1657\n",
            "Epoch 3191/3334\n",
            "Epoch 3191: Training Accuracy = 0.9893, Training Loss = 0.0904, Validation Accuracy = 0.9742, Validation Loss = 0.1629\n",
            "Epoch 3192/3334\n",
            "Epoch 3192: Training Accuracy = 0.9893, Training Loss = 0.0904, Validation Accuracy = 0.9742, Validation Loss = 0.1629\n",
            "Epoch 3193/3334\n",
            "Epoch 3193: Training Accuracy = 0.9893, Training Loss = 0.0904, Validation Accuracy = 0.9742, Validation Loss = 0.1629\n",
            "Epoch 3194/3334\n",
            "Epoch 3194: Training Accuracy = 0.9893, Training Loss = 0.0862, Validation Accuracy = 0.9750, Validation Loss = 0.1585\n",
            "Epoch 3195/3334\n",
            "Epoch 3195: Training Accuracy = 0.9893, Training Loss = 0.0862, Validation Accuracy = 0.9750, Validation Loss = 0.1585\n",
            "Epoch 3196/3334\n",
            "Epoch 3196: Training Accuracy = 0.9893, Training Loss = 0.0862, Validation Accuracy = 0.9750, Validation Loss = 0.1585\n",
            "Epoch 3197/3334\n",
            "Epoch 3197: Training Accuracy = 0.9884, Training Loss = 0.0899, Validation Accuracy = 0.9750, Validation Loss = 0.1576\n",
            "Epoch 3198/3334\n",
            "Epoch 3198: Training Accuracy = 0.9884, Training Loss = 0.0899, Validation Accuracy = 0.9750, Validation Loss = 0.1576\n",
            "Epoch 3199/3334\n",
            "Epoch 3199: Training Accuracy = 0.9884, Training Loss = 0.0899, Validation Accuracy = 0.9750, Validation Loss = 0.1576\n",
            "Epoch 3200/3334\n",
            "Epoch 3200: Training Accuracy = 0.9884, Training Loss = 0.0899, Validation Accuracy = 0.9750, Validation Loss = 0.1576\n",
            "Epoch 3201/3334\n",
            "Epoch 3201: Training Accuracy = 0.9893, Training Loss = 0.0859, Validation Accuracy = 0.9736, Validation Loss = 0.1572\n",
            "Epoch 3202/3334\n",
            "Epoch 3202: Training Accuracy = 0.9893, Training Loss = 0.0859, Validation Accuracy = 0.9736, Validation Loss = 0.1572\n",
            "Epoch 3203/3334\n",
            "Epoch 3203: Training Accuracy = 0.9893, Training Loss = 0.0859, Validation Accuracy = 0.9736, Validation Loss = 0.1572\n",
            "Epoch 3204/3334\n",
            "Epoch 3204: Training Accuracy = 0.9873, Training Loss = 0.0919, Validation Accuracy = 0.9750, Validation Loss = 0.1560\n",
            "Epoch 3205/3334\n",
            "Epoch 3205: Training Accuracy = 0.9873, Training Loss = 0.0919, Validation Accuracy = 0.9750, Validation Loss = 0.1560\n",
            "Epoch 3206/3334\n",
            "Epoch 3206: Training Accuracy = 0.9873, Training Loss = 0.0919, Validation Accuracy = 0.9750, Validation Loss = 0.1560\n",
            "Epoch 3207/3334\n",
            "Epoch 3207: Training Accuracy = 0.9858, Training Loss = 0.0946, Validation Accuracy = 0.9750, Validation Loss = 0.1567\n",
            "Epoch 3208/3334\n",
            "Epoch 3208: Training Accuracy = 0.9858, Training Loss = 0.0946, Validation Accuracy = 0.9750, Validation Loss = 0.1567\n",
            "Epoch 3209/3334\n",
            "Epoch 3209: Training Accuracy = 0.9858, Training Loss = 0.0946, Validation Accuracy = 0.9750, Validation Loss = 0.1567\n",
            "Epoch 3210/3334\n",
            "Epoch 3210: Training Accuracy = 0.9858, Training Loss = 0.0946, Validation Accuracy = 0.9750, Validation Loss = 0.1567\n",
            "Epoch 3211/3334\n",
            "Epoch 3211: Training Accuracy = 0.9902, Training Loss = 0.0812, Validation Accuracy = 0.9756, Validation Loss = 0.1554\n",
            "Epoch 3212/3334\n",
            "Epoch 3212: Training Accuracy = 0.9902, Training Loss = 0.0812, Validation Accuracy = 0.9756, Validation Loss = 0.1554\n",
            "Epoch 3213/3334\n",
            "Epoch 3213: Training Accuracy = 0.9902, Training Loss = 0.0812, Validation Accuracy = 0.9756, Validation Loss = 0.1554\n",
            "Epoch 3214/3334\n",
            "Epoch 3214: Training Accuracy = 0.4688, Training Loss = 2.3081, Validation Accuracy = 0.1861, Validation Loss = 3.5696\n",
            "Epoch 3215/3334\n",
            "Epoch 3215: Training Accuracy = 0.4688, Training Loss = 2.3081, Validation Accuracy = 0.1861, Validation Loss = 3.5696\n",
            "Epoch 3216/3334\n",
            "Epoch 3216: Training Accuracy = 0.4688, Training Loss = 2.3081, Validation Accuracy = 0.1861, Validation Loss = 3.5696\n",
            "Epoch 3217/3334\n",
            "Epoch 3217: Training Accuracy = 0.7571, Training Loss = 1.0916, Validation Accuracy = 0.7585, Validation Loss = 1.1165\n",
            "Epoch 3218/3334\n",
            "Epoch 3218: Training Accuracy = 0.7571, Training Loss = 1.0916, Validation Accuracy = 0.7585, Validation Loss = 1.1165\n",
            "Epoch 3219/3334\n",
            "Epoch 3219: Training Accuracy = 0.7571, Training Loss = 1.0916, Validation Accuracy = 0.7585, Validation Loss = 1.1165\n",
            "Epoch 3220/3334\n",
            "Epoch 3220: Training Accuracy = 0.7571, Training Loss = 1.0916, Validation Accuracy = 0.7585, Validation Loss = 1.1165\n",
            "Epoch 3221/3334\n",
            "Epoch 3221: Training Accuracy = 0.9766, Training Loss = 0.3491, Validation Accuracy = 0.9458, Validation Loss = 0.4696\n",
            "Epoch 3222/3334\n",
            "Epoch 3222: Training Accuracy = 0.9766, Training Loss = 0.3491, Validation Accuracy = 0.9458, Validation Loss = 0.4696\n",
            "Epoch 3223/3334\n",
            "Epoch 3223: Training Accuracy = 0.9766, Training Loss = 0.3491, Validation Accuracy = 0.9458, Validation Loss = 0.4696\n",
            "Epoch 3224/3334\n",
            "Epoch 3224: Training Accuracy = 0.9814, Training Loss = 0.1941, Validation Accuracy = 0.9699, Validation Loss = 0.2572\n",
            "Epoch 3225/3334\n",
            "Epoch 3225: Training Accuracy = 0.9814, Training Loss = 0.1941, Validation Accuracy = 0.9699, Validation Loss = 0.2572\n",
            "Epoch 3226/3334\n",
            "Epoch 3226: Training Accuracy = 0.9814, Training Loss = 0.1941, Validation Accuracy = 0.9699, Validation Loss = 0.2572\n",
            "Epoch 3227/3334\n",
            "Epoch 3227: Training Accuracy = 0.9922, Training Loss = 0.1179, Validation Accuracy = 0.9719, Validation Loss = 0.2023\n",
            "Epoch 3228/3334\n",
            "Epoch 3228: Training Accuracy = 0.9922, Training Loss = 0.1179, Validation Accuracy = 0.9719, Validation Loss = 0.2023\n",
            "Epoch 3229/3334\n",
            "Epoch 3229: Training Accuracy = 0.9922, Training Loss = 0.1179, Validation Accuracy = 0.9719, Validation Loss = 0.2023\n",
            "Epoch 3230/3334\n",
            "Epoch 3230: Training Accuracy = 0.9922, Training Loss = 0.1179, Validation Accuracy = 0.9719, Validation Loss = 0.2023\n",
            "Epoch 3231/3334\n",
            "Epoch 3231: Training Accuracy = 0.9873, Training Loss = 0.1106, Validation Accuracy = 0.9731, Validation Loss = 0.1784\n",
            "Epoch 3232/3334\n",
            "Epoch 3232: Training Accuracy = 0.9873, Training Loss = 0.1106, Validation Accuracy = 0.9731, Validation Loss = 0.1784\n",
            "Epoch 3233/3334\n",
            "Epoch 3233: Training Accuracy = 0.9873, Training Loss = 0.1106, Validation Accuracy = 0.9731, Validation Loss = 0.1784\n",
            "Epoch 3234/3334\n",
            "Epoch 3234: Training Accuracy = 0.9824, Training Loss = 0.1193, Validation Accuracy = 0.9734, Validation Loss = 0.1694\n",
            "Epoch 3235/3334\n",
            "Epoch 3235: Training Accuracy = 0.9824, Training Loss = 0.1193, Validation Accuracy = 0.9734, Validation Loss = 0.1694\n",
            "Epoch 3236/3334\n",
            "Epoch 3236: Training Accuracy = 0.9824, Training Loss = 0.1193, Validation Accuracy = 0.9734, Validation Loss = 0.1694\n",
            "Epoch 3237/3334\n",
            "Epoch 3237: Training Accuracy = 0.9897, Training Loss = 0.0931, Validation Accuracy = 0.9733, Validation Loss = 0.1655\n",
            "Epoch 3238/3334\n",
            "Epoch 3238: Training Accuracy = 0.9897, Training Loss = 0.0931, Validation Accuracy = 0.9733, Validation Loss = 0.1655\n",
            "Epoch 3239/3334\n",
            "Epoch 3239: Training Accuracy = 0.9897, Training Loss = 0.0931, Validation Accuracy = 0.9733, Validation Loss = 0.1655\n",
            "Epoch 3240/3334\n",
            "Epoch 3240: Training Accuracy = 0.9897, Training Loss = 0.0931, Validation Accuracy = 0.9733, Validation Loss = 0.1655\n",
            "Epoch 3241/3334\n",
            "Epoch 3241: Training Accuracy = 0.9922, Training Loss = 0.0843, Validation Accuracy = 0.9733, Validation Loss = 0.1646\n",
            "Epoch 3242/3334\n",
            "Epoch 3242: Training Accuracy = 0.9922, Training Loss = 0.0843, Validation Accuracy = 0.9733, Validation Loss = 0.1646\n",
            "Epoch 3243/3334\n",
            "Epoch 3243: Training Accuracy = 0.9922, Training Loss = 0.0843, Validation Accuracy = 0.9733, Validation Loss = 0.1646\n",
            "Epoch 3244/3334\n",
            "Epoch 3244: Training Accuracy = 0.9873, Training Loss = 0.1012, Validation Accuracy = 0.9743, Validation Loss = 0.1639\n",
            "Epoch 3245/3334\n",
            "Epoch 3245: Training Accuracy = 0.9873, Training Loss = 0.1012, Validation Accuracy = 0.9743, Validation Loss = 0.1639\n",
            "Epoch 3246/3334\n",
            "Epoch 3246: Training Accuracy = 0.9873, Training Loss = 0.1012, Validation Accuracy = 0.9743, Validation Loss = 0.1639\n",
            "Epoch 3247/3334\n",
            "Epoch 3247: Training Accuracy = 0.9910, Training Loss = 0.0863, Validation Accuracy = 0.9742, Validation Loss = 0.1624\n",
            "Epoch 3248/3334\n",
            "Epoch 3248: Training Accuracy = 0.9910, Training Loss = 0.0863, Validation Accuracy = 0.9742, Validation Loss = 0.1624\n",
            "Epoch 3249/3334\n",
            "Epoch 3249: Training Accuracy = 0.9910, Training Loss = 0.0863, Validation Accuracy = 0.9742, Validation Loss = 0.1624\n",
            "Epoch 3250/3334\n",
            "Epoch 3250: Training Accuracy = 0.9910, Training Loss = 0.0863, Validation Accuracy = 0.9742, Validation Loss = 0.1624\n",
            "Epoch 3251/3334\n",
            "Epoch 3251: Training Accuracy = 0.9932, Training Loss = 0.0750, Validation Accuracy = 0.9740, Validation Loss = 0.1623\n",
            "Epoch 3252/3334\n",
            "Epoch 3252: Training Accuracy = 0.9932, Training Loss = 0.0750, Validation Accuracy = 0.9740, Validation Loss = 0.1623\n",
            "Epoch 3253/3334\n",
            "Epoch 3253: Training Accuracy = 0.9932, Training Loss = 0.0750, Validation Accuracy = 0.9740, Validation Loss = 0.1623\n",
            "Epoch 3254/3334\n",
            "Epoch 3254: Training Accuracy = 0.9883, Training Loss = 0.0913, Validation Accuracy = 0.9734, Validation Loss = 0.1622\n",
            "Epoch 3255/3334\n",
            "Epoch 3255: Training Accuracy = 0.9883, Training Loss = 0.0913, Validation Accuracy = 0.9734, Validation Loss = 0.1622\n",
            "Epoch 3256/3334\n",
            "Epoch 3256: Training Accuracy = 0.9883, Training Loss = 0.0913, Validation Accuracy = 0.9734, Validation Loss = 0.1622\n",
            "Epoch 3257/3334\n",
            "Epoch 3257: Training Accuracy = 0.9897, Training Loss = 0.0854, Validation Accuracy = 0.9746, Validation Loss = 0.1614\n",
            "Epoch 3258/3334\n",
            "Epoch 3258: Training Accuracy = 0.9897, Training Loss = 0.0854, Validation Accuracy = 0.9746, Validation Loss = 0.1614\n",
            "Epoch 3259/3334\n",
            "Epoch 3259: Training Accuracy = 0.9897, Training Loss = 0.0854, Validation Accuracy = 0.9746, Validation Loss = 0.1614\n",
            "Epoch 3260/3334\n",
            "Epoch 3260: Training Accuracy = 0.9897, Training Loss = 0.0854, Validation Accuracy = 0.9746, Validation Loss = 0.1614\n",
            "Epoch 3261/3334\n",
            "Epoch 3261: Training Accuracy = 0.9844, Training Loss = 0.1087, Validation Accuracy = 0.9743, Validation Loss = 0.1585\n",
            "Epoch 3262/3334\n",
            "Epoch 3262: Training Accuracy = 0.9844, Training Loss = 0.1087, Validation Accuracy = 0.9743, Validation Loss = 0.1585\n",
            "Epoch 3263/3334\n",
            "Epoch 3263: Training Accuracy = 0.9844, Training Loss = 0.1087, Validation Accuracy = 0.9743, Validation Loss = 0.1585\n",
            "Epoch 3264/3334\n",
            "Epoch 3264: Training Accuracy = 0.9912, Training Loss = 0.0819, Validation Accuracy = 0.9728, Validation Loss = 0.1653\n",
            "Epoch 3265/3334\n",
            "Epoch 3265: Training Accuracy = 0.9912, Training Loss = 0.0819, Validation Accuracy = 0.9728, Validation Loss = 0.1653\n",
            "Epoch 3266/3334\n",
            "Epoch 3266: Training Accuracy = 0.9912, Training Loss = 0.0819, Validation Accuracy = 0.9728, Validation Loss = 0.1653\n",
            "Epoch 3267/3334\n",
            "Epoch 3267: Training Accuracy = 0.9910, Training Loss = 0.0812, Validation Accuracy = 0.9733, Validation Loss = 0.1731\n",
            "Epoch 3268/3334\n",
            "Epoch 3268: Training Accuracy = 0.9910, Training Loss = 0.0812, Validation Accuracy = 0.9733, Validation Loss = 0.1731\n",
            "Epoch 3269/3334\n",
            "Epoch 3269: Training Accuracy = 0.9910, Training Loss = 0.0812, Validation Accuracy = 0.9733, Validation Loss = 0.1731\n",
            "Epoch 3270/3334\n",
            "Epoch 3270: Training Accuracy = 0.9910, Training Loss = 0.0812, Validation Accuracy = 0.9733, Validation Loss = 0.1731\n",
            "Epoch 3271/3334\n",
            "Epoch 3271: Training Accuracy = 0.3477, Training Loss = 2.5729, Validation Accuracy = 0.4272, Validation Loss = 2.4723\n",
            "Epoch 3272/3334\n",
            "Epoch 3272: Training Accuracy = 0.3477, Training Loss = 2.5729, Validation Accuracy = 0.4272, Validation Loss = 2.4723\n",
            "Epoch 3273/3334\n",
            "Epoch 3273: Training Accuracy = 0.3477, Training Loss = 2.5729, Validation Accuracy = 0.4272, Validation Loss = 2.4723\n",
            "Epoch 3274/3334\n",
            "Epoch 3274: Training Accuracy = 0.8564, Training Loss = 0.8273, Validation Accuracy = 0.8286, Validation Loss = 0.9311\n",
            "Epoch 3275/3334\n",
            "Epoch 3275: Training Accuracy = 0.8564, Training Loss = 0.8273, Validation Accuracy = 0.8286, Validation Loss = 0.9311\n",
            "Epoch 3276/3334\n",
            "Epoch 3276: Training Accuracy = 0.8564, Training Loss = 0.8273, Validation Accuracy = 0.8286, Validation Loss = 0.9311\n",
            "Epoch 3277/3334\n",
            "Epoch 3277: Training Accuracy = 0.9755, Training Loss = 0.3353, Validation Accuracy = 0.9390, Validation Loss = 0.4899\n",
            "Epoch 3278/3334\n",
            "Epoch 3278: Training Accuracy = 0.9755, Training Loss = 0.3353, Validation Accuracy = 0.9390, Validation Loss = 0.4899\n",
            "Epoch 3279/3334\n",
            "Epoch 3279: Training Accuracy = 0.9755, Training Loss = 0.3353, Validation Accuracy = 0.9390, Validation Loss = 0.4899\n",
            "Epoch 3280/3334\n",
            "Epoch 3280: Training Accuracy = 0.9755, Training Loss = 0.3353, Validation Accuracy = 0.9390, Validation Loss = 0.4899\n",
            "Epoch 3281/3334\n",
            "Epoch 3281: Training Accuracy = 0.9824, Training Loss = 0.2008, Validation Accuracy = 0.9664, Validation Loss = 0.2918\n",
            "Epoch 3282/3334\n",
            "Epoch 3282: Training Accuracy = 0.9824, Training Loss = 0.2008, Validation Accuracy = 0.9664, Validation Loss = 0.2918\n",
            "Epoch 3283/3334\n",
            "Epoch 3283: Training Accuracy = 0.9824, Training Loss = 0.2008, Validation Accuracy = 0.9664, Validation Loss = 0.2918\n",
            "Epoch 3284/3334\n",
            "Epoch 3284: Training Accuracy = 0.9902, Training Loss = 0.1279, Validation Accuracy = 0.9733, Validation Loss = 0.2211\n",
            "Epoch 3285/3334\n",
            "Epoch 3285: Training Accuracy = 0.9902, Training Loss = 0.1279, Validation Accuracy = 0.9733, Validation Loss = 0.2211\n",
            "Epoch 3286/3334\n",
            "Epoch 3286: Training Accuracy = 0.9902, Training Loss = 0.1279, Validation Accuracy = 0.9733, Validation Loss = 0.2211\n",
            "Epoch 3287/3334\n",
            "Epoch 3287: Training Accuracy = 0.9935, Training Loss = 0.0948, Validation Accuracy = 0.9731, Validation Loss = 0.1910\n",
            "Epoch 3288/3334\n",
            "Epoch 3288: Training Accuracy = 0.9935, Training Loss = 0.0948, Validation Accuracy = 0.9731, Validation Loss = 0.1910\n",
            "Epoch 3289/3334\n",
            "Epoch 3289: Training Accuracy = 0.9935, Training Loss = 0.0948, Validation Accuracy = 0.9731, Validation Loss = 0.1910\n",
            "Epoch 3290/3334\n",
            "Epoch 3290: Training Accuracy = 0.9935, Training Loss = 0.0948, Validation Accuracy = 0.9731, Validation Loss = 0.1910\n",
            "Epoch 3291/3334\n",
            "Epoch 3291: Training Accuracy = 0.9873, Training Loss = 0.1098, Validation Accuracy = 0.9725, Validation Loss = 0.1823\n",
            "Epoch 3292/3334\n",
            "Epoch 3292: Training Accuracy = 0.9873, Training Loss = 0.1098, Validation Accuracy = 0.9725, Validation Loss = 0.1823\n",
            "Epoch 3293/3334\n",
            "Epoch 3293: Training Accuracy = 0.9873, Training Loss = 0.1098, Validation Accuracy = 0.9725, Validation Loss = 0.1823\n",
            "Epoch 3294/3334\n",
            "Epoch 3294: Training Accuracy = 0.9873, Training Loss = 0.1056, Validation Accuracy = 0.9740, Validation Loss = 0.1720\n",
            "Epoch 3295/3334\n",
            "Epoch 3295: Training Accuracy = 0.9873, Training Loss = 0.1056, Validation Accuracy = 0.9740, Validation Loss = 0.1720\n",
            "Epoch 3296/3334\n",
            "Epoch 3296: Training Accuracy = 0.9873, Training Loss = 0.1056, Validation Accuracy = 0.9740, Validation Loss = 0.1720\n",
            "Epoch 3297/3334\n",
            "Epoch 3297: Training Accuracy = 0.9922, Training Loss = 0.0848, Validation Accuracy = 0.9739, Validation Loss = 0.1696\n",
            "Epoch 3298/3334\n",
            "Epoch 3298: Training Accuracy = 0.9922, Training Loss = 0.0848, Validation Accuracy = 0.9739, Validation Loss = 0.1696\n",
            "Epoch 3299/3334\n",
            "Epoch 3299: Training Accuracy = 0.9922, Training Loss = 0.0848, Validation Accuracy = 0.9739, Validation Loss = 0.1696\n",
            "Epoch 3300/3334\n",
            "Epoch 3300: Training Accuracy = 0.9922, Training Loss = 0.0848, Validation Accuracy = 0.9739, Validation Loss = 0.1696\n",
            "Epoch 3301/3334\n",
            "Epoch 3301: Training Accuracy = 0.9912, Training Loss = 0.0859, Validation Accuracy = 0.9740, Validation Loss = 0.1667\n",
            "Epoch 3302/3334\n",
            "Epoch 3302: Training Accuracy = 0.9912, Training Loss = 0.0859, Validation Accuracy = 0.9740, Validation Loss = 0.1667\n",
            "Epoch 3303/3334\n",
            "Epoch 3303: Training Accuracy = 0.9912, Training Loss = 0.0859, Validation Accuracy = 0.9740, Validation Loss = 0.1667\n",
            "Epoch 3304/3334\n",
            "Epoch 3304: Training Accuracy = 0.9873, Training Loss = 0.0993, Validation Accuracy = 0.9740, Validation Loss = 0.1649\n",
            "Epoch 3305/3334\n",
            "Epoch 3305: Training Accuracy = 0.9873, Training Loss = 0.0993, Validation Accuracy = 0.9740, Validation Loss = 0.1649\n",
            "Epoch 3306/3334\n",
            "Epoch 3306: Training Accuracy = 0.9873, Training Loss = 0.0993, Validation Accuracy = 0.9740, Validation Loss = 0.1649\n",
            "Epoch 3307/3334\n",
            "Epoch 3307: Training Accuracy = 0.9819, Training Loss = 0.1221, Validation Accuracy = 0.9739, Validation Loss = 0.1624\n",
            "Epoch 3308/3334\n",
            "Epoch 3308: Training Accuracy = 0.9819, Training Loss = 0.1221, Validation Accuracy = 0.9739, Validation Loss = 0.1624\n",
            "Epoch 3309/3334\n",
            "Epoch 3309: Training Accuracy = 0.9819, Training Loss = 0.1221, Validation Accuracy = 0.9739, Validation Loss = 0.1624\n",
            "Epoch 3310/3334\n",
            "Epoch 3310: Training Accuracy = 0.9819, Training Loss = 0.1221, Validation Accuracy = 0.9739, Validation Loss = 0.1624\n",
            "Epoch 3311/3334\n",
            "Epoch 3311: Training Accuracy = 0.9951, Training Loss = 0.0687, Validation Accuracy = 0.9737, Validation Loss = 0.1623\n",
            "Epoch 3312/3334\n",
            "Epoch 3312: Training Accuracy = 0.9951, Training Loss = 0.0687, Validation Accuracy = 0.9737, Validation Loss = 0.1623\n",
            "Epoch 3313/3334\n",
            "Epoch 3313: Training Accuracy = 0.9951, Training Loss = 0.0687, Validation Accuracy = 0.9737, Validation Loss = 0.1623\n",
            "Epoch 3314/3334\n",
            "Epoch 3314: Training Accuracy = 0.9922, Training Loss = 0.0782, Validation Accuracy = 0.9748, Validation Loss = 0.1598\n",
            "Epoch 3315/3334\n",
            "Epoch 3315: Training Accuracy = 0.9922, Training Loss = 0.0782, Validation Accuracy = 0.9748, Validation Loss = 0.1598\n",
            "Epoch 3316/3334\n",
            "Epoch 3316: Training Accuracy = 0.9922, Training Loss = 0.0782, Validation Accuracy = 0.9748, Validation Loss = 0.1598\n",
            "Epoch 3317/3334\n",
            "Epoch 3317: Training Accuracy = 0.9884, Training Loss = 0.0939, Validation Accuracy = 0.9739, Validation Loss = 0.1578\n",
            "Epoch 3318/3334\n",
            "Epoch 3318: Training Accuracy = 0.9884, Training Loss = 0.0939, Validation Accuracy = 0.9739, Validation Loss = 0.1578\n",
            "Epoch 3319/3334\n",
            "Epoch 3319: Training Accuracy = 0.9884, Training Loss = 0.0939, Validation Accuracy = 0.9739, Validation Loss = 0.1578\n",
            "Epoch 3320/3334\n",
            "Epoch 3320: Training Accuracy = 0.9884, Training Loss = 0.0939, Validation Accuracy = 0.9739, Validation Loss = 0.1578\n",
            "Epoch 3321/3334\n",
            "Epoch 3321: Training Accuracy = 0.9824, Training Loss = 0.1083, Validation Accuracy = 0.9753, Validation Loss = 0.1581\n",
            "Epoch 3322/3334\n",
            "Epoch 3322: Training Accuracy = 0.9824, Training Loss = 0.1083, Validation Accuracy = 0.9753, Validation Loss = 0.1581\n",
            "Epoch 3323/3334\n",
            "Epoch 3323: Training Accuracy = 0.9824, Training Loss = 0.1083, Validation Accuracy = 0.9753, Validation Loss = 0.1581\n",
            "Epoch 3324/3334\n",
            "Epoch 3324: Training Accuracy = 0.9902, Training Loss = 0.0804, Validation Accuracy = 0.9739, Validation Loss = 0.1636\n",
            "Epoch 3325/3334\n",
            "Epoch 3325: Training Accuracy = 0.9902, Training Loss = 0.0804, Validation Accuracy = 0.9739, Validation Loss = 0.1636\n",
            "Epoch 3326/3334\n",
            "Epoch 3326: Training Accuracy = 0.9902, Training Loss = 0.0804, Validation Accuracy = 0.9739, Validation Loss = 0.1636\n",
            "Epoch 3327/3334\n",
            "Epoch 3327: Training Accuracy = 0.9509, Training Loss = 0.3403, Validation Accuracy = 0.1347, Validation Loss = 4.1797\n",
            "Epoch 3328/3334\n",
            "Epoch 3328: Training Accuracy = 0.9509, Training Loss = 0.3403, Validation Accuracy = 0.1347, Validation Loss = 4.1797\n",
            "Epoch 3329/3334\n",
            "Epoch 3329: Training Accuracy = 0.9509, Training Loss = 0.3403, Validation Accuracy = 0.1347, Validation Loss = 4.1797\n",
            "Epoch 3330/3334\n",
            "Epoch 3330: Training Accuracy = 0.9509, Training Loss = 0.3403, Validation Accuracy = 0.1347, Validation Loss = 4.1797\n",
            "Epoch 3331/3334\n",
            "Epoch 3331: Training Accuracy = 0.7725, Training Loss = 1.0218, Validation Accuracy = 0.7456, Validation Loss = 1.1107\n",
            "Epoch 3332/3334\n",
            "Epoch 3332: Training Accuracy = 0.7725, Training Loss = 1.0218, Validation Accuracy = 0.7456, Validation Loss = 1.1107\n",
            "Epoch 3333/3334\n",
            "Epoch 3333: Training Accuracy = 0.7725, Training Loss = 1.0218, Validation Accuracy = 0.7456, Validation Loss = 1.1107\n",
            "Epoch 3334/3334\n",
            "Epoch 3334: Training Accuracy = 0.7725, Training Loss = 1.0218, Validation Accuracy = 0.7456, Validation Loss = 1.1107\n",
            "Stopping early as maximum number of steps has been reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 学習率を小さく"
      ],
      "metadata": {
        "id": "jtWVSqAGZrg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from torch import Tensor\n",
        "from einops import rearrange, repeat\n",
        "from math import ceil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define operations and data functions\n",
        "DIVISION_MODULO_OPERATIONS = {\n",
        "    \"x/y\": lambda x, y, p: (x * y % p, y, x),\n",
        "}\n",
        "\n",
        "ALL_MODULO_OPERATIONS = {\n",
        "    \"x+y\": lambda x, y, _: (x, y, x + y),\n",
        "    \"x-y\": lambda x, y, _: (x, y, x - y),\n",
        "    **DIVISION_MODULO_OPERATIONS,\n",
        "}\n",
        "\n",
        "ALL_OPERATIONS = {\n",
        "    **ALL_MODULO_OPERATIONS,\n",
        "}\n",
        "\n",
        "def operation_mod_p_data(operation: str, p: int, eq_token: int, op_token: int):\n",
        "    x = torch.arange(0, p)\n",
        "    y = torch.arange(0 if operation in DIVISION_MODULO_OPERATIONS else 1, p)\n",
        "    x, y = torch.cartesian_prod(x, y).T\n",
        "\n",
        "    eq = torch.ones_like(x) * eq_token\n",
        "    op = torch.ones_like(x) * op_token\n",
        "\n",
        "    x, y, labels = ALL_OPERATIONS[operation](x, y, p)\n",
        "\n",
        "    inputs = torch.stack([x, op, y, eq], dim=1)\n",
        "\n",
        "    return inputs, labels\n",
        "\n",
        "def get_data(operation: str, prime: int, training_fraction: float, batch_size: int):\n",
        "    inputs, labels = operation_mod_p_data(operation, prime, prime, prime+1)\n",
        "    dataset = TensorDataset(inputs, labels)\n",
        "\n",
        "    train_size = int(training_fraction * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    batch_size = min(batch_size, ceil(len(dataset) / 2))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "# Define the model\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, dim_model: int, n_heads: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn = nn.MultiheadAttention(dim_model, n_heads)\n",
        "        self.self_attn_norm = nn.LayerNorm(dim_model)\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(dim_model, dim_model * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim_model * 4, dim_model)\n",
        "        )\n",
        "        self.ffn_norm = nn.LayerNorm(dim_model)\n",
        "\n",
        "    def forward(self, x: Tensor):\n",
        "        attn_mask = torch.full(\n",
        "            (len(x), len(x)), -float(\"Inf\"), device=x.device, dtype=x.dtype\n",
        "        )\n",
        "        attn_mask = torch.triu(attn_mask, diagonal=1)\n",
        "\n",
        "        a1, _ = self.self_attn(x, x, x, attn_mask=attn_mask)\n",
        "        a1 = self.self_attn_norm(x + a1)\n",
        "        a2 = self.ffn(a1)\n",
        "        a2 = self.ffn_norm(a1 + a2)\n",
        "\n",
        "        return a2\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, num_layers: int, dim_model: int, num_heads: int, num_tokens: int, seq_len: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.token_embeddings = nn.Embedding(num_tokens, dim_model)\n",
        "        self.position_embeddings = nn.Embedding(seq_len, dim_model)\n",
        "        self.model = nn.Sequential(\n",
        "            *[DecoderBlock(dim_model, num_heads) for _ in range(num_layers)],\n",
        "            nn.LayerNorm(dim_model),\n",
        "            nn.Linear(dim_model, num_tokens)\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs: Tensor):\n",
        "        batch_size, context_len = inputs.shape\n",
        "\n",
        "        token_embedding = self.token_embeddings(inputs)\n",
        "\n",
        "        positions = repeat(torch.arange(context_len, device=inputs.device), \"p -> b p\", b=batch_size)\n",
        "        position_embedding = self.position_embeddings(positions)\n",
        "\n",
        "        embedding = token_embedding + position_embedding\n",
        "\n",
        "        embedding = rearrange(embedding, 'b s d -> s b d')\n",
        "\n",
        "        return self.model(embedding)\n",
        "\n",
        "# Training and evaluation functions\n",
        "def evaluate(model, data_loader, device, metrics, step=None):\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    correct = 0\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            inputs, labels = batch\n",
        "            output = model(inputs)[-1, :, :]\n",
        "            correct += (torch.argmax(output, dim=1) == labels).sum().item()\n",
        "            total_loss += criterion(output, labels).item() * len(labels)\n",
        "\n",
        "    accuracy = correct / len(data_loader.dataset)\n",
        "    loss = total_loss / len(data_loader.dataset)\n",
        "\n",
        "    if step is not None:\n",
        "        metrics['validation/accuracy'].append((step, accuracy))\n",
        "        metrics['validation/loss'].append((step, loss))\n",
        "    else:\n",
        "        metrics['validation/accuracy'].append(accuracy)\n",
        "        metrics['validation/loss'].append(loss)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def train(model, train_loader, optimizer, scheduler, val_loader, device, metrics, step, record_frequency, config):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    pbar = tqdm(total=len(train_loader.dataset), desc=\"Training Progress\", unit='sample')\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs, labels = batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)[-1, :, :]\n",
        "        loss = criterion(output, labels)\n",
        "        acc = (torch.argmax(output, dim=1) == labels).sum().item() / len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Update metrics at the end of each batch\n",
        "        if step % record_frequency == 0:\n",
        "            metrics['training/accuracy'].append((step, acc))\n",
        "            metrics['training/loss'].append((step, loss.item()))\n",
        "\n",
        "        pbar.update(inputs.size(0))\n",
        "\n",
        "        # Evaluate validation set every `record_frequency` steps\n",
        "        if step % record_frequency == 0:\n",
        "            metrics = evaluate(model, val_loader, device, metrics, step)\n",
        "\n",
        "        step += 1\n",
        "\n",
        "        # Check if max number of steps is reached\n",
        "        if step >= config['num_steps']:\n",
        "            break\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    return metrics, step\n",
        "\n",
        "# Execute the training and evaluation\n",
        "# Configuration\n",
        "config = {\n",
        "    'operation': 'x/y',\n",
        "    'training_fraction': 0.3,\n",
        "    'prime': 97,\n",
        "    'num_layers': 2,\n",
        "    'dim_model': 128,\n",
        "    'num_heads': 4,\n",
        "    'batch_size': 512,\n",
        "    'learning_rate': 0.0005,\n",
        "    'weight_decay': 1,\n",
        "    'num_steps': 15000,  # int(1e6)\n",
        "    'max_epochs': int(1e8),\n",
        "    'record_frequency': 10,  # Frequency of recording metrics\n",
        "    'show_progress_bar': False,\n",
        "    'device': 'cpu',\n",
        "}\n",
        "\n",
        "# Training and evaluation functions\n",
        "def train(model, train_loader, optimizer, scheduler, val_loader, device, metrics, step, record_frequency, config):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Conditional progress bar based on config\n",
        "    pbar = tqdm(total=len(train_loader.dataset), desc=\"Training Progress\", unit='sample') if config.get('show_progress_bar', True) else None\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs, labels = batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)[-1, :, :]\n",
        "        loss = criterion(output, labels)\n",
        "        acc = (torch.argmax(output, dim=1) == labels).sum().item() / len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Update metrics at the end of each batch\n",
        "        if step % record_frequency == 0:\n",
        "            metrics['training/accuracy'].append((step, acc))\n",
        "            metrics['training/loss'].append((step, loss.item()))\n",
        "\n",
        "        if pbar:\n",
        "            pbar.update(inputs.size(0))\n",
        "\n",
        "        # Evaluate validation set every `record_frequency` steps\n",
        "        if step % record_frequency == 0:\n",
        "            metrics = evaluate(model, val_loader, device, metrics, step)\n",
        "\n",
        "        step += 1\n",
        "\n",
        "        # Check if max number of steps is reached\n",
        "        if step >= config['num_steps']:\n",
        "            break\n",
        "\n",
        "    if pbar:\n",
        "        pbar.close()\n",
        "\n",
        "    return metrics, step\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "train_loader, val_loader = get_data(\n",
        "    config['operation'],\n",
        "    config['prime'],\n",
        "    config['training_fraction'],\n",
        "    config['batch_size']\n",
        ")\n",
        "model = Transformer(\n",
        "    num_layers=config['num_layers'],\n",
        "    dim_model=config['dim_model'],\n",
        "    num_heads=config['num_heads'],\n",
        "    num_tokens=config['prime'] + 2,\n",
        "    seq_len=5\n",
        ").to(device)\n",
        "optimizer = optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=config['learning_rate'],\n",
        "    betas=(0.9, 0.98),\n",
        "    weight_decay=config['weight_decay']\n",
        ")\n",
        "scheduler = optim.lr_scheduler.LinearLR(\n",
        "    optimizer, start_factor=0.1, total_iters=9\n",
        ")\n",
        "\n",
        "num_epochs = min(config['max_epochs'], ceil(config['num_steps'] / len(train_loader)))\n",
        "\n",
        "metrics = {\n",
        "    'training/accuracy': [],\n",
        "    'training/loss': [],\n",
        "    'validation/accuracy': [],\n",
        "    'validation/loss': []\n",
        "}\n",
        "\n",
        "step = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "    metrics, step = train(model, train_loader, optimizer, scheduler, val_loader, device, metrics, step, config['record_frequency'], config)\n",
        "\n",
        "    # Print metrics for the current epoch in a single line\n",
        "    train_acc = metrics['training/accuracy'][-1][1]\n",
        "    train_loss = metrics['training/loss'][-1][1]\n",
        "    val_acc = metrics['validation/accuracy'][-1][1] if len(metrics['validation/accuracy']) > 0 else 0\n",
        "    val_loss = metrics['validation/loss'][-1][1] if len(metrics['validation/loss']) > 0 else 0\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}: Training Accuracy = {train_acc:.4f}, Training Loss = {train_loss:.4f}, Validation Accuracy = {val_acc:.4f}, Validation Loss = {val_loss:.4f}\")\n",
        "\n",
        "    # Check if max number of steps is reached\n",
        "    if step >= config['num_steps']:\n",
        "        print(\"Stopping early as maximum number of steps has been reached.\")\n",
        "        break\n",
        "\n",
        "# Ensure the final step is evaluated for training metrics\n",
        "metrics['training/accuracy'].append((step, train_acc))\n",
        "metrics['training/loss'].append((step, train_loss))\n",
        "metrics = evaluate(model, val_loader, device, metrics, step)\n",
        "\n",
        "# Plot metrics\n",
        "training_steps, training_accuracy = zip(*metrics['training/accuracy'])\n",
        "training_steps, training_loss = zip(*metrics['training/loss'])\n",
        "val_steps, validation_accuracy = zip(*metrics['validation/accuracy'])\n",
        "val_steps, validation_loss = zip(*metrics['validation/loss'])\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.semilogx(training_steps, [acc * 100 for acc in training_accuracy], color='red', label='Train')\n",
        "plt.semilogx(val_steps, [acc * 100 for acc in validation_accuracy], color='green', label='Val')\n",
        "plt.xlabel('Optimization Steps')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.title(f'Modular Division (training on {int(config[\"training_fraction\"] * 100)}% of data)')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.semilogx(training_steps, training_loss, color='red', label='Train')\n",
        "plt.semilogx(val_steps, validation_loss, color='green', label='Val')\n",
        "plt.xlabel('Optimization Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title(f'Modular Division (training on {int(config[\"training_fraction\"] * 100)}% of data)')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z3_TisTFZXzv",
        "outputId": "212be387-3e45-4072-bbdc-48d95c81e2c5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "Epoch 1: Training Accuracy = 0.0098, Training Loss = 4.8054, Validation Accuracy = 0.0096, Validation Loss = 4.7855\n",
            "Epoch 2/2500\n",
            "Epoch 2: Training Accuracy = 0.0215, Training Loss = 4.6142, Validation Accuracy = 0.0170, Validation Loss = 4.6339\n",
            "Epoch 3/2500\n",
            "Epoch 3: Training Accuracy = 0.0215, Training Loss = 4.6142, Validation Accuracy = 0.0170, Validation Loss = 4.6339\n",
            "Epoch 4/2500\n",
            "Epoch 4: Training Accuracy = 0.0410, Training Loss = 4.5575, Validation Accuracy = 0.0178, Validation Loss = 4.6135\n",
            "Epoch 5/2500\n",
            "Epoch 5: Training Accuracy = 0.0410, Training Loss = 4.5575, Validation Accuracy = 0.0178, Validation Loss = 4.6135\n",
            "Epoch 6/2500\n",
            "Epoch 6: Training Accuracy = 0.0234, Training Loss = 4.4873, Validation Accuracy = 0.0155, Validation Loss = 4.6020\n",
            "Epoch 7/2500\n",
            "Epoch 7: Training Accuracy = 0.0352, Training Loss = 4.4445, Validation Accuracy = 0.0140, Validation Loss = 4.6133\n",
            "Epoch 8/2500\n",
            "Epoch 8: Training Accuracy = 0.0352, Training Loss = 4.4445, Validation Accuracy = 0.0140, Validation Loss = 4.6133\n",
            "Epoch 9/2500\n",
            "Epoch 9: Training Accuracy = 0.0508, Training Loss = 4.4093, Validation Accuracy = 0.0134, Validation Loss = 4.6409\n",
            "Epoch 10/2500\n",
            "Epoch 10: Training Accuracy = 0.0508, Training Loss = 4.4093, Validation Accuracy = 0.0134, Validation Loss = 4.6409\n",
            "Epoch 11/2500\n",
            "Epoch 11: Training Accuracy = 0.0371, Training Loss = 4.3262, Validation Accuracy = 0.0132, Validation Loss = 4.7151\n",
            "Epoch 12/2500\n",
            "Epoch 12: Training Accuracy = 0.0586, Training Loss = 4.2366, Validation Accuracy = 0.0132, Validation Loss = 4.8546\n",
            "Epoch 13/2500\n",
            "Epoch 13: Training Accuracy = 0.0586, Training Loss = 4.2366, Validation Accuracy = 0.0132, Validation Loss = 4.8546\n",
            "Epoch 14/2500\n",
            "Epoch 14: Training Accuracy = 0.0781, Training Loss = 4.1316, Validation Accuracy = 0.0115, Validation Loss = 4.9672\n",
            "Epoch 15/2500\n",
            "Epoch 15: Training Accuracy = 0.0781, Training Loss = 4.1316, Validation Accuracy = 0.0115, Validation Loss = 4.9672\n",
            "Epoch 16/2500\n",
            "Epoch 16: Training Accuracy = 0.0820, Training Loss = 4.0374, Validation Accuracy = 0.0115, Validation Loss = 5.0270\n",
            "Epoch 17/2500\n",
            "Epoch 17: Training Accuracy = 0.0840, Training Loss = 3.9697, Validation Accuracy = 0.0108, Validation Loss = 5.0666\n",
            "Epoch 18/2500\n",
            "Epoch 18: Training Accuracy = 0.0840, Training Loss = 3.9697, Validation Accuracy = 0.0108, Validation Loss = 5.0666\n",
            "Epoch 19/2500\n",
            "Epoch 19: Training Accuracy = 0.1230, Training Loss = 3.8345, Validation Accuracy = 0.0106, Validation Loss = 5.1050\n",
            "Epoch 20/2500\n",
            "Epoch 20: Training Accuracy = 0.1230, Training Loss = 3.8345, Validation Accuracy = 0.0106, Validation Loss = 5.1050\n",
            "Epoch 21/2500\n",
            "Epoch 21: Training Accuracy = 0.1367, Training Loss = 3.7978, Validation Accuracy = 0.0106, Validation Loss = 5.1469\n",
            "Epoch 22/2500\n",
            "Epoch 22: Training Accuracy = 0.1426, Training Loss = 3.7741, Validation Accuracy = 0.0103, Validation Loss = 5.1913\n",
            "Epoch 23/2500\n",
            "Epoch 23: Training Accuracy = 0.1426, Training Loss = 3.7741, Validation Accuracy = 0.0103, Validation Loss = 5.1913\n",
            "Epoch 24/2500\n",
            "Epoch 24: Training Accuracy = 0.1758, Training Loss = 3.6506, Validation Accuracy = 0.0103, Validation Loss = 5.2249\n",
            "Epoch 25/2500\n",
            "Epoch 25: Training Accuracy = 0.1758, Training Loss = 3.6506, Validation Accuracy = 0.0103, Validation Loss = 5.2249\n",
            "Epoch 26/2500\n",
            "Epoch 26: Training Accuracy = 0.2031, Training Loss = 3.5912, Validation Accuracy = 0.0100, Validation Loss = 5.2648\n",
            "Epoch 27/2500\n",
            "Epoch 27: Training Accuracy = 0.1855, Training Loss = 3.5229, Validation Accuracy = 0.0103, Validation Loss = 5.2971\n",
            "Epoch 28/2500\n",
            "Epoch 28: Training Accuracy = 0.1855, Training Loss = 3.5229, Validation Accuracy = 0.0103, Validation Loss = 5.2971\n",
            "Epoch 29/2500\n",
            "Epoch 29: Training Accuracy = 0.1992, Training Loss = 3.4523, Validation Accuracy = 0.0106, Validation Loss = 5.3374\n",
            "Epoch 30/2500\n",
            "Epoch 30: Training Accuracy = 0.1992, Training Loss = 3.4523, Validation Accuracy = 0.0106, Validation Loss = 5.3374\n",
            "Epoch 31/2500\n",
            "Epoch 31: Training Accuracy = 0.2559, Training Loss = 3.3879, Validation Accuracy = 0.0102, Validation Loss = 5.3746\n",
            "Epoch 32/2500\n",
            "Epoch 32: Training Accuracy = 0.2676, Training Loss = 3.2733, Validation Accuracy = 0.0100, Validation Loss = 5.4147\n",
            "Epoch 33/2500\n",
            "Epoch 33: Training Accuracy = 0.2676, Training Loss = 3.2733, Validation Accuracy = 0.0100, Validation Loss = 5.4147\n",
            "Epoch 34/2500\n",
            "Epoch 34: Training Accuracy = 0.3008, Training Loss = 3.1653, Validation Accuracy = 0.0102, Validation Loss = 5.4443\n",
            "Epoch 35/2500\n",
            "Epoch 35: Training Accuracy = 0.3008, Training Loss = 3.1653, Validation Accuracy = 0.0102, Validation Loss = 5.4443\n",
            "Epoch 36/2500\n",
            "Epoch 36: Training Accuracy = 0.3223, Training Loss = 3.0847, Validation Accuracy = 0.0102, Validation Loss = 5.4872\n",
            "Epoch 37/2500\n",
            "Epoch 37: Training Accuracy = 0.3105, Training Loss = 3.1088, Validation Accuracy = 0.0102, Validation Loss = 5.5202\n",
            "Epoch 38/2500\n",
            "Epoch 38: Training Accuracy = 0.3105, Training Loss = 3.1088, Validation Accuracy = 0.0102, Validation Loss = 5.5202\n",
            "Epoch 39/2500\n",
            "Epoch 39: Training Accuracy = 0.3652, Training Loss = 3.0057, Validation Accuracy = 0.0105, Validation Loss = 5.5521\n",
            "Epoch 40/2500\n",
            "Epoch 40: Training Accuracy = 0.3652, Training Loss = 3.0057, Validation Accuracy = 0.0105, Validation Loss = 5.5521\n",
            "Epoch 41/2500\n",
            "Epoch 41: Training Accuracy = 0.4141, Training Loss = 2.9057, Validation Accuracy = 0.0103, Validation Loss = 5.5851\n",
            "Epoch 42/2500\n",
            "Epoch 42: Training Accuracy = 0.4434, Training Loss = 2.8362, Validation Accuracy = 0.0102, Validation Loss = 5.6291\n",
            "Epoch 43/2500\n",
            "Epoch 43: Training Accuracy = 0.4434, Training Loss = 2.8362, Validation Accuracy = 0.0102, Validation Loss = 5.6291\n",
            "Epoch 44/2500\n",
            "Epoch 44: Training Accuracy = 0.4375, Training Loss = 2.7645, Validation Accuracy = 0.0102, Validation Loss = 5.6715\n",
            "Epoch 45/2500\n",
            "Epoch 45: Training Accuracy = 0.4375, Training Loss = 2.7645, Validation Accuracy = 0.0102, Validation Loss = 5.6715\n",
            "Epoch 46/2500\n",
            "Epoch 46: Training Accuracy = 0.4609, Training Loss = 2.6582, Validation Accuracy = 0.0103, Validation Loss = 5.7108\n",
            "Epoch 47/2500\n",
            "Epoch 47: Training Accuracy = 0.4863, Training Loss = 2.6090, Validation Accuracy = 0.0103, Validation Loss = 5.7492\n",
            "Epoch 48/2500\n",
            "Epoch 48: Training Accuracy = 0.4863, Training Loss = 2.6090, Validation Accuracy = 0.0103, Validation Loss = 5.7492\n",
            "Epoch 49/2500\n",
            "Epoch 49: Training Accuracy = 0.4941, Training Loss = 2.5226, Validation Accuracy = 0.0103, Validation Loss = 5.7922\n",
            "Epoch 50/2500\n",
            "Epoch 50: Training Accuracy = 0.4941, Training Loss = 2.5226, Validation Accuracy = 0.0103, Validation Loss = 5.7922\n",
            "Epoch 51/2500\n",
            "Epoch 51: Training Accuracy = 0.5332, Training Loss = 2.4557, Validation Accuracy = 0.0103, Validation Loss = 5.8287\n",
            "Epoch 52/2500\n",
            "Epoch 52: Training Accuracy = 0.5059, Training Loss = 2.4372, Validation Accuracy = 0.0105, Validation Loss = 5.8777\n",
            "Epoch 53/2500\n",
            "Epoch 53: Training Accuracy = 0.5059, Training Loss = 2.4372, Validation Accuracy = 0.0105, Validation Loss = 5.8777\n",
            "Epoch 54/2500\n",
            "Epoch 54: Training Accuracy = 0.5547, Training Loss = 2.2939, Validation Accuracy = 0.0108, Validation Loss = 5.9191\n",
            "Epoch 55/2500\n",
            "Epoch 55: Training Accuracy = 0.5547, Training Loss = 2.2939, Validation Accuracy = 0.0108, Validation Loss = 5.9191\n",
            "Epoch 56/2500\n",
            "Epoch 56: Training Accuracy = 0.5938, Training Loss = 2.2253, Validation Accuracy = 0.0108, Validation Loss = 5.9615\n",
            "Epoch 57/2500\n",
            "Epoch 57: Training Accuracy = 0.6270, Training Loss = 2.1788, Validation Accuracy = 0.0108, Validation Loss = 6.0111\n",
            "Epoch 58/2500\n",
            "Epoch 58: Training Accuracy = 0.6270, Training Loss = 2.1788, Validation Accuracy = 0.0108, Validation Loss = 6.0111\n",
            "Epoch 59/2500\n",
            "Epoch 59: Training Accuracy = 0.6504, Training Loss = 2.0286, Validation Accuracy = 0.0108, Validation Loss = 6.0508\n",
            "Epoch 60/2500\n",
            "Epoch 60: Training Accuracy = 0.6504, Training Loss = 2.0286, Validation Accuracy = 0.0108, Validation Loss = 6.0508\n",
            "Epoch 61/2500\n",
            "Epoch 61: Training Accuracy = 0.6816, Training Loss = 1.9977, Validation Accuracy = 0.0108, Validation Loss = 6.1009\n",
            "Epoch 62/2500\n",
            "Epoch 62: Training Accuracy = 0.7031, Training Loss = 1.9033, Validation Accuracy = 0.0106, Validation Loss = 6.1367\n",
            "Epoch 63/2500\n",
            "Epoch 63: Training Accuracy = 0.7031, Training Loss = 1.9033, Validation Accuracy = 0.0106, Validation Loss = 6.1367\n",
            "Epoch 64/2500\n",
            "Epoch 64: Training Accuracy = 0.6973, Training Loss = 1.9004, Validation Accuracy = 0.0108, Validation Loss = 6.1782\n",
            "Epoch 65/2500\n",
            "Epoch 65: Training Accuracy = 0.6973, Training Loss = 1.9004, Validation Accuracy = 0.0108, Validation Loss = 6.1782\n",
            "Epoch 66/2500\n",
            "Epoch 66: Training Accuracy = 0.7422, Training Loss = 1.7182, Validation Accuracy = 0.0114, Validation Loss = 6.2283\n",
            "Epoch 67/2500\n",
            "Epoch 67: Training Accuracy = 0.7344, Training Loss = 1.7367, Validation Accuracy = 0.0111, Validation Loss = 6.2751\n",
            "Epoch 68/2500\n",
            "Epoch 68: Training Accuracy = 0.7344, Training Loss = 1.7367, Validation Accuracy = 0.0111, Validation Loss = 6.2751\n",
            "Epoch 69/2500\n",
            "Epoch 69: Training Accuracy = 0.7891, Training Loss = 1.6013, Validation Accuracy = 0.0109, Validation Loss = 6.3160\n",
            "Epoch 70/2500\n",
            "Epoch 70: Training Accuracy = 0.7891, Training Loss = 1.6013, Validation Accuracy = 0.0109, Validation Loss = 6.3160\n",
            "Epoch 71/2500\n",
            "Epoch 71: Training Accuracy = 0.8066, Training Loss = 1.5920, Validation Accuracy = 0.0111, Validation Loss = 6.3728\n",
            "Epoch 72/2500\n",
            "Epoch 72: Training Accuracy = 0.8066, Training Loss = 1.5451, Validation Accuracy = 0.0106, Validation Loss = 6.4063\n",
            "Epoch 73/2500\n",
            "Epoch 73: Training Accuracy = 0.8066, Training Loss = 1.5451, Validation Accuracy = 0.0106, Validation Loss = 6.4063\n",
            "Epoch 74/2500\n",
            "Epoch 74: Training Accuracy = 0.8262, Training Loss = 1.4352, Validation Accuracy = 0.0111, Validation Loss = 6.4451\n",
            "Epoch 75/2500\n",
            "Epoch 75: Training Accuracy = 0.8262, Training Loss = 1.4352, Validation Accuracy = 0.0111, Validation Loss = 6.4451\n",
            "Epoch 76/2500\n",
            "Epoch 76: Training Accuracy = 0.8516, Training Loss = 1.3469, Validation Accuracy = 0.0111, Validation Loss = 6.5027\n",
            "Epoch 77/2500\n",
            "Epoch 77: Training Accuracy = 0.8535, Training Loss = 1.3424, Validation Accuracy = 0.0109, Validation Loss = 6.5575\n",
            "Epoch 78/2500\n",
            "Epoch 78: Training Accuracy = 0.8535, Training Loss = 1.3424, Validation Accuracy = 0.0109, Validation Loss = 6.5575\n",
            "Epoch 79/2500\n",
            "Epoch 79: Training Accuracy = 0.8730, Training Loss = 1.2359, Validation Accuracy = 0.0112, Validation Loss = 6.5966\n",
            "Epoch 80/2500\n",
            "Epoch 80: Training Accuracy = 0.8730, Training Loss = 1.2359, Validation Accuracy = 0.0112, Validation Loss = 6.5966\n",
            "Epoch 81/2500\n",
            "Epoch 81: Training Accuracy = 0.9121, Training Loss = 1.1443, Validation Accuracy = 0.0111, Validation Loss = 6.6506\n",
            "Epoch 82/2500\n",
            "Epoch 82: Training Accuracy = 0.8789, Training Loss = 1.1803, Validation Accuracy = 0.0109, Validation Loss = 6.6819\n",
            "Epoch 83/2500\n",
            "Epoch 83: Training Accuracy = 0.8789, Training Loss = 1.1803, Validation Accuracy = 0.0109, Validation Loss = 6.6819\n",
            "Epoch 84/2500\n",
            "Epoch 84: Training Accuracy = 0.9355, Training Loss = 1.0514, Validation Accuracy = 0.0109, Validation Loss = 6.7381\n",
            "Epoch 85/2500\n",
            "Epoch 85: Training Accuracy = 0.9355, Training Loss = 1.0514, Validation Accuracy = 0.0109, Validation Loss = 6.7381\n",
            "Epoch 86/2500\n",
            "Epoch 86: Training Accuracy = 0.9375, Training Loss = 1.0142, Validation Accuracy = 0.0109, Validation Loss = 6.7862\n",
            "Epoch 87/2500\n",
            "Epoch 87: Training Accuracy = 0.9336, Training Loss = 1.0024, Validation Accuracy = 0.0111, Validation Loss = 6.8329\n",
            "Epoch 88/2500\n",
            "Epoch 88: Training Accuracy = 0.9336, Training Loss = 1.0024, Validation Accuracy = 0.0111, Validation Loss = 6.8329\n",
            "Epoch 89/2500\n",
            "Epoch 89: Training Accuracy = 0.9355, Training Loss = 0.9791, Validation Accuracy = 0.0108, Validation Loss = 6.8743\n",
            "Epoch 90/2500\n",
            "Epoch 90: Training Accuracy = 0.9355, Training Loss = 0.9791, Validation Accuracy = 0.0108, Validation Loss = 6.8743\n",
            "Epoch 91/2500\n",
            "Epoch 91: Training Accuracy = 0.9609, Training Loss = 0.8494, Validation Accuracy = 0.0114, Validation Loss = 6.9299\n",
            "Epoch 92/2500\n",
            "Epoch 92: Training Accuracy = 0.9590, Training Loss = 0.8793, Validation Accuracy = 0.0112, Validation Loss = 6.9680\n",
            "Epoch 93/2500\n",
            "Epoch 93: Training Accuracy = 0.9590, Training Loss = 0.8793, Validation Accuracy = 0.0112, Validation Loss = 6.9680\n",
            "Epoch 94/2500\n",
            "Epoch 94: Training Accuracy = 0.9688, Training Loss = 0.8208, Validation Accuracy = 0.0111, Validation Loss = 7.0187\n",
            "Epoch 95/2500\n",
            "Epoch 95: Training Accuracy = 0.9688, Training Loss = 0.8208, Validation Accuracy = 0.0111, Validation Loss = 7.0187\n",
            "Epoch 96/2500\n",
            "Epoch 96: Training Accuracy = 0.9805, Training Loss = 0.7019, Validation Accuracy = 0.0108, Validation Loss = 7.0697\n",
            "Epoch 97/2500\n",
            "Epoch 97: Training Accuracy = 0.9707, Training Loss = 0.7470, Validation Accuracy = 0.0105, Validation Loss = 7.1040\n",
            "Epoch 98/2500\n",
            "Epoch 98: Training Accuracy = 0.9707, Training Loss = 0.7470, Validation Accuracy = 0.0105, Validation Loss = 7.1040\n",
            "Epoch 99/2500\n",
            "Epoch 99: Training Accuracy = 0.9824, Training Loss = 0.6714, Validation Accuracy = 0.0109, Validation Loss = 7.1517\n",
            "Epoch 100/2500\n",
            "Epoch 100: Training Accuracy = 0.9824, Training Loss = 0.6714, Validation Accuracy = 0.0109, Validation Loss = 7.1517\n",
            "Epoch 101/2500\n",
            "Epoch 101: Training Accuracy = 0.9922, Training Loss = 0.5925, Validation Accuracy = 0.0112, Validation Loss = 7.2032\n",
            "Epoch 102/2500\n",
            "Epoch 102: Training Accuracy = 0.9844, Training Loss = 0.6325, Validation Accuracy = 0.0106, Validation Loss = 7.2344\n",
            "Epoch 103/2500\n",
            "Epoch 103: Training Accuracy = 0.9844, Training Loss = 0.6325, Validation Accuracy = 0.0106, Validation Loss = 7.2344\n",
            "Epoch 104/2500\n",
            "Epoch 104: Training Accuracy = 0.9902, Training Loss = 0.5688, Validation Accuracy = 0.0109, Validation Loss = 7.2776\n",
            "Epoch 105/2500\n",
            "Epoch 105: Training Accuracy = 0.9902, Training Loss = 0.5688, Validation Accuracy = 0.0109, Validation Loss = 7.2776\n",
            "Epoch 106/2500\n",
            "Epoch 106: Training Accuracy = 0.9824, Training Loss = 0.5337, Validation Accuracy = 0.0111, Validation Loss = 7.3309\n",
            "Epoch 107/2500\n",
            "Epoch 107: Training Accuracy = 0.9824, Training Loss = 0.5366, Validation Accuracy = 0.0115, Validation Loss = 7.3982\n",
            "Epoch 108/2500\n",
            "Epoch 108: Training Accuracy = 0.9824, Training Loss = 0.5366, Validation Accuracy = 0.0115, Validation Loss = 7.3982\n",
            "Epoch 109/2500\n",
            "Epoch 109: Training Accuracy = 0.9824, Training Loss = 0.4995, Validation Accuracy = 0.0111, Validation Loss = 7.4117\n",
            "Epoch 110/2500\n",
            "Epoch 110: Training Accuracy = 0.9824, Training Loss = 0.4995, Validation Accuracy = 0.0111, Validation Loss = 7.4117\n",
            "Epoch 111/2500\n",
            "Epoch 111: Training Accuracy = 0.9941, Training Loss = 0.4464, Validation Accuracy = 0.0112, Validation Loss = 7.4500\n",
            "Epoch 112/2500\n",
            "Epoch 112: Training Accuracy = 0.9883, Training Loss = 0.4586, Validation Accuracy = 0.0103, Validation Loss = 7.4991\n",
            "Epoch 113/2500\n",
            "Epoch 113: Training Accuracy = 0.9883, Training Loss = 0.4586, Validation Accuracy = 0.0103, Validation Loss = 7.4991\n",
            "Epoch 114/2500\n",
            "Epoch 114: Training Accuracy = 0.9902, Training Loss = 0.3983, Validation Accuracy = 0.0112, Validation Loss = 7.5394\n",
            "Epoch 115/2500\n",
            "Epoch 115: Training Accuracy = 0.9902, Training Loss = 0.3983, Validation Accuracy = 0.0112, Validation Loss = 7.5394\n",
            "Epoch 116/2500\n",
            "Epoch 116: Training Accuracy = 0.9941, Training Loss = 0.3608, Validation Accuracy = 0.0108, Validation Loss = 7.5731\n",
            "Epoch 117/2500\n",
            "Epoch 117: Training Accuracy = 0.9941, Training Loss = 0.3924, Validation Accuracy = 0.0108, Validation Loss = 7.6398\n",
            "Epoch 118/2500\n",
            "Epoch 118: Training Accuracy = 0.9941, Training Loss = 0.3924, Validation Accuracy = 0.0108, Validation Loss = 7.6398\n",
            "Epoch 119/2500\n",
            "Epoch 119: Training Accuracy = 0.9863, Training Loss = 0.3753, Validation Accuracy = 0.0114, Validation Loss = 7.6525\n",
            "Epoch 120/2500\n",
            "Epoch 120: Training Accuracy = 0.9863, Training Loss = 0.3753, Validation Accuracy = 0.0114, Validation Loss = 7.6525\n",
            "Epoch 121/2500\n",
            "Epoch 121: Training Accuracy = 0.9922, Training Loss = 0.3192, Validation Accuracy = 0.0114, Validation Loss = 7.7060\n",
            "Epoch 122/2500\n",
            "Epoch 122: Training Accuracy = 0.9922, Training Loss = 0.3346, Validation Accuracy = 0.0106, Validation Loss = 7.7276\n",
            "Epoch 123/2500\n",
            "Epoch 123: Training Accuracy = 0.9922, Training Loss = 0.3346, Validation Accuracy = 0.0106, Validation Loss = 7.7276\n",
            "Epoch 124/2500\n",
            "Epoch 124: Training Accuracy = 0.9883, Training Loss = 0.3078, Validation Accuracy = 0.0114, Validation Loss = 7.7802\n",
            "Epoch 125/2500\n",
            "Epoch 125: Training Accuracy = 0.9883, Training Loss = 0.3078, Validation Accuracy = 0.0114, Validation Loss = 7.7802\n",
            "Epoch 126/2500\n",
            "Epoch 126: Training Accuracy = 0.9844, Training Loss = 0.2908, Validation Accuracy = 0.0114, Validation Loss = 7.8201\n",
            "Epoch 127/2500\n",
            "Epoch 127: Training Accuracy = 0.9902, Training Loss = 0.2696, Validation Accuracy = 0.0112, Validation Loss = 7.8400\n",
            "Epoch 128/2500\n",
            "Epoch 128: Training Accuracy = 0.9902, Training Loss = 0.2696, Validation Accuracy = 0.0112, Validation Loss = 7.8400\n",
            "Epoch 129/2500\n",
            "Epoch 129: Training Accuracy = 0.9883, Training Loss = 0.2762, Validation Accuracy = 0.0112, Validation Loss = 7.8586\n",
            "Epoch 130/2500\n",
            "Epoch 130: Training Accuracy = 0.9883, Training Loss = 0.2762, Validation Accuracy = 0.0112, Validation Loss = 7.8586\n",
            "Epoch 131/2500\n",
            "Epoch 131: Training Accuracy = 0.9941, Training Loss = 0.2404, Validation Accuracy = 0.0112, Validation Loss = 7.9175\n",
            "Epoch 132/2500\n",
            "Epoch 132: Training Accuracy = 0.9844, Training Loss = 0.2701, Validation Accuracy = 0.0111, Validation Loss = 7.9559\n",
            "Epoch 133/2500\n",
            "Epoch 133: Training Accuracy = 0.9844, Training Loss = 0.2701, Validation Accuracy = 0.0111, Validation Loss = 7.9559\n",
            "Epoch 134/2500\n",
            "Epoch 134: Training Accuracy = 0.9902, Training Loss = 0.2195, Validation Accuracy = 0.0114, Validation Loss = 8.0043\n",
            "Epoch 135/2500\n",
            "Epoch 135: Training Accuracy = 0.9902, Training Loss = 0.2195, Validation Accuracy = 0.0114, Validation Loss = 8.0043\n",
            "Epoch 136/2500\n",
            "Epoch 136: Training Accuracy = 0.9941, Training Loss = 0.1913, Validation Accuracy = 0.0115, Validation Loss = 8.0024\n",
            "Epoch 137/2500\n",
            "Epoch 137: Training Accuracy = 0.9883, Training Loss = 0.2129, Validation Accuracy = 0.0112, Validation Loss = 8.0508\n",
            "Epoch 138/2500\n",
            "Epoch 138: Training Accuracy = 0.9883, Training Loss = 0.2129, Validation Accuracy = 0.0112, Validation Loss = 8.0508\n",
            "Epoch 139/2500\n",
            "Epoch 139: Training Accuracy = 0.9883, Training Loss = 0.2074, Validation Accuracy = 0.0108, Validation Loss = 8.0917\n",
            "Epoch 140/2500\n",
            "Epoch 140: Training Accuracy = 0.9883, Training Loss = 0.2074, Validation Accuracy = 0.0108, Validation Loss = 8.0917\n",
            "Epoch 141/2500\n",
            "Epoch 141: Training Accuracy = 0.9902, Training Loss = 0.1868, Validation Accuracy = 0.0121, Validation Loss = 8.1195\n",
            "Epoch 142/2500\n",
            "Epoch 142: Training Accuracy = 0.9922, Training Loss = 0.1787, Validation Accuracy = 0.0114, Validation Loss = 8.1401\n",
            "Epoch 143/2500\n",
            "Epoch 143: Training Accuracy = 0.9922, Training Loss = 0.1787, Validation Accuracy = 0.0114, Validation Loss = 8.1401\n",
            "Epoch 144/2500\n",
            "Epoch 144: Training Accuracy = 0.9922, Training Loss = 0.1656, Validation Accuracy = 0.0115, Validation Loss = 8.1873\n",
            "Epoch 145/2500\n",
            "Epoch 145: Training Accuracy = 0.9922, Training Loss = 0.1656, Validation Accuracy = 0.0115, Validation Loss = 8.1873\n",
            "Epoch 146/2500\n",
            "Epoch 146: Training Accuracy = 0.9844, Training Loss = 0.1945, Validation Accuracy = 0.0112, Validation Loss = 8.2168\n",
            "Epoch 147/2500\n",
            "Epoch 147: Training Accuracy = 1.0000, Training Loss = 0.1320, Validation Accuracy = 0.0111, Validation Loss = 8.2262\n",
            "Epoch 148/2500\n",
            "Epoch 148: Training Accuracy = 1.0000, Training Loss = 0.1320, Validation Accuracy = 0.0111, Validation Loss = 8.2262\n",
            "Epoch 149/2500\n",
            "Epoch 149: Training Accuracy = 0.9863, Training Loss = 0.1723, Validation Accuracy = 0.0111, Validation Loss = 8.2709\n",
            "Epoch 150/2500\n",
            "Epoch 150: Training Accuracy = 0.9863, Training Loss = 0.1723, Validation Accuracy = 0.0111, Validation Loss = 8.2709\n",
            "Epoch 151/2500\n",
            "Epoch 151: Training Accuracy = 0.9922, Training Loss = 0.1381, Validation Accuracy = 0.0111, Validation Loss = 8.3170\n",
            "Epoch 152/2500\n",
            "Epoch 152: Training Accuracy = 0.9902, Training Loss = 0.1503, Validation Accuracy = 0.0114, Validation Loss = 8.3345\n",
            "Epoch 153/2500\n",
            "Epoch 153: Training Accuracy = 0.9902, Training Loss = 0.1503, Validation Accuracy = 0.0114, Validation Loss = 8.3345\n",
            "Epoch 154/2500\n",
            "Epoch 154: Training Accuracy = 0.9902, Training Loss = 0.1399, Validation Accuracy = 0.0114, Validation Loss = 8.3647\n",
            "Epoch 155/2500\n",
            "Epoch 155: Training Accuracy = 0.9902, Training Loss = 0.1399, Validation Accuracy = 0.0114, Validation Loss = 8.3647\n",
            "Epoch 156/2500\n",
            "Epoch 156: Training Accuracy = 0.9961, Training Loss = 0.1120, Validation Accuracy = 0.0111, Validation Loss = 8.4188\n",
            "Epoch 157/2500\n",
            "Epoch 157: Training Accuracy = 0.9902, Training Loss = 0.1432, Validation Accuracy = 0.0121, Validation Loss = 8.3891\n",
            "Epoch 158/2500\n",
            "Epoch 158: Training Accuracy = 0.9902, Training Loss = 0.1432, Validation Accuracy = 0.0121, Validation Loss = 8.3891\n",
            "Epoch 159/2500\n",
            "Epoch 159: Training Accuracy = 0.9824, Training Loss = 0.1641, Validation Accuracy = 0.0117, Validation Loss = 8.4520\n",
            "Epoch 160/2500\n",
            "Epoch 160: Training Accuracy = 0.9824, Training Loss = 0.1641, Validation Accuracy = 0.0117, Validation Loss = 8.4520\n",
            "Epoch 161/2500\n",
            "Epoch 161: Training Accuracy = 0.9883, Training Loss = 0.1278, Validation Accuracy = 0.0114, Validation Loss = 8.5141\n",
            "Epoch 162/2500\n",
            "Epoch 162: Training Accuracy = 0.9883, Training Loss = 0.1265, Validation Accuracy = 0.0114, Validation Loss = 8.5196\n",
            "Epoch 163/2500\n",
            "Epoch 163: Training Accuracy = 0.9883, Training Loss = 0.1265, Validation Accuracy = 0.0114, Validation Loss = 8.5196\n",
            "Epoch 164/2500\n",
            "Epoch 164: Training Accuracy = 0.9844, Training Loss = 0.1383, Validation Accuracy = 0.0112, Validation Loss = 8.5426\n",
            "Epoch 165/2500\n",
            "Epoch 165: Training Accuracy = 0.9844, Training Loss = 0.1383, Validation Accuracy = 0.0112, Validation Loss = 8.5426\n",
            "Epoch 166/2500\n",
            "Epoch 166: Training Accuracy = 0.9922, Training Loss = 0.1043, Validation Accuracy = 0.0115, Validation Loss = 8.5633\n",
            "Epoch 167/2500\n",
            "Epoch 167: Training Accuracy = 0.9941, Training Loss = 0.0945, Validation Accuracy = 0.0115, Validation Loss = 8.5773\n",
            "Epoch 168/2500\n",
            "Epoch 168: Training Accuracy = 0.9941, Training Loss = 0.0945, Validation Accuracy = 0.0115, Validation Loss = 8.5773\n",
            "Epoch 169/2500\n",
            "Epoch 169: Training Accuracy = 0.9805, Training Loss = 0.1586, Validation Accuracy = 0.0111, Validation Loss = 8.5992\n",
            "Epoch 170/2500\n",
            "Epoch 170: Training Accuracy = 0.9805, Training Loss = 0.1586, Validation Accuracy = 0.0111, Validation Loss = 8.5992\n",
            "Epoch 171/2500\n",
            "Epoch 171: Training Accuracy = 0.9863, Training Loss = 0.1222, Validation Accuracy = 0.0120, Validation Loss = 8.6587\n",
            "Epoch 172/2500\n",
            "Epoch 172: Training Accuracy = 0.9902, Training Loss = 0.1159, Validation Accuracy = 0.0117, Validation Loss = 8.6523\n",
            "Epoch 173/2500\n",
            "Epoch 173: Training Accuracy = 0.9902, Training Loss = 0.1159, Validation Accuracy = 0.0117, Validation Loss = 8.6523\n",
            "Epoch 174/2500\n",
            "Epoch 174: Training Accuracy = 0.9883, Training Loss = 0.1056, Validation Accuracy = 0.0117, Validation Loss = 8.6824\n",
            "Epoch 175/2500\n",
            "Epoch 175: Training Accuracy = 0.9883, Training Loss = 0.1056, Validation Accuracy = 0.0117, Validation Loss = 8.6824\n",
            "Epoch 176/2500\n",
            "Epoch 176: Training Accuracy = 0.9883, Training Loss = 0.1053, Validation Accuracy = 0.0115, Validation Loss = 8.7269\n",
            "Epoch 177/2500\n",
            "Epoch 177: Training Accuracy = 0.9785, Training Loss = 0.1475, Validation Accuracy = 0.0112, Validation Loss = 8.7683\n",
            "Epoch 178/2500\n",
            "Epoch 178: Training Accuracy = 0.9785, Training Loss = 0.1475, Validation Accuracy = 0.0112, Validation Loss = 8.7683\n",
            "Epoch 179/2500\n",
            "Epoch 179: Training Accuracy = 0.9922, Training Loss = 0.0839, Validation Accuracy = 0.0111, Validation Loss = 8.7809\n",
            "Epoch 180/2500\n",
            "Epoch 180: Training Accuracy = 0.9922, Training Loss = 0.0839, Validation Accuracy = 0.0111, Validation Loss = 8.7809\n",
            "Epoch 181/2500\n",
            "Epoch 181: Training Accuracy = 0.9844, Training Loss = 0.1142, Validation Accuracy = 0.0117, Validation Loss = 8.7939\n",
            "Epoch 182/2500\n",
            "Epoch 182: Training Accuracy = 0.9766, Training Loss = 0.1519, Validation Accuracy = 0.0118, Validation Loss = 8.8080\n",
            "Epoch 183/2500\n",
            "Epoch 183: Training Accuracy = 0.9766, Training Loss = 0.1519, Validation Accuracy = 0.0118, Validation Loss = 8.8080\n",
            "Epoch 184/2500\n",
            "Epoch 184: Training Accuracy = 0.9941, Training Loss = 0.0831, Validation Accuracy = 0.0120, Validation Loss = 8.8142\n",
            "Epoch 185/2500\n",
            "Epoch 185: Training Accuracy = 0.9941, Training Loss = 0.0831, Validation Accuracy = 0.0120, Validation Loss = 8.8142\n",
            "Epoch 186/2500\n",
            "Epoch 186: Training Accuracy = 0.9844, Training Loss = 0.1103, Validation Accuracy = 0.0120, Validation Loss = 8.8161\n",
            "Epoch 187/2500\n",
            "Epoch 187: Training Accuracy = 0.9844, Training Loss = 0.1086, Validation Accuracy = 0.0109, Validation Loss = 8.8969\n",
            "Epoch 188/2500\n",
            "Epoch 188: Training Accuracy = 0.9844, Training Loss = 0.1086, Validation Accuracy = 0.0109, Validation Loss = 8.8969\n",
            "Epoch 189/2500\n",
            "Epoch 189: Training Accuracy = 0.9863, Training Loss = 0.0995, Validation Accuracy = 0.0120, Validation Loss = 8.8881\n",
            "Epoch 190/2500\n",
            "Epoch 190: Training Accuracy = 0.9863, Training Loss = 0.0995, Validation Accuracy = 0.0120, Validation Loss = 8.8881\n",
            "Epoch 191/2500\n",
            "Epoch 191: Training Accuracy = 0.9922, Training Loss = 0.0786, Validation Accuracy = 0.0111, Validation Loss = 8.9117\n",
            "Epoch 192/2500\n",
            "Epoch 192: Training Accuracy = 0.9902, Training Loss = 0.0933, Validation Accuracy = 0.0120, Validation Loss = 8.9518\n",
            "Epoch 193/2500\n",
            "Epoch 193: Training Accuracy = 0.9902, Training Loss = 0.0933, Validation Accuracy = 0.0120, Validation Loss = 8.9518\n",
            "Epoch 194/2500\n",
            "Epoch 194: Training Accuracy = 0.5234, Training Loss = 1.7345, Validation Accuracy = 0.0115, Validation Loss = 9.0650\n",
            "Epoch 195/2500\n",
            "Epoch 195: Training Accuracy = 0.5234, Training Loss = 1.7345, Validation Accuracy = 0.0115, Validation Loss = 9.0650\n",
            "Epoch 196/2500\n",
            "Epoch 196: Training Accuracy = 0.9512, Training Loss = 0.3218, Validation Accuracy = 0.0114, Validation Loss = 8.7988\n",
            "Epoch 197/2500\n",
            "Epoch 197: Training Accuracy = 0.9922, Training Loss = 0.1798, Validation Accuracy = 0.0114, Validation Loss = 8.7110\n",
            "Epoch 198/2500\n",
            "Epoch 198: Training Accuracy = 0.9922, Training Loss = 0.1798, Validation Accuracy = 0.0114, Validation Loss = 8.7110\n",
            "Epoch 199/2500\n",
            "Epoch 199: Training Accuracy = 0.9844, Training Loss = 0.1681, Validation Accuracy = 0.0118, Validation Loss = 8.8279\n",
            "Epoch 200/2500\n",
            "Epoch 200: Training Accuracy = 0.9844, Training Loss = 0.1681, Validation Accuracy = 0.0118, Validation Loss = 8.8279\n",
            "Epoch 201/2500\n",
            "Epoch 201: Training Accuracy = 0.9941, Training Loss = 0.0837, Validation Accuracy = 0.0115, Validation Loss = 8.8336\n",
            "Epoch 202/2500\n",
            "Epoch 202: Training Accuracy = 0.9961, Training Loss = 0.0701, Validation Accuracy = 0.0117, Validation Loss = 8.8493\n",
            "Epoch 203/2500\n",
            "Epoch 203: Training Accuracy = 0.9961, Training Loss = 0.0701, Validation Accuracy = 0.0117, Validation Loss = 8.8493\n",
            "Epoch 204/2500\n",
            "Epoch 204: Training Accuracy = 0.9824, Training Loss = 0.1130, Validation Accuracy = 0.0117, Validation Loss = 8.8144\n",
            "Epoch 205/2500\n",
            "Epoch 205: Training Accuracy = 0.9824, Training Loss = 0.1130, Validation Accuracy = 0.0117, Validation Loss = 8.8144\n",
            "Epoch 206/2500\n",
            "Epoch 206: Training Accuracy = 0.9961, Training Loss = 0.0637, Validation Accuracy = 0.0117, Validation Loss = 8.7847\n",
            "Epoch 207/2500\n",
            "Epoch 207: Training Accuracy = 0.9883, Training Loss = 0.0948, Validation Accuracy = 0.0115, Validation Loss = 8.7680\n",
            "Epoch 208/2500\n",
            "Epoch 208: Training Accuracy = 0.9883, Training Loss = 0.0948, Validation Accuracy = 0.0115, Validation Loss = 8.7680\n",
            "Epoch 209/2500\n",
            "Epoch 209: Training Accuracy = 0.9902, Training Loss = 0.0854, Validation Accuracy = 0.0117, Validation Loss = 8.7446\n",
            "Epoch 210/2500\n",
            "Epoch 210: Training Accuracy = 0.9902, Training Loss = 0.0854, Validation Accuracy = 0.0117, Validation Loss = 8.7446\n",
            "Epoch 211/2500\n",
            "Epoch 211: Training Accuracy = 0.9902, Training Loss = 0.0918, Validation Accuracy = 0.0117, Validation Loss = 8.7127\n",
            "Epoch 212/2500\n",
            "Epoch 212: Training Accuracy = 0.9922, Training Loss = 0.0837, Validation Accuracy = 0.0117, Validation Loss = 8.7092\n",
            "Epoch 213/2500\n",
            "Epoch 213: Training Accuracy = 0.9922, Training Loss = 0.0837, Validation Accuracy = 0.0117, Validation Loss = 8.7092\n",
            "Epoch 214/2500\n",
            "Epoch 214: Training Accuracy = 0.9922, Training Loss = 0.0812, Validation Accuracy = 0.0112, Validation Loss = 8.6981\n",
            "Epoch 215/2500\n",
            "Epoch 215: Training Accuracy = 0.9922, Training Loss = 0.0812, Validation Accuracy = 0.0112, Validation Loss = 8.6981\n",
            "Epoch 216/2500\n",
            "Epoch 216: Training Accuracy = 0.9824, Training Loss = 0.1162, Validation Accuracy = 0.0115, Validation Loss = 8.6977\n",
            "Epoch 217/2500\n",
            "Epoch 217: Training Accuracy = 0.9805, Training Loss = 0.1275, Validation Accuracy = 0.0115, Validation Loss = 8.6813\n",
            "Epoch 218/2500\n",
            "Epoch 218: Training Accuracy = 0.9805, Training Loss = 0.1275, Validation Accuracy = 0.0115, Validation Loss = 8.6813\n",
            "Epoch 219/2500\n",
            "Epoch 219: Training Accuracy = 0.9922, Training Loss = 0.0864, Validation Accuracy = 0.0115, Validation Loss = 8.6993\n",
            "Epoch 220/2500\n",
            "Epoch 220: Training Accuracy = 0.9922, Training Loss = 0.0864, Validation Accuracy = 0.0115, Validation Loss = 8.6993\n",
            "Epoch 221/2500\n",
            "Epoch 221: Training Accuracy = 0.9902, Training Loss = 0.0880, Validation Accuracy = 0.0111, Validation Loss = 8.7129\n",
            "Epoch 222/2500\n",
            "Epoch 222: Training Accuracy = 0.9922, Training Loss = 0.0898, Validation Accuracy = 0.0114, Validation Loss = 8.7207\n",
            "Epoch 223/2500\n",
            "Epoch 223: Training Accuracy = 0.9922, Training Loss = 0.0898, Validation Accuracy = 0.0114, Validation Loss = 8.7207\n",
            "Epoch 224/2500\n",
            "Epoch 224: Training Accuracy = 0.9883, Training Loss = 0.1025, Validation Accuracy = 0.0115, Validation Loss = 8.7587\n",
            "Epoch 225/2500\n",
            "Epoch 225: Training Accuracy = 0.9883, Training Loss = 0.1025, Validation Accuracy = 0.0115, Validation Loss = 8.7587\n",
            "Epoch 226/2500\n",
            "Epoch 226: Training Accuracy = 0.9863, Training Loss = 0.1143, Validation Accuracy = 0.0114, Validation Loss = 8.7461\n",
            "Epoch 227/2500\n",
            "Epoch 227: Training Accuracy = 0.9883, Training Loss = 0.1091, Validation Accuracy = 0.0112, Validation Loss = 8.7471\n",
            "Epoch 228/2500\n",
            "Epoch 228: Training Accuracy = 0.9883, Training Loss = 0.1091, Validation Accuracy = 0.0112, Validation Loss = 8.7471\n",
            "Epoch 229/2500\n",
            "Epoch 229: Training Accuracy = 0.9941, Training Loss = 0.0870, Validation Accuracy = 0.0117, Validation Loss = 8.8064\n",
            "Epoch 230/2500\n",
            "Epoch 230: Training Accuracy = 0.9941, Training Loss = 0.0870, Validation Accuracy = 0.0117, Validation Loss = 8.8064\n",
            "Epoch 231/2500\n",
            "Epoch 231: Training Accuracy = 0.9883, Training Loss = 0.1049, Validation Accuracy = 0.0114, Validation Loss = 8.8434\n",
            "Epoch 232/2500\n",
            "Epoch 232: Training Accuracy = 0.9883, Training Loss = 0.1133, Validation Accuracy = 0.0115, Validation Loss = 8.8555\n",
            "Epoch 233/2500\n",
            "Epoch 233: Training Accuracy = 0.9883, Training Loss = 0.1133, Validation Accuracy = 0.0115, Validation Loss = 8.8555\n",
            "Epoch 234/2500\n",
            "Epoch 234: Training Accuracy = 0.9863, Training Loss = 0.1123, Validation Accuracy = 0.0112, Validation Loss = 8.8862\n",
            "Epoch 235/2500\n",
            "Epoch 235: Training Accuracy = 0.9863, Training Loss = 0.1123, Validation Accuracy = 0.0112, Validation Loss = 8.8862\n",
            "Epoch 236/2500\n",
            "Epoch 236: Training Accuracy = 0.9941, Training Loss = 0.0809, Validation Accuracy = 0.0117, Validation Loss = 8.9018\n",
            "Epoch 237/2500\n",
            "Epoch 237: Training Accuracy = 0.9863, Training Loss = 0.1152, Validation Accuracy = 0.0114, Validation Loss = 8.9261\n",
            "Epoch 238/2500\n",
            "Epoch 238: Training Accuracy = 0.9863, Training Loss = 0.1152, Validation Accuracy = 0.0114, Validation Loss = 8.9261\n",
            "Epoch 239/2500\n",
            "Epoch 239: Training Accuracy = 0.9824, Training Loss = 0.1129, Validation Accuracy = 0.0112, Validation Loss = 8.9559\n",
            "Epoch 240/2500\n",
            "Epoch 240: Training Accuracy = 0.9824, Training Loss = 0.1129, Validation Accuracy = 0.0112, Validation Loss = 8.9559\n",
            "Epoch 241/2500\n",
            "Epoch 241: Training Accuracy = 0.9766, Training Loss = 0.1262, Validation Accuracy = 0.0115, Validation Loss = 8.9572\n",
            "Epoch 242/2500\n",
            "Epoch 242: Training Accuracy = 0.9844, Training Loss = 0.1088, Validation Accuracy = 0.0115, Validation Loss = 9.0049\n",
            "Epoch 243/2500\n",
            "Epoch 243: Training Accuracy = 0.9844, Training Loss = 0.1088, Validation Accuracy = 0.0115, Validation Loss = 9.0049\n",
            "Epoch 244/2500\n",
            "Epoch 244: Training Accuracy = 0.9863, Training Loss = 0.0877, Validation Accuracy = 0.0114, Validation Loss = 8.9873\n",
            "Epoch 245/2500\n",
            "Epoch 245: Training Accuracy = 0.9863, Training Loss = 0.0877, Validation Accuracy = 0.0114, Validation Loss = 8.9873\n",
            "Epoch 246/2500\n",
            "Epoch 246: Training Accuracy = 0.9922, Training Loss = 0.0647, Validation Accuracy = 0.0117, Validation Loss = 9.0073\n",
            "Epoch 247/2500\n",
            "Epoch 247: Training Accuracy = 0.9902, Training Loss = 0.0778, Validation Accuracy = 0.0112, Validation Loss = 8.9950\n",
            "Epoch 248/2500\n",
            "Epoch 248: Training Accuracy = 0.9902, Training Loss = 0.0778, Validation Accuracy = 0.0112, Validation Loss = 8.9950\n",
            "Epoch 249/2500\n",
            "Epoch 249: Training Accuracy = 0.9863, Training Loss = 0.0891, Validation Accuracy = 0.0121, Validation Loss = 9.0398\n",
            "Epoch 250/2500\n",
            "Epoch 250: Training Accuracy = 0.9863, Training Loss = 0.0891, Validation Accuracy = 0.0121, Validation Loss = 9.0398\n",
            "Epoch 251/2500\n",
            "Epoch 251: Training Accuracy = 0.6855, Training Loss = 1.4160, Validation Accuracy = 0.0114, Validation Loss = 7.9586\n",
            "Epoch 252/2500\n",
            "Epoch 252: Training Accuracy = 0.9590, Training Loss = 0.3569, Validation Accuracy = 0.0114, Validation Loss = 8.4954\n",
            "Epoch 253/2500\n",
            "Epoch 253: Training Accuracy = 0.9590, Training Loss = 0.3569, Validation Accuracy = 0.0114, Validation Loss = 8.4954\n",
            "Epoch 254/2500\n",
            "Epoch 254: Training Accuracy = 0.9766, Training Loss = 0.2342, Validation Accuracy = 0.0124, Validation Loss = 8.8119\n",
            "Epoch 255/2500\n",
            "Epoch 255: Training Accuracy = 0.9766, Training Loss = 0.2342, Validation Accuracy = 0.0124, Validation Loss = 8.8119\n",
            "Epoch 256/2500\n",
            "Epoch 256: Training Accuracy = 0.9883, Training Loss = 0.1467, Validation Accuracy = 0.0109, Validation Loss = 8.8589\n",
            "Epoch 257/2500\n",
            "Epoch 257: Training Accuracy = 0.9902, Training Loss = 0.1125, Validation Accuracy = 0.0112, Validation Loss = 8.8703\n",
            "Epoch 258/2500\n",
            "Epoch 258: Training Accuracy = 0.9902, Training Loss = 0.1125, Validation Accuracy = 0.0112, Validation Loss = 8.8703\n",
            "Epoch 259/2500\n",
            "Epoch 259: Training Accuracy = 0.9863, Training Loss = 0.1009, Validation Accuracy = 0.0111, Validation Loss = 8.9013\n",
            "Epoch 260/2500\n",
            "Epoch 260: Training Accuracy = 0.9863, Training Loss = 0.1009, Validation Accuracy = 0.0111, Validation Loss = 8.9013\n",
            "Epoch 261/2500\n",
            "Epoch 261: Training Accuracy = 0.9902, Training Loss = 0.0840, Validation Accuracy = 0.0112, Validation Loss = 8.8738\n",
            "Epoch 262/2500\n",
            "Epoch 262: Training Accuracy = 0.9922, Training Loss = 0.0792, Validation Accuracy = 0.0111, Validation Loss = 8.8355\n",
            "Epoch 263/2500\n",
            "Epoch 263: Training Accuracy = 0.9922, Training Loss = 0.0792, Validation Accuracy = 0.0111, Validation Loss = 8.8355\n",
            "Epoch 264/2500\n",
            "Epoch 264: Training Accuracy = 0.9922, Training Loss = 0.0779, Validation Accuracy = 0.0111, Validation Loss = 8.7928\n",
            "Epoch 265/2500\n",
            "Epoch 265: Training Accuracy = 0.9922, Training Loss = 0.0779, Validation Accuracy = 0.0111, Validation Loss = 8.7928\n",
            "Epoch 266/2500\n",
            "Epoch 266: Training Accuracy = 0.9902, Training Loss = 0.0930, Validation Accuracy = 0.0114, Validation Loss = 8.7647\n",
            "Epoch 267/2500\n",
            "Epoch 267: Training Accuracy = 0.9844, Training Loss = 0.1111, Validation Accuracy = 0.0115, Validation Loss = 8.7290\n",
            "Epoch 268/2500\n",
            "Epoch 268: Training Accuracy = 0.9844, Training Loss = 0.1111, Validation Accuracy = 0.0115, Validation Loss = 8.7290\n",
            "Epoch 269/2500\n",
            "Epoch 269: Training Accuracy = 0.9961, Training Loss = 0.0717, Validation Accuracy = 0.0114, Validation Loss = 8.6905\n",
            "Epoch 270/2500\n",
            "Epoch 270: Training Accuracy = 0.9961, Training Loss = 0.0717, Validation Accuracy = 0.0114, Validation Loss = 8.6905\n",
            "Epoch 271/2500\n",
            "Epoch 271: Training Accuracy = 0.9863, Training Loss = 0.1048, Validation Accuracy = 0.0118, Validation Loss = 8.6813\n",
            "Epoch 272/2500\n",
            "Epoch 272: Training Accuracy = 0.9902, Training Loss = 0.0987, Validation Accuracy = 0.0117, Validation Loss = 8.6581\n",
            "Epoch 273/2500\n",
            "Epoch 273: Training Accuracy = 0.9902, Training Loss = 0.0987, Validation Accuracy = 0.0117, Validation Loss = 8.6581\n",
            "Epoch 274/2500\n",
            "Epoch 274: Training Accuracy = 0.9902, Training Loss = 0.1013, Validation Accuracy = 0.0114, Validation Loss = 8.6354\n",
            "Epoch 275/2500\n",
            "Epoch 275: Training Accuracy = 0.9902, Training Loss = 0.1013, Validation Accuracy = 0.0114, Validation Loss = 8.6354\n",
            "Epoch 276/2500\n",
            "Epoch 276: Training Accuracy = 0.9922, Training Loss = 0.0979, Validation Accuracy = 0.0115, Validation Loss = 8.6611\n",
            "Epoch 277/2500\n",
            "Epoch 277: Training Accuracy = 0.9863, Training Loss = 0.1253, Validation Accuracy = 0.0112, Validation Loss = 8.6454\n",
            "Epoch 278/2500\n",
            "Epoch 278: Training Accuracy = 0.9863, Training Loss = 0.1253, Validation Accuracy = 0.0112, Validation Loss = 8.6454\n",
            "Epoch 279/2500\n",
            "Epoch 279: Training Accuracy = 0.9922, Training Loss = 0.0864, Validation Accuracy = 0.0112, Validation Loss = 8.6561\n",
            "Epoch 280/2500\n",
            "Epoch 280: Training Accuracy = 0.9922, Training Loss = 0.0864, Validation Accuracy = 0.0112, Validation Loss = 8.6561\n",
            "Epoch 281/2500\n",
            "Epoch 281: Training Accuracy = 0.9863, Training Loss = 0.1177, Validation Accuracy = 0.0117, Validation Loss = 8.6485\n",
            "Epoch 282/2500\n",
            "Epoch 282: Training Accuracy = 0.9883, Training Loss = 0.1222, Validation Accuracy = 0.0114, Validation Loss = 8.7127\n",
            "Epoch 283/2500\n",
            "Epoch 283: Training Accuracy = 0.9883, Training Loss = 0.1222, Validation Accuracy = 0.0114, Validation Loss = 8.7127\n",
            "Epoch 284/2500\n",
            "Epoch 284: Training Accuracy = 0.8027, Training Loss = 0.8072, Validation Accuracy = 0.0120, Validation Loss = 8.4647\n",
            "Epoch 285/2500\n",
            "Epoch 285: Training Accuracy = 0.8027, Training Loss = 0.8072, Validation Accuracy = 0.0120, Validation Loss = 8.4647\n",
            "Epoch 286/2500\n",
            "Epoch 286: Training Accuracy = 0.9785, Training Loss = 0.2798, Validation Accuracy = 0.0115, Validation Loss = 8.4732\n",
            "Epoch 287/2500\n",
            "Epoch 287: Training Accuracy = 0.9902, Training Loss = 0.1746, Validation Accuracy = 0.0114, Validation Loss = 8.5675\n",
            "Epoch 288/2500\n",
            "Epoch 288: Training Accuracy = 0.9902, Training Loss = 0.1746, Validation Accuracy = 0.0114, Validation Loss = 8.5675\n",
            "Epoch 289/2500\n",
            "Epoch 289: Training Accuracy = 0.9902, Training Loss = 0.1403, Validation Accuracy = 0.0115, Validation Loss = 8.6326\n",
            "Epoch 290/2500\n",
            "Epoch 290: Training Accuracy = 0.9902, Training Loss = 0.1403, Validation Accuracy = 0.0115, Validation Loss = 8.6326\n",
            "Epoch 291/2500\n",
            "Epoch 291: Training Accuracy = 0.9844, Training Loss = 0.1318, Validation Accuracy = 0.0115, Validation Loss = 8.6318\n",
            "Epoch 292/2500\n",
            "Epoch 292: Training Accuracy = 0.9863, Training Loss = 0.1161, Validation Accuracy = 0.0114, Validation Loss = 8.6290\n",
            "Epoch 293/2500\n",
            "Epoch 293: Training Accuracy = 0.9863, Training Loss = 0.1161, Validation Accuracy = 0.0114, Validation Loss = 8.6290\n",
            "Epoch 294/2500\n",
            "Epoch 294: Training Accuracy = 0.9902, Training Loss = 0.1001, Validation Accuracy = 0.0114, Validation Loss = 8.5996\n",
            "Epoch 295/2500\n",
            "Epoch 295: Training Accuracy = 0.9902, Training Loss = 0.1001, Validation Accuracy = 0.0114, Validation Loss = 8.5996\n",
            "Epoch 296/2500\n",
            "Epoch 296: Training Accuracy = 0.9883, Training Loss = 0.1016, Validation Accuracy = 0.0112, Validation Loss = 8.5830\n",
            "Epoch 297/2500\n",
            "Epoch 297: Training Accuracy = 0.9961, Training Loss = 0.0813, Validation Accuracy = 0.0115, Validation Loss = 8.5547\n",
            "Epoch 298/2500\n",
            "Epoch 298: Training Accuracy = 0.9961, Training Loss = 0.0813, Validation Accuracy = 0.0115, Validation Loss = 8.5547\n",
            "Epoch 299/2500\n",
            "Epoch 299: Training Accuracy = 0.9922, Training Loss = 0.0952, Validation Accuracy = 0.0117, Validation Loss = 8.5298\n",
            "Epoch 300/2500\n",
            "Epoch 300: Training Accuracy = 0.9922, Training Loss = 0.0952, Validation Accuracy = 0.0117, Validation Loss = 8.5298\n",
            "Epoch 301/2500\n",
            "Epoch 301: Training Accuracy = 0.9961, Training Loss = 0.0797, Validation Accuracy = 0.0115, Validation Loss = 8.5098\n",
            "Epoch 302/2500\n",
            "Epoch 302: Training Accuracy = 0.9941, Training Loss = 0.0976, Validation Accuracy = 0.0115, Validation Loss = 8.5003\n",
            "Epoch 303/2500\n",
            "Epoch 303: Training Accuracy = 0.9941, Training Loss = 0.0976, Validation Accuracy = 0.0115, Validation Loss = 8.5003\n",
            "Epoch 304/2500\n",
            "Epoch 304: Training Accuracy = 0.9961, Training Loss = 0.0886, Validation Accuracy = 0.0114, Validation Loss = 8.5208\n",
            "Epoch 305/2500\n",
            "Epoch 305: Training Accuracy = 0.9961, Training Loss = 0.0886, Validation Accuracy = 0.0114, Validation Loss = 8.5208\n",
            "Epoch 306/2500\n",
            "Epoch 306: Training Accuracy = 0.9844, Training Loss = 0.1331, Validation Accuracy = 0.0114, Validation Loss = 8.4897\n",
            "Epoch 307/2500\n",
            "Epoch 307: Training Accuracy = 0.9785, Training Loss = 0.2486, Validation Accuracy = 0.0126, Validation Loss = 8.8308\n",
            "Epoch 308/2500\n",
            "Epoch 308: Training Accuracy = 0.9785, Training Loss = 0.2486, Validation Accuracy = 0.0126, Validation Loss = 8.8308\n",
            "Epoch 309/2500\n",
            "Epoch 309: Training Accuracy = 0.8418, Training Loss = 0.8816, Validation Accuracy = 0.0108, Validation Loss = 7.8811\n",
            "Epoch 310/2500\n",
            "Epoch 310: Training Accuracy = 0.8418, Training Loss = 0.8816, Validation Accuracy = 0.0108, Validation Loss = 7.8811\n",
            "Epoch 311/2500\n",
            "Epoch 311: Training Accuracy = 0.9629, Training Loss = 0.3978, Validation Accuracy = 0.0120, Validation Loss = 8.2304\n",
            "Epoch 312/2500\n",
            "Epoch 312: Training Accuracy = 0.9844, Training Loss = 0.2465, Validation Accuracy = 0.0114, Validation Loss = 8.3796\n",
            "Epoch 313/2500\n",
            "Epoch 313: Training Accuracy = 0.9844, Training Loss = 0.2465, Validation Accuracy = 0.0114, Validation Loss = 8.3796\n",
            "Epoch 314/2500\n",
            "Epoch 314: Training Accuracy = 0.9902, Training Loss = 0.1527, Validation Accuracy = 0.0111, Validation Loss = 8.4761\n",
            "Epoch 315/2500\n",
            "Epoch 315: Training Accuracy = 0.9902, Training Loss = 0.1527, Validation Accuracy = 0.0111, Validation Loss = 8.4761\n",
            "Epoch 316/2500\n",
            "Epoch 316: Training Accuracy = 0.9922, Training Loss = 0.1250, Validation Accuracy = 0.0115, Validation Loss = 8.4704\n",
            "Epoch 317/2500\n",
            "Epoch 317: Training Accuracy = 0.9883, Training Loss = 0.1314, Validation Accuracy = 0.0114, Validation Loss = 8.4725\n",
            "Epoch 318/2500\n",
            "Epoch 318: Training Accuracy = 0.9883, Training Loss = 0.1314, Validation Accuracy = 0.0114, Validation Loss = 8.4725\n",
            "Epoch 319/2500\n",
            "Epoch 319: Training Accuracy = 0.9863, Training Loss = 0.1355, Validation Accuracy = 0.0117, Validation Loss = 8.4352\n",
            "Epoch 320/2500\n",
            "Epoch 320: Training Accuracy = 0.9863, Training Loss = 0.1355, Validation Accuracy = 0.0117, Validation Loss = 8.4352\n",
            "Epoch 321/2500\n",
            "Epoch 321: Training Accuracy = 0.9902, Training Loss = 0.1141, Validation Accuracy = 0.0121, Validation Loss = 8.4181\n",
            "Epoch 322/2500\n",
            "Epoch 322: Training Accuracy = 0.9922, Training Loss = 0.1123, Validation Accuracy = 0.0115, Validation Loss = 8.3926\n",
            "Epoch 323/2500\n",
            "Epoch 323: Training Accuracy = 0.9922, Training Loss = 0.1123, Validation Accuracy = 0.0115, Validation Loss = 8.3926\n",
            "Epoch 324/2500\n",
            "Epoch 324: Training Accuracy = 0.9902, Training Loss = 0.1152, Validation Accuracy = 0.0117, Validation Loss = 8.3684\n",
            "Epoch 325/2500\n",
            "Epoch 325: Training Accuracy = 0.9902, Training Loss = 0.1152, Validation Accuracy = 0.0117, Validation Loss = 8.3684\n",
            "Epoch 326/2500\n",
            "Epoch 326: Training Accuracy = 0.9902, Training Loss = 0.1123, Validation Accuracy = 0.0118, Validation Loss = 8.3416\n",
            "Epoch 327/2500\n",
            "Epoch 327: Training Accuracy = 0.9863, Training Loss = 0.1424, Validation Accuracy = 0.0115, Validation Loss = 8.3434\n",
            "Epoch 328/2500\n",
            "Epoch 328: Training Accuracy = 0.9863, Training Loss = 0.1424, Validation Accuracy = 0.0115, Validation Loss = 8.3434\n",
            "Epoch 329/2500\n",
            "Epoch 329: Training Accuracy = 0.9902, Training Loss = 0.1186, Validation Accuracy = 0.0115, Validation Loss = 8.3328\n",
            "Epoch 330/2500\n",
            "Epoch 330: Training Accuracy = 0.9902, Training Loss = 0.1186, Validation Accuracy = 0.0115, Validation Loss = 8.3328\n",
            "Epoch 331/2500\n",
            "Epoch 331: Training Accuracy = 0.3711, Training Loss = 2.5129, Validation Accuracy = 0.0112, Validation Loss = 8.0354\n",
            "Epoch 332/2500\n",
            "Epoch 332: Training Accuracy = 0.8477, Training Loss = 0.7114, Validation Accuracy = 0.0117, Validation Loss = 7.9414\n",
            "Epoch 333/2500\n",
            "Epoch 333: Training Accuracy = 0.8477, Training Loss = 0.7114, Validation Accuracy = 0.0117, Validation Loss = 7.9414\n",
            "Epoch 334/2500\n",
            "Epoch 334: Training Accuracy = 0.9746, Training Loss = 0.3213, Validation Accuracy = 0.0117, Validation Loss = 8.1563\n",
            "Epoch 335/2500\n",
            "Epoch 335: Training Accuracy = 0.9746, Training Loss = 0.3213, Validation Accuracy = 0.0117, Validation Loss = 8.1563\n",
            "Epoch 336/2500\n",
            "Epoch 336: Training Accuracy = 0.9844, Training Loss = 0.2383, Validation Accuracy = 0.0115, Validation Loss = 8.2378\n",
            "Epoch 337/2500\n",
            "Epoch 337: Training Accuracy = 0.9961, Training Loss = 0.1573, Validation Accuracy = 0.0112, Validation Loss = 8.2997\n",
            "Epoch 338/2500\n",
            "Epoch 338: Training Accuracy = 0.9961, Training Loss = 0.1573, Validation Accuracy = 0.0112, Validation Loss = 8.2997\n",
            "Epoch 339/2500\n",
            "Epoch 339: Training Accuracy = 0.9785, Training Loss = 0.1923, Validation Accuracy = 0.0120, Validation Loss = 8.3037\n",
            "Epoch 340/2500\n",
            "Epoch 340: Training Accuracy = 0.9785, Training Loss = 0.1923, Validation Accuracy = 0.0120, Validation Loss = 8.3037\n",
            "Epoch 341/2500\n",
            "Epoch 341: Training Accuracy = 0.9941, Training Loss = 0.1189, Validation Accuracy = 0.0117, Validation Loss = 8.3227\n",
            "Epoch 342/2500\n",
            "Epoch 342: Training Accuracy = 0.9941, Training Loss = 0.1168, Validation Accuracy = 0.0112, Validation Loss = 8.2901\n",
            "Epoch 343/2500\n",
            "Epoch 343: Training Accuracy = 0.9941, Training Loss = 0.1168, Validation Accuracy = 0.0112, Validation Loss = 8.2901\n",
            "Epoch 344/2500\n",
            "Epoch 344: Training Accuracy = 0.9863, Training Loss = 0.1473, Validation Accuracy = 0.0117, Validation Loss = 8.2758\n",
            "Epoch 345/2500\n",
            "Epoch 345: Training Accuracy = 0.9863, Training Loss = 0.1473, Validation Accuracy = 0.0117, Validation Loss = 8.2758\n",
            "Epoch 346/2500\n",
            "Epoch 346: Training Accuracy = 0.9902, Training Loss = 0.1304, Validation Accuracy = 0.0115, Validation Loss = 8.2492\n",
            "Epoch 347/2500\n",
            "Epoch 347: Training Accuracy = 0.9883, Training Loss = 0.1431, Validation Accuracy = 0.0112, Validation Loss = 8.2432\n",
            "Epoch 348/2500\n",
            "Epoch 348: Training Accuracy = 0.9883, Training Loss = 0.1431, Validation Accuracy = 0.0112, Validation Loss = 8.2432\n",
            "Epoch 349/2500\n",
            "Epoch 349: Training Accuracy = 0.9883, Training Loss = 0.1444, Validation Accuracy = 0.0111, Validation Loss = 8.2415\n",
            "Epoch 350/2500\n",
            "Epoch 350: Training Accuracy = 0.9883, Training Loss = 0.1444, Validation Accuracy = 0.0111, Validation Loss = 8.2415\n",
            "Epoch 351/2500\n",
            "Epoch 351: Training Accuracy = 0.9922, Training Loss = 0.2061, Validation Accuracy = 0.0118, Validation Loss = 8.3193\n",
            "Epoch 352/2500\n",
            "Epoch 352: Training Accuracy = 0.8555, Training Loss = 0.7632, Validation Accuracy = 0.0117, Validation Loss = 7.9718\n",
            "Epoch 353/2500\n",
            "Epoch 353: Training Accuracy = 0.8555, Training Loss = 0.7632, Validation Accuracy = 0.0117, Validation Loss = 7.9718\n",
            "Epoch 354/2500\n",
            "Epoch 354: Training Accuracy = 0.9805, Training Loss = 0.3317, Validation Accuracy = 0.0103, Validation Loss = 8.0932\n",
            "Epoch 355/2500\n",
            "Epoch 355: Training Accuracy = 0.9805, Training Loss = 0.3317, Validation Accuracy = 0.0103, Validation Loss = 8.0932\n",
            "Epoch 356/2500\n",
            "Epoch 356: Training Accuracy = 0.9844, Training Loss = 0.2126, Validation Accuracy = 0.0108, Validation Loss = 8.1612\n",
            "Epoch 357/2500\n",
            "Epoch 357: Training Accuracy = 0.9863, Training Loss = 0.1979, Validation Accuracy = 0.0112, Validation Loss = 8.2416\n",
            "Epoch 358/2500\n",
            "Epoch 358: Training Accuracy = 0.9863, Training Loss = 0.1979, Validation Accuracy = 0.0112, Validation Loss = 8.2416\n",
            "Epoch 359/2500\n",
            "Epoch 359: Training Accuracy = 0.9863, Training Loss = 0.1704, Validation Accuracy = 0.0112, Validation Loss = 8.2321\n",
            "Epoch 360/2500\n",
            "Epoch 360: Training Accuracy = 0.9863, Training Loss = 0.1704, Validation Accuracy = 0.0112, Validation Loss = 8.2321\n",
            "Epoch 361/2500\n",
            "Epoch 361: Training Accuracy = 0.9922, Training Loss = 0.1240, Validation Accuracy = 0.0112, Validation Loss = 8.2178\n",
            "Epoch 362/2500\n",
            "Epoch 362: Training Accuracy = 0.9902, Training Loss = 0.1364, Validation Accuracy = 0.0114, Validation Loss = 8.2203\n",
            "Epoch 363/2500\n",
            "Epoch 363: Training Accuracy = 0.9902, Training Loss = 0.1364, Validation Accuracy = 0.0114, Validation Loss = 8.2203\n",
            "Epoch 364/2500\n",
            "Epoch 364: Training Accuracy = 0.9922, Training Loss = 0.1235, Validation Accuracy = 0.0112, Validation Loss = 8.2082\n",
            "Epoch 365/2500\n",
            "Epoch 365: Training Accuracy = 0.9922, Training Loss = 0.1235, Validation Accuracy = 0.0112, Validation Loss = 8.2082\n",
            "Epoch 366/2500\n",
            "Epoch 366: Training Accuracy = 0.9922, Training Loss = 0.1268, Validation Accuracy = 0.0117, Validation Loss = 8.1856\n",
            "Epoch 367/2500\n",
            "Epoch 367: Training Accuracy = 0.9805, Training Loss = 0.1922, Validation Accuracy = 0.0114, Validation Loss = 8.1695\n",
            "Epoch 368/2500\n",
            "Epoch 368: Training Accuracy = 0.9805, Training Loss = 0.1922, Validation Accuracy = 0.0114, Validation Loss = 8.1695\n",
            "Epoch 369/2500\n",
            "Epoch 369: Training Accuracy = 0.9941, Training Loss = 0.1621, Validation Accuracy = 0.0118, Validation Loss = 8.2104\n",
            "Epoch 370/2500\n",
            "Epoch 370: Training Accuracy = 0.9941, Training Loss = 0.1621, Validation Accuracy = 0.0118, Validation Loss = 8.2104\n",
            "Epoch 371/2500\n",
            "Epoch 371: Training Accuracy = 0.9863, Training Loss = 0.1573, Validation Accuracy = 0.0111, Validation Loss = 8.1683\n",
            "Epoch 372/2500\n",
            "Epoch 372: Training Accuracy = 0.6777, Training Loss = 1.3991, Validation Accuracy = 0.0117, Validation Loss = 7.6715\n",
            "Epoch 373/2500\n",
            "Epoch 373: Training Accuracy = 0.6777, Training Loss = 1.3991, Validation Accuracy = 0.0117, Validation Loss = 7.6715\n",
            "Epoch 374/2500\n",
            "Epoch 374: Training Accuracy = 0.9492, Training Loss = 0.5066, Validation Accuracy = 0.0114, Validation Loss = 7.9108\n",
            "Epoch 375/2500\n",
            "Epoch 375: Training Accuracy = 0.9492, Training Loss = 0.5066, Validation Accuracy = 0.0114, Validation Loss = 7.9108\n",
            "Epoch 376/2500\n",
            "Epoch 376: Training Accuracy = 0.9824, Training Loss = 0.3029, Validation Accuracy = 0.0108, Validation Loss = 8.1314\n",
            "Epoch 377/2500\n",
            "Epoch 377: Training Accuracy = 0.9863, Training Loss = 0.2408, Validation Accuracy = 0.0112, Validation Loss = 8.1858\n",
            "Epoch 378/2500\n",
            "Epoch 378: Training Accuracy = 0.9863, Training Loss = 0.2408, Validation Accuracy = 0.0112, Validation Loss = 8.1858\n",
            "Epoch 379/2500\n",
            "Epoch 379: Training Accuracy = 0.9863, Training Loss = 0.1802, Validation Accuracy = 0.0108, Validation Loss = 8.2004\n",
            "Epoch 380/2500\n",
            "Epoch 380: Training Accuracy = 0.9863, Training Loss = 0.1802, Validation Accuracy = 0.0108, Validation Loss = 8.2004\n",
            "Epoch 381/2500\n",
            "Epoch 381: Training Accuracy = 0.9902, Training Loss = 0.1452, Validation Accuracy = 0.0115, Validation Loss = 8.2006\n",
            "Epoch 382/2500\n",
            "Epoch 382: Training Accuracy = 0.9805, Training Loss = 0.1822, Validation Accuracy = 0.0111, Validation Loss = 8.2026\n",
            "Epoch 383/2500\n",
            "Epoch 383: Training Accuracy = 0.9805, Training Loss = 0.1822, Validation Accuracy = 0.0111, Validation Loss = 8.2026\n",
            "Epoch 384/2500\n",
            "Epoch 384: Training Accuracy = 0.9844, Training Loss = 0.1584, Validation Accuracy = 0.0111, Validation Loss = 8.1770\n",
            "Epoch 385/2500\n",
            "Epoch 385: Training Accuracy = 0.9844, Training Loss = 0.1584, Validation Accuracy = 0.0111, Validation Loss = 8.1770\n",
            "Epoch 386/2500\n",
            "Epoch 386: Training Accuracy = 0.9824, Training Loss = 0.1640, Validation Accuracy = 0.0112, Validation Loss = 8.1509\n",
            "Epoch 387/2500\n",
            "Epoch 387: Training Accuracy = 0.9922, Training Loss = 0.1392, Validation Accuracy = 0.0112, Validation Loss = 8.1526\n",
            "Epoch 388/2500\n",
            "Epoch 388: Training Accuracy = 0.9922, Training Loss = 0.1392, Validation Accuracy = 0.0112, Validation Loss = 8.1526\n",
            "Epoch 389/2500\n",
            "Epoch 389: Training Accuracy = 0.9883, Training Loss = 0.1490, Validation Accuracy = 0.0114, Validation Loss = 8.1474\n",
            "Epoch 390/2500\n",
            "Epoch 390: Training Accuracy = 0.9883, Training Loss = 0.1490, Validation Accuracy = 0.0114, Validation Loss = 8.1474\n",
            "Epoch 391/2500\n",
            "Epoch 391: Training Accuracy = 0.9941, Training Loss = 0.1450, Validation Accuracy = 0.0114, Validation Loss = 8.1415\n",
            "Epoch 392/2500\n",
            "Epoch 392: Training Accuracy = 0.7266, Training Loss = 1.1279, Validation Accuracy = 0.0115, Validation Loss = 7.8779\n",
            "Epoch 393/2500\n",
            "Epoch 393: Training Accuracy = 0.7266, Training Loss = 1.1279, Validation Accuracy = 0.0115, Validation Loss = 7.8779\n",
            "Epoch 394/2500\n",
            "Epoch 394: Training Accuracy = 0.9492, Training Loss = 0.4571, Validation Accuracy = 0.0111, Validation Loss = 7.8875\n",
            "Epoch 395/2500\n",
            "Epoch 395: Training Accuracy = 0.9492, Training Loss = 0.4571, Validation Accuracy = 0.0111, Validation Loss = 7.8875\n",
            "Epoch 396/2500\n",
            "Epoch 396: Training Accuracy = 0.9707, Training Loss = 0.3327, Validation Accuracy = 0.0114, Validation Loss = 8.0329\n",
            "Epoch 397/2500\n",
            "Epoch 397: Training Accuracy = 0.9844, Training Loss = 0.2313, Validation Accuracy = 0.0102, Validation Loss = 8.1125\n",
            "Epoch 398/2500\n",
            "Epoch 398: Training Accuracy = 0.9844, Training Loss = 0.2313, Validation Accuracy = 0.0102, Validation Loss = 8.1125\n",
            "Epoch 399/2500\n",
            "Epoch 399: Training Accuracy = 0.9824, Training Loss = 0.1970, Validation Accuracy = 0.0114, Validation Loss = 8.1400\n",
            "Epoch 400/2500\n",
            "Epoch 400: Training Accuracy = 0.9824, Training Loss = 0.1970, Validation Accuracy = 0.0114, Validation Loss = 8.1400\n",
            "Epoch 401/2500\n",
            "Epoch 401: Training Accuracy = 0.9883, Training Loss = 0.1645, Validation Accuracy = 0.0106, Validation Loss = 8.1186\n",
            "Epoch 402/2500\n",
            "Epoch 402: Training Accuracy = 0.9863, Training Loss = 0.1702, Validation Accuracy = 0.0112, Validation Loss = 8.1593\n",
            "Epoch 403/2500\n",
            "Epoch 403: Training Accuracy = 0.9863, Training Loss = 0.1702, Validation Accuracy = 0.0112, Validation Loss = 8.1593\n",
            "Epoch 404/2500\n",
            "Epoch 404: Training Accuracy = 0.9863, Training Loss = 0.1566, Validation Accuracy = 0.0111, Validation Loss = 8.1334\n",
            "Epoch 405/2500\n",
            "Epoch 405: Training Accuracy = 0.9863, Training Loss = 0.1566, Validation Accuracy = 0.0111, Validation Loss = 8.1334\n",
            "Epoch 406/2500\n",
            "Epoch 406: Training Accuracy = 0.9902, Training Loss = 0.1417, Validation Accuracy = 0.0111, Validation Loss = 8.1147\n",
            "Epoch 407/2500\n",
            "Epoch 407: Training Accuracy = 0.9785, Training Loss = 0.1930, Validation Accuracy = 0.0112, Validation Loss = 8.1174\n",
            "Epoch 408/2500\n",
            "Epoch 408: Training Accuracy = 0.9785, Training Loss = 0.1930, Validation Accuracy = 0.0112, Validation Loss = 8.1174\n",
            "Epoch 409/2500\n",
            "Epoch 409: Training Accuracy = 0.9980, Training Loss = 0.1273, Validation Accuracy = 0.0111, Validation Loss = 8.1081\n",
            "Epoch 410/2500\n",
            "Epoch 410: Training Accuracy = 0.9980, Training Loss = 0.1273, Validation Accuracy = 0.0111, Validation Loss = 8.1081\n",
            "Epoch 411/2500\n",
            "Epoch 411: Training Accuracy = 0.9941, Training Loss = 0.2228, Validation Accuracy = 0.0109, Validation Loss = 8.2317\n",
            "Epoch 412/2500\n",
            "Epoch 412: Training Accuracy = 0.8887, Training Loss = 0.6934, Validation Accuracy = 0.0109, Validation Loss = 7.8257\n",
            "Epoch 413/2500\n",
            "Epoch 413: Training Accuracy = 0.8887, Training Loss = 0.6934, Validation Accuracy = 0.0109, Validation Loss = 7.8257\n",
            "Epoch 414/2500\n",
            "Epoch 414: Training Accuracy = 0.9688, Training Loss = 0.3613, Validation Accuracy = 0.0103, Validation Loss = 8.0231\n",
            "Epoch 415/2500\n",
            "Epoch 415: Training Accuracy = 0.9688, Training Loss = 0.3613, Validation Accuracy = 0.0103, Validation Loss = 8.0231\n",
            "Epoch 416/2500\n",
            "Epoch 416: Training Accuracy = 0.9922, Training Loss = 0.2384, Validation Accuracy = 0.0112, Validation Loss = 8.0195\n",
            "Epoch 417/2500\n",
            "Epoch 417: Training Accuracy = 0.9844, Training Loss = 0.1931, Validation Accuracy = 0.0109, Validation Loss = 8.1426\n",
            "Epoch 418/2500\n",
            "Epoch 418: Training Accuracy = 0.9844, Training Loss = 0.1931, Validation Accuracy = 0.0109, Validation Loss = 8.1426\n",
            "Epoch 419/2500\n",
            "Epoch 419: Training Accuracy = 0.9863, Training Loss = 0.1719, Validation Accuracy = 0.0108, Validation Loss = 8.1512\n",
            "Epoch 420/2500\n",
            "Epoch 420: Training Accuracy = 0.9863, Training Loss = 0.1719, Validation Accuracy = 0.0108, Validation Loss = 8.1512\n",
            "Epoch 421/2500\n",
            "Epoch 421: Training Accuracy = 0.9863, Training Loss = 0.1546, Validation Accuracy = 0.0114, Validation Loss = 8.1603\n",
            "Epoch 422/2500\n",
            "Epoch 422: Training Accuracy = 0.9844, Training Loss = 0.1759, Validation Accuracy = 0.0108, Validation Loss = 8.1325\n",
            "Epoch 423/2500\n",
            "Epoch 423: Training Accuracy = 0.9844, Training Loss = 0.1759, Validation Accuracy = 0.0108, Validation Loss = 8.1325\n",
            "Epoch 424/2500\n",
            "Epoch 424: Training Accuracy = 0.9883, Training Loss = 0.1497, Validation Accuracy = 0.0111, Validation Loss = 8.1516\n",
            "Epoch 425/2500\n",
            "Epoch 425: Training Accuracy = 0.9883, Training Loss = 0.1497, Validation Accuracy = 0.0111, Validation Loss = 8.1516\n",
            "Epoch 426/2500\n",
            "Epoch 426: Training Accuracy = 0.9883, Training Loss = 0.1441, Validation Accuracy = 0.0114, Validation Loss = 8.1241\n",
            "Epoch 427/2500\n",
            "Epoch 427: Training Accuracy = 0.9863, Training Loss = 0.1574, Validation Accuracy = 0.0117, Validation Loss = 8.0912\n",
            "Epoch 428/2500\n",
            "Epoch 428: Training Accuracy = 0.9863, Training Loss = 0.1574, Validation Accuracy = 0.0117, Validation Loss = 8.0912\n",
            "Epoch 429/2500\n",
            "Epoch 429: Training Accuracy = 0.9707, Training Loss = 0.3468, Validation Accuracy = 0.0124, Validation Loss = 8.3050\n",
            "Epoch 430/2500\n",
            "Epoch 430: Training Accuracy = 0.9707, Training Loss = 0.3468, Validation Accuracy = 0.0124, Validation Loss = 8.3050\n",
            "Epoch 431/2500\n",
            "Epoch 431: Training Accuracy = 0.8457, Training Loss = 0.7568, Validation Accuracy = 0.0105, Validation Loss = 7.7273\n",
            "Epoch 432/2500\n",
            "Epoch 432: Training Accuracy = 0.9629, Training Loss = 0.4114, Validation Accuracy = 0.0108, Validation Loss = 7.9863\n",
            "Epoch 433/2500\n",
            "Epoch 433: Training Accuracy = 0.9629, Training Loss = 0.4114, Validation Accuracy = 0.0108, Validation Loss = 7.9863\n",
            "Epoch 434/2500\n",
            "Epoch 434: Training Accuracy = 0.9883, Training Loss = 0.2416, Validation Accuracy = 0.0114, Validation Loss = 8.0732\n",
            "Epoch 435/2500\n",
            "Epoch 435: Training Accuracy = 0.9883, Training Loss = 0.2416, Validation Accuracy = 0.0114, Validation Loss = 8.0732\n",
            "Epoch 436/2500\n",
            "Epoch 436: Training Accuracy = 0.9941, Training Loss = 0.1760, Validation Accuracy = 0.0106, Validation Loss = 8.0672\n",
            "Epoch 437/2500\n",
            "Epoch 437: Training Accuracy = 0.9902, Training Loss = 0.1760, Validation Accuracy = 0.0109, Validation Loss = 8.1180\n",
            "Epoch 438/2500\n",
            "Epoch 438: Training Accuracy = 0.9902, Training Loss = 0.1760, Validation Accuracy = 0.0109, Validation Loss = 8.1180\n",
            "Epoch 439/2500\n",
            "Epoch 439: Training Accuracy = 0.9824, Training Loss = 0.1757, Validation Accuracy = 0.0108, Validation Loss = 8.1070\n",
            "Epoch 440/2500\n",
            "Epoch 440: Training Accuracy = 0.9824, Training Loss = 0.1757, Validation Accuracy = 0.0108, Validation Loss = 8.1070\n",
            "Epoch 441/2500\n",
            "Epoch 441: Training Accuracy = 0.9941, Training Loss = 0.1301, Validation Accuracy = 0.0109, Validation Loss = 8.0962\n",
            "Epoch 442/2500\n",
            "Epoch 442: Training Accuracy = 0.9922, Training Loss = 0.1527, Validation Accuracy = 0.0106, Validation Loss = 8.0748\n",
            "Epoch 443/2500\n",
            "Epoch 443: Training Accuracy = 0.9922, Training Loss = 0.1527, Validation Accuracy = 0.0106, Validation Loss = 8.0748\n",
            "Epoch 444/2500\n",
            "Epoch 444: Training Accuracy = 0.9980, Training Loss = 0.1169, Validation Accuracy = 0.0111, Validation Loss = 8.0823\n",
            "Epoch 445/2500\n",
            "Epoch 445: Training Accuracy = 0.9980, Training Loss = 0.1169, Validation Accuracy = 0.0111, Validation Loss = 8.0823\n",
            "Epoch 446/2500\n",
            "Epoch 446: Training Accuracy = 0.9922, Training Loss = 0.1506, Validation Accuracy = 0.0111, Validation Loss = 8.0650\n",
            "Epoch 447/2500\n",
            "Epoch 447: Training Accuracy = 0.9883, Training Loss = 0.1782, Validation Accuracy = 0.0108, Validation Loss = 8.0792\n",
            "Epoch 448/2500\n",
            "Epoch 448: Training Accuracy = 0.9883, Training Loss = 0.1782, Validation Accuracy = 0.0108, Validation Loss = 8.0792\n",
            "Epoch 449/2500\n",
            "Epoch 449: Training Accuracy = 0.9863, Training Loss = 0.2715, Validation Accuracy = 0.0115, Validation Loss = 8.0951\n",
            "Epoch 450/2500\n",
            "Epoch 450: Training Accuracy = 0.9863, Training Loss = 0.2715, Validation Accuracy = 0.0115, Validation Loss = 8.0951\n",
            "Epoch 451/2500\n",
            "Epoch 451: Training Accuracy = 0.9102, Training Loss = 0.6263, Validation Accuracy = 0.0111, Validation Loss = 7.6870\n",
            "Epoch 452/2500\n",
            "Epoch 452: Training Accuracy = 0.9668, Training Loss = 0.4285, Validation Accuracy = 0.0106, Validation Loss = 7.8752\n",
            "Epoch 453/2500\n",
            "Epoch 453: Training Accuracy = 0.9668, Training Loss = 0.4285, Validation Accuracy = 0.0106, Validation Loss = 7.8752\n",
            "Epoch 454/2500\n",
            "Epoch 454: Training Accuracy = 0.9883, Training Loss = 0.2713, Validation Accuracy = 0.0112, Validation Loss = 7.9964\n",
            "Epoch 455/2500\n",
            "Epoch 455: Training Accuracy = 0.9883, Training Loss = 0.2713, Validation Accuracy = 0.0112, Validation Loss = 7.9964\n",
            "Epoch 456/2500\n",
            "Epoch 456: Training Accuracy = 0.9766, Training Loss = 0.2375, Validation Accuracy = 0.0114, Validation Loss = 8.0579\n",
            "Epoch 457/2500\n",
            "Epoch 457: Training Accuracy = 0.9844, Training Loss = 0.1944, Validation Accuracy = 0.0111, Validation Loss = 8.0645\n",
            "Epoch 458/2500\n",
            "Epoch 458: Training Accuracy = 0.9844, Training Loss = 0.1944, Validation Accuracy = 0.0111, Validation Loss = 8.0645\n",
            "Epoch 459/2500\n",
            "Epoch 459: Training Accuracy = 0.9961, Training Loss = 0.1252, Validation Accuracy = 0.0115, Validation Loss = 8.0714\n",
            "Epoch 460/2500\n",
            "Epoch 460: Training Accuracy = 0.9961, Training Loss = 0.1252, Validation Accuracy = 0.0115, Validation Loss = 8.0714\n",
            "Epoch 461/2500\n",
            "Epoch 461: Training Accuracy = 0.9902, Training Loss = 0.1465, Validation Accuracy = 0.0114, Validation Loss = 8.0696\n",
            "Epoch 462/2500\n",
            "Epoch 462: Training Accuracy = 0.9844, Training Loss = 0.1787, Validation Accuracy = 0.0112, Validation Loss = 8.0614\n",
            "Epoch 463/2500\n",
            "Epoch 463: Training Accuracy = 0.9844, Training Loss = 0.1787, Validation Accuracy = 0.0112, Validation Loss = 8.0614\n",
            "Epoch 464/2500\n",
            "Epoch 464: Training Accuracy = 0.9863, Training Loss = 0.1640, Validation Accuracy = 0.0111, Validation Loss = 8.0269\n",
            "Epoch 465/2500\n",
            "Epoch 465: Training Accuracy = 0.9863, Training Loss = 0.1640, Validation Accuracy = 0.0111, Validation Loss = 8.0269\n",
            "Epoch 466/2500\n",
            "Epoch 466: Training Accuracy = 0.9922, Training Loss = 0.1374, Validation Accuracy = 0.0114, Validation Loss = 8.0166\n",
            "Epoch 467/2500\n",
            "Epoch 467: Training Accuracy = 0.9863, Training Loss = 0.1931, Validation Accuracy = 0.0112, Validation Loss = 7.9828\n",
            "Epoch 468/2500\n",
            "Epoch 468: Training Accuracy = 0.9863, Training Loss = 0.1931, Validation Accuracy = 0.0112, Validation Loss = 7.9828\n",
            "Epoch 469/2500\n",
            "Epoch 469: Training Accuracy = 0.9805, Training Loss = 0.2196, Validation Accuracy = 0.0115, Validation Loss = 7.9948\n",
            "Epoch 470/2500\n",
            "Epoch 470: Training Accuracy = 0.9805, Training Loss = 0.2196, Validation Accuracy = 0.0115, Validation Loss = 7.9948\n",
            "Epoch 471/2500\n",
            "Epoch 471: Training Accuracy = 0.7422, Training Loss = 1.1166, Validation Accuracy = 0.0115, Validation Loss = 7.7903\n",
            "Epoch 472/2500\n",
            "Epoch 472: Training Accuracy = 0.9473, Training Loss = 0.4628, Validation Accuracy = 0.0111, Validation Loss = 7.8544\n",
            "Epoch 473/2500\n",
            "Epoch 473: Training Accuracy = 0.9473, Training Loss = 0.4628, Validation Accuracy = 0.0111, Validation Loss = 7.8544\n",
            "Epoch 474/2500\n",
            "Epoch 474: Training Accuracy = 0.9863, Training Loss = 0.2666, Validation Accuracy = 0.0108, Validation Loss = 7.9090\n",
            "Epoch 475/2500\n",
            "Epoch 475: Training Accuracy = 0.9863, Training Loss = 0.2666, Validation Accuracy = 0.0108, Validation Loss = 7.9090\n",
            "Epoch 476/2500\n",
            "Epoch 476: Training Accuracy = 0.9883, Training Loss = 0.2092, Validation Accuracy = 0.0105, Validation Loss = 7.9906\n",
            "Epoch 477/2500\n",
            "Epoch 477: Training Accuracy = 1.0000, Training Loss = 0.1451, Validation Accuracy = 0.0114, Validation Loss = 8.0674\n",
            "Epoch 478/2500\n",
            "Epoch 478: Training Accuracy = 1.0000, Training Loss = 0.1451, Validation Accuracy = 0.0114, Validation Loss = 8.0674\n",
            "Epoch 479/2500\n",
            "Epoch 479: Training Accuracy = 0.9824, Training Loss = 0.1727, Validation Accuracy = 0.0106, Validation Loss = 8.0658\n",
            "Epoch 480/2500\n",
            "Epoch 480: Training Accuracy = 0.9824, Training Loss = 0.1727, Validation Accuracy = 0.0106, Validation Loss = 8.0658\n",
            "Epoch 481/2500\n",
            "Epoch 481: Training Accuracy = 0.9902, Training Loss = 0.1533, Validation Accuracy = 0.0108, Validation Loss = 8.0374\n",
            "Epoch 482/2500\n",
            "Epoch 482: Training Accuracy = 0.9824, Training Loss = 0.1794, Validation Accuracy = 0.0109, Validation Loss = 8.0316\n",
            "Epoch 483/2500\n",
            "Epoch 483: Training Accuracy = 0.9824, Training Loss = 0.1794, Validation Accuracy = 0.0109, Validation Loss = 8.0316\n",
            "Epoch 484/2500\n",
            "Epoch 484: Training Accuracy = 0.9805, Training Loss = 0.1800, Validation Accuracy = 0.0111, Validation Loss = 8.0599\n",
            "Epoch 485/2500\n",
            "Epoch 485: Training Accuracy = 0.9805, Training Loss = 0.1800, Validation Accuracy = 0.0111, Validation Loss = 8.0599\n",
            "Epoch 486/2500\n",
            "Epoch 486: Training Accuracy = 0.9863, Training Loss = 0.1788, Validation Accuracy = 0.0114, Validation Loss = 7.9946\n",
            "Epoch 487/2500\n",
            "Epoch 487: Training Accuracy = 0.9883, Training Loss = 0.2099, Validation Accuracy = 0.0109, Validation Loss = 7.9742\n",
            "Epoch 488/2500\n",
            "Epoch 488: Training Accuracy = 0.9883, Training Loss = 0.2099, Validation Accuracy = 0.0109, Validation Loss = 7.9742\n",
            "Epoch 489/2500\n",
            "Epoch 489: Training Accuracy = 0.8809, Training Loss = 0.6631, Validation Accuracy = 0.0115, Validation Loss = 8.0038\n",
            "Epoch 490/2500\n",
            "Epoch 490: Training Accuracy = 0.8809, Training Loss = 0.6631, Validation Accuracy = 0.0115, Validation Loss = 8.0038\n",
            "Epoch 491/2500\n",
            "Epoch 491: Training Accuracy = 0.9082, Training Loss = 0.6276, Validation Accuracy = 0.0103, Validation Loss = 7.6607\n",
            "Epoch 492/2500\n",
            "Epoch 492: Training Accuracy = 0.9727, Training Loss = 0.3742, Validation Accuracy = 0.0109, Validation Loss = 7.8553\n",
            "Epoch 493/2500\n",
            "Epoch 493: Training Accuracy = 0.9727, Training Loss = 0.3742, Validation Accuracy = 0.0109, Validation Loss = 7.8553\n",
            "Epoch 494/2500\n",
            "Epoch 494: Training Accuracy = 0.9863, Training Loss = 0.2479, Validation Accuracy = 0.0105, Validation Loss = 7.9874\n",
            "Epoch 495/2500\n",
            "Epoch 495: Training Accuracy = 0.9863, Training Loss = 0.2479, Validation Accuracy = 0.0105, Validation Loss = 7.9874\n",
            "Epoch 496/2500\n",
            "Epoch 496: Training Accuracy = 0.9844, Training Loss = 0.1882, Validation Accuracy = 0.0103, Validation Loss = 8.0448\n",
            "Epoch 497/2500\n",
            "Epoch 497: Training Accuracy = 0.9863, Training Loss = 0.1658, Validation Accuracy = 0.0117, Validation Loss = 8.0489\n",
            "Epoch 498/2500\n",
            "Epoch 498: Training Accuracy = 0.9863, Training Loss = 0.1658, Validation Accuracy = 0.0117, Validation Loss = 8.0489\n",
            "Epoch 499/2500\n",
            "Epoch 499: Training Accuracy = 0.9883, Training Loss = 0.1484, Validation Accuracy = 0.0112, Validation Loss = 8.0567\n",
            "Epoch 500/2500\n",
            "Epoch 500: Training Accuracy = 0.9883, Training Loss = 0.1484, Validation Accuracy = 0.0112, Validation Loss = 8.0567\n",
            "Epoch 501/2500\n",
            "Epoch 501: Training Accuracy = 0.9863, Training Loss = 0.1530, Validation Accuracy = 0.0115, Validation Loss = 8.0674\n",
            "Epoch 502/2500\n",
            "Epoch 502: Training Accuracy = 0.9922, Training Loss = 0.1338, Validation Accuracy = 0.0109, Validation Loss = 8.0478\n",
            "Epoch 503/2500\n",
            "Epoch 503: Training Accuracy = 0.9922, Training Loss = 0.1338, Validation Accuracy = 0.0109, Validation Loss = 8.0478\n",
            "Epoch 504/2500\n",
            "Epoch 504: Training Accuracy = 0.9941, Training Loss = 0.1205, Validation Accuracy = 0.0118, Validation Loss = 8.0263\n",
            "Epoch 505/2500\n",
            "Epoch 505: Training Accuracy = 0.9941, Training Loss = 0.1205, Validation Accuracy = 0.0118, Validation Loss = 8.0263\n",
            "Epoch 506/2500\n",
            "Epoch 506: Training Accuracy = 0.9922, Training Loss = 0.1325, Validation Accuracy = 0.0109, Validation Loss = 7.9858\n",
            "Epoch 507/2500\n",
            "Epoch 507: Training Accuracy = 0.6016, Training Loss = 1.5282, Validation Accuracy = 0.0164, Validation Loss = 7.5032\n",
            "Epoch 508/2500\n",
            "Epoch 508: Training Accuracy = 0.6016, Training Loss = 1.5282, Validation Accuracy = 0.0164, Validation Loss = 7.5032\n",
            "Epoch 509/2500\n",
            "Epoch 509: Training Accuracy = 0.8438, Training Loss = 0.8780, Validation Accuracy = 0.0103, Validation Loss = 7.5549\n",
            "Epoch 510/2500\n",
            "Epoch 510: Training Accuracy = 0.8438, Training Loss = 0.8780, Validation Accuracy = 0.0103, Validation Loss = 7.5549\n",
            "Epoch 511/2500\n",
            "Epoch 511: Training Accuracy = 0.9707, Training Loss = 0.3908, Validation Accuracy = 0.0114, Validation Loss = 7.7988\n",
            "Epoch 512/2500\n",
            "Epoch 512: Training Accuracy = 0.9883, Training Loss = 0.2615, Validation Accuracy = 0.0111, Validation Loss = 7.9363\n",
            "Epoch 513/2500\n",
            "Epoch 513: Training Accuracy = 0.9883, Training Loss = 0.2615, Validation Accuracy = 0.0111, Validation Loss = 7.9363\n",
            "Epoch 514/2500\n",
            "Epoch 514: Training Accuracy = 0.9922, Training Loss = 0.1645, Validation Accuracy = 0.0109, Validation Loss = 8.0102\n",
            "Epoch 515/2500\n",
            "Epoch 515: Training Accuracy = 0.9922, Training Loss = 0.1645, Validation Accuracy = 0.0109, Validation Loss = 8.0102\n",
            "Epoch 516/2500\n",
            "Epoch 516: Training Accuracy = 0.9863, Training Loss = 0.1652, Validation Accuracy = 0.0112, Validation Loss = 8.0485\n",
            "Epoch 517/2500\n",
            "Epoch 517: Training Accuracy = 0.9805, Training Loss = 0.1845, Validation Accuracy = 0.0111, Validation Loss = 8.0345\n",
            "Epoch 518/2500\n",
            "Epoch 518: Training Accuracy = 0.9805, Training Loss = 0.1845, Validation Accuracy = 0.0111, Validation Loss = 8.0345\n",
            "Epoch 519/2500\n",
            "Epoch 519: Training Accuracy = 0.9922, Training Loss = 0.1292, Validation Accuracy = 0.0109, Validation Loss = 8.0298\n",
            "Epoch 520/2500\n",
            "Epoch 520: Training Accuracy = 0.9922, Training Loss = 0.1292, Validation Accuracy = 0.0109, Validation Loss = 8.0298\n",
            "Epoch 521/2500\n",
            "Epoch 521: Training Accuracy = 0.9863, Training Loss = 0.1588, Validation Accuracy = 0.0105, Validation Loss = 7.9764\n",
            "Epoch 522/2500\n",
            "Epoch 522: Training Accuracy = 0.9980, Training Loss = 0.1443, Validation Accuracy = 0.0103, Validation Loss = 7.9903\n",
            "Epoch 523/2500\n",
            "Epoch 523: Training Accuracy = 0.9980, Training Loss = 0.1443, Validation Accuracy = 0.0103, Validation Loss = 7.9903\n",
            "Epoch 524/2500\n",
            "Epoch 524: Training Accuracy = 0.9922, Training Loss = 0.2213, Validation Accuracy = 0.0115, Validation Loss = 7.8698\n",
            "Epoch 525/2500\n",
            "Epoch 525: Training Accuracy = 0.9922, Training Loss = 0.2213, Validation Accuracy = 0.0115, Validation Loss = 7.8698\n",
            "Epoch 526/2500\n",
            "Epoch 526: Training Accuracy = 0.8242, Training Loss = 0.8535, Validation Accuracy = 0.0115, Validation Loss = 7.7460\n",
            "Epoch 527/2500\n",
            "Epoch 527: Training Accuracy = 0.9492, Training Loss = 0.4670, Validation Accuracy = 0.0108, Validation Loss = 7.9031\n",
            "Epoch 528/2500\n",
            "Epoch 528: Training Accuracy = 0.9492, Training Loss = 0.4670, Validation Accuracy = 0.0108, Validation Loss = 7.9031\n",
            "Epoch 529/2500\n",
            "Epoch 529: Training Accuracy = 0.9902, Training Loss = 0.2660, Validation Accuracy = 0.0105, Validation Loss = 7.8603\n",
            "Epoch 530/2500\n",
            "Epoch 530: Training Accuracy = 0.9902, Training Loss = 0.2660, Validation Accuracy = 0.0105, Validation Loss = 7.8603\n",
            "Epoch 531/2500\n",
            "Epoch 531: Training Accuracy = 0.9844, Training Loss = 0.2002, Validation Accuracy = 0.0111, Validation Loss = 7.9030\n",
            "Epoch 532/2500\n",
            "Epoch 532: Training Accuracy = 0.9902, Training Loss = 0.1784, Validation Accuracy = 0.0109, Validation Loss = 7.9973\n",
            "Epoch 533/2500\n",
            "Epoch 533: Training Accuracy = 0.9902, Training Loss = 0.1784, Validation Accuracy = 0.0109, Validation Loss = 7.9973\n",
            "Epoch 534/2500\n",
            "Epoch 534: Training Accuracy = 0.9824, Training Loss = 0.2056, Validation Accuracy = 0.0109, Validation Loss = 8.0199\n",
            "Epoch 535/2500\n",
            "Epoch 535: Training Accuracy = 0.9824, Training Loss = 0.2056, Validation Accuracy = 0.0109, Validation Loss = 8.0199\n",
            "Epoch 536/2500\n",
            "Epoch 536: Training Accuracy = 0.9805, Training Loss = 0.1859, Validation Accuracy = 0.0109, Validation Loss = 7.9750\n",
            "Epoch 537/2500\n",
            "Epoch 537: Training Accuracy = 0.9785, Training Loss = 0.1902, Validation Accuracy = 0.0118, Validation Loss = 7.9682\n",
            "Epoch 538/2500\n",
            "Epoch 538: Training Accuracy = 0.9785, Training Loss = 0.1902, Validation Accuracy = 0.0118, Validation Loss = 7.9682\n",
            "Epoch 539/2500\n",
            "Epoch 539: Training Accuracy = 0.9941, Training Loss = 0.1430, Validation Accuracy = 0.0106, Validation Loss = 7.9800\n",
            "Epoch 540/2500\n",
            "Epoch 540: Training Accuracy = 0.9941, Training Loss = 0.1430, Validation Accuracy = 0.0106, Validation Loss = 7.9800\n",
            "Epoch 541/2500\n",
            "Epoch 541: Training Accuracy = 0.9902, Training Loss = 0.1751, Validation Accuracy = 0.0117, Validation Loss = 7.8344\n",
            "Epoch 542/2500\n",
            "Epoch 542: Training Accuracy = 0.7676, Training Loss = 1.0951, Validation Accuracy = 0.0109, Validation Loss = 7.5038\n",
            "Epoch 543/2500\n",
            "Epoch 543: Training Accuracy = 0.7676, Training Loss = 1.0951, Validation Accuracy = 0.0109, Validation Loss = 7.5038\n",
            "Epoch 544/2500\n",
            "Epoch 544: Training Accuracy = 0.9336, Training Loss = 0.5896, Validation Accuracy = 0.0109, Validation Loss = 7.7769\n",
            "Epoch 545/2500\n",
            "Epoch 545: Training Accuracy = 0.9336, Training Loss = 0.5896, Validation Accuracy = 0.0109, Validation Loss = 7.7769\n",
            "Epoch 546/2500\n",
            "Epoch 546: Training Accuracy = 0.9824, Training Loss = 0.3228, Validation Accuracy = 0.0105, Validation Loss = 7.7877\n",
            "Epoch 547/2500\n",
            "Epoch 547: Training Accuracy = 0.9941, Training Loss = 0.2089, Validation Accuracy = 0.0103, Validation Loss = 7.9285\n",
            "Epoch 548/2500\n",
            "Epoch 548: Training Accuracy = 0.9941, Training Loss = 0.2089, Validation Accuracy = 0.0103, Validation Loss = 7.9285\n",
            "Epoch 549/2500\n",
            "Epoch 549: Training Accuracy = 0.9824, Training Loss = 0.1932, Validation Accuracy = 0.0105, Validation Loss = 7.9712\n",
            "Epoch 550/2500\n",
            "Epoch 550: Training Accuracy = 0.9824, Training Loss = 0.1932, Validation Accuracy = 0.0105, Validation Loss = 7.9712\n",
            "Epoch 551/2500\n",
            "Epoch 551: Training Accuracy = 0.9824, Training Loss = 0.1751, Validation Accuracy = 0.0111, Validation Loss = 7.9872\n",
            "Epoch 552/2500\n",
            "Epoch 552: Training Accuracy = 0.9863, Training Loss = 0.1535, Validation Accuracy = 0.0109, Validation Loss = 7.9956\n",
            "Epoch 553/2500\n",
            "Epoch 553: Training Accuracy = 0.9863, Training Loss = 0.1535, Validation Accuracy = 0.0109, Validation Loss = 7.9956\n",
            "Epoch 554/2500\n",
            "Epoch 554: Training Accuracy = 0.9727, Training Loss = 0.2023, Validation Accuracy = 0.0114, Validation Loss = 7.9488\n",
            "Epoch 555/2500\n",
            "Epoch 555: Training Accuracy = 0.9727, Training Loss = 0.2023, Validation Accuracy = 0.0114, Validation Loss = 7.9488\n",
            "Epoch 556/2500\n",
            "Epoch 556: Training Accuracy = 0.9863, Training Loss = 0.1513, Validation Accuracy = 0.0109, Validation Loss = 7.9529\n",
            "Epoch 557/2500\n",
            "Epoch 557: Training Accuracy = 0.9902, Training Loss = 0.1963, Validation Accuracy = 0.0114, Validation Loss = 7.8838\n",
            "Epoch 558/2500\n",
            "Epoch 558: Training Accuracy = 0.9902, Training Loss = 0.1963, Validation Accuracy = 0.0114, Validation Loss = 7.8838\n",
            "Epoch 559/2500\n",
            "Epoch 559: Training Accuracy = 0.7695, Training Loss = 1.1505, Validation Accuracy = 0.0114, Validation Loss = 7.5509\n",
            "Epoch 560/2500\n",
            "Epoch 560: Training Accuracy = 0.7695, Training Loss = 1.1505, Validation Accuracy = 0.0114, Validation Loss = 7.5509\n",
            "Epoch 561/2500\n",
            "Epoch 561: Training Accuracy = 0.9453, Training Loss = 0.4967, Validation Accuracy = 0.0118, Validation Loss = 7.6641\n",
            "Epoch 562/2500\n",
            "Epoch 562: Training Accuracy = 0.9746, Training Loss = 0.3480, Validation Accuracy = 0.0112, Validation Loss = 7.7910\n",
            "Epoch 563/2500\n",
            "Epoch 563: Training Accuracy = 0.9746, Training Loss = 0.3480, Validation Accuracy = 0.0112, Validation Loss = 7.7910\n",
            "Epoch 564/2500\n",
            "Epoch 564: Training Accuracy = 0.9922, Training Loss = 0.1976, Validation Accuracy = 0.0108, Validation Loss = 7.8805\n",
            "Epoch 565/2500\n",
            "Epoch 565: Training Accuracy = 0.9922, Training Loss = 0.1976, Validation Accuracy = 0.0108, Validation Loss = 7.8805\n",
            "Epoch 566/2500\n",
            "Epoch 566: Training Accuracy = 0.9863, Training Loss = 0.1841, Validation Accuracy = 0.0114, Validation Loss = 7.9179\n",
            "Epoch 567/2500\n",
            "Epoch 567: Training Accuracy = 0.9883, Training Loss = 0.1600, Validation Accuracy = 0.0115, Validation Loss = 7.9364\n",
            "Epoch 568/2500\n",
            "Epoch 568: Training Accuracy = 0.9883, Training Loss = 0.1600, Validation Accuracy = 0.0115, Validation Loss = 7.9364\n",
            "Epoch 569/2500\n",
            "Epoch 569: Training Accuracy = 0.9863, Training Loss = 0.1599, Validation Accuracy = 0.0109, Validation Loss = 7.9186\n",
            "Epoch 570/2500\n",
            "Epoch 570: Training Accuracy = 0.9863, Training Loss = 0.1599, Validation Accuracy = 0.0109, Validation Loss = 7.9186\n",
            "Epoch 571/2500\n",
            "Epoch 571: Training Accuracy = 0.9824, Training Loss = 0.1719, Validation Accuracy = 0.0114, Validation Loss = 7.8851\n",
            "Epoch 572/2500\n",
            "Epoch 572: Training Accuracy = 0.9961, Training Loss = 0.1279, Validation Accuracy = 0.0112, Validation Loss = 7.8781\n",
            "Epoch 573/2500\n",
            "Epoch 573: Training Accuracy = 0.9961, Training Loss = 0.1279, Validation Accuracy = 0.0112, Validation Loss = 7.8781\n",
            "Epoch 574/2500\n",
            "Epoch 574: Training Accuracy = 0.9766, Training Loss = 0.2121, Validation Accuracy = 0.0114, Validation Loss = 7.8427\n",
            "Epoch 575/2500\n",
            "Epoch 575: Training Accuracy = 0.9766, Training Loss = 0.2121, Validation Accuracy = 0.0114, Validation Loss = 7.8427\n",
            "Epoch 576/2500\n",
            "Epoch 576: Training Accuracy = 0.9922, Training Loss = 0.1563, Validation Accuracy = 0.0112, Validation Loss = 7.8013\n",
            "Epoch 577/2500\n",
            "Epoch 577: Training Accuracy = 0.7324, Training Loss = 1.1776, Validation Accuracy = 0.0117, Validation Loss = 7.5282\n",
            "Epoch 578/2500\n",
            "Epoch 578: Training Accuracy = 0.7324, Training Loss = 1.1776, Validation Accuracy = 0.0117, Validation Loss = 7.5282\n",
            "Epoch 579/2500\n",
            "Epoch 579: Training Accuracy = 0.9551, Training Loss = 0.5619, Validation Accuracy = 0.0108, Validation Loss = 7.6303\n",
            "Epoch 580/2500\n",
            "Epoch 580: Training Accuracy = 0.9551, Training Loss = 0.5619, Validation Accuracy = 0.0108, Validation Loss = 7.6303\n",
            "Epoch 581/2500\n",
            "Epoch 581: Training Accuracy = 0.9785, Training Loss = 0.3786, Validation Accuracy = 0.0108, Validation Loss = 7.6208\n",
            "Epoch 582/2500\n",
            "Epoch 582: Training Accuracy = 0.9902, Training Loss = 0.2321, Validation Accuracy = 0.0114, Validation Loss = 7.7796\n",
            "Epoch 583/2500\n",
            "Epoch 583: Training Accuracy = 0.9902, Training Loss = 0.2321, Validation Accuracy = 0.0114, Validation Loss = 7.7796\n",
            "Epoch 584/2500\n",
            "Epoch 584: Training Accuracy = 0.9922, Training Loss = 0.1807, Validation Accuracy = 0.0111, Validation Loss = 7.8145\n",
            "Epoch 585/2500\n",
            "Epoch 585: Training Accuracy = 0.9922, Training Loss = 0.1807, Validation Accuracy = 0.0111, Validation Loss = 7.8145\n",
            "Epoch 586/2500\n",
            "Epoch 586: Training Accuracy = 0.9902, Training Loss = 0.1574, Validation Accuracy = 0.0112, Validation Loss = 7.8186\n",
            "Epoch 587/2500\n",
            "Epoch 587: Training Accuracy = 0.9883, Training Loss = 0.1699, Validation Accuracy = 0.0106, Validation Loss = 7.8245\n",
            "Epoch 588/2500\n",
            "Epoch 588: Training Accuracy = 0.9883, Training Loss = 0.1699, Validation Accuracy = 0.0106, Validation Loss = 7.8245\n",
            "Epoch 589/2500\n",
            "Epoch 589: Training Accuracy = 0.9883, Training Loss = 0.1560, Validation Accuracy = 0.0115, Validation Loss = 7.8152\n",
            "Epoch 590/2500\n",
            "Epoch 590: Training Accuracy = 0.9883, Training Loss = 0.1560, Validation Accuracy = 0.0115, Validation Loss = 7.8152\n",
            "Epoch 591/2500\n",
            "Epoch 591: Training Accuracy = 0.9805, Training Loss = 0.1925, Validation Accuracy = 0.0111, Validation Loss = 7.7966\n",
            "Epoch 592/2500\n",
            "Epoch 592: Training Accuracy = 0.9883, Training Loss = 0.1736, Validation Accuracy = 0.0106, Validation Loss = 7.8135\n",
            "Epoch 593/2500\n",
            "Epoch 593: Training Accuracy = 0.9883, Training Loss = 0.1736, Validation Accuracy = 0.0106, Validation Loss = 7.8135\n",
            "Epoch 594/2500\n",
            "Epoch 594: Training Accuracy = 0.9941, Training Loss = 0.1684, Validation Accuracy = 0.0120, Validation Loss = 7.7072\n",
            "Epoch 595/2500\n",
            "Epoch 595: Training Accuracy = 0.9941, Training Loss = 0.1684, Validation Accuracy = 0.0120, Validation Loss = 7.7072\n",
            "Epoch 596/2500\n",
            "Epoch 596: Training Accuracy = 0.8008, Training Loss = 1.0309, Validation Accuracy = 0.0118, Validation Loss = 7.4043\n",
            "Epoch 597/2500\n",
            "Epoch 597: Training Accuracy = 0.9043, Training Loss = 0.6940, Validation Accuracy = 0.0108, Validation Loss = 7.6129\n",
            "Epoch 598/2500\n",
            "Epoch 598: Training Accuracy = 0.9043, Training Loss = 0.6940, Validation Accuracy = 0.0108, Validation Loss = 7.6129\n",
            "Epoch 599/2500\n",
            "Epoch 599: Training Accuracy = 0.9766, Training Loss = 0.3569, Validation Accuracy = 0.0120, Validation Loss = 7.6402\n",
            "Epoch 600/2500\n",
            "Epoch 600: Training Accuracy = 0.9766, Training Loss = 0.3569, Validation Accuracy = 0.0120, Validation Loss = 7.6402\n",
            "Epoch 601/2500\n",
            "Epoch 601: Training Accuracy = 0.9824, Training Loss = 0.2510, Validation Accuracy = 0.0112, Validation Loss = 7.6845\n",
            "Epoch 602/2500\n",
            "Epoch 602: Training Accuracy = 0.9863, Training Loss = 0.2035, Validation Accuracy = 0.0115, Validation Loss = 7.7273\n",
            "Epoch 603/2500\n",
            "Epoch 603: Training Accuracy = 0.9863, Training Loss = 0.2035, Validation Accuracy = 0.0115, Validation Loss = 7.7273\n",
            "Epoch 604/2500\n",
            "Epoch 604: Training Accuracy = 0.9883, Training Loss = 0.1693, Validation Accuracy = 0.0115, Validation Loss = 7.7593\n",
            "Epoch 605/2500\n",
            "Epoch 605: Training Accuracy = 0.9883, Training Loss = 0.1693, Validation Accuracy = 0.0115, Validation Loss = 7.7593\n",
            "Epoch 606/2500\n",
            "Epoch 606: Training Accuracy = 0.9961, Training Loss = 0.1387, Validation Accuracy = 0.0112, Validation Loss = 7.7607\n",
            "Epoch 607/2500\n",
            "Epoch 607: Training Accuracy = 0.9922, Training Loss = 0.1442, Validation Accuracy = 0.0115, Validation Loss = 7.7275\n",
            "Epoch 608/2500\n",
            "Epoch 608: Training Accuracy = 0.9922, Training Loss = 0.1442, Validation Accuracy = 0.0115, Validation Loss = 7.7275\n",
            "Epoch 609/2500\n",
            "Epoch 609: Training Accuracy = 0.9922, Training Loss = 0.1477, Validation Accuracy = 0.0114, Validation Loss = 7.7000\n",
            "Epoch 610/2500\n",
            "Epoch 610: Training Accuracy = 0.9922, Training Loss = 0.1477, Validation Accuracy = 0.0114, Validation Loss = 7.7000\n",
            "Epoch 611/2500\n",
            "Epoch 611: Training Accuracy = 0.9941, Training Loss = 0.1416, Validation Accuracy = 0.0112, Validation Loss = 7.6969\n",
            "Epoch 612/2500\n",
            "Epoch 612: Training Accuracy = 0.9961, Training Loss = 0.1427, Validation Accuracy = 0.0111, Validation Loss = 7.6687\n",
            "Epoch 613/2500\n",
            "Epoch 613: Training Accuracy = 0.9961, Training Loss = 0.1427, Validation Accuracy = 0.0111, Validation Loss = 7.6687\n",
            "Epoch 614/2500\n",
            "Epoch 614: Training Accuracy = 0.9902, Training Loss = 0.1614, Validation Accuracy = 0.0112, Validation Loss = 7.6937\n",
            "Epoch 615/2500\n",
            "Epoch 615: Training Accuracy = 0.9902, Training Loss = 0.1614, Validation Accuracy = 0.0112, Validation Loss = 7.6937\n",
            "Epoch 616/2500\n",
            "Epoch 616: Training Accuracy = 0.7227, Training Loss = 1.3006, Validation Accuracy = 0.0121, Validation Loss = 7.1122\n",
            "Epoch 617/2500\n",
            "Epoch 617: Training Accuracy = 0.9062, Training Loss = 0.7124, Validation Accuracy = 0.0111, Validation Loss = 7.1569\n",
            "Epoch 618/2500\n",
            "Epoch 618: Training Accuracy = 0.9062, Training Loss = 0.7124, Validation Accuracy = 0.0111, Validation Loss = 7.1569\n",
            "Epoch 619/2500\n",
            "Epoch 619: Training Accuracy = 0.9805, Training Loss = 0.3757, Validation Accuracy = 0.0118, Validation Loss = 7.5115\n",
            "Epoch 620/2500\n",
            "Epoch 620: Training Accuracy = 0.9805, Training Loss = 0.3757, Validation Accuracy = 0.0118, Validation Loss = 7.5115\n",
            "Epoch 621/2500\n",
            "Epoch 621: Training Accuracy = 0.9785, Training Loss = 0.2868, Validation Accuracy = 0.0117, Validation Loss = 7.5962\n",
            "Epoch 622/2500\n",
            "Epoch 622: Training Accuracy = 0.9961, Training Loss = 0.1901, Validation Accuracy = 0.0112, Validation Loss = 7.6703\n",
            "Epoch 623/2500\n",
            "Epoch 623: Training Accuracy = 0.9961, Training Loss = 0.1901, Validation Accuracy = 0.0112, Validation Loss = 7.6703\n",
            "Epoch 624/2500\n",
            "Epoch 624: Training Accuracy = 0.9805, Training Loss = 0.2098, Validation Accuracy = 0.0115, Validation Loss = 7.6614\n",
            "Epoch 625/2500\n",
            "Epoch 625: Training Accuracy = 0.9805, Training Loss = 0.2098, Validation Accuracy = 0.0115, Validation Loss = 7.6614\n",
            "Epoch 626/2500\n",
            "Epoch 626: Training Accuracy = 0.9922, Training Loss = 0.1478, Validation Accuracy = 0.0120, Validation Loss = 7.6607\n",
            "Epoch 627/2500\n",
            "Epoch 627: Training Accuracy = 0.9941, Training Loss = 0.1628, Validation Accuracy = 0.0115, Validation Loss = 7.6357\n",
            "Epoch 628/2500\n",
            "Epoch 628: Training Accuracy = 0.9941, Training Loss = 0.1628, Validation Accuracy = 0.0115, Validation Loss = 7.6357\n",
            "Epoch 629/2500\n",
            "Epoch 629: Training Accuracy = 0.9941, Training Loss = 0.1559, Validation Accuracy = 0.0109, Validation Loss = 7.6375\n",
            "Epoch 630/2500\n",
            "Epoch 630: Training Accuracy = 0.9941, Training Loss = 0.1559, Validation Accuracy = 0.0109, Validation Loss = 7.6375\n",
            "Epoch 631/2500\n",
            "Epoch 631: Training Accuracy = 0.9941, Training Loss = 0.1511, Validation Accuracy = 0.0114, Validation Loss = 7.6171\n",
            "Epoch 632/2500\n",
            "Epoch 632: Training Accuracy = 0.9961, Training Loss = 0.1596, Validation Accuracy = 0.0117, Validation Loss = 7.5885\n",
            "Epoch 633/2500\n",
            "Epoch 633: Training Accuracy = 0.9961, Training Loss = 0.1596, Validation Accuracy = 0.0117, Validation Loss = 7.5885\n",
            "Epoch 634/2500\n",
            "Epoch 634: Training Accuracy = 0.9863, Training Loss = 0.2128, Validation Accuracy = 0.0112, Validation Loss = 7.5718\n",
            "Epoch 635/2500\n",
            "Epoch 635: Training Accuracy = 0.9863, Training Loss = 0.2128, Validation Accuracy = 0.0112, Validation Loss = 7.5718\n",
            "Epoch 636/2500\n",
            "Epoch 636: Training Accuracy = 0.9648, Training Loss = 0.3566, Validation Accuracy = 0.0117, Validation Loss = 7.5190\n",
            "Epoch 637/2500\n",
            "Epoch 637: Training Accuracy = 0.9199, Training Loss = 0.6544, Validation Accuracy = 0.0111, Validation Loss = 7.3275\n",
            "Epoch 638/2500\n",
            "Epoch 638: Training Accuracy = 0.9199, Training Loss = 0.6544, Validation Accuracy = 0.0111, Validation Loss = 7.3275\n",
            "Epoch 639/2500\n",
            "Epoch 639: Training Accuracy = 0.9766, Training Loss = 0.3739, Validation Accuracy = 0.0120, Validation Loss = 7.4768\n",
            "Epoch 640/2500\n",
            "Epoch 640: Training Accuracy = 0.9766, Training Loss = 0.3739, Validation Accuracy = 0.0120, Validation Loss = 7.4768\n",
            "Epoch 641/2500\n",
            "Epoch 641: Training Accuracy = 0.9980, Training Loss = 0.2082, Validation Accuracy = 0.0114, Validation Loss = 7.5275\n",
            "Epoch 642/2500\n",
            "Epoch 642: Training Accuracy = 0.9863, Training Loss = 0.2044, Validation Accuracy = 0.0120, Validation Loss = 7.5853\n",
            "Epoch 643/2500\n",
            "Epoch 643: Training Accuracy = 0.9863, Training Loss = 0.2044, Validation Accuracy = 0.0120, Validation Loss = 7.5853\n",
            "Epoch 644/2500\n",
            "Epoch 644: Training Accuracy = 0.9902, Training Loss = 0.1523, Validation Accuracy = 0.0114, Validation Loss = 7.6175\n",
            "Epoch 645/2500\n",
            "Epoch 645: Training Accuracy = 0.9902, Training Loss = 0.1523, Validation Accuracy = 0.0114, Validation Loss = 7.6175\n",
            "Epoch 646/2500\n",
            "Epoch 646: Training Accuracy = 0.9863, Training Loss = 0.1566, Validation Accuracy = 0.0117, Validation Loss = 7.6037\n",
            "Epoch 647/2500\n",
            "Epoch 647: Training Accuracy = 0.9824, Training Loss = 0.1657, Validation Accuracy = 0.0120, Validation Loss = 7.6073\n",
            "Epoch 648/2500\n",
            "Epoch 648: Training Accuracy = 0.9824, Training Loss = 0.1657, Validation Accuracy = 0.0120, Validation Loss = 7.6073\n",
            "Epoch 649/2500\n",
            "Epoch 649: Training Accuracy = 0.9902, Training Loss = 0.1344, Validation Accuracy = 0.0118, Validation Loss = 7.5923\n",
            "Epoch 650/2500\n",
            "Epoch 650: Training Accuracy = 0.9902, Training Loss = 0.1344, Validation Accuracy = 0.0118, Validation Loss = 7.5923\n",
            "Epoch 651/2500\n",
            "Epoch 651: Training Accuracy = 0.9863, Training Loss = 0.1669, Validation Accuracy = 0.0121, Validation Loss = 7.5380\n",
            "Epoch 652/2500\n",
            "Epoch 652: Training Accuracy = 0.9902, Training Loss = 0.1898, Validation Accuracy = 0.0114, Validation Loss = 7.5368\n",
            "Epoch 653/2500\n",
            "Epoch 653: Training Accuracy = 0.9902, Training Loss = 0.1898, Validation Accuracy = 0.0114, Validation Loss = 7.5368\n",
            "Epoch 654/2500\n",
            "Epoch 654: Training Accuracy = 0.9883, Training Loss = 0.2832, Validation Accuracy = 0.0118, Validation Loss = 7.4609\n",
            "Epoch 655/2500\n",
            "Epoch 655: Training Accuracy = 0.9883, Training Loss = 0.2832, Validation Accuracy = 0.0118, Validation Loss = 7.4609\n",
            "Epoch 656/2500\n",
            "Epoch 656: Training Accuracy = 0.9727, Training Loss = 0.3808, Validation Accuracy = 0.0124, Validation Loss = 7.3307\n",
            "Epoch 657/2500\n",
            "Epoch 657: Training Accuracy = 0.9727, Training Loss = 0.3883, Validation Accuracy = 0.0108, Validation Loss = 7.3509\n",
            "Epoch 658/2500\n",
            "Epoch 658: Training Accuracy = 0.9727, Training Loss = 0.3883, Validation Accuracy = 0.0108, Validation Loss = 7.3509\n",
            "Epoch 659/2500\n",
            "Epoch 659: Training Accuracy = 0.9824, Training Loss = 0.2342, Validation Accuracy = 0.0121, Validation Loss = 7.5351\n",
            "Epoch 660/2500\n",
            "Epoch 660: Training Accuracy = 0.9824, Training Loss = 0.2342, Validation Accuracy = 0.0121, Validation Loss = 7.5351\n",
            "Epoch 661/2500\n",
            "Epoch 661: Training Accuracy = 0.9863, Training Loss = 0.2202, Validation Accuracy = 0.0121, Validation Loss = 7.5152\n",
            "Epoch 662/2500\n",
            "Epoch 662: Training Accuracy = 0.9902, Training Loss = 0.1651, Validation Accuracy = 0.0120, Validation Loss = 7.5535\n",
            "Epoch 663/2500\n",
            "Epoch 663: Training Accuracy = 0.9902, Training Loss = 0.1651, Validation Accuracy = 0.0120, Validation Loss = 7.5535\n",
            "Epoch 664/2500\n",
            "Epoch 664: Training Accuracy = 0.9883, Training Loss = 0.1472, Validation Accuracy = 0.0120, Validation Loss = 7.5825\n",
            "Epoch 665/2500\n",
            "Epoch 665: Training Accuracy = 0.9883, Training Loss = 0.1472, Validation Accuracy = 0.0120, Validation Loss = 7.5825\n",
            "Epoch 666/2500\n",
            "Epoch 666: Training Accuracy = 0.9844, Training Loss = 0.1456, Validation Accuracy = 0.0117, Validation Loss = 7.6115\n",
            "Epoch 667/2500\n",
            "Epoch 667: Training Accuracy = 0.9805, Training Loss = 0.1673, Validation Accuracy = 0.0118, Validation Loss = 7.5714\n",
            "Epoch 668/2500\n",
            "Epoch 668: Training Accuracy = 0.9805, Training Loss = 0.1673, Validation Accuracy = 0.0118, Validation Loss = 7.5714\n",
            "Epoch 669/2500\n",
            "Epoch 669: Training Accuracy = 0.9883, Training Loss = 0.1368, Validation Accuracy = 0.0117, Validation Loss = 7.6080\n",
            "Epoch 670/2500\n",
            "Epoch 670: Training Accuracy = 0.9883, Training Loss = 0.1368, Validation Accuracy = 0.0117, Validation Loss = 7.6080\n",
            "Epoch 671/2500\n",
            "Epoch 671: Training Accuracy = 0.9980, Training Loss = 0.1217, Validation Accuracy = 0.0120, Validation Loss = 7.5425\n",
            "Epoch 672/2500\n",
            "Epoch 672: Training Accuracy = 0.9766, Training Loss = 0.3652, Validation Accuracy = 0.0120, Validation Loss = 7.4104\n",
            "Epoch 673/2500\n",
            "Epoch 673: Training Accuracy = 0.9766, Training Loss = 0.3652, Validation Accuracy = 0.0120, Validation Loss = 7.4104\n",
            "Epoch 674/2500\n",
            "Epoch 674: Training Accuracy = 0.9277, Training Loss = 0.5251, Validation Accuracy = 0.0109, Validation Loss = 7.2752\n",
            "Epoch 675/2500\n",
            "Epoch 675: Training Accuracy = 0.9277, Training Loss = 0.5251, Validation Accuracy = 0.0109, Validation Loss = 7.2752\n",
            "Epoch 676/2500\n",
            "Epoch 676: Training Accuracy = 0.9727, Training Loss = 0.3643, Validation Accuracy = 0.0109, Validation Loss = 7.3348\n",
            "Epoch 677/2500\n",
            "Epoch 677: Training Accuracy = 0.9863, Training Loss = 0.2302, Validation Accuracy = 0.0112, Validation Loss = 7.4463\n",
            "Epoch 678/2500\n",
            "Epoch 678: Training Accuracy = 0.9863, Training Loss = 0.2302, Validation Accuracy = 0.0112, Validation Loss = 7.4463\n",
            "Epoch 679/2500\n",
            "Epoch 679: Training Accuracy = 0.9844, Training Loss = 0.1891, Validation Accuracy = 0.0121, Validation Loss = 7.5008\n",
            "Epoch 680/2500\n",
            "Epoch 680: Training Accuracy = 0.9844, Training Loss = 0.1891, Validation Accuracy = 0.0121, Validation Loss = 7.5008\n",
            "Epoch 681/2500\n",
            "Epoch 681: Training Accuracy = 0.9824, Training Loss = 0.1601, Validation Accuracy = 0.0120, Validation Loss = 7.5149\n",
            "Epoch 682/2500\n",
            "Epoch 682: Training Accuracy = 0.9883, Training Loss = 0.1352, Validation Accuracy = 0.0120, Validation Loss = 7.5483\n",
            "Epoch 683/2500\n",
            "Epoch 683: Training Accuracy = 0.9883, Training Loss = 0.1352, Validation Accuracy = 0.0120, Validation Loss = 7.5483\n",
            "Epoch 684/2500\n",
            "Epoch 684: Training Accuracy = 0.9844, Training Loss = 0.1311, Validation Accuracy = 0.0117, Validation Loss = 7.5179\n",
            "Epoch 685/2500\n",
            "Epoch 685: Training Accuracy = 0.9844, Training Loss = 0.1311, Validation Accuracy = 0.0117, Validation Loss = 7.5179\n",
            "Epoch 686/2500\n",
            "Epoch 686: Training Accuracy = 0.9941, Training Loss = 0.1014, Validation Accuracy = 0.0114, Validation Loss = 7.5341\n",
            "Epoch 687/2500\n",
            "Epoch 687: Training Accuracy = 0.9883, Training Loss = 0.1317, Validation Accuracy = 0.0115, Validation Loss = 7.5291\n",
            "Epoch 688/2500\n",
            "Epoch 688: Training Accuracy = 0.9883, Training Loss = 0.1317, Validation Accuracy = 0.0115, Validation Loss = 7.5291\n",
            "Epoch 689/2500\n",
            "Epoch 689: Training Accuracy = 0.9941, Training Loss = 0.1265, Validation Accuracy = 0.0115, Validation Loss = 7.4785\n",
            "Epoch 690/2500\n",
            "Epoch 690: Training Accuracy = 0.9941, Training Loss = 0.1265, Validation Accuracy = 0.0115, Validation Loss = 7.4785\n",
            "Epoch 691/2500\n",
            "Epoch 691: Training Accuracy = 0.9941, Training Loss = 0.1355, Validation Accuracy = 0.0118, Validation Loss = 7.5150\n",
            "Epoch 692/2500\n",
            "Epoch 692: Training Accuracy = 0.9824, Training Loss = 0.2063, Validation Accuracy = 0.0112, Validation Loss = 7.4738\n",
            "Epoch 693/2500\n",
            "Epoch 693: Training Accuracy = 0.9824, Training Loss = 0.2063, Validation Accuracy = 0.0112, Validation Loss = 7.4738\n",
            "Epoch 694/2500\n",
            "Epoch 694: Training Accuracy = 0.6113, Training Loss = 1.5931, Validation Accuracy = 0.0123, Validation Loss = 6.9173\n",
            "Epoch 695/2500\n",
            "Epoch 695: Training Accuracy = 0.6113, Training Loss = 1.5931, Validation Accuracy = 0.0123, Validation Loss = 6.9173\n",
            "Epoch 696/2500\n",
            "Epoch 696: Training Accuracy = 0.9395, Training Loss = 0.5502, Validation Accuracy = 0.0120, Validation Loss = 7.2241\n",
            "Epoch 697/2500\n",
            "Epoch 697: Training Accuracy = 0.9766, Training Loss = 0.3516, Validation Accuracy = 0.0114, Validation Loss = 7.3003\n",
            "Epoch 698/2500\n",
            "Epoch 698: Training Accuracy = 0.9766, Training Loss = 0.3516, Validation Accuracy = 0.0114, Validation Loss = 7.3003\n",
            "Epoch 699/2500\n",
            "Epoch 699: Training Accuracy = 0.9883, Training Loss = 0.2403, Validation Accuracy = 0.0117, Validation Loss = 7.3794\n",
            "Epoch 700/2500\n",
            "Epoch 700: Training Accuracy = 0.9883, Training Loss = 0.2403, Validation Accuracy = 0.0117, Validation Loss = 7.3794\n",
            "Epoch 701/2500\n",
            "Epoch 701: Training Accuracy = 0.9902, Training Loss = 0.1614, Validation Accuracy = 0.0118, Validation Loss = 7.4163\n",
            "Epoch 702/2500\n",
            "Epoch 702: Training Accuracy = 0.9863, Training Loss = 0.1588, Validation Accuracy = 0.0123, Validation Loss = 7.4279\n",
            "Epoch 703/2500\n",
            "Epoch 703: Training Accuracy = 0.9863, Training Loss = 0.1588, Validation Accuracy = 0.0123, Validation Loss = 7.4279\n",
            "Epoch 704/2500\n",
            "Epoch 704: Training Accuracy = 0.9941, Training Loss = 0.1179, Validation Accuracy = 0.0117, Validation Loss = 7.4241\n",
            "Epoch 705/2500\n",
            "Epoch 705: Training Accuracy = 0.9941, Training Loss = 0.1179, Validation Accuracy = 0.0117, Validation Loss = 7.4241\n",
            "Epoch 706/2500\n",
            "Epoch 706: Training Accuracy = 0.9844, Training Loss = 0.1450, Validation Accuracy = 0.0124, Validation Loss = 7.4213\n",
            "Epoch 707/2500\n",
            "Epoch 707: Training Accuracy = 0.9922, Training Loss = 0.1237, Validation Accuracy = 0.0120, Validation Loss = 7.3930\n",
            "Epoch 708/2500\n",
            "Epoch 708: Training Accuracy = 0.9922, Training Loss = 0.1237, Validation Accuracy = 0.0120, Validation Loss = 7.3930\n",
            "Epoch 709/2500\n",
            "Epoch 709: Training Accuracy = 0.9902, Training Loss = 0.1362, Validation Accuracy = 0.0114, Validation Loss = 7.3485\n",
            "Epoch 710/2500\n",
            "Epoch 710: Training Accuracy = 0.9902, Training Loss = 0.1362, Validation Accuracy = 0.0114, Validation Loss = 7.3485\n",
            "Epoch 711/2500\n",
            "Epoch 711: Training Accuracy = 0.9844, Training Loss = 0.1567, Validation Accuracy = 0.0123, Validation Loss = 7.3641\n",
            "Epoch 712/2500\n",
            "Epoch 712: Training Accuracy = 0.9922, Training Loss = 0.1626, Validation Accuracy = 0.0115, Validation Loss = 7.3303\n",
            "Epoch 713/2500\n",
            "Epoch 713: Training Accuracy = 0.9922, Training Loss = 0.1626, Validation Accuracy = 0.0115, Validation Loss = 7.3303\n",
            "Epoch 714/2500\n",
            "Epoch 714: Training Accuracy = 0.9902, Training Loss = 0.2460, Validation Accuracy = 0.0132, Validation Loss = 7.2881\n",
            "Epoch 715/2500\n",
            "Epoch 715: Training Accuracy = 0.9902, Training Loss = 0.2460, Validation Accuracy = 0.0132, Validation Loss = 7.2881\n",
            "Epoch 716/2500\n",
            "Epoch 716: Training Accuracy = 0.9062, Training Loss = 0.6319, Validation Accuracy = 0.0132, Validation Loss = 7.0099\n",
            "Epoch 717/2500\n",
            "Epoch 717: Training Accuracy = 0.9766, Training Loss = 0.3828, Validation Accuracy = 0.0118, Validation Loss = 7.0855\n",
            "Epoch 718/2500\n",
            "Epoch 718: Training Accuracy = 0.9766, Training Loss = 0.3828, Validation Accuracy = 0.0118, Validation Loss = 7.0855\n",
            "Epoch 719/2500\n",
            "Epoch 719: Training Accuracy = 0.9922, Training Loss = 0.2268, Validation Accuracy = 0.0124, Validation Loss = 7.2024\n",
            "Epoch 720/2500\n",
            "Epoch 720: Training Accuracy = 0.9922, Training Loss = 0.2268, Validation Accuracy = 0.0124, Validation Loss = 7.2024\n",
            "Epoch 721/2500\n",
            "Epoch 721: Training Accuracy = 0.9883, Training Loss = 0.1778, Validation Accuracy = 0.0135, Validation Loss = 7.2091\n",
            "Epoch 722/2500\n",
            "Epoch 722: Training Accuracy = 0.9941, Training Loss = 0.1406, Validation Accuracy = 0.0124, Validation Loss = 7.3004\n",
            "Epoch 723/2500\n",
            "Epoch 723: Training Accuracy = 0.9941, Training Loss = 0.1406, Validation Accuracy = 0.0124, Validation Loss = 7.3004\n",
            "Epoch 724/2500\n",
            "Epoch 724: Training Accuracy = 0.9805, Training Loss = 0.1740, Validation Accuracy = 0.0129, Validation Loss = 7.3190\n",
            "Epoch 725/2500\n",
            "Epoch 725: Training Accuracy = 0.9805, Training Loss = 0.1740, Validation Accuracy = 0.0129, Validation Loss = 7.3190\n",
            "Epoch 726/2500\n",
            "Epoch 726: Training Accuracy = 0.9883, Training Loss = 0.1448, Validation Accuracy = 0.0128, Validation Loss = 7.3118\n",
            "Epoch 727/2500\n",
            "Epoch 727: Training Accuracy = 0.9941, Training Loss = 0.1191, Validation Accuracy = 0.0126, Validation Loss = 7.3100\n",
            "Epoch 728/2500\n",
            "Epoch 728: Training Accuracy = 0.9941, Training Loss = 0.1191, Validation Accuracy = 0.0126, Validation Loss = 7.3100\n",
            "Epoch 729/2500\n",
            "Epoch 729: Training Accuracy = 0.9883, Training Loss = 0.1490, Validation Accuracy = 0.0120, Validation Loss = 7.2941\n",
            "Epoch 730/2500\n",
            "Epoch 730: Training Accuracy = 0.9883, Training Loss = 0.1490, Validation Accuracy = 0.0120, Validation Loss = 7.2941\n",
            "Epoch 731/2500\n",
            "Epoch 731: Training Accuracy = 0.9824, Training Loss = 0.2269, Validation Accuracy = 0.0138, Validation Loss = 7.1632\n",
            "Epoch 732/2500\n",
            "Epoch 732: Training Accuracy = 0.7070, Training Loss = 1.1783, Validation Accuracy = 0.0147, Validation Loss = 6.6880\n",
            "Epoch 733/2500\n",
            "Epoch 733: Training Accuracy = 0.7070, Training Loss = 1.1783, Validation Accuracy = 0.0147, Validation Loss = 6.6880\n",
            "Epoch 734/2500\n",
            "Epoch 734: Training Accuracy = 0.9141, Training Loss = 0.6129, Validation Accuracy = 0.0111, Validation Loss = 7.0175\n",
            "Epoch 735/2500\n",
            "Epoch 735: Training Accuracy = 0.9141, Training Loss = 0.6129, Validation Accuracy = 0.0111, Validation Loss = 7.0175\n",
            "Epoch 736/2500\n",
            "Epoch 736: Training Accuracy = 0.9824, Training Loss = 0.2880, Validation Accuracy = 0.0118, Validation Loss = 7.0561\n",
            "Epoch 737/2500\n",
            "Epoch 737: Training Accuracy = 0.9844, Training Loss = 0.2412, Validation Accuracy = 0.0129, Validation Loss = 7.1366\n",
            "Epoch 738/2500\n",
            "Epoch 738: Training Accuracy = 0.9844, Training Loss = 0.2412, Validation Accuracy = 0.0129, Validation Loss = 7.1366\n",
            "Epoch 739/2500\n",
            "Epoch 739: Training Accuracy = 0.9844, Training Loss = 0.1752, Validation Accuracy = 0.0117, Validation Loss = 7.2412\n",
            "Epoch 740/2500\n",
            "Epoch 740: Training Accuracy = 0.9844, Training Loss = 0.1752, Validation Accuracy = 0.0117, Validation Loss = 7.2412\n",
            "Epoch 741/2500\n",
            "Epoch 741: Training Accuracy = 0.9863, Training Loss = 0.1452, Validation Accuracy = 0.0138, Validation Loss = 7.2702\n",
            "Epoch 742/2500\n",
            "Epoch 742: Training Accuracy = 0.9922, Training Loss = 0.1211, Validation Accuracy = 0.0126, Validation Loss = 7.2550\n",
            "Epoch 743/2500\n",
            "Epoch 743: Training Accuracy = 0.9922, Training Loss = 0.1211, Validation Accuracy = 0.0126, Validation Loss = 7.2550\n",
            "Epoch 744/2500\n",
            "Epoch 744: Training Accuracy = 0.9844, Training Loss = 0.1381, Validation Accuracy = 0.0121, Validation Loss = 7.2724\n",
            "Epoch 745/2500\n",
            "Epoch 745: Training Accuracy = 0.9844, Training Loss = 0.1381, Validation Accuracy = 0.0121, Validation Loss = 7.2724\n",
            "Epoch 746/2500\n",
            "Epoch 746: Training Accuracy = 0.9902, Training Loss = 0.1230, Validation Accuracy = 0.0128, Validation Loss = 7.2293\n",
            "Epoch 747/2500\n",
            "Epoch 747: Training Accuracy = 0.9863, Training Loss = 0.1504, Validation Accuracy = 0.0132, Validation Loss = 7.2470\n",
            "Epoch 748/2500\n",
            "Epoch 748: Training Accuracy = 0.9863, Training Loss = 0.1504, Validation Accuracy = 0.0132, Validation Loss = 7.2470\n",
            "Epoch 749/2500\n",
            "Epoch 749: Training Accuracy = 0.9902, Training Loss = 0.1451, Validation Accuracy = 0.0121, Validation Loss = 7.2061\n",
            "Epoch 750/2500\n",
            "Epoch 750: Training Accuracy = 0.9902, Training Loss = 0.1451, Validation Accuracy = 0.0121, Validation Loss = 7.2061\n",
            "Epoch 751/2500\n",
            "Epoch 751: Training Accuracy = 0.9805, Training Loss = 0.2200, Validation Accuracy = 0.0123, Validation Loss = 7.1217\n",
            "Epoch 752/2500\n",
            "Epoch 752: Training Accuracy = 0.9824, Training Loss = 0.2649, Validation Accuracy = 0.0128, Validation Loss = 7.1443\n",
            "Epoch 753/2500\n",
            "Epoch 753: Training Accuracy = 0.9824, Training Loss = 0.2649, Validation Accuracy = 0.0128, Validation Loss = 7.1443\n",
            "Epoch 754/2500\n",
            "Epoch 754: Training Accuracy = 0.9902, Training Loss = 0.2363, Validation Accuracy = 0.0141, Validation Loss = 7.1163\n",
            "Epoch 755/2500\n",
            "Epoch 755: Training Accuracy = 0.9902, Training Loss = 0.2363, Validation Accuracy = 0.0141, Validation Loss = 7.1163\n",
            "Epoch 756/2500\n",
            "Epoch 756: Training Accuracy = 0.9902, Training Loss = 0.2747, Validation Accuracy = 0.0131, Validation Loss = 7.0916\n",
            "Epoch 757/2500\n",
            "Epoch 757: Training Accuracy = 0.9824, Training Loss = 0.2814, Validation Accuracy = 0.0135, Validation Loss = 7.1513\n",
            "Epoch 758/2500\n",
            "Epoch 758: Training Accuracy = 0.9824, Training Loss = 0.2814, Validation Accuracy = 0.0135, Validation Loss = 7.1513\n",
            "Epoch 759/2500\n",
            "Epoch 759: Training Accuracy = 0.9883, Training Loss = 0.1866, Validation Accuracy = 0.0132, Validation Loss = 7.1789\n",
            "Epoch 760/2500\n",
            "Epoch 760: Training Accuracy = 0.9883, Training Loss = 0.1866, Validation Accuracy = 0.0132, Validation Loss = 7.1789\n",
            "Epoch 761/2500\n",
            "Epoch 761: Training Accuracy = 0.9922, Training Loss = 0.1528, Validation Accuracy = 0.0131, Validation Loss = 7.2474\n",
            "Epoch 762/2500\n",
            "Epoch 762: Training Accuracy = 0.9844, Training Loss = 0.1613, Validation Accuracy = 0.0123, Validation Loss = 7.2699\n",
            "Epoch 763/2500\n",
            "Epoch 763: Training Accuracy = 0.9844, Training Loss = 0.1613, Validation Accuracy = 0.0123, Validation Loss = 7.2699\n",
            "Epoch 764/2500\n",
            "Epoch 764: Training Accuracy = 0.9824, Training Loss = 0.1593, Validation Accuracy = 0.0128, Validation Loss = 7.2524\n",
            "Epoch 765/2500\n",
            "Epoch 765: Training Accuracy = 0.9824, Training Loss = 0.1593, Validation Accuracy = 0.0128, Validation Loss = 7.2524\n",
            "Epoch 766/2500\n",
            "Epoch 766: Training Accuracy = 0.9902, Training Loss = 0.1351, Validation Accuracy = 0.0132, Validation Loss = 7.2006\n",
            "Epoch 767/2500\n",
            "Epoch 767: Training Accuracy = 0.9844, Training Loss = 0.1807, Validation Accuracy = 0.0131, Validation Loss = 7.2073\n",
            "Epoch 768/2500\n",
            "Epoch 768: Training Accuracy = 0.9844, Training Loss = 0.1807, Validation Accuracy = 0.0131, Validation Loss = 7.2073\n",
            "Epoch 769/2500\n",
            "Epoch 769: Training Accuracy = 0.9805, Training Loss = 0.2632, Validation Accuracy = 0.0138, Validation Loss = 7.1213\n",
            "Epoch 770/2500\n",
            "Epoch 770: Training Accuracy = 0.9805, Training Loss = 0.2632, Validation Accuracy = 0.0138, Validation Loss = 7.1213\n",
            "Epoch 771/2500\n",
            "Epoch 771: Training Accuracy = 0.9219, Training Loss = 0.5281, Validation Accuracy = 0.0129, Validation Loss = 7.0048\n",
            "Epoch 772/2500\n",
            "Epoch 772: Training Accuracy = 0.9844, Training Loss = 0.3066, Validation Accuracy = 0.0124, Validation Loss = 7.0695\n",
            "Epoch 773/2500\n",
            "Epoch 773: Training Accuracy = 0.9844, Training Loss = 0.3066, Validation Accuracy = 0.0124, Validation Loss = 7.0695\n",
            "Epoch 774/2500\n",
            "Epoch 774: Training Accuracy = 0.9902, Training Loss = 0.1820, Validation Accuracy = 0.0124, Validation Loss = 7.1616\n",
            "Epoch 775/2500\n",
            "Epoch 775: Training Accuracy = 0.9902, Training Loss = 0.1820, Validation Accuracy = 0.0124, Validation Loss = 7.1616\n",
            "Epoch 776/2500\n",
            "Epoch 776: Training Accuracy = 0.9902, Training Loss = 0.1382, Validation Accuracy = 0.0124, Validation Loss = 7.2519\n",
            "Epoch 777/2500\n",
            "Epoch 777: Training Accuracy = 0.9883, Training Loss = 0.1334, Validation Accuracy = 0.0129, Validation Loss = 7.2459\n",
            "Epoch 778/2500\n",
            "Epoch 778: Training Accuracy = 0.9883, Training Loss = 0.1334, Validation Accuracy = 0.0129, Validation Loss = 7.2459\n",
            "Epoch 779/2500\n",
            "Epoch 779: Training Accuracy = 0.9883, Training Loss = 0.1217, Validation Accuracy = 0.0124, Validation Loss = 7.2642\n",
            "Epoch 780/2500\n",
            "Epoch 780: Training Accuracy = 0.9883, Training Loss = 0.1217, Validation Accuracy = 0.0124, Validation Loss = 7.2642\n",
            "Epoch 781/2500\n",
            "Epoch 781: Training Accuracy = 0.9922, Training Loss = 0.0981, Validation Accuracy = 0.0132, Validation Loss = 7.2497\n",
            "Epoch 782/2500\n",
            "Epoch 782: Training Accuracy = 0.9844, Training Loss = 0.1363, Validation Accuracy = 0.0124, Validation Loss = 7.2860\n",
            "Epoch 783/2500\n",
            "Epoch 783: Training Accuracy = 0.9844, Training Loss = 0.1363, Validation Accuracy = 0.0124, Validation Loss = 7.2860\n",
            "Epoch 784/2500\n",
            "Epoch 784: Training Accuracy = 0.9902, Training Loss = 0.1169, Validation Accuracy = 0.0129, Validation Loss = 7.3116\n",
            "Epoch 785/2500\n",
            "Epoch 785: Training Accuracy = 0.9902, Training Loss = 0.1169, Validation Accuracy = 0.0129, Validation Loss = 7.3116\n",
            "Epoch 786/2500\n",
            "Epoch 786: Training Accuracy = 0.9922, Training Loss = 0.1672, Validation Accuracy = 0.0137, Validation Loss = 7.1571\n",
            "Epoch 787/2500\n",
            "Epoch 787: Training Accuracy = 0.9824, Training Loss = 0.2385, Validation Accuracy = 0.0129, Validation Loss = 7.1526\n",
            "Epoch 788/2500\n",
            "Epoch 788: Training Accuracy = 0.9824, Training Loss = 0.2385, Validation Accuracy = 0.0129, Validation Loss = 7.1526\n",
            "Epoch 789/2500\n",
            "Epoch 789: Training Accuracy = 0.9688, Training Loss = 0.3214, Validation Accuracy = 0.0124, Validation Loss = 7.2096\n",
            "Epoch 790/2500\n",
            "Epoch 790: Training Accuracy = 0.9688, Training Loss = 0.3214, Validation Accuracy = 0.0124, Validation Loss = 7.2096\n",
            "Epoch 791/2500\n",
            "Epoch 791: Training Accuracy = 0.9902, Training Loss = 0.2308, Validation Accuracy = 0.0126, Validation Loss = 7.1488\n",
            "Epoch 792/2500\n",
            "Epoch 792: Training Accuracy = 0.9922, Training Loss = 0.1873, Validation Accuracy = 0.0126, Validation Loss = 7.1737\n",
            "Epoch 793/2500\n",
            "Epoch 793: Training Accuracy = 0.9922, Training Loss = 0.1873, Validation Accuracy = 0.0126, Validation Loss = 7.1737\n",
            "Epoch 794/2500\n",
            "Epoch 794: Training Accuracy = 0.9922, Training Loss = 0.1516, Validation Accuracy = 0.0126, Validation Loss = 7.2549\n",
            "Epoch 795/2500\n",
            "Epoch 795: Training Accuracy = 0.9922, Training Loss = 0.1516, Validation Accuracy = 0.0126, Validation Loss = 7.2549\n",
            "Epoch 796/2500\n",
            "Epoch 796: Training Accuracy = 0.9922, Training Loss = 0.1320, Validation Accuracy = 0.0115, Validation Loss = 7.1865\n",
            "Epoch 797/2500\n",
            "Epoch 797: Training Accuracy = 0.9863, Training Loss = 0.1600, Validation Accuracy = 0.0135, Validation Loss = 7.2343\n",
            "Epoch 798/2500\n",
            "Epoch 798: Training Accuracy = 0.9863, Training Loss = 0.1600, Validation Accuracy = 0.0135, Validation Loss = 7.2343\n",
            "Epoch 799/2500\n",
            "Epoch 799: Training Accuracy = 0.9941, Training Loss = 0.1198, Validation Accuracy = 0.0134, Validation Loss = 7.2382\n",
            "Epoch 800/2500\n",
            "Epoch 800: Training Accuracy = 0.9941, Training Loss = 0.1198, Validation Accuracy = 0.0134, Validation Loss = 7.2382\n",
            "Epoch 801/2500\n",
            "Epoch 801: Training Accuracy = 0.9863, Training Loss = 0.1315, Validation Accuracy = 0.0128, Validation Loss = 7.2570\n",
            "Epoch 802/2500\n",
            "Epoch 802: Training Accuracy = 0.9844, Training Loss = 0.1438, Validation Accuracy = 0.0131, Validation Loss = 7.2878\n",
            "Epoch 803/2500\n",
            "Epoch 803: Training Accuracy = 0.9844, Training Loss = 0.1438, Validation Accuracy = 0.0131, Validation Loss = 7.2878\n",
            "Epoch 804/2500\n",
            "Epoch 804: Training Accuracy = 0.9902, Training Loss = 0.1211, Validation Accuracy = 0.0134, Validation Loss = 7.2746\n",
            "Epoch 805/2500\n",
            "Epoch 805: Training Accuracy = 0.9902, Training Loss = 0.1211, Validation Accuracy = 0.0134, Validation Loss = 7.2746\n",
            "Epoch 806/2500\n",
            "Epoch 806: Training Accuracy = 0.9883, Training Loss = 0.1212, Validation Accuracy = 0.0131, Validation Loss = 7.2784\n",
            "Epoch 807/2500\n",
            "Epoch 807: Training Accuracy = 0.4688, Training Loss = 2.5557, Validation Accuracy = 0.0152, Validation Loss = 5.9479\n",
            "Epoch 808/2500\n",
            "Epoch 808: Training Accuracy = 0.4688, Training Loss = 2.5557, Validation Accuracy = 0.0152, Validation Loss = 5.9479\n",
            "Epoch 809/2500\n",
            "Epoch 809: Training Accuracy = 0.7812, Training Loss = 1.0324, Validation Accuracy = 0.0128, Validation Loss = 6.6993\n",
            "Epoch 810/2500\n",
            "Epoch 810: Training Accuracy = 0.7812, Training Loss = 1.0324, Validation Accuracy = 0.0128, Validation Loss = 6.6993\n",
            "Epoch 811/2500\n",
            "Epoch 811: Training Accuracy = 0.9824, Training Loss = 0.4000, Validation Accuracy = 0.0131, Validation Loss = 6.9322\n",
            "Epoch 812/2500\n",
            "Epoch 812: Training Accuracy = 0.9863, Training Loss = 0.2503, Validation Accuracy = 0.0124, Validation Loss = 7.0077\n",
            "Epoch 813/2500\n",
            "Epoch 813: Training Accuracy = 0.9863, Training Loss = 0.2503, Validation Accuracy = 0.0124, Validation Loss = 7.0077\n",
            "Epoch 814/2500\n",
            "Epoch 814: Training Accuracy = 0.9844, Training Loss = 0.1824, Validation Accuracy = 0.0123, Validation Loss = 7.0933\n",
            "Epoch 815/2500\n",
            "Epoch 815: Training Accuracy = 0.9844, Training Loss = 0.1824, Validation Accuracy = 0.0123, Validation Loss = 7.0933\n",
            "Epoch 816/2500\n",
            "Epoch 816: Training Accuracy = 0.9883, Training Loss = 0.1347, Validation Accuracy = 0.0131, Validation Loss = 7.1273\n",
            "Epoch 817/2500\n",
            "Epoch 817: Training Accuracy = 0.9844, Training Loss = 0.1492, Validation Accuracy = 0.0134, Validation Loss = 7.2013\n",
            "Epoch 818/2500\n",
            "Epoch 818: Training Accuracy = 0.9844, Training Loss = 0.1492, Validation Accuracy = 0.0134, Validation Loss = 7.2013\n",
            "Epoch 819/2500\n",
            "Epoch 819: Training Accuracy = 0.9902, Training Loss = 0.1136, Validation Accuracy = 0.0132, Validation Loss = 7.2093\n",
            "Epoch 820/2500\n",
            "Epoch 820: Training Accuracy = 0.9902, Training Loss = 0.1136, Validation Accuracy = 0.0132, Validation Loss = 7.2093\n",
            "Epoch 821/2500\n",
            "Epoch 821: Training Accuracy = 0.9863, Training Loss = 0.1225, Validation Accuracy = 0.0124, Validation Loss = 7.1737\n",
            "Epoch 822/2500\n",
            "Epoch 822: Training Accuracy = 0.9941, Training Loss = 0.1057, Validation Accuracy = 0.0126, Validation Loss = 7.1477\n",
            "Epoch 823/2500\n",
            "Epoch 823: Training Accuracy = 0.9941, Training Loss = 0.1057, Validation Accuracy = 0.0126, Validation Loss = 7.1477\n",
            "Epoch 824/2500\n",
            "Epoch 824: Training Accuracy = 0.9863, Training Loss = 0.1323, Validation Accuracy = 0.0141, Validation Loss = 7.1812\n",
            "Epoch 825/2500\n",
            "Epoch 825: Training Accuracy = 0.9863, Training Loss = 0.1323, Validation Accuracy = 0.0141, Validation Loss = 7.1812\n",
            "Epoch 826/2500\n",
            "Epoch 826: Training Accuracy = 0.9844, Training Loss = 0.1334, Validation Accuracy = 0.0126, Validation Loss = 7.1770\n",
            "Epoch 827/2500\n",
            "Epoch 827: Training Accuracy = 0.9922, Training Loss = 0.1279, Validation Accuracy = 0.0129, Validation Loss = 7.1475\n",
            "Epoch 828/2500\n",
            "Epoch 828: Training Accuracy = 0.9922, Training Loss = 0.1279, Validation Accuracy = 0.0129, Validation Loss = 7.1475\n",
            "Epoch 829/2500\n",
            "Epoch 829: Training Accuracy = 0.9883, Training Loss = 0.1508, Validation Accuracy = 0.0128, Validation Loss = 7.0602\n",
            "Epoch 830/2500\n",
            "Epoch 830: Training Accuracy = 0.9883, Training Loss = 0.1508, Validation Accuracy = 0.0128, Validation Loss = 7.0602\n",
            "Epoch 831/2500\n",
            "Epoch 831: Training Accuracy = 0.9883, Training Loss = 0.1894, Validation Accuracy = 0.0140, Validation Loss = 7.0270\n",
            "Epoch 832/2500\n",
            "Epoch 832: Training Accuracy = 0.8730, Training Loss = 0.7439, Validation Accuracy = 0.0153, Validation Loss = 6.9262\n",
            "Epoch 833/2500\n",
            "Epoch 833: Training Accuracy = 0.8730, Training Loss = 0.7439, Validation Accuracy = 0.0153, Validation Loss = 6.9262\n",
            "Epoch 834/2500\n",
            "Epoch 834: Training Accuracy = 0.9473, Training Loss = 0.4666, Validation Accuracy = 0.0146, Validation Loss = 6.8167\n",
            "Epoch 835/2500\n",
            "Epoch 835: Training Accuracy = 0.9473, Training Loss = 0.4666, Validation Accuracy = 0.0146, Validation Loss = 6.8167\n",
            "Epoch 836/2500\n",
            "Epoch 836: Training Accuracy = 0.9824, Training Loss = 0.2443, Validation Accuracy = 0.0137, Validation Loss = 6.9562\n",
            "Epoch 837/2500\n",
            "Epoch 837: Training Accuracy = 0.9883, Training Loss = 0.1710, Validation Accuracy = 0.0141, Validation Loss = 7.0077\n",
            "Epoch 838/2500\n",
            "Epoch 838: Training Accuracy = 0.9883, Training Loss = 0.1710, Validation Accuracy = 0.0141, Validation Loss = 7.0077\n",
            "Epoch 839/2500\n",
            "Epoch 839: Training Accuracy = 0.9863, Training Loss = 0.1445, Validation Accuracy = 0.0129, Validation Loss = 7.0585\n",
            "Epoch 840/2500\n",
            "Epoch 840: Training Accuracy = 0.9863, Training Loss = 0.1445, Validation Accuracy = 0.0129, Validation Loss = 7.0585\n",
            "Epoch 841/2500\n",
            "Epoch 841: Training Accuracy = 0.9785, Training Loss = 0.1467, Validation Accuracy = 0.0134, Validation Loss = 7.0932\n",
            "Epoch 842/2500\n",
            "Epoch 842: Training Accuracy = 0.9941, Training Loss = 0.0956, Validation Accuracy = 0.0137, Validation Loss = 7.1082\n",
            "Epoch 843/2500\n",
            "Epoch 843: Training Accuracy = 0.9941, Training Loss = 0.0956, Validation Accuracy = 0.0137, Validation Loss = 7.1082\n",
            "Epoch 844/2500\n",
            "Epoch 844: Training Accuracy = 0.9922, Training Loss = 0.0974, Validation Accuracy = 0.0135, Validation Loss = 7.0930\n",
            "Epoch 845/2500\n",
            "Epoch 845: Training Accuracy = 0.9922, Training Loss = 0.0974, Validation Accuracy = 0.0135, Validation Loss = 7.0930\n",
            "Epoch 846/2500\n",
            "Epoch 846: Training Accuracy = 0.9941, Training Loss = 0.0896, Validation Accuracy = 0.0129, Validation Loss = 7.0906\n",
            "Epoch 847/2500\n",
            "Epoch 847: Training Accuracy = 0.9922, Training Loss = 0.1020, Validation Accuracy = 0.0131, Validation Loss = 7.0733\n",
            "Epoch 848/2500\n",
            "Epoch 848: Training Accuracy = 0.9922, Training Loss = 0.1020, Validation Accuracy = 0.0131, Validation Loss = 7.0733\n",
            "Epoch 849/2500\n",
            "Epoch 849: Training Accuracy = 0.9961, Training Loss = 0.0880, Validation Accuracy = 0.0132, Validation Loss = 7.0667\n",
            "Epoch 850/2500\n",
            "Epoch 850: Training Accuracy = 0.9961, Training Loss = 0.0880, Validation Accuracy = 0.0132, Validation Loss = 7.0667\n",
            "Epoch 851/2500\n",
            "Epoch 851: Training Accuracy = 0.9863, Training Loss = 0.1321, Validation Accuracy = 0.0141, Validation Loss = 7.0038\n",
            "Epoch 852/2500\n",
            "Epoch 852: Training Accuracy = 0.9922, Training Loss = 0.1583, Validation Accuracy = 0.0146, Validation Loss = 7.0092\n",
            "Epoch 853/2500\n",
            "Epoch 853: Training Accuracy = 0.9922, Training Loss = 0.1583, Validation Accuracy = 0.0146, Validation Loss = 7.0092\n",
            "Epoch 854/2500\n",
            "Epoch 854: Training Accuracy = 0.4375, Training Loss = 2.6680, Validation Accuracy = 0.0123, Validation Loss = 5.4420\n",
            "Epoch 855/2500\n",
            "Epoch 855: Training Accuracy = 0.4375, Training Loss = 2.6680, Validation Accuracy = 0.0123, Validation Loss = 5.4420\n",
            "Epoch 856/2500\n",
            "Epoch 856: Training Accuracy = 0.8340, Training Loss = 0.9214, Validation Accuracy = 0.0129, Validation Loss = 6.4665\n",
            "Epoch 857/2500\n",
            "Epoch 857: Training Accuracy = 0.9746, Training Loss = 0.4221, Validation Accuracy = 0.0121, Validation Loss = 6.6286\n",
            "Epoch 858/2500\n",
            "Epoch 858: Training Accuracy = 0.9746, Training Loss = 0.4221, Validation Accuracy = 0.0121, Validation Loss = 6.6286\n",
            "Epoch 859/2500\n",
            "Epoch 859: Training Accuracy = 0.9863, Training Loss = 0.2450, Validation Accuracy = 0.0147, Validation Loss = 6.7986\n",
            "Epoch 860/2500\n",
            "Epoch 860: Training Accuracy = 0.9863, Training Loss = 0.2450, Validation Accuracy = 0.0147, Validation Loss = 6.7986\n",
            "Epoch 861/2500\n",
            "Epoch 861: Training Accuracy = 0.9922, Training Loss = 0.1758, Validation Accuracy = 0.0129, Validation Loss = 6.8537\n",
            "Epoch 862/2500\n",
            "Epoch 862: Training Accuracy = 0.9941, Training Loss = 0.1291, Validation Accuracy = 0.0137, Validation Loss = 6.9513\n",
            "Epoch 863/2500\n",
            "Epoch 863: Training Accuracy = 0.9941, Training Loss = 0.1291, Validation Accuracy = 0.0137, Validation Loss = 6.9513\n",
            "Epoch 864/2500\n",
            "Epoch 864: Training Accuracy = 0.9902, Training Loss = 0.1190, Validation Accuracy = 0.0124, Validation Loss = 6.9626\n",
            "Epoch 865/2500\n",
            "Epoch 865: Training Accuracy = 0.9902, Training Loss = 0.1190, Validation Accuracy = 0.0124, Validation Loss = 6.9626\n",
            "Epoch 866/2500\n",
            "Epoch 866: Training Accuracy = 0.9922, Training Loss = 0.1043, Validation Accuracy = 0.0137, Validation Loss = 6.9768\n",
            "Epoch 867/2500\n",
            "Epoch 867: Training Accuracy = 0.9844, Training Loss = 0.1437, Validation Accuracy = 0.0135, Validation Loss = 6.9458\n",
            "Epoch 868/2500\n",
            "Epoch 868: Training Accuracy = 0.9844, Training Loss = 0.1437, Validation Accuracy = 0.0135, Validation Loss = 6.9458\n",
            "Epoch 869/2500\n",
            "Epoch 869: Training Accuracy = 0.9941, Training Loss = 0.1004, Validation Accuracy = 0.0135, Validation Loss = 6.9538\n",
            "Epoch 870/2500\n",
            "Epoch 870: Training Accuracy = 0.9941, Training Loss = 0.1004, Validation Accuracy = 0.0135, Validation Loss = 6.9538\n",
            "Epoch 871/2500\n",
            "Epoch 871: Training Accuracy = 0.9863, Training Loss = 0.1307, Validation Accuracy = 0.0137, Validation Loss = 6.9111\n",
            "Epoch 872/2500\n",
            "Epoch 872: Training Accuracy = 0.9902, Training Loss = 0.1308, Validation Accuracy = 0.0137, Validation Loss = 6.9010\n",
            "Epoch 873/2500\n",
            "Epoch 873: Training Accuracy = 0.9902, Training Loss = 0.1308, Validation Accuracy = 0.0137, Validation Loss = 6.9010\n",
            "Epoch 874/2500\n",
            "Epoch 874: Training Accuracy = 0.9824, Training Loss = 0.1668, Validation Accuracy = 0.0124, Validation Loss = 6.8875\n",
            "Epoch 875/2500\n",
            "Epoch 875: Training Accuracy = 0.9824, Training Loss = 0.1668, Validation Accuracy = 0.0124, Validation Loss = 6.8875\n",
            "Epoch 876/2500\n",
            "Epoch 876: Training Accuracy = 0.7793, Training Loss = 1.0365, Validation Accuracy = 0.0159, Validation Loss = 6.5987\n",
            "Epoch 877/2500\n",
            "Epoch 877: Training Accuracy = 0.9453, Training Loss = 0.5573, Validation Accuracy = 0.0140, Validation Loss = 6.4600\n",
            "Epoch 878/2500\n",
            "Epoch 878: Training Accuracy = 0.9453, Training Loss = 0.5573, Validation Accuracy = 0.0140, Validation Loss = 6.4600\n",
            "Epoch 879/2500\n",
            "Epoch 879: Training Accuracy = 0.9941, Training Loss = 0.2738, Validation Accuracy = 0.0137, Validation Loss = 6.6665\n",
            "Epoch 880/2500\n",
            "Epoch 880: Training Accuracy = 0.9941, Training Loss = 0.2738, Validation Accuracy = 0.0137, Validation Loss = 6.6665\n",
            "Epoch 881/2500\n",
            "Epoch 881: Training Accuracy = 0.9863, Training Loss = 0.2005, Validation Accuracy = 0.0132, Validation Loss = 6.7142\n",
            "Epoch 882/2500\n",
            "Epoch 882: Training Accuracy = 0.9941, Training Loss = 0.1465, Validation Accuracy = 0.0131, Validation Loss = 6.8081\n",
            "Epoch 883/2500\n",
            "Epoch 883: Training Accuracy = 0.9941, Training Loss = 0.1465, Validation Accuracy = 0.0131, Validation Loss = 6.8081\n",
            "Epoch 884/2500\n",
            "Epoch 884: Training Accuracy = 0.9883, Training Loss = 0.1401, Validation Accuracy = 0.0128, Validation Loss = 6.8455\n",
            "Epoch 885/2500\n",
            "Epoch 885: Training Accuracy = 0.9883, Training Loss = 0.1401, Validation Accuracy = 0.0128, Validation Loss = 6.8455\n",
            "Epoch 886/2500\n",
            "Epoch 886: Training Accuracy = 0.9922, Training Loss = 0.1049, Validation Accuracy = 0.0140, Validation Loss = 6.8373\n",
            "Epoch 887/2500\n",
            "Epoch 887: Training Accuracy = 0.9961, Training Loss = 0.1017, Validation Accuracy = 0.0134, Validation Loss = 6.8474\n",
            "Epoch 888/2500\n",
            "Epoch 888: Training Accuracy = 0.9961, Training Loss = 0.1017, Validation Accuracy = 0.0134, Validation Loss = 6.8474\n",
            "Epoch 889/2500\n",
            "Epoch 889: Training Accuracy = 0.9883, Training Loss = 0.1199, Validation Accuracy = 0.0138, Validation Loss = 6.8442\n",
            "Epoch 890/2500\n",
            "Epoch 890: Training Accuracy = 0.9883, Training Loss = 0.1199, Validation Accuracy = 0.0138, Validation Loss = 6.8442\n",
            "Epoch 891/2500\n",
            "Epoch 891: Training Accuracy = 0.9883, Training Loss = 0.1214, Validation Accuracy = 0.0131, Validation Loss = 6.8103\n",
            "Epoch 892/2500\n",
            "Epoch 892: Training Accuracy = 0.9863, Training Loss = 0.1444, Validation Accuracy = 0.0134, Validation Loss = 6.8166\n",
            "Epoch 893/2500\n",
            "Epoch 893: Training Accuracy = 0.9863, Training Loss = 0.1444, Validation Accuracy = 0.0134, Validation Loss = 6.8166\n",
            "Epoch 894/2500\n",
            "Epoch 894: Training Accuracy = 0.9941, Training Loss = 0.1220, Validation Accuracy = 0.0135, Validation Loss = 6.7758\n",
            "Epoch 895/2500\n",
            "Epoch 895: Training Accuracy = 0.9941, Training Loss = 0.1220, Validation Accuracy = 0.0135, Validation Loss = 6.7758\n",
            "Epoch 896/2500\n",
            "Epoch 896: Training Accuracy = 0.9922, Training Loss = 0.1554, Validation Accuracy = 0.0132, Validation Loss = 6.7456\n",
            "Epoch 897/2500\n",
            "Epoch 897: Training Accuracy = 0.7832, Training Loss = 1.0264, Validation Accuracy = 0.0167, Validation Loss = 6.3030\n",
            "Epoch 898/2500\n",
            "Epoch 898: Training Accuracy = 0.7832, Training Loss = 1.0264, Validation Accuracy = 0.0167, Validation Loss = 6.3030\n",
            "Epoch 899/2500\n",
            "Epoch 899: Training Accuracy = 0.9551, Training Loss = 0.5028, Validation Accuracy = 0.0128, Validation Loss = 6.3811\n",
            "Epoch 900/2500\n",
            "Epoch 900: Training Accuracy = 0.9551, Training Loss = 0.5028, Validation Accuracy = 0.0128, Validation Loss = 6.3811\n",
            "Epoch 901/2500\n",
            "Epoch 901: Training Accuracy = 0.9844, Training Loss = 0.2323, Validation Accuracy = 0.0137, Validation Loss = 6.5886\n",
            "Epoch 902/2500\n",
            "Epoch 902: Training Accuracy = 0.9961, Training Loss = 0.1747, Validation Accuracy = 0.0126, Validation Loss = 6.6988\n",
            "Epoch 903/2500\n",
            "Epoch 903: Training Accuracy = 0.9961, Training Loss = 0.1747, Validation Accuracy = 0.0126, Validation Loss = 6.6988\n",
            "Epoch 904/2500\n",
            "Epoch 904: Training Accuracy = 0.9863, Training Loss = 0.1549, Validation Accuracy = 0.0123, Validation Loss = 6.7189\n",
            "Epoch 905/2500\n",
            "Epoch 905: Training Accuracy = 0.9863, Training Loss = 0.1549, Validation Accuracy = 0.0123, Validation Loss = 6.7189\n",
            "Epoch 906/2500\n",
            "Epoch 906: Training Accuracy = 0.9941, Training Loss = 0.1020, Validation Accuracy = 0.0135, Validation Loss = 6.7550\n",
            "Epoch 907/2500\n",
            "Epoch 907: Training Accuracy = 0.9824, Training Loss = 0.1484, Validation Accuracy = 0.0132, Validation Loss = 6.7901\n",
            "Epoch 908/2500\n",
            "Epoch 908: Training Accuracy = 0.9824, Training Loss = 0.1484, Validation Accuracy = 0.0132, Validation Loss = 6.7901\n",
            "Epoch 909/2500\n",
            "Epoch 909: Training Accuracy = 0.9824, Training Loss = 0.1367, Validation Accuracy = 0.0132, Validation Loss = 6.7942\n",
            "Epoch 910/2500\n",
            "Epoch 910: Training Accuracy = 0.9824, Training Loss = 0.1367, Validation Accuracy = 0.0132, Validation Loss = 6.7942\n",
            "Epoch 911/2500\n",
            "Epoch 911: Training Accuracy = 0.9844, Training Loss = 0.1336, Validation Accuracy = 0.0135, Validation Loss = 6.7633\n",
            "Epoch 912/2500\n",
            "Epoch 912: Training Accuracy = 0.9961, Training Loss = 0.0942, Validation Accuracy = 0.0140, Validation Loss = 6.7576\n",
            "Epoch 913/2500\n",
            "Epoch 913: Training Accuracy = 0.9961, Training Loss = 0.0942, Validation Accuracy = 0.0140, Validation Loss = 6.7576\n",
            "Epoch 914/2500\n",
            "Epoch 914: Training Accuracy = 0.9922, Training Loss = 0.1179, Validation Accuracy = 0.0140, Validation Loss = 6.7464\n",
            "Epoch 915/2500\n",
            "Epoch 915: Training Accuracy = 0.9922, Training Loss = 0.1179, Validation Accuracy = 0.0140, Validation Loss = 6.7464\n",
            "Epoch 916/2500\n",
            "Epoch 916: Training Accuracy = 0.9902, Training Loss = 0.1294, Validation Accuracy = 0.0141, Validation Loss = 6.7481\n",
            "Epoch 917/2500\n",
            "Epoch 917: Training Accuracy = 0.7441, Training Loss = 1.1234, Validation Accuracy = 0.0146, Validation Loss = 6.1726\n",
            "Epoch 918/2500\n",
            "Epoch 918: Training Accuracy = 0.7441, Training Loss = 1.1234, Validation Accuracy = 0.0146, Validation Loss = 6.1726\n",
            "Epoch 919/2500\n",
            "Epoch 919: Training Accuracy = 0.9746, Training Loss = 0.4191, Validation Accuracy = 0.0141, Validation Loss = 6.4442\n",
            "Epoch 920/2500\n",
            "Epoch 920: Training Accuracy = 0.9746, Training Loss = 0.4191, Validation Accuracy = 0.0141, Validation Loss = 6.4442\n",
            "Epoch 921/2500\n",
            "Epoch 921: Training Accuracy = 0.9844, Training Loss = 0.2519, Validation Accuracy = 0.0153, Validation Loss = 6.5102\n",
            "Epoch 922/2500\n",
            "Epoch 922: Training Accuracy = 0.9922, Training Loss = 0.1934, Validation Accuracy = 0.0141, Validation Loss = 6.6257\n",
            "Epoch 923/2500\n",
            "Epoch 923: Training Accuracy = 0.9922, Training Loss = 0.1934, Validation Accuracy = 0.0141, Validation Loss = 6.6257\n",
            "Epoch 924/2500\n",
            "Epoch 924: Training Accuracy = 0.9805, Training Loss = 0.1729, Validation Accuracy = 0.0137, Validation Loss = 6.6528\n",
            "Epoch 925/2500\n",
            "Epoch 925: Training Accuracy = 0.9805, Training Loss = 0.1729, Validation Accuracy = 0.0137, Validation Loss = 6.6528\n",
            "Epoch 926/2500\n",
            "Epoch 926: Training Accuracy = 0.9902, Training Loss = 0.1171, Validation Accuracy = 0.0135, Validation Loss = 6.6939\n",
            "Epoch 927/2500\n",
            "Epoch 927: Training Accuracy = 1.0000, Training Loss = 0.0901, Validation Accuracy = 0.0137, Validation Loss = 6.7098\n",
            "Epoch 928/2500\n",
            "Epoch 928: Training Accuracy = 1.0000, Training Loss = 0.0901, Validation Accuracy = 0.0137, Validation Loss = 6.7098\n",
            "Epoch 929/2500\n",
            "Epoch 929: Training Accuracy = 0.9902, Training Loss = 0.1090, Validation Accuracy = 0.0138, Validation Loss = 6.7172\n",
            "Epoch 930/2500\n",
            "Epoch 930: Training Accuracy = 0.9902, Training Loss = 0.1090, Validation Accuracy = 0.0138, Validation Loss = 6.7172\n",
            "Epoch 931/2500\n",
            "Epoch 931: Training Accuracy = 0.9824, Training Loss = 0.1364, Validation Accuracy = 0.0131, Validation Loss = 6.7173\n",
            "Epoch 932/2500\n",
            "Epoch 932: Training Accuracy = 0.9922, Training Loss = 0.1046, Validation Accuracy = 0.0137, Validation Loss = 6.6769\n",
            "Epoch 933/2500\n",
            "Epoch 933: Training Accuracy = 0.9922, Training Loss = 0.1046, Validation Accuracy = 0.0137, Validation Loss = 6.6769\n",
            "Epoch 934/2500\n",
            "Epoch 934: Training Accuracy = 0.9941, Training Loss = 0.1022, Validation Accuracy = 0.0138, Validation Loss = 6.6942\n",
            "Epoch 935/2500\n",
            "Epoch 935: Training Accuracy = 0.9941, Training Loss = 0.1022, Validation Accuracy = 0.0138, Validation Loss = 6.6942\n",
            "Epoch 936/2500\n",
            "Epoch 936: Training Accuracy = 0.9980, Training Loss = 0.1086, Validation Accuracy = 0.0137, Validation Loss = 6.6948\n",
            "Epoch 937/2500\n",
            "Epoch 937: Training Accuracy = 0.9883, Training Loss = 0.1443, Validation Accuracy = 0.0147, Validation Loss = 6.6544\n",
            "Epoch 938/2500\n",
            "Epoch 938: Training Accuracy = 0.9883, Training Loss = 0.1443, Validation Accuracy = 0.0147, Validation Loss = 6.6544\n",
            "Epoch 939/2500\n",
            "Epoch 939: Training Accuracy = 0.5508, Training Loss = 2.2637, Validation Accuracy = 0.0172, Validation Loss = 5.4741\n",
            "Epoch 940/2500\n",
            "Epoch 940: Training Accuracy = 0.5508, Training Loss = 2.2637, Validation Accuracy = 0.0172, Validation Loss = 5.4741\n",
            "Epoch 941/2500\n",
            "Epoch 941: Training Accuracy = 0.8516, Training Loss = 0.8076, Validation Accuracy = 0.0141, Validation Loss = 6.3025\n",
            "Epoch 942/2500\n",
            "Epoch 942: Training Accuracy = 0.9570, Training Loss = 0.4610, Validation Accuracy = 0.0159, Validation Loss = 6.3226\n",
            "Epoch 943/2500\n",
            "Epoch 943: Training Accuracy = 0.9570, Training Loss = 0.4610, Validation Accuracy = 0.0159, Validation Loss = 6.3226\n",
            "Epoch 944/2500\n",
            "Epoch 944: Training Accuracy = 0.9863, Training Loss = 0.2459, Validation Accuracy = 0.0141, Validation Loss = 6.5098\n",
            "Epoch 945/2500\n",
            "Epoch 945: Training Accuracy = 0.9863, Training Loss = 0.2459, Validation Accuracy = 0.0141, Validation Loss = 6.5098\n",
            "Epoch 946/2500\n",
            "Epoch 946: Training Accuracy = 0.9941, Training Loss = 0.1453, Validation Accuracy = 0.0140, Validation Loss = 6.5445\n",
            "Epoch 947/2500\n",
            "Epoch 947: Training Accuracy = 0.9883, Training Loss = 0.1403, Validation Accuracy = 0.0129, Validation Loss = 6.6054\n",
            "Epoch 948/2500\n",
            "Epoch 948: Training Accuracy = 0.9883, Training Loss = 0.1403, Validation Accuracy = 0.0129, Validation Loss = 6.6054\n",
            "Epoch 949/2500\n",
            "Epoch 949: Training Accuracy = 0.9863, Training Loss = 0.1361, Validation Accuracy = 0.0143, Validation Loss = 6.6437\n",
            "Epoch 950/2500\n",
            "Epoch 950: Training Accuracy = 0.9863, Training Loss = 0.1361, Validation Accuracy = 0.0143, Validation Loss = 6.6437\n",
            "Epoch 951/2500\n",
            "Epoch 951: Training Accuracy = 0.9844, Training Loss = 0.1288, Validation Accuracy = 0.0128, Validation Loss = 6.6243\n",
            "Epoch 952/2500\n",
            "Epoch 952: Training Accuracy = 0.9883, Training Loss = 0.1194, Validation Accuracy = 0.0146, Validation Loss = 6.6250\n",
            "Epoch 953/2500\n",
            "Epoch 953: Training Accuracy = 0.9883, Training Loss = 0.1194, Validation Accuracy = 0.0146, Validation Loss = 6.6250\n",
            "Epoch 954/2500\n",
            "Epoch 954: Training Accuracy = 0.9961, Training Loss = 0.0895, Validation Accuracy = 0.0132, Validation Loss = 6.6052\n",
            "Epoch 955/2500\n",
            "Epoch 955: Training Accuracy = 0.9961, Training Loss = 0.0895, Validation Accuracy = 0.0132, Validation Loss = 6.6052\n",
            "Epoch 956/2500\n",
            "Epoch 956: Training Accuracy = 0.9902, Training Loss = 0.1076, Validation Accuracy = 0.0144, Validation Loss = 6.6126\n",
            "Epoch 957/2500\n",
            "Epoch 957: Training Accuracy = 0.9922, Training Loss = 0.1175, Validation Accuracy = 0.0135, Validation Loss = 6.5897\n",
            "Epoch 958/2500\n",
            "Epoch 958: Training Accuracy = 0.9922, Training Loss = 0.1175, Validation Accuracy = 0.0135, Validation Loss = 6.5897\n",
            "Epoch 959/2500\n",
            "Epoch 959: Training Accuracy = 0.9941, Training Loss = 0.1190, Validation Accuracy = 0.0144, Validation Loss = 6.5692\n",
            "Epoch 960/2500\n",
            "Epoch 960: Training Accuracy = 0.9941, Training Loss = 0.1190, Validation Accuracy = 0.0144, Validation Loss = 6.5692\n",
            "Epoch 961/2500\n",
            "Epoch 961: Training Accuracy = 0.4336, Training Loss = 2.1054, Validation Accuracy = 0.0223, Validation Loss = 5.9123\n",
            "Epoch 962/2500\n",
            "Epoch 962: Training Accuracy = 0.8555, Training Loss = 0.8970, Validation Accuracy = 0.0161, Validation Loss = 6.1263\n",
            "Epoch 963/2500\n",
            "Epoch 963: Training Accuracy = 0.8555, Training Loss = 0.8970, Validation Accuracy = 0.0161, Validation Loss = 6.1263\n",
            "Epoch 964/2500\n",
            "Epoch 964: Training Accuracy = 0.9707, Training Loss = 0.4012, Validation Accuracy = 0.0152, Validation Loss = 6.2117\n",
            "Epoch 965/2500\n",
            "Epoch 965: Training Accuracy = 0.9707, Training Loss = 0.4012, Validation Accuracy = 0.0152, Validation Loss = 6.2117\n",
            "Epoch 966/2500\n",
            "Epoch 966: Training Accuracy = 0.9922, Training Loss = 0.2145, Validation Accuracy = 0.0146, Validation Loss = 6.3470\n",
            "Epoch 967/2500\n",
            "Epoch 967: Training Accuracy = 0.9902, Training Loss = 0.1606, Validation Accuracy = 0.0137, Validation Loss = 6.4544\n",
            "Epoch 968/2500\n",
            "Epoch 968: Training Accuracy = 0.9902, Training Loss = 0.1606, Validation Accuracy = 0.0137, Validation Loss = 6.4544\n",
            "Epoch 969/2500\n",
            "Epoch 969: Training Accuracy = 0.9922, Training Loss = 0.1311, Validation Accuracy = 0.0152, Validation Loss = 6.5003\n",
            "Epoch 970/2500\n",
            "Epoch 970: Training Accuracy = 0.9922, Training Loss = 0.1311, Validation Accuracy = 0.0152, Validation Loss = 6.5003\n",
            "Epoch 971/2500\n",
            "Epoch 971: Training Accuracy = 0.9863, Training Loss = 0.1359, Validation Accuracy = 0.0146, Validation Loss = 6.5049\n",
            "Epoch 972/2500\n",
            "Epoch 972: Training Accuracy = 0.9844, Training Loss = 0.1397, Validation Accuracy = 0.0149, Validation Loss = 6.5122\n",
            "Epoch 973/2500\n",
            "Epoch 973: Training Accuracy = 0.9844, Training Loss = 0.1397, Validation Accuracy = 0.0149, Validation Loss = 6.5122\n",
            "Epoch 974/2500\n",
            "Epoch 974: Training Accuracy = 0.9902, Training Loss = 0.1150, Validation Accuracy = 0.0140, Validation Loss = 6.5164\n",
            "Epoch 975/2500\n",
            "Epoch 975: Training Accuracy = 0.9902, Training Loss = 0.1150, Validation Accuracy = 0.0140, Validation Loss = 6.5164\n",
            "Epoch 976/2500\n",
            "Epoch 976: Training Accuracy = 0.9863, Training Loss = 0.1265, Validation Accuracy = 0.0146, Validation Loss = 6.4960\n",
            "Epoch 977/2500\n",
            "Epoch 977: Training Accuracy = 0.9922, Training Loss = 0.1125, Validation Accuracy = 0.0143, Validation Loss = 6.4908\n",
            "Epoch 978/2500\n",
            "Epoch 978: Training Accuracy = 0.9922, Training Loss = 0.1125, Validation Accuracy = 0.0143, Validation Loss = 6.4908\n",
            "Epoch 979/2500\n",
            "Epoch 979: Training Accuracy = 0.9863, Training Loss = 0.1350, Validation Accuracy = 0.0149, Validation Loss = 6.5006\n",
            "Epoch 980/2500\n",
            "Epoch 980: Training Accuracy = 0.9863, Training Loss = 0.1350, Validation Accuracy = 0.0149, Validation Loss = 6.5006\n",
            "Epoch 981/2500\n",
            "Epoch 981: Training Accuracy = 0.9863, Training Loss = 0.1461, Validation Accuracy = 0.0140, Validation Loss = 6.4489\n",
            "Epoch 982/2500\n",
            "Epoch 982: Training Accuracy = 0.9883, Training Loss = 0.1692, Validation Accuracy = 0.0159, Validation Loss = 6.4699\n",
            "Epoch 983/2500\n",
            "Epoch 983: Training Accuracy = 0.9883, Training Loss = 0.1692, Validation Accuracy = 0.0159, Validation Loss = 6.4699\n",
            "Epoch 984/2500\n",
            "Epoch 984: Training Accuracy = 0.9785, Training Loss = 0.2951, Validation Accuracy = 0.0159, Validation Loss = 6.4248\n",
            "Epoch 985/2500\n",
            "Epoch 985: Training Accuracy = 0.9785, Training Loss = 0.2951, Validation Accuracy = 0.0159, Validation Loss = 6.4248\n",
            "Epoch 986/2500\n",
            "Epoch 986: Training Accuracy = 0.9629, Training Loss = 0.4335, Validation Accuracy = 0.0146, Validation Loss = 6.3426\n",
            "Epoch 987/2500\n",
            "Epoch 987: Training Accuracy = 0.9785, Training Loss = 0.3080, Validation Accuracy = 0.0170, Validation Loss = 6.2463\n",
            "Epoch 988/2500\n",
            "Epoch 988: Training Accuracy = 0.9785, Training Loss = 0.3080, Validation Accuracy = 0.0170, Validation Loss = 6.2463\n",
            "Epoch 989/2500\n",
            "Epoch 989: Training Accuracy = 0.9863, Training Loss = 0.2004, Validation Accuracy = 0.0155, Validation Loss = 6.3670\n",
            "Epoch 990/2500\n",
            "Epoch 990: Training Accuracy = 0.9863, Training Loss = 0.2004, Validation Accuracy = 0.0155, Validation Loss = 6.3670\n",
            "Epoch 991/2500\n",
            "Epoch 991: Training Accuracy = 0.9961, Training Loss = 0.1163, Validation Accuracy = 0.0152, Validation Loss = 6.3833\n",
            "Epoch 992/2500\n",
            "Epoch 992: Training Accuracy = 0.9863, Training Loss = 0.1491, Validation Accuracy = 0.0159, Validation Loss = 6.4607\n",
            "Epoch 993/2500\n",
            "Epoch 993: Training Accuracy = 0.9863, Training Loss = 0.1491, Validation Accuracy = 0.0159, Validation Loss = 6.4607\n",
            "Epoch 994/2500\n",
            "Epoch 994: Training Accuracy = 0.9844, Training Loss = 0.1270, Validation Accuracy = 0.0156, Validation Loss = 6.4601\n",
            "Epoch 995/2500\n",
            "Epoch 995: Training Accuracy = 0.9844, Training Loss = 0.1270, Validation Accuracy = 0.0156, Validation Loss = 6.4601\n",
            "Epoch 996/2500\n",
            "Epoch 996: Training Accuracy = 0.9902, Training Loss = 0.1051, Validation Accuracy = 0.0147, Validation Loss = 6.4731\n",
            "Epoch 997/2500\n",
            "Epoch 997: Training Accuracy = 0.9922, Training Loss = 0.1005, Validation Accuracy = 0.0150, Validation Loss = 6.4927\n",
            "Epoch 998/2500\n",
            "Epoch 998: Training Accuracy = 0.9922, Training Loss = 0.1005, Validation Accuracy = 0.0150, Validation Loss = 6.4927\n",
            "Epoch 999/2500\n",
            "Epoch 999: Training Accuracy = 0.9883, Training Loss = 0.1115, Validation Accuracy = 0.0152, Validation Loss = 6.4838\n",
            "Epoch 1000/2500\n",
            "Epoch 1000: Training Accuracy = 0.9883, Training Loss = 0.1115, Validation Accuracy = 0.0152, Validation Loss = 6.4838\n",
            "Epoch 1001/2500\n",
            "Epoch 1001: Training Accuracy = 0.9902, Training Loss = 0.1069, Validation Accuracy = 0.0149, Validation Loss = 6.4841\n",
            "Epoch 1002/2500\n",
            "Epoch 1002: Training Accuracy = 0.9922, Training Loss = 0.1314, Validation Accuracy = 0.0158, Validation Loss = 6.4151\n",
            "Epoch 1003/2500\n",
            "Epoch 1003: Training Accuracy = 0.9922, Training Loss = 0.1314, Validation Accuracy = 0.0158, Validation Loss = 6.4151\n",
            "Epoch 1004/2500\n",
            "Epoch 1004: Training Accuracy = 0.9922, Training Loss = 0.1479, Validation Accuracy = 0.0169, Validation Loss = 6.4993\n",
            "Epoch 1005/2500\n",
            "Epoch 1005: Training Accuracy = 0.9922, Training Loss = 0.1479, Validation Accuracy = 0.0169, Validation Loss = 6.4993\n",
            "Epoch 1006/2500\n",
            "Epoch 1006: Training Accuracy = 0.8906, Training Loss = 0.7715, Validation Accuracy = 0.0169, Validation Loss = 6.1664\n",
            "Epoch 1007/2500\n",
            "Epoch 1007: Training Accuracy = 0.9785, Training Loss = 0.3635, Validation Accuracy = 0.0156, Validation Loss = 6.1676\n",
            "Epoch 1008/2500\n",
            "Epoch 1008: Training Accuracy = 0.9785, Training Loss = 0.3635, Validation Accuracy = 0.0156, Validation Loss = 6.1676\n",
            "Epoch 1009/2500\n",
            "Epoch 1009: Training Accuracy = 0.9824, Training Loss = 0.2456, Validation Accuracy = 0.0167, Validation Loss = 6.2610\n",
            "Epoch 1010/2500\n",
            "Epoch 1010: Training Accuracy = 0.9824, Training Loss = 0.2456, Validation Accuracy = 0.0167, Validation Loss = 6.2610\n",
            "Epoch 1011/2500\n",
            "Epoch 1011: Training Accuracy = 0.9922, Training Loss = 0.1396, Validation Accuracy = 0.0167, Validation Loss = 6.3806\n",
            "Epoch 1012/2500\n",
            "Epoch 1012: Training Accuracy = 0.9922, Training Loss = 0.1112, Validation Accuracy = 0.0146, Validation Loss = 6.4171\n",
            "Epoch 1013/2500\n",
            "Epoch 1013: Training Accuracy = 0.9922, Training Loss = 0.1112, Validation Accuracy = 0.0146, Validation Loss = 6.4171\n",
            "Epoch 1014/2500\n",
            "Epoch 1014: Training Accuracy = 0.9785, Training Loss = 0.1418, Validation Accuracy = 0.0158, Validation Loss = 6.4272\n",
            "Epoch 1015/2500\n",
            "Epoch 1015: Training Accuracy = 0.9785, Training Loss = 0.1418, Validation Accuracy = 0.0158, Validation Loss = 6.4272\n",
            "Epoch 1016/2500\n",
            "Epoch 1016: Training Accuracy = 0.9844, Training Loss = 0.1178, Validation Accuracy = 0.0146, Validation Loss = 6.4411\n",
            "Epoch 1017/2500\n",
            "Epoch 1017: Training Accuracy = 0.9922, Training Loss = 0.0946, Validation Accuracy = 0.0147, Validation Loss = 6.4505\n",
            "Epoch 1018/2500\n",
            "Epoch 1018: Training Accuracy = 0.9922, Training Loss = 0.0946, Validation Accuracy = 0.0147, Validation Loss = 6.4505\n",
            "Epoch 1019/2500\n",
            "Epoch 1019: Training Accuracy = 0.9883, Training Loss = 0.1035, Validation Accuracy = 0.0156, Validation Loss = 6.4269\n",
            "Epoch 1020/2500\n",
            "Epoch 1020: Training Accuracy = 0.9883, Training Loss = 0.1035, Validation Accuracy = 0.0156, Validation Loss = 6.4269\n",
            "Epoch 1021/2500\n",
            "Epoch 1021: Training Accuracy = 0.9863, Training Loss = 0.1110, Validation Accuracy = 0.0165, Validation Loss = 6.4033\n",
            "Epoch 1022/2500\n",
            "Epoch 1022: Training Accuracy = 0.9844, Training Loss = 0.1412, Validation Accuracy = 0.0149, Validation Loss = 6.4000\n",
            "Epoch 1023/2500\n",
            "Epoch 1023: Training Accuracy = 0.9844, Training Loss = 0.1412, Validation Accuracy = 0.0149, Validation Loss = 6.4000\n",
            "Epoch 1024/2500\n",
            "Epoch 1024: Training Accuracy = 0.9863, Training Loss = 0.1277, Validation Accuracy = 0.0159, Validation Loss = 6.3984\n",
            "Epoch 1025/2500\n",
            "Epoch 1025: Training Accuracy = 0.9863, Training Loss = 0.1277, Validation Accuracy = 0.0159, Validation Loss = 6.3984\n",
            "Epoch 1026/2500\n",
            "Epoch 1026: Training Accuracy = 0.9492, Training Loss = 0.4295, Validation Accuracy = 0.0200, Validation Loss = 6.5627\n",
            "Epoch 1027/2500\n",
            "Epoch 1027: Training Accuracy = 0.8848, Training Loss = 0.7677, Validation Accuracy = 0.0159, Validation Loss = 6.0787\n",
            "Epoch 1028/2500\n",
            "Epoch 1028: Training Accuracy = 0.8848, Training Loss = 0.7677, Validation Accuracy = 0.0159, Validation Loss = 6.0787\n",
            "Epoch 1029/2500\n",
            "Epoch 1029: Training Accuracy = 0.9805, Training Loss = 0.3365, Validation Accuracy = 0.0153, Validation Loss = 6.0640\n",
            "Epoch 1030/2500\n",
            "Epoch 1030: Training Accuracy = 0.9805, Training Loss = 0.3365, Validation Accuracy = 0.0153, Validation Loss = 6.0640\n",
            "Epoch 1031/2500\n",
            "Epoch 1031: Training Accuracy = 0.9844, Training Loss = 0.2063, Validation Accuracy = 0.0179, Validation Loss = 6.1592\n",
            "Epoch 1032/2500\n",
            "Epoch 1032: Training Accuracy = 0.9746, Training Loss = 0.2011, Validation Accuracy = 0.0167, Validation Loss = 6.2638\n",
            "Epoch 1033/2500\n",
            "Epoch 1033: Training Accuracy = 0.9746, Training Loss = 0.2011, Validation Accuracy = 0.0167, Validation Loss = 6.2638\n",
            "Epoch 1034/2500\n",
            "Epoch 1034: Training Accuracy = 0.9980, Training Loss = 0.0872, Validation Accuracy = 0.0159, Validation Loss = 6.2985\n",
            "Epoch 1035/2500\n",
            "Epoch 1035: Training Accuracy = 0.9980, Training Loss = 0.0872, Validation Accuracy = 0.0159, Validation Loss = 6.2985\n",
            "Epoch 1036/2500\n",
            "Epoch 1036: Training Accuracy = 0.9883, Training Loss = 0.1162, Validation Accuracy = 0.0156, Validation Loss = 6.3233\n",
            "Epoch 1037/2500\n",
            "Epoch 1037: Training Accuracy = 0.9883, Training Loss = 0.1137, Validation Accuracy = 0.0155, Validation Loss = 6.3293\n",
            "Epoch 1038/2500\n",
            "Epoch 1038: Training Accuracy = 0.9883, Training Loss = 0.1137, Validation Accuracy = 0.0155, Validation Loss = 6.3293\n",
            "Epoch 1039/2500\n",
            "Epoch 1039: Training Accuracy = 0.9980, Training Loss = 0.0735, Validation Accuracy = 0.0161, Validation Loss = 6.2896\n",
            "Epoch 1040/2500\n",
            "Epoch 1040: Training Accuracy = 0.9980, Training Loss = 0.0735, Validation Accuracy = 0.0161, Validation Loss = 6.2896\n",
            "Epoch 1041/2500\n",
            "Epoch 1041: Training Accuracy = 0.9902, Training Loss = 0.1048, Validation Accuracy = 0.0156, Validation Loss = 6.3093\n",
            "Epoch 1042/2500\n",
            "Epoch 1042: Training Accuracy = 0.9805, Training Loss = 0.1477, Validation Accuracy = 0.0161, Validation Loss = 6.2879\n",
            "Epoch 1043/2500\n",
            "Epoch 1043: Training Accuracy = 0.9805, Training Loss = 0.1477, Validation Accuracy = 0.0161, Validation Loss = 6.2879\n",
            "Epoch 1044/2500\n",
            "Epoch 1044: Training Accuracy = 0.9844, Training Loss = 0.1255, Validation Accuracy = 0.0169, Validation Loss = 6.2917\n",
            "Epoch 1045/2500\n",
            "Epoch 1045: Training Accuracy = 0.9844, Training Loss = 0.1255, Validation Accuracy = 0.0169, Validation Loss = 6.2917\n",
            "Epoch 1046/2500\n",
            "Epoch 1046: Training Accuracy = 0.9902, Training Loss = 0.1090, Validation Accuracy = 0.0161, Validation Loss = 6.2272\n",
            "Epoch 1047/2500\n",
            "Epoch 1047: Training Accuracy = 0.9902, Training Loss = 0.1509, Validation Accuracy = 0.0164, Validation Loss = 6.2412\n",
            "Epoch 1048/2500\n",
            "Epoch 1048: Training Accuracy = 0.9902, Training Loss = 0.1509, Validation Accuracy = 0.0164, Validation Loss = 6.2412\n",
            "Epoch 1049/2500\n",
            "Epoch 1049: Training Accuracy = 0.9180, Training Loss = 0.6118, Validation Accuracy = 0.0190, Validation Loss = 6.2792\n",
            "Epoch 1050/2500\n",
            "Epoch 1050: Training Accuracy = 0.9180, Training Loss = 0.6118, Validation Accuracy = 0.0190, Validation Loss = 6.2792\n",
            "Epoch 1051/2500\n",
            "Epoch 1051: Training Accuracy = 0.9609, Training Loss = 0.4806, Validation Accuracy = 0.0182, Validation Loss = 5.8355\n",
            "Epoch 1052/2500\n",
            "Epoch 1052: Training Accuracy = 0.9746, Training Loss = 0.3249, Validation Accuracy = 0.0176, Validation Loss = 6.0270\n",
            "Epoch 1053/2500\n",
            "Epoch 1053: Training Accuracy = 0.9746, Training Loss = 0.3249, Validation Accuracy = 0.0176, Validation Loss = 6.0270\n",
            "Epoch 1054/2500\n",
            "Epoch 1054: Training Accuracy = 0.9922, Training Loss = 0.1553, Validation Accuracy = 0.0179, Validation Loss = 6.0907\n",
            "Epoch 1055/2500\n",
            "Epoch 1055: Training Accuracy = 0.9922, Training Loss = 0.1553, Validation Accuracy = 0.0179, Validation Loss = 6.0907\n",
            "Epoch 1056/2500\n",
            "Epoch 1056: Training Accuracy = 0.9922, Training Loss = 0.1146, Validation Accuracy = 0.0172, Validation Loss = 6.1260\n",
            "Epoch 1057/2500\n",
            "Epoch 1057: Training Accuracy = 0.9961, Training Loss = 0.0977, Validation Accuracy = 0.0176, Validation Loss = 6.1758\n",
            "Epoch 1058/2500\n",
            "Epoch 1058: Training Accuracy = 0.9961, Training Loss = 0.0977, Validation Accuracy = 0.0176, Validation Loss = 6.1758\n",
            "Epoch 1059/2500\n",
            "Epoch 1059: Training Accuracy = 0.9883, Training Loss = 0.1102, Validation Accuracy = 0.0179, Validation Loss = 6.1976\n",
            "Epoch 1060/2500\n",
            "Epoch 1060: Training Accuracy = 0.9883, Training Loss = 0.1102, Validation Accuracy = 0.0179, Validation Loss = 6.1976\n",
            "Epoch 1061/2500\n",
            "Epoch 1061: Training Accuracy = 0.9863, Training Loss = 0.1079, Validation Accuracy = 0.0176, Validation Loss = 6.1895\n",
            "Epoch 1062/2500\n",
            "Epoch 1062: Training Accuracy = 0.9844, Training Loss = 0.1236, Validation Accuracy = 0.0169, Validation Loss = 6.1858\n",
            "Epoch 1063/2500\n",
            "Epoch 1063: Training Accuracy = 0.9844, Training Loss = 0.1236, Validation Accuracy = 0.0169, Validation Loss = 6.1858\n",
            "Epoch 1064/2500\n",
            "Epoch 1064: Training Accuracy = 0.9941, Training Loss = 0.0875, Validation Accuracy = 0.0167, Validation Loss = 6.2035\n",
            "Epoch 1065/2500\n",
            "Epoch 1065: Training Accuracy = 0.9941, Training Loss = 0.0875, Validation Accuracy = 0.0167, Validation Loss = 6.2035\n",
            "Epoch 1066/2500\n",
            "Epoch 1066: Training Accuracy = 0.9863, Training Loss = 0.1153, Validation Accuracy = 0.0173, Validation Loss = 6.1639\n",
            "Epoch 1067/2500\n",
            "Epoch 1067: Training Accuracy = 0.9863, Training Loss = 0.1206, Validation Accuracy = 0.0170, Validation Loss = 6.1745\n",
            "Epoch 1068/2500\n",
            "Epoch 1068: Training Accuracy = 0.9863, Training Loss = 0.1206, Validation Accuracy = 0.0170, Validation Loss = 6.1745\n",
            "Epoch 1069/2500\n",
            "Epoch 1069: Training Accuracy = 0.9785, Training Loss = 0.1457, Validation Accuracy = 0.0175, Validation Loss = 6.1596\n",
            "Epoch 1070/2500\n",
            "Epoch 1070: Training Accuracy = 0.9785, Training Loss = 0.1457, Validation Accuracy = 0.0175, Validation Loss = 6.1596\n",
            "Epoch 1071/2500\n",
            "Epoch 1071: Training Accuracy = 0.5293, Training Loss = 1.8559, Validation Accuracy = 0.0150, Validation Loss = 6.3970\n",
            "Epoch 1072/2500\n",
            "Epoch 1072: Training Accuracy = 0.8340, Training Loss = 0.8624, Validation Accuracy = 0.0190, Validation Loss = 5.7973\n",
            "Epoch 1073/2500\n",
            "Epoch 1073: Training Accuracy = 0.8340, Training Loss = 0.8624, Validation Accuracy = 0.0190, Validation Loss = 5.7973\n",
            "Epoch 1074/2500\n",
            "Epoch 1074: Training Accuracy = 0.9707, Training Loss = 0.4107, Validation Accuracy = 0.0165, Validation Loss = 5.8410\n",
            "Epoch 1075/2500\n",
            "Epoch 1075: Training Accuracy = 0.9707, Training Loss = 0.4107, Validation Accuracy = 0.0165, Validation Loss = 5.8410\n",
            "Epoch 1076/2500\n",
            "Epoch 1076: Training Accuracy = 0.9883, Training Loss = 0.2052, Validation Accuracy = 0.0191, Validation Loss = 5.9150\n",
            "Epoch 1077/2500\n",
            "Epoch 1077: Training Accuracy = 0.9883, Training Loss = 0.1736, Validation Accuracy = 0.0179, Validation Loss = 5.9465\n",
            "Epoch 1078/2500\n",
            "Epoch 1078: Training Accuracy = 0.9883, Training Loss = 0.1736, Validation Accuracy = 0.0179, Validation Loss = 5.9465\n",
            "Epoch 1079/2500\n",
            "Epoch 1079: Training Accuracy = 0.9961, Training Loss = 0.1033, Validation Accuracy = 0.0197, Validation Loss = 6.0203\n",
            "Epoch 1080/2500\n",
            "Epoch 1080: Training Accuracy = 0.9961, Training Loss = 0.1033, Validation Accuracy = 0.0197, Validation Loss = 6.0203\n",
            "Epoch 1081/2500\n",
            "Epoch 1081: Training Accuracy = 0.9902, Training Loss = 0.1069, Validation Accuracy = 0.0181, Validation Loss = 6.0102\n",
            "Epoch 1082/2500\n",
            "Epoch 1082: Training Accuracy = 0.9766, Training Loss = 0.1593, Validation Accuracy = 0.0182, Validation Loss = 6.0327\n",
            "Epoch 1083/2500\n",
            "Epoch 1083: Training Accuracy = 0.9766, Training Loss = 0.1593, Validation Accuracy = 0.0182, Validation Loss = 6.0327\n",
            "Epoch 1084/2500\n",
            "Epoch 1084: Training Accuracy = 0.9922, Training Loss = 0.0960, Validation Accuracy = 0.0179, Validation Loss = 6.0132\n",
            "Epoch 1085/2500\n",
            "Epoch 1085: Training Accuracy = 0.9922, Training Loss = 0.0960, Validation Accuracy = 0.0179, Validation Loss = 6.0132\n",
            "Epoch 1086/2500\n",
            "Epoch 1086: Training Accuracy = 0.9844, Training Loss = 0.1176, Validation Accuracy = 0.0175, Validation Loss = 5.9973\n",
            "Epoch 1087/2500\n",
            "Epoch 1087: Training Accuracy = 0.9844, Training Loss = 0.1253, Validation Accuracy = 0.0187, Validation Loss = 6.0098\n",
            "Epoch 1088/2500\n",
            "Epoch 1088: Training Accuracy = 0.9844, Training Loss = 0.1253, Validation Accuracy = 0.0187, Validation Loss = 6.0098\n",
            "Epoch 1089/2500\n",
            "Epoch 1089: Training Accuracy = 0.9805, Training Loss = 0.1511, Validation Accuracy = 0.0194, Validation Loss = 5.9841\n",
            "Epoch 1090/2500\n",
            "Epoch 1090: Training Accuracy = 0.9805, Training Loss = 0.1511, Validation Accuracy = 0.0194, Validation Loss = 5.9841\n",
            "Epoch 1091/2500\n",
            "Epoch 1091: Training Accuracy = 0.9961, Training Loss = 0.0896, Validation Accuracy = 0.0194, Validation Loss = 5.9590\n",
            "Epoch 1092/2500\n",
            "Epoch 1092: Training Accuracy = 0.9922, Training Loss = 0.1789, Validation Accuracy = 0.0197, Validation Loss = 6.0085\n",
            "Epoch 1093/2500\n",
            "Epoch 1093: Training Accuracy = 0.9922, Training Loss = 0.1789, Validation Accuracy = 0.0197, Validation Loss = 6.0085\n",
            "Epoch 1094/2500\n",
            "Epoch 1094: Training Accuracy = 0.8926, Training Loss = 0.7462, Validation Accuracy = 0.0205, Validation Loss = 5.7452\n",
            "Epoch 1095/2500\n",
            "Epoch 1095: Training Accuracy = 0.8926, Training Loss = 0.7462, Validation Accuracy = 0.0205, Validation Loss = 5.7452\n",
            "Epoch 1096/2500\n",
            "Epoch 1096: Training Accuracy = 0.9824, Training Loss = 0.3464, Validation Accuracy = 0.0191, Validation Loss = 5.5917\n",
            "Epoch 1097/2500\n",
            "Epoch 1097: Training Accuracy = 0.9902, Training Loss = 0.2395, Validation Accuracy = 0.0196, Validation Loss = 5.7059\n",
            "Epoch 1098/2500\n",
            "Epoch 1098: Training Accuracy = 0.9902, Training Loss = 0.2395, Validation Accuracy = 0.0196, Validation Loss = 5.7059\n",
            "Epoch 1099/2500\n",
            "Epoch 1099: Training Accuracy = 0.9922, Training Loss = 0.1503, Validation Accuracy = 0.0179, Validation Loss = 5.7635\n",
            "Epoch 1100/2500\n",
            "Epoch 1100: Training Accuracy = 0.9922, Training Loss = 0.1503, Validation Accuracy = 0.0179, Validation Loss = 5.7635\n",
            "Epoch 1101/2500\n",
            "Epoch 1101: Training Accuracy = 0.9941, Training Loss = 0.1093, Validation Accuracy = 0.0197, Validation Loss = 5.8246\n",
            "Epoch 1102/2500\n",
            "Epoch 1102: Training Accuracy = 0.9941, Training Loss = 0.1061, Validation Accuracy = 0.0197, Validation Loss = 5.8301\n",
            "Epoch 1103/2500\n",
            "Epoch 1103: Training Accuracy = 0.9941, Training Loss = 0.1061, Validation Accuracy = 0.0197, Validation Loss = 5.8301\n",
            "Epoch 1104/2500\n",
            "Epoch 1104: Training Accuracy = 0.9844, Training Loss = 0.1252, Validation Accuracy = 0.0208, Validation Loss = 5.8507\n",
            "Epoch 1105/2500\n",
            "Epoch 1105: Training Accuracy = 0.9844, Training Loss = 0.1252, Validation Accuracy = 0.0208, Validation Loss = 5.8507\n",
            "Epoch 1106/2500\n",
            "Epoch 1106: Training Accuracy = 0.9883, Training Loss = 0.1203, Validation Accuracy = 0.0181, Validation Loss = 5.8340\n",
            "Epoch 1107/2500\n",
            "Epoch 1107: Training Accuracy = 0.9922, Training Loss = 0.0992, Validation Accuracy = 0.0196, Validation Loss = 5.8421\n",
            "Epoch 1108/2500\n",
            "Epoch 1108: Training Accuracy = 0.9922, Training Loss = 0.0992, Validation Accuracy = 0.0196, Validation Loss = 5.8421\n",
            "Epoch 1109/2500\n",
            "Epoch 1109: Training Accuracy = 0.9863, Training Loss = 0.1307, Validation Accuracy = 0.0197, Validation Loss = 5.8400\n",
            "Epoch 1110/2500\n",
            "Epoch 1110: Training Accuracy = 0.9863, Training Loss = 0.1307, Validation Accuracy = 0.0197, Validation Loss = 5.8400\n",
            "Epoch 1111/2500\n",
            "Epoch 1111: Training Accuracy = 0.9863, Training Loss = 0.1290, Validation Accuracy = 0.0213, Validation Loss = 5.8220\n",
            "Epoch 1112/2500\n",
            "Epoch 1112: Training Accuracy = 0.9883, Training Loss = 0.1461, Validation Accuracy = 0.0210, Validation Loss = 5.8006\n",
            "Epoch 1113/2500\n",
            "Epoch 1113: Training Accuracy = 0.9883, Training Loss = 0.1461, Validation Accuracy = 0.0210, Validation Loss = 5.8006\n",
            "Epoch 1114/2500\n",
            "Epoch 1114: Training Accuracy = 0.9863, Training Loss = 0.1604, Validation Accuracy = 0.0214, Validation Loss = 5.8242\n",
            "Epoch 1115/2500\n",
            "Epoch 1115: Training Accuracy = 0.9863, Training Loss = 0.1604, Validation Accuracy = 0.0214, Validation Loss = 5.8242\n",
            "Epoch 1116/2500\n",
            "Epoch 1116: Training Accuracy = 0.9863, Training Loss = 0.2200, Validation Accuracy = 0.0199, Validation Loss = 5.8220\n",
            "Epoch 1117/2500\n",
            "Epoch 1117: Training Accuracy = 0.9844, Training Loss = 0.2730, Validation Accuracy = 0.0234, Validation Loss = 5.8170\n",
            "Epoch 1118/2500\n",
            "Epoch 1118: Training Accuracy = 0.9844, Training Loss = 0.2730, Validation Accuracy = 0.0234, Validation Loss = 5.8170\n",
            "Epoch 1119/2500\n",
            "Epoch 1119: Training Accuracy = 0.9863, Training Loss = 0.2320, Validation Accuracy = 0.0220, Validation Loss = 5.7289\n",
            "Epoch 1120/2500\n",
            "Epoch 1120: Training Accuracy = 0.9863, Training Loss = 0.2320, Validation Accuracy = 0.0220, Validation Loss = 5.7289\n",
            "Epoch 1121/2500\n",
            "Epoch 1121: Training Accuracy = 0.9805, Training Loss = 0.1930, Validation Accuracy = 0.0210, Validation Loss = 5.6546\n",
            "Epoch 1122/2500\n",
            "Epoch 1122: Training Accuracy = 0.9902, Training Loss = 0.1397, Validation Accuracy = 0.0234, Validation Loss = 5.7215\n",
            "Epoch 1123/2500\n",
            "Epoch 1123: Training Accuracy = 0.9902, Training Loss = 0.1397, Validation Accuracy = 0.0234, Validation Loss = 5.7215\n",
            "Epoch 1124/2500\n",
            "Epoch 1124: Training Accuracy = 0.9941, Training Loss = 0.0957, Validation Accuracy = 0.0220, Validation Loss = 5.7296\n",
            "Epoch 1125/2500\n",
            "Epoch 1125: Training Accuracy = 0.9941, Training Loss = 0.0957, Validation Accuracy = 0.0220, Validation Loss = 5.7296\n",
            "Epoch 1126/2500\n",
            "Epoch 1126: Training Accuracy = 0.9922, Training Loss = 0.1059, Validation Accuracy = 0.0238, Validation Loss = 5.7637\n",
            "Epoch 1127/2500\n",
            "Epoch 1127: Training Accuracy = 0.9863, Training Loss = 0.1233, Validation Accuracy = 0.0214, Validation Loss = 5.7810\n",
            "Epoch 1128/2500\n",
            "Epoch 1128: Training Accuracy = 0.9863, Training Loss = 0.1233, Validation Accuracy = 0.0214, Validation Loss = 5.7810\n",
            "Epoch 1129/2500\n",
            "Epoch 1129: Training Accuracy = 0.9883, Training Loss = 0.1084, Validation Accuracy = 0.0210, Validation Loss = 5.7885\n",
            "Epoch 1130/2500\n",
            "Epoch 1130: Training Accuracy = 0.9883, Training Loss = 0.1084, Validation Accuracy = 0.0210, Validation Loss = 5.7885\n",
            "Epoch 1131/2500\n",
            "Epoch 1131: Training Accuracy = 0.9902, Training Loss = 0.1062, Validation Accuracy = 0.0220, Validation Loss = 5.7614\n",
            "Epoch 1132/2500\n",
            "Epoch 1132: Training Accuracy = 0.9805, Training Loss = 0.1450, Validation Accuracy = 0.0241, Validation Loss = 5.7571\n",
            "Epoch 1133/2500\n",
            "Epoch 1133: Training Accuracy = 0.9805, Training Loss = 0.1450, Validation Accuracy = 0.0241, Validation Loss = 5.7571\n",
            "Epoch 1134/2500\n",
            "Epoch 1134: Training Accuracy = 0.9863, Training Loss = 0.1631, Validation Accuracy = 0.0250, Validation Loss = 5.8197\n",
            "Epoch 1135/2500\n",
            "Epoch 1135: Training Accuracy = 0.9863, Training Loss = 0.1631, Validation Accuracy = 0.0250, Validation Loss = 5.8197\n",
            "Epoch 1136/2500\n",
            "Epoch 1136: Training Accuracy = 0.8809, Training Loss = 0.7408, Validation Accuracy = 0.0241, Validation Loss = 5.5725\n",
            "Epoch 1137/2500\n",
            "Epoch 1137: Training Accuracy = 0.9609, Training Loss = 0.4423, Validation Accuracy = 0.0249, Validation Loss = 5.3755\n",
            "Epoch 1138/2500\n",
            "Epoch 1138: Training Accuracy = 0.9609, Training Loss = 0.4423, Validation Accuracy = 0.0249, Validation Loss = 5.3755\n",
            "Epoch 1139/2500\n",
            "Epoch 1139: Training Accuracy = 0.9844, Training Loss = 0.2372, Validation Accuracy = 0.0238, Validation Loss = 5.4326\n",
            "Epoch 1140/2500\n",
            "Epoch 1140: Training Accuracy = 0.9844, Training Loss = 0.2372, Validation Accuracy = 0.0238, Validation Loss = 5.4326\n",
            "Epoch 1141/2500\n",
            "Epoch 1141: Training Accuracy = 0.9844, Training Loss = 0.1656, Validation Accuracy = 0.0232, Validation Loss = 5.5142\n",
            "Epoch 1142/2500\n",
            "Epoch 1142: Training Accuracy = 0.9883, Training Loss = 0.1420, Validation Accuracy = 0.0238, Validation Loss = 5.5158\n",
            "Epoch 1143/2500\n",
            "Epoch 1143: Training Accuracy = 0.9883, Training Loss = 0.1420, Validation Accuracy = 0.0238, Validation Loss = 5.5158\n",
            "Epoch 1144/2500\n",
            "Epoch 1144: Training Accuracy = 0.9844, Training Loss = 0.1238, Validation Accuracy = 0.0246, Validation Loss = 5.5604\n",
            "Epoch 1145/2500\n",
            "Epoch 1145: Training Accuracy = 0.9844, Training Loss = 0.1238, Validation Accuracy = 0.0246, Validation Loss = 5.5604\n",
            "Epoch 1146/2500\n",
            "Epoch 1146: Training Accuracy = 0.9844, Training Loss = 0.1129, Validation Accuracy = 0.0229, Validation Loss = 5.5636\n",
            "Epoch 1147/2500\n",
            "Epoch 1147: Training Accuracy = 0.9805, Training Loss = 0.1345, Validation Accuracy = 0.0257, Validation Loss = 5.5571\n",
            "Epoch 1148/2500\n",
            "Epoch 1148: Training Accuracy = 0.9805, Training Loss = 0.1345, Validation Accuracy = 0.0257, Validation Loss = 5.5571\n",
            "Epoch 1149/2500\n",
            "Epoch 1149: Training Accuracy = 0.9883, Training Loss = 0.1007, Validation Accuracy = 0.0250, Validation Loss = 5.5555\n",
            "Epoch 1150/2500\n",
            "Epoch 1150: Training Accuracy = 0.9883, Training Loss = 0.1007, Validation Accuracy = 0.0250, Validation Loss = 5.5555\n",
            "Epoch 1151/2500\n",
            "Epoch 1151: Training Accuracy = 0.9863, Training Loss = 0.1049, Validation Accuracy = 0.0260, Validation Loss = 5.5324\n",
            "Epoch 1152/2500\n",
            "Epoch 1152: Training Accuracy = 0.9863, Training Loss = 0.1064, Validation Accuracy = 0.0238, Validation Loss = 5.5355\n",
            "Epoch 1153/2500\n",
            "Epoch 1153: Training Accuracy = 0.9863, Training Loss = 0.1064, Validation Accuracy = 0.0238, Validation Loss = 5.5355\n",
            "Epoch 1154/2500\n",
            "Epoch 1154: Training Accuracy = 0.9961, Training Loss = 0.0724, Validation Accuracy = 0.0246, Validation Loss = 5.5273\n",
            "Epoch 1155/2500\n",
            "Epoch 1155: Training Accuracy = 0.9961, Training Loss = 0.0724, Validation Accuracy = 0.0246, Validation Loss = 5.5273\n",
            "Epoch 1156/2500\n",
            "Epoch 1156: Training Accuracy = 0.9844, Training Loss = 0.1311, Validation Accuracy = 0.0264, Validation Loss = 5.5490\n",
            "Epoch 1157/2500\n",
            "Epoch 1157: Training Accuracy = 0.9902, Training Loss = 0.1367, Validation Accuracy = 0.0275, Validation Loss = 5.4902\n",
            "Epoch 1158/2500\n",
            "Epoch 1158: Training Accuracy = 0.9902, Training Loss = 0.1367, Validation Accuracy = 0.0275, Validation Loss = 5.4902\n",
            "Epoch 1159/2500\n",
            "Epoch 1159: Training Accuracy = 0.7109, Training Loss = 1.3569, Validation Accuracy = 0.0270, Validation Loss = 5.4011\n",
            "Epoch 1160/2500\n",
            "Epoch 1160: Training Accuracy = 0.7109, Training Loss = 1.3569, Validation Accuracy = 0.0270, Validation Loss = 5.4011\n",
            "Epoch 1161/2500\n",
            "Epoch 1161: Training Accuracy = 0.9590, Training Loss = 0.4420, Validation Accuracy = 0.0305, Validation Loss = 5.2037\n",
            "Epoch 1162/2500\n",
            "Epoch 1162: Training Accuracy = 0.9824, Training Loss = 0.2835, Validation Accuracy = 0.0302, Validation Loss = 5.1370\n",
            "Epoch 1163/2500\n",
            "Epoch 1163: Training Accuracy = 0.9824, Training Loss = 0.2835, Validation Accuracy = 0.0302, Validation Loss = 5.1370\n",
            "Epoch 1164/2500\n",
            "Epoch 1164: Training Accuracy = 0.9941, Training Loss = 0.1630, Validation Accuracy = 0.0284, Validation Loss = 5.2091\n",
            "Epoch 1165/2500\n",
            "Epoch 1165: Training Accuracy = 0.9941, Training Loss = 0.1630, Validation Accuracy = 0.0284, Validation Loss = 5.2091\n",
            "Epoch 1166/2500\n",
            "Epoch 1166: Training Accuracy = 0.9766, Training Loss = 0.1677, Validation Accuracy = 0.0281, Validation Loss = 5.2583\n",
            "Epoch 1167/2500\n",
            "Epoch 1167: Training Accuracy = 0.9922, Training Loss = 0.1055, Validation Accuracy = 0.0275, Validation Loss = 5.2746\n",
            "Epoch 1168/2500\n",
            "Epoch 1168: Training Accuracy = 0.9922, Training Loss = 0.1055, Validation Accuracy = 0.0275, Validation Loss = 5.2746\n",
            "Epoch 1169/2500\n",
            "Epoch 1169: Training Accuracy = 0.9863, Training Loss = 0.1126, Validation Accuracy = 0.0284, Validation Loss = 5.2868\n",
            "Epoch 1170/2500\n",
            "Epoch 1170: Training Accuracy = 0.9863, Training Loss = 0.1126, Validation Accuracy = 0.0284, Validation Loss = 5.2868\n",
            "Epoch 1171/2500\n",
            "Epoch 1171: Training Accuracy = 0.9883, Training Loss = 0.1007, Validation Accuracy = 0.0293, Validation Loss = 5.2942\n",
            "Epoch 1172/2500\n",
            "Epoch 1172: Training Accuracy = 0.9844, Training Loss = 0.1141, Validation Accuracy = 0.0281, Validation Loss = 5.2837\n",
            "Epoch 1173/2500\n",
            "Epoch 1173: Training Accuracy = 0.9844, Training Loss = 0.1141, Validation Accuracy = 0.0281, Validation Loss = 5.2837\n",
            "Epoch 1174/2500\n",
            "Epoch 1174: Training Accuracy = 0.9863, Training Loss = 0.1041, Validation Accuracy = 0.0276, Validation Loss = 5.2795\n",
            "Epoch 1175/2500\n",
            "Epoch 1175: Training Accuracy = 0.9863, Training Loss = 0.1041, Validation Accuracy = 0.0276, Validation Loss = 5.2795\n",
            "Epoch 1176/2500\n",
            "Epoch 1176: Training Accuracy = 0.9902, Training Loss = 0.0922, Validation Accuracy = 0.0305, Validation Loss = 5.2650\n",
            "Epoch 1177/2500\n",
            "Epoch 1177: Training Accuracy = 0.9844, Training Loss = 0.1283, Validation Accuracy = 0.0307, Validation Loss = 5.2664\n",
            "Epoch 1178/2500\n",
            "Epoch 1178: Training Accuracy = 0.9844, Training Loss = 0.1283, Validation Accuracy = 0.0307, Validation Loss = 5.2664\n",
            "Epoch 1179/2500\n",
            "Epoch 1179: Training Accuracy = 0.9863, Training Loss = 0.1235, Validation Accuracy = 0.0322, Validation Loss = 5.2667\n",
            "Epoch 1180/2500\n",
            "Epoch 1180: Training Accuracy = 0.9863, Training Loss = 0.1235, Validation Accuracy = 0.0322, Validation Loss = 5.2667\n",
            "Epoch 1181/2500\n",
            "Epoch 1181: Training Accuracy = 0.9883, Training Loss = 0.1849, Validation Accuracy = 0.0322, Validation Loss = 5.2775\n",
            "Epoch 1182/2500\n",
            "Epoch 1182: Training Accuracy = 0.8281, Training Loss = 0.8793, Validation Accuracy = 0.0310, Validation Loss = 5.2214\n",
            "Epoch 1183/2500\n",
            "Epoch 1183: Training Accuracy = 0.8281, Training Loss = 0.8793, Validation Accuracy = 0.0310, Validation Loss = 5.2214\n",
            "Epoch 1184/2500\n",
            "Epoch 1184: Training Accuracy = 0.9551, Training Loss = 0.3830, Validation Accuracy = 0.0378, Validation Loss = 4.9265\n",
            "Epoch 1185/2500\n",
            "Epoch 1185: Training Accuracy = 0.9551, Training Loss = 0.3830, Validation Accuracy = 0.0378, Validation Loss = 4.9265\n",
            "Epoch 1186/2500\n",
            "Epoch 1186: Training Accuracy = 0.9844, Training Loss = 0.2092, Validation Accuracy = 0.0357, Validation Loss = 4.8936\n",
            "Epoch 1187/2500\n",
            "Epoch 1187: Training Accuracy = 0.9902, Training Loss = 0.1597, Validation Accuracy = 0.0367, Validation Loss = 4.9379\n",
            "Epoch 1188/2500\n",
            "Epoch 1188: Training Accuracy = 0.9902, Training Loss = 0.1597, Validation Accuracy = 0.0367, Validation Loss = 4.9379\n",
            "Epoch 1189/2500\n",
            "Epoch 1189: Training Accuracy = 0.9785, Training Loss = 0.1630, Validation Accuracy = 0.0348, Validation Loss = 4.9615\n",
            "Epoch 1190/2500\n",
            "Epoch 1190: Training Accuracy = 0.9785, Training Loss = 0.1630, Validation Accuracy = 0.0348, Validation Loss = 4.9615\n",
            "Epoch 1191/2500\n",
            "Epoch 1191: Training Accuracy = 0.9883, Training Loss = 0.1041, Validation Accuracy = 0.0361, Validation Loss = 5.0001\n",
            "Epoch 1192/2500\n",
            "Epoch 1192: Training Accuracy = 0.9844, Training Loss = 0.1156, Validation Accuracy = 0.0354, Validation Loss = 5.0103\n",
            "Epoch 1193/2500\n",
            "Epoch 1193: Training Accuracy = 0.9844, Training Loss = 0.1156, Validation Accuracy = 0.0354, Validation Loss = 5.0103\n",
            "Epoch 1194/2500\n",
            "Epoch 1194: Training Accuracy = 0.9844, Training Loss = 0.1096, Validation Accuracy = 0.0339, Validation Loss = 5.0068\n",
            "Epoch 1195/2500\n",
            "Epoch 1195: Training Accuracy = 0.9844, Training Loss = 0.1096, Validation Accuracy = 0.0339, Validation Loss = 5.0068\n",
            "Epoch 1196/2500\n",
            "Epoch 1196: Training Accuracy = 0.9902, Training Loss = 0.0861, Validation Accuracy = 0.0339, Validation Loss = 5.0214\n",
            "Epoch 1197/2500\n",
            "Epoch 1197: Training Accuracy = 0.9883, Training Loss = 0.1016, Validation Accuracy = 0.0346, Validation Loss = 5.0024\n",
            "Epoch 1198/2500\n",
            "Epoch 1198: Training Accuracy = 0.9883, Training Loss = 0.1016, Validation Accuracy = 0.0346, Validation Loss = 5.0024\n",
            "Epoch 1199/2500\n",
            "Epoch 1199: Training Accuracy = 0.9863, Training Loss = 0.1055, Validation Accuracy = 0.0349, Validation Loss = 5.0160\n",
            "Epoch 1200/2500\n",
            "Epoch 1200: Training Accuracy = 0.9863, Training Loss = 0.1055, Validation Accuracy = 0.0349, Validation Loss = 5.0160\n",
            "Epoch 1201/2500\n",
            "Epoch 1201: Training Accuracy = 0.9844, Training Loss = 0.1166, Validation Accuracy = 0.0340, Validation Loss = 4.9966\n",
            "Epoch 1202/2500\n",
            "Epoch 1202: Training Accuracy = 0.9883, Training Loss = 0.1216, Validation Accuracy = 0.0331, Validation Loss = 5.0096\n",
            "Epoch 1203/2500\n",
            "Epoch 1203: Training Accuracy = 0.9883, Training Loss = 0.1216, Validation Accuracy = 0.0331, Validation Loss = 5.0096\n",
            "Epoch 1204/2500\n",
            "Epoch 1204: Training Accuracy = 0.9766, Training Loss = 0.2503, Validation Accuracy = 0.0354, Validation Loss = 5.2277\n",
            "Epoch 1205/2500\n",
            "Epoch 1205: Training Accuracy = 0.9766, Training Loss = 0.2503, Validation Accuracy = 0.0354, Validation Loss = 5.2277\n",
            "Epoch 1206/2500\n",
            "Epoch 1206: Training Accuracy = 0.9082, Training Loss = 0.6981, Validation Accuracy = 0.0354, Validation Loss = 5.0470\n",
            "Epoch 1207/2500\n",
            "Epoch 1207: Training Accuracy = 0.9766, Training Loss = 0.3541, Validation Accuracy = 0.0417, Validation Loss = 4.6966\n",
            "Epoch 1208/2500\n",
            "Epoch 1208: Training Accuracy = 0.9766, Training Loss = 0.3541, Validation Accuracy = 0.0417, Validation Loss = 4.6966\n",
            "Epoch 1209/2500\n",
            "Epoch 1209: Training Accuracy = 0.9863, Training Loss = 0.2268, Validation Accuracy = 0.0427, Validation Loss = 4.6050\n",
            "Epoch 1210/2500\n",
            "Epoch 1210: Training Accuracy = 0.9863, Training Loss = 0.2268, Validation Accuracy = 0.0427, Validation Loss = 4.6050\n",
            "Epoch 1211/2500\n",
            "Epoch 1211: Training Accuracy = 0.9922, Training Loss = 0.1295, Validation Accuracy = 0.0411, Validation Loss = 4.6593\n",
            "Epoch 1212/2500\n",
            "Epoch 1212: Training Accuracy = 0.9824, Training Loss = 0.1539, Validation Accuracy = 0.0445, Validation Loss = 4.6803\n",
            "Epoch 1213/2500\n",
            "Epoch 1213: Training Accuracy = 0.9824, Training Loss = 0.1539, Validation Accuracy = 0.0445, Validation Loss = 4.6803\n",
            "Epoch 1214/2500\n",
            "Epoch 1214: Training Accuracy = 0.9902, Training Loss = 0.1012, Validation Accuracy = 0.0416, Validation Loss = 4.7049\n",
            "Epoch 1215/2500\n",
            "Epoch 1215: Training Accuracy = 0.9902, Training Loss = 0.1012, Validation Accuracy = 0.0416, Validation Loss = 4.7049\n",
            "Epoch 1216/2500\n",
            "Epoch 1216: Training Accuracy = 0.9941, Training Loss = 0.0799, Validation Accuracy = 0.0410, Validation Loss = 4.7077\n",
            "Epoch 1217/2500\n",
            "Epoch 1217: Training Accuracy = 0.9863, Training Loss = 0.1144, Validation Accuracy = 0.0416, Validation Loss = 4.7081\n",
            "Epoch 1218/2500\n",
            "Epoch 1218: Training Accuracy = 0.9863, Training Loss = 0.1144, Validation Accuracy = 0.0416, Validation Loss = 4.7081\n",
            "Epoch 1219/2500\n",
            "Epoch 1219: Training Accuracy = 0.9902, Training Loss = 0.0941, Validation Accuracy = 0.0413, Validation Loss = 4.7155\n",
            "Epoch 1220/2500\n",
            "Epoch 1220: Training Accuracy = 0.9902, Training Loss = 0.0941, Validation Accuracy = 0.0413, Validation Loss = 4.7155\n",
            "Epoch 1221/2500\n",
            "Epoch 1221: Training Accuracy = 0.9961, Training Loss = 0.0693, Validation Accuracy = 0.0402, Validation Loss = 4.7256\n",
            "Epoch 1222/2500\n",
            "Epoch 1222: Training Accuracy = 0.9922, Training Loss = 0.1006, Validation Accuracy = 0.0414, Validation Loss = 4.7255\n",
            "Epoch 1223/2500\n",
            "Epoch 1223: Training Accuracy = 0.9922, Training Loss = 0.1006, Validation Accuracy = 0.0414, Validation Loss = 4.7255\n",
            "Epoch 1224/2500\n",
            "Epoch 1224: Training Accuracy = 0.9883, Training Loss = 0.1019, Validation Accuracy = 0.0410, Validation Loss = 4.7328\n",
            "Epoch 1225/2500\n",
            "Epoch 1225: Training Accuracy = 0.9883, Training Loss = 0.1019, Validation Accuracy = 0.0410, Validation Loss = 4.7328\n",
            "Epoch 1226/2500\n",
            "Epoch 1226: Training Accuracy = 0.9941, Training Loss = 0.0848, Validation Accuracy = 0.0454, Validation Loss = 4.6993\n",
            "Epoch 1227/2500\n",
            "Epoch 1227: Training Accuracy = 0.9922, Training Loss = 0.1128, Validation Accuracy = 0.0427, Validation Loss = 4.7067\n",
            "Epoch 1228/2500\n",
            "Epoch 1228: Training Accuracy = 0.9922, Training Loss = 0.1128, Validation Accuracy = 0.0427, Validation Loss = 4.7067\n",
            "Epoch 1229/2500\n",
            "Epoch 1229: Training Accuracy = 0.7148, Training Loss = 1.5580, Validation Accuracy = 0.0285, Validation Loss = 5.2579\n",
            "Epoch 1230/2500\n",
            "Epoch 1230: Training Accuracy = 0.7148, Training Loss = 1.5580, Validation Accuracy = 0.0285, Validation Loss = 5.2579\n",
            "Epoch 1231/2500\n",
            "Epoch 1231: Training Accuracy = 0.9082, Training Loss = 0.6638, Validation Accuracy = 0.0499, Validation Loss = 4.5896\n",
            "Epoch 1232/2500\n",
            "Epoch 1232: Training Accuracy = 0.9688, Training Loss = 0.3748, Validation Accuracy = 0.0563, Validation Loss = 4.2509\n",
            "Epoch 1233/2500\n",
            "Epoch 1233: Training Accuracy = 0.9688, Training Loss = 0.3748, Validation Accuracy = 0.0563, Validation Loss = 4.2509\n",
            "Epoch 1234/2500\n",
            "Epoch 1234: Training Accuracy = 0.9805, Training Loss = 0.2303, Validation Accuracy = 0.0594, Validation Loss = 4.2519\n",
            "Epoch 1235/2500\n",
            "Epoch 1235: Training Accuracy = 0.9805, Training Loss = 0.2303, Validation Accuracy = 0.0594, Validation Loss = 4.2519\n",
            "Epoch 1236/2500\n",
            "Epoch 1236: Training Accuracy = 0.9941, Training Loss = 0.1238, Validation Accuracy = 0.0562, Validation Loss = 4.2862\n",
            "Epoch 1237/2500\n",
            "Epoch 1237: Training Accuracy = 0.9922, Training Loss = 0.1141, Validation Accuracy = 0.0540, Validation Loss = 4.3552\n",
            "Epoch 1238/2500\n",
            "Epoch 1238: Training Accuracy = 0.9922, Training Loss = 0.1141, Validation Accuracy = 0.0540, Validation Loss = 4.3552\n",
            "Epoch 1239/2500\n",
            "Epoch 1239: Training Accuracy = 0.9844, Training Loss = 0.1332, Validation Accuracy = 0.0545, Validation Loss = 4.3673\n",
            "Epoch 1240/2500\n",
            "Epoch 1240: Training Accuracy = 0.9844, Training Loss = 0.1332, Validation Accuracy = 0.0545, Validation Loss = 4.3673\n",
            "Epoch 1241/2500\n",
            "Epoch 1241: Training Accuracy = 0.9883, Training Loss = 0.1049, Validation Accuracy = 0.0524, Validation Loss = 4.3849\n",
            "Epoch 1242/2500\n",
            "Epoch 1242: Training Accuracy = 0.9941, Training Loss = 0.0951, Validation Accuracy = 0.0515, Validation Loss = 4.3865\n",
            "Epoch 1243/2500\n",
            "Epoch 1243: Training Accuracy = 0.9941, Training Loss = 0.0951, Validation Accuracy = 0.0515, Validation Loss = 4.3865\n",
            "Epoch 1244/2500\n",
            "Epoch 1244: Training Accuracy = 0.9902, Training Loss = 0.1004, Validation Accuracy = 0.0548, Validation Loss = 4.3757\n",
            "Epoch 1245/2500\n",
            "Epoch 1245: Training Accuracy = 0.9902, Training Loss = 0.1004, Validation Accuracy = 0.0548, Validation Loss = 4.3757\n",
            "Epoch 1246/2500\n",
            "Epoch 1246: Training Accuracy = 0.9922, Training Loss = 0.0918, Validation Accuracy = 0.0534, Validation Loss = 4.3987\n",
            "Epoch 1247/2500\n",
            "Epoch 1247: Training Accuracy = 0.9941, Training Loss = 0.0945, Validation Accuracy = 0.0560, Validation Loss = 4.3638\n",
            "Epoch 1248/2500\n",
            "Epoch 1248: Training Accuracy = 0.9941, Training Loss = 0.0945, Validation Accuracy = 0.0560, Validation Loss = 4.3638\n",
            "Epoch 1249/2500\n",
            "Epoch 1249: Training Accuracy = 0.9805, Training Loss = 0.1466, Validation Accuracy = 0.0565, Validation Loss = 4.3739\n",
            "Epoch 1250/2500\n",
            "Epoch 1250: Training Accuracy = 0.9805, Training Loss = 0.1466, Validation Accuracy = 0.0565, Validation Loss = 4.3739\n",
            "Epoch 1251/2500\n",
            "Epoch 1251: Training Accuracy = 0.9941, Training Loss = 0.1202, Validation Accuracy = 0.0556, Validation Loss = 4.4092\n",
            "Epoch 1252/2500\n",
            "Epoch 1252: Training Accuracy = 0.9844, Training Loss = 0.2067, Validation Accuracy = 0.0501, Validation Loss = 4.5318\n",
            "Epoch 1253/2500\n",
            "Epoch 1253: Training Accuracy = 0.9844, Training Loss = 0.2067, Validation Accuracy = 0.0501, Validation Loss = 4.5318\n",
            "Epoch 1254/2500\n",
            "Epoch 1254: Training Accuracy = 0.9766, Training Loss = 0.2349, Validation Accuracy = 0.0601, Validation Loss = 4.3383\n",
            "Epoch 1255/2500\n",
            "Epoch 1255: Training Accuracy = 0.9766, Training Loss = 0.2349, Validation Accuracy = 0.0601, Validation Loss = 4.3383\n",
            "Epoch 1256/2500\n",
            "Epoch 1256: Training Accuracy = 0.9941, Training Loss = 0.1475, Validation Accuracy = 0.0632, Validation Loss = 4.2526\n",
            "Epoch 1257/2500\n",
            "Epoch 1257: Training Accuracy = 0.9883, Training Loss = 0.2354, Validation Accuracy = 0.0615, Validation Loss = 4.2586\n",
            "Epoch 1258/2500\n",
            "Epoch 1258: Training Accuracy = 0.9883, Training Loss = 0.2354, Validation Accuracy = 0.0615, Validation Loss = 4.2586\n",
            "Epoch 1259/2500\n",
            "Epoch 1259: Training Accuracy = 0.9902, Training Loss = 0.1803, Validation Accuracy = 0.0650, Validation Loss = 4.1983\n",
            "Epoch 1260/2500\n",
            "Epoch 1260: Training Accuracy = 0.9902, Training Loss = 0.1803, Validation Accuracy = 0.0650, Validation Loss = 4.1983\n",
            "Epoch 1261/2500\n",
            "Epoch 1261: Training Accuracy = 0.9941, Training Loss = 0.1090, Validation Accuracy = 0.0704, Validation Loss = 4.1965\n",
            "Epoch 1262/2500\n",
            "Epoch 1262: Training Accuracy = 0.9922, Training Loss = 0.1018, Validation Accuracy = 0.0700, Validation Loss = 4.1763\n",
            "Epoch 1263/2500\n",
            "Epoch 1263: Training Accuracy = 0.9922, Training Loss = 0.1018, Validation Accuracy = 0.0700, Validation Loss = 4.1763\n",
            "Epoch 1264/2500\n",
            "Epoch 1264: Training Accuracy = 0.9824, Training Loss = 0.1237, Validation Accuracy = 0.0677, Validation Loss = 4.2099\n",
            "Epoch 1265/2500\n",
            "Epoch 1265: Training Accuracy = 0.9824, Training Loss = 0.1237, Validation Accuracy = 0.0677, Validation Loss = 4.2099\n",
            "Epoch 1266/2500\n",
            "Epoch 1266: Training Accuracy = 0.9941, Training Loss = 0.0716, Validation Accuracy = 0.0656, Validation Loss = 4.2186\n",
            "Epoch 1267/2500\n",
            "Epoch 1267: Training Accuracy = 0.9883, Training Loss = 0.1055, Validation Accuracy = 0.0679, Validation Loss = 4.1480\n",
            "Epoch 1268/2500\n",
            "Epoch 1268: Training Accuracy = 0.9883, Training Loss = 0.1055, Validation Accuracy = 0.0679, Validation Loss = 4.1480\n",
            "Epoch 1269/2500\n",
            "Epoch 1269: Training Accuracy = 0.9922, Training Loss = 0.0803, Validation Accuracy = 0.0697, Validation Loss = 4.2011\n",
            "Epoch 1270/2500\n",
            "Epoch 1270: Training Accuracy = 0.9922, Training Loss = 0.0803, Validation Accuracy = 0.0697, Validation Loss = 4.2011\n",
            "Epoch 1271/2500\n",
            "Epoch 1271: Training Accuracy = 0.9922, Training Loss = 0.0880, Validation Accuracy = 0.0698, Validation Loss = 4.1804\n",
            "Epoch 1272/2500\n",
            "Epoch 1272: Training Accuracy = 0.9922, Training Loss = 0.1087, Validation Accuracy = 0.0726, Validation Loss = 4.2060\n",
            "Epoch 1273/2500\n",
            "Epoch 1273: Training Accuracy = 0.9922, Training Loss = 0.1087, Validation Accuracy = 0.0726, Validation Loss = 4.2060\n",
            "Epoch 1274/2500\n",
            "Epoch 1274: Training Accuracy = 0.2578, Training Loss = 3.1840, Validation Accuracy = 0.0402, Validation Loss = 4.7841\n",
            "Epoch 1275/2500\n",
            "Epoch 1275: Training Accuracy = 0.2578, Training Loss = 3.1840, Validation Accuracy = 0.0402, Validation Loss = 4.7841\n",
            "Epoch 1276/2500\n",
            "Epoch 1276: Training Accuracy = 0.8047, Training Loss = 1.0188, Validation Accuracy = 0.0714, Validation Loss = 4.0333\n",
            "Epoch 1277/2500\n",
            "Epoch 1277: Training Accuracy = 0.9395, Training Loss = 0.5100, Validation Accuracy = 0.0902, Validation Loss = 3.6593\n",
            "Epoch 1278/2500\n",
            "Epoch 1278: Training Accuracy = 0.9395, Training Loss = 0.5100, Validation Accuracy = 0.0902, Validation Loss = 3.6593\n",
            "Epoch 1279/2500\n",
            "Epoch 1279: Training Accuracy = 0.9883, Training Loss = 0.2661, Validation Accuracy = 0.1048, Validation Loss = 3.6160\n",
            "Epoch 1280/2500\n",
            "Epoch 1280: Training Accuracy = 0.9883, Training Loss = 0.2661, Validation Accuracy = 0.1048, Validation Loss = 3.6160\n",
            "Epoch 1281/2500\n",
            "Epoch 1281: Training Accuracy = 0.9805, Training Loss = 0.1918, Validation Accuracy = 0.1017, Validation Loss = 3.6077\n",
            "Epoch 1282/2500\n",
            "Epoch 1282: Training Accuracy = 0.9785, Training Loss = 0.1817, Validation Accuracy = 0.1013, Validation Loss = 3.6352\n",
            "Epoch 1283/2500\n",
            "Epoch 1283: Training Accuracy = 0.9785, Training Loss = 0.1817, Validation Accuracy = 0.1013, Validation Loss = 3.6352\n",
            "Epoch 1284/2500\n",
            "Epoch 1284: Training Accuracy = 0.9883, Training Loss = 0.1163, Validation Accuracy = 0.1022, Validation Loss = 3.6630\n",
            "Epoch 1285/2500\n",
            "Epoch 1285: Training Accuracy = 0.9883, Training Loss = 0.1163, Validation Accuracy = 0.1022, Validation Loss = 3.6630\n",
            "Epoch 1286/2500\n",
            "Epoch 1286: Training Accuracy = 0.9883, Training Loss = 0.1035, Validation Accuracy = 0.0991, Validation Loss = 3.6748\n",
            "Epoch 1287/2500\n",
            "Epoch 1287: Training Accuracy = 0.9844, Training Loss = 0.1252, Validation Accuracy = 0.1046, Validation Loss = 3.6803\n",
            "Epoch 1288/2500\n",
            "Epoch 1288: Training Accuracy = 0.9844, Training Loss = 0.1252, Validation Accuracy = 0.1046, Validation Loss = 3.6803\n",
            "Epoch 1289/2500\n",
            "Epoch 1289: Training Accuracy = 0.9922, Training Loss = 0.0838, Validation Accuracy = 0.1034, Validation Loss = 3.6868\n",
            "Epoch 1290/2500\n",
            "Epoch 1290: Training Accuracy = 0.9922, Training Loss = 0.0838, Validation Accuracy = 0.1034, Validation Loss = 3.6868\n",
            "Epoch 1291/2500\n",
            "Epoch 1291: Training Accuracy = 0.9883, Training Loss = 0.0968, Validation Accuracy = 0.1007, Validation Loss = 3.6918\n",
            "Epoch 1292/2500\n",
            "Epoch 1292: Training Accuracy = 0.9902, Training Loss = 0.0991, Validation Accuracy = 0.1025, Validation Loss = 3.6852\n",
            "Epoch 1293/2500\n",
            "Epoch 1293: Training Accuracy = 0.9902, Training Loss = 0.0991, Validation Accuracy = 0.1025, Validation Loss = 3.6852\n",
            "Epoch 1294/2500\n",
            "Epoch 1294: Training Accuracy = 0.9902, Training Loss = 0.0902, Validation Accuracy = 0.1007, Validation Loss = 3.7127\n",
            "Epoch 1295/2500\n",
            "Epoch 1295: Training Accuracy = 0.9902, Training Loss = 0.0902, Validation Accuracy = 0.1007, Validation Loss = 3.7127\n",
            "Epoch 1296/2500\n",
            "Epoch 1296: Training Accuracy = 0.9922, Training Loss = 0.0995, Validation Accuracy = 0.1051, Validation Loss = 3.7091\n",
            "Epoch 1297/2500\n",
            "Epoch 1297: Training Accuracy = 0.9883, Training Loss = 0.1258, Validation Accuracy = 0.0997, Validation Loss = 3.7203\n",
            "Epoch 1298/2500\n",
            "Epoch 1298: Training Accuracy = 0.9883, Training Loss = 0.1258, Validation Accuracy = 0.0997, Validation Loss = 3.7203\n",
            "Epoch 1299/2500\n",
            "Epoch 1299: Training Accuracy = 0.9863, Training Loss = 0.1290, Validation Accuracy = 0.1020, Validation Loss = 3.7094\n",
            "Epoch 1300/2500\n",
            "Epoch 1300: Training Accuracy = 0.9863, Training Loss = 0.1290, Validation Accuracy = 0.1020, Validation Loss = 3.7094\n",
            "Epoch 1301/2500\n",
            "Epoch 1301: Training Accuracy = 0.5234, Training Loss = 1.7506, Validation Accuracy = 0.0625, Validation Loss = 4.4380\n",
            "Epoch 1302/2500\n",
            "Epoch 1302: Training Accuracy = 0.9004, Training Loss = 0.5821, Validation Accuracy = 0.1032, Validation Loss = 3.6658\n",
            "Epoch 1303/2500\n",
            "Epoch 1303: Training Accuracy = 0.9004, Training Loss = 0.5821, Validation Accuracy = 0.1032, Validation Loss = 3.6658\n",
            "Epoch 1304/2500\n",
            "Epoch 1304: Training Accuracy = 0.9844, Training Loss = 0.2747, Validation Accuracy = 0.1284, Validation Loss = 3.3408\n",
            "Epoch 1305/2500\n",
            "Epoch 1305: Training Accuracy = 0.9844, Training Loss = 0.2747, Validation Accuracy = 0.1284, Validation Loss = 3.3408\n",
            "Epoch 1306/2500\n",
            "Epoch 1306: Training Accuracy = 0.9922, Training Loss = 0.1613, Validation Accuracy = 0.1345, Validation Loss = 3.3141\n",
            "Epoch 1307/2500\n",
            "Epoch 1307: Training Accuracy = 0.9941, Training Loss = 0.1172, Validation Accuracy = 0.1382, Validation Loss = 3.2735\n",
            "Epoch 1308/2500\n",
            "Epoch 1308: Training Accuracy = 0.9941, Training Loss = 0.1172, Validation Accuracy = 0.1382, Validation Loss = 3.2735\n",
            "Epoch 1309/2500\n",
            "Epoch 1309: Training Accuracy = 0.9941, Training Loss = 0.0942, Validation Accuracy = 0.1357, Validation Loss = 3.3006\n",
            "Epoch 1310/2500\n",
            "Epoch 1310: Training Accuracy = 0.9941, Training Loss = 0.0942, Validation Accuracy = 0.1357, Validation Loss = 3.3006\n",
            "Epoch 1311/2500\n",
            "Epoch 1311: Training Accuracy = 0.9883, Training Loss = 0.1063, Validation Accuracy = 0.1371, Validation Loss = 3.3460\n",
            "Epoch 1312/2500\n",
            "Epoch 1312: Training Accuracy = 0.9863, Training Loss = 0.1088, Validation Accuracy = 0.1363, Validation Loss = 3.3407\n",
            "Epoch 1313/2500\n",
            "Epoch 1313: Training Accuracy = 0.9863, Training Loss = 0.1088, Validation Accuracy = 0.1363, Validation Loss = 3.3407\n",
            "Epoch 1314/2500\n",
            "Epoch 1314: Training Accuracy = 0.9824, Training Loss = 0.1149, Validation Accuracy = 0.1359, Validation Loss = 3.3633\n",
            "Epoch 1315/2500\n",
            "Epoch 1315: Training Accuracy = 0.9824, Training Loss = 0.1149, Validation Accuracy = 0.1359, Validation Loss = 3.3633\n",
            "Epoch 1316/2500\n",
            "Epoch 1316: Training Accuracy = 0.9883, Training Loss = 0.0969, Validation Accuracy = 0.1391, Validation Loss = 3.3649\n",
            "Epoch 1317/2500\n",
            "Epoch 1317: Training Accuracy = 0.9883, Training Loss = 0.0995, Validation Accuracy = 0.1337, Validation Loss = 3.3971\n",
            "Epoch 1318/2500\n",
            "Epoch 1318: Training Accuracy = 0.9883, Training Loss = 0.0995, Validation Accuracy = 0.1337, Validation Loss = 3.3971\n",
            "Epoch 1319/2500\n",
            "Epoch 1319: Training Accuracy = 0.9922, Training Loss = 0.0840, Validation Accuracy = 0.1353, Validation Loss = 3.3868\n",
            "Epoch 1320/2500\n",
            "Epoch 1320: Training Accuracy = 0.9922, Training Loss = 0.0840, Validation Accuracy = 0.1353, Validation Loss = 3.3868\n",
            "Epoch 1321/2500\n",
            "Epoch 1321: Training Accuracy = 0.9902, Training Loss = 0.0971, Validation Accuracy = 0.1354, Validation Loss = 3.4136\n",
            "Epoch 1322/2500\n",
            "Epoch 1322: Training Accuracy = 0.9863, Training Loss = 0.1201, Validation Accuracy = 0.1360, Validation Loss = 3.4068\n",
            "Epoch 1323/2500\n",
            "Epoch 1323: Training Accuracy = 0.9863, Training Loss = 0.1201, Validation Accuracy = 0.1360, Validation Loss = 3.4068\n",
            "Epoch 1324/2500\n",
            "Epoch 1324: Training Accuracy = 0.9863, Training Loss = 0.1237, Validation Accuracy = 0.1435, Validation Loss = 3.3986\n",
            "Epoch 1325/2500\n",
            "Epoch 1325: Training Accuracy = 0.9863, Training Loss = 0.1237, Validation Accuracy = 0.1435, Validation Loss = 3.3986\n",
            "Epoch 1326/2500\n",
            "Epoch 1326: Training Accuracy = 0.9902, Training Loss = 0.1141, Validation Accuracy = 0.1310, Validation Loss = 3.4410\n",
            "Epoch 1327/2500\n",
            "Epoch 1327: Training Accuracy = 0.9883, Training Loss = 0.1800, Validation Accuracy = 0.1366, Validation Loss = 3.4541\n",
            "Epoch 1328/2500\n",
            "Epoch 1328: Training Accuracy = 0.9883, Training Loss = 0.1800, Validation Accuracy = 0.1366, Validation Loss = 3.4541\n",
            "Epoch 1329/2500\n",
            "Epoch 1329: Training Accuracy = 0.6367, Training Loss = 1.5247, Validation Accuracy = 0.0938, Validation Loss = 3.9687\n",
            "Epoch 1330/2500\n",
            "Epoch 1330: Training Accuracy = 0.6367, Training Loss = 1.5247, Validation Accuracy = 0.0938, Validation Loss = 3.9687\n",
            "Epoch 1331/2500\n",
            "Epoch 1331: Training Accuracy = 0.9746, Training Loss = 0.3590, Validation Accuracy = 0.1377, Validation Loss = 3.3703\n",
            "Epoch 1332/2500\n",
            "Epoch 1332: Training Accuracy = 0.9844, Training Loss = 0.2562, Validation Accuracy = 0.1687, Validation Loss = 3.0296\n",
            "Epoch 1333/2500\n",
            "Epoch 1333: Training Accuracy = 0.9844, Training Loss = 0.2562, Validation Accuracy = 0.1687, Validation Loss = 3.0296\n",
            "Epoch 1334/2500\n",
            "Epoch 1334: Training Accuracy = 0.9941, Training Loss = 0.1354, Validation Accuracy = 0.1814, Validation Loss = 2.9600\n",
            "Epoch 1335/2500\n",
            "Epoch 1335: Training Accuracy = 0.9941, Training Loss = 0.1354, Validation Accuracy = 0.1814, Validation Loss = 2.9600\n",
            "Epoch 1336/2500\n",
            "Epoch 1336: Training Accuracy = 0.9922, Training Loss = 0.1087, Validation Accuracy = 0.1832, Validation Loss = 2.9843\n",
            "Epoch 1337/2500\n",
            "Epoch 1337: Training Accuracy = 0.9883, Training Loss = 0.1084, Validation Accuracy = 0.1892, Validation Loss = 2.9782\n",
            "Epoch 1338/2500\n",
            "Epoch 1338: Training Accuracy = 0.9883, Training Loss = 0.1084, Validation Accuracy = 0.1892, Validation Loss = 2.9782\n",
            "Epoch 1339/2500\n",
            "Epoch 1339: Training Accuracy = 0.9922, Training Loss = 0.0848, Validation Accuracy = 0.1904, Validation Loss = 2.9956\n",
            "Epoch 1340/2500\n",
            "Epoch 1340: Training Accuracy = 0.9922, Training Loss = 0.0848, Validation Accuracy = 0.1904, Validation Loss = 2.9956\n",
            "Epoch 1341/2500\n",
            "Epoch 1341: Training Accuracy = 0.9883, Training Loss = 0.0958, Validation Accuracy = 0.1845, Validation Loss = 3.0180\n",
            "Epoch 1342/2500\n",
            "Epoch 1342: Training Accuracy = 0.9805, Training Loss = 0.1243, Validation Accuracy = 0.1838, Validation Loss = 3.0120\n",
            "Epoch 1343/2500\n",
            "Epoch 1343: Training Accuracy = 0.9805, Training Loss = 0.1243, Validation Accuracy = 0.1838, Validation Loss = 3.0120\n",
            "Epoch 1344/2500\n",
            "Epoch 1344: Training Accuracy = 0.9883, Training Loss = 0.0913, Validation Accuracy = 0.1857, Validation Loss = 3.0375\n",
            "Epoch 1345/2500\n",
            "Epoch 1345: Training Accuracy = 0.9883, Training Loss = 0.0913, Validation Accuracy = 0.1857, Validation Loss = 3.0375\n",
            "Epoch 1346/2500\n",
            "Epoch 1346: Training Accuracy = 0.9883, Training Loss = 0.0948, Validation Accuracy = 0.1842, Validation Loss = 3.0562\n",
            "Epoch 1347/2500\n",
            "Epoch 1347: Training Accuracy = 0.9902, Training Loss = 0.0922, Validation Accuracy = 0.1878, Validation Loss = 3.0485\n",
            "Epoch 1348/2500\n",
            "Epoch 1348: Training Accuracy = 0.9902, Training Loss = 0.0922, Validation Accuracy = 0.1878, Validation Loss = 3.0485\n",
            "Epoch 1349/2500\n",
            "Epoch 1349: Training Accuracy = 0.9824, Training Loss = 0.1139, Validation Accuracy = 0.1796, Validation Loss = 3.0782\n",
            "Epoch 1350/2500\n",
            "Epoch 1350: Training Accuracy = 0.9824, Training Loss = 0.1139, Validation Accuracy = 0.1796, Validation Loss = 3.0782\n",
            "Epoch 1351/2500\n",
            "Epoch 1351: Training Accuracy = 0.9922, Training Loss = 0.0858, Validation Accuracy = 0.1829, Validation Loss = 3.0476\n",
            "Epoch 1352/2500\n",
            "Epoch 1352: Training Accuracy = 0.9824, Training Loss = 0.1351, Validation Accuracy = 0.1863, Validation Loss = 3.0635\n",
            "Epoch 1353/2500\n",
            "Epoch 1353: Training Accuracy = 0.9824, Training Loss = 0.1351, Validation Accuracy = 0.1863, Validation Loss = 3.0635\n",
            "Epoch 1354/2500\n",
            "Epoch 1354: Training Accuracy = 0.9902, Training Loss = 0.1121, Validation Accuracy = 0.1869, Validation Loss = 3.0776\n",
            "Epoch 1355/2500\n",
            "Epoch 1355: Training Accuracy = 0.9902, Training Loss = 0.1121, Validation Accuracy = 0.1869, Validation Loss = 3.0776\n",
            "Epoch 1356/2500\n",
            "Epoch 1356: Training Accuracy = 0.9922, Training Loss = 0.1029, Validation Accuracy = 0.1884, Validation Loss = 3.0954\n",
            "Epoch 1357/2500\n",
            "Epoch 1357: Training Accuracy = 0.9902, Training Loss = 0.1385, Validation Accuracy = 0.1864, Validation Loss = 3.0451\n",
            "Epoch 1358/2500\n",
            "Epoch 1358: Training Accuracy = 0.9902, Training Loss = 0.1385, Validation Accuracy = 0.1864, Validation Loss = 3.0451\n",
            "Epoch 1359/2500\n",
            "Epoch 1359: Training Accuracy = 0.9883, Training Loss = 0.1521, Validation Accuracy = 0.1936, Validation Loss = 3.0368\n",
            "Epoch 1360/2500\n",
            "Epoch 1360: Training Accuracy = 0.9883, Training Loss = 0.1521, Validation Accuracy = 0.1936, Validation Loss = 3.0368\n",
            "Epoch 1361/2500\n",
            "Epoch 1361: Training Accuracy = 0.9922, Training Loss = 0.1138, Validation Accuracy = 0.1937, Validation Loss = 3.0165\n",
            "Epoch 1362/2500\n",
            "Epoch 1362: Training Accuracy = 0.9863, Training Loss = 0.1442, Validation Accuracy = 0.1957, Validation Loss = 3.0014\n",
            "Epoch 1363/2500\n",
            "Epoch 1363: Training Accuracy = 0.9863, Training Loss = 0.1442, Validation Accuracy = 0.1957, Validation Loss = 3.0014\n",
            "Epoch 1364/2500\n",
            "Epoch 1364: Training Accuracy = 0.9883, Training Loss = 0.1287, Validation Accuracy = 0.2077, Validation Loss = 2.9473\n",
            "Epoch 1365/2500\n",
            "Epoch 1365: Training Accuracy = 0.9883, Training Loss = 0.1287, Validation Accuracy = 0.2077, Validation Loss = 2.9473\n",
            "Epoch 1366/2500\n",
            "Epoch 1366: Training Accuracy = 0.9863, Training Loss = 0.1223, Validation Accuracy = 0.1992, Validation Loss = 2.9870\n",
            "Epoch 1367/2500\n",
            "Epoch 1367: Training Accuracy = 0.9961, Training Loss = 0.0855, Validation Accuracy = 0.2203, Validation Loss = 2.8501\n",
            "Epoch 1368/2500\n",
            "Epoch 1368: Training Accuracy = 0.9961, Training Loss = 0.0855, Validation Accuracy = 0.2203, Validation Loss = 2.8501\n",
            "Epoch 1369/2500\n",
            "Epoch 1369: Training Accuracy = 0.9902, Training Loss = 0.0902, Validation Accuracy = 0.2327, Validation Loss = 2.8393\n",
            "Epoch 1370/2500\n",
            "Epoch 1370: Training Accuracy = 0.9902, Training Loss = 0.0902, Validation Accuracy = 0.2327, Validation Loss = 2.8393\n",
            "Epoch 1371/2500\n",
            "Epoch 1371: Training Accuracy = 0.9961, Training Loss = 0.0560, Validation Accuracy = 0.2197, Validation Loss = 2.8487\n",
            "Epoch 1372/2500\n",
            "Epoch 1372: Training Accuracy = 0.9883, Training Loss = 0.0906, Validation Accuracy = 0.2279, Validation Loss = 2.8275\n",
            "Epoch 1373/2500\n",
            "Epoch 1373: Training Accuracy = 0.9883, Training Loss = 0.0906, Validation Accuracy = 0.2279, Validation Loss = 2.8275\n",
            "Epoch 1374/2500\n",
            "Epoch 1374: Training Accuracy = 0.9922, Training Loss = 0.0855, Validation Accuracy = 0.2311, Validation Loss = 2.8020\n",
            "Epoch 1375/2500\n",
            "Epoch 1375: Training Accuracy = 0.9922, Training Loss = 0.0855, Validation Accuracy = 0.2311, Validation Loss = 2.8020\n",
            "Epoch 1376/2500\n",
            "Epoch 1376: Training Accuracy = 0.9922, Training Loss = 0.0854, Validation Accuracy = 0.2359, Validation Loss = 2.7950\n",
            "Epoch 1377/2500\n",
            "Epoch 1377: Training Accuracy = 0.9883, Training Loss = 0.1042, Validation Accuracy = 0.2356, Validation Loss = 2.7793\n",
            "Epoch 1378/2500\n",
            "Epoch 1378: Training Accuracy = 0.9883, Training Loss = 0.1042, Validation Accuracy = 0.2356, Validation Loss = 2.7793\n",
            "Epoch 1379/2500\n",
            "Epoch 1379: Training Accuracy = 0.9922, Training Loss = 0.0978, Validation Accuracy = 0.2333, Validation Loss = 2.8792\n",
            "Epoch 1380/2500\n",
            "Epoch 1380: Training Accuracy = 0.9922, Training Loss = 0.0978, Validation Accuracy = 0.2333, Validation Loss = 2.8792\n",
            "Epoch 1381/2500\n",
            "Epoch 1381: Training Accuracy = 0.9941, Training Loss = 0.1222, Validation Accuracy = 0.2265, Validation Loss = 2.9018\n",
            "Epoch 1382/2500\n",
            "Epoch 1382: Training Accuracy = 0.9785, Training Loss = 0.2171, Validation Accuracy = 0.2292, Validation Loss = 2.8561\n",
            "Epoch 1383/2500\n",
            "Epoch 1383: Training Accuracy = 0.9785, Training Loss = 0.2171, Validation Accuracy = 0.2292, Validation Loss = 2.8561\n",
            "Epoch 1384/2500\n",
            "Epoch 1384: Training Accuracy = 0.9922, Training Loss = 0.1364, Validation Accuracy = 0.2522, Validation Loss = 2.7323\n",
            "Epoch 1385/2500\n",
            "Epoch 1385: Training Accuracy = 0.9922, Training Loss = 0.1364, Validation Accuracy = 0.2522, Validation Loss = 2.7323\n",
            "Epoch 1386/2500\n",
            "Epoch 1386: Training Accuracy = 0.9863, Training Loss = 0.1123, Validation Accuracy = 0.2651, Validation Loss = 2.6270\n",
            "Epoch 1387/2500\n",
            "Epoch 1387: Training Accuracy = 0.9902, Training Loss = 0.0920, Validation Accuracy = 0.2904, Validation Loss = 2.5264\n",
            "Epoch 1388/2500\n",
            "Epoch 1388: Training Accuracy = 0.9902, Training Loss = 0.0920, Validation Accuracy = 0.2904, Validation Loss = 2.5264\n",
            "Epoch 1389/2500\n",
            "Epoch 1389: Training Accuracy = 0.9863, Training Loss = 0.0840, Validation Accuracy = 0.2842, Validation Loss = 2.5171\n",
            "Epoch 1390/2500\n",
            "Epoch 1390: Training Accuracy = 0.9863, Training Loss = 0.0840, Validation Accuracy = 0.2842, Validation Loss = 2.5171\n",
            "Epoch 1391/2500\n",
            "Epoch 1391: Training Accuracy = 0.9941, Training Loss = 0.0537, Validation Accuracy = 0.2950, Validation Loss = 2.4904\n",
            "Epoch 1392/2500\n",
            "Epoch 1392: Training Accuracy = 0.9902, Training Loss = 0.0653, Validation Accuracy = 0.2971, Validation Loss = 2.5061\n",
            "Epoch 1393/2500\n",
            "Epoch 1393: Training Accuracy = 0.9902, Training Loss = 0.0653, Validation Accuracy = 0.2971, Validation Loss = 2.5061\n",
            "Epoch 1394/2500\n",
            "Epoch 1394: Training Accuracy = 0.9883, Training Loss = 0.0687, Validation Accuracy = 0.2965, Validation Loss = 2.5011\n",
            "Epoch 1395/2500\n",
            "Epoch 1395: Training Accuracy = 0.9883, Training Loss = 0.0687, Validation Accuracy = 0.2965, Validation Loss = 2.5011\n",
            "Epoch 1396/2500\n",
            "Epoch 1396: Training Accuracy = 0.9863, Training Loss = 0.0757, Validation Accuracy = 0.2843, Validation Loss = 2.5264\n",
            "Epoch 1397/2500\n",
            "Epoch 1397: Training Accuracy = 0.9863, Training Loss = 0.0994, Validation Accuracy = 0.2859, Validation Loss = 2.5549\n",
            "Epoch 1398/2500\n",
            "Epoch 1398: Training Accuracy = 0.9863, Training Loss = 0.0994, Validation Accuracy = 0.2859, Validation Loss = 2.5549\n",
            "Epoch 1399/2500\n",
            "Epoch 1399: Training Accuracy = 0.9941, Training Loss = 0.0744, Validation Accuracy = 0.2812, Validation Loss = 2.5801\n",
            "Epoch 1400/2500\n",
            "Epoch 1400: Training Accuracy = 0.9941, Training Loss = 0.0744, Validation Accuracy = 0.2812, Validation Loss = 2.5801\n",
            "Epoch 1401/2500\n",
            "Epoch 1401: Training Accuracy = 0.9805, Training Loss = 0.1442, Validation Accuracy = 0.2605, Validation Loss = 2.6531\n",
            "Epoch 1402/2500\n",
            "Epoch 1402: Training Accuracy = 0.9902, Training Loss = 0.1378, Validation Accuracy = 0.2778, Validation Loss = 2.5738\n",
            "Epoch 1403/2500\n",
            "Epoch 1403: Training Accuracy = 0.9902, Training Loss = 0.1378, Validation Accuracy = 0.2778, Validation Loss = 2.5738\n",
            "Epoch 1404/2500\n",
            "Epoch 1404: Training Accuracy = 0.9863, Training Loss = 0.1548, Validation Accuracy = 0.2687, Validation Loss = 2.6231\n",
            "Epoch 1405/2500\n",
            "Epoch 1405: Training Accuracy = 0.9863, Training Loss = 0.1548, Validation Accuracy = 0.2687, Validation Loss = 2.6231\n",
            "Epoch 1406/2500\n",
            "Epoch 1406: Training Accuracy = 0.9922, Training Loss = 0.1375, Validation Accuracy = 0.2853, Validation Loss = 2.5304\n",
            "Epoch 1407/2500\n",
            "Epoch 1407: Training Accuracy = 0.9883, Training Loss = 0.1322, Validation Accuracy = 0.3262, Validation Loss = 2.3666\n",
            "Epoch 1408/2500\n",
            "Epoch 1408: Training Accuracy = 0.9883, Training Loss = 0.1322, Validation Accuracy = 0.3262, Validation Loss = 2.3666\n",
            "Epoch 1409/2500\n",
            "Epoch 1409: Training Accuracy = 0.9844, Training Loss = 0.1121, Validation Accuracy = 0.3388, Validation Loss = 2.2600\n",
            "Epoch 1410/2500\n",
            "Epoch 1410: Training Accuracy = 0.9844, Training Loss = 0.1121, Validation Accuracy = 0.3388, Validation Loss = 2.2600\n",
            "Epoch 1411/2500\n",
            "Epoch 1411: Training Accuracy = 0.9902, Training Loss = 0.0649, Validation Accuracy = 0.3513, Validation Loss = 2.2235\n",
            "Epoch 1412/2500\n",
            "Epoch 1412: Training Accuracy = 0.9922, Training Loss = 0.0586, Validation Accuracy = 0.3639, Validation Loss = 2.1763\n",
            "Epoch 1413/2500\n",
            "Epoch 1413: Training Accuracy = 0.9922, Training Loss = 0.0586, Validation Accuracy = 0.3639, Validation Loss = 2.1763\n",
            "Epoch 1414/2500\n",
            "Epoch 1414: Training Accuracy = 0.9883, Training Loss = 0.0673, Validation Accuracy = 0.3622, Validation Loss = 2.1902\n",
            "Epoch 1415/2500\n",
            "Epoch 1415: Training Accuracy = 0.9883, Training Loss = 0.0673, Validation Accuracy = 0.3622, Validation Loss = 2.1902\n",
            "Epoch 1416/2500\n",
            "Epoch 1416: Training Accuracy = 0.9883, Training Loss = 0.0710, Validation Accuracy = 0.3719, Validation Loss = 2.1557\n",
            "Epoch 1417/2500\n",
            "Epoch 1417: Training Accuracy = 0.9922, Training Loss = 0.0526, Validation Accuracy = 0.3634, Validation Loss = 2.1795\n",
            "Epoch 1418/2500\n",
            "Epoch 1418: Training Accuracy = 0.9922, Training Loss = 0.0526, Validation Accuracy = 0.3634, Validation Loss = 2.1795\n",
            "Epoch 1419/2500\n",
            "Epoch 1419: Training Accuracy = 0.9902, Training Loss = 0.0566, Validation Accuracy = 0.3683, Validation Loss = 2.1807\n",
            "Epoch 1420/2500\n",
            "Epoch 1420: Training Accuracy = 0.9902, Training Loss = 0.0566, Validation Accuracy = 0.3683, Validation Loss = 2.1807\n",
            "Epoch 1421/2500\n",
            "Epoch 1421: Training Accuracy = 0.9902, Training Loss = 0.0547, Validation Accuracy = 0.3727, Validation Loss = 2.1662\n",
            "Epoch 1422/2500\n",
            "Epoch 1422: Training Accuracy = 0.9902, Training Loss = 0.0607, Validation Accuracy = 0.3557, Validation Loss = 2.2305\n",
            "Epoch 1423/2500\n",
            "Epoch 1423: Training Accuracy = 0.9902, Training Loss = 0.0607, Validation Accuracy = 0.3557, Validation Loss = 2.2305\n",
            "Epoch 1424/2500\n",
            "Epoch 1424: Training Accuracy = 0.9941, Training Loss = 0.0541, Validation Accuracy = 0.3727, Validation Loss = 2.1635\n",
            "Epoch 1425/2500\n",
            "Epoch 1425: Training Accuracy = 0.9941, Training Loss = 0.0541, Validation Accuracy = 0.3727, Validation Loss = 2.1635\n",
            "Epoch 1426/2500\n",
            "Epoch 1426: Training Accuracy = 0.9902, Training Loss = 0.0994, Validation Accuracy = 0.3234, Validation Loss = 2.4520\n",
            "Epoch 1427/2500\n",
            "Epoch 1427: Training Accuracy = 0.6777, Training Loss = 1.5715, Validation Accuracy = 0.1828, Validation Loss = 3.1880\n",
            "Epoch 1428/2500\n",
            "Epoch 1428: Training Accuracy = 0.6777, Training Loss = 1.5715, Validation Accuracy = 0.1828, Validation Loss = 3.1880\n",
            "Epoch 1429/2500\n",
            "Epoch 1429: Training Accuracy = 0.9570, Training Loss = 0.4006, Validation Accuracy = 0.3574, Validation Loss = 2.1445\n",
            "Epoch 1430/2500\n",
            "Epoch 1430: Training Accuracy = 0.9570, Training Loss = 0.4006, Validation Accuracy = 0.3574, Validation Loss = 2.1445\n",
            "Epoch 1431/2500\n",
            "Epoch 1431: Training Accuracy = 0.9922, Training Loss = 0.1956, Validation Accuracy = 0.4281, Validation Loss = 1.8718\n",
            "Epoch 1432/2500\n",
            "Epoch 1432: Training Accuracy = 0.9902, Training Loss = 0.1290, Validation Accuracy = 0.4626, Validation Loss = 1.7712\n",
            "Epoch 1433/2500\n",
            "Epoch 1433: Training Accuracy = 0.9902, Training Loss = 0.1290, Validation Accuracy = 0.4626, Validation Loss = 1.7712\n",
            "Epoch 1434/2500\n",
            "Epoch 1434: Training Accuracy = 0.9902, Training Loss = 0.0948, Validation Accuracy = 0.4870, Validation Loss = 1.6998\n",
            "Epoch 1435/2500\n",
            "Epoch 1435: Training Accuracy = 0.9902, Training Loss = 0.0948, Validation Accuracy = 0.4870, Validation Loss = 1.6998\n",
            "Epoch 1436/2500\n",
            "Epoch 1436: Training Accuracy = 0.9941, Training Loss = 0.0681, Validation Accuracy = 0.4952, Validation Loss = 1.6803\n",
            "Epoch 1437/2500\n",
            "Epoch 1437: Training Accuracy = 0.9883, Training Loss = 0.0835, Validation Accuracy = 0.5034, Validation Loss = 1.6643\n",
            "Epoch 1438/2500\n",
            "Epoch 1438: Training Accuracy = 0.9883, Training Loss = 0.0835, Validation Accuracy = 0.5034, Validation Loss = 1.6643\n",
            "Epoch 1439/2500\n",
            "Epoch 1439: Training Accuracy = 0.9844, Training Loss = 0.0914, Validation Accuracy = 0.5134, Validation Loss = 1.6351\n",
            "Epoch 1440/2500\n",
            "Epoch 1440: Training Accuracy = 0.9844, Training Loss = 0.0914, Validation Accuracy = 0.5134, Validation Loss = 1.6351\n",
            "Epoch 1441/2500\n",
            "Epoch 1441: Training Accuracy = 0.9902, Training Loss = 0.0715, Validation Accuracy = 0.5184, Validation Loss = 1.6363\n",
            "Epoch 1442/2500\n",
            "Epoch 1442: Training Accuracy = 0.9980, Training Loss = 0.0406, Validation Accuracy = 0.5122, Validation Loss = 1.6489\n",
            "Epoch 1443/2500\n",
            "Epoch 1443: Training Accuracy = 0.9980, Training Loss = 0.0406, Validation Accuracy = 0.5122, Validation Loss = 1.6489\n",
            "Epoch 1444/2500\n",
            "Epoch 1444: Training Accuracy = 0.9863, Training Loss = 0.0839, Validation Accuracy = 0.5150, Validation Loss = 1.6358\n",
            "Epoch 1445/2500\n",
            "Epoch 1445: Training Accuracy = 0.9863, Training Loss = 0.0839, Validation Accuracy = 0.5150, Validation Loss = 1.6358\n",
            "Epoch 1446/2500\n",
            "Epoch 1446: Training Accuracy = 0.9902, Training Loss = 0.0663, Validation Accuracy = 0.5121, Validation Loss = 1.6578\n",
            "Epoch 1447/2500\n",
            "Epoch 1447: Training Accuracy = 0.9902, Training Loss = 0.0679, Validation Accuracy = 0.5156, Validation Loss = 1.6475\n",
            "Epoch 1448/2500\n",
            "Epoch 1448: Training Accuracy = 0.9902, Training Loss = 0.0679, Validation Accuracy = 0.5156, Validation Loss = 1.6475\n",
            "Epoch 1449/2500\n",
            "Epoch 1449: Training Accuracy = 0.9922, Training Loss = 0.0619, Validation Accuracy = 0.5116, Validation Loss = 1.6584\n",
            "Epoch 1450/2500\n",
            "Epoch 1450: Training Accuracy = 0.9922, Training Loss = 0.0619, Validation Accuracy = 0.5116, Validation Loss = 1.6584\n",
            "Epoch 1451/2500\n",
            "Epoch 1451: Training Accuracy = 0.9941, Training Loss = 0.0580, Validation Accuracy = 0.5095, Validation Loss = 1.6824\n",
            "Epoch 1452/2500\n",
            "Epoch 1452: Training Accuracy = 0.9902, Training Loss = 0.0728, Validation Accuracy = 0.5101, Validation Loss = 1.6828\n",
            "Epoch 1453/2500\n",
            "Epoch 1453: Training Accuracy = 0.9902, Training Loss = 0.0728, Validation Accuracy = 0.5101, Validation Loss = 1.6828\n",
            "Epoch 1454/2500\n",
            "Epoch 1454: Training Accuracy = 0.9902, Training Loss = 0.0812, Validation Accuracy = 0.4659, Validation Loss = 1.8004\n",
            "Epoch 1455/2500\n",
            "Epoch 1455: Training Accuracy = 0.9902, Training Loss = 0.0812, Validation Accuracy = 0.4659, Validation Loss = 1.8004\n",
            "Epoch 1456/2500\n",
            "Epoch 1456: Training Accuracy = 0.9883, Training Loss = 0.0837, Validation Accuracy = 0.5122, Validation Loss = 1.6806\n",
            "Epoch 1457/2500\n",
            "Epoch 1457: Training Accuracy = 0.9922, Training Loss = 0.0732, Validation Accuracy = 0.4849, Validation Loss = 1.7896\n",
            "Epoch 1458/2500\n",
            "Epoch 1458: Training Accuracy = 0.9922, Training Loss = 0.0732, Validation Accuracy = 0.4849, Validation Loss = 1.7896\n",
            "Epoch 1459/2500\n",
            "Epoch 1459: Training Accuracy = 0.9863, Training Loss = 0.1275, Validation Accuracy = 0.4529, Validation Loss = 1.8895\n",
            "Epoch 1460/2500\n",
            "Epoch 1460: Training Accuracy = 0.9863, Training Loss = 0.1275, Validation Accuracy = 0.4529, Validation Loss = 1.8895\n",
            "Epoch 1461/2500\n",
            "Epoch 1461: Training Accuracy = 0.9941, Training Loss = 0.1195, Validation Accuracy = 0.4629, Validation Loss = 1.8405\n",
            "Epoch 1462/2500\n",
            "Epoch 1462: Training Accuracy = 0.9883, Training Loss = 0.1160, Validation Accuracy = 0.5254, Validation Loss = 1.6286\n",
            "Epoch 1463/2500\n",
            "Epoch 1463: Training Accuracy = 0.9883, Training Loss = 0.1160, Validation Accuracy = 0.5254, Validation Loss = 1.6286\n",
            "Epoch 1464/2500\n",
            "Epoch 1464: Training Accuracy = 0.9961, Training Loss = 0.0608, Validation Accuracy = 0.5487, Validation Loss = 1.5532\n",
            "Epoch 1465/2500\n",
            "Epoch 1465: Training Accuracy = 0.9961, Training Loss = 0.0608, Validation Accuracy = 0.5487, Validation Loss = 1.5532\n",
            "Epoch 1466/2500\n",
            "Epoch 1466: Training Accuracy = 0.9863, Training Loss = 0.0843, Validation Accuracy = 0.5616, Validation Loss = 1.4978\n",
            "Epoch 1467/2500\n",
            "Epoch 1467: Training Accuracy = 0.9922, Training Loss = 0.0611, Validation Accuracy = 0.5773, Validation Loss = 1.4466\n",
            "Epoch 1468/2500\n",
            "Epoch 1468: Training Accuracy = 0.9922, Training Loss = 0.0611, Validation Accuracy = 0.5773, Validation Loss = 1.4466\n",
            "Epoch 1469/2500\n",
            "Epoch 1469: Training Accuracy = 0.9844, Training Loss = 0.0844, Validation Accuracy = 0.5937, Validation Loss = 1.4034\n",
            "Epoch 1470/2500\n",
            "Epoch 1470: Training Accuracy = 0.9844, Training Loss = 0.0844, Validation Accuracy = 0.5937, Validation Loss = 1.4034\n",
            "Epoch 1471/2500\n",
            "Epoch 1471: Training Accuracy = 0.9941, Training Loss = 0.0473, Validation Accuracy = 0.5749, Validation Loss = 1.4720\n",
            "Epoch 1472/2500\n",
            "Epoch 1472: Training Accuracy = 0.9883, Training Loss = 0.0752, Validation Accuracy = 0.5893, Validation Loss = 1.4285\n",
            "Epoch 1473/2500\n",
            "Epoch 1473: Training Accuracy = 0.9883, Training Loss = 0.0752, Validation Accuracy = 0.5893, Validation Loss = 1.4285\n",
            "Epoch 1474/2500\n",
            "Epoch 1474: Training Accuracy = 0.9902, Training Loss = 0.0691, Validation Accuracy = 0.5766, Validation Loss = 1.4739\n",
            "Epoch 1475/2500\n",
            "Epoch 1475: Training Accuracy = 0.9902, Training Loss = 0.0691, Validation Accuracy = 0.5766, Validation Loss = 1.4739\n",
            "Epoch 1476/2500\n",
            "Epoch 1476: Training Accuracy = 0.9961, Training Loss = 0.0562, Validation Accuracy = 0.5960, Validation Loss = 1.4359\n",
            "Epoch 1477/2500\n",
            "Epoch 1477: Training Accuracy = 0.9863, Training Loss = 0.0935, Validation Accuracy = 0.5816, Validation Loss = 1.4536\n",
            "Epoch 1478/2500\n",
            "Epoch 1478: Training Accuracy = 0.9863, Training Loss = 0.0935, Validation Accuracy = 0.5816, Validation Loss = 1.4536\n",
            "Epoch 1479/2500\n",
            "Epoch 1479: Training Accuracy = 0.9980, Training Loss = 0.0495, Validation Accuracy = 0.5804, Validation Loss = 1.4645\n",
            "Epoch 1480/2500\n",
            "Epoch 1480: Training Accuracy = 0.9980, Training Loss = 0.0495, Validation Accuracy = 0.5804, Validation Loss = 1.4645\n",
            "Epoch 1481/2500\n",
            "Epoch 1481: Training Accuracy = 0.9844, Training Loss = 0.0900, Validation Accuracy = 0.5804, Validation Loss = 1.4809\n",
            "Epoch 1482/2500\n",
            "Epoch 1482: Training Accuracy = 0.9844, Training Loss = 0.0951, Validation Accuracy = 0.5986, Validation Loss = 1.4044\n",
            "Epoch 1483/2500\n",
            "Epoch 1483: Training Accuracy = 0.9844, Training Loss = 0.0951, Validation Accuracy = 0.5986, Validation Loss = 1.4044\n",
            "Epoch 1484/2500\n",
            "Epoch 1484: Training Accuracy = 0.9863, Training Loss = 0.0777, Validation Accuracy = 0.5799, Validation Loss = 1.4371\n",
            "Epoch 1485/2500\n",
            "Epoch 1485: Training Accuracy = 0.9863, Training Loss = 0.0777, Validation Accuracy = 0.5799, Validation Loss = 1.4371\n",
            "Epoch 1486/2500\n",
            "Epoch 1486: Training Accuracy = 0.9941, Training Loss = 0.0607, Validation Accuracy = 0.6120, Validation Loss = 1.3824\n",
            "Epoch 1487/2500\n",
            "Epoch 1487: Training Accuracy = 0.9863, Training Loss = 0.1037, Validation Accuracy = 0.6001, Validation Loss = 1.4064\n",
            "Epoch 1488/2500\n",
            "Epoch 1488: Training Accuracy = 0.9863, Training Loss = 0.1037, Validation Accuracy = 0.6001, Validation Loss = 1.4064\n",
            "Epoch 1489/2500\n",
            "Epoch 1489: Training Accuracy = 0.9844, Training Loss = 0.0982, Validation Accuracy = 0.6098, Validation Loss = 1.3775\n",
            "Epoch 1490/2500\n",
            "Epoch 1490: Training Accuracy = 0.9844, Training Loss = 0.0982, Validation Accuracy = 0.6098, Validation Loss = 1.3775\n",
            "Epoch 1491/2500\n",
            "Epoch 1491: Training Accuracy = 0.9805, Training Loss = 0.1010, Validation Accuracy = 0.6135, Validation Loss = 1.3490\n",
            "Epoch 1492/2500\n",
            "Epoch 1492: Training Accuracy = 0.9844, Training Loss = 0.1051, Validation Accuracy = 0.6326, Validation Loss = 1.2856\n",
            "Epoch 1493/2500\n",
            "Epoch 1493: Training Accuracy = 0.9844, Training Loss = 0.1051, Validation Accuracy = 0.6326, Validation Loss = 1.2856\n",
            "Epoch 1494/2500\n",
            "Epoch 1494: Training Accuracy = 0.9922, Training Loss = 0.0805, Validation Accuracy = 0.6211, Validation Loss = 1.3326\n",
            "Epoch 1495/2500\n",
            "Epoch 1495: Training Accuracy = 0.9922, Training Loss = 0.0805, Validation Accuracy = 0.6211, Validation Loss = 1.3326\n",
            "Epoch 1496/2500\n",
            "Epoch 1496: Training Accuracy = 0.9922, Training Loss = 0.0585, Validation Accuracy = 0.6575, Validation Loss = 1.2303\n",
            "Epoch 1497/2500\n",
            "Epoch 1497: Training Accuracy = 0.9922, Training Loss = 0.0570, Validation Accuracy = 0.6517, Validation Loss = 1.2525\n",
            "Epoch 1498/2500\n",
            "Epoch 1498: Training Accuracy = 0.9922, Training Loss = 0.0570, Validation Accuracy = 0.6517, Validation Loss = 1.2525\n",
            "Epoch 1499/2500\n",
            "Epoch 1499: Training Accuracy = 0.9941, Training Loss = 0.0512, Validation Accuracy = 0.6728, Validation Loss = 1.1821\n",
            "Epoch 1500/2500\n",
            "Epoch 1500: Training Accuracy = 0.9941, Training Loss = 0.0512, Validation Accuracy = 0.6728, Validation Loss = 1.1821\n",
            "Epoch 1501/2500\n",
            "Epoch 1501: Training Accuracy = 0.9824, Training Loss = 0.0928, Validation Accuracy = 0.6779, Validation Loss = 1.1654\n",
            "Epoch 1502/2500\n",
            "Epoch 1502: Training Accuracy = 0.9902, Training Loss = 0.0652, Validation Accuracy = 0.6926, Validation Loss = 1.1265\n",
            "Epoch 1503/2500\n",
            "Epoch 1503: Training Accuracy = 0.9902, Training Loss = 0.0652, Validation Accuracy = 0.6926, Validation Loss = 1.1265\n",
            "Epoch 1504/2500\n",
            "Epoch 1504: Training Accuracy = 0.9883, Training Loss = 0.0659, Validation Accuracy = 0.6710, Validation Loss = 1.1643\n",
            "Epoch 1505/2500\n",
            "Epoch 1505: Training Accuracy = 0.9883, Training Loss = 0.0659, Validation Accuracy = 0.6710, Validation Loss = 1.1643\n",
            "Epoch 1506/2500\n",
            "Epoch 1506: Training Accuracy = 0.9883, Training Loss = 0.0703, Validation Accuracy = 0.6979, Validation Loss = 1.1155\n",
            "Epoch 1507/2500\n",
            "Epoch 1507: Training Accuracy = 0.9844, Training Loss = 0.0989, Validation Accuracy = 0.6710, Validation Loss = 1.2210\n",
            "Epoch 1508/2500\n",
            "Epoch 1508: Training Accuracy = 0.9844, Training Loss = 0.0989, Validation Accuracy = 0.6710, Validation Loss = 1.2210\n",
            "Epoch 1509/2500\n",
            "Epoch 1509: Training Accuracy = 0.7207, Training Loss = 1.0724, Validation Accuracy = 0.2598, Validation Loss = 2.7615\n",
            "Epoch 1510/2500\n",
            "Epoch 1510: Training Accuracy = 0.7207, Training Loss = 1.0724, Validation Accuracy = 0.2598, Validation Loss = 2.7615\n",
            "Epoch 1511/2500\n",
            "Epoch 1511: Training Accuracy = 0.9414, Training Loss = 0.3721, Validation Accuracy = 0.5418, Validation Loss = 1.5913\n",
            "Epoch 1512/2500\n",
            "Epoch 1512: Training Accuracy = 0.9805, Training Loss = 0.1815, Validation Accuracy = 0.6854, Validation Loss = 1.1556\n",
            "Epoch 1513/2500\n",
            "Epoch 1513: Training Accuracy = 0.9805, Training Loss = 0.1815, Validation Accuracy = 0.6854, Validation Loss = 1.1556\n",
            "Epoch 1514/2500\n",
            "Epoch 1514: Training Accuracy = 0.9922, Training Loss = 0.0857, Validation Accuracy = 0.7322, Validation Loss = 0.9943\n",
            "Epoch 1515/2500\n",
            "Epoch 1515: Training Accuracy = 0.9922, Training Loss = 0.0857, Validation Accuracy = 0.7322, Validation Loss = 0.9943\n",
            "Epoch 1516/2500\n",
            "Epoch 1516: Training Accuracy = 0.9863, Training Loss = 0.0875, Validation Accuracy = 0.7729, Validation Loss = 0.8738\n",
            "Epoch 1517/2500\n",
            "Epoch 1517: Training Accuracy = 0.9824, Training Loss = 0.0892, Validation Accuracy = 0.7875, Validation Loss = 0.8305\n",
            "Epoch 1518/2500\n",
            "Epoch 1518: Training Accuracy = 0.9824, Training Loss = 0.0892, Validation Accuracy = 0.7875, Validation Loss = 0.8305\n",
            "Epoch 1519/2500\n",
            "Epoch 1519: Training Accuracy = 0.9824, Training Loss = 0.0866, Validation Accuracy = 0.7970, Validation Loss = 0.8051\n",
            "Epoch 1520/2500\n",
            "Epoch 1520: Training Accuracy = 0.9824, Training Loss = 0.0866, Validation Accuracy = 0.7970, Validation Loss = 0.8051\n",
            "Epoch 1521/2500\n",
            "Epoch 1521: Training Accuracy = 0.9961, Training Loss = 0.0356, Validation Accuracy = 0.8043, Validation Loss = 0.7960\n",
            "Epoch 1522/2500\n",
            "Epoch 1522: Training Accuracy = 0.9883, Training Loss = 0.0638, Validation Accuracy = 0.8039, Validation Loss = 0.7947\n",
            "Epoch 1523/2500\n",
            "Epoch 1523: Training Accuracy = 0.9883, Training Loss = 0.0638, Validation Accuracy = 0.8039, Validation Loss = 0.7947\n",
            "Epoch 1524/2500\n",
            "Epoch 1524: Training Accuracy = 0.9922, Training Loss = 0.0479, Validation Accuracy = 0.7991, Validation Loss = 0.8102\n",
            "Epoch 1525/2500\n",
            "Epoch 1525: Training Accuracy = 0.9922, Training Loss = 0.0479, Validation Accuracy = 0.7991, Validation Loss = 0.8102\n",
            "Epoch 1526/2500\n",
            "Epoch 1526: Training Accuracy = 0.9844, Training Loss = 0.0760, Validation Accuracy = 0.8005, Validation Loss = 0.8124\n",
            "Epoch 1527/2500\n",
            "Epoch 1527: Training Accuracy = 0.9844, Training Loss = 0.0803, Validation Accuracy = 0.8037, Validation Loss = 0.8042\n",
            "Epoch 1528/2500\n",
            "Epoch 1528: Training Accuracy = 0.9844, Training Loss = 0.0803, Validation Accuracy = 0.8037, Validation Loss = 0.8042\n",
            "Epoch 1529/2500\n",
            "Epoch 1529: Training Accuracy = 0.9922, Training Loss = 0.0511, Validation Accuracy = 0.8066, Validation Loss = 0.8132\n",
            "Epoch 1530/2500\n",
            "Epoch 1530: Training Accuracy = 0.9922, Training Loss = 0.0511, Validation Accuracy = 0.8066, Validation Loss = 0.8132\n",
            "Epoch 1531/2500\n",
            "Epoch 1531: Training Accuracy = 0.9785, Training Loss = 0.0977, Validation Accuracy = 0.7957, Validation Loss = 0.8289\n",
            "Epoch 1532/2500\n",
            "Epoch 1532: Training Accuracy = 0.9922, Training Loss = 0.0505, Validation Accuracy = 0.7978, Validation Loss = 0.8234\n",
            "Epoch 1533/2500\n",
            "Epoch 1533: Training Accuracy = 0.9922, Training Loss = 0.0505, Validation Accuracy = 0.7978, Validation Loss = 0.8234\n",
            "Epoch 1534/2500\n",
            "Epoch 1534: Training Accuracy = 0.9961, Training Loss = 0.0375, Validation Accuracy = 0.8051, Validation Loss = 0.8200\n",
            "Epoch 1535/2500\n",
            "Epoch 1535: Training Accuracy = 0.9961, Training Loss = 0.0375, Validation Accuracy = 0.8051, Validation Loss = 0.8200\n",
            "Epoch 1536/2500\n",
            "Epoch 1536: Training Accuracy = 0.9805, Training Loss = 0.0916, Validation Accuracy = 0.7958, Validation Loss = 0.8356\n",
            "Epoch 1537/2500\n",
            "Epoch 1537: Training Accuracy = 0.9902, Training Loss = 0.0590, Validation Accuracy = 0.8042, Validation Loss = 0.8195\n",
            "Epoch 1538/2500\n",
            "Epoch 1538: Training Accuracy = 0.9902, Training Loss = 0.0590, Validation Accuracy = 0.8042, Validation Loss = 0.8195\n",
            "Epoch 1539/2500\n",
            "Epoch 1539: Training Accuracy = 0.9824, Training Loss = 0.0929, Validation Accuracy = 0.7972, Validation Loss = 0.8412\n",
            "Epoch 1540/2500\n",
            "Epoch 1540: Training Accuracy = 0.9824, Training Loss = 0.0929, Validation Accuracy = 0.7972, Validation Loss = 0.8412\n",
            "Epoch 1541/2500\n",
            "Epoch 1541: Training Accuracy = 0.9863, Training Loss = 0.0761, Validation Accuracy = 0.7875, Validation Loss = 0.8765\n",
            "Epoch 1542/2500\n",
            "Epoch 1542: Training Accuracy = 0.9902, Training Loss = 0.0734, Validation Accuracy = 0.7825, Validation Loss = 0.8840\n",
            "Epoch 1543/2500\n",
            "Epoch 1543: Training Accuracy = 0.9902, Training Loss = 0.0734, Validation Accuracy = 0.7825, Validation Loss = 0.8840\n",
            "Epoch 1544/2500\n",
            "Epoch 1544: Training Accuracy = 0.4883, Training Loss = 1.9629, Validation Accuracy = 0.1380, Validation Loss = 3.4803\n",
            "Epoch 1545/2500\n",
            "Epoch 1545: Training Accuracy = 0.4883, Training Loss = 1.9629, Validation Accuracy = 0.1380, Validation Loss = 3.4803\n",
            "Epoch 1546/2500\n",
            "Epoch 1546: Training Accuracy = 0.9512, Training Loss = 0.4237, Validation Accuracy = 0.5679, Validation Loss = 1.5732\n",
            "Epoch 1547/2500\n",
            "Epoch 1547: Training Accuracy = 0.9766, Training Loss = 0.2541, Validation Accuracy = 0.7401, Validation Loss = 1.0118\n",
            "Epoch 1548/2500\n",
            "Epoch 1548: Training Accuracy = 0.9766, Training Loss = 0.2541, Validation Accuracy = 0.7401, Validation Loss = 1.0118\n",
            "Epoch 1549/2500\n",
            "Epoch 1549: Training Accuracy = 0.9863, Training Loss = 0.1296, Validation Accuracy = 0.8011, Validation Loss = 0.8388\n",
            "Epoch 1550/2500\n",
            "Epoch 1550: Training Accuracy = 0.9863, Training Loss = 0.1296, Validation Accuracy = 0.8011, Validation Loss = 0.8388\n",
            "Epoch 1551/2500\n",
            "Epoch 1551: Training Accuracy = 0.9883, Training Loss = 0.0890, Validation Accuracy = 0.8506, Validation Loss = 0.6993\n",
            "Epoch 1552/2500\n",
            "Epoch 1552: Training Accuracy = 0.9941, Training Loss = 0.0607, Validation Accuracy = 0.8628, Validation Loss = 0.6463\n",
            "Epoch 1553/2500\n",
            "Epoch 1553: Training Accuracy = 0.9941, Training Loss = 0.0607, Validation Accuracy = 0.8628, Validation Loss = 0.6463\n",
            "Epoch 1554/2500\n",
            "Epoch 1554: Training Accuracy = 0.9902, Training Loss = 0.0670, Validation Accuracy = 0.8735, Validation Loss = 0.6187\n",
            "Epoch 1555/2500\n",
            "Epoch 1555: Training Accuracy = 0.9902, Training Loss = 0.0670, Validation Accuracy = 0.8735, Validation Loss = 0.6187\n",
            "Epoch 1556/2500\n",
            "Epoch 1556: Training Accuracy = 0.9883, Training Loss = 0.0721, Validation Accuracy = 0.8766, Validation Loss = 0.6099\n",
            "Epoch 1557/2500\n",
            "Epoch 1557: Training Accuracy = 0.9902, Training Loss = 0.0645, Validation Accuracy = 0.8836, Validation Loss = 0.6038\n",
            "Epoch 1558/2500\n",
            "Epoch 1558: Training Accuracy = 0.9902, Training Loss = 0.0645, Validation Accuracy = 0.8836, Validation Loss = 0.6038\n",
            "Epoch 1559/2500\n",
            "Epoch 1559: Training Accuracy = 0.9922, Training Loss = 0.0567, Validation Accuracy = 0.8833, Validation Loss = 0.6087\n",
            "Epoch 1560/2500\n",
            "Epoch 1560: Training Accuracy = 0.9922, Training Loss = 0.0567, Validation Accuracy = 0.8833, Validation Loss = 0.6087\n",
            "Epoch 1561/2500\n",
            "Epoch 1561: Training Accuracy = 0.9766, Training Loss = 0.1112, Validation Accuracy = 0.8798, Validation Loss = 0.6104\n",
            "Epoch 1562/2500\n",
            "Epoch 1562: Training Accuracy = 0.9883, Training Loss = 0.0720, Validation Accuracy = 0.8814, Validation Loss = 0.6083\n",
            "Epoch 1563/2500\n",
            "Epoch 1563: Training Accuracy = 0.9883, Training Loss = 0.0720, Validation Accuracy = 0.8814, Validation Loss = 0.6083\n",
            "Epoch 1564/2500\n",
            "Epoch 1564: Training Accuracy = 0.9902, Training Loss = 0.0638, Validation Accuracy = 0.8784, Validation Loss = 0.6205\n",
            "Epoch 1565/2500\n",
            "Epoch 1565: Training Accuracy = 0.9902, Training Loss = 0.0638, Validation Accuracy = 0.8784, Validation Loss = 0.6205\n",
            "Epoch 1566/2500\n",
            "Epoch 1566: Training Accuracy = 0.9883, Training Loss = 0.0703, Validation Accuracy = 0.8796, Validation Loss = 0.6192\n",
            "Epoch 1567/2500\n",
            "Epoch 1567: Training Accuracy = 0.9844, Training Loss = 0.0863, Validation Accuracy = 0.8719, Validation Loss = 0.6443\n",
            "Epoch 1568/2500\n",
            "Epoch 1568: Training Accuracy = 0.9844, Training Loss = 0.0863, Validation Accuracy = 0.8719, Validation Loss = 0.6443\n",
            "Epoch 1569/2500\n",
            "Epoch 1569: Training Accuracy = 0.9824, Training Loss = 0.0949, Validation Accuracy = 0.8801, Validation Loss = 0.6323\n",
            "Epoch 1570/2500\n",
            "Epoch 1570: Training Accuracy = 0.9824, Training Loss = 0.0949, Validation Accuracy = 0.8801, Validation Loss = 0.6323\n",
            "Epoch 1571/2500\n",
            "Epoch 1571: Training Accuracy = 0.9941, Training Loss = 0.0513, Validation Accuracy = 0.8839, Validation Loss = 0.6173\n",
            "Epoch 1572/2500\n",
            "Epoch 1572: Training Accuracy = 0.9883, Training Loss = 0.0724, Validation Accuracy = 0.8757, Validation Loss = 0.6273\n",
            "Epoch 1573/2500\n",
            "Epoch 1573: Training Accuracy = 0.9883, Training Loss = 0.0724, Validation Accuracy = 0.8757, Validation Loss = 0.6273\n",
            "Epoch 1574/2500\n",
            "Epoch 1574: Training Accuracy = 0.9922, Training Loss = 0.0680, Validation Accuracy = 0.8766, Validation Loss = 0.6363\n",
            "Epoch 1575/2500\n",
            "Epoch 1575: Training Accuracy = 0.9922, Training Loss = 0.0680, Validation Accuracy = 0.8766, Validation Loss = 0.6363\n",
            "Epoch 1576/2500\n",
            "Epoch 1576: Training Accuracy = 0.9863, Training Loss = 0.0885, Validation Accuracy = 0.8530, Validation Loss = 0.7086\n",
            "Epoch 1577/2500\n",
            "Epoch 1577: Training Accuracy = 0.7871, Training Loss = 1.0287, Validation Accuracy = 0.4943, Validation Loss = 1.9211\n",
            "Epoch 1578/2500\n",
            "Epoch 1578: Training Accuracy = 0.7871, Training Loss = 1.0287, Validation Accuracy = 0.4943, Validation Loss = 1.9211\n",
            "Epoch 1579/2500\n",
            "Epoch 1579: Training Accuracy = 0.9629, Training Loss = 0.3502, Validation Accuracy = 0.7299, Validation Loss = 1.1388\n",
            "Epoch 1580/2500\n",
            "Epoch 1580: Training Accuracy = 0.9629, Training Loss = 0.3502, Validation Accuracy = 0.7299, Validation Loss = 1.1388\n",
            "Epoch 1581/2500\n",
            "Epoch 1581: Training Accuracy = 0.9863, Training Loss = 0.1686, Validation Accuracy = 0.8338, Validation Loss = 0.7915\n",
            "Epoch 1582/2500\n",
            "Epoch 1582: Training Accuracy = 0.9883, Training Loss = 0.1117, Validation Accuracy = 0.8775, Validation Loss = 0.6460\n",
            "Epoch 1583/2500\n",
            "Epoch 1583: Training Accuracy = 0.9883, Training Loss = 0.1117, Validation Accuracy = 0.8775, Validation Loss = 0.6460\n",
            "Epoch 1584/2500\n",
            "Epoch 1584: Training Accuracy = 0.9902, Training Loss = 0.0825, Validation Accuracy = 0.8992, Validation Loss = 0.5661\n",
            "Epoch 1585/2500\n",
            "Epoch 1585: Training Accuracy = 0.9902, Training Loss = 0.0825, Validation Accuracy = 0.8992, Validation Loss = 0.5661\n",
            "Epoch 1586/2500\n",
            "Epoch 1586: Training Accuracy = 0.9863, Training Loss = 0.0831, Validation Accuracy = 0.9092, Validation Loss = 0.5317\n",
            "Epoch 1587/2500\n",
            "Epoch 1587: Training Accuracy = 0.9824, Training Loss = 0.0986, Validation Accuracy = 0.9123, Validation Loss = 0.5103\n",
            "Epoch 1588/2500\n",
            "Epoch 1588: Training Accuracy = 0.9824, Training Loss = 0.0986, Validation Accuracy = 0.9123, Validation Loss = 0.5103\n",
            "Epoch 1589/2500\n",
            "Epoch 1589: Training Accuracy = 0.9863, Training Loss = 0.0796, Validation Accuracy = 0.9167, Validation Loss = 0.5012\n",
            "Epoch 1590/2500\n",
            "Epoch 1590: Training Accuracy = 0.9863, Training Loss = 0.0796, Validation Accuracy = 0.9167, Validation Loss = 0.5012\n",
            "Epoch 1591/2500\n",
            "Epoch 1591: Training Accuracy = 0.9961, Training Loss = 0.0452, Validation Accuracy = 0.9180, Validation Loss = 0.5014\n",
            "Epoch 1592/2500\n",
            "Epoch 1592: Training Accuracy = 0.9902, Training Loss = 0.0672, Validation Accuracy = 0.9198, Validation Loss = 0.4968\n",
            "Epoch 1593/2500\n",
            "Epoch 1593: Training Accuracy = 0.9902, Training Loss = 0.0672, Validation Accuracy = 0.9198, Validation Loss = 0.4968\n",
            "Epoch 1594/2500\n",
            "Epoch 1594: Training Accuracy = 0.9844, Training Loss = 0.0856, Validation Accuracy = 0.9185, Validation Loss = 0.4989\n",
            "Epoch 1595/2500\n",
            "Epoch 1595: Training Accuracy = 0.9844, Training Loss = 0.0856, Validation Accuracy = 0.9185, Validation Loss = 0.4989\n",
            "Epoch 1596/2500\n",
            "Epoch 1596: Training Accuracy = 0.9883, Training Loss = 0.0734, Validation Accuracy = 0.9171, Validation Loss = 0.5040\n",
            "Epoch 1597/2500\n",
            "Epoch 1597: Training Accuracy = 0.9902, Training Loss = 0.0705, Validation Accuracy = 0.9162, Validation Loss = 0.5126\n",
            "Epoch 1598/2500\n",
            "Epoch 1598: Training Accuracy = 0.9902, Training Loss = 0.0705, Validation Accuracy = 0.9162, Validation Loss = 0.5126\n",
            "Epoch 1599/2500\n",
            "Epoch 1599: Training Accuracy = 0.9902, Training Loss = 0.0672, Validation Accuracy = 0.9179, Validation Loss = 0.5200\n",
            "Epoch 1600/2500\n",
            "Epoch 1600: Training Accuracy = 0.9902, Training Loss = 0.0672, Validation Accuracy = 0.9179, Validation Loss = 0.5200\n",
            "Epoch 1601/2500\n",
            "Epoch 1601: Training Accuracy = 0.9883, Training Loss = 0.0748, Validation Accuracy = 0.9151, Validation Loss = 0.5189\n",
            "Epoch 1602/2500\n",
            "Epoch 1602: Training Accuracy = 0.9922, Training Loss = 0.0638, Validation Accuracy = 0.9201, Validation Loss = 0.5071\n",
            "Epoch 1603/2500\n",
            "Epoch 1603: Training Accuracy = 0.9922, Training Loss = 0.0638, Validation Accuracy = 0.9201, Validation Loss = 0.5071\n",
            "Epoch 1604/2500\n",
            "Epoch 1604: Training Accuracy = 0.9844, Training Loss = 0.0881, Validation Accuracy = 0.9189, Validation Loss = 0.5073\n",
            "Epoch 1605/2500\n",
            "Epoch 1605: Training Accuracy = 0.9844, Training Loss = 0.0881, Validation Accuracy = 0.9189, Validation Loss = 0.5073\n",
            "Epoch 1606/2500\n",
            "Epoch 1606: Training Accuracy = 0.9941, Training Loss = 0.0518, Validation Accuracy = 0.9141, Validation Loss = 0.5294\n",
            "Epoch 1607/2500\n",
            "Epoch 1607: Training Accuracy = 0.9844, Training Loss = 0.0972, Validation Accuracy = 0.9116, Validation Loss = 0.5366\n",
            "Epoch 1608/2500\n",
            "Epoch 1608: Training Accuracy = 0.9844, Training Loss = 0.0972, Validation Accuracy = 0.9116, Validation Loss = 0.5366\n",
            "Epoch 1609/2500\n",
            "Epoch 1609: Training Accuracy = 0.6738, Training Loss = 1.3776, Validation Accuracy = 0.4325, Validation Loss = 2.2158\n",
            "Epoch 1610/2500\n",
            "Epoch 1610: Training Accuracy = 0.6738, Training Loss = 1.3776, Validation Accuracy = 0.4325, Validation Loss = 2.2158\n",
            "Epoch 1611/2500\n",
            "Epoch 1611: Training Accuracy = 0.9824, Training Loss = 0.3462, Validation Accuracy = 0.7445, Validation Loss = 1.0852\n",
            "Epoch 1612/2500\n",
            "Epoch 1612: Training Accuracy = 0.9941, Training Loss = 0.2033, Validation Accuracy = 0.8717, Validation Loss = 0.7098\n",
            "Epoch 1613/2500\n",
            "Epoch 1613: Training Accuracy = 0.9941, Training Loss = 0.2033, Validation Accuracy = 0.8717, Validation Loss = 0.7098\n",
            "Epoch 1614/2500\n",
            "Epoch 1614: Training Accuracy = 0.9883, Training Loss = 0.1225, Validation Accuracy = 0.9126, Validation Loss = 0.5587\n",
            "Epoch 1615/2500\n",
            "Epoch 1615: Training Accuracy = 0.9883, Training Loss = 0.1225, Validation Accuracy = 0.9126, Validation Loss = 0.5587\n",
            "Epoch 1616/2500\n",
            "Epoch 1616: Training Accuracy = 0.9902, Training Loss = 0.0890, Validation Accuracy = 0.9311, Validation Loss = 0.4680\n",
            "Epoch 1617/2500\n",
            "Epoch 1617: Training Accuracy = 0.9941, Training Loss = 0.0664, Validation Accuracy = 0.9403, Validation Loss = 0.4265\n",
            "Epoch 1618/2500\n",
            "Epoch 1618: Training Accuracy = 0.9941, Training Loss = 0.0664, Validation Accuracy = 0.9403, Validation Loss = 0.4265\n",
            "Epoch 1619/2500\n",
            "Epoch 1619: Training Accuracy = 0.9844, Training Loss = 0.0962, Validation Accuracy = 0.9432, Validation Loss = 0.4103\n",
            "Epoch 1620/2500\n",
            "Epoch 1620: Training Accuracy = 0.9844, Training Loss = 0.0962, Validation Accuracy = 0.9432, Validation Loss = 0.4103\n",
            "Epoch 1621/2500\n",
            "Epoch 1621: Training Accuracy = 0.9883, Training Loss = 0.0769, Validation Accuracy = 0.9432, Validation Loss = 0.4088\n",
            "Epoch 1622/2500\n",
            "Epoch 1622: Training Accuracy = 0.9883, Training Loss = 0.0797, Validation Accuracy = 0.9458, Validation Loss = 0.4011\n",
            "Epoch 1623/2500\n",
            "Epoch 1623: Training Accuracy = 0.9883, Training Loss = 0.0797, Validation Accuracy = 0.9458, Validation Loss = 0.4011\n",
            "Epoch 1624/2500\n",
            "Epoch 1624: Training Accuracy = 0.9844, Training Loss = 0.0928, Validation Accuracy = 0.9450, Validation Loss = 0.4076\n",
            "Epoch 1625/2500\n",
            "Epoch 1625: Training Accuracy = 0.9844, Training Loss = 0.0928, Validation Accuracy = 0.9450, Validation Loss = 0.4076\n",
            "Epoch 1626/2500\n",
            "Epoch 1626: Training Accuracy = 0.9863, Training Loss = 0.0833, Validation Accuracy = 0.9425, Validation Loss = 0.4133\n",
            "Epoch 1627/2500\n",
            "Epoch 1627: Training Accuracy = 0.9941, Training Loss = 0.0619, Validation Accuracy = 0.9453, Validation Loss = 0.4117\n",
            "Epoch 1628/2500\n",
            "Epoch 1628: Training Accuracy = 0.9941, Training Loss = 0.0619, Validation Accuracy = 0.9453, Validation Loss = 0.4117\n",
            "Epoch 1629/2500\n",
            "Epoch 1629: Training Accuracy = 0.9922, Training Loss = 0.0646, Validation Accuracy = 0.9440, Validation Loss = 0.4207\n",
            "Epoch 1630/2500\n",
            "Epoch 1630: Training Accuracy = 0.9922, Training Loss = 0.0646, Validation Accuracy = 0.9440, Validation Loss = 0.4207\n",
            "Epoch 1631/2500\n",
            "Epoch 1631: Training Accuracy = 0.9922, Training Loss = 0.0638, Validation Accuracy = 0.9461, Validation Loss = 0.4176\n",
            "Epoch 1632/2500\n",
            "Epoch 1632: Training Accuracy = 0.9863, Training Loss = 0.0869, Validation Accuracy = 0.9428, Validation Loss = 0.4187\n",
            "Epoch 1633/2500\n",
            "Epoch 1633: Training Accuracy = 0.9863, Training Loss = 0.0869, Validation Accuracy = 0.9428, Validation Loss = 0.4187\n",
            "Epoch 1634/2500\n",
            "Epoch 1634: Training Accuracy = 0.9805, Training Loss = 0.1078, Validation Accuracy = 0.9425, Validation Loss = 0.4251\n",
            "Epoch 1635/2500\n",
            "Epoch 1635: Training Accuracy = 0.9805, Training Loss = 0.1078, Validation Accuracy = 0.9425, Validation Loss = 0.4251\n",
            "Epoch 1636/2500\n",
            "Epoch 1636: Training Accuracy = 0.9863, Training Loss = 0.0833, Validation Accuracy = 0.9467, Validation Loss = 0.4155\n",
            "Epoch 1637/2500\n",
            "Epoch 1637: Training Accuracy = 0.9883, Training Loss = 0.0858, Validation Accuracy = 0.9458, Validation Loss = 0.4211\n",
            "Epoch 1638/2500\n",
            "Epoch 1638: Training Accuracy = 0.9883, Training Loss = 0.0858, Validation Accuracy = 0.9458, Validation Loss = 0.4211\n",
            "Epoch 1639/2500\n",
            "Epoch 1639: Training Accuracy = 0.9844, Training Loss = 0.1080, Validation Accuracy = 0.9381, Validation Loss = 0.4536\n",
            "Epoch 1640/2500\n",
            "Epoch 1640: Training Accuracy = 0.9844, Training Loss = 0.1080, Validation Accuracy = 0.9381, Validation Loss = 0.4536\n",
            "Epoch 1641/2500\n",
            "Epoch 1641: Training Accuracy = 0.9941, Training Loss = 0.0626, Validation Accuracy = 0.9378, Validation Loss = 0.4458\n",
            "Epoch 1642/2500\n",
            "Epoch 1642: Training Accuracy = 0.9902, Training Loss = 0.0840, Validation Accuracy = 0.9412, Validation Loss = 0.4348\n",
            "Epoch 1643/2500\n",
            "Epoch 1643: Training Accuracy = 0.9902, Training Loss = 0.0840, Validation Accuracy = 0.9412, Validation Loss = 0.4348\n",
            "Epoch 1644/2500\n",
            "Epoch 1644: Training Accuracy = 0.9902, Training Loss = 0.0865, Validation Accuracy = 0.9403, Validation Loss = 0.4530\n",
            "Epoch 1645/2500\n",
            "Epoch 1645: Training Accuracy = 0.9902, Training Loss = 0.0865, Validation Accuracy = 0.9403, Validation Loss = 0.4530\n",
            "Epoch 1646/2500\n",
            "Epoch 1646: Training Accuracy = 0.7617, Training Loss = 1.0700, Validation Accuracy = 0.4750, Validation Loss = 1.9197\n",
            "Epoch 1647/2500\n",
            "Epoch 1647: Training Accuracy = 0.9824, Training Loss = 0.2880, Validation Accuracy = 0.8386, Validation Loss = 0.8192\n",
            "Epoch 1648/2500\n",
            "Epoch 1648: Training Accuracy = 0.9824, Training Loss = 0.2880, Validation Accuracy = 0.8386, Validation Loss = 0.8192\n",
            "Epoch 1649/2500\n",
            "Epoch 1649: Training Accuracy = 0.9902, Training Loss = 0.1419, Validation Accuracy = 0.9180, Validation Loss = 0.5386\n",
            "Epoch 1650/2500\n",
            "Epoch 1650: Training Accuracy = 0.9902, Training Loss = 0.1419, Validation Accuracy = 0.9180, Validation Loss = 0.5386\n",
            "Epoch 1651/2500\n",
            "Epoch 1651: Training Accuracy = 0.9883, Training Loss = 0.1120, Validation Accuracy = 0.9457, Validation Loss = 0.4257\n",
            "Epoch 1652/2500\n",
            "Epoch 1652: Training Accuracy = 0.9824, Training Loss = 0.1133, Validation Accuracy = 0.9596, Validation Loss = 0.3594\n",
            "Epoch 1653/2500\n",
            "Epoch 1653: Training Accuracy = 0.9824, Training Loss = 0.1133, Validation Accuracy = 0.9596, Validation Loss = 0.3594\n",
            "Epoch 1654/2500\n",
            "Epoch 1654: Training Accuracy = 0.9883, Training Loss = 0.0847, Validation Accuracy = 0.9636, Validation Loss = 0.3322\n",
            "Epoch 1655/2500\n",
            "Epoch 1655: Training Accuracy = 0.9883, Training Loss = 0.0847, Validation Accuracy = 0.9636, Validation Loss = 0.3322\n",
            "Epoch 1656/2500\n",
            "Epoch 1656: Training Accuracy = 0.9863, Training Loss = 0.0909, Validation Accuracy = 0.9625, Validation Loss = 0.3267\n",
            "Epoch 1657/2500\n",
            "Epoch 1657: Training Accuracy = 0.9863, Training Loss = 0.0834, Validation Accuracy = 0.9663, Validation Loss = 0.3150\n",
            "Epoch 1658/2500\n",
            "Epoch 1658: Training Accuracy = 0.9863, Training Loss = 0.0834, Validation Accuracy = 0.9663, Validation Loss = 0.3150\n",
            "Epoch 1659/2500\n",
            "Epoch 1659: Training Accuracy = 0.9902, Training Loss = 0.0674, Validation Accuracy = 0.9671, Validation Loss = 0.3152\n",
            "Epoch 1660/2500\n",
            "Epoch 1660: Training Accuracy = 0.9902, Training Loss = 0.0674, Validation Accuracy = 0.9671, Validation Loss = 0.3152\n",
            "Epoch 1661/2500\n",
            "Epoch 1661: Training Accuracy = 0.9844, Training Loss = 0.0853, Validation Accuracy = 0.9654, Validation Loss = 0.3171\n",
            "Epoch 1662/2500\n",
            "Epoch 1662: Training Accuracy = 0.9805, Training Loss = 0.1080, Validation Accuracy = 0.9660, Validation Loss = 0.3223\n",
            "Epoch 1663/2500\n",
            "Epoch 1663: Training Accuracy = 0.9805, Training Loss = 0.1080, Validation Accuracy = 0.9660, Validation Loss = 0.3223\n",
            "Epoch 1664/2500\n",
            "Epoch 1664: Training Accuracy = 0.9922, Training Loss = 0.0610, Validation Accuracy = 0.9658, Validation Loss = 0.3202\n",
            "Epoch 1665/2500\n",
            "Epoch 1665: Training Accuracy = 0.9922, Training Loss = 0.0610, Validation Accuracy = 0.9658, Validation Loss = 0.3202\n",
            "Epoch 1666/2500\n",
            "Epoch 1666: Training Accuracy = 0.9902, Training Loss = 0.0685, Validation Accuracy = 0.9651, Validation Loss = 0.3245\n",
            "Epoch 1667/2500\n",
            "Epoch 1667: Training Accuracy = 0.9883, Training Loss = 0.0811, Validation Accuracy = 0.9643, Validation Loss = 0.3279\n",
            "Epoch 1668/2500\n",
            "Epoch 1668: Training Accuracy = 0.9883, Training Loss = 0.0811, Validation Accuracy = 0.9643, Validation Loss = 0.3279\n",
            "Epoch 1669/2500\n",
            "Epoch 1669: Training Accuracy = 0.9922, Training Loss = 0.0643, Validation Accuracy = 0.9674, Validation Loss = 0.3155\n",
            "Epoch 1670/2500\n",
            "Epoch 1670: Training Accuracy = 0.9922, Training Loss = 0.0643, Validation Accuracy = 0.9674, Validation Loss = 0.3155\n",
            "Epoch 1671/2500\n",
            "Epoch 1671: Training Accuracy = 0.9922, Training Loss = 0.0620, Validation Accuracy = 0.9584, Validation Loss = 0.3422\n",
            "Epoch 1672/2500\n",
            "Epoch 1672: Training Accuracy = 0.9980, Training Loss = 0.0452, Validation Accuracy = 0.9596, Validation Loss = 0.3509\n",
            "Epoch 1673/2500\n",
            "Epoch 1673: Training Accuracy = 0.9980, Training Loss = 0.0452, Validation Accuracy = 0.9596, Validation Loss = 0.3509\n",
            "Epoch 1674/2500\n",
            "Epoch 1674: Training Accuracy = 0.9922, Training Loss = 0.0688, Validation Accuracy = 0.9596, Validation Loss = 0.3521\n",
            "Epoch 1675/2500\n",
            "Epoch 1675: Training Accuracy = 0.9922, Training Loss = 0.0688, Validation Accuracy = 0.9596, Validation Loss = 0.3521\n",
            "Epoch 1676/2500\n",
            "Epoch 1676: Training Accuracy = 0.9902, Training Loss = 0.0814, Validation Accuracy = 0.9617, Validation Loss = 0.3311\n",
            "Epoch 1677/2500\n",
            "Epoch 1677: Training Accuracy = 0.9941, Training Loss = 0.0648, Validation Accuracy = 0.9654, Validation Loss = 0.3277\n",
            "Epoch 1678/2500\n",
            "Epoch 1678: Training Accuracy = 0.9941, Training Loss = 0.0648, Validation Accuracy = 0.9654, Validation Loss = 0.3277\n",
            "Epoch 1679/2500\n",
            "Epoch 1679: Training Accuracy = 0.9922, Training Loss = 0.0835, Validation Accuracy = 0.9566, Validation Loss = 0.3746\n",
            "Epoch 1680/2500\n",
            "Epoch 1680: Training Accuracy = 0.9922, Training Loss = 0.0835, Validation Accuracy = 0.9566, Validation Loss = 0.3746\n",
            "Epoch 1681/2500\n",
            "Epoch 1681: Training Accuracy = 0.9785, Training Loss = 0.1220, Validation Accuracy = 0.9522, Validation Loss = 0.3699\n",
            "Epoch 1682/2500\n",
            "Epoch 1682: Training Accuracy = 0.9883, Training Loss = 0.0807, Validation Accuracy = 0.9309, Validation Loss = 0.4557\n",
            "Epoch 1683/2500\n",
            "Epoch 1683: Training Accuracy = 0.9883, Training Loss = 0.0807, Validation Accuracy = 0.9309, Validation Loss = 0.4557\n",
            "Epoch 1684/2500\n",
            "Epoch 1684: Training Accuracy = 0.8926, Training Loss = 0.6035, Validation Accuracy = 0.7214, Validation Loss = 1.1599\n",
            "Epoch 1685/2500\n",
            "Epoch 1685: Training Accuracy = 0.8926, Training Loss = 0.6035, Validation Accuracy = 0.7214, Validation Loss = 1.1599\n",
            "Epoch 1686/2500\n",
            "Epoch 1686: Training Accuracy = 0.9844, Training Loss = 0.2100, Validation Accuracy = 0.8980, Validation Loss = 0.6298\n",
            "Epoch 1687/2500\n",
            "Epoch 1687: Training Accuracy = 0.9941, Training Loss = 0.1168, Validation Accuracy = 0.9493, Validation Loss = 0.4078\n",
            "Epoch 1688/2500\n",
            "Epoch 1688: Training Accuracy = 0.9941, Training Loss = 0.1168, Validation Accuracy = 0.9493, Validation Loss = 0.4078\n",
            "Epoch 1689/2500\n",
            "Epoch 1689: Training Accuracy = 0.9863, Training Loss = 0.1016, Validation Accuracy = 0.9630, Validation Loss = 0.3252\n",
            "Epoch 1690/2500\n",
            "Epoch 1690: Training Accuracy = 0.9863, Training Loss = 0.1016, Validation Accuracy = 0.9630, Validation Loss = 0.3252\n",
            "Epoch 1691/2500\n",
            "Epoch 1691: Training Accuracy = 0.9863, Training Loss = 0.0854, Validation Accuracy = 0.9709, Validation Loss = 0.2850\n",
            "Epoch 1692/2500\n",
            "Epoch 1692: Training Accuracy = 0.9863, Training Loss = 0.0806, Validation Accuracy = 0.9733, Validation Loss = 0.2634\n",
            "Epoch 1693/2500\n",
            "Epoch 1693: Training Accuracy = 0.9863, Training Loss = 0.0806, Validation Accuracy = 0.9733, Validation Loss = 0.2634\n",
            "Epoch 1694/2500\n",
            "Epoch 1694: Training Accuracy = 0.9922, Training Loss = 0.0581, Validation Accuracy = 0.9730, Validation Loss = 0.2611\n",
            "Epoch 1695/2500\n",
            "Epoch 1695: Training Accuracy = 0.9922, Training Loss = 0.0581, Validation Accuracy = 0.9730, Validation Loss = 0.2611\n",
            "Epoch 1696/2500\n",
            "Epoch 1696: Training Accuracy = 0.9805, Training Loss = 0.0964, Validation Accuracy = 0.9745, Validation Loss = 0.2522\n",
            "Epoch 1697/2500\n",
            "Epoch 1697: Training Accuracy = 0.9902, Training Loss = 0.0658, Validation Accuracy = 0.9760, Validation Loss = 0.2532\n",
            "Epoch 1698/2500\n",
            "Epoch 1698: Training Accuracy = 0.9902, Training Loss = 0.0658, Validation Accuracy = 0.9760, Validation Loss = 0.2532\n",
            "Epoch 1699/2500\n",
            "Epoch 1699: Training Accuracy = 0.9941, Training Loss = 0.0485, Validation Accuracy = 0.9742, Validation Loss = 0.2520\n",
            "Epoch 1700/2500\n",
            "Epoch 1700: Training Accuracy = 0.9941, Training Loss = 0.0485, Validation Accuracy = 0.9742, Validation Loss = 0.2520\n",
            "Epoch 1701/2500\n",
            "Epoch 1701: Training Accuracy = 0.9824, Training Loss = 0.0908, Validation Accuracy = 0.9743, Validation Loss = 0.2528\n",
            "Epoch 1702/2500\n",
            "Epoch 1702: Training Accuracy = 0.9902, Training Loss = 0.0645, Validation Accuracy = 0.9765, Validation Loss = 0.2468\n",
            "Epoch 1703/2500\n",
            "Epoch 1703: Training Accuracy = 0.9902, Training Loss = 0.0645, Validation Accuracy = 0.9765, Validation Loss = 0.2468\n",
            "Epoch 1704/2500\n",
            "Epoch 1704: Training Accuracy = 0.9863, Training Loss = 0.0769, Validation Accuracy = 0.9733, Validation Loss = 0.2494\n",
            "Epoch 1705/2500\n",
            "Epoch 1705: Training Accuracy = 0.9863, Training Loss = 0.0769, Validation Accuracy = 0.9733, Validation Loss = 0.2494\n",
            "Epoch 1706/2500\n",
            "Epoch 1706: Training Accuracy = 0.9902, Training Loss = 0.0631, Validation Accuracy = 0.9719, Validation Loss = 0.2603\n",
            "Epoch 1707/2500\n",
            "Epoch 1707: Training Accuracy = 0.9883, Training Loss = 0.0748, Validation Accuracy = 0.9740, Validation Loss = 0.2607\n",
            "Epoch 1708/2500\n",
            "Epoch 1708: Training Accuracy = 0.9883, Training Loss = 0.0748, Validation Accuracy = 0.9740, Validation Loss = 0.2607\n",
            "Epoch 1709/2500\n",
            "Epoch 1709: Training Accuracy = 0.9941, Training Loss = 0.0528, Validation Accuracy = 0.9725, Validation Loss = 0.2687\n",
            "Epoch 1710/2500\n",
            "Epoch 1710: Training Accuracy = 0.9941, Training Loss = 0.0528, Validation Accuracy = 0.9725, Validation Loss = 0.2687\n",
            "Epoch 1711/2500\n",
            "Epoch 1711: Training Accuracy = 0.9922, Training Loss = 0.0595, Validation Accuracy = 0.9736, Validation Loss = 0.2642\n",
            "Epoch 1712/2500\n",
            "Epoch 1712: Training Accuracy = 0.9922, Training Loss = 0.0727, Validation Accuracy = 0.9705, Validation Loss = 0.2692\n",
            "Epoch 1713/2500\n",
            "Epoch 1713: Training Accuracy = 0.9922, Training Loss = 0.0727, Validation Accuracy = 0.9705, Validation Loss = 0.2692\n",
            "Epoch 1714/2500\n",
            "Epoch 1714: Training Accuracy = 0.9902, Training Loss = 0.0903, Validation Accuracy = 0.9619, Validation Loss = 0.3260\n",
            "Epoch 1715/2500\n",
            "Epoch 1715: Training Accuracy = 0.9902, Training Loss = 0.0903, Validation Accuracy = 0.9619, Validation Loss = 0.3260\n",
            "Epoch 1716/2500\n",
            "Epoch 1716: Training Accuracy = 0.9922, Training Loss = 0.0879, Validation Accuracy = 0.9537, Validation Loss = 0.3676\n",
            "Epoch 1717/2500\n",
            "Epoch 1717: Training Accuracy = 0.9805, Training Loss = 0.1337, Validation Accuracy = 0.9532, Validation Loss = 0.3663\n",
            "Epoch 1718/2500\n",
            "Epoch 1718: Training Accuracy = 0.9805, Training Loss = 0.1337, Validation Accuracy = 0.9532, Validation Loss = 0.3663\n",
            "Epoch 1719/2500\n",
            "Epoch 1719: Training Accuracy = 0.9922, Training Loss = 0.0927, Validation Accuracy = 0.9602, Validation Loss = 0.3269\n",
            "Epoch 1720/2500\n",
            "Epoch 1720: Training Accuracy = 0.9922, Training Loss = 0.0927, Validation Accuracy = 0.9602, Validation Loss = 0.3269\n",
            "Epoch 1721/2500\n",
            "Epoch 1721: Training Accuracy = 0.9883, Training Loss = 0.0807, Validation Accuracy = 0.9680, Validation Loss = 0.2794\n",
            "Epoch 1722/2500\n",
            "Epoch 1722: Training Accuracy = 0.9961, Training Loss = 0.0520, Validation Accuracy = 0.9727, Validation Loss = 0.2504\n",
            "Epoch 1723/2500\n",
            "Epoch 1723: Training Accuracy = 0.9961, Training Loss = 0.0520, Validation Accuracy = 0.9727, Validation Loss = 0.2504\n",
            "Epoch 1724/2500\n",
            "Epoch 1724: Training Accuracy = 0.9883, Training Loss = 0.0692, Validation Accuracy = 0.9763, Validation Loss = 0.2337\n",
            "Epoch 1725/2500\n",
            "Epoch 1725: Training Accuracy = 0.9883, Training Loss = 0.0692, Validation Accuracy = 0.9763, Validation Loss = 0.2337\n",
            "Epoch 1726/2500\n",
            "Epoch 1726: Training Accuracy = 0.9961, Training Loss = 0.0381, Validation Accuracy = 0.9712, Validation Loss = 0.2426\n",
            "Epoch 1727/2500\n",
            "Epoch 1727: Training Accuracy = 0.9824, Training Loss = 0.0928, Validation Accuracy = 0.9780, Validation Loss = 0.2212\n",
            "Epoch 1728/2500\n",
            "Epoch 1728: Training Accuracy = 0.9824, Training Loss = 0.0928, Validation Accuracy = 0.9780, Validation Loss = 0.2212\n",
            "Epoch 1729/2500\n",
            "Epoch 1729: Training Accuracy = 0.9844, Training Loss = 0.0763, Validation Accuracy = 0.9766, Validation Loss = 0.2204\n",
            "Epoch 1730/2500\n",
            "Epoch 1730: Training Accuracy = 0.9844, Training Loss = 0.0763, Validation Accuracy = 0.9766, Validation Loss = 0.2204\n",
            "Epoch 1731/2500\n",
            "Epoch 1731: Training Accuracy = 0.9922, Training Loss = 0.0512, Validation Accuracy = 0.9768, Validation Loss = 0.2180\n",
            "Epoch 1732/2500\n",
            "Epoch 1732: Training Accuracy = 0.9824, Training Loss = 0.0861, Validation Accuracy = 0.9790, Validation Loss = 0.2227\n",
            "Epoch 1733/2500\n",
            "Epoch 1733: Training Accuracy = 0.9824, Training Loss = 0.0861, Validation Accuracy = 0.9790, Validation Loss = 0.2227\n",
            "Epoch 1734/2500\n",
            "Epoch 1734: Training Accuracy = 0.9844, Training Loss = 0.0795, Validation Accuracy = 0.9790, Validation Loss = 0.2427\n",
            "Epoch 1735/2500\n",
            "Epoch 1735: Training Accuracy = 0.9844, Training Loss = 0.0795, Validation Accuracy = 0.9790, Validation Loss = 0.2427\n",
            "Epoch 1736/2500\n",
            "Epoch 1736: Training Accuracy = 0.8789, Training Loss = 0.6551, Validation Accuracy = 0.6979, Validation Loss = 1.2365\n",
            "Epoch 1737/2500\n",
            "Epoch 1737: Training Accuracy = 0.9668, Training Loss = 0.2874, Validation Accuracy = 0.9188, Validation Loss = 0.5334\n",
            "Epoch 1738/2500\n",
            "Epoch 1738: Training Accuracy = 0.9668, Training Loss = 0.2874, Validation Accuracy = 0.9188, Validation Loss = 0.5334\n",
            "Epoch 1739/2500\n",
            "Epoch 1739: Training Accuracy = 0.9863, Training Loss = 0.1574, Validation Accuracy = 0.9540, Validation Loss = 0.3771\n",
            "Epoch 1740/2500\n",
            "Epoch 1740: Training Accuracy = 0.9863, Training Loss = 0.1574, Validation Accuracy = 0.9540, Validation Loss = 0.3771\n",
            "Epoch 1741/2500\n",
            "Epoch 1741: Training Accuracy = 0.9844, Training Loss = 0.1051, Validation Accuracy = 0.9746, Validation Loss = 0.2714\n",
            "Epoch 1742/2500\n",
            "Epoch 1742: Training Accuracy = 0.9883, Training Loss = 0.0784, Validation Accuracy = 0.9780, Validation Loss = 0.2286\n",
            "Epoch 1743/2500\n",
            "Epoch 1743: Training Accuracy = 0.9883, Training Loss = 0.0784, Validation Accuracy = 0.9780, Validation Loss = 0.2286\n",
            "Epoch 1744/2500\n",
            "Epoch 1744: Training Accuracy = 0.9961, Training Loss = 0.0431, Validation Accuracy = 0.9807, Validation Loss = 0.2107\n",
            "Epoch 1745/2500\n",
            "Epoch 1745: Training Accuracy = 0.9961, Training Loss = 0.0431, Validation Accuracy = 0.9807, Validation Loss = 0.2107\n",
            "Epoch 1746/2500\n",
            "Epoch 1746: Training Accuracy = 0.9863, Training Loss = 0.0755, Validation Accuracy = 0.9809, Validation Loss = 0.2087\n",
            "Epoch 1747/2500\n",
            "Epoch 1747: Training Accuracy = 0.9883, Training Loss = 0.0670, Validation Accuracy = 0.9816, Validation Loss = 0.2006\n",
            "Epoch 1748/2500\n",
            "Epoch 1748: Training Accuracy = 0.9883, Training Loss = 0.0670, Validation Accuracy = 0.9816, Validation Loss = 0.2006\n",
            "Epoch 1749/2500\n",
            "Epoch 1749: Training Accuracy = 0.9922, Training Loss = 0.0546, Validation Accuracy = 0.9810, Validation Loss = 0.1989\n",
            "Epoch 1750/2500\n",
            "Epoch 1750: Training Accuracy = 0.9922, Training Loss = 0.0546, Validation Accuracy = 0.9810, Validation Loss = 0.1989\n",
            "Epoch 1751/2500\n",
            "Epoch 1751: Training Accuracy = 0.9844, Training Loss = 0.0785, Validation Accuracy = 0.9813, Validation Loss = 0.1977\n",
            "Epoch 1752/2500\n",
            "Epoch 1752: Training Accuracy = 0.9902, Training Loss = 0.0593, Validation Accuracy = 0.9821, Validation Loss = 0.1953\n",
            "Epoch 1753/2500\n",
            "Epoch 1753: Training Accuracy = 0.9902, Training Loss = 0.0593, Validation Accuracy = 0.9821, Validation Loss = 0.1953\n",
            "Epoch 1754/2500\n",
            "Epoch 1754: Training Accuracy = 0.9883, Training Loss = 0.0677, Validation Accuracy = 0.9818, Validation Loss = 0.1991\n",
            "Epoch 1755/2500\n",
            "Epoch 1755: Training Accuracy = 0.9883, Training Loss = 0.0677, Validation Accuracy = 0.9818, Validation Loss = 0.1991\n",
            "Epoch 1756/2500\n",
            "Epoch 1756: Training Accuracy = 0.9863, Training Loss = 0.0767, Validation Accuracy = 0.9810, Validation Loss = 0.2043\n",
            "Epoch 1757/2500\n",
            "Epoch 1757: Training Accuracy = 0.9922, Training Loss = 0.0568, Validation Accuracy = 0.9806, Validation Loss = 0.2090\n",
            "Epoch 1758/2500\n",
            "Epoch 1758: Training Accuracy = 0.9922, Training Loss = 0.0568, Validation Accuracy = 0.9806, Validation Loss = 0.2090\n",
            "Epoch 1759/2500\n",
            "Epoch 1759: Training Accuracy = 0.9902, Training Loss = 0.0652, Validation Accuracy = 0.9810, Validation Loss = 0.2246\n",
            "Epoch 1760/2500\n",
            "Epoch 1760: Training Accuracy = 0.9902, Training Loss = 0.0652, Validation Accuracy = 0.9810, Validation Loss = 0.2246\n",
            "Epoch 1761/2500\n",
            "Epoch 1761: Training Accuracy = 0.9902, Training Loss = 0.0658, Validation Accuracy = 0.9807, Validation Loss = 0.2179\n",
            "Epoch 1762/2500\n",
            "Epoch 1762: Training Accuracy = 0.9805, Training Loss = 0.0993, Validation Accuracy = 0.9822, Validation Loss = 0.2118\n",
            "Epoch 1763/2500\n",
            "Epoch 1763: Training Accuracy = 0.9805, Training Loss = 0.0993, Validation Accuracy = 0.9822, Validation Loss = 0.2118\n",
            "Epoch 1764/2500\n",
            "Epoch 1764: Training Accuracy = 0.9883, Training Loss = 0.0693, Validation Accuracy = 0.9819, Validation Loss = 0.2070\n",
            "Epoch 1765/2500\n",
            "Epoch 1765: Training Accuracy = 0.9883, Training Loss = 0.0693, Validation Accuracy = 0.9819, Validation Loss = 0.2070\n",
            "Epoch 1766/2500\n",
            "Epoch 1766: Training Accuracy = 0.9902, Training Loss = 0.0641, Validation Accuracy = 0.9810, Validation Loss = 0.2141\n",
            "Epoch 1767/2500\n",
            "Epoch 1767: Training Accuracy = 0.9902, Training Loss = 0.0712, Validation Accuracy = 0.9822, Validation Loss = 0.2244\n",
            "Epoch 1768/2500\n",
            "Epoch 1768: Training Accuracy = 0.9902, Training Loss = 0.0712, Validation Accuracy = 0.9822, Validation Loss = 0.2244\n",
            "Epoch 1769/2500\n",
            "Epoch 1769: Training Accuracy = 0.9785, Training Loss = 0.1185, Validation Accuracy = 0.9809, Validation Loss = 0.2355\n",
            "Epoch 1770/2500\n",
            "Epoch 1770: Training Accuracy = 0.9785, Training Loss = 0.1185, Validation Accuracy = 0.9809, Validation Loss = 0.2355\n",
            "Epoch 1771/2500\n",
            "Epoch 1771: Training Accuracy = 0.9902, Training Loss = 0.0728, Validation Accuracy = 0.9794, Validation Loss = 0.2333\n",
            "Epoch 1772/2500\n",
            "Epoch 1772: Training Accuracy = 0.9902, Training Loss = 0.0734, Validation Accuracy = 0.9812, Validation Loss = 0.2148\n",
            "Epoch 1773/2500\n",
            "Epoch 1773: Training Accuracy = 0.9902, Training Loss = 0.0734, Validation Accuracy = 0.9812, Validation Loss = 0.2148\n",
            "Epoch 1774/2500\n",
            "Epoch 1774: Training Accuracy = 0.9922, Training Loss = 0.0560, Validation Accuracy = 0.9839, Validation Loss = 0.1980\n",
            "Epoch 1775/2500\n",
            "Epoch 1775: Training Accuracy = 0.9922, Training Loss = 0.0560, Validation Accuracy = 0.9839, Validation Loss = 0.1980\n",
            "Epoch 1776/2500\n",
            "Epoch 1776: Training Accuracy = 0.9863, Training Loss = 0.0767, Validation Accuracy = 0.9833, Validation Loss = 0.1933\n",
            "Epoch 1777/2500\n",
            "Epoch 1777: Training Accuracy = 0.9863, Training Loss = 0.0836, Validation Accuracy = 0.9828, Validation Loss = 0.2083\n",
            "Epoch 1778/2500\n",
            "Epoch 1778: Training Accuracy = 0.9863, Training Loss = 0.0836, Validation Accuracy = 0.9828, Validation Loss = 0.2083\n",
            "Epoch 1779/2500\n",
            "Epoch 1779: Training Accuracy = 0.9727, Training Loss = 0.1324, Validation Accuracy = 0.9836, Validation Loss = 0.1935\n",
            "Epoch 1780/2500\n",
            "Epoch 1780: Training Accuracy = 0.9727, Training Loss = 0.1324, Validation Accuracy = 0.9836, Validation Loss = 0.1935\n",
            "Epoch 1781/2500\n",
            "Epoch 1781: Training Accuracy = 0.9883, Training Loss = 0.0670, Validation Accuracy = 0.9842, Validation Loss = 0.1994\n",
            "Epoch 1782/2500\n",
            "Epoch 1782: Training Accuracy = 0.9902, Training Loss = 0.0633, Validation Accuracy = 0.9848, Validation Loss = 0.1881\n",
            "Epoch 1783/2500\n",
            "Epoch 1783: Training Accuracy = 0.9902, Training Loss = 0.0633, Validation Accuracy = 0.9848, Validation Loss = 0.1881\n",
            "Epoch 1784/2500\n",
            "Epoch 1784: Training Accuracy = 0.9883, Training Loss = 0.0688, Validation Accuracy = 0.9825, Validation Loss = 0.2040\n",
            "Epoch 1785/2500\n",
            "Epoch 1785: Training Accuracy = 0.9883, Training Loss = 0.0688, Validation Accuracy = 0.9825, Validation Loss = 0.2040\n",
            "Epoch 1786/2500\n",
            "Epoch 1786: Training Accuracy = 0.9941, Training Loss = 0.0488, Validation Accuracy = 0.9833, Validation Loss = 0.1938\n",
            "Epoch 1787/2500\n",
            "Epoch 1787: Training Accuracy = 0.6074, Training Loss = 1.6137, Validation Accuracy = 0.1952, Validation Loss = 3.4487\n",
            "Epoch 1788/2500\n",
            "Epoch 1788: Training Accuracy = 0.6074, Training Loss = 1.6137, Validation Accuracy = 0.1952, Validation Loss = 3.4487\n",
            "Epoch 1789/2500\n",
            "Epoch 1789: Training Accuracy = 0.9258, Training Loss = 0.5109, Validation Accuracy = 0.8080, Validation Loss = 0.9131\n",
            "Epoch 1790/2500\n",
            "Epoch 1790: Training Accuracy = 0.9258, Training Loss = 0.5109, Validation Accuracy = 0.8080, Validation Loss = 0.9131\n",
            "Epoch 1791/2500\n",
            "Epoch 1791: Training Accuracy = 0.9824, Training Loss = 0.2088, Validation Accuracy = 0.9405, Validation Loss = 0.4548\n",
            "Epoch 1792/2500\n",
            "Epoch 1792: Training Accuracy = 0.9824, Training Loss = 0.1441, Validation Accuracy = 0.9721, Validation Loss = 0.2995\n",
            "Epoch 1793/2500\n",
            "Epoch 1793: Training Accuracy = 0.9824, Training Loss = 0.1441, Validation Accuracy = 0.9721, Validation Loss = 0.2995\n",
            "Epoch 1794/2500\n",
            "Epoch 1794: Training Accuracy = 0.9883, Training Loss = 0.0861, Validation Accuracy = 0.9806, Validation Loss = 0.2251\n",
            "Epoch 1795/2500\n",
            "Epoch 1795: Training Accuracy = 0.9883, Training Loss = 0.0861, Validation Accuracy = 0.9806, Validation Loss = 0.2251\n",
            "Epoch 1796/2500\n",
            "Epoch 1796: Training Accuracy = 0.9941, Training Loss = 0.0507, Validation Accuracy = 0.9825, Validation Loss = 0.1951\n",
            "Epoch 1797/2500\n",
            "Epoch 1797: Training Accuracy = 0.9883, Training Loss = 0.0682, Validation Accuracy = 0.9851, Validation Loss = 0.1785\n",
            "Epoch 1798/2500\n",
            "Epoch 1798: Training Accuracy = 0.9883, Training Loss = 0.0682, Validation Accuracy = 0.9851, Validation Loss = 0.1785\n",
            "Epoch 1799/2500\n",
            "Epoch 1799: Training Accuracy = 0.9863, Training Loss = 0.0784, Validation Accuracy = 0.9857, Validation Loss = 0.1718\n",
            "Epoch 1800/2500\n",
            "Epoch 1800: Training Accuracy = 0.9863, Training Loss = 0.0784, Validation Accuracy = 0.9857, Validation Loss = 0.1718\n",
            "Epoch 1801/2500\n",
            "Epoch 1801: Training Accuracy = 0.9902, Training Loss = 0.0565, Validation Accuracy = 0.9859, Validation Loss = 0.1685\n",
            "Epoch 1802/2500\n",
            "Epoch 1802: Training Accuracy = 0.9941, Training Loss = 0.0447, Validation Accuracy = 0.9865, Validation Loss = 0.1673\n",
            "Epoch 1803/2500\n",
            "Epoch 1803: Training Accuracy = 0.9941, Training Loss = 0.0447, Validation Accuracy = 0.9865, Validation Loss = 0.1673\n",
            "Epoch 1804/2500\n",
            "Epoch 1804: Training Accuracy = 0.9922, Training Loss = 0.0501, Validation Accuracy = 0.9874, Validation Loss = 0.1631\n",
            "Epoch 1805/2500\n",
            "Epoch 1805: Training Accuracy = 0.9922, Training Loss = 0.0501, Validation Accuracy = 0.9874, Validation Loss = 0.1631\n",
            "Epoch 1806/2500\n",
            "Epoch 1806: Training Accuracy = 0.9863, Training Loss = 0.0708, Validation Accuracy = 0.9865, Validation Loss = 0.1716\n",
            "Epoch 1807/2500\n",
            "Epoch 1807: Training Accuracy = 0.9824, Training Loss = 0.0900, Validation Accuracy = 0.9868, Validation Loss = 0.1629\n",
            "Epoch 1808/2500\n",
            "Epoch 1808: Training Accuracy = 0.9824, Training Loss = 0.0900, Validation Accuracy = 0.9868, Validation Loss = 0.1629\n",
            "Epoch 1809/2500\n",
            "Epoch 1809: Training Accuracy = 0.9883, Training Loss = 0.0642, Validation Accuracy = 0.9889, Validation Loss = 0.1615\n",
            "Epoch 1810/2500\n",
            "Epoch 1810: Training Accuracy = 0.9883, Training Loss = 0.0642, Validation Accuracy = 0.9889, Validation Loss = 0.1615\n",
            "Epoch 1811/2500\n",
            "Epoch 1811: Training Accuracy = 0.9863, Training Loss = 0.0710, Validation Accuracy = 0.9877, Validation Loss = 0.1648\n",
            "Epoch 1812/2500\n",
            "Epoch 1812: Training Accuracy = 0.9902, Training Loss = 0.0561, Validation Accuracy = 0.9879, Validation Loss = 0.1617\n",
            "Epoch 1813/2500\n",
            "Epoch 1813: Training Accuracy = 0.9902, Training Loss = 0.0561, Validation Accuracy = 0.9879, Validation Loss = 0.1617\n",
            "Epoch 1814/2500\n",
            "Epoch 1814: Training Accuracy = 0.9883, Training Loss = 0.0648, Validation Accuracy = 0.9882, Validation Loss = 0.1633\n",
            "Epoch 1815/2500\n",
            "Epoch 1815: Training Accuracy = 0.9883, Training Loss = 0.0648, Validation Accuracy = 0.9882, Validation Loss = 0.1633\n",
            "Epoch 1816/2500\n",
            "Epoch 1816: Training Accuracy = 0.9824, Training Loss = 0.0832, Validation Accuracy = 0.9874, Validation Loss = 0.1674\n",
            "Epoch 1817/2500\n",
            "Epoch 1817: Training Accuracy = 0.9961, Training Loss = 0.0357, Validation Accuracy = 0.9882, Validation Loss = 0.1713\n",
            "Epoch 1818/2500\n",
            "Epoch 1818: Training Accuracy = 0.9961, Training Loss = 0.0357, Validation Accuracy = 0.9882, Validation Loss = 0.1713\n",
            "Epoch 1819/2500\n",
            "Epoch 1819: Training Accuracy = 0.9902, Training Loss = 0.0624, Validation Accuracy = 0.9824, Validation Loss = 0.2125\n",
            "Epoch 1820/2500\n",
            "Epoch 1820: Training Accuracy = 0.9902, Training Loss = 0.0624, Validation Accuracy = 0.9824, Validation Loss = 0.2125\n",
            "Epoch 1821/2500\n",
            "Epoch 1821: Training Accuracy = 0.9824, Training Loss = 0.0935, Validation Accuracy = 0.9863, Validation Loss = 0.1968\n",
            "Epoch 1822/2500\n",
            "Epoch 1822: Training Accuracy = 0.9922, Training Loss = 0.0641, Validation Accuracy = 0.9871, Validation Loss = 0.1779\n",
            "Epoch 1823/2500\n",
            "Epoch 1823: Training Accuracy = 0.9922, Training Loss = 0.0641, Validation Accuracy = 0.9871, Validation Loss = 0.1779\n",
            "Epoch 1824/2500\n",
            "Epoch 1824: Training Accuracy = 0.9746, Training Loss = 0.1244, Validation Accuracy = 0.9853, Validation Loss = 0.1923\n",
            "Epoch 1825/2500\n",
            "Epoch 1825: Training Accuracy = 0.9746, Training Loss = 0.1244, Validation Accuracy = 0.9853, Validation Loss = 0.1923\n",
            "Epoch 1826/2500\n",
            "Epoch 1826: Training Accuracy = 0.9863, Training Loss = 0.0803, Validation Accuracy = 0.9865, Validation Loss = 0.1796\n",
            "Epoch 1827/2500\n",
            "Epoch 1827: Training Accuracy = 0.9922, Training Loss = 0.0560, Validation Accuracy = 0.9888, Validation Loss = 0.1576\n",
            "Epoch 1828/2500\n",
            "Epoch 1828: Training Accuracy = 0.9922, Training Loss = 0.0560, Validation Accuracy = 0.9888, Validation Loss = 0.1576\n",
            "Epoch 1829/2500\n",
            "Epoch 1829: Training Accuracy = 0.9902, Training Loss = 0.0563, Validation Accuracy = 0.9888, Validation Loss = 0.1495\n",
            "Epoch 1830/2500\n",
            "Epoch 1830: Training Accuracy = 0.9902, Training Loss = 0.0563, Validation Accuracy = 0.9888, Validation Loss = 0.1495\n",
            "Epoch 1831/2500\n",
            "Epoch 1831: Training Accuracy = 0.9902, Training Loss = 0.0553, Validation Accuracy = 0.9883, Validation Loss = 0.1582\n",
            "Epoch 1832/2500\n",
            "Epoch 1832: Training Accuracy = 0.9863, Training Loss = 0.0785, Validation Accuracy = 0.9880, Validation Loss = 0.1568\n",
            "Epoch 1833/2500\n",
            "Epoch 1833: Training Accuracy = 0.9863, Training Loss = 0.0785, Validation Accuracy = 0.9880, Validation Loss = 0.1568\n",
            "Epoch 1834/2500\n",
            "Epoch 1834: Training Accuracy = 0.6426, Training Loss = 1.5521, Validation Accuracy = 0.6164, Validation Loss = 1.6783\n",
            "Epoch 1835/2500\n",
            "Epoch 1835: Training Accuracy = 0.6426, Training Loss = 1.5521, Validation Accuracy = 0.6164, Validation Loss = 1.6783\n",
            "Epoch 1836/2500\n",
            "Epoch 1836: Training Accuracy = 0.9688, Training Loss = 0.3546, Validation Accuracy = 0.9294, Validation Loss = 0.5779\n",
            "Epoch 1837/2500\n",
            "Epoch 1837: Training Accuracy = 0.9902, Training Loss = 0.1560, Validation Accuracy = 0.9730, Validation Loss = 0.3291\n",
            "Epoch 1838/2500\n",
            "Epoch 1838: Training Accuracy = 0.9902, Training Loss = 0.1560, Validation Accuracy = 0.9730, Validation Loss = 0.3291\n",
            "Epoch 1839/2500\n",
            "Epoch 1839: Training Accuracy = 0.9844, Training Loss = 0.1160, Validation Accuracy = 0.9850, Validation Loss = 0.2299\n",
            "Epoch 1840/2500\n",
            "Epoch 1840: Training Accuracy = 0.9844, Training Loss = 0.1160, Validation Accuracy = 0.9850, Validation Loss = 0.2299\n",
            "Epoch 1841/2500\n",
            "Epoch 1841: Training Accuracy = 0.9824, Training Loss = 0.1039, Validation Accuracy = 0.9880, Validation Loss = 0.1820\n",
            "Epoch 1842/2500\n",
            "Epoch 1842: Training Accuracy = 0.9863, Training Loss = 0.0843, Validation Accuracy = 0.9889, Validation Loss = 0.1548\n",
            "Epoch 1843/2500\n",
            "Epoch 1843: Training Accuracy = 0.9863, Training Loss = 0.0843, Validation Accuracy = 0.9889, Validation Loss = 0.1548\n",
            "Epoch 1844/2500\n",
            "Epoch 1844: Training Accuracy = 0.9883, Training Loss = 0.0732, Validation Accuracy = 0.9898, Validation Loss = 0.1442\n",
            "Epoch 1845/2500\n",
            "Epoch 1845: Training Accuracy = 0.9883, Training Loss = 0.0732, Validation Accuracy = 0.9898, Validation Loss = 0.1442\n",
            "Epoch 1846/2500\n",
            "Epoch 1846: Training Accuracy = 0.9922, Training Loss = 0.0503, Validation Accuracy = 0.9900, Validation Loss = 0.1414\n",
            "Epoch 1847/2500\n",
            "Epoch 1847: Training Accuracy = 0.9863, Training Loss = 0.0719, Validation Accuracy = 0.9900, Validation Loss = 0.1384\n",
            "Epoch 1848/2500\n",
            "Epoch 1848: Training Accuracy = 0.9863, Training Loss = 0.0719, Validation Accuracy = 0.9900, Validation Loss = 0.1384\n",
            "Epoch 1849/2500\n",
            "Epoch 1849: Training Accuracy = 0.9922, Training Loss = 0.0558, Validation Accuracy = 0.9901, Validation Loss = 0.1360\n",
            "Epoch 1850/2500\n",
            "Epoch 1850: Training Accuracy = 0.9922, Training Loss = 0.0558, Validation Accuracy = 0.9901, Validation Loss = 0.1360\n",
            "Epoch 1851/2500\n",
            "Epoch 1851: Training Accuracy = 0.9883, Training Loss = 0.0621, Validation Accuracy = 0.9901, Validation Loss = 0.1373\n",
            "Epoch 1852/2500\n",
            "Epoch 1852: Training Accuracy = 0.9844, Training Loss = 0.0783, Validation Accuracy = 0.9901, Validation Loss = 0.1346\n",
            "Epoch 1853/2500\n",
            "Epoch 1853: Training Accuracy = 0.9844, Training Loss = 0.0783, Validation Accuracy = 0.9901, Validation Loss = 0.1346\n",
            "Epoch 1854/2500\n",
            "Epoch 1854: Training Accuracy = 0.9863, Training Loss = 0.0698, Validation Accuracy = 0.9901, Validation Loss = 0.1333\n",
            "Epoch 1855/2500\n",
            "Epoch 1855: Training Accuracy = 0.9863, Training Loss = 0.0698, Validation Accuracy = 0.9901, Validation Loss = 0.1333\n",
            "Epoch 1856/2500\n",
            "Epoch 1856: Training Accuracy = 0.9902, Training Loss = 0.0568, Validation Accuracy = 0.9900, Validation Loss = 0.1358\n",
            "Epoch 1857/2500\n",
            "Epoch 1857: Training Accuracy = 0.9863, Training Loss = 0.0730, Validation Accuracy = 0.9900, Validation Loss = 0.1381\n",
            "Epoch 1858/2500\n",
            "Epoch 1858: Training Accuracy = 0.9863, Training Loss = 0.0730, Validation Accuracy = 0.9900, Validation Loss = 0.1381\n",
            "Epoch 1859/2500\n",
            "Epoch 1859: Training Accuracy = 0.9805, Training Loss = 0.0936, Validation Accuracy = 0.9900, Validation Loss = 0.1383\n",
            "Epoch 1860/2500\n",
            "Epoch 1860: Training Accuracy = 0.9805, Training Loss = 0.0936, Validation Accuracy = 0.9900, Validation Loss = 0.1383\n",
            "Epoch 1861/2500\n",
            "Epoch 1861: Training Accuracy = 0.9824, Training Loss = 0.0860, Validation Accuracy = 0.9895, Validation Loss = 0.1488\n",
            "Epoch 1862/2500\n",
            "Epoch 1862: Training Accuracy = 0.9883, Training Loss = 0.0729, Validation Accuracy = 0.9900, Validation Loss = 0.1463\n",
            "Epoch 1863/2500\n",
            "Epoch 1863: Training Accuracy = 0.9883, Training Loss = 0.0729, Validation Accuracy = 0.9900, Validation Loss = 0.1463\n",
            "Epoch 1864/2500\n",
            "Epoch 1864: Training Accuracy = 0.9824, Training Loss = 0.0859, Validation Accuracy = 0.9894, Validation Loss = 0.1457\n",
            "Epoch 1865/2500\n",
            "Epoch 1865: Training Accuracy = 0.9824, Training Loss = 0.0859, Validation Accuracy = 0.9894, Validation Loss = 0.1457\n",
            "Epoch 1866/2500\n",
            "Epoch 1866: Training Accuracy = 0.9922, Training Loss = 0.0671, Validation Accuracy = 0.9897, Validation Loss = 0.1470\n",
            "Epoch 1867/2500\n",
            "Epoch 1867: Training Accuracy = 0.9824, Training Loss = 0.0950, Validation Accuracy = 0.9894, Validation Loss = 0.1506\n",
            "Epoch 1868/2500\n",
            "Epoch 1868: Training Accuracy = 0.9824, Training Loss = 0.0950, Validation Accuracy = 0.9894, Validation Loss = 0.1506\n",
            "Epoch 1869/2500\n",
            "Epoch 1869: Training Accuracy = 0.9980, Training Loss = 0.0391, Validation Accuracy = 0.9892, Validation Loss = 0.1513\n",
            "Epoch 1870/2500\n",
            "Epoch 1870: Training Accuracy = 0.9980, Training Loss = 0.0391, Validation Accuracy = 0.9892, Validation Loss = 0.1513\n",
            "Epoch 1871/2500\n",
            "Epoch 1871: Training Accuracy = 0.9883, Training Loss = 0.0713, Validation Accuracy = 0.9897, Validation Loss = 0.1400\n",
            "Epoch 1872/2500\n",
            "Epoch 1872: Training Accuracy = 0.9883, Training Loss = 0.0756, Validation Accuracy = 0.9891, Validation Loss = 0.1446\n",
            "Epoch 1873/2500\n",
            "Epoch 1873: Training Accuracy = 0.9883, Training Loss = 0.0756, Validation Accuracy = 0.9891, Validation Loss = 0.1446\n",
            "Epoch 1874/2500\n",
            "Epoch 1874: Training Accuracy = 0.9922, Training Loss = 0.0617, Validation Accuracy = 0.9889, Validation Loss = 0.1614\n",
            "Epoch 1875/2500\n",
            "Epoch 1875: Training Accuracy = 0.9922, Training Loss = 0.0617, Validation Accuracy = 0.9889, Validation Loss = 0.1614\n",
            "Epoch 1876/2500\n",
            "Epoch 1876: Training Accuracy = 0.9902, Training Loss = 0.0668, Validation Accuracy = 0.9894, Validation Loss = 0.1497\n",
            "Epoch 1877/2500\n",
            "Epoch 1877: Training Accuracy = 0.9863, Training Loss = 0.0762, Validation Accuracy = 0.9894, Validation Loss = 0.1421\n",
            "Epoch 1878/2500\n",
            "Epoch 1878: Training Accuracy = 0.9863, Training Loss = 0.0762, Validation Accuracy = 0.9894, Validation Loss = 0.1421\n",
            "Epoch 1879/2500\n",
            "Epoch 1879: Training Accuracy = 0.9922, Training Loss = 0.0652, Validation Accuracy = 0.9892, Validation Loss = 0.1462\n",
            "Epoch 1880/2500\n",
            "Epoch 1880: Training Accuracy = 0.9922, Training Loss = 0.0652, Validation Accuracy = 0.9892, Validation Loss = 0.1462\n",
            "Epoch 1881/2500\n",
            "Epoch 1881: Training Accuracy = 0.9902, Training Loss = 0.0585, Validation Accuracy = 0.9897, Validation Loss = 0.1360\n",
            "Epoch 1882/2500\n",
            "Epoch 1882: Training Accuracy = 0.9883, Training Loss = 0.0653, Validation Accuracy = 0.9889, Validation Loss = 0.1430\n",
            "Epoch 1883/2500\n",
            "Epoch 1883: Training Accuracy = 0.9883, Training Loss = 0.0653, Validation Accuracy = 0.9889, Validation Loss = 0.1430\n",
            "Epoch 1884/2500\n",
            "Epoch 1884: Training Accuracy = 0.9922, Training Loss = 0.0518, Validation Accuracy = 0.9853, Validation Loss = 0.1533\n",
            "Epoch 1885/2500\n",
            "Epoch 1885: Training Accuracy = 0.9922, Training Loss = 0.0518, Validation Accuracy = 0.9853, Validation Loss = 0.1533\n",
            "Epoch 1886/2500\n",
            "Epoch 1886: Training Accuracy = 0.9922, Training Loss = 0.0662, Validation Accuracy = 0.9879, Validation Loss = 0.1687\n",
            "Epoch 1887/2500\n",
            "Epoch 1887: Training Accuracy = 0.8555, Training Loss = 0.6121, Validation Accuracy = 0.7846, Validation Loss = 0.8830\n",
            "Epoch 1888/2500\n",
            "Epoch 1888: Training Accuracy = 0.8555, Training Loss = 0.6121, Validation Accuracy = 0.7846, Validation Loss = 0.8830\n",
            "Epoch 1889/2500\n",
            "Epoch 1889: Training Accuracy = 0.9805, Training Loss = 0.2239, Validation Accuracy = 0.9551, Validation Loss = 0.3788\n",
            "Epoch 1890/2500\n",
            "Epoch 1890: Training Accuracy = 0.9805, Training Loss = 0.2239, Validation Accuracy = 0.9551, Validation Loss = 0.3788\n",
            "Epoch 1891/2500\n",
            "Epoch 1891: Training Accuracy = 0.9844, Training Loss = 0.1282, Validation Accuracy = 0.9824, Validation Loss = 0.2282\n",
            "Epoch 1892/2500\n",
            "Epoch 1892: Training Accuracy = 0.9980, Training Loss = 0.0445, Validation Accuracy = 0.9892, Validation Loss = 0.1561\n",
            "Epoch 1893/2500\n",
            "Epoch 1893: Training Accuracy = 0.9980, Training Loss = 0.0445, Validation Accuracy = 0.9892, Validation Loss = 0.1561\n",
            "Epoch 1894/2500\n",
            "Epoch 1894: Training Accuracy = 0.9902, Training Loss = 0.0583, Validation Accuracy = 0.9897, Validation Loss = 0.1313\n",
            "Epoch 1895/2500\n",
            "Epoch 1895: Training Accuracy = 0.9902, Training Loss = 0.0583, Validation Accuracy = 0.9897, Validation Loss = 0.1313\n",
            "Epoch 1896/2500\n",
            "Epoch 1896: Training Accuracy = 0.9863, Training Loss = 0.0656, Validation Accuracy = 0.9898, Validation Loss = 0.1176\n",
            "Epoch 1897/2500\n",
            "Epoch 1897: Training Accuracy = 0.9941, Training Loss = 0.0372, Validation Accuracy = 0.9900, Validation Loss = 0.1129\n",
            "Epoch 1898/2500\n",
            "Epoch 1898: Training Accuracy = 0.9941, Training Loss = 0.0372, Validation Accuracy = 0.9900, Validation Loss = 0.1129\n",
            "Epoch 1899/2500\n",
            "Epoch 1899: Training Accuracy = 0.9883, Training Loss = 0.0573, Validation Accuracy = 0.9900, Validation Loss = 0.1103\n",
            "Epoch 1900/2500\n",
            "Epoch 1900: Training Accuracy = 0.9883, Training Loss = 0.0573, Validation Accuracy = 0.9900, Validation Loss = 0.1103\n",
            "Epoch 1901/2500\n",
            "Epoch 1901: Training Accuracy = 0.9883, Training Loss = 0.0550, Validation Accuracy = 0.9901, Validation Loss = 0.1090\n",
            "Epoch 1902/2500\n",
            "Epoch 1902: Training Accuracy = 0.9902, Training Loss = 0.0505, Validation Accuracy = 0.9901, Validation Loss = 0.1079\n",
            "Epoch 1903/2500\n",
            "Epoch 1903: Training Accuracy = 0.9902, Training Loss = 0.0505, Validation Accuracy = 0.9901, Validation Loss = 0.1079\n",
            "Epoch 1904/2500\n",
            "Epoch 1904: Training Accuracy = 0.9902, Training Loss = 0.0497, Validation Accuracy = 0.9900, Validation Loss = 0.1098\n",
            "Epoch 1905/2500\n",
            "Epoch 1905: Training Accuracy = 0.9902, Training Loss = 0.0497, Validation Accuracy = 0.9900, Validation Loss = 0.1098\n",
            "Epoch 1906/2500\n",
            "Epoch 1906: Training Accuracy = 0.9844, Training Loss = 0.0766, Validation Accuracy = 0.9901, Validation Loss = 0.1122\n",
            "Epoch 1907/2500\n",
            "Epoch 1907: Training Accuracy = 0.9902, Training Loss = 0.0510, Validation Accuracy = 0.9900, Validation Loss = 0.1142\n",
            "Epoch 1908/2500\n",
            "Epoch 1908: Training Accuracy = 0.9902, Training Loss = 0.0510, Validation Accuracy = 0.9900, Validation Loss = 0.1142\n",
            "Epoch 1909/2500\n",
            "Epoch 1909: Training Accuracy = 0.9941, Training Loss = 0.0360, Validation Accuracy = 0.9901, Validation Loss = 0.1124\n",
            "Epoch 1910/2500\n",
            "Epoch 1910: Training Accuracy = 0.9941, Training Loss = 0.0360, Validation Accuracy = 0.9901, Validation Loss = 0.1124\n",
            "Epoch 1911/2500\n",
            "Epoch 1911: Training Accuracy = 0.9941, Training Loss = 0.0426, Validation Accuracy = 0.9901, Validation Loss = 0.1087\n",
            "Epoch 1912/2500\n",
            "Epoch 1912: Training Accuracy = 0.9941, Training Loss = 0.0379, Validation Accuracy = 0.9900, Validation Loss = 0.1116\n",
            "Epoch 1913/2500\n",
            "Epoch 1913: Training Accuracy = 0.9941, Training Loss = 0.0379, Validation Accuracy = 0.9900, Validation Loss = 0.1116\n",
            "Epoch 1914/2500\n",
            "Epoch 1914: Training Accuracy = 0.9902, Training Loss = 0.0495, Validation Accuracy = 0.9900, Validation Loss = 0.1091\n",
            "Epoch 1915/2500\n",
            "Epoch 1915: Training Accuracy = 0.9902, Training Loss = 0.0495, Validation Accuracy = 0.9900, Validation Loss = 0.1091\n",
            "Epoch 1916/2500\n",
            "Epoch 1916: Training Accuracy = 0.9805, Training Loss = 0.0873, Validation Accuracy = 0.9901, Validation Loss = 0.1171\n",
            "Epoch 1917/2500\n",
            "Epoch 1917: Training Accuracy = 0.9844, Training Loss = 0.0848, Validation Accuracy = 0.9901, Validation Loss = 0.1205\n",
            "Epoch 1918/2500\n",
            "Epoch 1918: Training Accuracy = 0.9844, Training Loss = 0.0848, Validation Accuracy = 0.9901, Validation Loss = 0.1205\n",
            "Epoch 1919/2500\n",
            "Epoch 1919: Training Accuracy = 0.7676, Training Loss = 1.0751, Validation Accuracy = 0.6625, Validation Loss = 1.4132\n",
            "Epoch 1920/2500\n",
            "Epoch 1920: Training Accuracy = 0.7676, Training Loss = 1.0751, Validation Accuracy = 0.6625, Validation Loss = 1.4132\n",
            "Epoch 1921/2500\n",
            "Epoch 1921: Training Accuracy = 0.9668, Training Loss = 0.3147, Validation Accuracy = 0.9290, Validation Loss = 0.5388\n",
            "Epoch 1922/2500\n",
            "Epoch 1922: Training Accuracy = 0.9902, Training Loss = 0.1412, Validation Accuracy = 0.9822, Validation Loss = 0.2556\n",
            "Epoch 1923/2500\n",
            "Epoch 1923: Training Accuracy = 0.9902, Training Loss = 0.1412, Validation Accuracy = 0.9822, Validation Loss = 0.2556\n",
            "Epoch 1924/2500\n",
            "Epoch 1924: Training Accuracy = 0.9805, Training Loss = 0.1308, Validation Accuracy = 0.9888, Validation Loss = 0.1801\n",
            "Epoch 1925/2500\n",
            "Epoch 1925: Training Accuracy = 0.9805, Training Loss = 0.1308, Validation Accuracy = 0.9888, Validation Loss = 0.1801\n",
            "Epoch 1926/2500\n",
            "Epoch 1926: Training Accuracy = 0.9883, Training Loss = 0.0771, Validation Accuracy = 0.9901, Validation Loss = 0.1428\n",
            "Epoch 1927/2500\n",
            "Epoch 1927: Training Accuracy = 0.9883, Training Loss = 0.0669, Validation Accuracy = 0.9900, Validation Loss = 0.1249\n",
            "Epoch 1928/2500\n",
            "Epoch 1928: Training Accuracy = 0.9883, Training Loss = 0.0669, Validation Accuracy = 0.9900, Validation Loss = 0.1249\n",
            "Epoch 1929/2500\n",
            "Epoch 1929: Training Accuracy = 0.9922, Training Loss = 0.0499, Validation Accuracy = 0.9901, Validation Loss = 0.1191\n",
            "Epoch 1930/2500\n",
            "Epoch 1930: Training Accuracy = 0.9922, Training Loss = 0.0499, Validation Accuracy = 0.9901, Validation Loss = 0.1191\n",
            "Epoch 1931/2500\n",
            "Epoch 1931: Training Accuracy = 0.9863, Training Loss = 0.0685, Validation Accuracy = 0.9901, Validation Loss = 0.1166\n",
            "Epoch 1932/2500\n",
            "Epoch 1932: Training Accuracy = 0.9902, Training Loss = 0.0553, Validation Accuracy = 0.9901, Validation Loss = 0.1146\n",
            "Epoch 1933/2500\n",
            "Epoch 1933: Training Accuracy = 0.9902, Training Loss = 0.0553, Validation Accuracy = 0.9901, Validation Loss = 0.1146\n",
            "Epoch 1934/2500\n",
            "Epoch 1934: Training Accuracy = 0.9902, Training Loss = 0.0605, Validation Accuracy = 0.9901, Validation Loss = 0.1146\n",
            "Epoch 1935/2500\n",
            "Epoch 1935: Training Accuracy = 0.9902, Training Loss = 0.0605, Validation Accuracy = 0.9901, Validation Loss = 0.1146\n",
            "Epoch 1936/2500\n",
            "Epoch 1936: Training Accuracy = 0.9883, Training Loss = 0.0620, Validation Accuracy = 0.9901, Validation Loss = 0.1185\n",
            "Epoch 1937/2500\n",
            "Epoch 1937: Training Accuracy = 0.9922, Training Loss = 0.0497, Validation Accuracy = 0.9901, Validation Loss = 0.1151\n",
            "Epoch 1938/2500\n",
            "Epoch 1938: Training Accuracy = 0.9922, Training Loss = 0.0497, Validation Accuracy = 0.9901, Validation Loss = 0.1151\n",
            "Epoch 1939/2500\n",
            "Epoch 1939: Training Accuracy = 0.9902, Training Loss = 0.0561, Validation Accuracy = 0.9901, Validation Loss = 0.1156\n",
            "Epoch 1940/2500\n",
            "Epoch 1940: Training Accuracy = 0.9902, Training Loss = 0.0561, Validation Accuracy = 0.9901, Validation Loss = 0.1156\n",
            "Epoch 1941/2500\n",
            "Epoch 1941: Training Accuracy = 0.9922, Training Loss = 0.0487, Validation Accuracy = 0.9901, Validation Loss = 0.1158\n",
            "Epoch 1942/2500\n",
            "Epoch 1942: Training Accuracy = 0.9805, Training Loss = 0.0918, Validation Accuracy = 0.9901, Validation Loss = 0.1144\n",
            "Epoch 1943/2500\n",
            "Epoch 1943: Training Accuracy = 0.9805, Training Loss = 0.0918, Validation Accuracy = 0.9901, Validation Loss = 0.1144\n",
            "Epoch 1944/2500\n",
            "Epoch 1944: Training Accuracy = 0.9863, Training Loss = 0.0699, Validation Accuracy = 0.9901, Validation Loss = 0.1168\n",
            "Epoch 1945/2500\n",
            "Epoch 1945: Training Accuracy = 0.9863, Training Loss = 0.0699, Validation Accuracy = 0.9901, Validation Loss = 0.1168\n",
            "Epoch 1946/2500\n",
            "Epoch 1946: Training Accuracy = 0.9922, Training Loss = 0.0493, Validation Accuracy = 0.9901, Validation Loss = 0.1173\n",
            "Epoch 1947/2500\n",
            "Epoch 1947: Training Accuracy = 0.9883, Training Loss = 0.0672, Validation Accuracy = 0.9901, Validation Loss = 0.1179\n",
            "Epoch 1948/2500\n",
            "Epoch 1948: Training Accuracy = 0.9883, Training Loss = 0.0672, Validation Accuracy = 0.9901, Validation Loss = 0.1179\n",
            "Epoch 1949/2500\n",
            "Epoch 1949: Training Accuracy = 0.9922, Training Loss = 0.0537, Validation Accuracy = 0.9901, Validation Loss = 0.1131\n",
            "Epoch 1950/2500\n",
            "Epoch 1950: Training Accuracy = 0.9922, Training Loss = 0.0537, Validation Accuracy = 0.9901, Validation Loss = 0.1131\n",
            "Epoch 1951/2500\n",
            "Epoch 1951: Training Accuracy = 0.9824, Training Loss = 0.0875, Validation Accuracy = 0.9900, Validation Loss = 0.1275\n",
            "Epoch 1952/2500\n",
            "Epoch 1952: Training Accuracy = 0.9883, Training Loss = 0.0755, Validation Accuracy = 0.9901, Validation Loss = 0.1293\n",
            "Epoch 1953/2500\n",
            "Epoch 1953: Training Accuracy = 0.9883, Training Loss = 0.0755, Validation Accuracy = 0.9901, Validation Loss = 0.1293\n",
            "Epoch 1954/2500\n",
            "Epoch 1954: Training Accuracy = 0.9883, Training Loss = 0.1021, Validation Accuracy = 0.9768, Validation Loss = 0.4315\n",
            "Epoch 1955/2500\n",
            "Epoch 1955: Training Accuracy = 0.9883, Training Loss = 0.1021, Validation Accuracy = 0.9768, Validation Loss = 0.4315\n",
            "Epoch 1956/2500\n",
            "Epoch 1956: Training Accuracy = 0.8945, Training Loss = 0.7650, Validation Accuracy = 0.8741, Validation Loss = 0.8519\n",
            "Epoch 1957/2500\n",
            "Epoch 1957: Training Accuracy = 0.9863, Training Loss = 0.2188, Validation Accuracy = 0.9736, Validation Loss = 0.3576\n",
            "Epoch 1958/2500\n",
            "Epoch 1958: Training Accuracy = 0.9863, Training Loss = 0.2188, Validation Accuracy = 0.9736, Validation Loss = 0.3576\n",
            "Epoch 1959/2500\n",
            "Epoch 1959: Training Accuracy = 0.9863, Training Loss = 0.1320, Validation Accuracy = 0.9880, Validation Loss = 0.2210\n",
            "Epoch 1960/2500\n",
            "Epoch 1960: Training Accuracy = 0.9863, Training Loss = 0.1320, Validation Accuracy = 0.9880, Validation Loss = 0.2210\n",
            "Epoch 1961/2500\n",
            "Epoch 1961: Training Accuracy = 0.9922, Training Loss = 0.0801, Validation Accuracy = 0.9900, Validation Loss = 0.1539\n",
            "Epoch 1962/2500\n",
            "Epoch 1962: Training Accuracy = 0.9961, Training Loss = 0.0468, Validation Accuracy = 0.9901, Validation Loss = 0.1282\n",
            "Epoch 1963/2500\n",
            "Epoch 1963: Training Accuracy = 0.9961, Training Loss = 0.0468, Validation Accuracy = 0.9901, Validation Loss = 0.1282\n",
            "Epoch 1964/2500\n",
            "Epoch 1964: Training Accuracy = 0.9902, Training Loss = 0.0607, Validation Accuracy = 0.9901, Validation Loss = 0.1203\n",
            "Epoch 1965/2500\n",
            "Epoch 1965: Training Accuracy = 0.9902, Training Loss = 0.0607, Validation Accuracy = 0.9901, Validation Loss = 0.1203\n",
            "Epoch 1966/2500\n",
            "Epoch 1966: Training Accuracy = 0.9805, Training Loss = 0.1006, Validation Accuracy = 0.9901, Validation Loss = 0.1184\n",
            "Epoch 1967/2500\n",
            "Epoch 1967: Training Accuracy = 0.9941, Training Loss = 0.0446, Validation Accuracy = 0.9901, Validation Loss = 0.1154\n",
            "Epoch 1968/2500\n",
            "Epoch 1968: Training Accuracy = 0.9941, Training Loss = 0.0446, Validation Accuracy = 0.9901, Validation Loss = 0.1154\n",
            "Epoch 1969/2500\n",
            "Epoch 1969: Training Accuracy = 0.9922, Training Loss = 0.0528, Validation Accuracy = 0.9901, Validation Loss = 0.1139\n",
            "Epoch 1970/2500\n",
            "Epoch 1970: Training Accuracy = 0.9922, Training Loss = 0.0528, Validation Accuracy = 0.9901, Validation Loss = 0.1139\n",
            "Epoch 1971/2500\n",
            "Epoch 1971: Training Accuracy = 0.9902, Training Loss = 0.0568, Validation Accuracy = 0.9901, Validation Loss = 0.1137\n",
            "Epoch 1972/2500\n",
            "Epoch 1972: Training Accuracy = 0.9922, Training Loss = 0.0537, Validation Accuracy = 0.9901, Validation Loss = 0.1173\n",
            "Epoch 1973/2500\n",
            "Epoch 1973: Training Accuracy = 0.9922, Training Loss = 0.0537, Validation Accuracy = 0.9901, Validation Loss = 0.1173\n",
            "Epoch 1974/2500\n",
            "Epoch 1974: Training Accuracy = 0.9902, Training Loss = 0.0580, Validation Accuracy = 0.9901, Validation Loss = 0.1130\n",
            "Epoch 1975/2500\n",
            "Epoch 1975: Training Accuracy = 0.9902, Training Loss = 0.0580, Validation Accuracy = 0.9901, Validation Loss = 0.1130\n",
            "Epoch 1976/2500\n",
            "Epoch 1976: Training Accuracy = 0.9941, Training Loss = 0.0473, Validation Accuracy = 0.9901, Validation Loss = 0.1136\n",
            "Epoch 1977/2500\n",
            "Epoch 1977: Training Accuracy = 0.9902, Training Loss = 0.0596, Validation Accuracy = 0.9901, Validation Loss = 0.1114\n",
            "Epoch 1978/2500\n",
            "Epoch 1978: Training Accuracy = 0.9902, Training Loss = 0.0596, Validation Accuracy = 0.9901, Validation Loss = 0.1114\n",
            "Epoch 1979/2500\n",
            "Epoch 1979: Training Accuracy = 0.9863, Training Loss = 0.0726, Validation Accuracy = 0.9901, Validation Loss = 0.1117\n",
            "Epoch 1980/2500\n",
            "Epoch 1980: Training Accuracy = 0.9863, Training Loss = 0.0726, Validation Accuracy = 0.9901, Validation Loss = 0.1117\n",
            "Epoch 1981/2500\n",
            "Epoch 1981: Training Accuracy = 0.9922, Training Loss = 0.0485, Validation Accuracy = 0.9901, Validation Loss = 0.1127\n",
            "Epoch 1982/2500\n",
            "Epoch 1982: Training Accuracy = 0.9922, Training Loss = 0.0544, Validation Accuracy = 0.9901, Validation Loss = 0.1244\n",
            "Epoch 1983/2500\n",
            "Epoch 1983: Training Accuracy = 0.9922, Training Loss = 0.0544, Validation Accuracy = 0.9901, Validation Loss = 0.1244\n",
            "Epoch 1984/2500\n",
            "Epoch 1984: Training Accuracy = 0.9844, Training Loss = 0.0821, Validation Accuracy = 0.9901, Validation Loss = 0.1306\n",
            "Epoch 1985/2500\n",
            "Epoch 1985: Training Accuracy = 0.9844, Training Loss = 0.0821, Validation Accuracy = 0.9901, Validation Loss = 0.1306\n",
            "Epoch 1986/2500\n",
            "Epoch 1986: Training Accuracy = 0.9824, Training Loss = 0.0926, Validation Accuracy = 0.9900, Validation Loss = 0.1378\n",
            "Epoch 1987/2500\n",
            "Epoch 1987: Training Accuracy = 0.9844, Training Loss = 0.0936, Validation Accuracy = 0.9900, Validation Loss = 0.1537\n",
            "Epoch 1988/2500\n",
            "Epoch 1988: Training Accuracy = 0.9844, Training Loss = 0.0936, Validation Accuracy = 0.9900, Validation Loss = 0.1537\n",
            "Epoch 1989/2500\n",
            "Epoch 1989: Training Accuracy = 0.9922, Training Loss = 0.0619, Validation Accuracy = 0.9900, Validation Loss = 0.1527\n",
            "Epoch 1990/2500\n",
            "Epoch 1990: Training Accuracy = 0.9922, Training Loss = 0.0619, Validation Accuracy = 0.9900, Validation Loss = 0.1527\n",
            "Epoch 1991/2500\n",
            "Epoch 1991: Training Accuracy = 0.9922, Training Loss = 0.0555, Validation Accuracy = 0.9897, Validation Loss = 0.1231\n",
            "Epoch 1992/2500\n",
            "Epoch 1992: Training Accuracy = 0.9824, Training Loss = 0.0895, Validation Accuracy = 0.9901, Validation Loss = 0.1180\n",
            "Epoch 1993/2500\n",
            "Epoch 1993: Training Accuracy = 0.9824, Training Loss = 0.0895, Validation Accuracy = 0.9901, Validation Loss = 0.1180\n",
            "Epoch 1994/2500\n",
            "Epoch 1994: Training Accuracy = 0.9863, Training Loss = 0.0680, Validation Accuracy = 0.9901, Validation Loss = 0.1190\n",
            "Epoch 1995/2500\n",
            "Epoch 1995: Training Accuracy = 0.9863, Training Loss = 0.0680, Validation Accuracy = 0.9901, Validation Loss = 0.1190\n",
            "Epoch 1996/2500\n",
            "Epoch 1996: Training Accuracy = 0.9941, Training Loss = 0.0454, Validation Accuracy = 0.9901, Validation Loss = 0.1143\n",
            "Epoch 1997/2500\n",
            "Epoch 1997: Training Accuracy = 0.9902, Training Loss = 0.0558, Validation Accuracy = 0.9901, Validation Loss = 0.1130\n",
            "Epoch 1998/2500\n",
            "Epoch 1998: Training Accuracy = 0.9902, Training Loss = 0.0558, Validation Accuracy = 0.9901, Validation Loss = 0.1130\n",
            "Epoch 1999/2500\n",
            "Epoch 1999: Training Accuracy = 0.9824, Training Loss = 0.0902, Validation Accuracy = 0.9901, Validation Loss = 0.1122\n",
            "Epoch 2000/2500\n",
            "Epoch 2000: Training Accuracy = 0.9824, Training Loss = 0.0902, Validation Accuracy = 0.9901, Validation Loss = 0.1122\n",
            "Epoch 2001/2500\n",
            "Epoch 2001: Training Accuracy = 0.9863, Training Loss = 0.0761, Validation Accuracy = 0.9900, Validation Loss = 0.1163\n",
            "Epoch 2002/2500\n",
            "Epoch 2002: Training Accuracy = 0.5488, Training Loss = 2.2011, Validation Accuracy = 0.4084, Validation Loss = 2.4866\n",
            "Epoch 2003/2500\n",
            "Epoch 2003: Training Accuracy = 0.5488, Training Loss = 2.2011, Validation Accuracy = 0.4084, Validation Loss = 2.4866\n",
            "Epoch 2004/2500\n",
            "Epoch 2004: Training Accuracy = 0.9727, Training Loss = 0.3639, Validation Accuracy = 0.9186, Validation Loss = 0.6075\n",
            "Epoch 2005/2500\n",
            "Epoch 2005: Training Accuracy = 0.9727, Training Loss = 0.3639, Validation Accuracy = 0.9186, Validation Loss = 0.6075\n",
            "Epoch 2006/2500\n",
            "Epoch 2006: Training Accuracy = 0.9844, Training Loss = 0.2027, Validation Accuracy = 0.9828, Validation Loss = 0.2844\n",
            "Epoch 2007/2500\n",
            "Epoch 2007: Training Accuracy = 0.9883, Training Loss = 0.1164, Validation Accuracy = 0.9886, Validation Loss = 0.1850\n",
            "Epoch 2008/2500\n",
            "Epoch 2008: Training Accuracy = 0.9883, Training Loss = 0.1164, Validation Accuracy = 0.9886, Validation Loss = 0.1850\n",
            "Epoch 2009/2500\n",
            "Epoch 2009: Training Accuracy = 0.9824, Training Loss = 0.1033, Validation Accuracy = 0.9898, Validation Loss = 0.1431\n",
            "Epoch 2010/2500\n",
            "Epoch 2010: Training Accuracy = 0.9824, Training Loss = 0.1033, Validation Accuracy = 0.9898, Validation Loss = 0.1431\n",
            "Epoch 2011/2500\n",
            "Epoch 2011: Training Accuracy = 0.9902, Training Loss = 0.0654, Validation Accuracy = 0.9900, Validation Loss = 0.1230\n",
            "Epoch 2012/2500\n",
            "Epoch 2012: Training Accuracy = 0.9902, Training Loss = 0.0608, Validation Accuracy = 0.9900, Validation Loss = 0.1149\n",
            "Epoch 2013/2500\n",
            "Epoch 2013: Training Accuracy = 0.9902, Training Loss = 0.0608, Validation Accuracy = 0.9900, Validation Loss = 0.1149\n",
            "Epoch 2014/2500\n",
            "Epoch 2014: Training Accuracy = 0.9863, Training Loss = 0.0717, Validation Accuracy = 0.9901, Validation Loss = 0.1100\n",
            "Epoch 2015/2500\n",
            "Epoch 2015: Training Accuracy = 0.9863, Training Loss = 0.0717, Validation Accuracy = 0.9901, Validation Loss = 0.1100\n",
            "Epoch 2016/2500\n",
            "Epoch 2016: Training Accuracy = 0.9902, Training Loss = 0.0628, Validation Accuracy = 0.9901, Validation Loss = 0.1085\n",
            "Epoch 2017/2500\n",
            "Epoch 2017: Training Accuracy = 0.9902, Training Loss = 0.0567, Validation Accuracy = 0.9901, Validation Loss = 0.1078\n",
            "Epoch 2018/2500\n",
            "Epoch 2018: Training Accuracy = 0.9902, Training Loss = 0.0567, Validation Accuracy = 0.9901, Validation Loss = 0.1078\n",
            "Epoch 2019/2500\n",
            "Epoch 2019: Training Accuracy = 0.9863, Training Loss = 0.0713, Validation Accuracy = 0.9901, Validation Loss = 0.1078\n",
            "Epoch 2020/2500\n",
            "Epoch 2020: Training Accuracy = 0.9863, Training Loss = 0.0713, Validation Accuracy = 0.9901, Validation Loss = 0.1078\n",
            "Epoch 2021/2500\n",
            "Epoch 2021: Training Accuracy = 0.9941, Training Loss = 0.0409, Validation Accuracy = 0.9901, Validation Loss = 0.1063\n",
            "Epoch 2022/2500\n",
            "Epoch 2022: Training Accuracy = 0.9961, Training Loss = 0.0349, Validation Accuracy = 0.9901, Validation Loss = 0.1071\n",
            "Epoch 2023/2500\n",
            "Epoch 2023: Training Accuracy = 0.9961, Training Loss = 0.0349, Validation Accuracy = 0.9901, Validation Loss = 0.1071\n",
            "Epoch 2024/2500\n",
            "Epoch 2024: Training Accuracy = 0.9805, Training Loss = 0.0884, Validation Accuracy = 0.9901, Validation Loss = 0.1077\n",
            "Epoch 2025/2500\n",
            "Epoch 2025: Training Accuracy = 0.9805, Training Loss = 0.0884, Validation Accuracy = 0.9901, Validation Loss = 0.1077\n",
            "Epoch 2026/2500\n",
            "Epoch 2026: Training Accuracy = 0.9941, Training Loss = 0.0427, Validation Accuracy = 0.9901, Validation Loss = 0.1064\n",
            "Epoch 2027/2500\n",
            "Epoch 2027: Training Accuracy = 0.9902, Training Loss = 0.0582, Validation Accuracy = 0.9901, Validation Loss = 0.1048\n",
            "Epoch 2028/2500\n",
            "Epoch 2028: Training Accuracy = 0.9902, Training Loss = 0.0582, Validation Accuracy = 0.9901, Validation Loss = 0.1048\n",
            "Epoch 2029/2500\n",
            "Epoch 2029: Training Accuracy = 0.9883, Training Loss = 0.0637, Validation Accuracy = 0.9901, Validation Loss = 0.1084\n",
            "Epoch 2030/2500\n",
            "Epoch 2030: Training Accuracy = 0.9883, Training Loss = 0.0637, Validation Accuracy = 0.9901, Validation Loss = 0.1084\n",
            "Epoch 2031/2500\n",
            "Epoch 2031: Training Accuracy = 0.9863, Training Loss = 0.0704, Validation Accuracy = 0.9901, Validation Loss = 0.1083\n",
            "Epoch 2032/2500\n",
            "Epoch 2032: Training Accuracy = 0.9883, Training Loss = 0.0649, Validation Accuracy = 0.9901, Validation Loss = 0.1073\n",
            "Epoch 2033/2500\n",
            "Epoch 2033: Training Accuracy = 0.9883, Training Loss = 0.0649, Validation Accuracy = 0.9901, Validation Loss = 0.1073\n",
            "Epoch 2034/2500\n",
            "Epoch 2034: Training Accuracy = 0.9902, Training Loss = 0.0561, Validation Accuracy = 0.9901, Validation Loss = 0.1042\n",
            "Epoch 2035/2500\n",
            "Epoch 2035: Training Accuracy = 0.9902, Training Loss = 0.0561, Validation Accuracy = 0.9901, Validation Loss = 0.1042\n",
            "Epoch 2036/2500\n",
            "Epoch 2036: Training Accuracy = 0.9922, Training Loss = 0.0508, Validation Accuracy = 0.9901, Validation Loss = 0.1071\n",
            "Epoch 2037/2500\n",
            "Epoch 2037: Training Accuracy = 0.9902, Training Loss = 0.0607, Validation Accuracy = 0.9900, Validation Loss = 0.1158\n",
            "Epoch 2038/2500\n",
            "Epoch 2038: Training Accuracy = 0.9902, Training Loss = 0.0607, Validation Accuracy = 0.9900, Validation Loss = 0.1158\n",
            "Epoch 2039/2500\n",
            "Epoch 2039: Training Accuracy = 0.2715, Training Loss = 3.0487, Validation Accuracy = 0.4041, Validation Loss = 2.5616\n",
            "Epoch 2040/2500\n",
            "Epoch 2040: Training Accuracy = 0.2715, Training Loss = 3.0487, Validation Accuracy = 0.4041, Validation Loss = 2.5616\n",
            "Epoch 2041/2500\n",
            "Epoch 2041: Training Accuracy = 0.9102, Training Loss = 0.6353, Validation Accuracy = 0.8667, Validation Loss = 0.8450\n",
            "Epoch 2042/2500\n",
            "Epoch 2042: Training Accuracy = 0.9746, Training Loss = 0.2658, Validation Accuracy = 0.9707, Validation Loss = 0.3715\n",
            "Epoch 2043/2500\n",
            "Epoch 2043: Training Accuracy = 0.9746, Training Loss = 0.2658, Validation Accuracy = 0.9707, Validation Loss = 0.3715\n",
            "Epoch 2044/2500\n",
            "Epoch 2044: Training Accuracy = 0.9922, Training Loss = 0.1211, Validation Accuracy = 0.9871, Validation Loss = 0.2159\n",
            "Epoch 2045/2500\n",
            "Epoch 2045: Training Accuracy = 0.9922, Training Loss = 0.1211, Validation Accuracy = 0.9871, Validation Loss = 0.2159\n",
            "Epoch 2046/2500\n",
            "Epoch 2046: Training Accuracy = 0.9863, Training Loss = 0.0979, Validation Accuracy = 0.9901, Validation Loss = 0.1528\n",
            "Epoch 2047/2500\n",
            "Epoch 2047: Training Accuracy = 0.9883, Training Loss = 0.0784, Validation Accuracy = 0.9901, Validation Loss = 0.1310\n",
            "Epoch 2048/2500\n",
            "Epoch 2048: Training Accuracy = 0.9883, Training Loss = 0.0784, Validation Accuracy = 0.9901, Validation Loss = 0.1310\n",
            "Epoch 2049/2500\n",
            "Epoch 2049: Training Accuracy = 0.9824, Training Loss = 0.0954, Validation Accuracy = 0.9901, Validation Loss = 0.1214\n",
            "Epoch 2050/2500\n",
            "Epoch 2050: Training Accuracy = 0.9824, Training Loss = 0.0954, Validation Accuracy = 0.9901, Validation Loss = 0.1214\n",
            "Epoch 2051/2500\n",
            "Epoch 2051: Training Accuracy = 0.9922, Training Loss = 0.0562, Validation Accuracy = 0.9901, Validation Loss = 0.1162\n",
            "Epoch 2052/2500\n",
            "Epoch 2052: Training Accuracy = 0.9902, Training Loss = 0.0644, Validation Accuracy = 0.9901, Validation Loss = 0.1129\n",
            "Epoch 2053/2500\n",
            "Epoch 2053: Training Accuracy = 0.9902, Training Loss = 0.0644, Validation Accuracy = 0.9901, Validation Loss = 0.1129\n",
            "Epoch 2054/2500\n",
            "Epoch 2054: Training Accuracy = 0.9883, Training Loss = 0.0705, Validation Accuracy = 0.9901, Validation Loss = 0.1129\n",
            "Epoch 2055/2500\n",
            "Epoch 2055: Training Accuracy = 0.9883, Training Loss = 0.0705, Validation Accuracy = 0.9901, Validation Loss = 0.1129\n",
            "Epoch 2056/2500\n",
            "Epoch 2056: Training Accuracy = 0.9922, Training Loss = 0.0524, Validation Accuracy = 0.9901, Validation Loss = 0.1122\n",
            "Epoch 2057/2500\n",
            "Epoch 2057: Training Accuracy = 0.9844, Training Loss = 0.0829, Validation Accuracy = 0.9901, Validation Loss = 0.1105\n",
            "Epoch 2058/2500\n",
            "Epoch 2058: Training Accuracy = 0.9844, Training Loss = 0.0829, Validation Accuracy = 0.9901, Validation Loss = 0.1105\n",
            "Epoch 2059/2500\n",
            "Epoch 2059: Training Accuracy = 0.9844, Training Loss = 0.0823, Validation Accuracy = 0.9901, Validation Loss = 0.1088\n",
            "Epoch 2060/2500\n",
            "Epoch 2060: Training Accuracy = 0.9844, Training Loss = 0.0823, Validation Accuracy = 0.9901, Validation Loss = 0.1088\n",
            "Epoch 2061/2500\n",
            "Epoch 2061: Training Accuracy = 0.9883, Training Loss = 0.0724, Validation Accuracy = 0.9901, Validation Loss = 0.1109\n",
            "Epoch 2062/2500\n",
            "Epoch 2062: Training Accuracy = 0.9863, Training Loss = 0.0807, Validation Accuracy = 0.9901, Validation Loss = 0.1086\n",
            "Epoch 2063/2500\n",
            "Epoch 2063: Training Accuracy = 0.9863, Training Loss = 0.0807, Validation Accuracy = 0.9901, Validation Loss = 0.1086\n",
            "Epoch 2064/2500\n",
            "Epoch 2064: Training Accuracy = 0.9922, Training Loss = 0.0527, Validation Accuracy = 0.9901, Validation Loss = 0.1067\n",
            "Epoch 2065/2500\n",
            "Epoch 2065: Training Accuracy = 0.9922, Training Loss = 0.0527, Validation Accuracy = 0.9901, Validation Loss = 0.1067\n",
            "Epoch 2066/2500\n",
            "Epoch 2066: Training Accuracy = 0.9922, Training Loss = 0.0525, Validation Accuracy = 0.9901, Validation Loss = 0.1069\n",
            "Epoch 2067/2500\n",
            "Epoch 2067: Training Accuracy = 0.9805, Training Loss = 0.0951, Validation Accuracy = 0.9901, Validation Loss = 0.1050\n",
            "Epoch 2068/2500\n",
            "Epoch 2068: Training Accuracy = 0.9805, Training Loss = 0.0951, Validation Accuracy = 0.9901, Validation Loss = 0.1050\n",
            "Epoch 2069/2500\n",
            "Epoch 2069: Training Accuracy = 0.9863, Training Loss = 0.0748, Validation Accuracy = 0.9901, Validation Loss = 0.1073\n",
            "Epoch 2070/2500\n",
            "Epoch 2070: Training Accuracy = 0.9863, Training Loss = 0.0748, Validation Accuracy = 0.9901, Validation Loss = 0.1073\n",
            "Epoch 2071/2500\n",
            "Epoch 2071: Training Accuracy = 0.9961, Training Loss = 0.0404, Validation Accuracy = 0.9901, Validation Loss = 0.1077\n",
            "Epoch 2072/2500\n",
            "Epoch 2072: Training Accuracy = 0.9824, Training Loss = 0.0977, Validation Accuracy = 0.9901, Validation Loss = 0.1229\n",
            "Epoch 2073/2500\n",
            "Epoch 2073: Training Accuracy = 0.9824, Training Loss = 0.0977, Validation Accuracy = 0.9901, Validation Loss = 0.1229\n",
            "Epoch 2074/2500\n",
            "Epoch 2074: Training Accuracy = 0.2480, Training Loss = 3.0437, Validation Accuracy = 0.3218, Validation Loss = 2.8616\n",
            "Epoch 2075/2500\n",
            "Epoch 2075: Training Accuracy = 0.2480, Training Loss = 3.0437, Validation Accuracy = 0.3218, Validation Loss = 2.8616\n",
            "Epoch 2076/2500\n",
            "Epoch 2076: Training Accuracy = 0.9102, Training Loss = 0.6409, Validation Accuracy = 0.8693, Validation Loss = 0.8238\n",
            "Epoch 2077/2500\n",
            "Epoch 2077: Training Accuracy = 0.9883, Training Loss = 0.2646, Validation Accuracy = 0.9757, Validation Loss = 0.3771\n",
            "Epoch 2078/2500\n",
            "Epoch 2078: Training Accuracy = 0.9883, Training Loss = 0.2646, Validation Accuracy = 0.9757, Validation Loss = 0.3771\n",
            "Epoch 2079/2500\n",
            "Epoch 2079: Training Accuracy = 0.9961, Training Loss = 0.1228, Validation Accuracy = 0.9880, Validation Loss = 0.2124\n",
            "Epoch 2080/2500\n",
            "Epoch 2080: Training Accuracy = 0.9961, Training Loss = 0.1228, Validation Accuracy = 0.9880, Validation Loss = 0.2124\n",
            "Epoch 2081/2500\n",
            "Epoch 2081: Training Accuracy = 0.9902, Training Loss = 0.0977, Validation Accuracy = 0.9900, Validation Loss = 0.1549\n",
            "Epoch 2082/2500\n",
            "Epoch 2082: Training Accuracy = 0.9883, Training Loss = 0.0818, Validation Accuracy = 0.9901, Validation Loss = 0.1291\n",
            "Epoch 2083/2500\n",
            "Epoch 2083: Training Accuracy = 0.9883, Training Loss = 0.0818, Validation Accuracy = 0.9901, Validation Loss = 0.1291\n",
            "Epoch 2084/2500\n",
            "Epoch 2084: Training Accuracy = 0.9902, Training Loss = 0.0672, Validation Accuracy = 0.9901, Validation Loss = 0.1181\n",
            "Epoch 2085/2500\n",
            "Epoch 2085: Training Accuracy = 0.9902, Training Loss = 0.0672, Validation Accuracy = 0.9901, Validation Loss = 0.1181\n",
            "Epoch 2086/2500\n",
            "Epoch 2086: Training Accuracy = 0.9941, Training Loss = 0.0529, Validation Accuracy = 0.9901, Validation Loss = 0.1149\n",
            "Epoch 2087/2500\n",
            "Epoch 2087: Training Accuracy = 0.9902, Training Loss = 0.0642, Validation Accuracy = 0.9901, Validation Loss = 0.1108\n",
            "Epoch 2088/2500\n",
            "Epoch 2088: Training Accuracy = 0.9902, Training Loss = 0.0642, Validation Accuracy = 0.9901, Validation Loss = 0.1108\n",
            "Epoch 2089/2500\n",
            "Epoch 2089: Training Accuracy = 0.9961, Training Loss = 0.0489, Validation Accuracy = 0.9901, Validation Loss = 0.1100\n",
            "Epoch 2090/2500\n",
            "Epoch 2090: Training Accuracy = 0.9961, Training Loss = 0.0489, Validation Accuracy = 0.9901, Validation Loss = 0.1100\n",
            "Epoch 2091/2500\n",
            "Epoch 2091: Training Accuracy = 0.9922, Training Loss = 0.0574, Validation Accuracy = 0.9901, Validation Loss = 0.1084\n",
            "Epoch 2092/2500\n",
            "Epoch 2092: Training Accuracy = 0.9922, Training Loss = 0.0580, Validation Accuracy = 0.9901, Validation Loss = 0.1108\n",
            "Epoch 2093/2500\n",
            "Epoch 2093: Training Accuracy = 0.9922, Training Loss = 0.0580, Validation Accuracy = 0.9901, Validation Loss = 0.1108\n",
            "Epoch 2094/2500\n",
            "Epoch 2094: Training Accuracy = 0.9980, Training Loss = 0.0357, Validation Accuracy = 0.9901, Validation Loss = 0.1091\n",
            "Epoch 2095/2500\n",
            "Epoch 2095: Training Accuracy = 0.9980, Training Loss = 0.0357, Validation Accuracy = 0.9901, Validation Loss = 0.1091\n",
            "Epoch 2096/2500\n",
            "Epoch 2096: Training Accuracy = 0.9863, Training Loss = 0.0797, Validation Accuracy = 0.9901, Validation Loss = 0.1089\n",
            "Epoch 2097/2500\n",
            "Epoch 2097: Training Accuracy = 0.9941, Training Loss = 0.0493, Validation Accuracy = 0.9901, Validation Loss = 0.1103\n",
            "Epoch 2098/2500\n",
            "Epoch 2098: Training Accuracy = 0.9941, Training Loss = 0.0493, Validation Accuracy = 0.9901, Validation Loss = 0.1103\n",
            "Epoch 2099/2500\n",
            "Epoch 2099: Training Accuracy = 0.9863, Training Loss = 0.0767, Validation Accuracy = 0.9901, Validation Loss = 0.1059\n",
            "Epoch 2100/2500\n",
            "Epoch 2100: Training Accuracy = 0.9863, Training Loss = 0.0767, Validation Accuracy = 0.9901, Validation Loss = 0.1059\n",
            "Epoch 2101/2500\n",
            "Epoch 2101: Training Accuracy = 0.9863, Training Loss = 0.0790, Validation Accuracy = 0.9901, Validation Loss = 0.1082\n",
            "Epoch 2102/2500\n",
            "Epoch 2102: Training Accuracy = 0.9844, Training Loss = 0.0837, Validation Accuracy = 0.9901, Validation Loss = 0.1127\n",
            "Epoch 2103/2500\n",
            "Epoch 2103: Training Accuracy = 0.9844, Training Loss = 0.0837, Validation Accuracy = 0.9901, Validation Loss = 0.1127\n",
            "Epoch 2104/2500\n",
            "Epoch 2104: Training Accuracy = 0.9805, Training Loss = 0.0982, Validation Accuracy = 0.9901, Validation Loss = 0.1084\n",
            "Epoch 2105/2500\n",
            "Epoch 2105: Training Accuracy = 0.9805, Training Loss = 0.0982, Validation Accuracy = 0.9901, Validation Loss = 0.1084\n",
            "Epoch 2106/2500\n",
            "Epoch 2106: Training Accuracy = 0.9863, Training Loss = 0.0767, Validation Accuracy = 0.9901, Validation Loss = 0.1087\n",
            "Epoch 2107/2500\n",
            "Epoch 2107: Training Accuracy = 0.9863, Training Loss = 0.0826, Validation Accuracy = 0.9901, Validation Loss = 0.1215\n",
            "Epoch 2108/2500\n",
            "Epoch 2108: Training Accuracy = 0.9863, Training Loss = 0.0826, Validation Accuracy = 0.9901, Validation Loss = 0.1215\n",
            "Epoch 2109/2500\n",
            "Epoch 2109: Training Accuracy = 0.7676, Training Loss = 1.1139, Validation Accuracy = 0.7330, Validation Loss = 1.2132\n",
            "Epoch 2110/2500\n",
            "Epoch 2110: Training Accuracy = 0.7676, Training Loss = 1.1139, Validation Accuracy = 0.7330, Validation Loss = 1.2132\n",
            "Epoch 2111/2500\n",
            "Epoch 2111: Training Accuracy = 0.9688, Training Loss = 0.3584, Validation Accuracy = 0.9387, Validation Loss = 0.5181\n",
            "Epoch 2112/2500\n",
            "Epoch 2112: Training Accuracy = 0.9805, Training Loss = 0.2260, Validation Accuracy = 0.9801, Validation Loss = 0.2818\n",
            "Epoch 2113/2500\n",
            "Epoch 2113: Training Accuracy = 0.9805, Training Loss = 0.2260, Validation Accuracy = 0.9801, Validation Loss = 0.2818\n",
            "Epoch 2114/2500\n",
            "Epoch 2114: Training Accuracy = 0.9863, Training Loss = 0.1222, Validation Accuracy = 0.9898, Validation Loss = 0.1747\n",
            "Epoch 2115/2500\n",
            "Epoch 2115: Training Accuracy = 0.9863, Training Loss = 0.1222, Validation Accuracy = 0.9898, Validation Loss = 0.1747\n",
            "Epoch 2116/2500\n",
            "Epoch 2116: Training Accuracy = 0.9902, Training Loss = 0.0807, Validation Accuracy = 0.9901, Validation Loss = 0.1353\n",
            "Epoch 2117/2500\n",
            "Epoch 2117: Training Accuracy = 0.9844, Training Loss = 0.0925, Validation Accuracy = 0.9901, Validation Loss = 0.1207\n",
            "Epoch 2118/2500\n",
            "Epoch 2118: Training Accuracy = 0.9844, Training Loss = 0.0925, Validation Accuracy = 0.9901, Validation Loss = 0.1207\n",
            "Epoch 2119/2500\n",
            "Epoch 2119: Training Accuracy = 0.9883, Training Loss = 0.0743, Validation Accuracy = 0.9901, Validation Loss = 0.1149\n",
            "Epoch 2120/2500\n",
            "Epoch 2120: Training Accuracy = 0.9883, Training Loss = 0.0743, Validation Accuracy = 0.9901, Validation Loss = 0.1149\n",
            "Epoch 2121/2500\n",
            "Epoch 2121: Training Accuracy = 0.9941, Training Loss = 0.0504, Validation Accuracy = 0.9901, Validation Loss = 0.1115\n",
            "Epoch 2122/2500\n",
            "Epoch 2122: Training Accuracy = 0.9844, Training Loss = 0.0860, Validation Accuracy = 0.9901, Validation Loss = 0.1113\n",
            "Epoch 2123/2500\n",
            "Epoch 2123: Training Accuracy = 0.9844, Training Loss = 0.0860, Validation Accuracy = 0.9901, Validation Loss = 0.1113\n",
            "Epoch 2124/2500\n",
            "Epoch 2124: Training Accuracy = 0.9883, Training Loss = 0.0710, Validation Accuracy = 0.9901, Validation Loss = 0.1103\n",
            "Epoch 2125/2500\n",
            "Epoch 2125: Training Accuracy = 0.9883, Training Loss = 0.0710, Validation Accuracy = 0.9901, Validation Loss = 0.1103\n",
            "Epoch 2126/2500\n",
            "Epoch 2126: Training Accuracy = 0.9922, Training Loss = 0.0643, Validation Accuracy = 0.9901, Validation Loss = 0.1095\n",
            "Epoch 2127/2500\n",
            "Epoch 2127: Training Accuracy = 0.9961, Training Loss = 0.0423, Validation Accuracy = 0.9901, Validation Loss = 0.1092\n",
            "Epoch 2128/2500\n",
            "Epoch 2128: Training Accuracy = 0.9961, Training Loss = 0.0423, Validation Accuracy = 0.9901, Validation Loss = 0.1092\n",
            "Epoch 2129/2500\n",
            "Epoch 2129: Training Accuracy = 0.9941, Training Loss = 0.0506, Validation Accuracy = 0.9901, Validation Loss = 0.1094\n",
            "Epoch 2130/2500\n",
            "Epoch 2130: Training Accuracy = 0.9941, Training Loss = 0.0506, Validation Accuracy = 0.9901, Validation Loss = 0.1094\n",
            "Epoch 2131/2500\n",
            "Epoch 2131: Training Accuracy = 0.9805, Training Loss = 0.0965, Validation Accuracy = 0.9901, Validation Loss = 0.1083\n",
            "Epoch 2132/2500\n",
            "Epoch 2132: Training Accuracy = 0.9844, Training Loss = 0.0853, Validation Accuracy = 0.9901, Validation Loss = 0.1090\n",
            "Epoch 2133/2500\n",
            "Epoch 2133: Training Accuracy = 0.9844, Training Loss = 0.0853, Validation Accuracy = 0.9901, Validation Loss = 0.1090\n",
            "Epoch 2134/2500\n",
            "Epoch 2134: Training Accuracy = 0.9902, Training Loss = 0.0638, Validation Accuracy = 0.9901, Validation Loss = 0.1080\n",
            "Epoch 2135/2500\n",
            "Epoch 2135: Training Accuracy = 0.9902, Training Loss = 0.0638, Validation Accuracy = 0.9901, Validation Loss = 0.1080\n",
            "Epoch 2136/2500\n",
            "Epoch 2136: Training Accuracy = 0.9922, Training Loss = 0.0563, Validation Accuracy = 0.9901, Validation Loss = 0.1093\n",
            "Epoch 2137/2500\n",
            "Epoch 2137: Training Accuracy = 0.9922, Training Loss = 0.0576, Validation Accuracy = 0.9901, Validation Loss = 0.1076\n",
            "Epoch 2138/2500\n",
            "Epoch 2138: Training Accuracy = 0.9922, Training Loss = 0.0576, Validation Accuracy = 0.9901, Validation Loss = 0.1076\n",
            "Epoch 2139/2500\n",
            "Epoch 2139: Training Accuracy = 0.9922, Training Loss = 0.0655, Validation Accuracy = 0.9901, Validation Loss = 0.1149\n",
            "Epoch 2140/2500\n",
            "Epoch 2140: Training Accuracy = 0.9922, Training Loss = 0.0655, Validation Accuracy = 0.9901, Validation Loss = 0.1149\n",
            "Epoch 2141/2500\n",
            "Epoch 2141: Training Accuracy = 0.9863, Training Loss = 0.0825, Validation Accuracy = 0.9901, Validation Loss = 0.1178\n",
            "Epoch 2142/2500\n",
            "Epoch 2142: Training Accuracy = 0.9961, Training Loss = 0.0553, Validation Accuracy = 0.9901, Validation Loss = 0.1362\n",
            "Epoch 2143/2500\n",
            "Epoch 2143: Training Accuracy = 0.9961, Training Loss = 0.0553, Validation Accuracy = 0.9901, Validation Loss = 0.1362\n",
            "Epoch 2144/2500\n",
            "Epoch 2144: Training Accuracy = 0.8105, Training Loss = 1.1715, Validation Accuracy = 0.8014, Validation Loss = 1.1493\n",
            "Epoch 2145/2500\n",
            "Epoch 2145: Training Accuracy = 0.8105, Training Loss = 1.1715, Validation Accuracy = 0.8014, Validation Loss = 1.1493\n",
            "Epoch 2146/2500\n",
            "Epoch 2146: Training Accuracy = 0.9824, Training Loss = 0.3182, Validation Accuracy = 0.9584, Validation Loss = 0.5006\n",
            "Epoch 2147/2500\n",
            "Epoch 2147: Training Accuracy = 0.9883, Training Loss = 0.1937, Validation Accuracy = 0.9850, Validation Loss = 0.2617\n",
            "Epoch 2148/2500\n",
            "Epoch 2148: Training Accuracy = 0.9883, Training Loss = 0.1937, Validation Accuracy = 0.9850, Validation Loss = 0.2617\n",
            "Epoch 2149/2500\n",
            "Epoch 2149: Training Accuracy = 0.9922, Training Loss = 0.1004, Validation Accuracy = 0.9900, Validation Loss = 0.1672\n",
            "Epoch 2150/2500\n",
            "Epoch 2150: Training Accuracy = 0.9922, Training Loss = 0.1004, Validation Accuracy = 0.9900, Validation Loss = 0.1672\n",
            "Epoch 2151/2500\n",
            "Epoch 2151: Training Accuracy = 0.9844, Training Loss = 0.1083, Validation Accuracy = 0.9901, Validation Loss = 0.1358\n",
            "Epoch 2152/2500\n",
            "Epoch 2152: Training Accuracy = 0.9922, Training Loss = 0.0663, Validation Accuracy = 0.9901, Validation Loss = 0.1204\n",
            "Epoch 2153/2500\n",
            "Epoch 2153: Training Accuracy = 0.9922, Training Loss = 0.0663, Validation Accuracy = 0.9901, Validation Loss = 0.1204\n",
            "Epoch 2154/2500\n",
            "Epoch 2154: Training Accuracy = 0.9902, Training Loss = 0.0695, Validation Accuracy = 0.9901, Validation Loss = 0.1137\n",
            "Epoch 2155/2500\n",
            "Epoch 2155: Training Accuracy = 0.9902, Training Loss = 0.0695, Validation Accuracy = 0.9901, Validation Loss = 0.1137\n",
            "Epoch 2156/2500\n",
            "Epoch 2156: Training Accuracy = 0.9824, Training Loss = 0.0937, Validation Accuracy = 0.9901, Validation Loss = 0.1109\n",
            "Epoch 2157/2500\n",
            "Epoch 2157: Training Accuracy = 0.9844, Training Loss = 0.0897, Validation Accuracy = 0.9901, Validation Loss = 0.1095\n",
            "Epoch 2158/2500\n",
            "Epoch 2158: Training Accuracy = 0.9844, Training Loss = 0.0897, Validation Accuracy = 0.9901, Validation Loss = 0.1095\n",
            "Epoch 2159/2500\n",
            "Epoch 2159: Training Accuracy = 0.9902, Training Loss = 0.0653, Validation Accuracy = 0.9901, Validation Loss = 0.1081\n",
            "Epoch 2160/2500\n",
            "Epoch 2160: Training Accuracy = 0.9902, Training Loss = 0.0653, Validation Accuracy = 0.9901, Validation Loss = 0.1081\n",
            "Epoch 2161/2500\n",
            "Epoch 2161: Training Accuracy = 0.9863, Training Loss = 0.0761, Validation Accuracy = 0.9901, Validation Loss = 0.1085\n",
            "Epoch 2162/2500\n",
            "Epoch 2162: Training Accuracy = 0.9922, Training Loss = 0.0570, Validation Accuracy = 0.9901, Validation Loss = 0.1076\n",
            "Epoch 2163/2500\n",
            "Epoch 2163: Training Accuracy = 0.9922, Training Loss = 0.0570, Validation Accuracy = 0.9901, Validation Loss = 0.1076\n",
            "Epoch 2164/2500\n",
            "Epoch 2164: Training Accuracy = 0.9922, Training Loss = 0.0580, Validation Accuracy = 0.9901, Validation Loss = 0.1071\n",
            "Epoch 2165/2500\n",
            "Epoch 2165: Training Accuracy = 0.9922, Training Loss = 0.0580, Validation Accuracy = 0.9901, Validation Loss = 0.1071\n",
            "Epoch 2166/2500\n",
            "Epoch 2166: Training Accuracy = 0.9941, Training Loss = 0.0518, Validation Accuracy = 0.9901, Validation Loss = 0.1079\n",
            "Epoch 2167/2500\n",
            "Epoch 2167: Training Accuracy = 0.9941, Training Loss = 0.0505, Validation Accuracy = 0.9901, Validation Loss = 0.1093\n",
            "Epoch 2168/2500\n",
            "Epoch 2168: Training Accuracy = 0.9941, Training Loss = 0.0505, Validation Accuracy = 0.9901, Validation Loss = 0.1093\n",
            "Epoch 2169/2500\n",
            "Epoch 2169: Training Accuracy = 0.9883, Training Loss = 0.0693, Validation Accuracy = 0.9901, Validation Loss = 0.1049\n",
            "Epoch 2170/2500\n",
            "Epoch 2170: Training Accuracy = 0.9883, Training Loss = 0.0693, Validation Accuracy = 0.9901, Validation Loss = 0.1049\n",
            "Epoch 2171/2500\n",
            "Epoch 2171: Training Accuracy = 0.9844, Training Loss = 0.0840, Validation Accuracy = 0.9901, Validation Loss = 0.1051\n",
            "Epoch 2172/2500\n",
            "Epoch 2172: Training Accuracy = 0.9922, Training Loss = 0.0575, Validation Accuracy = 0.9901, Validation Loss = 0.1072\n",
            "Epoch 2173/2500\n",
            "Epoch 2173: Training Accuracy = 0.9922, Training Loss = 0.0575, Validation Accuracy = 0.9901, Validation Loss = 0.1072\n",
            "Epoch 2174/2500\n",
            "Epoch 2174: Training Accuracy = 0.9902, Training Loss = 0.0682, Validation Accuracy = 0.9901, Validation Loss = 0.1138\n",
            "Epoch 2175/2500\n",
            "Epoch 2175: Training Accuracy = 0.9902, Training Loss = 0.0682, Validation Accuracy = 0.9901, Validation Loss = 0.1138\n",
            "Epoch 2176/2500\n",
            "Epoch 2176: Training Accuracy = 0.8027, Training Loss = 1.1246, Validation Accuracy = 0.8678, Validation Loss = 0.9436\n",
            "Epoch 2177/2500\n",
            "Epoch 2177: Training Accuracy = 0.9805, Training Loss = 0.2928, Validation Accuracy = 0.9730, Validation Loss = 0.3885\n",
            "Epoch 2178/2500\n",
            "Epoch 2178: Training Accuracy = 0.9805, Training Loss = 0.2928, Validation Accuracy = 0.9730, Validation Loss = 0.3885\n",
            "Epoch 2179/2500\n",
            "Epoch 2179: Training Accuracy = 0.9902, Training Loss = 0.1515, Validation Accuracy = 0.9891, Validation Loss = 0.2157\n",
            "Epoch 2180/2500\n",
            "Epoch 2180: Training Accuracy = 0.9902, Training Loss = 0.1515, Validation Accuracy = 0.9891, Validation Loss = 0.2157\n",
            "Epoch 2181/2500\n",
            "Epoch 2181: Training Accuracy = 0.9961, Training Loss = 0.0733, Validation Accuracy = 0.9898, Validation Loss = 0.1544\n",
            "Epoch 2182/2500\n",
            "Epoch 2182: Training Accuracy = 0.9805, Training Loss = 0.1177, Validation Accuracy = 0.9901, Validation Loss = 0.1251\n",
            "Epoch 2183/2500\n",
            "Epoch 2183: Training Accuracy = 0.9805, Training Loss = 0.1177, Validation Accuracy = 0.9901, Validation Loss = 0.1251\n",
            "Epoch 2184/2500\n",
            "Epoch 2184: Training Accuracy = 0.9902, Training Loss = 0.0712, Validation Accuracy = 0.9901, Validation Loss = 0.1139\n",
            "Epoch 2185/2500\n",
            "Epoch 2185: Training Accuracy = 0.9902, Training Loss = 0.0712, Validation Accuracy = 0.9901, Validation Loss = 0.1139\n",
            "Epoch 2186/2500\n",
            "Epoch 2186: Training Accuracy = 0.9883, Training Loss = 0.0716, Validation Accuracy = 0.9901, Validation Loss = 0.1086\n",
            "Epoch 2187/2500\n",
            "Epoch 2187: Training Accuracy = 0.9805, Training Loss = 0.1008, Validation Accuracy = 0.9901, Validation Loss = 0.1056\n",
            "Epoch 2188/2500\n",
            "Epoch 2188: Training Accuracy = 0.9805, Training Loss = 0.1008, Validation Accuracy = 0.9901, Validation Loss = 0.1056\n",
            "Epoch 2189/2500\n",
            "Epoch 2189: Training Accuracy = 0.9844, Training Loss = 0.0863, Validation Accuracy = 0.9901, Validation Loss = 0.1061\n",
            "Epoch 2190/2500\n",
            "Epoch 2190: Training Accuracy = 0.9844, Training Loss = 0.0863, Validation Accuracy = 0.9901, Validation Loss = 0.1061\n",
            "Epoch 2191/2500\n",
            "Epoch 2191: Training Accuracy = 0.9785, Training Loss = 0.1060, Validation Accuracy = 0.9901, Validation Loss = 0.1050\n",
            "Epoch 2192/2500\n",
            "Epoch 2192: Training Accuracy = 0.9863, Training Loss = 0.0787, Validation Accuracy = 0.9901, Validation Loss = 0.1048\n",
            "Epoch 2193/2500\n",
            "Epoch 2193: Training Accuracy = 0.9863, Training Loss = 0.0787, Validation Accuracy = 0.9901, Validation Loss = 0.1048\n",
            "Epoch 2194/2500\n",
            "Epoch 2194: Training Accuracy = 0.9863, Training Loss = 0.0783, Validation Accuracy = 0.9901, Validation Loss = 0.1054\n",
            "Epoch 2195/2500\n",
            "Epoch 2195: Training Accuracy = 0.9863, Training Loss = 0.0783, Validation Accuracy = 0.9901, Validation Loss = 0.1054\n",
            "Epoch 2196/2500\n",
            "Epoch 2196: Training Accuracy = 0.9883, Training Loss = 0.0793, Validation Accuracy = 0.9901, Validation Loss = 0.1093\n",
            "Epoch 2197/2500\n",
            "Epoch 2197: Training Accuracy = 0.9902, Training Loss = 0.0623, Validation Accuracy = 0.9901, Validation Loss = 0.1085\n",
            "Epoch 2198/2500\n",
            "Epoch 2198: Training Accuracy = 0.9902, Training Loss = 0.0623, Validation Accuracy = 0.9901, Validation Loss = 0.1085\n",
            "Epoch 2199/2500\n",
            "Epoch 2199: Training Accuracy = 0.9863, Training Loss = 0.0781, Validation Accuracy = 0.9901, Validation Loss = 0.1061\n",
            "Epoch 2200/2500\n",
            "Epoch 2200: Training Accuracy = 0.9863, Training Loss = 0.0781, Validation Accuracy = 0.9901, Validation Loss = 0.1061\n",
            "Epoch 2201/2500\n",
            "Epoch 2201: Training Accuracy = 0.9863, Training Loss = 0.0783, Validation Accuracy = 0.9901, Validation Loss = 0.1057\n",
            "Epoch 2202/2500\n",
            "Epoch 2202: Training Accuracy = 0.9922, Training Loss = 0.0646, Validation Accuracy = 0.9901, Validation Loss = 0.1041\n",
            "Epoch 2203/2500\n",
            "Epoch 2203: Training Accuracy = 0.9922, Training Loss = 0.0646, Validation Accuracy = 0.9901, Validation Loss = 0.1041\n",
            "Epoch 2204/2500\n",
            "Epoch 2204: Training Accuracy = 0.9902, Training Loss = 0.0660, Validation Accuracy = 0.9901, Validation Loss = 0.1138\n",
            "Epoch 2205/2500\n",
            "Epoch 2205: Training Accuracy = 0.9902, Training Loss = 0.0660, Validation Accuracy = 0.9901, Validation Loss = 0.1138\n",
            "Epoch 2206/2500\n",
            "Epoch 2206: Training Accuracy = 0.9922, Training Loss = 0.0581, Validation Accuracy = 0.9901, Validation Loss = 0.1082\n",
            "Epoch 2207/2500\n",
            "Epoch 2207: Training Accuracy = 0.9922, Training Loss = 0.0577, Validation Accuracy = 0.9901, Validation Loss = 0.1096\n",
            "Epoch 2208/2500\n",
            "Epoch 2208: Training Accuracy = 0.9922, Training Loss = 0.0577, Validation Accuracy = 0.9901, Validation Loss = 0.1096\n",
            "Epoch 2209/2500\n",
            "Epoch 2209: Training Accuracy = 0.2656, Training Loss = 2.5424, Validation Accuracy = 0.4469, Validation Loss = 2.3472\n",
            "Epoch 2210/2500\n",
            "Epoch 2210: Training Accuracy = 0.2656, Training Loss = 2.5424, Validation Accuracy = 0.4469, Validation Loss = 2.3472\n",
            "Epoch 2211/2500\n",
            "Epoch 2211: Training Accuracy = 0.8730, Training Loss = 0.7799, Validation Accuracy = 0.8108, Validation Loss = 0.9775\n",
            "Epoch 2212/2500\n",
            "Epoch 2212: Training Accuracy = 0.9707, Training Loss = 0.3406, Validation Accuracy = 0.9681, Validation Loss = 0.4038\n",
            "Epoch 2213/2500\n",
            "Epoch 2213: Training Accuracy = 0.9707, Training Loss = 0.3406, Validation Accuracy = 0.9681, Validation Loss = 0.4038\n",
            "Epoch 2214/2500\n",
            "Epoch 2214: Training Accuracy = 0.9824, Training Loss = 0.1818, Validation Accuracy = 0.9882, Validation Loss = 0.2307\n",
            "Epoch 2215/2500\n",
            "Epoch 2215: Training Accuracy = 0.9824, Training Loss = 0.1818, Validation Accuracy = 0.9882, Validation Loss = 0.2307\n",
            "Epoch 2216/2500\n",
            "Epoch 2216: Training Accuracy = 0.9922, Training Loss = 0.0935, Validation Accuracy = 0.9900, Validation Loss = 0.1541\n",
            "Epoch 2217/2500\n",
            "Epoch 2217: Training Accuracy = 0.9922, Training Loss = 0.0727, Validation Accuracy = 0.9901, Validation Loss = 0.1284\n",
            "Epoch 2218/2500\n",
            "Epoch 2218: Training Accuracy = 0.9922, Training Loss = 0.0727, Validation Accuracy = 0.9901, Validation Loss = 0.1284\n",
            "Epoch 2219/2500\n",
            "Epoch 2219: Training Accuracy = 0.9902, Training Loss = 0.0710, Validation Accuracy = 0.9901, Validation Loss = 0.1165\n",
            "Epoch 2220/2500\n",
            "Epoch 2220: Training Accuracy = 0.9902, Training Loss = 0.0710, Validation Accuracy = 0.9901, Validation Loss = 0.1165\n",
            "Epoch 2221/2500\n",
            "Epoch 2221: Training Accuracy = 0.9883, Training Loss = 0.0742, Validation Accuracy = 0.9901, Validation Loss = 0.1121\n",
            "Epoch 2222/2500\n",
            "Epoch 2222: Training Accuracy = 0.9902, Training Loss = 0.0680, Validation Accuracy = 0.9901, Validation Loss = 0.1098\n",
            "Epoch 2223/2500\n",
            "Epoch 2223: Training Accuracy = 0.9902, Training Loss = 0.0680, Validation Accuracy = 0.9901, Validation Loss = 0.1098\n",
            "Epoch 2224/2500\n",
            "Epoch 2224: Training Accuracy = 0.9844, Training Loss = 0.0866, Validation Accuracy = 0.9901, Validation Loss = 0.1091\n",
            "Epoch 2225/2500\n",
            "Epoch 2225: Training Accuracy = 0.9844, Training Loss = 0.0866, Validation Accuracy = 0.9901, Validation Loss = 0.1091\n",
            "Epoch 2226/2500\n",
            "Epoch 2226: Training Accuracy = 0.9844, Training Loss = 0.0857, Validation Accuracy = 0.9901, Validation Loss = 0.1075\n",
            "Epoch 2227/2500\n",
            "Epoch 2227: Training Accuracy = 0.9824, Training Loss = 0.0943, Validation Accuracy = 0.9901, Validation Loss = 0.1075\n",
            "Epoch 2228/2500\n",
            "Epoch 2228: Training Accuracy = 0.9824, Training Loss = 0.0943, Validation Accuracy = 0.9901, Validation Loss = 0.1075\n",
            "Epoch 2229/2500\n",
            "Epoch 2229: Training Accuracy = 0.9863, Training Loss = 0.0869, Validation Accuracy = 0.9901, Validation Loss = 0.1056\n",
            "Epoch 2230/2500\n",
            "Epoch 2230: Training Accuracy = 0.9863, Training Loss = 0.0869, Validation Accuracy = 0.9901, Validation Loss = 0.1056\n",
            "Epoch 2231/2500\n",
            "Epoch 2231: Training Accuracy = 0.9922, Training Loss = 0.0589, Validation Accuracy = 0.9901, Validation Loss = 0.1077\n",
            "Epoch 2232/2500\n",
            "Epoch 2232: Training Accuracy = 0.9941, Training Loss = 0.0520, Validation Accuracy = 0.9901, Validation Loss = 0.1077\n",
            "Epoch 2233/2500\n",
            "Epoch 2233: Training Accuracy = 0.9941, Training Loss = 0.0520, Validation Accuracy = 0.9901, Validation Loss = 0.1077\n",
            "Epoch 2234/2500\n",
            "Epoch 2234: Training Accuracy = 0.9922, Training Loss = 0.0599, Validation Accuracy = 0.9901, Validation Loss = 0.1059\n",
            "Epoch 2235/2500\n",
            "Epoch 2235: Training Accuracy = 0.9922, Training Loss = 0.0599, Validation Accuracy = 0.9901, Validation Loss = 0.1059\n",
            "Epoch 2236/2500\n",
            "Epoch 2236: Training Accuracy = 0.9863, Training Loss = 0.0788, Validation Accuracy = 0.9901, Validation Loss = 0.1050\n",
            "Epoch 2237/2500\n",
            "Epoch 2237: Training Accuracy = 0.9863, Training Loss = 0.0787, Validation Accuracy = 0.9901, Validation Loss = 0.1060\n",
            "Epoch 2238/2500\n",
            "Epoch 2238: Training Accuracy = 0.9863, Training Loss = 0.0787, Validation Accuracy = 0.9901, Validation Loss = 0.1060\n",
            "Epoch 2239/2500\n",
            "Epoch 2239: Training Accuracy = 0.9844, Training Loss = 0.0880, Validation Accuracy = 0.9901, Validation Loss = 0.1079\n",
            "Epoch 2240/2500\n",
            "Epoch 2240: Training Accuracy = 0.9844, Training Loss = 0.0880, Validation Accuracy = 0.9901, Validation Loss = 0.1079\n",
            "Epoch 2241/2500\n",
            "Epoch 2241: Training Accuracy = 0.9863, Training Loss = 0.0818, Validation Accuracy = 0.9901, Validation Loss = 0.1082\n",
            "Epoch 2242/2500\n",
            "Epoch 2242: Training Accuracy = 0.9043, Training Loss = 0.8475, Validation Accuracy = 0.4249, Validation Loss = 2.1561\n",
            "Epoch 2243/2500\n",
            "Epoch 2243: Training Accuracy = 0.9043, Training Loss = 0.8475, Validation Accuracy = 0.4249, Validation Loss = 2.1561\n",
            "Epoch 2244/2500\n",
            "Epoch 2244: Training Accuracy = 0.9258, Training Loss = 0.6631, Validation Accuracy = 0.9335, Validation Loss = 0.6618\n",
            "Epoch 2245/2500\n",
            "Epoch 2245: Training Accuracy = 0.9258, Training Loss = 0.6631, Validation Accuracy = 0.9335, Validation Loss = 0.6618\n",
            "Epoch 2246/2500\n",
            "Epoch 2246: Training Accuracy = 0.9922, Training Loss = 0.2144, Validation Accuracy = 0.9880, Validation Loss = 0.3104\n",
            "Epoch 2247/2500\n",
            "Epoch 2247: Training Accuracy = 0.9863, Training Loss = 0.1381, Validation Accuracy = 0.9901, Validation Loss = 0.1754\n",
            "Epoch 2248/2500\n",
            "Epoch 2248: Training Accuracy = 0.9863, Training Loss = 0.1381, Validation Accuracy = 0.9901, Validation Loss = 0.1754\n",
            "Epoch 2249/2500\n",
            "Epoch 2249: Training Accuracy = 0.9863, Training Loss = 0.0989, Validation Accuracy = 0.9901, Validation Loss = 0.1390\n",
            "Epoch 2250/2500\n",
            "Epoch 2250: Training Accuracy = 0.9863, Training Loss = 0.0989, Validation Accuracy = 0.9901, Validation Loss = 0.1390\n",
            "Epoch 2251/2500\n",
            "Epoch 2251: Training Accuracy = 0.9883, Training Loss = 0.0775, Validation Accuracy = 0.9901, Validation Loss = 0.1144\n",
            "Epoch 2252/2500\n",
            "Epoch 2252: Training Accuracy = 0.9941, Training Loss = 0.0524, Validation Accuracy = 0.9901, Validation Loss = 0.1079\n",
            "Epoch 2253/2500\n",
            "Epoch 2253: Training Accuracy = 0.9941, Training Loss = 0.0524, Validation Accuracy = 0.9901, Validation Loss = 0.1079\n",
            "Epoch 2254/2500\n",
            "Epoch 2254: Training Accuracy = 0.9922, Training Loss = 0.0588, Validation Accuracy = 0.9901, Validation Loss = 0.1044\n",
            "Epoch 2255/2500\n",
            "Epoch 2255: Training Accuracy = 0.9922, Training Loss = 0.0588, Validation Accuracy = 0.9901, Validation Loss = 0.1044\n",
            "Epoch 2256/2500\n",
            "Epoch 2256: Training Accuracy = 0.9824, Training Loss = 0.0981, Validation Accuracy = 0.9901, Validation Loss = 0.1056\n",
            "Epoch 2257/2500\n",
            "Epoch 2257: Training Accuracy = 0.9941, Training Loss = 0.0507, Validation Accuracy = 0.9901, Validation Loss = 0.1043\n",
            "Epoch 2258/2500\n",
            "Epoch 2258: Training Accuracy = 0.9941, Training Loss = 0.0507, Validation Accuracy = 0.9901, Validation Loss = 0.1043\n",
            "Epoch 2259/2500\n",
            "Epoch 2259: Training Accuracy = 0.9883, Training Loss = 0.0704, Validation Accuracy = 0.9901, Validation Loss = 0.1047\n",
            "Epoch 2260/2500\n",
            "Epoch 2260: Training Accuracy = 0.9883, Training Loss = 0.0704, Validation Accuracy = 0.9901, Validation Loss = 0.1047\n",
            "Epoch 2261/2500\n",
            "Epoch 2261: Training Accuracy = 0.9902, Training Loss = 0.0615, Validation Accuracy = 0.9901, Validation Loss = 0.1036\n",
            "Epoch 2262/2500\n",
            "Epoch 2262: Training Accuracy = 0.9902, Training Loss = 0.0630, Validation Accuracy = 0.9901, Validation Loss = 0.1040\n",
            "Epoch 2263/2500\n",
            "Epoch 2263: Training Accuracy = 0.9902, Training Loss = 0.0630, Validation Accuracy = 0.9901, Validation Loss = 0.1040\n",
            "Epoch 2264/2500\n",
            "Epoch 2264: Training Accuracy = 0.9922, Training Loss = 0.0582, Validation Accuracy = 0.9901, Validation Loss = 0.1059\n",
            "Epoch 2265/2500\n",
            "Epoch 2265: Training Accuracy = 0.9922, Training Loss = 0.0582, Validation Accuracy = 0.9901, Validation Loss = 0.1059\n",
            "Epoch 2266/2500\n",
            "Epoch 2266: Training Accuracy = 0.9883, Training Loss = 0.0713, Validation Accuracy = 0.9901, Validation Loss = 0.1041\n",
            "Epoch 2267/2500\n",
            "Epoch 2267: Training Accuracy = 0.9922, Training Loss = 0.0584, Validation Accuracy = 0.9901, Validation Loss = 0.1022\n",
            "Epoch 2268/2500\n",
            "Epoch 2268: Training Accuracy = 0.9922, Training Loss = 0.0584, Validation Accuracy = 0.9901, Validation Loss = 0.1022\n",
            "Epoch 2269/2500\n",
            "Epoch 2269: Training Accuracy = 0.9902, Training Loss = 0.0622, Validation Accuracy = 0.9901, Validation Loss = 0.1052\n",
            "Epoch 2270/2500\n",
            "Epoch 2270: Training Accuracy = 0.9902, Training Loss = 0.0622, Validation Accuracy = 0.9901, Validation Loss = 0.1052\n",
            "Epoch 2271/2500\n",
            "Epoch 2271: Training Accuracy = 0.9922, Training Loss = 0.0559, Validation Accuracy = 0.9901, Validation Loss = 0.1070\n",
            "Epoch 2272/2500\n",
            "Epoch 2272: Training Accuracy = 0.9922, Training Loss = 0.0626, Validation Accuracy = 0.9901, Validation Loss = 0.1093\n",
            "Epoch 2273/2500\n",
            "Epoch 2273: Training Accuracy = 0.9922, Training Loss = 0.0626, Validation Accuracy = 0.9901, Validation Loss = 0.1093\n",
            "Epoch 2274/2500\n",
            "Epoch 2274: Training Accuracy = 0.3984, Training Loss = 2.5430, Validation Accuracy = 0.3600, Validation Loss = 2.8431\n",
            "Epoch 2275/2500\n",
            "Epoch 2275: Training Accuracy = 0.3984, Training Loss = 2.5430, Validation Accuracy = 0.3600, Validation Loss = 2.8431\n",
            "Epoch 2276/2500\n",
            "Epoch 2276: Training Accuracy = 0.9512, Training Loss = 0.6082, Validation Accuracy = 0.9177, Validation Loss = 0.6895\n",
            "Epoch 2277/2500\n",
            "Epoch 2277: Training Accuracy = 0.9941, Training Loss = 0.2442, Validation Accuracy = 0.9833, Validation Loss = 0.3054\n",
            "Epoch 2278/2500\n",
            "Epoch 2278: Training Accuracy = 0.9941, Training Loss = 0.2442, Validation Accuracy = 0.9833, Validation Loss = 0.3054\n",
            "Epoch 2279/2500\n",
            "Epoch 2279: Training Accuracy = 0.9863, Training Loss = 0.1467, Validation Accuracy = 0.9891, Validation Loss = 0.1916\n",
            "Epoch 2280/2500\n",
            "Epoch 2280: Training Accuracy = 0.9863, Training Loss = 0.1467, Validation Accuracy = 0.9891, Validation Loss = 0.1916\n",
            "Epoch 2281/2500\n",
            "Epoch 2281: Training Accuracy = 0.9902, Training Loss = 0.1002, Validation Accuracy = 0.9898, Validation Loss = 0.1455\n",
            "Epoch 2282/2500\n",
            "Epoch 2282: Training Accuracy = 0.9844, Training Loss = 0.0980, Validation Accuracy = 0.9901, Validation Loss = 0.1178\n",
            "Epoch 2283/2500\n",
            "Epoch 2283: Training Accuracy = 0.9844, Training Loss = 0.0980, Validation Accuracy = 0.9901, Validation Loss = 0.1178\n",
            "Epoch 2284/2500\n",
            "Epoch 2284: Training Accuracy = 0.9941, Training Loss = 0.0545, Validation Accuracy = 0.9901, Validation Loss = 0.1107\n",
            "Epoch 2285/2500\n",
            "Epoch 2285: Training Accuracy = 0.9941, Training Loss = 0.0545, Validation Accuracy = 0.9901, Validation Loss = 0.1107\n",
            "Epoch 2286/2500\n",
            "Epoch 2286: Training Accuracy = 0.9902, Training Loss = 0.0640, Validation Accuracy = 0.9901, Validation Loss = 0.1063\n",
            "Epoch 2287/2500\n",
            "Epoch 2287: Training Accuracy = 0.9902, Training Loss = 0.0641, Validation Accuracy = 0.9901, Validation Loss = 0.1021\n",
            "Epoch 2288/2500\n",
            "Epoch 2288: Training Accuracy = 0.9902, Training Loss = 0.0641, Validation Accuracy = 0.9901, Validation Loss = 0.1021\n",
            "Epoch 2289/2500\n",
            "Epoch 2289: Training Accuracy = 0.9941, Training Loss = 0.0552, Validation Accuracy = 0.9901, Validation Loss = 0.1022\n",
            "Epoch 2290/2500\n",
            "Epoch 2290: Training Accuracy = 0.9941, Training Loss = 0.0552, Validation Accuracy = 0.9901, Validation Loss = 0.1022\n",
            "Epoch 2291/2500\n",
            "Epoch 2291: Training Accuracy = 0.9902, Training Loss = 0.0604, Validation Accuracy = 0.9901, Validation Loss = 0.1018\n",
            "Epoch 2292/2500\n",
            "Epoch 2292: Training Accuracy = 0.9961, Training Loss = 0.0417, Validation Accuracy = 0.9901, Validation Loss = 0.1011\n",
            "Epoch 2293/2500\n",
            "Epoch 2293: Training Accuracy = 0.9961, Training Loss = 0.0417, Validation Accuracy = 0.9901, Validation Loss = 0.1011\n",
            "Epoch 2294/2500\n",
            "Epoch 2294: Training Accuracy = 0.9922, Training Loss = 0.0541, Validation Accuracy = 0.9901, Validation Loss = 0.1003\n",
            "Epoch 2295/2500\n",
            "Epoch 2295: Training Accuracy = 0.9922, Training Loss = 0.0541, Validation Accuracy = 0.9901, Validation Loss = 0.1003\n",
            "Epoch 2296/2500\n",
            "Epoch 2296: Training Accuracy = 0.9941, Training Loss = 0.0519, Validation Accuracy = 0.9901, Validation Loss = 0.1001\n",
            "Epoch 2297/2500\n",
            "Epoch 2297: Training Accuracy = 0.9922, Training Loss = 0.0548, Validation Accuracy = 0.9901, Validation Loss = 0.0999\n",
            "Epoch 2298/2500\n",
            "Epoch 2298: Training Accuracy = 0.9922, Training Loss = 0.0548, Validation Accuracy = 0.9901, Validation Loss = 0.0999\n",
            "Epoch 2299/2500\n",
            "Epoch 2299: Training Accuracy = 0.9941, Training Loss = 0.0480, Validation Accuracy = 0.9901, Validation Loss = 0.0988\n",
            "Epoch 2300/2500\n",
            "Epoch 2300: Training Accuracy = 0.9941, Training Loss = 0.0480, Validation Accuracy = 0.9901, Validation Loss = 0.0988\n",
            "Epoch 2301/2500\n",
            "Epoch 2301: Training Accuracy = 0.9941, Training Loss = 0.0469, Validation Accuracy = 0.9901, Validation Loss = 0.1007\n",
            "Epoch 2302/2500\n",
            "Epoch 2302: Training Accuracy = 0.9883, Training Loss = 0.0712, Validation Accuracy = 0.9901, Validation Loss = 0.0986\n",
            "Epoch 2303/2500\n",
            "Epoch 2303: Training Accuracy = 0.9883, Training Loss = 0.0712, Validation Accuracy = 0.9901, Validation Loss = 0.0986\n",
            "Epoch 2304/2500\n",
            "Epoch 2304: Training Accuracy = 0.9883, Training Loss = 0.0726, Validation Accuracy = 0.9901, Validation Loss = 0.1019\n",
            "Epoch 2305/2500\n",
            "Epoch 2305: Training Accuracy = 0.9883, Training Loss = 0.0726, Validation Accuracy = 0.9901, Validation Loss = 0.1019\n",
            "Epoch 2306/2500\n",
            "Epoch 2306: Training Accuracy = 0.9805, Training Loss = 0.1004, Validation Accuracy = 0.9901, Validation Loss = 0.1023\n",
            "Epoch 2307/2500\n",
            "Epoch 2307: Training Accuracy = 0.9883, Training Loss = 0.0698, Validation Accuracy = 0.9901, Validation Loss = 0.1023\n",
            "Epoch 2308/2500\n",
            "Epoch 2308: Training Accuracy = 0.9883, Training Loss = 0.0698, Validation Accuracy = 0.9901, Validation Loss = 0.1023\n",
            "Epoch 2309/2500\n",
            "Epoch 2309: Training Accuracy = 0.9863, Training Loss = 0.0792, Validation Accuracy = 0.9901, Validation Loss = 0.1004\n",
            "Epoch 2310/2500\n",
            "Epoch 2310: Training Accuracy = 0.9863, Training Loss = 0.0792, Validation Accuracy = 0.9901, Validation Loss = 0.1004\n",
            "Epoch 2311/2500\n",
            "Epoch 2311: Training Accuracy = 0.6367, Training Loss = 1.5601, Validation Accuracy = 0.6042, Validation Loss = 1.6670\n",
            "Epoch 2312/2500\n",
            "Epoch 2312: Training Accuracy = 0.9531, Training Loss = 0.4781, Validation Accuracy = 0.9431, Validation Loss = 0.5349\n",
            "Epoch 2313/2500\n",
            "Epoch 2313: Training Accuracy = 0.9531, Training Loss = 0.4781, Validation Accuracy = 0.9431, Validation Loss = 0.5349\n",
            "Epoch 2314/2500\n",
            "Epoch 2314: Training Accuracy = 0.9766, Training Loss = 0.2214, Validation Accuracy = 0.9863, Validation Loss = 0.2442\n",
            "Epoch 2315/2500\n",
            "Epoch 2315: Training Accuracy = 0.9766, Training Loss = 0.2214, Validation Accuracy = 0.9863, Validation Loss = 0.2442\n",
            "Epoch 2316/2500\n",
            "Epoch 2316: Training Accuracy = 0.9902, Training Loss = 0.1128, Validation Accuracy = 0.9891, Validation Loss = 0.1606\n",
            "Epoch 2317/2500\n",
            "Epoch 2317: Training Accuracy = 0.9902, Training Loss = 0.0775, Validation Accuracy = 0.9901, Validation Loss = 0.1232\n",
            "Epoch 2318/2500\n",
            "Epoch 2318: Training Accuracy = 0.9902, Training Loss = 0.0775, Validation Accuracy = 0.9901, Validation Loss = 0.1232\n",
            "Epoch 2319/2500\n",
            "Epoch 2319: Training Accuracy = 0.9863, Training Loss = 0.0833, Validation Accuracy = 0.9901, Validation Loss = 0.1103\n",
            "Epoch 2320/2500\n",
            "Epoch 2320: Training Accuracy = 0.9863, Training Loss = 0.0833, Validation Accuracy = 0.9901, Validation Loss = 0.1103\n",
            "Epoch 2321/2500\n",
            "Epoch 2321: Training Accuracy = 0.9863, Training Loss = 0.0777, Validation Accuracy = 0.9901, Validation Loss = 0.1041\n",
            "Epoch 2322/2500\n",
            "Epoch 2322: Training Accuracy = 0.9902, Training Loss = 0.0630, Validation Accuracy = 0.9901, Validation Loss = 0.1031\n",
            "Epoch 2323/2500\n",
            "Epoch 2323: Training Accuracy = 0.9902, Training Loss = 0.0630, Validation Accuracy = 0.9901, Validation Loss = 0.1031\n",
            "Epoch 2324/2500\n",
            "Epoch 2324: Training Accuracy = 0.9844, Training Loss = 0.0835, Validation Accuracy = 0.9901, Validation Loss = 0.1010\n",
            "Epoch 2325/2500\n",
            "Epoch 2325: Training Accuracy = 0.9844, Training Loss = 0.0835, Validation Accuracy = 0.9901, Validation Loss = 0.1010\n",
            "Epoch 2326/2500\n",
            "Epoch 2326: Training Accuracy = 0.9863, Training Loss = 0.0752, Validation Accuracy = 0.9901, Validation Loss = 0.1006\n",
            "Epoch 2327/2500\n",
            "Epoch 2327: Training Accuracy = 0.9844, Training Loss = 0.0818, Validation Accuracy = 0.9901, Validation Loss = 0.1004\n",
            "Epoch 2328/2500\n",
            "Epoch 2328: Training Accuracy = 0.9844, Training Loss = 0.0818, Validation Accuracy = 0.9901, Validation Loss = 0.1004\n",
            "Epoch 2329/2500\n",
            "Epoch 2329: Training Accuracy = 0.9922, Training Loss = 0.0538, Validation Accuracy = 0.9901, Validation Loss = 0.1004\n",
            "Epoch 2330/2500\n",
            "Epoch 2330: Training Accuracy = 0.9922, Training Loss = 0.0538, Validation Accuracy = 0.9901, Validation Loss = 0.1004\n",
            "Epoch 2331/2500\n",
            "Epoch 2331: Training Accuracy = 0.9844, Training Loss = 0.0807, Validation Accuracy = 0.9901, Validation Loss = 0.1001\n",
            "Epoch 2332/2500\n",
            "Epoch 2332: Training Accuracy = 0.9863, Training Loss = 0.0772, Validation Accuracy = 0.9901, Validation Loss = 0.1006\n",
            "Epoch 2333/2500\n",
            "Epoch 2333: Training Accuracy = 0.9863, Training Loss = 0.0772, Validation Accuracy = 0.9901, Validation Loss = 0.1006\n",
            "Epoch 2334/2500\n",
            "Epoch 2334: Training Accuracy = 0.9844, Training Loss = 0.0854, Validation Accuracy = 0.9901, Validation Loss = 0.1010\n",
            "Epoch 2335/2500\n",
            "Epoch 2335: Training Accuracy = 0.9844, Training Loss = 0.0854, Validation Accuracy = 0.9901, Validation Loss = 0.1010\n",
            "Epoch 2336/2500\n",
            "Epoch 2336: Training Accuracy = 0.9902, Training Loss = 0.0625, Validation Accuracy = 0.9901, Validation Loss = 0.1003\n",
            "Epoch 2337/2500\n",
            "Epoch 2337: Training Accuracy = 0.9863, Training Loss = 0.0764, Validation Accuracy = 0.9901, Validation Loss = 0.1006\n",
            "Epoch 2338/2500\n",
            "Epoch 2338: Training Accuracy = 0.9863, Training Loss = 0.0764, Validation Accuracy = 0.9901, Validation Loss = 0.1006\n",
            "Epoch 2339/2500\n",
            "Epoch 2339: Training Accuracy = 0.9863, Training Loss = 0.0756, Validation Accuracy = 0.9901, Validation Loss = 0.1002\n",
            "Epoch 2340/2500\n",
            "Epoch 2340: Training Accuracy = 0.9863, Training Loss = 0.0756, Validation Accuracy = 0.9901, Validation Loss = 0.1002\n",
            "Epoch 2341/2500\n",
            "Epoch 2341: Training Accuracy = 0.9922, Training Loss = 0.0559, Validation Accuracy = 0.9901, Validation Loss = 0.1025\n",
            "Epoch 2342/2500\n",
            "Epoch 2342: Training Accuracy = 0.9902, Training Loss = 0.0667, Validation Accuracy = 0.9901, Validation Loss = 0.1034\n",
            "Epoch 2343/2500\n",
            "Epoch 2343: Training Accuracy = 0.9902, Training Loss = 0.0667, Validation Accuracy = 0.9901, Validation Loss = 0.1034\n",
            "Epoch 2344/2500\n",
            "Epoch 2344: Training Accuracy = 0.9902, Training Loss = 0.0667, Validation Accuracy = 0.9901, Validation Loss = 0.1052\n",
            "Epoch 2345/2500\n",
            "Epoch 2345: Training Accuracy = 0.9902, Training Loss = 0.0667, Validation Accuracy = 0.9901, Validation Loss = 0.1052\n",
            "Epoch 2346/2500\n",
            "Epoch 2346: Training Accuracy = 0.9727, Training Loss = 0.1361, Validation Accuracy = 0.9901, Validation Loss = 0.1158\n",
            "Epoch 2347/2500\n",
            "Epoch 2347: Training Accuracy = 0.4180, Training Loss = 2.2810, Validation Accuracy = 0.4208, Validation Loss = 2.3749\n",
            "Epoch 2348/2500\n",
            "Epoch 2348: Training Accuracy = 0.4180, Training Loss = 2.2810, Validation Accuracy = 0.4208, Validation Loss = 2.3749\n",
            "Epoch 2349/2500\n",
            "Epoch 2349: Training Accuracy = 0.9316, Training Loss = 0.5760, Validation Accuracy = 0.8937, Validation Loss = 0.7286\n",
            "Epoch 2350/2500\n",
            "Epoch 2350: Training Accuracy = 0.9316, Training Loss = 0.5760, Validation Accuracy = 0.8937, Validation Loss = 0.7286\n",
            "Epoch 2351/2500\n",
            "Epoch 2351: Training Accuracy = 0.9707, Training Loss = 0.2872, Validation Accuracy = 0.9737, Validation Loss = 0.3513\n",
            "Epoch 2352/2500\n",
            "Epoch 2352: Training Accuracy = 0.9883, Training Loss = 0.1503, Validation Accuracy = 0.9898, Validation Loss = 0.1965\n",
            "Epoch 2353/2500\n",
            "Epoch 2353: Training Accuracy = 0.9883, Training Loss = 0.1503, Validation Accuracy = 0.9898, Validation Loss = 0.1965\n",
            "Epoch 2354/2500\n",
            "Epoch 2354: Training Accuracy = 0.9824, Training Loss = 0.1217, Validation Accuracy = 0.9901, Validation Loss = 0.1454\n",
            "Epoch 2355/2500\n",
            "Epoch 2355: Training Accuracy = 0.9824, Training Loss = 0.1217, Validation Accuracy = 0.9901, Validation Loss = 0.1454\n",
            "Epoch 2356/2500\n",
            "Epoch 2356: Training Accuracy = 0.9902, Training Loss = 0.0754, Validation Accuracy = 0.9901, Validation Loss = 0.1220\n",
            "Epoch 2357/2500\n",
            "Epoch 2357: Training Accuracy = 0.9805, Training Loss = 0.1059, Validation Accuracy = 0.9901, Validation Loss = 0.1120\n",
            "Epoch 2358/2500\n",
            "Epoch 2358: Training Accuracy = 0.9805, Training Loss = 0.1059, Validation Accuracy = 0.9901, Validation Loss = 0.1120\n",
            "Epoch 2359/2500\n",
            "Epoch 2359: Training Accuracy = 0.9844, Training Loss = 0.0873, Validation Accuracy = 0.9901, Validation Loss = 0.1081\n",
            "Epoch 2360/2500\n",
            "Epoch 2360: Training Accuracy = 0.9844, Training Loss = 0.0873, Validation Accuracy = 0.9901, Validation Loss = 0.1081\n",
            "Epoch 2361/2500\n",
            "Epoch 2361: Training Accuracy = 0.9922, Training Loss = 0.0655, Validation Accuracy = 0.9901, Validation Loss = 0.1066\n",
            "Epoch 2362/2500\n",
            "Epoch 2362: Training Accuracy = 0.9941, Training Loss = 0.0524, Validation Accuracy = 0.9901, Validation Loss = 0.1045\n",
            "Epoch 2363/2500\n",
            "Epoch 2363: Training Accuracy = 0.9941, Training Loss = 0.0524, Validation Accuracy = 0.9901, Validation Loss = 0.1045\n",
            "Epoch 2364/2500\n",
            "Epoch 2364: Training Accuracy = 0.9902, Training Loss = 0.0646, Validation Accuracy = 0.9901, Validation Loss = 0.1039\n",
            "Epoch 2365/2500\n",
            "Epoch 2365: Training Accuracy = 0.9902, Training Loss = 0.0646, Validation Accuracy = 0.9901, Validation Loss = 0.1039\n",
            "Epoch 2366/2500\n",
            "Epoch 2366: Training Accuracy = 0.9902, Training Loss = 0.0631, Validation Accuracy = 0.9901, Validation Loss = 0.1035\n",
            "Epoch 2367/2500\n",
            "Epoch 2367: Training Accuracy = 0.9844, Training Loss = 0.0916, Validation Accuracy = 0.9901, Validation Loss = 0.1032\n",
            "Epoch 2368/2500\n",
            "Epoch 2368: Training Accuracy = 0.9844, Training Loss = 0.0916, Validation Accuracy = 0.9901, Validation Loss = 0.1032\n",
            "Epoch 2369/2500\n",
            "Epoch 2369: Training Accuracy = 0.9883, Training Loss = 0.0701, Validation Accuracy = 0.9901, Validation Loss = 0.1026\n",
            "Epoch 2370/2500\n",
            "Epoch 2370: Training Accuracy = 0.9883, Training Loss = 0.0701, Validation Accuracy = 0.9901, Validation Loss = 0.1026\n",
            "Epoch 2371/2500\n",
            "Epoch 2371: Training Accuracy = 0.9941, Training Loss = 0.0515, Validation Accuracy = 0.9901, Validation Loss = 0.1062\n",
            "Epoch 2372/2500\n",
            "Epoch 2372: Training Accuracy = 0.9844, Training Loss = 0.0871, Validation Accuracy = 0.9901, Validation Loss = 0.1038\n",
            "Epoch 2373/2500\n",
            "Epoch 2373: Training Accuracy = 0.9844, Training Loss = 0.0871, Validation Accuracy = 0.9901, Validation Loss = 0.1038\n",
            "Epoch 2374/2500\n",
            "Epoch 2374: Training Accuracy = 0.9844, Training Loss = 0.0834, Validation Accuracy = 0.9901, Validation Loss = 0.1040\n",
            "Epoch 2375/2500\n",
            "Epoch 2375: Training Accuracy = 0.9844, Training Loss = 0.0834, Validation Accuracy = 0.9901, Validation Loss = 0.1040\n",
            "Epoch 2376/2500\n",
            "Epoch 2376: Training Accuracy = 0.9883, Training Loss = 0.0717, Validation Accuracy = 0.9901, Validation Loss = 0.1030\n",
            "Epoch 2377/2500\n",
            "Epoch 2377: Training Accuracy = 0.9941, Training Loss = 0.0525, Validation Accuracy = 0.9901, Validation Loss = 0.1049\n",
            "Epoch 2378/2500\n",
            "Epoch 2378: Training Accuracy = 0.9941, Training Loss = 0.0525, Validation Accuracy = 0.9901, Validation Loss = 0.1049\n",
            "Epoch 2379/2500\n",
            "Epoch 2379: Training Accuracy = 0.9883, Training Loss = 0.0694, Validation Accuracy = 0.9901, Validation Loss = 0.1064\n",
            "Epoch 2380/2500\n",
            "Epoch 2380: Training Accuracy = 0.9883, Training Loss = 0.0694, Validation Accuracy = 0.9901, Validation Loss = 0.1064\n",
            "Epoch 2381/2500\n",
            "Epoch 2381: Training Accuracy = 0.9844, Training Loss = 0.0821, Validation Accuracy = 0.9901, Validation Loss = 0.1047\n",
            "Epoch 2382/2500\n",
            "Epoch 2382: Training Accuracy = 0.9922, Training Loss = 0.0614, Validation Accuracy = 0.9901, Validation Loss = 0.1051\n",
            "Epoch 2383/2500\n",
            "Epoch 2383: Training Accuracy = 0.9922, Training Loss = 0.0614, Validation Accuracy = 0.9901, Validation Loss = 0.1051\n",
            "Epoch 2384/2500\n",
            "Epoch 2384: Training Accuracy = 0.9766, Training Loss = 0.1344, Validation Accuracy = 0.9898, Validation Loss = 0.1603\n",
            "Epoch 2385/2500\n",
            "Epoch 2385: Training Accuracy = 0.9766, Training Loss = 0.1344, Validation Accuracy = 0.9898, Validation Loss = 0.1603\n",
            "Epoch 2386/2500\n",
            "Epoch 2386: Training Accuracy = 0.7207, Training Loss = 1.4920, Validation Accuracy = 0.6566, Validation Loss = 1.5952\n",
            "Epoch 2387/2500\n",
            "Epoch 2387: Training Accuracy = 0.9492, Training Loss = 0.4559, Validation Accuracy = 0.9573, Validation Loss = 0.4922\n",
            "Epoch 2388/2500\n",
            "Epoch 2388: Training Accuracy = 0.9492, Training Loss = 0.4559, Validation Accuracy = 0.9573, Validation Loss = 0.4922\n",
            "Epoch 2389/2500\n",
            "Epoch 2389: Training Accuracy = 0.9863, Training Loss = 0.1917, Validation Accuracy = 0.9844, Validation Loss = 0.2742\n",
            "Epoch 2390/2500\n",
            "Epoch 2390: Training Accuracy = 0.9863, Training Loss = 0.1917, Validation Accuracy = 0.9844, Validation Loss = 0.2742\n",
            "Epoch 2391/2500\n",
            "Epoch 2391: Training Accuracy = 0.9863, Training Loss = 0.1253, Validation Accuracy = 0.9900, Validation Loss = 0.1616\n",
            "Epoch 2392/2500\n",
            "Epoch 2392: Training Accuracy = 0.9863, Training Loss = 0.1019, Validation Accuracy = 0.9901, Validation Loss = 0.1256\n",
            "Epoch 2393/2500\n",
            "Epoch 2393: Training Accuracy = 0.9863, Training Loss = 0.1019, Validation Accuracy = 0.9901, Validation Loss = 0.1256\n",
            "Epoch 2394/2500\n",
            "Epoch 2394: Training Accuracy = 0.9824, Training Loss = 0.0981, Validation Accuracy = 0.9901, Validation Loss = 0.1102\n",
            "Epoch 2395/2500\n",
            "Epoch 2395: Training Accuracy = 0.9824, Training Loss = 0.0981, Validation Accuracy = 0.9901, Validation Loss = 0.1102\n",
            "Epoch 2396/2500\n",
            "Epoch 2396: Training Accuracy = 0.9844, Training Loss = 0.0844, Validation Accuracy = 0.9901, Validation Loss = 0.1030\n",
            "Epoch 2397/2500\n",
            "Epoch 2397: Training Accuracy = 0.9883, Training Loss = 0.0731, Validation Accuracy = 0.9901, Validation Loss = 0.1001\n",
            "Epoch 2398/2500\n",
            "Epoch 2398: Training Accuracy = 0.9883, Training Loss = 0.0731, Validation Accuracy = 0.9901, Validation Loss = 0.1001\n",
            "Epoch 2399/2500\n",
            "Epoch 2399: Training Accuracy = 0.9883, Training Loss = 0.0764, Validation Accuracy = 0.9901, Validation Loss = 0.0985\n",
            "Epoch 2400/2500\n",
            "Epoch 2400: Training Accuracy = 0.9883, Training Loss = 0.0764, Validation Accuracy = 0.9901, Validation Loss = 0.0985\n",
            "Epoch 2401/2500\n",
            "Epoch 2401: Training Accuracy = 0.9902, Training Loss = 0.0644, Validation Accuracy = 0.9901, Validation Loss = 0.0982\n",
            "Epoch 2402/2500\n",
            "Epoch 2402: Training Accuracy = 0.9844, Training Loss = 0.0848, Validation Accuracy = 0.9901, Validation Loss = 0.1016\n",
            "Epoch 2403/2500\n",
            "Epoch 2403: Training Accuracy = 0.9844, Training Loss = 0.0848, Validation Accuracy = 0.9901, Validation Loss = 0.1016\n",
            "Epoch 2404/2500\n",
            "Epoch 2404: Training Accuracy = 0.9883, Training Loss = 0.0689, Validation Accuracy = 0.9901, Validation Loss = 0.0993\n",
            "Epoch 2405/2500\n",
            "Epoch 2405: Training Accuracy = 0.9883, Training Loss = 0.0689, Validation Accuracy = 0.9901, Validation Loss = 0.0993\n",
            "Epoch 2406/2500\n",
            "Epoch 2406: Training Accuracy = 0.9883, Training Loss = 0.0699, Validation Accuracy = 0.9901, Validation Loss = 0.0982\n",
            "Epoch 2407/2500\n",
            "Epoch 2407: Training Accuracy = 0.9883, Training Loss = 0.0703, Validation Accuracy = 0.9901, Validation Loss = 0.0990\n",
            "Epoch 2408/2500\n",
            "Epoch 2408: Training Accuracy = 0.9883, Training Loss = 0.0703, Validation Accuracy = 0.9901, Validation Loss = 0.0990\n",
            "Epoch 2409/2500\n",
            "Epoch 2409: Training Accuracy = 0.9902, Training Loss = 0.0629, Validation Accuracy = 0.9901, Validation Loss = 0.1011\n",
            "Epoch 2410/2500\n",
            "Epoch 2410: Training Accuracy = 0.9902, Training Loss = 0.0629, Validation Accuracy = 0.9901, Validation Loss = 0.1011\n",
            "Epoch 2411/2500\n",
            "Epoch 2411: Training Accuracy = 0.9883, Training Loss = 0.0693, Validation Accuracy = 0.9901, Validation Loss = 0.1017\n",
            "Epoch 2412/2500\n",
            "Epoch 2412: Training Accuracy = 0.9902, Training Loss = 0.0611, Validation Accuracy = 0.9901, Validation Loss = 0.1012\n",
            "Epoch 2413/2500\n",
            "Epoch 2413: Training Accuracy = 0.9902, Training Loss = 0.0611, Validation Accuracy = 0.9901, Validation Loss = 0.1012\n",
            "Epoch 2414/2500\n",
            "Epoch 2414: Training Accuracy = 0.9805, Training Loss = 0.0981, Validation Accuracy = 0.9901, Validation Loss = 0.1005\n",
            "Epoch 2415/2500\n",
            "Epoch 2415: Training Accuracy = 0.9805, Training Loss = 0.0981, Validation Accuracy = 0.9901, Validation Loss = 0.1005\n",
            "Epoch 2416/2500\n",
            "Epoch 2416: Training Accuracy = 0.9883, Training Loss = 0.0753, Validation Accuracy = 0.9901, Validation Loss = 0.1023\n",
            "Epoch 2417/2500\n",
            "Epoch 2417: Training Accuracy = 0.5293, Training Loss = 2.3868, Validation Accuracy = 0.5490, Validation Loss = 2.0960\n",
            "Epoch 2418/2500\n",
            "Epoch 2418: Training Accuracy = 0.5293, Training Loss = 2.3868, Validation Accuracy = 0.5490, Validation Loss = 2.0960\n",
            "Epoch 2419/2500\n",
            "Epoch 2419: Training Accuracy = 0.9609, Training Loss = 0.4769, Validation Accuracy = 0.9349, Validation Loss = 0.5604\n",
            "Epoch 2420/2500\n",
            "Epoch 2420: Training Accuracy = 0.9609, Training Loss = 0.4769, Validation Accuracy = 0.9349, Validation Loss = 0.5604\n",
            "Epoch 2421/2500\n",
            "Epoch 2421: Training Accuracy = 0.9902, Training Loss = 0.1761, Validation Accuracy = 0.9892, Validation Loss = 0.2509\n",
            "Epoch 2422/2500\n",
            "Epoch 2422: Training Accuracy = 0.9824, Training Loss = 0.1463, Validation Accuracy = 0.9900, Validation Loss = 0.1690\n",
            "Epoch 2423/2500\n",
            "Epoch 2423: Training Accuracy = 0.9824, Training Loss = 0.1463, Validation Accuracy = 0.9900, Validation Loss = 0.1690\n",
            "Epoch 2424/2500\n",
            "Epoch 2424: Training Accuracy = 0.9922, Training Loss = 0.0814, Validation Accuracy = 0.9901, Validation Loss = 0.1251\n",
            "Epoch 2425/2500\n",
            "Epoch 2425: Training Accuracy = 0.9922, Training Loss = 0.0814, Validation Accuracy = 0.9901, Validation Loss = 0.1251\n",
            "Epoch 2426/2500\n",
            "Epoch 2426: Training Accuracy = 0.9902, Training Loss = 0.0701, Validation Accuracy = 0.9901, Validation Loss = 0.1110\n",
            "Epoch 2427/2500\n",
            "Epoch 2427: Training Accuracy = 0.9844, Training Loss = 0.0887, Validation Accuracy = 0.9901, Validation Loss = 0.1031\n",
            "Epoch 2428/2500\n",
            "Epoch 2428: Training Accuracy = 0.9844, Training Loss = 0.0887, Validation Accuracy = 0.9901, Validation Loss = 0.1031\n",
            "Epoch 2429/2500\n",
            "Epoch 2429: Training Accuracy = 0.9941, Training Loss = 0.0568, Validation Accuracy = 0.9901, Validation Loss = 0.1014\n",
            "Epoch 2430/2500\n",
            "Epoch 2430: Training Accuracy = 0.9941, Training Loss = 0.0568, Validation Accuracy = 0.9901, Validation Loss = 0.1014\n",
            "Epoch 2431/2500\n",
            "Epoch 2431: Training Accuracy = 0.9844, Training Loss = 0.0840, Validation Accuracy = 0.9901, Validation Loss = 0.1005\n",
            "Epoch 2432/2500\n",
            "Epoch 2432: Training Accuracy = 0.9844, Training Loss = 0.0905, Validation Accuracy = 0.9901, Validation Loss = 0.0996\n",
            "Epoch 2433/2500\n",
            "Epoch 2433: Training Accuracy = 0.9844, Training Loss = 0.0905, Validation Accuracy = 0.9901, Validation Loss = 0.0996\n",
            "Epoch 2434/2500\n",
            "Epoch 2434: Training Accuracy = 0.9941, Training Loss = 0.0491, Validation Accuracy = 0.9901, Validation Loss = 0.1004\n",
            "Epoch 2435/2500\n",
            "Epoch 2435: Training Accuracy = 0.9941, Training Loss = 0.0491, Validation Accuracy = 0.9901, Validation Loss = 0.1004\n",
            "Epoch 2436/2500\n",
            "Epoch 2436: Training Accuracy = 0.9941, Training Loss = 0.0549, Validation Accuracy = 0.9901, Validation Loss = 0.0980\n",
            "Epoch 2437/2500\n",
            "Epoch 2437: Training Accuracy = 0.9883, Training Loss = 0.0702, Validation Accuracy = 0.9901, Validation Loss = 0.0981\n",
            "Epoch 2438/2500\n",
            "Epoch 2438: Training Accuracy = 0.9883, Training Loss = 0.0702, Validation Accuracy = 0.9901, Validation Loss = 0.0981\n",
            "Epoch 2439/2500\n",
            "Epoch 2439: Training Accuracy = 0.9863, Training Loss = 0.0834, Validation Accuracy = 0.9901, Validation Loss = 0.0996\n",
            "Epoch 2440/2500\n",
            "Epoch 2440: Training Accuracy = 0.9863, Training Loss = 0.0834, Validation Accuracy = 0.9901, Validation Loss = 0.0996\n",
            "Epoch 2441/2500\n",
            "Epoch 2441: Training Accuracy = 0.9805, Training Loss = 0.1056, Validation Accuracy = 0.9901, Validation Loss = 0.1026\n",
            "Epoch 2442/2500\n",
            "Epoch 2442: Training Accuracy = 0.9863, Training Loss = 0.0810, Validation Accuracy = 0.9901, Validation Loss = 0.1002\n",
            "Epoch 2443/2500\n",
            "Epoch 2443: Training Accuracy = 0.9863, Training Loss = 0.0810, Validation Accuracy = 0.9901, Validation Loss = 0.1002\n",
            "Epoch 2444/2500\n",
            "Epoch 2444: Training Accuracy = 0.9902, Training Loss = 0.0650, Validation Accuracy = 0.9901, Validation Loss = 0.1010\n",
            "Epoch 2445/2500\n",
            "Epoch 2445: Training Accuracy = 0.9902, Training Loss = 0.0650, Validation Accuracy = 0.9901, Validation Loss = 0.1010\n",
            "Epoch 2446/2500\n",
            "Epoch 2446: Training Accuracy = 0.9883, Training Loss = 0.0762, Validation Accuracy = 0.9901, Validation Loss = 0.0999\n",
            "Epoch 2447/2500\n",
            "Epoch 2447: Training Accuracy = 0.9922, Training Loss = 0.0814, Validation Accuracy = 0.9897, Validation Loss = 0.2357\n",
            "Epoch 2448/2500\n",
            "Epoch 2448: Training Accuracy = 0.9922, Training Loss = 0.0814, Validation Accuracy = 0.9897, Validation Loss = 0.2357\n",
            "Epoch 2449/2500\n",
            "Epoch 2449: Training Accuracy = 0.7109, Training Loss = 1.6740, Validation Accuracy = 0.7591, Validation Loss = 1.5239\n",
            "Epoch 2450/2500\n",
            "Epoch 2450: Training Accuracy = 0.7109, Training Loss = 1.6740, Validation Accuracy = 0.7591, Validation Loss = 1.5239\n",
            "Epoch 2451/2500\n",
            "Epoch 2451: Training Accuracy = 0.9727, Training Loss = 0.4084, Validation Accuracy = 0.9666, Validation Loss = 0.4724\n",
            "Epoch 2452/2500\n",
            "Epoch 2452: Training Accuracy = 0.9844, Training Loss = 0.1967, Validation Accuracy = 0.9880, Validation Loss = 0.2397\n",
            "Epoch 2453/2500\n",
            "Epoch 2453: Training Accuracy = 0.9844, Training Loss = 0.1967, Validation Accuracy = 0.9880, Validation Loss = 0.2397\n",
            "Epoch 2454/2500\n",
            "Epoch 2454: Training Accuracy = 0.9863, Training Loss = 0.1364, Validation Accuracy = 0.9900, Validation Loss = 0.1660\n",
            "Epoch 2455/2500\n",
            "Epoch 2455: Training Accuracy = 0.9863, Training Loss = 0.1364, Validation Accuracy = 0.9900, Validation Loss = 0.1660\n",
            "Epoch 2456/2500\n",
            "Epoch 2456: Training Accuracy = 0.9844, Training Loss = 0.1044, Validation Accuracy = 0.9901, Validation Loss = 0.1265\n",
            "Epoch 2457/2500\n",
            "Epoch 2457: Training Accuracy = 0.9883, Training Loss = 0.0797, Validation Accuracy = 0.9901, Validation Loss = 0.1096\n",
            "Epoch 2458/2500\n",
            "Epoch 2458: Training Accuracy = 0.9883, Training Loss = 0.0797, Validation Accuracy = 0.9901, Validation Loss = 0.1096\n",
            "Epoch 2459/2500\n",
            "Epoch 2459: Training Accuracy = 0.9844, Training Loss = 0.0888, Validation Accuracy = 0.9901, Validation Loss = 0.1059\n",
            "Epoch 2460/2500\n",
            "Epoch 2460: Training Accuracy = 0.9844, Training Loss = 0.0888, Validation Accuracy = 0.9901, Validation Loss = 0.1059\n",
            "Epoch 2461/2500\n",
            "Epoch 2461: Training Accuracy = 0.9902, Training Loss = 0.0630, Validation Accuracy = 0.9901, Validation Loss = 0.1034\n",
            "Epoch 2462/2500\n",
            "Epoch 2462: Training Accuracy = 0.9883, Training Loss = 0.0704, Validation Accuracy = 0.9901, Validation Loss = 0.1018\n",
            "Epoch 2463/2500\n",
            "Epoch 2463: Training Accuracy = 0.9883, Training Loss = 0.0704, Validation Accuracy = 0.9901, Validation Loss = 0.1018\n",
            "Epoch 2464/2500\n",
            "Epoch 2464: Training Accuracy = 0.9922, Training Loss = 0.0571, Validation Accuracy = 0.9901, Validation Loss = 0.1017\n",
            "Epoch 2465/2500\n",
            "Epoch 2465: Training Accuracy = 0.9922, Training Loss = 0.0571, Validation Accuracy = 0.9901, Validation Loss = 0.1017\n",
            "Epoch 2466/2500\n",
            "Epoch 2466: Training Accuracy = 0.9863, Training Loss = 0.0748, Validation Accuracy = 0.9901, Validation Loss = 0.1004\n",
            "Epoch 2467/2500\n",
            "Epoch 2467: Training Accuracy = 0.9922, Training Loss = 0.0546, Validation Accuracy = 0.9901, Validation Loss = 0.0999\n",
            "Epoch 2468/2500\n",
            "Epoch 2468: Training Accuracy = 0.9922, Training Loss = 0.0546, Validation Accuracy = 0.9901, Validation Loss = 0.0999\n",
            "Epoch 2469/2500\n",
            "Epoch 2469: Training Accuracy = 0.9824, Training Loss = 0.0915, Validation Accuracy = 0.9901, Validation Loss = 0.1005\n",
            "Epoch 2470/2500\n",
            "Epoch 2470: Training Accuracy = 0.9824, Training Loss = 0.0915, Validation Accuracy = 0.9901, Validation Loss = 0.1005\n",
            "Epoch 2471/2500\n",
            "Epoch 2471: Training Accuracy = 0.9824, Training Loss = 0.0905, Validation Accuracy = 0.9901, Validation Loss = 0.1000\n",
            "Epoch 2472/2500\n",
            "Epoch 2472: Training Accuracy = 0.9922, Training Loss = 0.0553, Validation Accuracy = 0.9901, Validation Loss = 0.0989\n",
            "Epoch 2473/2500\n",
            "Epoch 2473: Training Accuracy = 0.9922, Training Loss = 0.0553, Validation Accuracy = 0.9901, Validation Loss = 0.0989\n",
            "Epoch 2474/2500\n",
            "Epoch 2474: Training Accuracy = 0.9883, Training Loss = 0.0695, Validation Accuracy = 0.9901, Validation Loss = 0.0997\n",
            "Epoch 2475/2500\n",
            "Epoch 2475: Training Accuracy = 0.9883, Training Loss = 0.0695, Validation Accuracy = 0.9901, Validation Loss = 0.0997\n",
            "Epoch 2476/2500\n",
            "Epoch 2476: Training Accuracy = 0.9902, Training Loss = 0.0668, Validation Accuracy = 0.9901, Validation Loss = 0.1004\n",
            "Epoch 2477/2500\n",
            "Epoch 2477: Training Accuracy = 0.9902, Training Loss = 0.0652, Validation Accuracy = 0.9901, Validation Loss = 0.1017\n",
            "Epoch 2478/2500\n",
            "Epoch 2478: Training Accuracy = 0.9902, Training Loss = 0.0652, Validation Accuracy = 0.9901, Validation Loss = 0.1017\n",
            "Epoch 2479/2500\n",
            "Epoch 2479: Training Accuracy = 0.9902, Training Loss = 0.0673, Validation Accuracy = 0.9901, Validation Loss = 0.1010\n",
            "Epoch 2480/2500\n",
            "Epoch 2480: Training Accuracy = 0.9902, Training Loss = 0.0673, Validation Accuracy = 0.9901, Validation Loss = 0.1010\n",
            "Epoch 2481/2500\n",
            "Epoch 2481: Training Accuracy = 0.9922, Training Loss = 0.0615, Validation Accuracy = 0.9901, Validation Loss = 0.1009\n",
            "Epoch 2482/2500\n",
            "Epoch 2482: Training Accuracy = 0.9824, Training Loss = 0.1002, Validation Accuracy = 0.9901, Validation Loss = 0.1116\n",
            "Epoch 2483/2500\n",
            "Epoch 2483: Training Accuracy = 0.9824, Training Loss = 0.1002, Validation Accuracy = 0.9901, Validation Loss = 0.1116\n",
            "Epoch 2484/2500\n",
            "Epoch 2484: Training Accuracy = 0.6914, Training Loss = 1.6392, Validation Accuracy = 0.5222, Validation Loss = 1.9491\n",
            "Epoch 2485/2500\n",
            "Epoch 2485: Training Accuracy = 0.6914, Training Loss = 1.6392, Validation Accuracy = 0.5222, Validation Loss = 1.9491\n",
            "Epoch 2486/2500\n",
            "Epoch 2486: Training Accuracy = 0.9492, Training Loss = 0.5291, Validation Accuracy = 0.9085, Validation Loss = 0.6512\n",
            "Epoch 2487/2500\n",
            "Epoch 2487: Training Accuracy = 0.9863, Training Loss = 0.2314, Validation Accuracy = 0.9847, Validation Loss = 0.2719\n",
            "Epoch 2488/2500\n",
            "Epoch 2488: Training Accuracy = 0.9863, Training Loss = 0.2314, Validation Accuracy = 0.9847, Validation Loss = 0.2719\n",
            "Epoch 2489/2500\n",
            "Epoch 2489: Training Accuracy = 0.9941, Training Loss = 0.1051, Validation Accuracy = 0.9889, Validation Loss = 0.1687\n",
            "Epoch 2490/2500\n",
            "Epoch 2490: Training Accuracy = 0.9941, Training Loss = 0.1051, Validation Accuracy = 0.9889, Validation Loss = 0.1687\n",
            "Epoch 2491/2500\n",
            "Epoch 2491: Training Accuracy = 0.9863, Training Loss = 0.0950, Validation Accuracy = 0.9901, Validation Loss = 0.1260\n",
            "Epoch 2492/2500\n",
            "Epoch 2492: Training Accuracy = 0.9883, Training Loss = 0.0786, Validation Accuracy = 0.9901, Validation Loss = 0.1116\n",
            "Epoch 2493/2500\n",
            "Epoch 2493: Training Accuracy = 0.9883, Training Loss = 0.0786, Validation Accuracy = 0.9901, Validation Loss = 0.1116\n",
            "Epoch 2494/2500\n",
            "Epoch 2494: Training Accuracy = 0.9883, Training Loss = 0.0799, Validation Accuracy = 0.9901, Validation Loss = 0.1041\n",
            "Epoch 2495/2500\n",
            "Epoch 2495: Training Accuracy = 0.9883, Training Loss = 0.0799, Validation Accuracy = 0.9901, Validation Loss = 0.1041\n",
            "Epoch 2496/2500\n",
            "Epoch 2496: Training Accuracy = 0.9902, Training Loss = 0.0635, Validation Accuracy = 0.9901, Validation Loss = 0.1019\n",
            "Epoch 2497/2500\n",
            "Epoch 2497: Training Accuracy = 0.9902, Training Loss = 0.0644, Validation Accuracy = 0.9901, Validation Loss = 0.1010\n",
            "Epoch 2498/2500\n",
            "Epoch 2498: Training Accuracy = 0.9902, Training Loss = 0.0644, Validation Accuracy = 0.9901, Validation Loss = 0.1010\n",
            "Epoch 2499/2500\n",
            "Epoch 2499: Training Accuracy = 0.9961, Training Loss = 0.0419, Validation Accuracy = 0.9901, Validation Loss = 0.1009\n",
            "Epoch 2500/2500\n",
            "Epoch 2500: Training Accuracy = 0.9961, Training Loss = 0.0419, Validation Accuracy = 0.9901, Validation Loss = 0.1009\n",
            "Stopping early as maximum number of steps has been reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5回の結果を平均"
      ],
      "metadata": {
        "id": "1o8q1AfDbEnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "config = {\n",
        "    'operation': 'x/y',\n",
        "    'training_fraction': 0.3,\n",
        "    'prime': 97,\n",
        "    'num_layers': 2,\n",
        "    'dim_model': 128,\n",
        "    'num_heads': 4,\n",
        "    'batch_size': 512,\n",
        "    'learning_rate': 0.0005,\n",
        "    'weight_decay': 1,\n",
        "    'num_steps': 20000,  # int(1e6)\n",
        "    'max_epochs': int(1e8),\n",
        "    'record_frequency': 10,  # Frequency of recording metrics\n",
        "    'show_progress_bar': False,\n",
        "    'device': 'cpu',\n",
        "}\n",
        "\n",
        "# Define a function to run a single experiment and return metrics\n",
        "def run_experiment(config):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(device)\n",
        "\n",
        "    train_loader, val_loader = get_data(\n",
        "        config['operation'],\n",
        "        config['prime'],\n",
        "        config['training_fraction'],\n",
        "        config['batch_size']\n",
        "    )\n",
        "    model = Transformer(\n",
        "        num_layers=config['num_layers'],\n",
        "        dim_model=config['dim_model'],\n",
        "        num_heads=config['num_heads'],\n",
        "        num_tokens=config['prime'] + 2,\n",
        "        seq_len=5\n",
        "    ).to(device)\n",
        "    optimizer = optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=config['learning_rate'],\n",
        "        betas=(0.9, 0.98),\n",
        "        weight_decay=config['weight_decay']\n",
        "    )\n",
        "    scheduler = optim.lr_scheduler.LinearLR(\n",
        "        optimizer, start_factor=0.1, total_iters=9\n",
        "    )\n",
        "\n",
        "    num_epochs = min(config['max_epochs'], ceil(config['num_steps'] / len(train_loader)))\n",
        "\n",
        "    metrics = {\n",
        "        'training/accuracy': [],\n",
        "        'training/loss': [],\n",
        "        'validation/accuracy': [],\n",
        "        'validation/loss': []\n",
        "    }\n",
        "\n",
        "    step = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "        metrics, step = train(model, train_loader, optimizer, scheduler, val_loader, device, metrics, step, config['record_frequency'], config)\n",
        "\n",
        "        # Print metrics for the current epoch in a single line\n",
        "        train_acc = metrics['training/accuracy'][-1][1]\n",
        "        train_loss = metrics['training/loss'][-1][1]\n",
        "        val_acc = metrics['validation/accuracy'][-1][1] if len(metrics['validation/accuracy']) > 0 else 0\n",
        "        val_loss = metrics['validation/loss'][-1][1] if len(metrics['validation/loss']) > 0 else 0\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}: Training Accuracy = {train_acc:.4f}, Training Loss = {train_loss:.4f}, Validation Accuracy = {val_acc:.4f}, Validation Loss = {val_loss:.4f}\")\n",
        "\n",
        "        # Check if max number of steps is reached\n",
        "        if step >= config['num_steps']:\n",
        "            print(\"Stopping early as maximum number of steps has been reached.\")\n",
        "            break\n",
        "\n",
        "    # Ensure the final step is evaluated for training metrics\n",
        "    metrics['training/accuracy'].append((step, train_acc))\n",
        "    metrics['training/loss'].append((step, train_loss))\n",
        "    metrics = evaluate(model, val_loader, device, metrics, step)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Number of experiments to run\n",
        "num_experiments = 5\n",
        "\n",
        "# Initialize lists to collect metrics\n",
        "all_training_accuracy = []\n",
        "all_training_loss = []\n",
        "all_validation_accuracy = []\n",
        "all_validation_loss = []\n",
        "\n",
        "# Run experiments and collect metrics\n",
        "for i in range(num_experiments):\n",
        "    print(f\"Running experiment {i + 1}/{num_experiments}\")\n",
        "    metrics = run_experiment(config)\n",
        "\n",
        "    all_training_accuracy.append(np.array([acc for _, acc in metrics['training/accuracy']]))\n",
        "    all_training_loss.append(np.array([loss for _, loss in metrics['training/loss']]))\n",
        "    all_validation_accuracy.append(np.array([acc for _, acc in metrics['validation/accuracy']]))\n",
        "    all_validation_loss.append(np.array([loss for _, loss in metrics['validation/loss']]))\n",
        "\n",
        "# Convert lists to numpy arrays for easier manipulation\n",
        "all_training_accuracy = np.array(all_training_accuracy)\n",
        "all_training_loss = np.array(all_training_loss)\n",
        "all_validation_accuracy = np.array(all_validation_accuracy)\n",
        "all_validation_loss = np.array(all_validation_loss)\n",
        "\n",
        "# Calculate means\n",
        "mean_train_acc = np.mean(all_training_accuracy, axis=0)\n",
        "mean_train_loss = np.mean(all_training_loss, axis=0)\n",
        "mean_val_acc = np.mean(all_validation_accuracy, axis=0)\n",
        "mean_val_loss = np.mean(all_validation_loss, axis=0)\n",
        "\n",
        "# Plot metrics\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.semilogx(\n",
        "    [step for step, _ in metrics['training/accuracy']],\n",
        "    mean_train_acc * 100,\n",
        "    color='red', label='Train'\n",
        ")\n",
        "plt.semilogx(\n",
        "    [step for step, _ in metrics['validation/accuracy']],\n",
        "    mean_val_acc * 100,\n",
        "    color='green', label='Val'\n",
        ")\n",
        "plt.xlabel('Optimization Steps')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.title(f'Modular Division (training on {int(config[\"training_fraction\"] * 100)}% of data)')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.semilogx(\n",
        "    [step for step, _ in metrics['training/loss']],\n",
        "    mean_train_loss,\n",
        "    color='red', label='Train'\n",
        ")\n",
        "plt.semilogx(\n",
        "    [step for step, _ in metrics['validation/loss']],\n",
        "    mean_val_loss,\n",
        "    color='green', label='Val'\n",
        ")\n",
        "plt.xlabel('Optimization Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title(f'Modular Division (training on {int(config[\"training_fraction\"] * 100)}% of data)')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_2mEacNrYeDX",
        "outputId": "0827d3de-62f4-49c4-d2da-c751aef09baa"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "Epoch 835: Training Accuracy = 0.9961, Training Loss = 0.1525, Validation Accuracy = 0.0147, Validation Loss = 7.3906\n",
            "Epoch 836/3334\n",
            "Epoch 836: Training Accuracy = 0.9863, Training Loss = 0.1580, Validation Accuracy = 0.0134, Validation Loss = 7.4245\n",
            "Epoch 837/3334\n",
            "Epoch 837: Training Accuracy = 0.9922, Training Loss = 0.1263, Validation Accuracy = 0.0129, Validation Loss = 7.3962\n",
            "Epoch 838/3334\n",
            "Epoch 838: Training Accuracy = 0.9922, Training Loss = 0.1263, Validation Accuracy = 0.0129, Validation Loss = 7.3962\n",
            "Epoch 839/3334\n",
            "Epoch 839: Training Accuracy = 0.9980, Training Loss = 0.1021, Validation Accuracy = 0.0140, Validation Loss = 7.4108\n",
            "Epoch 840/3334\n",
            "Epoch 840: Training Accuracy = 0.9980, Training Loss = 0.1021, Validation Accuracy = 0.0140, Validation Loss = 7.4108\n",
            "Epoch 841/3334\n",
            "Epoch 841: Training Accuracy = 0.9844, Training Loss = 0.1484, Validation Accuracy = 0.0138, Validation Loss = 7.3988\n",
            "Epoch 842/3334\n",
            "Epoch 842: Training Accuracy = 0.9922, Training Loss = 0.1262, Validation Accuracy = 0.0143, Validation Loss = 7.3712\n",
            "Epoch 843/3334\n",
            "Epoch 843: Training Accuracy = 0.9922, Training Loss = 0.1262, Validation Accuracy = 0.0143, Validation Loss = 7.3712\n",
            "Epoch 844/3334\n",
            "Epoch 844: Training Accuracy = 0.9863, Training Loss = 0.1521, Validation Accuracy = 0.0132, Validation Loss = 7.3700\n",
            "Epoch 845/3334\n",
            "Epoch 845: Training Accuracy = 0.9863, Training Loss = 0.1521, Validation Accuracy = 0.0132, Validation Loss = 7.3700\n",
            "Epoch 846/3334\n",
            "Epoch 846: Training Accuracy = 0.9922, Training Loss = 0.1550, Validation Accuracy = 0.0129, Validation Loss = 7.3179\n",
            "Epoch 847/3334\n",
            "Epoch 847: Training Accuracy = 0.9902, Training Loss = 0.1588, Validation Accuracy = 0.0135, Validation Loss = 7.2931\n",
            "Epoch 848/3334\n",
            "Epoch 848: Training Accuracy = 0.9902, Training Loss = 0.1588, Validation Accuracy = 0.0135, Validation Loss = 7.2931\n",
            "Epoch 849/3334\n",
            "Epoch 849: Training Accuracy = 0.8594, Training Loss = 0.8644, Validation Accuracy = 0.0146, Validation Loss = 7.0153\n",
            "Epoch 850/3334\n",
            "Epoch 850: Training Accuracy = 0.8594, Training Loss = 0.8644, Validation Accuracy = 0.0146, Validation Loss = 7.0153\n",
            "Epoch 851/3334\n",
            "Epoch 851: Training Accuracy = 0.9492, Training Loss = 0.5626, Validation Accuracy = 0.0138, Validation Loss = 7.0516\n",
            "Epoch 852/3334\n",
            "Epoch 852: Training Accuracy = 0.9961, Training Loss = 0.2653, Validation Accuracy = 0.0134, Validation Loss = 7.2016\n",
            "Epoch 853/3334\n",
            "Epoch 853: Training Accuracy = 0.9961, Training Loss = 0.2653, Validation Accuracy = 0.0134, Validation Loss = 7.2016\n",
            "Epoch 854/3334\n",
            "Epoch 854: Training Accuracy = 0.9902, Training Loss = 0.1929, Validation Accuracy = 0.0146, Validation Loss = 7.3372\n",
            "Epoch 855/3334\n",
            "Epoch 855: Training Accuracy = 0.9902, Training Loss = 0.1929, Validation Accuracy = 0.0146, Validation Loss = 7.3372\n",
            "Epoch 856/3334\n",
            "Epoch 856: Training Accuracy = 0.9844, Training Loss = 0.1600, Validation Accuracy = 0.0135, Validation Loss = 7.3143\n",
            "Epoch 857/3334\n",
            "Epoch 857: Training Accuracy = 0.9844, Training Loss = 0.1552, Validation Accuracy = 0.0140, Validation Loss = 7.3852\n",
            "Epoch 858/3334\n",
            "Epoch 858: Training Accuracy = 0.9844, Training Loss = 0.1552, Validation Accuracy = 0.0140, Validation Loss = 7.3852\n",
            "Epoch 859/3334\n",
            "Epoch 859: Training Accuracy = 0.9883, Training Loss = 0.1255, Validation Accuracy = 0.0137, Validation Loss = 7.3814\n",
            "Epoch 860/3334\n",
            "Epoch 860: Training Accuracy = 0.9883, Training Loss = 0.1255, Validation Accuracy = 0.0137, Validation Loss = 7.3814\n",
            "Epoch 861/3334\n",
            "Epoch 861: Training Accuracy = 0.9941, Training Loss = 0.1012, Validation Accuracy = 0.0143, Validation Loss = 7.3631\n",
            "Epoch 862/3334\n",
            "Epoch 862: Training Accuracy = 0.9883, Training Loss = 0.1260, Validation Accuracy = 0.0138, Validation Loss = 7.3590\n",
            "Epoch 863/3334\n",
            "Epoch 863: Training Accuracy = 0.9883, Training Loss = 0.1260, Validation Accuracy = 0.0138, Validation Loss = 7.3590\n",
            "Epoch 864/3334\n",
            "Epoch 864: Training Accuracy = 0.9902, Training Loss = 0.1086, Validation Accuracy = 0.0140, Validation Loss = 7.3446\n",
            "Epoch 865/3334\n",
            "Epoch 865: Training Accuracy = 0.9902, Training Loss = 0.1086, Validation Accuracy = 0.0140, Validation Loss = 7.3446\n",
            "Epoch 866/3334\n",
            "Epoch 866: Training Accuracy = 0.9980, Training Loss = 0.0849, Validation Accuracy = 0.0140, Validation Loss = 7.3220\n",
            "Epoch 867/3334\n",
            "Epoch 867: Training Accuracy = 0.9941, Training Loss = 0.1553, Validation Accuracy = 0.0143, Validation Loss = 7.3207\n",
            "Epoch 868/3334\n",
            "Epoch 868: Training Accuracy = 0.9941, Training Loss = 0.1553, Validation Accuracy = 0.0143, Validation Loss = 7.3207\n",
            "Epoch 869/3334\n",
            "Epoch 869: Training Accuracy = 0.8262, Training Loss = 0.9543, Validation Accuracy = 0.0141, Validation Loss = 6.9962\n",
            "Epoch 870/3334\n",
            "Epoch 870: Training Accuracy = 0.8262, Training Loss = 0.9543, Validation Accuracy = 0.0141, Validation Loss = 6.9962\n",
            "Epoch 871/3334\n",
            "Epoch 871: Training Accuracy = 0.9395, Training Loss = 0.5227, Validation Accuracy = 0.0140, Validation Loss = 7.0364\n",
            "Epoch 872/3334\n",
            "Epoch 872: Training Accuracy = 0.9863, Training Loss = 0.2543, Validation Accuracy = 0.0141, Validation Loss = 7.1629\n",
            "Epoch 873/3334\n",
            "Epoch 873: Training Accuracy = 0.9863, Training Loss = 0.2543, Validation Accuracy = 0.0141, Validation Loss = 7.1629\n",
            "Epoch 874/3334\n",
            "Epoch 874: Training Accuracy = 0.9863, Training Loss = 0.1998, Validation Accuracy = 0.0143, Validation Loss = 7.2415\n",
            "Epoch 875/3334\n",
            "Epoch 875: Training Accuracy = 0.9863, Training Loss = 0.1998, Validation Accuracy = 0.0143, Validation Loss = 7.2415\n",
            "Epoch 876/3334\n",
            "Epoch 876: Training Accuracy = 0.9922, Training Loss = 0.1619, Validation Accuracy = 0.0135, Validation Loss = 7.3099\n",
            "Epoch 877/3334\n",
            "Epoch 877: Training Accuracy = 0.9902, Training Loss = 0.1383, Validation Accuracy = 0.0146, Validation Loss = 7.3257\n",
            "Epoch 878/3334\n",
            "Epoch 878: Training Accuracy = 0.9902, Training Loss = 0.1383, Validation Accuracy = 0.0146, Validation Loss = 7.3257\n",
            "Epoch 879/3334\n",
            "Epoch 879: Training Accuracy = 0.9902, Training Loss = 0.1212, Validation Accuracy = 0.0144, Validation Loss = 7.3275\n",
            "Epoch 880/3334\n",
            "Epoch 880: Training Accuracy = 0.9902, Training Loss = 0.1212, Validation Accuracy = 0.0144, Validation Loss = 7.3275\n",
            "Epoch 881/3334\n",
            "Epoch 881: Training Accuracy = 0.9883, Training Loss = 0.1216, Validation Accuracy = 0.0132, Validation Loss = 7.3038\n",
            "Epoch 882/3334\n",
            "Epoch 882: Training Accuracy = 0.9883, Training Loss = 0.1235, Validation Accuracy = 0.0140, Validation Loss = 7.2930\n",
            "Epoch 883/3334\n",
            "Epoch 883: Training Accuracy = 0.9883, Training Loss = 0.1235, Validation Accuracy = 0.0140, Validation Loss = 7.2930\n",
            "Epoch 884/3334\n",
            "Epoch 884: Training Accuracy = 0.9922, Training Loss = 0.1119, Validation Accuracy = 0.0141, Validation Loss = 7.2896\n",
            "Epoch 885/3334\n",
            "Epoch 885: Training Accuracy = 0.9922, Training Loss = 0.1119, Validation Accuracy = 0.0141, Validation Loss = 7.2896\n",
            "Epoch 886/3334\n",
            "Epoch 886: Training Accuracy = 0.9902, Training Loss = 0.1679, Validation Accuracy = 0.0150, Validation Loss = 7.2839\n",
            "Epoch 887/3334\n",
            "Epoch 887: Training Accuracy = 0.9844, Training Loss = 0.2350, Validation Accuracy = 0.0143, Validation Loss = 7.2526\n",
            "Epoch 888/3334\n",
            "Epoch 888: Training Accuracy = 0.9844, Training Loss = 0.2350, Validation Accuracy = 0.0143, Validation Loss = 7.2526\n",
            "Epoch 889/3334\n",
            "Epoch 889: Training Accuracy = 0.9922, Training Loss = 0.2363, Validation Accuracy = 0.0137, Validation Loss = 7.2331\n",
            "Epoch 890/3334\n",
            "Epoch 890: Training Accuracy = 0.9922, Training Loss = 0.2363, Validation Accuracy = 0.0137, Validation Loss = 7.2331\n",
            "Epoch 891/3334\n",
            "Epoch 891: Training Accuracy = 0.9844, Training Loss = 0.2092, Validation Accuracy = 0.0126, Validation Loss = 7.1726\n",
            "Epoch 892/3334\n",
            "Epoch 892: Training Accuracy = 0.9941, Training Loss = 0.1862, Validation Accuracy = 0.0150, Validation Loss = 7.2605\n",
            "Epoch 893/3334\n",
            "Epoch 893: Training Accuracy = 0.9941, Training Loss = 0.1862, Validation Accuracy = 0.0150, Validation Loss = 7.2605\n",
            "Epoch 894/3334\n",
            "Epoch 894: Training Accuracy = 0.9941, Training Loss = 0.1678, Validation Accuracy = 0.0143, Validation Loss = 7.2809\n",
            "Epoch 895/3334\n",
            "Epoch 895: Training Accuracy = 0.9941, Training Loss = 0.1678, Validation Accuracy = 0.0143, Validation Loss = 7.2809\n",
            "Epoch 896/3334\n",
            "Epoch 896: Training Accuracy = 0.9883, Training Loss = 0.1345, Validation Accuracy = 0.0141, Validation Loss = 7.2559\n",
            "Epoch 897/3334\n",
            "Epoch 897: Training Accuracy = 0.9922, Training Loss = 0.1151, Validation Accuracy = 0.0155, Validation Loss = 7.3453\n",
            "Epoch 898/3334\n",
            "Epoch 898: Training Accuracy = 0.9922, Training Loss = 0.1151, Validation Accuracy = 0.0155, Validation Loss = 7.3453\n",
            "Epoch 899/3334\n",
            "Epoch 899: Training Accuracy = 0.9883, Training Loss = 0.1196, Validation Accuracy = 0.0146, Validation Loss = 7.3408\n",
            "Epoch 900/3334\n",
            "Epoch 900: Training Accuracy = 0.9883, Training Loss = 0.1196, Validation Accuracy = 0.0146, Validation Loss = 7.3408\n",
            "Epoch 901/3334\n",
            "Epoch 901: Training Accuracy = 0.9922, Training Loss = 0.1312, Validation Accuracy = 0.0152, Validation Loss = 7.3285\n",
            "Epoch 902/3334\n",
            "Epoch 902: Training Accuracy = 0.9922, Training Loss = 0.1447, Validation Accuracy = 0.0143, Validation Loss = 7.3210\n",
            "Epoch 903/3334\n",
            "Epoch 903: Training Accuracy = 0.9922, Training Loss = 0.1447, Validation Accuracy = 0.0143, Validation Loss = 7.3210\n",
            "Epoch 904/3334\n",
            "Epoch 904: Training Accuracy = 0.9902, Training Loss = 0.1398, Validation Accuracy = 0.0153, Validation Loss = 7.3206\n",
            "Epoch 905/3334\n",
            "Epoch 905: Training Accuracy = 0.9902, Training Loss = 0.1398, Validation Accuracy = 0.0153, Validation Loss = 7.3206\n",
            "Epoch 906/3334\n",
            "Epoch 906: Training Accuracy = 0.9824, Training Loss = 0.1928, Validation Accuracy = 0.0155, Validation Loss = 7.3179\n",
            "Epoch 907/3334\n",
            "Epoch 907: Training Accuracy = 0.9824, Training Loss = 0.2165, Validation Accuracy = 0.0146, Validation Loss = 7.2271\n",
            "Epoch 908/3334\n",
            "Epoch 908: Training Accuracy = 0.9824, Training Loss = 0.2165, Validation Accuracy = 0.0146, Validation Loss = 7.2271\n",
            "Epoch 909/3334\n",
            "Epoch 909: Training Accuracy = 0.9844, Training Loss = 0.2349, Validation Accuracy = 0.0137, Validation Loss = 7.3533\n",
            "Epoch 910/3334\n",
            "Epoch 910: Training Accuracy = 0.9844, Training Loss = 0.2349, Validation Accuracy = 0.0137, Validation Loss = 7.3533\n",
            "Epoch 911/3334\n",
            "Epoch 911: Training Accuracy = 0.9609, Training Loss = 0.4008, Validation Accuracy = 0.0134, Validation Loss = 7.1347\n",
            "Epoch 912/3334\n",
            "Epoch 912: Training Accuracy = 0.9551, Training Loss = 0.3808, Validation Accuracy = 0.0135, Validation Loss = 7.2436\n",
            "Epoch 913/3334\n",
            "Epoch 913: Training Accuracy = 0.9551, Training Loss = 0.3808, Validation Accuracy = 0.0135, Validation Loss = 7.2436\n",
            "Epoch 914/3334\n",
            "Epoch 914: Training Accuracy = 0.9922, Training Loss = 0.1820, Validation Accuracy = 0.0144, Validation Loss = 7.3467\n",
            "Epoch 915/3334\n",
            "Epoch 915: Training Accuracy = 0.9922, Training Loss = 0.1820, Validation Accuracy = 0.0144, Validation Loss = 7.3467\n",
            "Epoch 916/3334\n",
            "Epoch 916: Training Accuracy = 0.9844, Training Loss = 0.1526, Validation Accuracy = 0.0140, Validation Loss = 7.3427\n",
            "Epoch 917/3334\n",
            "Epoch 917: Training Accuracy = 0.9883, Training Loss = 0.1242, Validation Accuracy = 0.0143, Validation Loss = 7.4268\n",
            "Epoch 918/3334\n",
            "Epoch 918: Training Accuracy = 0.9883, Training Loss = 0.1242, Validation Accuracy = 0.0143, Validation Loss = 7.4268\n",
            "Epoch 919/3334\n",
            "Epoch 919: Training Accuracy = 0.9805, Training Loss = 0.1331, Validation Accuracy = 0.0143, Validation Loss = 7.4667\n",
            "Epoch 920/3334\n",
            "Epoch 920: Training Accuracy = 0.9805, Training Loss = 0.1331, Validation Accuracy = 0.0143, Validation Loss = 7.4667\n",
            "Epoch 921/3334\n",
            "Epoch 921: Training Accuracy = 0.9902, Training Loss = 0.0919, Validation Accuracy = 0.0146, Validation Loss = 7.4580\n",
            "Epoch 922/3334\n",
            "Epoch 922: Training Accuracy = 0.9883, Training Loss = 0.0970, Validation Accuracy = 0.0144, Validation Loss = 7.4439\n",
            "Epoch 923/3334\n",
            "Epoch 923: Training Accuracy = 0.9883, Training Loss = 0.0970, Validation Accuracy = 0.0144, Validation Loss = 7.4439\n",
            "Epoch 924/3334\n",
            "Epoch 924: Training Accuracy = 0.9844, Training Loss = 0.1059, Validation Accuracy = 0.0147, Validation Loss = 7.4331\n",
            "Epoch 925/3334\n",
            "Epoch 925: Training Accuracy = 0.9844, Training Loss = 0.1059, Validation Accuracy = 0.0147, Validation Loss = 7.4331\n",
            "Epoch 926/3334\n",
            "Epoch 926: Training Accuracy = 0.9961, Training Loss = 0.0872, Validation Accuracy = 0.0146, Validation Loss = 7.4392\n",
            "Epoch 927/3334\n",
            "Epoch 927: Training Accuracy = 0.9922, Training Loss = 0.1595, Validation Accuracy = 0.0155, Validation Loss = 7.3420\n",
            "Epoch 928/3334\n",
            "Epoch 928: Training Accuracy = 0.9922, Training Loss = 0.1595, Validation Accuracy = 0.0155, Validation Loss = 7.3420\n",
            "Epoch 929/3334\n",
            "Epoch 929: Training Accuracy = 0.9199, Training Loss = 0.5543, Validation Accuracy = 0.0138, Validation Loss = 7.0607\n",
            "Epoch 930/3334\n",
            "Epoch 930: Training Accuracy = 0.9199, Training Loss = 0.5543, Validation Accuracy = 0.0138, Validation Loss = 7.0607\n",
            "Epoch 931/3334\n",
            "Epoch 931: Training Accuracy = 0.9863, Training Loss = 0.2745, Validation Accuracy = 0.0140, Validation Loss = 7.1882\n",
            "Epoch 932/3334\n",
            "Epoch 932: Training Accuracy = 0.9844, Training Loss = 0.2100, Validation Accuracy = 0.0146, Validation Loss = 7.3250\n",
            "Epoch 933/3334\n",
            "Epoch 933: Training Accuracy = 0.9844, Training Loss = 0.2100, Validation Accuracy = 0.0146, Validation Loss = 7.3250\n",
            "Epoch 934/3334\n",
            "Epoch 934: Training Accuracy = 1.0000, Training Loss = 0.0904, Validation Accuracy = 0.0138, Validation Loss = 7.3550\n",
            "Epoch 935/3334\n",
            "Epoch 935: Training Accuracy = 1.0000, Training Loss = 0.0904, Validation Accuracy = 0.0138, Validation Loss = 7.3550\n",
            "Epoch 936/3334\n",
            "Epoch 936: Training Accuracy = 0.9863, Training Loss = 0.1152, Validation Accuracy = 0.0138, Validation Loss = 7.3992\n",
            "Epoch 937/3334\n",
            "Epoch 937: Training Accuracy = 0.9922, Training Loss = 0.0978, Validation Accuracy = 0.0149, Validation Loss = 7.4245\n",
            "Epoch 938/3334\n",
            "Epoch 938: Training Accuracy = 0.9922, Training Loss = 0.0978, Validation Accuracy = 0.0149, Validation Loss = 7.4245\n",
            "Epoch 939/3334\n",
            "Epoch 939: Training Accuracy = 0.9922, Training Loss = 0.0778, Validation Accuracy = 0.0149, Validation Loss = 7.4257\n",
            "Epoch 940/3334\n",
            "Epoch 940: Training Accuracy = 0.9922, Training Loss = 0.0778, Validation Accuracy = 0.0149, Validation Loss = 7.4257\n",
            "Epoch 941/3334\n",
            "Epoch 941: Training Accuracy = 0.9863, Training Loss = 0.1051, Validation Accuracy = 0.0143, Validation Loss = 7.3858\n",
            "Epoch 942/3334\n",
            "Epoch 942: Training Accuracy = 0.9902, Training Loss = 0.0912, Validation Accuracy = 0.0144, Validation Loss = 7.3727\n",
            "Epoch 943/3334\n",
            "Epoch 943: Training Accuracy = 0.9902, Training Loss = 0.0912, Validation Accuracy = 0.0144, Validation Loss = 7.3727\n",
            "Epoch 944/3334\n",
            "Epoch 944: Training Accuracy = 0.9883, Training Loss = 0.1000, Validation Accuracy = 0.0138, Validation Loss = 7.3718\n",
            "Epoch 945/3334\n",
            "Epoch 945: Training Accuracy = 0.9883, Training Loss = 0.1000, Validation Accuracy = 0.0138, Validation Loss = 7.3718\n",
            "Epoch 946/3334\n",
            "Epoch 946: Training Accuracy = 0.9902, Training Loss = 0.0890, Validation Accuracy = 0.0150, Validation Loss = 7.3674\n",
            "Epoch 947/3334\n",
            "Epoch 947: Training Accuracy = 0.9883, Training Loss = 0.1114, Validation Accuracy = 0.0156, Validation Loss = 7.3352\n",
            "Epoch 948/3334\n",
            "Epoch 948: Training Accuracy = 0.9883, Training Loss = 0.1114, Validation Accuracy = 0.0156, Validation Loss = 7.3352\n",
            "Epoch 949/3334\n",
            "Epoch 949: Training Accuracy = 0.6289, Training Loss = 1.2967, Validation Accuracy = 0.0169, Validation Loss = 6.5858\n",
            "Epoch 950/3334\n",
            "Epoch 950: Training Accuracy = 0.6289, Training Loss = 1.2967, Validation Accuracy = 0.0169, Validation Loss = 6.5858\n",
            "Epoch 951/3334\n",
            "Epoch 951: Training Accuracy = 0.7578, Training Loss = 1.2007, Validation Accuracy = 0.0135, Validation Loss = 6.7028\n",
            "Epoch 952/3334\n",
            "Epoch 952: Training Accuracy = 0.9473, Training Loss = 0.5155, Validation Accuracy = 0.0140, Validation Loss = 6.9946\n",
            "Epoch 953/3334\n",
            "Epoch 953: Training Accuracy = 0.9473, Training Loss = 0.5155, Validation Accuracy = 0.0140, Validation Loss = 6.9946\n",
            "Epoch 954/3334\n",
            "Epoch 954: Training Accuracy = 0.9863, Training Loss = 0.2354, Validation Accuracy = 0.0141, Validation Loss = 7.1547\n",
            "Epoch 955/3334\n",
            "Epoch 955: Training Accuracy = 0.9863, Training Loss = 0.2354, Validation Accuracy = 0.0141, Validation Loss = 7.1547\n",
            "Epoch 956/3334\n",
            "Epoch 956: Training Accuracy = 0.9863, Training Loss = 0.1736, Validation Accuracy = 0.0152, Validation Loss = 7.2435\n",
            "Epoch 957/3334\n",
            "Epoch 957: Training Accuracy = 0.9883, Training Loss = 0.1475, Validation Accuracy = 0.0143, Validation Loss = 7.2859\n",
            "Epoch 958/3334\n",
            "Epoch 958: Training Accuracy = 0.9883, Training Loss = 0.1475, Validation Accuracy = 0.0143, Validation Loss = 7.2859\n",
            "Epoch 959/3334\n",
            "Epoch 959: Training Accuracy = 0.9922, Training Loss = 0.1051, Validation Accuracy = 0.0144, Validation Loss = 7.2920\n",
            "Epoch 960/3334\n",
            "Epoch 960: Training Accuracy = 0.9922, Training Loss = 0.1051, Validation Accuracy = 0.0144, Validation Loss = 7.2920\n",
            "Epoch 961/3334\n",
            "Epoch 961: Training Accuracy = 0.9883, Training Loss = 0.1074, Validation Accuracy = 0.0149, Validation Loss = 7.2729\n",
            "Epoch 962/3334\n",
            "Epoch 962: Training Accuracy = 0.9883, Training Loss = 0.1108, Validation Accuracy = 0.0146, Validation Loss = 7.2781\n",
            "Epoch 963/3334\n",
            "Epoch 963: Training Accuracy = 0.9883, Training Loss = 0.1108, Validation Accuracy = 0.0146, Validation Loss = 7.2781\n",
            "Epoch 964/3334\n",
            "Epoch 964: Training Accuracy = 0.9922, Training Loss = 0.0937, Validation Accuracy = 0.0149, Validation Loss = 7.2551\n",
            "Epoch 965/3334\n",
            "Epoch 965: Training Accuracy = 0.9922, Training Loss = 0.0937, Validation Accuracy = 0.0149, Validation Loss = 7.2551\n",
            "Epoch 966/3334\n",
            "Epoch 966: Training Accuracy = 0.9902, Training Loss = 0.0923, Validation Accuracy = 0.0153, Validation Loss = 7.2333\n",
            "Epoch 967/3334\n",
            "Epoch 967: Training Accuracy = 0.9883, Training Loss = 0.1096, Validation Accuracy = 0.0144, Validation Loss = 7.2123\n",
            "Epoch 968/3334\n",
            "Epoch 968: Training Accuracy = 0.9883, Training Loss = 0.1096, Validation Accuracy = 0.0144, Validation Loss = 7.2123\n",
            "Epoch 969/3334\n",
            "Epoch 969: Training Accuracy = 0.9785, Training Loss = 0.1523, Validation Accuracy = 0.0152, Validation Loss = 7.2006\n",
            "Epoch 970/3334\n",
            "Epoch 970: Training Accuracy = 0.9785, Training Loss = 0.1523, Validation Accuracy = 0.0152, Validation Loss = 7.2006\n",
            "Epoch 971/3334\n",
            "Epoch 971: Training Accuracy = 0.9863, Training Loss = 0.1505, Validation Accuracy = 0.0156, Validation Loss = 7.1708\n",
            "Epoch 972/3334\n",
            "Epoch 972: Training Accuracy = 0.7090, Training Loss = 1.2161, Validation Accuracy = 0.0159, Validation Loss = 6.6796\n",
            "Epoch 973/3334\n",
            "Epoch 973: Training Accuracy = 0.7090, Training Loss = 1.2161, Validation Accuracy = 0.0159, Validation Loss = 6.6796\n",
            "Epoch 974/3334\n",
            "Epoch 974: Training Accuracy = 0.9062, Training Loss = 0.6480, Validation Accuracy = 0.0165, Validation Loss = 6.8419\n",
            "Epoch 975/3334\n",
            "Epoch 975: Training Accuracy = 0.9062, Training Loss = 0.6480, Validation Accuracy = 0.0165, Validation Loss = 6.8419\n",
            "Epoch 976/3334\n",
            "Epoch 976: Training Accuracy = 0.9863, Training Loss = 0.2639, Validation Accuracy = 0.0155, Validation Loss = 6.9699\n",
            "Epoch 977/3334\n",
            "Epoch 977: Training Accuracy = 0.9883, Training Loss = 0.1966, Validation Accuracy = 0.0147, Validation Loss = 7.1042\n",
            "Epoch 978/3334\n",
            "Epoch 978: Training Accuracy = 0.9883, Training Loss = 0.1966, Validation Accuracy = 0.0147, Validation Loss = 7.1042\n",
            "Epoch 979/3334\n",
            "Epoch 979: Training Accuracy = 0.9883, Training Loss = 0.1496, Validation Accuracy = 0.0146, Validation Loss = 7.1397\n",
            "Epoch 980/3334\n",
            "Epoch 980: Training Accuracy = 0.9883, Training Loss = 0.1496, Validation Accuracy = 0.0146, Validation Loss = 7.1397\n",
            "Epoch 981/3334\n",
            "Epoch 981: Training Accuracy = 0.9785, Training Loss = 0.1615, Validation Accuracy = 0.0155, Validation Loss = 7.1434\n",
            "Epoch 982/3334\n",
            "Epoch 982: Training Accuracy = 0.9902, Training Loss = 0.1120, Validation Accuracy = 0.0149, Validation Loss = 7.1439\n",
            "Epoch 983/3334\n",
            "Epoch 983: Training Accuracy = 0.9902, Training Loss = 0.1120, Validation Accuracy = 0.0149, Validation Loss = 7.1439\n",
            "Epoch 984/3334\n",
            "Epoch 984: Training Accuracy = 0.9883, Training Loss = 0.1123, Validation Accuracy = 0.0144, Validation Loss = 7.1461\n",
            "Epoch 985/3334\n",
            "Epoch 985: Training Accuracy = 0.9883, Training Loss = 0.1123, Validation Accuracy = 0.0144, Validation Loss = 7.1461\n",
            "Epoch 986/3334\n",
            "Epoch 986: Training Accuracy = 0.9922, Training Loss = 0.1034, Validation Accuracy = 0.0158, Validation Loss = 7.1450\n",
            "Epoch 987/3334\n",
            "Epoch 987: Training Accuracy = 0.9902, Training Loss = 0.1113, Validation Accuracy = 0.0152, Validation Loss = 7.1082\n",
            "Epoch 988/3334\n",
            "Epoch 988: Training Accuracy = 0.9902, Training Loss = 0.1113, Validation Accuracy = 0.0152, Validation Loss = 7.1082\n",
            "Epoch 989/3334\n",
            "Epoch 989: Training Accuracy = 0.9863, Training Loss = 0.1227, Validation Accuracy = 0.0144, Validation Loss = 7.0944\n",
            "Epoch 990/3334\n",
            "Epoch 990: Training Accuracy = 0.9863, Training Loss = 0.1227, Validation Accuracy = 0.0144, Validation Loss = 7.0944\n",
            "Epoch 991/3334\n",
            "Epoch 991: Training Accuracy = 0.9902, Training Loss = 0.1216, Validation Accuracy = 0.0155, Validation Loss = 7.0901\n",
            "Epoch 992/3334\n",
            "Epoch 992: Training Accuracy = 0.9961, Training Loss = 0.1615, Validation Accuracy = 0.0155, Validation Loss = 7.0386\n",
            "Epoch 993/3334\n",
            "Epoch 993: Training Accuracy = 0.9961, Training Loss = 0.1615, Validation Accuracy = 0.0155, Validation Loss = 7.0386\n",
            "Epoch 994/3334\n",
            "Epoch 994: Training Accuracy = 0.7949, Training Loss = 1.1421, Validation Accuracy = 0.0144, Validation Loss = 6.4270\n",
            "Epoch 995/3334\n",
            "Epoch 995: Training Accuracy = 0.7949, Training Loss = 1.1421, Validation Accuracy = 0.0144, Validation Loss = 6.4270\n",
            "Epoch 996/3334\n",
            "Epoch 996: Training Accuracy = 0.9766, Training Loss = 0.4134, Validation Accuracy = 0.0155, Validation Loss = 6.7427\n",
            "Epoch 997/3334\n",
            "Epoch 997: Training Accuracy = 0.9863, Training Loss = 0.2986, Validation Accuracy = 0.0152, Validation Loss = 6.8928\n",
            "Epoch 998/3334\n",
            "Epoch 998: Training Accuracy = 0.9863, Training Loss = 0.2986, Validation Accuracy = 0.0152, Validation Loss = 6.8928\n",
            "Epoch 999/3334\n",
            "Epoch 999: Training Accuracy = 0.9863, Training Loss = 0.1959, Validation Accuracy = 0.0153, Validation Loss = 6.9967\n",
            "Epoch 1000/3334\n",
            "Epoch 1000: Training Accuracy = 0.9863, Training Loss = 0.1959, Validation Accuracy = 0.0153, Validation Loss = 6.9967\n",
            "Epoch 1001/3334\n",
            "Epoch 1001: Training Accuracy = 0.9824, Training Loss = 0.1559, Validation Accuracy = 0.0144, Validation Loss = 7.0432\n",
            "Epoch 1002/3334\n",
            "Epoch 1002: Training Accuracy = 0.9961, Training Loss = 0.1029, Validation Accuracy = 0.0141, Validation Loss = 7.0134\n",
            "Epoch 1003/3334\n",
            "Epoch 1003: Training Accuracy = 0.9961, Training Loss = 0.1029, Validation Accuracy = 0.0141, Validation Loss = 7.0134\n",
            "Epoch 1004/3334\n",
            "Epoch 1004: Training Accuracy = 0.9883, Training Loss = 0.1181, Validation Accuracy = 0.0147, Validation Loss = 7.0568\n",
            "Epoch 1005/3334\n",
            "Epoch 1005: Training Accuracy = 0.9883, Training Loss = 0.1181, Validation Accuracy = 0.0147, Validation Loss = 7.0568\n",
            "Epoch 1006/3334\n",
            "Epoch 1006: Training Accuracy = 0.9863, Training Loss = 0.1208, Validation Accuracy = 0.0141, Validation Loss = 7.0340\n",
            "Epoch 1007/3334\n",
            "Epoch 1007: Training Accuracy = 0.9922, Training Loss = 0.1077, Validation Accuracy = 0.0146, Validation Loss = 6.9897\n",
            "Epoch 1008/3334\n",
            "Epoch 1008: Training Accuracy = 0.9922, Training Loss = 0.1077, Validation Accuracy = 0.0146, Validation Loss = 6.9897\n",
            "Epoch 1009/3334\n",
            "Epoch 1009: Training Accuracy = 0.9902, Training Loss = 0.1145, Validation Accuracy = 0.0150, Validation Loss = 6.9766\n",
            "Epoch 1010/3334\n",
            "Epoch 1010: Training Accuracy = 0.9902, Training Loss = 0.1145, Validation Accuracy = 0.0150, Validation Loss = 6.9766\n",
            "Epoch 1011/3334\n",
            "Epoch 1011: Training Accuracy = 0.9844, Training Loss = 0.1410, Validation Accuracy = 0.0153, Validation Loss = 6.9568\n",
            "Epoch 1012/3334\n",
            "Epoch 1012: Training Accuracy = 0.9883, Training Loss = 0.1452, Validation Accuracy = 0.0147, Validation Loss = 6.9518\n",
            "Epoch 1013/3334\n",
            "Epoch 1013: Training Accuracy = 0.9883, Training Loss = 0.1452, Validation Accuracy = 0.0147, Validation Loss = 6.9518\n",
            "Epoch 1014/3334\n",
            "Epoch 1014: Training Accuracy = 0.9883, Training Loss = 0.1731, Validation Accuracy = 0.0137, Validation Loss = 6.9334\n",
            "Epoch 1015/3334\n",
            "Epoch 1015: Training Accuracy = 0.9883, Training Loss = 0.1731, Validation Accuracy = 0.0137, Validation Loss = 6.9334\n",
            "Epoch 1016/3334\n",
            "Epoch 1016: Training Accuracy = 0.9902, Training Loss = 0.1632, Validation Accuracy = 0.0140, Validation Loss = 6.9857\n",
            "Epoch 1017/3334\n",
            "Epoch 1017: Training Accuracy = 0.7520, Training Loss = 1.1716, Validation Accuracy = 0.0162, Validation Loss = 6.5133\n",
            "Epoch 1018/3334\n",
            "Epoch 1018: Training Accuracy = 0.7520, Training Loss = 1.1716, Validation Accuracy = 0.0162, Validation Loss = 6.5133\n",
            "Epoch 1019/3334\n",
            "Epoch 1019: Training Accuracy = 0.9707, Training Loss = 0.4219, Validation Accuracy = 0.0153, Validation Loss = 6.7529\n",
            "Epoch 1020/3334\n",
            "Epoch 1020: Training Accuracy = 0.9707, Training Loss = 0.4219, Validation Accuracy = 0.0153, Validation Loss = 6.7529\n",
            "Epoch 1021/3334\n",
            "Epoch 1021: Training Accuracy = 0.9863, Training Loss = 0.2539, Validation Accuracy = 0.0149, Validation Loss = 6.8050\n",
            "Epoch 1022/3334\n",
            "Epoch 1022: Training Accuracy = 0.9883, Training Loss = 0.1724, Validation Accuracy = 0.0164, Validation Loss = 6.9645\n",
            "Epoch 1023/3334\n",
            "Epoch 1023: Training Accuracy = 0.9883, Training Loss = 0.1724, Validation Accuracy = 0.0164, Validation Loss = 6.9645\n",
            "Epoch 1024/3334\n",
            "Epoch 1024: Training Accuracy = 0.9941, Training Loss = 0.1049, Validation Accuracy = 0.0158, Validation Loss = 6.9743\n",
            "Epoch 1025/3334\n",
            "Epoch 1025: Training Accuracy = 0.9941, Training Loss = 0.1049, Validation Accuracy = 0.0158, Validation Loss = 6.9743\n",
            "Epoch 1026/3334\n",
            "Epoch 1026: Training Accuracy = 0.9980, Training Loss = 0.0817, Validation Accuracy = 0.0155, Validation Loss = 6.9827\n",
            "Epoch 1027/3334\n",
            "Epoch 1027: Training Accuracy = 0.9805, Training Loss = 0.1494, Validation Accuracy = 0.0161, Validation Loss = 6.9733\n",
            "Epoch 1028/3334\n",
            "Epoch 1028: Training Accuracy = 0.9805, Training Loss = 0.1494, Validation Accuracy = 0.0161, Validation Loss = 6.9733\n",
            "Epoch 1029/3334\n",
            "Epoch 1029: Training Accuracy = 0.9941, Training Loss = 0.0952, Validation Accuracy = 0.0150, Validation Loss = 6.9752\n",
            "Epoch 1030/3334\n",
            "Epoch 1030: Training Accuracy = 0.9941, Training Loss = 0.0952, Validation Accuracy = 0.0150, Validation Loss = 6.9752\n",
            "Epoch 1031/3334\n",
            "Epoch 1031: Training Accuracy = 0.9922, Training Loss = 0.0934, Validation Accuracy = 0.0147, Validation Loss = 6.9749\n",
            "Epoch 1032/3334\n",
            "Epoch 1032: Training Accuracy = 0.9961, Training Loss = 0.0874, Validation Accuracy = 0.0155, Validation Loss = 6.9640\n",
            "Epoch 1033/3334\n",
            "Epoch 1033: Training Accuracy = 0.9961, Training Loss = 0.0874, Validation Accuracy = 0.0155, Validation Loss = 6.9640\n",
            "Epoch 1034/3334\n",
            "Epoch 1034: Training Accuracy = 0.9863, Training Loss = 0.1229, Validation Accuracy = 0.0161, Validation Loss = 6.9345\n",
            "Epoch 1035/3334\n",
            "Epoch 1035: Training Accuracy = 0.9863, Training Loss = 0.1229, Validation Accuracy = 0.0161, Validation Loss = 6.9345\n",
            "Epoch 1036/3334\n",
            "Epoch 1036: Training Accuracy = 0.9844, Training Loss = 0.1523, Validation Accuracy = 0.0152, Validation Loss = 6.8874\n",
            "Epoch 1037/3334\n",
            "Epoch 1037: Training Accuracy = 0.9883, Training Loss = 0.1773, Validation Accuracy = 0.0149, Validation Loss = 6.9085\n",
            "Epoch 1038/3334\n",
            "Epoch 1038: Training Accuracy = 0.9883, Training Loss = 0.1773, Validation Accuracy = 0.0149, Validation Loss = 6.9085\n",
            "Epoch 1039/3334\n",
            "Epoch 1039: Training Accuracy = 0.7070, Training Loss = 1.6035, Validation Accuracy = 0.0165, Validation Loss = 6.2163\n",
            "Epoch 1040/3334\n",
            "Epoch 1040: Training Accuracy = 0.7070, Training Loss = 1.6035, Validation Accuracy = 0.0165, Validation Loss = 6.2163\n",
            "Epoch 1041/3334\n",
            "Epoch 1041: Training Accuracy = 0.9375, Training Loss = 0.5267, Validation Accuracy = 0.0155, Validation Loss = 6.5485\n",
            "Epoch 1042/3334\n",
            "Epoch 1042: Training Accuracy = 0.9961, Training Loss = 0.2839, Validation Accuracy = 0.0153, Validation Loss = 6.6893\n",
            "Epoch 1043/3334\n",
            "Epoch 1043: Training Accuracy = 0.9961, Training Loss = 0.2839, Validation Accuracy = 0.0153, Validation Loss = 6.6893\n",
            "Epoch 1044/3334\n",
            "Epoch 1044: Training Accuracy = 0.9902, Training Loss = 0.1942, Validation Accuracy = 0.0159, Validation Loss = 6.7997\n",
            "Epoch 1045/3334\n",
            "Epoch 1045: Training Accuracy = 0.9902, Training Loss = 0.1942, Validation Accuracy = 0.0159, Validation Loss = 6.7997\n",
            "Epoch 1046/3334\n",
            "Epoch 1046: Training Accuracy = 0.9883, Training Loss = 0.1435, Validation Accuracy = 0.0153, Validation Loss = 6.8482\n",
            "Epoch 1047/3334\n",
            "Epoch 1047: Training Accuracy = 0.9863, Training Loss = 0.1428, Validation Accuracy = 0.0150, Validation Loss = 6.8634\n",
            "Epoch 1048/3334\n",
            "Epoch 1048: Training Accuracy = 0.9863, Training Loss = 0.1428, Validation Accuracy = 0.0150, Validation Loss = 6.8634\n",
            "Epoch 1049/3334\n",
            "Epoch 1049: Training Accuracy = 0.9902, Training Loss = 0.1111, Validation Accuracy = 0.0155, Validation Loss = 6.8815\n",
            "Epoch 1050/3334\n",
            "Epoch 1050: Training Accuracy = 0.9902, Training Loss = 0.1111, Validation Accuracy = 0.0155, Validation Loss = 6.8815\n",
            "Epoch 1051/3334\n",
            "Epoch 1051: Training Accuracy = 0.9922, Training Loss = 0.1047, Validation Accuracy = 0.0159, Validation Loss = 6.8564\n",
            "Epoch 1052/3334\n",
            "Epoch 1052: Training Accuracy = 0.9922, Training Loss = 0.1122, Validation Accuracy = 0.0156, Validation Loss = 6.8576\n",
            "Epoch 1053/3334\n",
            "Epoch 1053: Training Accuracy = 0.9922, Training Loss = 0.1122, Validation Accuracy = 0.0156, Validation Loss = 6.8576\n",
            "Epoch 1054/3334\n",
            "Epoch 1054: Training Accuracy = 0.9922, Training Loss = 0.1001, Validation Accuracy = 0.0149, Validation Loss = 6.8381\n",
            "Epoch 1055/3334\n",
            "Epoch 1055: Training Accuracy = 0.9922, Training Loss = 0.1001, Validation Accuracy = 0.0149, Validation Loss = 6.8381\n",
            "Epoch 1056/3334\n",
            "Epoch 1056: Training Accuracy = 0.9902, Training Loss = 0.1049, Validation Accuracy = 0.0162, Validation Loss = 6.8183\n",
            "Epoch 1057/3334\n",
            "Epoch 1057: Training Accuracy = 0.9980, Training Loss = 0.1013, Validation Accuracy = 0.0164, Validation Loss = 6.7988\n",
            "Epoch 1058/3334\n",
            "Epoch 1058: Training Accuracy = 0.9980, Training Loss = 0.1013, Validation Accuracy = 0.0164, Validation Loss = 6.7988\n",
            "Epoch 1059/3334\n",
            "Epoch 1059: Training Accuracy = 0.9902, Training Loss = 0.1595, Validation Accuracy = 0.0146, Validation Loss = 6.8137\n",
            "Epoch 1060/3334\n",
            "Epoch 1060: Training Accuracy = 0.9902, Training Loss = 0.1595, Validation Accuracy = 0.0146, Validation Loss = 6.8137\n",
            "Epoch 1061/3334\n",
            "Epoch 1061: Training Accuracy = 0.8945, Training Loss = 0.6915, Validation Accuracy = 0.0167, Validation Loss = 6.6525\n",
            "Epoch 1062/3334\n",
            "Epoch 1062: Training Accuracy = 0.9668, Training Loss = 0.4317, Validation Accuracy = 0.0156, Validation Loss = 6.5913\n",
            "Epoch 1063/3334\n",
            "Epoch 1063: Training Accuracy = 0.9668, Training Loss = 0.4317, Validation Accuracy = 0.0156, Validation Loss = 6.5913\n",
            "Epoch 1064/3334\n",
            "Epoch 1064: Training Accuracy = 0.9902, Training Loss = 0.2152, Validation Accuracy = 0.0150, Validation Loss = 6.6716\n",
            "Epoch 1065/3334\n",
            "Epoch 1065: Training Accuracy = 0.9902, Training Loss = 0.2152, Validation Accuracy = 0.0150, Validation Loss = 6.6716\n",
            "Epoch 1066/3334\n",
            "Epoch 1066: Training Accuracy = 0.9961, Training Loss = 0.1323, Validation Accuracy = 0.0158, Validation Loss = 6.7566\n",
            "Epoch 1067/3334\n",
            "Epoch 1067: Training Accuracy = 0.9902, Training Loss = 0.1295, Validation Accuracy = 0.0159, Validation Loss = 6.7922\n",
            "Epoch 1068/3334\n",
            "Epoch 1068: Training Accuracy = 0.9902, Training Loss = 0.1295, Validation Accuracy = 0.0159, Validation Loss = 6.7922\n",
            "Epoch 1069/3334\n",
            "Epoch 1069: Training Accuracy = 0.9863, Training Loss = 0.1231, Validation Accuracy = 0.0165, Validation Loss = 6.8031\n",
            "Epoch 1070/3334\n",
            "Epoch 1070: Training Accuracy = 0.9863, Training Loss = 0.1231, Validation Accuracy = 0.0165, Validation Loss = 6.8031\n",
            "Epoch 1071/3334\n",
            "Epoch 1071: Training Accuracy = 0.9941, Training Loss = 0.0874, Validation Accuracy = 0.0165, Validation Loss = 6.8242\n",
            "Epoch 1072/3334\n",
            "Epoch 1072: Training Accuracy = 0.9941, Training Loss = 0.0924, Validation Accuracy = 0.0159, Validation Loss = 6.8008\n",
            "Epoch 1073/3334\n",
            "Epoch 1073: Training Accuracy = 0.9941, Training Loss = 0.0924, Validation Accuracy = 0.0159, Validation Loss = 6.8008\n",
            "Epoch 1074/3334\n",
            "Epoch 1074: Training Accuracy = 0.9844, Training Loss = 0.1239, Validation Accuracy = 0.0158, Validation Loss = 6.7927\n",
            "Epoch 1075/3334\n",
            "Epoch 1075: Training Accuracy = 0.9844, Training Loss = 0.1239, Validation Accuracy = 0.0158, Validation Loss = 6.7927\n",
            "Epoch 1076/3334\n",
            "Epoch 1076: Training Accuracy = 0.9941, Training Loss = 0.0890, Validation Accuracy = 0.0155, Validation Loss = 6.7750\n",
            "Epoch 1077/3334\n",
            "Epoch 1077: Training Accuracy = 0.9883, Training Loss = 0.1510, Validation Accuracy = 0.0172, Validation Loss = 6.7547\n",
            "Epoch 1078/3334\n",
            "Epoch 1078: Training Accuracy = 0.9883, Training Loss = 0.1510, Validation Accuracy = 0.0172, Validation Loss = 6.7547\n",
            "Epoch 1079/3334\n",
            "Epoch 1079: Training Accuracy = 0.9941, Training Loss = 0.1976, Validation Accuracy = 0.0182, Validation Loss = 6.7495\n",
            "Epoch 1080/3334\n",
            "Epoch 1080: Training Accuracy = 0.9941, Training Loss = 0.1976, Validation Accuracy = 0.0182, Validation Loss = 6.7495\n",
            "Epoch 1081/3334\n",
            "Epoch 1081: Training Accuracy = 0.9609, Training Loss = 0.3754, Validation Accuracy = 0.0169, Validation Loss = 6.7226\n",
            "Epoch 1082/3334\n",
            "Epoch 1082: Training Accuracy = 0.9746, Training Loss = 0.3146, Validation Accuracy = 0.0156, Validation Loss = 6.6892\n",
            "Epoch 1083/3334\n",
            "Epoch 1083: Training Accuracy = 0.9746, Training Loss = 0.3146, Validation Accuracy = 0.0156, Validation Loss = 6.6892\n",
            "Epoch 1084/3334\n",
            "Epoch 1084: Training Accuracy = 0.9902, Training Loss = 0.1936, Validation Accuracy = 0.0155, Validation Loss = 6.7416\n",
            "Epoch 1085/3334\n",
            "Epoch 1085: Training Accuracy = 0.9902, Training Loss = 0.1936, Validation Accuracy = 0.0155, Validation Loss = 6.7416\n",
            "Epoch 1086/3334\n",
            "Epoch 1086: Training Accuracy = 0.9922, Training Loss = 0.1306, Validation Accuracy = 0.0162, Validation Loss = 6.7648\n",
            "Epoch 1087/3334\n",
            "Epoch 1087: Training Accuracy = 0.9922, Training Loss = 0.1171, Validation Accuracy = 0.0156, Validation Loss = 6.7918\n",
            "Epoch 1088/3334\n",
            "Epoch 1088: Training Accuracy = 0.9922, Training Loss = 0.1171, Validation Accuracy = 0.0156, Validation Loss = 6.7918\n",
            "Epoch 1089/3334\n",
            "Epoch 1089: Training Accuracy = 0.9902, Training Loss = 0.0982, Validation Accuracy = 0.0158, Validation Loss = 6.8019\n",
            "Epoch 1090/3334\n",
            "Epoch 1090: Training Accuracy = 0.9902, Training Loss = 0.0982, Validation Accuracy = 0.0158, Validation Loss = 6.8019\n",
            "Epoch 1091/3334\n",
            "Epoch 1091: Training Accuracy = 0.9883, Training Loss = 0.1004, Validation Accuracy = 0.0158, Validation Loss = 6.8196\n",
            "Epoch 1092/3334\n",
            "Epoch 1092: Training Accuracy = 0.9844, Training Loss = 0.1181, Validation Accuracy = 0.0152, Validation Loss = 6.8264\n",
            "Epoch 1093/3334\n",
            "Epoch 1093: Training Accuracy = 0.9844, Training Loss = 0.1181, Validation Accuracy = 0.0152, Validation Loss = 6.8264\n",
            "Epoch 1094/3334\n",
            "Epoch 1094: Training Accuracy = 0.9902, Training Loss = 0.1090, Validation Accuracy = 0.0158, Validation Loss = 6.7878\n",
            "Epoch 1095/3334\n",
            "Epoch 1095: Training Accuracy = 0.9902, Training Loss = 0.1090, Validation Accuracy = 0.0158, Validation Loss = 6.7878\n",
            "Epoch 1096/3334\n",
            "Epoch 1096: Training Accuracy = 0.9863, Training Loss = 0.1194, Validation Accuracy = 0.0172, Validation Loss = 6.8273\n",
            "Epoch 1097/3334\n",
            "Epoch 1097: Training Accuracy = 0.9844, Training Loss = 0.1475, Validation Accuracy = 0.0159, Validation Loss = 6.8136\n",
            "Epoch 1098/3334\n",
            "Epoch 1098: Training Accuracy = 0.9844, Training Loss = 0.1475, Validation Accuracy = 0.0159, Validation Loss = 6.8136\n",
            "Epoch 1099/3334\n",
            "Epoch 1099: Training Accuracy = 0.6641, Training Loss = 1.5216, Validation Accuracy = 0.0169, Validation Loss = 6.4399\n",
            "Epoch 1100/3334\n",
            "Epoch 1100: Training Accuracy = 0.6641, Training Loss = 1.5216, Validation Accuracy = 0.0169, Validation Loss = 6.4399\n",
            "Epoch 1101/3334\n",
            "Epoch 1101: Training Accuracy = 0.9258, Training Loss = 0.5453, Validation Accuracy = 0.0173, Validation Loss = 6.5372\n",
            "Epoch 1102/3334\n",
            "Epoch 1102: Training Accuracy = 0.9492, Training Loss = 0.4105, Validation Accuracy = 0.0170, Validation Loss = 6.6077\n",
            "Epoch 1103/3334\n",
            "Epoch 1103: Training Accuracy = 0.9492, Training Loss = 0.4105, Validation Accuracy = 0.0170, Validation Loss = 6.6077\n",
            "Epoch 1104/3334\n",
            "Epoch 1104: Training Accuracy = 0.9902, Training Loss = 0.1929, Validation Accuracy = 0.0158, Validation Loss = 6.6742\n",
            "Epoch 1105/3334\n",
            "Epoch 1105: Training Accuracy = 0.9902, Training Loss = 0.1929, Validation Accuracy = 0.0158, Validation Loss = 6.6742\n",
            "Epoch 1106/3334\n",
            "Epoch 1106: Training Accuracy = 0.9961, Training Loss = 0.1245, Validation Accuracy = 0.0167, Validation Loss = 6.6574\n",
            "Epoch 1107/3334\n",
            "Epoch 1107: Training Accuracy = 0.9961, Training Loss = 0.0971, Validation Accuracy = 0.0161, Validation Loss = 6.7091\n",
            "Epoch 1108/3334\n",
            "Epoch 1108: Training Accuracy = 0.9961, Training Loss = 0.0971, Validation Accuracy = 0.0161, Validation Loss = 6.7091\n",
            "Epoch 1109/3334\n",
            "Epoch 1109: Training Accuracy = 0.9961, Training Loss = 0.0829, Validation Accuracy = 0.0170, Validation Loss = 6.6815\n",
            "Epoch 1110/3334\n",
            "Epoch 1110: Training Accuracy = 0.9961, Training Loss = 0.0829, Validation Accuracy = 0.0170, Validation Loss = 6.6815\n",
            "Epoch 1111/3334\n",
            "Epoch 1111: Training Accuracy = 0.9844, Training Loss = 0.1157, Validation Accuracy = 0.0159, Validation Loss = 6.6859\n",
            "Epoch 1112/3334\n",
            "Epoch 1112: Training Accuracy = 0.9941, Training Loss = 0.0865, Validation Accuracy = 0.0162, Validation Loss = 6.6830\n",
            "Epoch 1113/3334\n",
            "Epoch 1113: Training Accuracy = 0.9941, Training Loss = 0.0865, Validation Accuracy = 0.0162, Validation Loss = 6.6830\n",
            "Epoch 1114/3334\n",
            "Epoch 1114: Training Accuracy = 0.9941, Training Loss = 0.0795, Validation Accuracy = 0.0150, Validation Loss = 6.6486\n",
            "Epoch 1115/3334\n",
            "Epoch 1115: Training Accuracy = 0.9941, Training Loss = 0.0795, Validation Accuracy = 0.0150, Validation Loss = 6.6486\n",
            "Epoch 1116/3334\n",
            "Epoch 1116: Training Accuracy = 0.9863, Training Loss = 0.1106, Validation Accuracy = 0.0152, Validation Loss = 6.6380\n",
            "Epoch 1117/3334\n",
            "Epoch 1117: Training Accuracy = 0.9941, Training Loss = 0.1004, Validation Accuracy = 0.0169, Validation Loss = 6.6475\n",
            "Epoch 1118/3334\n",
            "Epoch 1118: Training Accuracy = 0.9941, Training Loss = 0.1004, Validation Accuracy = 0.0169, Validation Loss = 6.6475\n",
            "Epoch 1119/3334\n",
            "Epoch 1119: Training Accuracy = 0.9961, Training Loss = 0.0849, Validation Accuracy = 0.0162, Validation Loss = 6.6221\n",
            "Epoch 1120/3334\n",
            "Epoch 1120: Training Accuracy = 0.9961, Training Loss = 0.0849, Validation Accuracy = 0.0162, Validation Loss = 6.6221\n",
            "Epoch 1121/3334\n",
            "Epoch 1121: Training Accuracy = 0.9844, Training Loss = 0.1850, Validation Accuracy = 0.0169, Validation Loss = 6.4942\n",
            "Epoch 1122/3334\n",
            "Epoch 1122: Training Accuracy = 0.7480, Training Loss = 1.1701, Validation Accuracy = 0.0172, Validation Loss = 6.2853\n",
            "Epoch 1123/3334\n",
            "Epoch 1123: Training Accuracy = 0.7480, Training Loss = 1.1701, Validation Accuracy = 0.0172, Validation Loss = 6.2853\n",
            "Epoch 1124/3334\n",
            "Epoch 1124: Training Accuracy = 0.9551, Training Loss = 0.4750, Validation Accuracy = 0.0175, Validation Loss = 6.2773\n",
            "Epoch 1125/3334\n",
            "Epoch 1125: Training Accuracy = 0.9551, Training Loss = 0.4750, Validation Accuracy = 0.0175, Validation Loss = 6.2773\n",
            "Epoch 1126/3334\n",
            "Epoch 1126: Training Accuracy = 0.9941, Training Loss = 0.2435, Validation Accuracy = 0.0161, Validation Loss = 6.4124\n",
            "Epoch 1127/3334\n",
            "Epoch 1127: Training Accuracy = 0.9863, Training Loss = 0.2108, Validation Accuracy = 0.0176, Validation Loss = 6.4654\n",
            "Epoch 1128/3334\n",
            "Epoch 1128: Training Accuracy = 0.9863, Training Loss = 0.2108, Validation Accuracy = 0.0176, Validation Loss = 6.4654\n",
            "Epoch 1129/3334\n",
            "Epoch 1129: Training Accuracy = 0.9922, Training Loss = 0.1398, Validation Accuracy = 0.0181, Validation Loss = 6.5105\n",
            "Epoch 1130/3334\n",
            "Epoch 1130: Training Accuracy = 0.9922, Training Loss = 0.1398, Validation Accuracy = 0.0181, Validation Loss = 6.5105\n",
            "Epoch 1131/3334\n",
            "Epoch 1131: Training Accuracy = 0.9922, Training Loss = 0.1080, Validation Accuracy = 0.0155, Validation Loss = 6.4978\n",
            "Epoch 1132/3334\n",
            "Epoch 1132: Training Accuracy = 0.9844, Training Loss = 0.1295, Validation Accuracy = 0.0178, Validation Loss = 6.5218\n",
            "Epoch 1133/3334\n",
            "Epoch 1133: Training Accuracy = 0.9844, Training Loss = 0.1295, Validation Accuracy = 0.0178, Validation Loss = 6.5218\n",
            "Epoch 1134/3334\n",
            "Epoch 1134: Training Accuracy = 0.9961, Training Loss = 0.0871, Validation Accuracy = 0.0167, Validation Loss = 6.5171\n",
            "Epoch 1135/3334\n",
            "Epoch 1135: Training Accuracy = 0.9961, Training Loss = 0.0871, Validation Accuracy = 0.0167, Validation Loss = 6.5171\n",
            "Epoch 1136/3334\n",
            "Epoch 1136: Training Accuracy = 0.9980, Training Loss = 0.0806, Validation Accuracy = 0.0170, Validation Loss = 6.4932\n",
            "Epoch 1137/3334\n",
            "Epoch 1137: Training Accuracy = 0.9902, Training Loss = 0.1168, Validation Accuracy = 0.0173, Validation Loss = 6.5017\n",
            "Epoch 1138/3334\n",
            "Epoch 1138: Training Accuracy = 0.9902, Training Loss = 0.1168, Validation Accuracy = 0.0173, Validation Loss = 6.5017\n",
            "Epoch 1139/3334\n",
            "Epoch 1139: Training Accuracy = 0.9883, Training Loss = 0.1099, Validation Accuracy = 0.0175, Validation Loss = 6.4826\n",
            "Epoch 1140/3334\n",
            "Epoch 1140: Training Accuracy = 0.9883, Training Loss = 0.1099, Validation Accuracy = 0.0175, Validation Loss = 6.4826\n",
            "Epoch 1141/3334\n",
            "Epoch 1141: Training Accuracy = 0.9863, Training Loss = 0.1377, Validation Accuracy = 0.0156, Validation Loss = 6.4582\n",
            "Epoch 1142/3334\n",
            "Epoch 1142: Training Accuracy = 0.9941, Training Loss = 0.1255, Validation Accuracy = 0.0188, Validation Loss = 6.4747\n",
            "Epoch 1143/3334\n",
            "Epoch 1143: Training Accuracy = 0.9941, Training Loss = 0.1255, Validation Accuracy = 0.0188, Validation Loss = 6.4747\n",
            "Epoch 1144/3334\n",
            "Epoch 1144: Training Accuracy = 0.9824, Training Loss = 0.1767, Validation Accuracy = 0.0178, Validation Loss = 6.4509\n",
            "Epoch 1145/3334\n",
            "Epoch 1145: Training Accuracy = 0.9824, Training Loss = 0.1767, Validation Accuracy = 0.0178, Validation Loss = 6.4509\n",
            "Epoch 1146/3334\n",
            "Epoch 1146: Training Accuracy = 0.8164, Training Loss = 1.0164, Validation Accuracy = 0.0193, Validation Loss = 6.1526\n",
            "Epoch 1147/3334\n",
            "Epoch 1147: Training Accuracy = 0.9746, Training Loss = 0.4387, Validation Accuracy = 0.0190, Validation Loss = 6.2304\n",
            "Epoch 1148/3334\n",
            "Epoch 1148: Training Accuracy = 0.9746, Training Loss = 0.4387, Validation Accuracy = 0.0190, Validation Loss = 6.2304\n",
            "Epoch 1149/3334\n",
            "Epoch 1149: Training Accuracy = 0.9844, Training Loss = 0.2449, Validation Accuracy = 0.0182, Validation Loss = 6.2792\n",
            "Epoch 1150/3334\n",
            "Epoch 1150: Training Accuracy = 0.9844, Training Loss = 0.2449, Validation Accuracy = 0.0182, Validation Loss = 6.2792\n",
            "Epoch 1151/3334\n",
            "Epoch 1151: Training Accuracy = 0.9941, Training Loss = 0.1491, Validation Accuracy = 0.0176, Validation Loss = 6.3179\n",
            "Epoch 1152/3334\n",
            "Epoch 1152: Training Accuracy = 0.9824, Training Loss = 0.1629, Validation Accuracy = 0.0172, Validation Loss = 6.3640\n",
            "Epoch 1153/3334\n",
            "Epoch 1153: Training Accuracy = 0.9824, Training Loss = 0.1629, Validation Accuracy = 0.0172, Validation Loss = 6.3640\n",
            "Epoch 1154/3334\n",
            "Epoch 1154: Training Accuracy = 0.9844, Training Loss = 0.1252, Validation Accuracy = 0.0178, Validation Loss = 6.4059\n",
            "Epoch 1155/3334\n",
            "Epoch 1155: Training Accuracy = 0.9844, Training Loss = 0.1252, Validation Accuracy = 0.0178, Validation Loss = 6.4059\n",
            "Epoch 1156/3334\n",
            "Epoch 1156: Training Accuracy = 0.9961, Training Loss = 0.0779, Validation Accuracy = 0.0169, Validation Loss = 6.4031\n",
            "Epoch 1157/3334\n",
            "Epoch 1157: Training Accuracy = 0.9941, Training Loss = 0.0890, Validation Accuracy = 0.0170, Validation Loss = 6.3899\n",
            "Epoch 1158/3334\n",
            "Epoch 1158: Training Accuracy = 0.9941, Training Loss = 0.0890, Validation Accuracy = 0.0170, Validation Loss = 6.3899\n",
            "Epoch 1159/3334\n",
            "Epoch 1159: Training Accuracy = 0.9805, Training Loss = 0.1342, Validation Accuracy = 0.0178, Validation Loss = 6.4018\n",
            "Epoch 1160/3334\n",
            "Epoch 1160: Training Accuracy = 0.9805, Training Loss = 0.1342, Validation Accuracy = 0.0178, Validation Loss = 6.4018\n",
            "Epoch 1161/3334\n",
            "Epoch 1161: Training Accuracy = 0.9922, Training Loss = 0.0889, Validation Accuracy = 0.0179, Validation Loss = 6.3907\n",
            "Epoch 1162/3334\n",
            "Epoch 1162: Training Accuracy = 0.9863, Training Loss = 0.1281, Validation Accuracy = 0.0167, Validation Loss = 6.3851\n",
            "Epoch 1163/3334\n",
            "Epoch 1163: Training Accuracy = 0.9863, Training Loss = 0.1281, Validation Accuracy = 0.0167, Validation Loss = 6.3851\n",
            "Epoch 1164/3334\n",
            "Epoch 1164: Training Accuracy = 0.9902, Training Loss = 0.1066, Validation Accuracy = 0.0176, Validation Loss = 6.3778\n",
            "Epoch 1165/3334\n",
            "Epoch 1165: Training Accuracy = 0.9902, Training Loss = 0.1066, Validation Accuracy = 0.0176, Validation Loss = 6.3778\n",
            "Epoch 1166/3334\n",
            "Epoch 1166: Training Accuracy = 0.9941, Training Loss = 0.1017, Validation Accuracy = 0.0188, Validation Loss = 6.3525\n",
            "Epoch 1167/3334\n",
            "Epoch 1167: Training Accuracy = 0.6855, Training Loss = 1.4622, Validation Accuracy = 0.0187, Validation Loss = 5.8177\n",
            "Epoch 1168/3334\n",
            "Epoch 1168: Training Accuracy = 0.6855, Training Loss = 1.4622, Validation Accuracy = 0.0187, Validation Loss = 5.8177\n",
            "Epoch 1169/3334\n",
            "Epoch 1169: Training Accuracy = 0.9512, Training Loss = 0.4686, Validation Accuracy = 0.0176, Validation Loss = 6.1754\n",
            "Epoch 1170/3334\n",
            "Epoch 1170: Training Accuracy = 0.9512, Training Loss = 0.4686, Validation Accuracy = 0.0176, Validation Loss = 6.1754\n",
            "Epoch 1171/3334\n",
            "Epoch 1171: Training Accuracy = 0.9668, Training Loss = 0.3704, Validation Accuracy = 0.0190, Validation Loss = 6.0759\n",
            "Epoch 1172/3334\n",
            "Epoch 1172: Training Accuracy = 0.9844, Training Loss = 0.2402, Validation Accuracy = 0.0178, Validation Loss = 6.2218\n",
            "Epoch 1173/3334\n",
            "Epoch 1173: Training Accuracy = 0.9844, Training Loss = 0.2402, Validation Accuracy = 0.0178, Validation Loss = 6.2218\n",
            "Epoch 1174/3334\n",
            "Epoch 1174: Training Accuracy = 0.9883, Training Loss = 0.1511, Validation Accuracy = 0.0181, Validation Loss = 6.2373\n",
            "Epoch 1175/3334\n",
            "Epoch 1175: Training Accuracy = 0.9883, Training Loss = 0.1511, Validation Accuracy = 0.0181, Validation Loss = 6.2373\n",
            "Epoch 1176/3334\n",
            "Epoch 1176: Training Accuracy = 0.9902, Training Loss = 0.1119, Validation Accuracy = 0.0188, Validation Loss = 6.2813\n",
            "Epoch 1177/3334\n",
            "Epoch 1177: Training Accuracy = 0.9883, Training Loss = 0.1253, Validation Accuracy = 0.0185, Validation Loss = 6.2723\n",
            "Epoch 1178/3334\n",
            "Epoch 1178: Training Accuracy = 0.9883, Training Loss = 0.1253, Validation Accuracy = 0.0185, Validation Loss = 6.2723\n",
            "Epoch 1179/3334\n",
            "Epoch 1179: Training Accuracy = 0.9863, Training Loss = 0.1171, Validation Accuracy = 0.0175, Validation Loss = 6.2850\n",
            "Epoch 1180/3334\n",
            "Epoch 1180: Training Accuracy = 0.9863, Training Loss = 0.1171, Validation Accuracy = 0.0175, Validation Loss = 6.2850\n",
            "Epoch 1181/3334\n",
            "Epoch 1181: Training Accuracy = 0.9922, Training Loss = 0.0886, Validation Accuracy = 0.0179, Validation Loss = 6.2777\n",
            "Epoch 1182/3334\n",
            "Epoch 1182: Training Accuracy = 0.9980, Training Loss = 0.0790, Validation Accuracy = 0.0182, Validation Loss = 6.2653\n",
            "Epoch 1183/3334\n",
            "Epoch 1183: Training Accuracy = 0.9980, Training Loss = 0.0790, Validation Accuracy = 0.0182, Validation Loss = 6.2653\n",
            "Epoch 1184/3334\n",
            "Epoch 1184: Training Accuracy = 0.9941, Training Loss = 0.0850, Validation Accuracy = 0.0190, Validation Loss = 6.2779\n",
            "Epoch 1185/3334\n",
            "Epoch 1185: Training Accuracy = 0.9941, Training Loss = 0.0850, Validation Accuracy = 0.0190, Validation Loss = 6.2779\n",
            "Epoch 1186/3334\n",
            "Epoch 1186: Training Accuracy = 0.9902, Training Loss = 0.1016, Validation Accuracy = 0.0196, Validation Loss = 6.2580\n",
            "Epoch 1187/3334\n",
            "Epoch 1187: Training Accuracy = 0.9863, Training Loss = 0.1300, Validation Accuracy = 0.0193, Validation Loss = 6.2363\n",
            "Epoch 1188/3334\n",
            "Epoch 1188: Training Accuracy = 0.9863, Training Loss = 0.1300, Validation Accuracy = 0.0193, Validation Loss = 6.2363\n",
            "Epoch 1189/3334\n",
            "Epoch 1189: Training Accuracy = 0.9844, Training Loss = 0.1831, Validation Accuracy = 0.0178, Validation Loss = 6.2467\n",
            "Epoch 1190/3334\n",
            "Epoch 1190: Training Accuracy = 0.9844, Training Loss = 0.1831, Validation Accuracy = 0.0178, Validation Loss = 6.2467\n",
            "Epoch 1191/3334\n",
            "Epoch 1191: Training Accuracy = 0.8848, Training Loss = 0.6851, Validation Accuracy = 0.0167, Validation Loss = 6.0857\n",
            "Epoch 1192/3334\n",
            "Epoch 1192: Training Accuracy = 0.9648, Training Loss = 0.4046, Validation Accuracy = 0.0179, Validation Loss = 6.0499\n",
            "Epoch 1193/3334\n",
            "Epoch 1193: Training Accuracy = 0.9648, Training Loss = 0.4046, Validation Accuracy = 0.0179, Validation Loss = 6.0499\n",
            "Epoch 1194/3334\n",
            "Epoch 1194: Training Accuracy = 0.9961, Training Loss = 0.1802, Validation Accuracy = 0.0184, Validation Loss = 6.0397\n",
            "Epoch 1195/3334\n",
            "Epoch 1195: Training Accuracy = 0.9961, Training Loss = 0.1802, Validation Accuracy = 0.0184, Validation Loss = 6.0397\n",
            "Epoch 1196/3334\n",
            "Epoch 1196: Training Accuracy = 0.9863, Training Loss = 0.1649, Validation Accuracy = 0.0196, Validation Loss = 6.1244\n",
            "Epoch 1197/3334\n",
            "Epoch 1197: Training Accuracy = 0.9902, Training Loss = 0.1230, Validation Accuracy = 0.0197, Validation Loss = 6.1318\n",
            "Epoch 1198/3334\n",
            "Epoch 1198: Training Accuracy = 0.9902, Training Loss = 0.1230, Validation Accuracy = 0.0197, Validation Loss = 6.1318\n",
            "Epoch 1199/3334\n",
            "Epoch 1199: Training Accuracy = 0.9922, Training Loss = 0.0993, Validation Accuracy = 0.0214, Validation Loss = 6.1265\n",
            "Epoch 1200/3334\n",
            "Epoch 1200: Training Accuracy = 0.9922, Training Loss = 0.0993, Validation Accuracy = 0.0214, Validation Loss = 6.1265\n",
            "Epoch 1201/3334\n",
            "Epoch 1201: Training Accuracy = 0.9961, Training Loss = 0.0747, Validation Accuracy = 0.0181, Validation Loss = 6.1633\n",
            "Epoch 1202/3334\n",
            "Epoch 1202: Training Accuracy = 0.9902, Training Loss = 0.0981, Validation Accuracy = 0.0194, Validation Loss = 6.1555\n",
            "Epoch 1203/3334\n",
            "Epoch 1203: Training Accuracy = 0.9902, Training Loss = 0.0981, Validation Accuracy = 0.0194, Validation Loss = 6.1555\n",
            "Epoch 1204/3334\n",
            "Epoch 1204: Training Accuracy = 0.9922, Training Loss = 0.0867, Validation Accuracy = 0.0197, Validation Loss = 6.1485\n",
            "Epoch 1205/3334\n",
            "Epoch 1205: Training Accuracy = 0.9922, Training Loss = 0.0867, Validation Accuracy = 0.0197, Validation Loss = 6.1485\n",
            "Epoch 1206/3334\n",
            "Epoch 1206: Training Accuracy = 0.9922, Training Loss = 0.0847, Validation Accuracy = 0.0197, Validation Loss = 6.1732\n",
            "Epoch 1207/3334\n",
            "Epoch 1207: Training Accuracy = 0.9883, Training Loss = 0.1168, Validation Accuracy = 0.0199, Validation Loss = 6.1391\n",
            "Epoch 1208/3334\n",
            "Epoch 1208: Training Accuracy = 0.9883, Training Loss = 0.1168, Validation Accuracy = 0.0199, Validation Loss = 6.1391\n",
            "Epoch 1209/3334\n",
            "Epoch 1209: Training Accuracy = 0.9902, Training Loss = 0.1132, Validation Accuracy = 0.0190, Validation Loss = 6.1684\n",
            "Epoch 1210/3334\n",
            "Epoch 1210: Training Accuracy = 0.9902, Training Loss = 0.1132, Validation Accuracy = 0.0190, Validation Loss = 6.1684\n",
            "Epoch 1211/3334\n",
            "Epoch 1211: Training Accuracy = 0.9941, Training Loss = 0.1072, Validation Accuracy = 0.0211, Validation Loss = 6.1435\n",
            "Epoch 1212/3334\n",
            "Epoch 1212: Training Accuracy = 0.9590, Training Loss = 0.3894, Validation Accuracy = 0.0228, Validation Loss = 6.1415\n",
            "Epoch 1213/3334\n",
            "Epoch 1213: Training Accuracy = 0.9590, Training Loss = 0.3894, Validation Accuracy = 0.0228, Validation Loss = 6.1415\n",
            "Epoch 1214/3334\n",
            "Epoch 1214: Training Accuracy = 0.8438, Training Loss = 0.9235, Validation Accuracy = 0.0187, Validation Loss = 5.8288\n",
            "Epoch 1215/3334\n",
            "Epoch 1215: Training Accuracy = 0.8438, Training Loss = 0.9235, Validation Accuracy = 0.0187, Validation Loss = 5.8288\n",
            "Epoch 1216/3334\n",
            "Epoch 1216: Training Accuracy = 0.9805, Training Loss = 0.3679, Validation Accuracy = 0.0216, Validation Loss = 5.7368\n",
            "Epoch 1217/3334\n",
            "Epoch 1217: Training Accuracy = 0.9727, Training Loss = 0.2683, Validation Accuracy = 0.0193, Validation Loss = 5.8863\n",
            "Epoch 1218/3334\n",
            "Epoch 1218: Training Accuracy = 0.9727, Training Loss = 0.2683, Validation Accuracy = 0.0193, Validation Loss = 5.8863\n",
            "Epoch 1219/3334\n",
            "Epoch 1219: Training Accuracy = 0.9863, Training Loss = 0.1747, Validation Accuracy = 0.0210, Validation Loss = 5.9299\n",
            "Epoch 1220/3334\n",
            "Epoch 1220: Training Accuracy = 0.9863, Training Loss = 0.1747, Validation Accuracy = 0.0210, Validation Loss = 5.9299\n",
            "Epoch 1221/3334\n",
            "Epoch 1221: Training Accuracy = 0.9883, Training Loss = 0.1315, Validation Accuracy = 0.0205, Validation Loss = 5.9856\n",
            "Epoch 1222/3334\n",
            "Epoch 1222: Training Accuracy = 0.9961, Training Loss = 0.0847, Validation Accuracy = 0.0203, Validation Loss = 6.0047\n",
            "Epoch 1223/3334\n",
            "Epoch 1223: Training Accuracy = 0.9961, Training Loss = 0.0847, Validation Accuracy = 0.0203, Validation Loss = 6.0047\n",
            "Epoch 1224/3334\n",
            "Epoch 1224: Training Accuracy = 0.9941, Training Loss = 0.0863, Validation Accuracy = 0.0206, Validation Loss = 5.9961\n",
            "Epoch 1225/3334\n",
            "Epoch 1225: Training Accuracy = 0.9941, Training Loss = 0.0863, Validation Accuracy = 0.0206, Validation Loss = 5.9961\n",
            "Epoch 1226/3334\n",
            "Epoch 1226: Training Accuracy = 0.9805, Training Loss = 0.1322, Validation Accuracy = 0.0205, Validation Loss = 5.9970\n",
            "Epoch 1227/3334\n",
            "Epoch 1227: Training Accuracy = 0.9863, Training Loss = 0.1135, Validation Accuracy = 0.0210, Validation Loss = 5.9926\n",
            "Epoch 1228/3334\n",
            "Epoch 1228: Training Accuracy = 0.9863, Training Loss = 0.1135, Validation Accuracy = 0.0210, Validation Loss = 5.9926\n",
            "Epoch 1229/3334\n",
            "Epoch 1229: Training Accuracy = 0.9941, Training Loss = 0.0813, Validation Accuracy = 0.0228, Validation Loss = 5.9915\n",
            "Epoch 1230/3334\n",
            "Epoch 1230: Training Accuracy = 0.9941, Training Loss = 0.0813, Validation Accuracy = 0.0228, Validation Loss = 5.9915\n",
            "Epoch 1231/3334\n",
            "Epoch 1231: Training Accuracy = 0.9902, Training Loss = 0.0904, Validation Accuracy = 0.0199, Validation Loss = 5.9902\n",
            "Epoch 1232/3334\n",
            "Epoch 1232: Training Accuracy = 0.9883, Training Loss = 0.1311, Validation Accuracy = 0.0214, Validation Loss = 5.9493\n",
            "Epoch 1233/3334\n",
            "Epoch 1233: Training Accuracy = 0.9883, Training Loss = 0.1311, Validation Accuracy = 0.0214, Validation Loss = 5.9493\n",
            "Epoch 1234/3334\n",
            "Epoch 1234: Training Accuracy = 0.9922, Training Loss = 0.1404, Validation Accuracy = 0.0222, Validation Loss = 5.9614\n",
            "Epoch 1235/3334\n",
            "Epoch 1235: Training Accuracy = 0.9922, Training Loss = 0.1404, Validation Accuracy = 0.0222, Validation Loss = 5.9614\n",
            "Epoch 1236/3334\n",
            "Epoch 1236: Training Accuracy = 0.7676, Training Loss = 1.0769, Validation Accuracy = 0.0213, Validation Loss = 5.6933\n",
            "Epoch 1237/3334\n",
            "Epoch 1237: Training Accuracy = 0.9551, Training Loss = 0.4675, Validation Accuracy = 0.0213, Validation Loss = 5.6333\n",
            "Epoch 1238/3334\n",
            "Epoch 1238: Training Accuracy = 0.9551, Training Loss = 0.4675, Validation Accuracy = 0.0213, Validation Loss = 5.6333\n",
            "Epoch 1239/3334\n",
            "Epoch 1239: Training Accuracy = 0.9766, Training Loss = 0.2775, Validation Accuracy = 0.0244, Validation Loss = 5.6861\n",
            "Epoch 1240/3334\n",
            "Epoch 1240: Training Accuracy = 0.9766, Training Loss = 0.2775, Validation Accuracy = 0.0244, Validation Loss = 5.6861\n",
            "Epoch 1241/3334\n",
            "Epoch 1241: Training Accuracy = 0.9922, Training Loss = 0.1637, Validation Accuracy = 0.0241, Validation Loss = 5.7299\n",
            "Epoch 1242/3334\n",
            "Epoch 1242: Training Accuracy = 0.9941, Training Loss = 0.1180, Validation Accuracy = 0.0222, Validation Loss = 5.8346\n",
            "Epoch 1243/3334\n",
            "Epoch 1243: Training Accuracy = 0.9941, Training Loss = 0.1180, Validation Accuracy = 0.0222, Validation Loss = 5.8346\n",
            "Epoch 1244/3334\n",
            "Epoch 1244: Training Accuracy = 0.9922, Training Loss = 0.1043, Validation Accuracy = 0.0226, Validation Loss = 5.8381\n",
            "Epoch 1245/3334\n",
            "Epoch 1245: Training Accuracy = 0.9922, Training Loss = 0.1043, Validation Accuracy = 0.0226, Validation Loss = 5.8381\n",
            "Epoch 1246/3334\n",
            "Epoch 1246: Training Accuracy = 0.9922, Training Loss = 0.0876, Validation Accuracy = 0.0211, Validation Loss = 5.8466\n",
            "Epoch 1247/3334\n",
            "Epoch 1247: Training Accuracy = 0.9961, Training Loss = 0.0785, Validation Accuracy = 0.0231, Validation Loss = 5.8507\n",
            "Epoch 1248/3334\n",
            "Epoch 1248: Training Accuracy = 0.9961, Training Loss = 0.0785, Validation Accuracy = 0.0231, Validation Loss = 5.8507\n",
            "Epoch 1249/3334\n",
            "Epoch 1249: Training Accuracy = 0.9883, Training Loss = 0.1001, Validation Accuracy = 0.0214, Validation Loss = 5.8660\n",
            "Epoch 1250/3334\n",
            "Epoch 1250: Training Accuracy = 0.9883, Training Loss = 0.1001, Validation Accuracy = 0.0214, Validation Loss = 5.8660\n",
            "Epoch 1251/3334\n",
            "Epoch 1251: Training Accuracy = 0.9863, Training Loss = 0.1070, Validation Accuracy = 0.0232, Validation Loss = 5.8302\n",
            "Epoch 1252/3334\n",
            "Epoch 1252: Training Accuracy = 0.9922, Training Loss = 0.1006, Validation Accuracy = 0.0220, Validation Loss = 5.8251\n",
            "Epoch 1253/3334\n",
            "Epoch 1253: Training Accuracy = 0.9922, Training Loss = 0.1006, Validation Accuracy = 0.0220, Validation Loss = 5.8251\n",
            "Epoch 1254/3334\n",
            "Epoch 1254: Training Accuracy = 0.9902, Training Loss = 0.0996, Validation Accuracy = 0.0240, Validation Loss = 5.8236\n",
            "Epoch 1255/3334\n",
            "Epoch 1255: Training Accuracy = 0.9902, Training Loss = 0.0996, Validation Accuracy = 0.0240, Validation Loss = 5.8236\n",
            "Epoch 1256/3334\n",
            "Epoch 1256: Training Accuracy = 0.9863, Training Loss = 0.1287, Validation Accuracy = 0.0237, Validation Loss = 5.7902\n",
            "Epoch 1257/3334\n",
            "Epoch 1257: Training Accuracy = 0.7168, Training Loss = 1.2507, Validation Accuracy = 0.0287, Validation Loss = 5.8816\n",
            "Epoch 1258/3334\n",
            "Epoch 1258: Training Accuracy = 0.7168, Training Loss = 1.2507, Validation Accuracy = 0.0287, Validation Loss = 5.8816\n",
            "Epoch 1259/3334\n",
            "Epoch 1259: Training Accuracy = 0.9062, Training Loss = 0.6574, Validation Accuracy = 0.0241, Validation Loss = 5.4690\n",
            "Epoch 1260/3334\n",
            "Epoch 1260: Training Accuracy = 0.9062, Training Loss = 0.6574, Validation Accuracy = 0.0241, Validation Loss = 5.4690\n",
            "Epoch 1261/3334\n",
            "Epoch 1261: Training Accuracy = 0.9902, Training Loss = 0.2884, Validation Accuracy = 0.0244, Validation Loss = 5.4592\n",
            "Epoch 1262/3334\n",
            "Epoch 1262: Training Accuracy = 0.9922, Training Loss = 0.2042, Validation Accuracy = 0.0247, Validation Loss = 5.5046\n",
            "Epoch 1263/3334\n",
            "Epoch 1263: Training Accuracy = 0.9922, Training Loss = 0.2042, Validation Accuracy = 0.0247, Validation Loss = 5.5046\n",
            "Epoch 1264/3334\n",
            "Epoch 1264: Training Accuracy = 0.9863, Training Loss = 0.1563, Validation Accuracy = 0.0266, Validation Loss = 5.5822\n",
            "Epoch 1265/3334\n",
            "Epoch 1265: Training Accuracy = 0.9863, Training Loss = 0.1563, Validation Accuracy = 0.0266, Validation Loss = 5.5822\n",
            "Epoch 1266/3334\n",
            "Epoch 1266: Training Accuracy = 0.9863, Training Loss = 0.1230, Validation Accuracy = 0.0229, Validation Loss = 5.6435\n",
            "Epoch 1267/3334\n",
            "Epoch 1267: Training Accuracy = 0.9805, Training Loss = 0.1403, Validation Accuracy = 0.0246, Validation Loss = 5.6714\n",
            "Epoch 1268/3334\n",
            "Epoch 1268: Training Accuracy = 0.9805, Training Loss = 0.1403, Validation Accuracy = 0.0246, Validation Loss = 5.6714\n",
            "Epoch 1269/3334\n",
            "Epoch 1269: Training Accuracy = 0.9902, Training Loss = 0.0998, Validation Accuracy = 0.0235, Validation Loss = 5.6843\n",
            "Epoch 1270/3334\n",
            "Epoch 1270: Training Accuracy = 0.9902, Training Loss = 0.0998, Validation Accuracy = 0.0235, Validation Loss = 5.6843\n",
            "Epoch 1271/3334\n",
            "Epoch 1271: Training Accuracy = 0.9961, Training Loss = 0.0715, Validation Accuracy = 0.0231, Validation Loss = 5.6765\n",
            "Epoch 1272/3334\n",
            "Epoch 1272: Training Accuracy = 0.9961, Training Loss = 0.0828, Validation Accuracy = 0.0244, Validation Loss = 5.6880\n",
            "Epoch 1273/3334\n",
            "Epoch 1273: Training Accuracy = 0.9961, Training Loss = 0.0828, Validation Accuracy = 0.0244, Validation Loss = 5.6880\n",
            "Epoch 1274/3334\n",
            "Epoch 1274: Training Accuracy = 0.9941, Training Loss = 0.0841, Validation Accuracy = 0.0260, Validation Loss = 5.6780\n",
            "Epoch 1275/3334\n",
            "Epoch 1275: Training Accuracy = 0.9941, Training Loss = 0.0841, Validation Accuracy = 0.0260, Validation Loss = 5.6780\n",
            "Epoch 1276/3334\n",
            "Epoch 1276: Training Accuracy = 0.9883, Training Loss = 0.1114, Validation Accuracy = 0.0246, Validation Loss = 5.6572\n",
            "Epoch 1277/3334\n",
            "Epoch 1277: Training Accuracy = 0.9922, Training Loss = 0.1121, Validation Accuracy = 0.0226, Validation Loss = 5.6859\n",
            "Epoch 1278/3334\n",
            "Epoch 1278: Training Accuracy = 0.9922, Training Loss = 0.1121, Validation Accuracy = 0.0226, Validation Loss = 5.6859\n",
            "Epoch 1279/3334\n",
            "Epoch 1279: Training Accuracy = 0.9883, Training Loss = 0.1683, Validation Accuracy = 0.0278, Validation Loss = 5.6934\n",
            "Epoch 1280/3334\n",
            "Epoch 1280: Training Accuracy = 0.9883, Training Loss = 0.1683, Validation Accuracy = 0.0278, Validation Loss = 5.6934\n",
            "Epoch 1281/3334\n",
            "Epoch 1281: Training Accuracy = 0.9160, Training Loss = 0.6232, Validation Accuracy = 0.0232, Validation Loss = 5.5868\n",
            "Epoch 1282/3334\n",
            "Epoch 1282: Training Accuracy = 0.9512, Training Loss = 0.4251, Validation Accuracy = 0.0270, Validation Loss = 5.4330\n",
            "Epoch 1283/3334\n",
            "Epoch 1283: Training Accuracy = 0.9512, Training Loss = 0.4251, Validation Accuracy = 0.0270, Validation Loss = 5.4330\n",
            "Epoch 1284/3334\n",
            "Epoch 1284: Training Accuracy = 0.9902, Training Loss = 0.2007, Validation Accuracy = 0.0264, Validation Loss = 5.4492\n",
            "Epoch 1285/3334\n",
            "Epoch 1285: Training Accuracy = 0.9902, Training Loss = 0.2007, Validation Accuracy = 0.0264, Validation Loss = 5.4492\n",
            "Epoch 1286/3334\n",
            "Epoch 1286: Training Accuracy = 0.9980, Training Loss = 0.1182, Validation Accuracy = 0.0267, Validation Loss = 5.4827\n",
            "Epoch 1287/3334\n",
            "Epoch 1287: Training Accuracy = 0.9824, Training Loss = 0.1547, Validation Accuracy = 0.0244, Validation Loss = 5.5208\n",
            "Epoch 1288/3334\n",
            "Epoch 1288: Training Accuracy = 0.9824, Training Loss = 0.1547, Validation Accuracy = 0.0244, Validation Loss = 5.5208\n",
            "Epoch 1289/3334\n",
            "Epoch 1289: Training Accuracy = 0.9883, Training Loss = 0.1070, Validation Accuracy = 0.0247, Validation Loss = 5.5540\n",
            "Epoch 1290/3334\n",
            "Epoch 1290: Training Accuracy = 0.9883, Training Loss = 0.1070, Validation Accuracy = 0.0247, Validation Loss = 5.5540\n",
            "Epoch 1291/3334\n",
            "Epoch 1291: Training Accuracy = 0.9922, Training Loss = 0.0867, Validation Accuracy = 0.0258, Validation Loss = 5.5984\n",
            "Epoch 1292/3334\n",
            "Epoch 1292: Training Accuracy = 0.9961, Training Loss = 0.0737, Validation Accuracy = 0.0254, Validation Loss = 5.5642\n",
            "Epoch 1293/3334\n",
            "Epoch 1293: Training Accuracy = 0.9961, Training Loss = 0.0737, Validation Accuracy = 0.0254, Validation Loss = 5.5642\n",
            "Epoch 1294/3334\n",
            "Epoch 1294: Training Accuracy = 0.9922, Training Loss = 0.0831, Validation Accuracy = 0.0260, Validation Loss = 5.5913\n",
            "Epoch 1295/3334\n",
            "Epoch 1295: Training Accuracy = 0.9922, Training Loss = 0.0831, Validation Accuracy = 0.0260, Validation Loss = 5.5913\n",
            "Epoch 1296/3334\n",
            "Epoch 1296: Training Accuracy = 0.9922, Training Loss = 0.0806, Validation Accuracy = 0.0272, Validation Loss = 5.5788\n",
            "Epoch 1297/3334\n",
            "Epoch 1297: Training Accuracy = 0.9902, Training Loss = 0.0949, Validation Accuracy = 0.0252, Validation Loss = 5.5947\n",
            "Epoch 1298/3334\n",
            "Epoch 1298: Training Accuracy = 0.9902, Training Loss = 0.0949, Validation Accuracy = 0.0252, Validation Loss = 5.5947\n",
            "Epoch 1299/3334\n",
            "Epoch 1299: Training Accuracy = 0.9902, Training Loss = 0.1040, Validation Accuracy = 0.0298, Validation Loss = 5.5811\n",
            "Epoch 1300/3334\n",
            "Epoch 1300: Training Accuracy = 0.9902, Training Loss = 0.1040, Validation Accuracy = 0.0298, Validation Loss = 5.5811\n",
            "Epoch 1301/3334\n",
            "Epoch 1301: Training Accuracy = 0.9902, Training Loss = 0.1148, Validation Accuracy = 0.0284, Validation Loss = 5.5735\n",
            "Epoch 1302/3334\n",
            "Epoch 1302: Training Accuracy = 0.9922, Training Loss = 0.1900, Validation Accuracy = 0.0311, Validation Loss = 5.7483\n",
            "Epoch 1303/3334\n",
            "Epoch 1303: Training Accuracy = 0.9922, Training Loss = 0.1900, Validation Accuracy = 0.0311, Validation Loss = 5.7483\n",
            "Epoch 1304/3334\n",
            "Epoch 1304: Training Accuracy = 0.7559, Training Loss = 1.0728, Validation Accuracy = 0.0266, Validation Loss = 5.4182\n",
            "Epoch 1305/3334\n",
            "Epoch 1305: Training Accuracy = 0.7559, Training Loss = 1.0728, Validation Accuracy = 0.0266, Validation Loss = 5.4182\n",
            "Epoch 1306/3334\n",
            "Epoch 1306: Training Accuracy = 0.9531, Training Loss = 0.4709, Validation Accuracy = 0.0329, Validation Loss = 5.1266\n",
            "Epoch 1307/3334\n",
            "Epoch 1307: Training Accuracy = 0.9805, Training Loss = 0.3020, Validation Accuracy = 0.0285, Validation Loss = 5.1966\n",
            "Epoch 1308/3334\n",
            "Epoch 1308: Training Accuracy = 0.9805, Training Loss = 0.3020, Validation Accuracy = 0.0285, Validation Loss = 5.1966\n",
            "Epoch 1309/3334\n",
            "Epoch 1309: Training Accuracy = 0.9941, Training Loss = 0.1581, Validation Accuracy = 0.0276, Validation Loss = 5.2548\n",
            "Epoch 1310/3334\n",
            "Epoch 1310: Training Accuracy = 0.9941, Training Loss = 0.1581, Validation Accuracy = 0.0276, Validation Loss = 5.2548\n",
            "Epoch 1311/3334\n",
            "Epoch 1311: Training Accuracy = 0.9922, Training Loss = 0.1213, Validation Accuracy = 0.0307, Validation Loss = 5.3239\n",
            "Epoch 1312/3334\n",
            "Epoch 1312: Training Accuracy = 0.9902, Training Loss = 0.1166, Validation Accuracy = 0.0266, Validation Loss = 5.3987\n",
            "Epoch 1313/3334\n",
            "Epoch 1313: Training Accuracy = 0.9902, Training Loss = 0.1166, Validation Accuracy = 0.0266, Validation Loss = 5.3987\n",
            "Epoch 1314/3334\n",
            "Epoch 1314: Training Accuracy = 0.9941, Training Loss = 0.0878, Validation Accuracy = 0.0295, Validation Loss = 5.3813\n",
            "Epoch 1315/3334\n",
            "Epoch 1315: Training Accuracy = 0.9941, Training Loss = 0.0878, Validation Accuracy = 0.0295, Validation Loss = 5.3813\n",
            "Epoch 1316/3334\n",
            "Epoch 1316: Training Accuracy = 0.9922, Training Loss = 0.0870, Validation Accuracy = 0.0288, Validation Loss = 5.3941\n",
            "Epoch 1317/3334\n",
            "Epoch 1317: Training Accuracy = 0.9922, Training Loss = 0.0920, Validation Accuracy = 0.0287, Validation Loss = 5.4151\n",
            "Epoch 1318/3334\n",
            "Epoch 1318: Training Accuracy = 0.9922, Training Loss = 0.0920, Validation Accuracy = 0.0287, Validation Loss = 5.4151\n",
            "Epoch 1319/3334\n",
            "Epoch 1319: Training Accuracy = 0.9883, Training Loss = 0.1052, Validation Accuracy = 0.0290, Validation Loss = 5.4200\n",
            "Epoch 1320/3334\n",
            "Epoch 1320: Training Accuracy = 0.9883, Training Loss = 0.1052, Validation Accuracy = 0.0290, Validation Loss = 5.4200\n",
            "Epoch 1321/3334\n",
            "Epoch 1321: Training Accuracy = 0.9883, Training Loss = 0.1075, Validation Accuracy = 0.0272, Validation Loss = 5.3807\n",
            "Epoch 1322/3334\n",
            "Epoch 1322: Training Accuracy = 0.9922, Training Loss = 0.1002, Validation Accuracy = 0.0287, Validation Loss = 5.3945\n",
            "Epoch 1323/3334\n",
            "Epoch 1323: Training Accuracy = 0.9922, Training Loss = 0.1002, Validation Accuracy = 0.0287, Validation Loss = 5.3945\n",
            "Epoch 1324/3334\n",
            "Epoch 1324: Training Accuracy = 0.9844, Training Loss = 0.1333, Validation Accuracy = 0.0285, Validation Loss = 5.4092\n",
            "Epoch 1325/3334\n",
            "Epoch 1325: Training Accuracy = 0.9844, Training Loss = 0.1333, Validation Accuracy = 0.0285, Validation Loss = 5.4092\n",
            "Epoch 1326/3334\n",
            "Epoch 1326: Training Accuracy = 0.9863, Training Loss = 0.1458, Validation Accuracy = 0.0282, Validation Loss = 5.3726\n",
            "Epoch 1327/3334\n",
            "Epoch 1327: Training Accuracy = 0.8262, Training Loss = 0.7591, Validation Accuracy = 0.0287, Validation Loss = 5.2992\n",
            "Epoch 1328/3334\n",
            "Epoch 1328: Training Accuracy = 0.8262, Training Loss = 0.7591, Validation Accuracy = 0.0287, Validation Loss = 5.2992\n",
            "Epoch 1329/3334\n",
            "Epoch 1329: Training Accuracy = 0.9551, Training Loss = 0.4393, Validation Accuracy = 0.0302, Validation Loss = 5.1334\n",
            "Epoch 1330/3334\n",
            "Epoch 1330: Training Accuracy = 0.9551, Training Loss = 0.4393, Validation Accuracy = 0.0302, Validation Loss = 5.1334\n",
            "Epoch 1331/3334\n",
            "Epoch 1331: Training Accuracy = 0.9883, Training Loss = 0.2196, Validation Accuracy = 0.0316, Validation Loss = 5.0460\n",
            "Epoch 1332/3334\n",
            "Epoch 1332: Training Accuracy = 0.9902, Training Loss = 0.1904, Validation Accuracy = 0.0310, Validation Loss = 5.1701\n",
            "Epoch 1333/3334\n",
            "Epoch 1333: Training Accuracy = 0.9902, Training Loss = 0.1904, Validation Accuracy = 0.0310, Validation Loss = 5.1701\n",
            "Epoch 1334/3334\n",
            "Epoch 1334: Training Accuracy = 0.9902, Training Loss = 0.1247, Validation Accuracy = 0.0329, Validation Loss = 5.2386\n",
            "Epoch 1335/3334\n",
            "Epoch 1335: Training Accuracy = 0.9902, Training Loss = 0.1247, Validation Accuracy = 0.0329, Validation Loss = 5.2386\n",
            "Epoch 1336/3334\n",
            "Epoch 1336: Training Accuracy = 0.9922, Training Loss = 0.0900, Validation Accuracy = 0.0302, Validation Loss = 5.2784\n",
            "Epoch 1337/3334\n",
            "Epoch 1337: Training Accuracy = 0.9922, Training Loss = 0.0943, Validation Accuracy = 0.0304, Validation Loss = 5.3054\n",
            "Epoch 1338/3334\n",
            "Epoch 1338: Training Accuracy = 0.9922, Training Loss = 0.0943, Validation Accuracy = 0.0304, Validation Loss = 5.3054\n",
            "Epoch 1339/3334\n",
            "Epoch 1339: Training Accuracy = 0.9785, Training Loss = 0.1329, Validation Accuracy = 0.0304, Validation Loss = 5.3216\n",
            "Epoch 1340/3334\n",
            "Epoch 1340: Training Accuracy = 0.9785, Training Loss = 0.1329, Validation Accuracy = 0.0304, Validation Loss = 5.3216\n",
            "Epoch 1341/3334\n",
            "Epoch 1341: Training Accuracy = 0.9863, Training Loss = 0.1011, Validation Accuracy = 0.0307, Validation Loss = 5.3057\n",
            "Epoch 1342/3334\n",
            "Epoch 1342: Training Accuracy = 0.9883, Training Loss = 0.0987, Validation Accuracy = 0.0299, Validation Loss = 5.3079\n",
            "Epoch 1343/3334\n",
            "Epoch 1343: Training Accuracy = 0.9883, Training Loss = 0.0987, Validation Accuracy = 0.0299, Validation Loss = 5.3079\n",
            "Epoch 1344/3334\n",
            "Epoch 1344: Training Accuracy = 0.9941, Training Loss = 0.0819, Validation Accuracy = 0.0311, Validation Loss = 5.3087\n",
            "Epoch 1345/3334\n",
            "Epoch 1345: Training Accuracy = 0.9941, Training Loss = 0.0819, Validation Accuracy = 0.0311, Validation Loss = 5.3087\n",
            "Epoch 1346/3334\n",
            "Epoch 1346: Training Accuracy = 0.9902, Training Loss = 0.1052, Validation Accuracy = 0.0304, Validation Loss = 5.3052\n",
            "Epoch 1347/3334\n",
            "Epoch 1347: Training Accuracy = 0.9863, Training Loss = 0.1349, Validation Accuracy = 0.0334, Validation Loss = 5.3397\n",
            "Epoch 1348/3334\n",
            "Epoch 1348: Training Accuracy = 0.9863, Training Loss = 0.1349, Validation Accuracy = 0.0334, Validation Loss = 5.3397\n",
            "Epoch 1349/3334\n",
            "Epoch 1349: Training Accuracy = 0.9863, Training Loss = 0.1775, Validation Accuracy = 0.0343, Validation Loss = 5.3080\n",
            "Epoch 1350/3334\n",
            "Epoch 1350: Training Accuracy = 0.9863, Training Loss = 0.1775, Validation Accuracy = 0.0343, Validation Loss = 5.3080\n",
            "Epoch 1351/3334\n",
            "Epoch 1351: Training Accuracy = 0.9805, Training Loss = 0.3313, Validation Accuracy = 0.0322, Validation Loss = 5.3259\n",
            "Epoch 1352/3334\n",
            "Epoch 1352: Training Accuracy = 0.9824, Training Loss = 0.2641, Validation Accuracy = 0.0370, Validation Loss = 4.9855\n",
            "Epoch 1353/3334\n",
            "Epoch 1353: Training Accuracy = 0.9824, Training Loss = 0.2641, Validation Accuracy = 0.0370, Validation Loss = 4.9855\n",
            "Epoch 1354/3334\n",
            "Epoch 1354: Training Accuracy = 0.9922, Training Loss = 0.1727, Validation Accuracy = 0.0383, Validation Loss = 5.0680\n",
            "Epoch 1355/3334\n",
            "Epoch 1355: Training Accuracy = 0.9922, Training Loss = 0.1727, Validation Accuracy = 0.0383, Validation Loss = 5.0680\n",
            "Epoch 1356/3334\n",
            "Epoch 1356: Training Accuracy = 0.9883, Training Loss = 0.1331, Validation Accuracy = 0.0337, Validation Loss = 5.1728\n",
            "Epoch 1357/3334\n",
            "Epoch 1357: Training Accuracy = 0.9922, Training Loss = 0.1066, Validation Accuracy = 0.0355, Validation Loss = 5.1858\n",
            "Epoch 1358/3334\n",
            "Epoch 1358: Training Accuracy = 0.9922, Training Loss = 0.1066, Validation Accuracy = 0.0355, Validation Loss = 5.1858\n",
            "Epoch 1359/3334\n",
            "Epoch 1359: Training Accuracy = 0.9863, Training Loss = 0.1048, Validation Accuracy = 0.0346, Validation Loss = 5.2640\n",
            "Epoch 1360/3334\n",
            "Epoch 1360: Training Accuracy = 0.9863, Training Loss = 0.1048, Validation Accuracy = 0.0346, Validation Loss = 5.2640\n",
            "Epoch 1361/3334\n",
            "Epoch 1361: Training Accuracy = 0.9941, Training Loss = 0.0724, Validation Accuracy = 0.0349, Validation Loss = 5.2469\n",
            "Epoch 1362/3334\n",
            "Epoch 1362: Training Accuracy = 0.9824, Training Loss = 0.1141, Validation Accuracy = 0.0354, Validation Loss = 5.2543\n",
            "Epoch 1363/3334\n",
            "Epoch 1363: Training Accuracy = 0.9824, Training Loss = 0.1141, Validation Accuracy = 0.0354, Validation Loss = 5.2543\n",
            "Epoch 1364/3334\n",
            "Epoch 1364: Training Accuracy = 0.9902, Training Loss = 0.0836, Validation Accuracy = 0.0329, Validation Loss = 5.2717\n",
            "Epoch 1365/3334\n",
            "Epoch 1365: Training Accuracy = 0.9902, Training Loss = 0.0836, Validation Accuracy = 0.0329, Validation Loss = 5.2717\n",
            "Epoch 1366/3334\n",
            "Epoch 1366: Training Accuracy = 0.9883, Training Loss = 0.0931, Validation Accuracy = 0.0308, Validation Loss = 5.2610\n",
            "Epoch 1367/3334\n",
            "Epoch 1367: Training Accuracy = 0.9922, Training Loss = 0.0826, Validation Accuracy = 0.0345, Validation Loss = 5.2132\n",
            "Epoch 1368/3334\n",
            "Epoch 1368: Training Accuracy = 0.9922, Training Loss = 0.0826, Validation Accuracy = 0.0345, Validation Loss = 5.2132\n",
            "Epoch 1369/3334\n",
            "Epoch 1369: Training Accuracy = 0.9863, Training Loss = 0.1095, Validation Accuracy = 0.0345, Validation Loss = 5.2592\n",
            "Epoch 1370/3334\n",
            "Epoch 1370: Training Accuracy = 0.9863, Training Loss = 0.1095, Validation Accuracy = 0.0345, Validation Loss = 5.2592\n",
            "Epoch 1371/3334\n",
            "Epoch 1371: Training Accuracy = 0.9902, Training Loss = 0.0974, Validation Accuracy = 0.0363, Validation Loss = 5.2367\n",
            "Epoch 1372/3334\n",
            "Epoch 1372: Training Accuracy = 0.3496, Training Loss = 3.3849, Validation Accuracy = 0.0240, Validation Loss = 4.8789\n",
            "Epoch 1373/3334\n",
            "Epoch 1373: Training Accuracy = 0.3496, Training Loss = 3.3849, Validation Accuracy = 0.0240, Validation Loss = 4.8789\n",
            "Epoch 1374/3334\n",
            "Epoch 1374: Training Accuracy = 0.8086, Training Loss = 1.0093, Validation Accuracy = 0.0393, Validation Loss = 4.5571\n",
            "Epoch 1375/3334\n",
            "Epoch 1375: Training Accuracy = 0.8086, Training Loss = 1.0093, Validation Accuracy = 0.0393, Validation Loss = 4.5571\n",
            "Epoch 1376/3334\n",
            "Epoch 1376: Training Accuracy = 0.9570, Training Loss = 0.4657, Validation Accuracy = 0.0437, Validation Loss = 4.5282\n",
            "Epoch 1377/3334\n",
            "Epoch 1377: Training Accuracy = 0.9824, Training Loss = 0.3220, Validation Accuracy = 0.0460, Validation Loss = 4.6760\n",
            "Epoch 1378/3334\n",
            "Epoch 1378: Training Accuracy = 0.9824, Training Loss = 0.3220, Validation Accuracy = 0.0460, Validation Loss = 4.6760\n",
            "Epoch 1379/3334\n",
            "Epoch 1379: Training Accuracy = 0.9844, Training Loss = 0.1874, Validation Accuracy = 0.0424, Validation Loss = 4.8430\n",
            "Epoch 1380/3334\n",
            "Epoch 1380: Training Accuracy = 0.9844, Training Loss = 0.1874, Validation Accuracy = 0.0424, Validation Loss = 4.8430\n",
            "Epoch 1381/3334\n",
            "Epoch 1381: Training Accuracy = 0.9922, Training Loss = 0.1313, Validation Accuracy = 0.0411, Validation Loss = 4.8640\n",
            "Epoch 1382/3334\n",
            "Epoch 1382: Training Accuracy = 0.9941, Training Loss = 0.1179, Validation Accuracy = 0.0401, Validation Loss = 4.9035\n",
            "Epoch 1383/3334\n",
            "Epoch 1383: Training Accuracy = 0.9941, Training Loss = 0.1179, Validation Accuracy = 0.0401, Validation Loss = 4.9035\n",
            "Epoch 1384/3334\n",
            "Epoch 1384: Training Accuracy = 0.9902, Training Loss = 0.1089, Validation Accuracy = 0.0419, Validation Loss = 4.9175\n",
            "Epoch 1385/3334\n",
            "Epoch 1385: Training Accuracy = 0.9902, Training Loss = 0.1089, Validation Accuracy = 0.0419, Validation Loss = 4.9175\n",
            "Epoch 1386/3334\n",
            "Epoch 1386: Training Accuracy = 0.9922, Training Loss = 0.0932, Validation Accuracy = 0.0373, Validation Loss = 4.9282\n",
            "Epoch 1387/3334\n",
            "Epoch 1387: Training Accuracy = 0.9883, Training Loss = 0.1174, Validation Accuracy = 0.0408, Validation Loss = 4.9388\n",
            "Epoch 1388/3334\n",
            "Epoch 1388: Training Accuracy = 0.9883, Training Loss = 0.1174, Validation Accuracy = 0.0408, Validation Loss = 4.9388\n",
            "Epoch 1389/3334\n",
            "Epoch 1389: Training Accuracy = 0.9941, Training Loss = 0.0790, Validation Accuracy = 0.0399, Validation Loss = 4.9358\n",
            "Epoch 1390/3334\n",
            "Epoch 1390: Training Accuracy = 0.9941, Training Loss = 0.0790, Validation Accuracy = 0.0399, Validation Loss = 4.9358\n",
            "Epoch 1391/3334\n",
            "Epoch 1391: Training Accuracy = 0.9922, Training Loss = 0.0947, Validation Accuracy = 0.0399, Validation Loss = 4.9273\n",
            "Epoch 1392/3334\n",
            "Epoch 1392: Training Accuracy = 0.9902, Training Loss = 0.1053, Validation Accuracy = 0.0416, Validation Loss = 4.9490\n",
            "Epoch 1393/3334\n",
            "Epoch 1393: Training Accuracy = 0.9902, Training Loss = 0.1053, Validation Accuracy = 0.0416, Validation Loss = 4.9490\n",
            "Epoch 1394/3334\n",
            "Epoch 1394: Training Accuracy = 0.9863, Training Loss = 0.1173, Validation Accuracy = 0.0389, Validation Loss = 4.9383\n",
            "Epoch 1395/3334\n",
            "Epoch 1395: Training Accuracy = 0.9863, Training Loss = 0.1173, Validation Accuracy = 0.0389, Validation Loss = 4.9383\n",
            "Epoch 1396/3334\n",
            "Epoch 1396: Training Accuracy = 0.9902, Training Loss = 0.1035, Validation Accuracy = 0.0413, Validation Loss = 4.9272\n",
            "Epoch 1397/3334\n",
            "Epoch 1397: Training Accuracy = 0.9922, Training Loss = 0.1263, Validation Accuracy = 0.0402, Validation Loss = 4.9556\n",
            "Epoch 1398/3334\n",
            "Epoch 1398: Training Accuracy = 0.9922, Training Loss = 0.1263, Validation Accuracy = 0.0402, Validation Loss = 4.9556\n",
            "Epoch 1399/3334\n",
            "Epoch 1399: Training Accuracy = 0.8789, Training Loss = 0.6681, Validation Accuracy = 0.0378, Validation Loss = 5.2355\n",
            "Epoch 1400/3334\n",
            "Epoch 1400: Training Accuracy = 0.8789, Training Loss = 0.6681, Validation Accuracy = 0.0378, Validation Loss = 5.2355\n",
            "Epoch 1401/3334\n",
            "Epoch 1401: Training Accuracy = 0.9766, Training Loss = 0.3268, Validation Accuracy = 0.0422, Validation Loss = 4.6502\n",
            "Epoch 1402/3334\n",
            "Epoch 1402: Training Accuracy = 0.9902, Training Loss = 0.2090, Validation Accuracy = 0.0431, Validation Loss = 4.6338\n",
            "Epoch 1403/3334\n",
            "Epoch 1403: Training Accuracy = 0.9902, Training Loss = 0.2090, Validation Accuracy = 0.0431, Validation Loss = 4.6338\n",
            "Epoch 1404/3334\n",
            "Epoch 1404: Training Accuracy = 0.9922, Training Loss = 0.1431, Validation Accuracy = 0.0436, Validation Loss = 4.7266\n",
            "Epoch 1405/3334\n",
            "Epoch 1405: Training Accuracy = 0.9922, Training Loss = 0.1431, Validation Accuracy = 0.0436, Validation Loss = 4.7266\n",
            "Epoch 1406/3334\n",
            "Epoch 1406: Training Accuracy = 0.9824, Training Loss = 0.1377, Validation Accuracy = 0.0422, Validation Loss = 4.8034\n",
            "Epoch 1407/3334\n",
            "Epoch 1407: Training Accuracy = 0.9902, Training Loss = 0.1022, Validation Accuracy = 0.0437, Validation Loss = 4.8147\n",
            "Epoch 1408/3334\n",
            "Epoch 1408: Training Accuracy = 0.9902, Training Loss = 0.1022, Validation Accuracy = 0.0437, Validation Loss = 4.8147\n",
            "Epoch 1409/3334\n",
            "Epoch 1409: Training Accuracy = 0.9902, Training Loss = 0.0917, Validation Accuracy = 0.0445, Validation Loss = 4.8489\n",
            "Epoch 1410/3334\n",
            "Epoch 1410: Training Accuracy = 0.9902, Training Loss = 0.0917, Validation Accuracy = 0.0445, Validation Loss = 4.8489\n",
            "Epoch 1411/3334\n",
            "Epoch 1411: Training Accuracy = 0.9922, Training Loss = 0.0856, Validation Accuracy = 0.0457, Validation Loss = 4.8480\n",
            "Epoch 1412/3334\n",
            "Epoch 1412: Training Accuracy = 0.9922, Training Loss = 0.0869, Validation Accuracy = 0.0431, Validation Loss = 4.8549\n",
            "Epoch 1413/3334\n",
            "Epoch 1413: Training Accuracy = 0.9922, Training Loss = 0.0869, Validation Accuracy = 0.0431, Validation Loss = 4.8549\n",
            "Epoch 1414/3334\n",
            "Epoch 1414: Training Accuracy = 0.9941, Training Loss = 0.0732, Validation Accuracy = 0.0422, Validation Loss = 4.8540\n",
            "Epoch 1415/3334\n",
            "Epoch 1415: Training Accuracy = 0.9941, Training Loss = 0.0732, Validation Accuracy = 0.0422, Validation Loss = 4.8540\n",
            "Epoch 1416/3334\n",
            "Epoch 1416: Training Accuracy = 0.9922, Training Loss = 0.0912, Validation Accuracy = 0.0442, Validation Loss = 4.8330\n",
            "Epoch 1417/3334\n",
            "Epoch 1417: Training Accuracy = 0.9883, Training Loss = 0.1181, Validation Accuracy = 0.0454, Validation Loss = 4.8309\n",
            "Epoch 1418/3334\n",
            "Epoch 1418: Training Accuracy = 0.9883, Training Loss = 0.1181, Validation Accuracy = 0.0454, Validation Loss = 4.8309\n",
            "Epoch 1419/3334\n",
            "Epoch 1419: Training Accuracy = 0.9941, Training Loss = 0.0942, Validation Accuracy = 0.0483, Validation Loss = 4.8568\n",
            "Epoch 1420/3334\n",
            "Epoch 1420: Training Accuracy = 0.9941, Training Loss = 0.0942, Validation Accuracy = 0.0483, Validation Loss = 4.8568\n",
            "Epoch 1421/3334\n",
            "Epoch 1421: Training Accuracy = 0.9922, Training Loss = 0.1642, Validation Accuracy = 0.0430, Validation Loss = 4.8854\n",
            "Epoch 1422/3334\n",
            "Epoch 1422: Training Accuracy = 0.9570, Training Loss = 0.4138, Validation Accuracy = 0.0506, Validation Loss = 4.8188\n",
            "Epoch 1423/3334\n",
            "Epoch 1423: Training Accuracy = 0.9570, Training Loss = 0.4138, Validation Accuracy = 0.0506, Validation Loss = 4.8188\n",
            "Epoch 1424/3334\n",
            "Epoch 1424: Training Accuracy = 0.9883, Training Loss = 0.2392, Validation Accuracy = 0.0486, Validation Loss = 4.6660\n",
            "Epoch 1425/3334\n",
            "Epoch 1425: Training Accuracy = 0.9883, Training Loss = 0.2392, Validation Accuracy = 0.0486, Validation Loss = 4.6660\n",
            "Epoch 1426/3334\n",
            "Epoch 1426: Training Accuracy = 0.9766, Training Loss = 0.1914, Validation Accuracy = 0.0495, Validation Loss = 4.6308\n",
            "Epoch 1427/3334\n",
            "Epoch 1427: Training Accuracy = 0.9883, Training Loss = 0.1489, Validation Accuracy = 0.0533, Validation Loss = 4.6927\n",
            "Epoch 1428/3334\n",
            "Epoch 1428: Training Accuracy = 0.9883, Training Loss = 0.1489, Validation Accuracy = 0.0533, Validation Loss = 4.6927\n",
            "Epoch 1429/3334\n",
            "Epoch 1429: Training Accuracy = 0.9883, Training Loss = 0.1041, Validation Accuracy = 0.0499, Validation Loss = 4.7313\n",
            "Epoch 1430/3334\n",
            "Epoch 1430: Training Accuracy = 0.9883, Training Loss = 0.1041, Validation Accuracy = 0.0499, Validation Loss = 4.7313\n",
            "Epoch 1431/3334\n",
            "Epoch 1431: Training Accuracy = 0.9922, Training Loss = 0.0806, Validation Accuracy = 0.0489, Validation Loss = 4.7513\n",
            "Epoch 1432/3334\n",
            "Epoch 1432: Training Accuracy = 0.9844, Training Loss = 0.1047, Validation Accuracy = 0.0475, Validation Loss = 4.7814\n",
            "Epoch 1433/3334\n",
            "Epoch 1433: Training Accuracy = 0.9844, Training Loss = 0.1047, Validation Accuracy = 0.0475, Validation Loss = 4.7814\n",
            "Epoch 1434/3334\n",
            "Epoch 1434: Training Accuracy = 0.9883, Training Loss = 0.0835, Validation Accuracy = 0.0489, Validation Loss = 4.7736\n",
            "Epoch 1435/3334\n",
            "Epoch 1435: Training Accuracy = 0.9883, Training Loss = 0.0835, Validation Accuracy = 0.0489, Validation Loss = 4.7736\n",
            "Epoch 1436/3334\n",
            "Epoch 1436: Training Accuracy = 0.9961, Training Loss = 0.0568, Validation Accuracy = 0.0501, Validation Loss = 4.7689\n",
            "Epoch 1437/3334\n",
            "Epoch 1437: Training Accuracy = 0.9902, Training Loss = 0.0830, Validation Accuracy = 0.0486, Validation Loss = 4.7660\n",
            "Epoch 1438/3334\n",
            "Epoch 1438: Training Accuracy = 0.9902, Training Loss = 0.0830, Validation Accuracy = 0.0486, Validation Loss = 4.7660\n",
            "Epoch 1439/3334\n",
            "Epoch 1439: Training Accuracy = 0.9863, Training Loss = 0.0933, Validation Accuracy = 0.0496, Validation Loss = 4.8057\n",
            "Epoch 1440/3334\n",
            "Epoch 1440: Training Accuracy = 0.9863, Training Loss = 0.0933, Validation Accuracy = 0.0496, Validation Loss = 4.8057\n",
            "Epoch 1441/3334\n",
            "Epoch 1441: Training Accuracy = 0.9902, Training Loss = 0.0935, Validation Accuracy = 0.0489, Validation Loss = 4.7479\n",
            "Epoch 1442/3334\n",
            "Epoch 1442: Training Accuracy = 0.9844, Training Loss = 0.1357, Validation Accuracy = 0.0518, Validation Loss = 4.7670\n",
            "Epoch 1443/3334\n",
            "Epoch 1443: Training Accuracy = 0.9844, Training Loss = 0.1357, Validation Accuracy = 0.0518, Validation Loss = 4.7670\n",
            "Epoch 1444/3334\n",
            "Epoch 1444: Training Accuracy = 0.7129, Training Loss = 1.3229, Validation Accuracy = 0.0422, Validation Loss = 4.8950\n",
            "Epoch 1445/3334\n",
            "Epoch 1445: Training Accuracy = 0.7129, Training Loss = 1.3229, Validation Accuracy = 0.0422, Validation Loss = 4.8950\n",
            "Epoch 1446/3334\n",
            "Epoch 1446: Training Accuracy = 0.9512, Training Loss = 0.5167, Validation Accuracy = 0.0632, Validation Loss = 4.1341\n",
            "Epoch 1447/3334\n",
            "Epoch 1447: Training Accuracy = 0.9727, Training Loss = 0.3488, Validation Accuracy = 0.0616, Validation Loss = 4.1392\n",
            "Epoch 1448/3334\n",
            "Epoch 1448: Training Accuracy = 0.9727, Training Loss = 0.3488, Validation Accuracy = 0.0616, Validation Loss = 4.1392\n",
            "Epoch 1449/3334\n",
            "Epoch 1449: Training Accuracy = 0.9844, Training Loss = 0.1981, Validation Accuracy = 0.0632, Validation Loss = 4.2557\n",
            "Epoch 1450/3334\n",
            "Epoch 1450: Training Accuracy = 0.9844, Training Loss = 0.1981, Validation Accuracy = 0.0632, Validation Loss = 4.2557\n",
            "Epoch 1451/3334\n",
            "Epoch 1451: Training Accuracy = 0.9883, Training Loss = 0.1394, Validation Accuracy = 0.0621, Validation Loss = 4.3178\n",
            "Epoch 1452/3334\n",
            "Epoch 1452: Training Accuracy = 0.9922, Training Loss = 0.1075, Validation Accuracy = 0.0595, Validation Loss = 4.3340\n",
            "Epoch 1453/3334\n",
            "Epoch 1453: Training Accuracy = 0.9922, Training Loss = 0.1075, Validation Accuracy = 0.0595, Validation Loss = 4.3340\n",
            "Epoch 1454/3334\n",
            "Epoch 1454: Training Accuracy = 0.9980, Training Loss = 0.0798, Validation Accuracy = 0.0641, Validation Loss = 4.3655\n",
            "Epoch 1455/3334\n",
            "Epoch 1455: Training Accuracy = 0.9980, Training Loss = 0.0798, Validation Accuracy = 0.0641, Validation Loss = 4.3655\n",
            "Epoch 1456/3334\n",
            "Epoch 1456: Training Accuracy = 0.9941, Training Loss = 0.0753, Validation Accuracy = 0.0625, Validation Loss = 4.3955\n",
            "Epoch 1457/3334\n",
            "Epoch 1457: Training Accuracy = 0.9805, Training Loss = 0.1271, Validation Accuracy = 0.0606, Validation Loss = 4.4121\n",
            "Epoch 1458/3334\n",
            "Epoch 1458: Training Accuracy = 0.9805, Training Loss = 0.1271, Validation Accuracy = 0.0606, Validation Loss = 4.4121\n",
            "Epoch 1459/3334\n",
            "Epoch 1459: Training Accuracy = 0.9902, Training Loss = 0.0837, Validation Accuracy = 0.0600, Validation Loss = 4.4260\n",
            "Epoch 1460/3334\n",
            "Epoch 1460: Training Accuracy = 0.9902, Training Loss = 0.0837, Validation Accuracy = 0.0600, Validation Loss = 4.4260\n",
            "Epoch 1461/3334\n",
            "Epoch 1461: Training Accuracy = 0.9863, Training Loss = 0.0993, Validation Accuracy = 0.0595, Validation Loss = 4.4169\n",
            "Epoch 1462/3334\n",
            "Epoch 1462: Training Accuracy = 0.9922, Training Loss = 0.0828, Validation Accuracy = 0.0632, Validation Loss = 4.4203\n",
            "Epoch 1463/3334\n",
            "Epoch 1463: Training Accuracy = 0.9922, Training Loss = 0.0828, Validation Accuracy = 0.0632, Validation Loss = 4.4203\n",
            "Epoch 1464/3334\n",
            "Epoch 1464: Training Accuracy = 0.9883, Training Loss = 0.0921, Validation Accuracy = 0.0615, Validation Loss = 4.4290\n",
            "Epoch 1465/3334\n",
            "Epoch 1465: Training Accuracy = 0.9883, Training Loss = 0.0921, Validation Accuracy = 0.0615, Validation Loss = 4.4290\n",
            "Epoch 1466/3334\n",
            "Epoch 1466: Training Accuracy = 0.9902, Training Loss = 0.0921, Validation Accuracy = 0.0581, Validation Loss = 4.4348\n",
            "Epoch 1467/3334\n",
            "Epoch 1467: Training Accuracy = 0.9902, Training Loss = 0.1006, Validation Accuracy = 0.0622, Validation Loss = 4.4295\n",
            "Epoch 1468/3334\n",
            "Epoch 1468: Training Accuracy = 0.9902, Training Loss = 0.1006, Validation Accuracy = 0.0622, Validation Loss = 4.4295\n",
            "Epoch 1469/3334\n",
            "Epoch 1469: Training Accuracy = 0.9883, Training Loss = 0.1188, Validation Accuracy = 0.0621, Validation Loss = 4.4228\n",
            "Epoch 1470/3334\n",
            "Epoch 1470: Training Accuracy = 0.9883, Training Loss = 0.1188, Validation Accuracy = 0.0621, Validation Loss = 4.4228\n",
            "Epoch 1471/3334\n",
            "Epoch 1471: Training Accuracy = 0.9883, Training Loss = 0.2110, Validation Accuracy = 0.0612, Validation Loss = 4.6037\n",
            "Epoch 1472/3334\n",
            "Epoch 1472: Training Accuracy = 0.9355, Training Loss = 0.5577, Validation Accuracy = 0.0638, Validation Loss = 4.2415\n",
            "Epoch 1473/3334\n",
            "Epoch 1473: Training Accuracy = 0.9355, Training Loss = 0.5577, Validation Accuracy = 0.0638, Validation Loss = 4.2415\n",
            "Epoch 1474/3334\n",
            "Epoch 1474: Training Accuracy = 0.9844, Training Loss = 0.2716, Validation Accuracy = 0.0758, Validation Loss = 4.0227\n",
            "Epoch 1475/3334\n",
            "Epoch 1475: Training Accuracy = 0.9844, Training Loss = 0.2716, Validation Accuracy = 0.0758, Validation Loss = 4.0227\n",
            "Epoch 1476/3334\n",
            "Epoch 1476: Training Accuracy = 0.9863, Training Loss = 0.1741, Validation Accuracy = 0.0729, Validation Loss = 4.0521\n",
            "Epoch 1477/3334\n",
            "Epoch 1477: Training Accuracy = 0.9922, Training Loss = 0.1214, Validation Accuracy = 0.0758, Validation Loss = 4.0837\n",
            "Epoch 1478/3334\n",
            "Epoch 1478: Training Accuracy = 0.9922, Training Loss = 0.1214, Validation Accuracy = 0.0758, Validation Loss = 4.0837\n",
            "Epoch 1479/3334\n",
            "Epoch 1479: Training Accuracy = 0.9902, Training Loss = 0.0992, Validation Accuracy = 0.0715, Validation Loss = 4.1463\n",
            "Epoch 1480/3334\n",
            "Epoch 1480: Training Accuracy = 0.9902, Training Loss = 0.0992, Validation Accuracy = 0.0715, Validation Loss = 4.1463\n",
            "Epoch 1481/3334\n",
            "Epoch 1481: Training Accuracy = 0.9902, Training Loss = 0.0850, Validation Accuracy = 0.0706, Validation Loss = 4.1918\n",
            "Epoch 1482/3334\n",
            "Epoch 1482: Training Accuracy = 0.9824, Training Loss = 0.1176, Validation Accuracy = 0.0697, Validation Loss = 4.1846\n",
            "Epoch 1483/3334\n",
            "Epoch 1483: Training Accuracy = 0.9824, Training Loss = 0.1176, Validation Accuracy = 0.0697, Validation Loss = 4.1846\n",
            "Epoch 1484/3334\n",
            "Epoch 1484: Training Accuracy = 0.9902, Training Loss = 0.0869, Validation Accuracy = 0.0689, Validation Loss = 4.2172\n",
            "Epoch 1485/3334\n",
            "Epoch 1485: Training Accuracy = 0.9902, Training Loss = 0.0869, Validation Accuracy = 0.0689, Validation Loss = 4.2172\n",
            "Epoch 1486/3334\n",
            "Epoch 1486: Training Accuracy = 0.9883, Training Loss = 0.0846, Validation Accuracy = 0.0724, Validation Loss = 4.2204\n",
            "Epoch 1487/3334\n",
            "Epoch 1487: Training Accuracy = 0.9863, Training Loss = 0.1022, Validation Accuracy = 0.0720, Validation Loss = 4.2143\n",
            "Epoch 1488/3334\n",
            "Epoch 1488: Training Accuracy = 0.9863, Training Loss = 0.1022, Validation Accuracy = 0.0720, Validation Loss = 4.2143\n",
            "Epoch 1489/3334\n",
            "Epoch 1489: Training Accuracy = 0.9902, Training Loss = 0.0808, Validation Accuracy = 0.0715, Validation Loss = 4.2234\n",
            "Epoch 1490/3334\n",
            "Epoch 1490: Training Accuracy = 0.9902, Training Loss = 0.0808, Validation Accuracy = 0.0715, Validation Loss = 4.2234\n",
            "Epoch 1491/3334\n",
            "Epoch 1491: Training Accuracy = 0.9902, Training Loss = 0.0824, Validation Accuracy = 0.0717, Validation Loss = 4.2191\n",
            "Epoch 1492/3334\n",
            "Epoch 1492: Training Accuracy = 0.9883, Training Loss = 0.1004, Validation Accuracy = 0.0742, Validation Loss = 4.2163\n",
            "Epoch 1493/3334\n",
            "Epoch 1493: Training Accuracy = 0.9883, Training Loss = 0.1004, Validation Accuracy = 0.0742, Validation Loss = 4.2163\n",
            "Epoch 1494/3334\n",
            "Epoch 1494: Training Accuracy = 0.9941, Training Loss = 0.0894, Validation Accuracy = 0.0701, Validation Loss = 4.2422\n",
            "Epoch 1495/3334\n",
            "Epoch 1495: Training Accuracy = 0.9941, Training Loss = 0.0894, Validation Accuracy = 0.0701, Validation Loss = 4.2422\n",
            "Epoch 1496/3334\n",
            "Epoch 1496: Training Accuracy = 0.9805, Training Loss = 0.1429, Validation Accuracy = 0.0742, Validation Loss = 4.2636\n",
            "Epoch 1497/3334\n",
            "Epoch 1497: Training Accuracy = 0.8457, Training Loss = 0.7647, Validation Accuracy = 0.0668, Validation Loss = 4.3014\n",
            "Epoch 1498/3334\n",
            "Epoch 1498: Training Accuracy = 0.8457, Training Loss = 0.7647, Validation Accuracy = 0.0668, Validation Loss = 4.3014\n",
            "Epoch 1499/3334\n",
            "Epoch 1499: Training Accuracy = 0.9727, Training Loss = 0.3537, Validation Accuracy = 0.0849, Validation Loss = 3.8670\n",
            "Epoch 1500/3334\n",
            "Epoch 1500: Training Accuracy = 0.9727, Training Loss = 0.3537, Validation Accuracy = 0.0849, Validation Loss = 3.8670\n",
            "Epoch 1501/3334\n",
            "Epoch 1501: Training Accuracy = 0.9883, Training Loss = 0.2033, Validation Accuracy = 0.0871, Validation Loss = 3.7961\n",
            "Epoch 1502/3334\n",
            "Epoch 1502: Training Accuracy = 0.9961, Training Loss = 0.1257, Validation Accuracy = 0.0902, Validation Loss = 3.8679\n",
            "Epoch 1503/3334\n",
            "Epoch 1503: Training Accuracy = 0.9961, Training Loss = 0.1257, Validation Accuracy = 0.0902, Validation Loss = 3.8679\n",
            "Epoch 1504/3334\n",
            "Epoch 1504: Training Accuracy = 0.9863, Training Loss = 0.1164, Validation Accuracy = 0.0890, Validation Loss = 3.9218\n",
            "Epoch 1505/3334\n",
            "Epoch 1505: Training Accuracy = 0.9863, Training Loss = 0.1164, Validation Accuracy = 0.0890, Validation Loss = 3.9218\n",
            "Epoch 1506/3334\n",
            "Epoch 1506: Training Accuracy = 0.9844, Training Loss = 0.1003, Validation Accuracy = 0.0806, Validation Loss = 3.9908\n",
            "Epoch 1507/3334\n",
            "Epoch 1507: Training Accuracy = 0.9805, Training Loss = 0.1159, Validation Accuracy = 0.0850, Validation Loss = 3.9818\n",
            "Epoch 1508/3334\n",
            "Epoch 1508: Training Accuracy = 0.9805, Training Loss = 0.1159, Validation Accuracy = 0.0850, Validation Loss = 3.9818\n",
            "Epoch 1509/3334\n",
            "Epoch 1509: Training Accuracy = 0.9863, Training Loss = 0.0889, Validation Accuracy = 0.0821, Validation Loss = 4.0178\n",
            "Epoch 1510/3334\n",
            "Epoch 1510: Training Accuracy = 0.9863, Training Loss = 0.0889, Validation Accuracy = 0.0821, Validation Loss = 4.0178\n",
            "Epoch 1511/3334\n",
            "Epoch 1511: Training Accuracy = 0.9961, Training Loss = 0.0614, Validation Accuracy = 0.0830, Validation Loss = 4.0023\n",
            "Epoch 1512/3334\n",
            "Epoch 1512: Training Accuracy = 0.9941, Training Loss = 0.0675, Validation Accuracy = 0.0830, Validation Loss = 4.0050\n",
            "Epoch 1513/3334\n",
            "Epoch 1513: Training Accuracy = 0.9941, Training Loss = 0.0675, Validation Accuracy = 0.0830, Validation Loss = 4.0050\n",
            "Epoch 1514/3334\n",
            "Epoch 1514: Training Accuracy = 0.9883, Training Loss = 0.0782, Validation Accuracy = 0.0812, Validation Loss = 4.0195\n",
            "Epoch 1515/3334\n",
            "Epoch 1515: Training Accuracy = 0.9883, Training Loss = 0.0782, Validation Accuracy = 0.0812, Validation Loss = 4.0195\n",
            "Epoch 1516/3334\n",
            "Epoch 1516: Training Accuracy = 0.9941, Training Loss = 0.0701, Validation Accuracy = 0.0841, Validation Loss = 4.0269\n",
            "Epoch 1517/3334\n",
            "Epoch 1517: Training Accuracy = 0.9902, Training Loss = 0.0912, Validation Accuracy = 0.0836, Validation Loss = 3.9902\n",
            "Epoch 1518/3334\n",
            "Epoch 1518: Training Accuracy = 0.9902, Training Loss = 0.0912, Validation Accuracy = 0.0836, Validation Loss = 3.9902\n",
            "Epoch 1519/3334\n",
            "Epoch 1519: Training Accuracy = 0.9922, Training Loss = 0.1011, Validation Accuracy = 0.0838, Validation Loss = 4.0302\n",
            "Epoch 1520/3334\n",
            "Epoch 1520: Training Accuracy = 0.9922, Training Loss = 0.1011, Validation Accuracy = 0.0838, Validation Loss = 4.0302\n",
            "Epoch 1521/3334\n",
            "Epoch 1521: Training Accuracy = 0.9902, Training Loss = 0.1474, Validation Accuracy = 0.0814, Validation Loss = 4.1573\n",
            "Epoch 1522/3334\n",
            "Epoch 1522: Training Accuracy = 0.8457, Training Loss = 0.8401, Validation Accuracy = 0.0811, Validation Loss = 3.9934\n",
            "Epoch 1523/3334\n",
            "Epoch 1523: Training Accuracy = 0.8457, Training Loss = 0.8401, Validation Accuracy = 0.0811, Validation Loss = 3.9934\n",
            "Epoch 1524/3334\n",
            "Epoch 1524: Training Accuracy = 0.9570, Training Loss = 0.3747, Validation Accuracy = 0.1017, Validation Loss = 3.5632\n",
            "Epoch 1525/3334\n",
            "Epoch 1525: Training Accuracy = 0.9570, Training Loss = 0.3747, Validation Accuracy = 0.1017, Validation Loss = 3.5632\n",
            "Epoch 1526/3334\n",
            "Epoch 1526: Training Accuracy = 0.9863, Training Loss = 0.2153, Validation Accuracy = 0.1102, Validation Loss = 3.5822\n",
            "Epoch 1527/3334\n",
            "Epoch 1527: Training Accuracy = 0.9922, Training Loss = 0.1447, Validation Accuracy = 0.0996, Validation Loss = 3.6467\n",
            "Epoch 1528/3334\n",
            "Epoch 1528: Training Accuracy = 0.9922, Training Loss = 0.1447, Validation Accuracy = 0.0996, Validation Loss = 3.6467\n",
            "Epoch 1529/3334\n",
            "Epoch 1529: Training Accuracy = 0.9863, Training Loss = 0.1206, Validation Accuracy = 0.1011, Validation Loss = 3.6883\n",
            "Epoch 1530/3334\n",
            "Epoch 1530: Training Accuracy = 0.9863, Training Loss = 0.1206, Validation Accuracy = 0.1011, Validation Loss = 3.6883\n",
            "Epoch 1531/3334\n",
            "Epoch 1531: Training Accuracy = 0.9922, Training Loss = 0.0804, Validation Accuracy = 0.1003, Validation Loss = 3.7265\n",
            "Epoch 1532/3334\n",
            "Epoch 1532: Training Accuracy = 0.9902, Training Loss = 0.0806, Validation Accuracy = 0.1003, Validation Loss = 3.7556\n",
            "Epoch 1533/3334\n",
            "Epoch 1533: Training Accuracy = 0.9902, Training Loss = 0.0806, Validation Accuracy = 0.1003, Validation Loss = 3.7556\n",
            "Epoch 1534/3334\n",
            "Epoch 1534: Training Accuracy = 0.9941, Training Loss = 0.0632, Validation Accuracy = 0.0963, Validation Loss = 3.7561\n",
            "Epoch 1535/3334\n",
            "Epoch 1535: Training Accuracy = 0.9941, Training Loss = 0.0632, Validation Accuracy = 0.0963, Validation Loss = 3.7561\n",
            "Epoch 1536/3334\n",
            "Epoch 1536: Training Accuracy = 0.9941, Training Loss = 0.0582, Validation Accuracy = 0.0982, Validation Loss = 3.7902\n",
            "Epoch 1537/3334\n",
            "Epoch 1537: Training Accuracy = 0.9883, Training Loss = 0.0843, Validation Accuracy = 0.1022, Validation Loss = 3.7904\n",
            "Epoch 1538/3334\n",
            "Epoch 1538: Training Accuracy = 0.9883, Training Loss = 0.0843, Validation Accuracy = 0.1022, Validation Loss = 3.7904\n",
            "Epoch 1539/3334\n",
            "Epoch 1539: Training Accuracy = 0.9902, Training Loss = 0.0777, Validation Accuracy = 0.1017, Validation Loss = 3.7907\n",
            "Epoch 1540/3334\n",
            "Epoch 1540: Training Accuracy = 0.9902, Training Loss = 0.0777, Validation Accuracy = 0.1017, Validation Loss = 3.7907\n",
            "Epoch 1541/3334\n",
            "Epoch 1541: Training Accuracy = 0.9902, Training Loss = 0.0729, Validation Accuracy = 0.0991, Validation Loss = 3.8015\n",
            "Epoch 1542/3334\n",
            "Epoch 1542: Training Accuracy = 0.9902, Training Loss = 0.0814, Validation Accuracy = 0.0997, Validation Loss = 3.8251\n",
            "Epoch 1543/3334\n",
            "Epoch 1543: Training Accuracy = 0.9902, Training Loss = 0.0814, Validation Accuracy = 0.0997, Validation Loss = 3.8251\n",
            "Epoch 1544/3334\n",
            "Epoch 1544: Training Accuracy = 0.9902, Training Loss = 0.0893, Validation Accuracy = 0.0976, Validation Loss = 3.8578\n",
            "Epoch 1545/3334\n",
            "Epoch 1545: Training Accuracy = 0.9902, Training Loss = 0.0893, Validation Accuracy = 0.0976, Validation Loss = 3.8578\n",
            "Epoch 1546/3334\n",
            "Epoch 1546: Training Accuracy = 0.9863, Training Loss = 0.1215, Validation Accuracy = 0.0985, Validation Loss = 3.8414\n",
            "Epoch 1547/3334\n",
            "Epoch 1547: Training Accuracy = 0.9902, Training Loss = 0.1295, Validation Accuracy = 0.0964, Validation Loss = 3.8670\n",
            "Epoch 1548/3334\n",
            "Epoch 1548: Training Accuracy = 0.9902, Training Loss = 0.1295, Validation Accuracy = 0.0964, Validation Loss = 3.8670\n",
            "Epoch 1549/3334\n",
            "Epoch 1549: Training Accuracy = 0.8223, Training Loss = 0.9776, Validation Accuracy = 0.0764, Validation Loss = 3.9531\n",
            "Epoch 1550/3334\n",
            "Epoch 1550: Training Accuracy = 0.8223, Training Loss = 0.9776, Validation Accuracy = 0.0764, Validation Loss = 3.9531\n",
            "Epoch 1551/3334\n",
            "Epoch 1551: Training Accuracy = 0.9785, Training Loss = 0.3591, Validation Accuracy = 0.1193, Validation Loss = 3.3397\n",
            "Epoch 1552/3334\n",
            "Epoch 1552: Training Accuracy = 0.9805, Training Loss = 0.2714, Validation Accuracy = 0.1389, Validation Loss = 3.2759\n",
            "Epoch 1553/3334\n",
            "Epoch 1553: Training Accuracy = 0.9805, Training Loss = 0.2714, Validation Accuracy = 0.1389, Validation Loss = 3.2759\n",
            "Epoch 1554/3334\n",
            "Epoch 1554: Training Accuracy = 0.9844, Training Loss = 0.1592, Validation Accuracy = 0.1303, Validation Loss = 3.3692\n",
            "Epoch 1555/3334\n",
            "Epoch 1555: Training Accuracy = 0.9844, Training Loss = 0.1592, Validation Accuracy = 0.1303, Validation Loss = 3.3692\n",
            "Epoch 1556/3334\n",
            "Epoch 1556: Training Accuracy = 0.9922, Training Loss = 0.0964, Validation Accuracy = 0.1248, Validation Loss = 3.4453\n",
            "Epoch 1557/3334\n",
            "Epoch 1557: Training Accuracy = 0.9922, Training Loss = 0.0821, Validation Accuracy = 0.1278, Validation Loss = 3.4652\n",
            "Epoch 1558/3334\n",
            "Epoch 1558: Training Accuracy = 0.9922, Training Loss = 0.0821, Validation Accuracy = 0.1278, Validation Loss = 3.4652\n",
            "Epoch 1559/3334\n",
            "Epoch 1559: Training Accuracy = 0.9961, Training Loss = 0.0600, Validation Accuracy = 0.1230, Validation Loss = 3.4950\n",
            "Epoch 1560/3334\n",
            "Epoch 1560: Training Accuracy = 0.9961, Training Loss = 0.0600, Validation Accuracy = 0.1230, Validation Loss = 3.4950\n",
            "Epoch 1561/3334\n",
            "Epoch 1561: Training Accuracy = 0.9902, Training Loss = 0.0792, Validation Accuracy = 0.1225, Validation Loss = 3.5132\n",
            "Epoch 1562/3334\n",
            "Epoch 1562: Training Accuracy = 0.9902, Training Loss = 0.0766, Validation Accuracy = 0.1236, Validation Loss = 3.5325\n",
            "Epoch 1563/3334\n",
            "Epoch 1563: Training Accuracy = 0.9902, Training Loss = 0.0766, Validation Accuracy = 0.1236, Validation Loss = 3.5325\n",
            "Epoch 1564/3334\n",
            "Epoch 1564: Training Accuracy = 0.9902, Training Loss = 0.0729, Validation Accuracy = 0.1242, Validation Loss = 3.5096\n",
            "Epoch 1565/3334\n",
            "Epoch 1565: Training Accuracy = 0.9902, Training Loss = 0.0729, Validation Accuracy = 0.1242, Validation Loss = 3.5096\n",
            "Epoch 1566/3334\n",
            "Epoch 1566: Training Accuracy = 0.9941, Training Loss = 0.0595, Validation Accuracy = 0.1237, Validation Loss = 3.5168\n",
            "Epoch 1567/3334\n",
            "Epoch 1567: Training Accuracy = 0.9961, Training Loss = 0.0570, Validation Accuracy = 0.1225, Validation Loss = 3.5406\n",
            "Epoch 1568/3334\n",
            "Epoch 1568: Training Accuracy = 0.9961, Training Loss = 0.0570, Validation Accuracy = 0.1225, Validation Loss = 3.5406\n",
            "Epoch 1569/3334\n",
            "Epoch 1569: Training Accuracy = 0.9941, Training Loss = 0.0632, Validation Accuracy = 0.1274, Validation Loss = 3.5171\n",
            "Epoch 1570/3334\n",
            "Epoch 1570: Training Accuracy = 0.9941, Training Loss = 0.0632, Validation Accuracy = 0.1274, Validation Loss = 3.5171\n",
            "Epoch 1571/3334\n",
            "Epoch 1571: Training Accuracy = 0.9980, Training Loss = 0.0467, Validation Accuracy = 0.1260, Validation Loss = 3.5518\n",
            "Epoch 1572/3334\n",
            "Epoch 1572: Training Accuracy = 0.9902, Training Loss = 0.0987, Validation Accuracy = 0.1272, Validation Loss = 3.5462\n",
            "Epoch 1573/3334\n",
            "Epoch 1573: Training Accuracy = 0.9902, Training Loss = 0.0987, Validation Accuracy = 0.1272, Validation Loss = 3.5462\n",
            "Epoch 1574/3334\n",
            "Epoch 1574: Training Accuracy = 0.6387, Training Loss = 2.0526, Validation Accuracy = 0.0697, Validation Loss = 4.2296\n",
            "Epoch 1575/3334\n",
            "Epoch 1575: Training Accuracy = 0.6387, Training Loss = 2.0526, Validation Accuracy = 0.0697, Validation Loss = 4.2296\n",
            "Epoch 1576/3334\n",
            "Epoch 1576: Training Accuracy = 0.9414, Training Loss = 0.5033, Validation Accuracy = 0.1339, Validation Loss = 3.2726\n",
            "Epoch 1577/3334\n",
            "Epoch 1577: Training Accuracy = 0.9805, Training Loss = 0.2908, Validation Accuracy = 0.1523, Validation Loss = 3.0459\n",
            "Epoch 1578/3334\n",
            "Epoch 1578: Training Accuracy = 0.9805, Training Loss = 0.2908, Validation Accuracy = 0.1523, Validation Loss = 3.0459\n",
            "Epoch 1579/3334\n",
            "Epoch 1579: Training Accuracy = 0.9902, Training Loss = 0.1771, Validation Accuracy = 0.1556, Validation Loss = 3.1037\n",
            "Epoch 1580/3334\n",
            "Epoch 1580: Training Accuracy = 0.9902, Training Loss = 0.1771, Validation Accuracy = 0.1556, Validation Loss = 3.1037\n",
            "Epoch 1581/3334\n",
            "Epoch 1581: Training Accuracy = 0.9961, Training Loss = 0.0974, Validation Accuracy = 0.1542, Validation Loss = 3.1527\n",
            "Epoch 1582/3334\n",
            "Epoch 1582: Training Accuracy = 0.9941, Training Loss = 0.0880, Validation Accuracy = 0.1498, Validation Loss = 3.1931\n",
            "Epoch 1583/3334\n",
            "Epoch 1583: Training Accuracy = 0.9941, Training Loss = 0.0880, Validation Accuracy = 0.1498, Validation Loss = 3.1931\n",
            "Epoch 1584/3334\n",
            "Epoch 1584: Training Accuracy = 0.9863, Training Loss = 0.1041, Validation Accuracy = 0.1524, Validation Loss = 3.2233\n",
            "Epoch 1585/3334\n",
            "Epoch 1585: Training Accuracy = 0.9863, Training Loss = 0.1041, Validation Accuracy = 0.1524, Validation Loss = 3.2233\n",
            "Epoch 1586/3334\n",
            "Epoch 1586: Training Accuracy = 0.9824, Training Loss = 0.1081, Validation Accuracy = 0.1517, Validation Loss = 3.2284\n",
            "Epoch 1587/3334\n",
            "Epoch 1587: Training Accuracy = 0.9922, Training Loss = 0.0721, Validation Accuracy = 0.1515, Validation Loss = 3.2385\n",
            "Epoch 1588/3334\n",
            "Epoch 1588: Training Accuracy = 0.9922, Training Loss = 0.0721, Validation Accuracy = 0.1515, Validation Loss = 3.2385\n",
            "Epoch 1589/3334\n",
            "Epoch 1589: Training Accuracy = 0.9824, Training Loss = 0.1060, Validation Accuracy = 0.1485, Validation Loss = 3.2488\n",
            "Epoch 1590/3334\n",
            "Epoch 1590: Training Accuracy = 0.9824, Training Loss = 0.1060, Validation Accuracy = 0.1485, Validation Loss = 3.2488\n",
            "Epoch 1591/3334\n",
            "Epoch 1591: Training Accuracy = 0.9824, Training Loss = 0.1040, Validation Accuracy = 0.1488, Validation Loss = 3.2571\n",
            "Epoch 1592/3334\n",
            "Epoch 1592: Training Accuracy = 0.9922, Training Loss = 0.0755, Validation Accuracy = 0.1503, Validation Loss = 3.2595\n",
            "Epoch 1593/3334\n",
            "Epoch 1593: Training Accuracy = 0.9922, Training Loss = 0.0755, Validation Accuracy = 0.1503, Validation Loss = 3.2595\n",
            "Epoch 1594/3334\n",
            "Epoch 1594: Training Accuracy = 0.9844, Training Loss = 0.0997, Validation Accuracy = 0.1480, Validation Loss = 3.2608\n",
            "Epoch 1595/3334\n",
            "Epoch 1595: Training Accuracy = 0.9844, Training Loss = 0.0997, Validation Accuracy = 0.1480, Validation Loss = 3.2608\n",
            "Epoch 1596/3334\n",
            "Epoch 1596: Training Accuracy = 0.9883, Training Loss = 0.0888, Validation Accuracy = 0.1529, Validation Loss = 3.2744\n",
            "Epoch 1597/3334\n",
            "Epoch 1597: Training Accuracy = 0.9902, Training Loss = 0.0894, Validation Accuracy = 0.1518, Validation Loss = 3.2609\n",
            "Epoch 1598/3334\n",
            "Epoch 1598: Training Accuracy = 0.9902, Training Loss = 0.0894, Validation Accuracy = 0.1518, Validation Loss = 3.2609\n",
            "Epoch 1599/3334\n",
            "Epoch 1599: Training Accuracy = 0.9941, Training Loss = 0.0994, Validation Accuracy = 0.1498, Validation Loss = 3.3600\n",
            "Epoch 1600/3334\n",
            "Epoch 1600: Training Accuracy = 0.9941, Training Loss = 0.0994, Validation Accuracy = 0.1498, Validation Loss = 3.3600\n",
            "Epoch 1601/3334\n",
            "Epoch 1601: Training Accuracy = 0.9395, Training Loss = 0.4992, Validation Accuracy = 0.1010, Validation Loss = 3.6608\n",
            "Epoch 1602/3334\n",
            "Epoch 1602: Training Accuracy = 0.9824, Training Loss = 0.3100, Validation Accuracy = 0.1647, Validation Loss = 3.0162\n",
            "Epoch 1603/3334\n",
            "Epoch 1603: Training Accuracy = 0.9824, Training Loss = 0.3100, Validation Accuracy = 0.1647, Validation Loss = 3.0162\n",
            "Epoch 1604/3334\n",
            "Epoch 1604: Training Accuracy = 0.9863, Training Loss = 0.2194, Validation Accuracy = 0.1785, Validation Loss = 2.9866\n",
            "Epoch 1605/3334\n",
            "Epoch 1605: Training Accuracy = 0.9863, Training Loss = 0.2194, Validation Accuracy = 0.1785, Validation Loss = 2.9866\n",
            "Epoch 1606/3334\n",
            "Epoch 1606: Training Accuracy = 0.9863, Training Loss = 0.1352, Validation Accuracy = 0.1737, Validation Loss = 3.0132\n",
            "Epoch 1607/3334\n",
            "Epoch 1607: Training Accuracy = 0.9961, Training Loss = 0.0830, Validation Accuracy = 0.1764, Validation Loss = 3.0141\n",
            "Epoch 1608/3334\n",
            "Epoch 1608: Training Accuracy = 0.9961, Training Loss = 0.0830, Validation Accuracy = 0.1764, Validation Loss = 3.0141\n",
            "Epoch 1609/3334\n",
            "Epoch 1609: Training Accuracy = 0.9902, Training Loss = 0.0862, Validation Accuracy = 0.1845, Validation Loss = 2.9977\n",
            "Epoch 1610/3334\n",
            "Epoch 1610: Training Accuracy = 0.9902, Training Loss = 0.0862, Validation Accuracy = 0.1845, Validation Loss = 2.9977\n",
            "Epoch 1611/3334\n",
            "Epoch 1611: Training Accuracy = 0.9844, Training Loss = 0.0994, Validation Accuracy = 0.1808, Validation Loss = 3.0368\n",
            "Epoch 1612/3334\n",
            "Epoch 1612: Training Accuracy = 0.9922, Training Loss = 0.0735, Validation Accuracy = 0.1823, Validation Loss = 3.0255\n",
            "Epoch 1613/3334\n",
            "Epoch 1613: Training Accuracy = 0.9922, Training Loss = 0.0735, Validation Accuracy = 0.1823, Validation Loss = 3.0255\n",
            "Epoch 1614/3334\n",
            "Epoch 1614: Training Accuracy = 0.9980, Training Loss = 0.0507, Validation Accuracy = 0.1814, Validation Loss = 3.0440\n",
            "Epoch 1615/3334\n",
            "Epoch 1615: Training Accuracy = 0.9980, Training Loss = 0.0507, Validation Accuracy = 0.1814, Validation Loss = 3.0440\n",
            "Epoch 1616/3334\n",
            "Epoch 1616: Training Accuracy = 0.9941, Training Loss = 0.0606, Validation Accuracy = 0.1808, Validation Loss = 3.0430\n",
            "Epoch 1617/3334\n",
            "Epoch 1617: Training Accuracy = 0.9922, Training Loss = 0.0737, Validation Accuracy = 0.1796, Validation Loss = 3.0718\n",
            "Epoch 1618/3334\n",
            "Epoch 1618: Training Accuracy = 0.9922, Training Loss = 0.0737, Validation Accuracy = 0.1796, Validation Loss = 3.0718\n",
            "Epoch 1619/3334\n",
            "Epoch 1619: Training Accuracy = 0.9922, Training Loss = 0.0723, Validation Accuracy = 0.1804, Validation Loss = 3.0603\n",
            "Epoch 1620/3334\n",
            "Epoch 1620: Training Accuracy = 0.9922, Training Loss = 0.0723, Validation Accuracy = 0.1804, Validation Loss = 3.0603\n",
            "Epoch 1621/3334\n",
            "Epoch 1621: Training Accuracy = 0.9922, Training Loss = 0.0702, Validation Accuracy = 0.1838, Validation Loss = 3.0148\n",
            "Epoch 1622/3334\n",
            "Epoch 1622: Training Accuracy = 0.9922, Training Loss = 0.0806, Validation Accuracy = 0.1846, Validation Loss = 3.0335\n",
            "Epoch 1623/3334\n",
            "Epoch 1623: Training Accuracy = 0.9922, Training Loss = 0.0806, Validation Accuracy = 0.1846, Validation Loss = 3.0335\n",
            "Epoch 1624/3334\n",
            "Epoch 1624: Training Accuracy = 0.9902, Training Loss = 0.0891, Validation Accuracy = 0.1852, Validation Loss = 3.0670\n",
            "Epoch 1625/3334\n",
            "Epoch 1625: Training Accuracy = 0.9902, Training Loss = 0.0891, Validation Accuracy = 0.1852, Validation Loss = 3.0670\n",
            "Epoch 1626/3334\n",
            "Epoch 1626: Training Accuracy = 0.7109, Training Loss = 1.3887, Validation Accuracy = 0.0783, Validation Loss = 4.0034\n",
            "Epoch 1627/3334\n",
            "Epoch 1627: Training Accuracy = 0.9219, Training Loss = 0.5339, Validation Accuracy = 0.1731, Validation Loss = 2.9814\n",
            "Epoch 1628/3334\n",
            "Epoch 1628: Training Accuracy = 0.9219, Training Loss = 0.5339, Validation Accuracy = 0.1731, Validation Loss = 2.9814\n",
            "Epoch 1629/3334\n",
            "Epoch 1629: Training Accuracy = 0.9785, Training Loss = 0.2593, Validation Accuracy = 0.2075, Validation Loss = 2.7432\n",
            "Epoch 1630/3334\n",
            "Epoch 1630: Training Accuracy = 0.9785, Training Loss = 0.2593, Validation Accuracy = 0.2075, Validation Loss = 2.7432\n",
            "Epoch 1631/3334\n",
            "Epoch 1631: Training Accuracy = 0.9883, Training Loss = 0.1708, Validation Accuracy = 0.2232, Validation Loss = 2.6464\n",
            "Epoch 1632/3334\n",
            "Epoch 1632: Training Accuracy = 0.9902, Training Loss = 0.1264, Validation Accuracy = 0.2242, Validation Loss = 2.7164\n",
            "Epoch 1633/3334\n",
            "Epoch 1633: Training Accuracy = 0.9902, Training Loss = 0.1264, Validation Accuracy = 0.2242, Validation Loss = 2.7164\n",
            "Epoch 1634/3334\n",
            "Epoch 1634: Training Accuracy = 0.9980, Training Loss = 0.0651, Validation Accuracy = 0.2229, Validation Loss = 2.7018\n",
            "Epoch 1635/3334\n",
            "Epoch 1635: Training Accuracy = 0.9980, Training Loss = 0.0651, Validation Accuracy = 0.2229, Validation Loss = 2.7018\n",
            "Epoch 1636/3334\n",
            "Epoch 1636: Training Accuracy = 0.9863, Training Loss = 0.0954, Validation Accuracy = 0.2289, Validation Loss = 2.7068\n",
            "Epoch 1637/3334\n",
            "Epoch 1637: Training Accuracy = 0.9902, Training Loss = 0.0818, Validation Accuracy = 0.2242, Validation Loss = 2.7174\n",
            "Epoch 1638/3334\n",
            "Epoch 1638: Training Accuracy = 0.9902, Training Loss = 0.0818, Validation Accuracy = 0.2242, Validation Loss = 2.7174\n",
            "Epoch 1639/3334\n",
            "Epoch 1639: Training Accuracy = 0.9863, Training Loss = 0.0886, Validation Accuracy = 0.2261, Validation Loss = 2.7247\n",
            "Epoch 1640/3334\n",
            "Epoch 1640: Training Accuracy = 0.9863, Training Loss = 0.0886, Validation Accuracy = 0.2261, Validation Loss = 2.7247\n",
            "Epoch 1641/3334\n",
            "Epoch 1641: Training Accuracy = 0.9805, Training Loss = 0.1081, Validation Accuracy = 0.2291, Validation Loss = 2.7413\n",
            "Epoch 1642/3334\n",
            "Epoch 1642: Training Accuracy = 0.9902, Training Loss = 0.0794, Validation Accuracy = 0.2216, Validation Loss = 2.7356\n",
            "Epoch 1643/3334\n",
            "Epoch 1643: Training Accuracy = 0.9902, Training Loss = 0.0794, Validation Accuracy = 0.2216, Validation Loss = 2.7356\n",
            "Epoch 1644/3334\n",
            "Epoch 1644: Training Accuracy = 0.9844, Training Loss = 0.0964, Validation Accuracy = 0.2239, Validation Loss = 2.7749\n",
            "Epoch 1645/3334\n",
            "Epoch 1645: Training Accuracy = 0.9844, Training Loss = 0.0964, Validation Accuracy = 0.2239, Validation Loss = 2.7749\n",
            "Epoch 1646/3334\n",
            "Epoch 1646: Training Accuracy = 0.9902, Training Loss = 0.0790, Validation Accuracy = 0.2289, Validation Loss = 2.7652\n",
            "Epoch 1647/3334\n",
            "Epoch 1647: Training Accuracy = 0.9941, Training Loss = 0.0732, Validation Accuracy = 0.2285, Validation Loss = 2.7974\n",
            "Epoch 1648/3334\n",
            "Epoch 1648: Training Accuracy = 0.9941, Training Loss = 0.0732, Validation Accuracy = 0.2285, Validation Loss = 2.7974\n",
            "Epoch 1649/3334\n",
            "Epoch 1649: Training Accuracy = 0.9902, Training Loss = 0.0952, Validation Accuracy = 0.2248, Validation Loss = 2.7921\n",
            "Epoch 1650/3334\n",
            "Epoch 1650: Training Accuracy = 0.9902, Training Loss = 0.0952, Validation Accuracy = 0.2248, Validation Loss = 2.7921\n",
            "Epoch 1651/3334\n",
            "Epoch 1651: Training Accuracy = 0.9922, Training Loss = 0.1457, Validation Accuracy = 0.2086, Validation Loss = 2.9287\n",
            "Epoch 1652/3334\n",
            "Epoch 1652: Training Accuracy = 0.9648, Training Loss = 0.3643, Validation Accuracy = 0.2056, Validation Loss = 2.8758\n",
            "Epoch 1653/3334\n",
            "Epoch 1653: Training Accuracy = 0.9648, Training Loss = 0.3643, Validation Accuracy = 0.2056, Validation Loss = 2.8758\n",
            "Epoch 1654/3334\n",
            "Epoch 1654: Training Accuracy = 0.9844, Training Loss = 0.2036, Validation Accuracy = 0.2440, Validation Loss = 2.5791\n",
            "Epoch 1655/3334\n",
            "Epoch 1655: Training Accuracy = 0.9844, Training Loss = 0.2036, Validation Accuracy = 0.2440, Validation Loss = 2.5791\n",
            "Epoch 1656/3334\n",
            "Epoch 1656: Training Accuracy = 1.0000, Training Loss = 0.0833, Validation Accuracy = 0.2602, Validation Loss = 2.5425\n",
            "Epoch 1657/3334\n",
            "Epoch 1657: Training Accuracy = 0.9961, Training Loss = 0.0834, Validation Accuracy = 0.2546, Validation Loss = 2.5903\n",
            "Epoch 1658/3334\n",
            "Epoch 1658: Training Accuracy = 0.9961, Training Loss = 0.0834, Validation Accuracy = 0.2546, Validation Loss = 2.5903\n",
            "Epoch 1659/3334\n",
            "Epoch 1659: Training Accuracy = 0.9941, Training Loss = 0.0770, Validation Accuracy = 0.2686, Validation Loss = 2.5564\n",
            "Epoch 1660/3334\n",
            "Epoch 1660: Training Accuracy = 0.9941, Training Loss = 0.0770, Validation Accuracy = 0.2686, Validation Loss = 2.5564\n",
            "Epoch 1661/3334\n",
            "Epoch 1661: Training Accuracy = 0.9883, Training Loss = 0.0815, Validation Accuracy = 0.2622, Validation Loss = 2.5534\n",
            "Epoch 1662/3334\n",
            "Epoch 1662: Training Accuracy = 0.9980, Training Loss = 0.0484, Validation Accuracy = 0.2661, Validation Loss = 2.5529\n",
            "Epoch 1663/3334\n",
            "Epoch 1663: Training Accuracy = 0.9980, Training Loss = 0.0484, Validation Accuracy = 0.2661, Validation Loss = 2.5529\n",
            "Epoch 1664/3334\n",
            "Epoch 1664: Training Accuracy = 0.9824, Training Loss = 0.0984, Validation Accuracy = 0.2617, Validation Loss = 2.5642\n",
            "Epoch 1665/3334\n",
            "Epoch 1665: Training Accuracy = 0.9824, Training Loss = 0.0984, Validation Accuracy = 0.2617, Validation Loss = 2.5642\n",
            "Epoch 1666/3334\n",
            "Epoch 1666: Training Accuracy = 0.9883, Training Loss = 0.0759, Validation Accuracy = 0.2601, Validation Loss = 2.5849\n",
            "Epoch 1667/3334\n",
            "Epoch 1667: Training Accuracy = 0.9863, Training Loss = 0.0869, Validation Accuracy = 0.2648, Validation Loss = 2.5630\n",
            "Epoch 1668/3334\n",
            "Epoch 1668: Training Accuracy = 0.9863, Training Loss = 0.0869, Validation Accuracy = 0.2648, Validation Loss = 2.5630\n",
            "Epoch 1669/3334\n",
            "Epoch 1669: Training Accuracy = 0.9883, Training Loss = 0.0785, Validation Accuracy = 0.2617, Validation Loss = 2.5887\n",
            "Epoch 1670/3334\n",
            "Epoch 1670: Training Accuracy = 0.9883, Training Loss = 0.0785, Validation Accuracy = 0.2617, Validation Loss = 2.5887\n",
            "Epoch 1671/3334\n",
            "Epoch 1671: Training Accuracy = 0.9902, Training Loss = 0.0849, Validation Accuracy = 0.2657, Validation Loss = 2.5931\n",
            "Epoch 1672/3334\n",
            "Epoch 1672: Training Accuracy = 0.9941, Training Loss = 0.0726, Validation Accuracy = 0.2623, Validation Loss = 2.5929\n",
            "Epoch 1673/3334\n",
            "Epoch 1673: Training Accuracy = 0.9941, Training Loss = 0.0726, Validation Accuracy = 0.2623, Validation Loss = 2.5929\n",
            "Epoch 1674/3334\n",
            "Epoch 1674: Training Accuracy = 0.9844, Training Loss = 0.1121, Validation Accuracy = 0.2604, Validation Loss = 2.6423\n",
            "Epoch 1675/3334\n",
            "Epoch 1675: Training Accuracy = 0.9844, Training Loss = 0.1121, Validation Accuracy = 0.2604, Validation Loss = 2.6423\n",
            "Epoch 1676/3334\n",
            "Epoch 1676: Training Accuracy = 0.9551, Training Loss = 0.3045, Validation Accuracy = 0.1788, Validation Loss = 3.4983\n",
            "Epoch 1677/3334\n",
            "Epoch 1677: Training Accuracy = 0.9238, Training Loss = 0.5007, Validation Accuracy = 0.2103, Validation Loss = 2.8293\n",
            "Epoch 1678/3334\n",
            "Epoch 1678: Training Accuracy = 0.9238, Training Loss = 0.5007, Validation Accuracy = 0.2103, Validation Loss = 2.8293\n",
            "Epoch 1679/3334\n",
            "Epoch 1679: Training Accuracy = 0.9707, Training Loss = 0.2798, Validation Accuracy = 0.2669, Validation Loss = 2.4202\n",
            "Epoch 1680/3334\n",
            "Epoch 1680: Training Accuracy = 0.9707, Training Loss = 0.2798, Validation Accuracy = 0.2669, Validation Loss = 2.4202\n",
            "Epoch 1681/3334\n",
            "Epoch 1681: Training Accuracy = 0.9902, Training Loss = 0.1545, Validation Accuracy = 0.2881, Validation Loss = 2.3729\n",
            "Epoch 1682/3334\n",
            "Epoch 1682: Training Accuracy = 0.9941, Training Loss = 0.1033, Validation Accuracy = 0.2968, Validation Loss = 2.3461\n",
            "Epoch 1683/3334\n",
            "Epoch 1683: Training Accuracy = 0.9941, Training Loss = 0.1033, Validation Accuracy = 0.2968, Validation Loss = 2.3461\n",
            "Epoch 1684/3334\n",
            "Epoch 1684: Training Accuracy = 0.9922, Training Loss = 0.0812, Validation Accuracy = 0.3067, Validation Loss = 2.3148\n",
            "Epoch 1685/3334\n",
            "Epoch 1685: Training Accuracy = 0.9922, Training Loss = 0.0812, Validation Accuracy = 0.3067, Validation Loss = 2.3148\n",
            "Epoch 1686/3334\n",
            "Epoch 1686: Training Accuracy = 0.9844, Training Loss = 0.0966, Validation Accuracy = 0.3099, Validation Loss = 2.3123\n",
            "Epoch 1687/3334\n",
            "Epoch 1687: Training Accuracy = 0.9922, Training Loss = 0.0691, Validation Accuracy = 0.3105, Validation Loss = 2.3212\n",
            "Epoch 1688/3334\n",
            "Epoch 1688: Training Accuracy = 0.9922, Training Loss = 0.0691, Validation Accuracy = 0.3105, Validation Loss = 2.3212\n",
            "Epoch 1689/3334\n",
            "Epoch 1689: Training Accuracy = 0.9844, Training Loss = 0.0933, Validation Accuracy = 0.3126, Validation Loss = 2.3388\n",
            "Epoch 1690/3334\n",
            "Epoch 1690: Training Accuracy = 0.9844, Training Loss = 0.0933, Validation Accuracy = 0.3126, Validation Loss = 2.3388\n",
            "Epoch 1691/3334\n",
            "Epoch 1691: Training Accuracy = 0.9922, Training Loss = 0.0642, Validation Accuracy = 0.3161, Validation Loss = 2.3307\n",
            "Epoch 1692/3334\n",
            "Epoch 1692: Training Accuracy = 0.9863, Training Loss = 0.0848, Validation Accuracy = 0.3143, Validation Loss = 2.3266\n",
            "Epoch 1693/3334\n",
            "Epoch 1693: Training Accuracy = 0.9863, Training Loss = 0.0848, Validation Accuracy = 0.3143, Validation Loss = 2.3266\n",
            "Epoch 1694/3334\n",
            "Epoch 1694: Training Accuracy = 0.9805, Training Loss = 0.1075, Validation Accuracy = 0.3130, Validation Loss = 2.3451\n",
            "Epoch 1695/3334\n",
            "Epoch 1695: Training Accuracy = 0.9805, Training Loss = 0.1075, Validation Accuracy = 0.3130, Validation Loss = 2.3451\n",
            "Epoch 1696/3334\n",
            "Epoch 1696: Training Accuracy = 0.9902, Training Loss = 0.0691, Validation Accuracy = 0.3123, Validation Loss = 2.3347\n",
            "Epoch 1697/3334\n",
            "Epoch 1697: Training Accuracy = 0.9883, Training Loss = 0.0840, Validation Accuracy = 0.3194, Validation Loss = 2.3367\n",
            "Epoch 1698/3334\n",
            "Epoch 1698: Training Accuracy = 0.9883, Training Loss = 0.0840, Validation Accuracy = 0.3194, Validation Loss = 2.3367\n",
            "Epoch 1699/3334\n",
            "Epoch 1699: Training Accuracy = 0.9863, Training Loss = 0.0865, Validation Accuracy = 0.3179, Validation Loss = 2.3394\n",
            "Epoch 1700/3334\n",
            "Epoch 1700: Training Accuracy = 0.9863, Training Loss = 0.0865, Validation Accuracy = 0.3179, Validation Loss = 2.3394\n",
            "Epoch 1701/3334\n",
            "Epoch 1701: Training Accuracy = 0.9883, Training Loss = 0.0783, Validation Accuracy = 0.3123, Validation Loss = 2.3443\n",
            "Epoch 1702/3334\n",
            "Epoch 1702: Training Accuracy = 0.9844, Training Loss = 0.1025, Validation Accuracy = 0.3150, Validation Loss = 2.3703\n",
            "Epoch 1703/3334\n",
            "Epoch 1703: Training Accuracy = 0.9844, Training Loss = 0.1025, Validation Accuracy = 0.3150, Validation Loss = 2.3703\n",
            "Epoch 1704/3334\n",
            "Epoch 1704: Training Accuracy = 0.9902, Training Loss = 0.1048, Validation Accuracy = 0.3061, Validation Loss = 2.4461\n",
            "Epoch 1705/3334\n",
            "Epoch 1705: Training Accuracy = 0.9902, Training Loss = 0.1048, Validation Accuracy = 0.3061, Validation Loss = 2.4461\n",
            "Epoch 1706/3334\n",
            "Epoch 1706: Training Accuracy = 0.9219, Training Loss = 0.5400, Validation Accuracy = 0.2172, Validation Loss = 2.8580\n",
            "Epoch 1707/3334\n",
            "Epoch 1707: Training Accuracy = 0.9551, Training Loss = 0.3617, Validation Accuracy = 0.3033, Validation Loss = 2.3189\n",
            "Epoch 1708/3334\n",
            "Epoch 1708: Training Accuracy = 0.9551, Training Loss = 0.3617, Validation Accuracy = 0.3033, Validation Loss = 2.3189\n",
            "Epoch 1709/3334\n",
            "Epoch 1709: Training Accuracy = 0.9746, Training Loss = 0.2088, Validation Accuracy = 0.3373, Validation Loss = 2.1429\n",
            "Epoch 1710/3334\n",
            "Epoch 1710: Training Accuracy = 0.9746, Training Loss = 0.2088, Validation Accuracy = 0.3373, Validation Loss = 2.1429\n",
            "Epoch 1711/3334\n",
            "Epoch 1711: Training Accuracy = 0.9902, Training Loss = 0.1129, Validation Accuracy = 0.3601, Validation Loss = 2.0614\n",
            "Epoch 1712/3334\n",
            "Epoch 1712: Training Accuracy = 0.9863, Training Loss = 0.1108, Validation Accuracy = 0.3707, Validation Loss = 2.0839\n",
            "Epoch 1713/3334\n",
            "Epoch 1713: Training Accuracy = 0.9863, Training Loss = 0.1108, Validation Accuracy = 0.3707, Validation Loss = 2.0839\n",
            "Epoch 1714/3334\n",
            "Epoch 1714: Training Accuracy = 0.9883, Training Loss = 0.0850, Validation Accuracy = 0.3814, Validation Loss = 2.0539\n",
            "Epoch 1715/3334\n",
            "Epoch 1715: Training Accuracy = 0.9883, Training Loss = 0.0850, Validation Accuracy = 0.3814, Validation Loss = 2.0539\n",
            "Epoch 1716/3334\n",
            "Epoch 1716: Training Accuracy = 0.9961, Training Loss = 0.0509, Validation Accuracy = 0.3782, Validation Loss = 2.0427\n",
            "Epoch 1717/3334\n",
            "Epoch 1717: Training Accuracy = 0.9922, Training Loss = 0.0635, Validation Accuracy = 0.3836, Validation Loss = 2.0430\n",
            "Epoch 1718/3334\n",
            "Epoch 1718: Training Accuracy = 0.9922, Training Loss = 0.0635, Validation Accuracy = 0.3836, Validation Loss = 2.0430\n",
            "Epoch 1719/3334\n",
            "Epoch 1719: Training Accuracy = 0.9922, Training Loss = 0.0589, Validation Accuracy = 0.3868, Validation Loss = 2.0422\n",
            "Epoch 1720/3334\n",
            "Epoch 1720: Training Accuracy = 0.9922, Training Loss = 0.0589, Validation Accuracy = 0.3868, Validation Loss = 2.0422\n",
            "Epoch 1721/3334\n",
            "Epoch 1721: Training Accuracy = 0.9980, Training Loss = 0.0479, Validation Accuracy = 0.3821, Validation Loss = 2.0668\n",
            "Epoch 1722/3334\n",
            "Epoch 1722: Training Accuracy = 0.9883, Training Loss = 0.0783, Validation Accuracy = 0.3777, Validation Loss = 2.0610\n",
            "Epoch 1723/3334\n",
            "Epoch 1723: Training Accuracy = 0.9883, Training Loss = 0.0783, Validation Accuracy = 0.3777, Validation Loss = 2.0610\n",
            "Epoch 1724/3334\n",
            "Epoch 1724: Training Accuracy = 0.9824, Training Loss = 0.0929, Validation Accuracy = 0.3771, Validation Loss = 2.0859\n",
            "Epoch 1725/3334\n",
            "Epoch 1725: Training Accuracy = 0.9824, Training Loss = 0.0929, Validation Accuracy = 0.3771, Validation Loss = 2.0859\n",
            "Epoch 1726/3334\n",
            "Epoch 1726: Training Accuracy = 0.9844, Training Loss = 0.0917, Validation Accuracy = 0.3786, Validation Loss = 2.0844\n",
            "Epoch 1727/3334\n",
            "Epoch 1727: Training Accuracy = 0.9902, Training Loss = 0.0734, Validation Accuracy = 0.3836, Validation Loss = 2.0778\n",
            "Epoch 1728/3334\n",
            "Epoch 1728: Training Accuracy = 0.9902, Training Loss = 0.0734, Validation Accuracy = 0.3836, Validation Loss = 2.0778\n",
            "Epoch 1729/3334\n",
            "Epoch 1729: Training Accuracy = 0.9844, Training Loss = 0.0956, Validation Accuracy = 0.3724, Validation Loss = 2.1083\n",
            "Epoch 1730/3334\n",
            "Epoch 1730: Training Accuracy = 0.9844, Training Loss = 0.0956, Validation Accuracy = 0.3724, Validation Loss = 2.1083\n",
            "Epoch 1731/3334\n",
            "Epoch 1731: Training Accuracy = 0.9941, Training Loss = 0.1257, Validation Accuracy = 0.2812, Validation Loss = 2.6056\n",
            "Epoch 1732/3334\n",
            "Epoch 1732: Training Accuracy = 0.9141, Training Loss = 0.6072, Validation Accuracy = 0.2995, Validation Loss = 2.3788\n",
            "Epoch 1733/3334\n",
            "Epoch 1733: Training Accuracy = 0.9141, Training Loss = 0.6072, Validation Accuracy = 0.2995, Validation Loss = 2.3788\n",
            "Epoch 1734/3334\n",
            "Epoch 1734: Training Accuracy = 0.9727, Training Loss = 0.2996, Validation Accuracy = 0.3681, Validation Loss = 2.0537\n",
            "Epoch 1735/3334\n",
            "Epoch 1735: Training Accuracy = 0.9727, Training Loss = 0.2996, Validation Accuracy = 0.3681, Validation Loss = 2.0537\n",
            "Epoch 1736/3334\n",
            "Epoch 1736: Training Accuracy = 0.9941, Training Loss = 0.1407, Validation Accuracy = 0.4138, Validation Loss = 1.9296\n",
            "Epoch 1737/3334\n",
            "Epoch 1737: Training Accuracy = 0.9844, Training Loss = 0.1369, Validation Accuracy = 0.4258, Validation Loss = 1.8496\n",
            "Epoch 1738/3334\n",
            "Epoch 1738: Training Accuracy = 0.9844, Training Loss = 0.1369, Validation Accuracy = 0.4258, Validation Loss = 1.8496\n",
            "Epoch 1739/3334\n",
            "Epoch 1739: Training Accuracy = 1.0000, Training Loss = 0.0543, Validation Accuracy = 0.4418, Validation Loss = 1.8186\n",
            "Epoch 1740/3334\n",
            "Epoch 1740: Training Accuracy = 1.0000, Training Loss = 0.0543, Validation Accuracy = 0.4418, Validation Loss = 1.8186\n",
            "Epoch 1741/3334\n",
            "Epoch 1741: Training Accuracy = 0.9902, Training Loss = 0.0834, Validation Accuracy = 0.4441, Validation Loss = 1.7999\n",
            "Epoch 1742/3334\n",
            "Epoch 1742: Training Accuracy = 0.9844, Training Loss = 0.0942, Validation Accuracy = 0.4535, Validation Loss = 1.7939\n",
            "Epoch 1743/3334\n",
            "Epoch 1743: Training Accuracy = 0.9844, Training Loss = 0.0942, Validation Accuracy = 0.4535, Validation Loss = 1.7939\n",
            "Epoch 1744/3334\n",
            "Epoch 1744: Training Accuracy = 0.9922, Training Loss = 0.0688, Validation Accuracy = 0.4548, Validation Loss = 1.7893\n",
            "Epoch 1745/3334\n",
            "Epoch 1745: Training Accuracy = 0.9922, Training Loss = 0.0688, Validation Accuracy = 0.4548, Validation Loss = 1.7893\n",
            "Epoch 1746/3334\n",
            "Epoch 1746: Training Accuracy = 0.9824, Training Loss = 0.0953, Validation Accuracy = 0.4564, Validation Loss = 1.8021\n",
            "Epoch 1747/3334\n",
            "Epoch 1747: Training Accuracy = 0.9941, Training Loss = 0.0598, Validation Accuracy = 0.4553, Validation Loss = 1.8017\n",
            "Epoch 1748/3334\n",
            "Epoch 1748: Training Accuracy = 0.9941, Training Loss = 0.0598, Validation Accuracy = 0.4553, Validation Loss = 1.8017\n",
            "Epoch 1749/3334\n",
            "Epoch 1749: Training Accuracy = 0.9961, Training Loss = 0.0498, Validation Accuracy = 0.4545, Validation Loss = 1.8065\n",
            "Epoch 1750/3334\n",
            "Epoch 1750: Training Accuracy = 0.9961, Training Loss = 0.0498, Validation Accuracy = 0.4545, Validation Loss = 1.8065\n",
            "Epoch 1751/3334\n",
            "Epoch 1751: Training Accuracy = 0.9883, Training Loss = 0.0761, Validation Accuracy = 0.4513, Validation Loss = 1.8264\n",
            "Epoch 1752/3334\n",
            "Epoch 1752: Training Accuracy = 0.9863, Training Loss = 0.0830, Validation Accuracy = 0.4475, Validation Loss = 1.8343\n",
            "Epoch 1753/3334\n",
            "Epoch 1753: Training Accuracy = 0.9863, Training Loss = 0.0830, Validation Accuracy = 0.4475, Validation Loss = 1.8343\n",
            "Epoch 1754/3334\n",
            "Epoch 1754: Training Accuracy = 0.9883, Training Loss = 0.0786, Validation Accuracy = 0.4608, Validation Loss = 1.8195\n",
            "Epoch 1755/3334\n",
            "Epoch 1755: Training Accuracy = 0.9883, Training Loss = 0.0786, Validation Accuracy = 0.4608, Validation Loss = 1.8195\n",
            "Epoch 1756/3334\n",
            "Epoch 1756: Training Accuracy = 0.9922, Training Loss = 0.0748, Validation Accuracy = 0.4554, Validation Loss = 1.8316\n",
            "Epoch 1757/3334\n",
            "Epoch 1757: Training Accuracy = 0.9785, Training Loss = 0.2576, Validation Accuracy = 0.2707, Validation Loss = 2.7436\n",
            "Epoch 1758/3334\n",
            "Epoch 1758: Training Accuracy = 0.9785, Training Loss = 0.2576, Validation Accuracy = 0.2707, Validation Loss = 2.7436\n",
            "Epoch 1759/3334\n",
            "Epoch 1759: Training Accuracy = 0.9473, Training Loss = 0.4742, Validation Accuracy = 0.3568, Validation Loss = 2.1337\n",
            "Epoch 1760/3334\n",
            "Epoch 1760: Training Accuracy = 0.9473, Training Loss = 0.4742, Validation Accuracy = 0.3568, Validation Loss = 2.1337\n",
            "Epoch 1761/3334\n",
            "Epoch 1761: Training Accuracy = 0.9746, Training Loss = 0.2477, Validation Accuracy = 0.4284, Validation Loss = 1.7904\n",
            "Epoch 1762/3334\n",
            "Epoch 1762: Training Accuracy = 0.9863, Training Loss = 0.1607, Validation Accuracy = 0.4828, Validation Loss = 1.6577\n",
            "Epoch 1763/3334\n",
            "Epoch 1763: Training Accuracy = 0.9863, Training Loss = 0.1607, Validation Accuracy = 0.4828, Validation Loss = 1.6577\n",
            "Epoch 1764/3334\n",
            "Epoch 1764: Training Accuracy = 0.9941, Training Loss = 0.0911, Validation Accuracy = 0.5065, Validation Loss = 1.5798\n",
            "Epoch 1765/3334\n",
            "Epoch 1765: Training Accuracy = 0.9941, Training Loss = 0.0911, Validation Accuracy = 0.5065, Validation Loss = 1.5798\n",
            "Epoch 1766/3334\n",
            "Epoch 1766: Training Accuracy = 0.9941, Training Loss = 0.0734, Validation Accuracy = 0.5265, Validation Loss = 1.5496\n",
            "Epoch 1767/3334\n",
            "Epoch 1767: Training Accuracy = 0.9863, Training Loss = 0.0963, Validation Accuracy = 0.5292, Validation Loss = 1.5428\n",
            "Epoch 1768/3334\n",
            "Epoch 1768: Training Accuracy = 0.9863, Training Loss = 0.0963, Validation Accuracy = 0.5292, Validation Loss = 1.5428\n",
            "Epoch 1769/3334\n",
            "Epoch 1769: Training Accuracy = 0.9922, Training Loss = 0.0738, Validation Accuracy = 0.5315, Validation Loss = 1.5390\n",
            "Epoch 1770/3334\n",
            "Epoch 1770: Training Accuracy = 0.9922, Training Loss = 0.0738, Validation Accuracy = 0.5315, Validation Loss = 1.5390\n",
            "Epoch 1771/3334\n",
            "Epoch 1771: Training Accuracy = 0.9902, Training Loss = 0.0716, Validation Accuracy = 0.5269, Validation Loss = 1.5596\n",
            "Epoch 1772/3334\n",
            "Epoch 1772: Training Accuracy = 0.9922, Training Loss = 0.0669, Validation Accuracy = 0.5297, Validation Loss = 1.5563\n",
            "Epoch 1773/3334\n",
            "Epoch 1773: Training Accuracy = 0.9922, Training Loss = 0.0669, Validation Accuracy = 0.5297, Validation Loss = 1.5563\n",
            "Epoch 1774/3334\n",
            "Epoch 1774: Training Accuracy = 1.0000, Training Loss = 0.0401, Validation Accuracy = 0.5291, Validation Loss = 1.5486\n",
            "Epoch 1775/3334\n",
            "Epoch 1775: Training Accuracy = 1.0000, Training Loss = 0.0401, Validation Accuracy = 0.5291, Validation Loss = 1.5486\n",
            "Epoch 1776/3334\n",
            "Epoch 1776: Training Accuracy = 0.9883, Training Loss = 0.0801, Validation Accuracy = 0.5289, Validation Loss = 1.5605\n",
            "Epoch 1777/3334\n",
            "Epoch 1777: Training Accuracy = 0.9922, Training Loss = 0.0718, Validation Accuracy = 0.5248, Validation Loss = 1.5665\n",
            "Epoch 1778/3334\n",
            "Epoch 1778: Training Accuracy = 0.9922, Training Loss = 0.0718, Validation Accuracy = 0.5248, Validation Loss = 1.5665\n",
            "Epoch 1779/3334\n",
            "Epoch 1779: Training Accuracy = 0.9863, Training Loss = 0.0918, Validation Accuracy = 0.5288, Validation Loss = 1.5774\n",
            "Epoch 1780/3334\n",
            "Epoch 1780: Training Accuracy = 0.9863, Training Loss = 0.0918, Validation Accuracy = 0.5288, Validation Loss = 1.5774\n",
            "Epoch 1781/3334\n",
            "Epoch 1781: Training Accuracy = 0.9883, Training Loss = 0.0822, Validation Accuracy = 0.5140, Validation Loss = 1.6113\n",
            "Epoch 1782/3334\n",
            "Epoch 1782: Training Accuracy = 0.9941, Training Loss = 0.0662, Validation Accuracy = 0.5248, Validation Loss = 1.6048\n",
            "Epoch 1783/3334\n",
            "Epoch 1783: Training Accuracy = 0.9941, Training Loss = 0.0662, Validation Accuracy = 0.5248, Validation Loss = 1.6048\n",
            "Epoch 1784/3334\n",
            "Epoch 1784: Training Accuracy = 0.9844, Training Loss = 0.1249, Validation Accuracy = 0.5028, Validation Loss = 1.6716\n",
            "Epoch 1785/3334\n",
            "Epoch 1785: Training Accuracy = 0.9844, Training Loss = 0.1249, Validation Accuracy = 0.5028, Validation Loss = 1.6716\n",
            "Epoch 1786/3334\n",
            "Epoch 1786: Training Accuracy = 0.8203, Training Loss = 0.9809, Validation Accuracy = 0.3027, Validation Loss = 2.5873\n",
            "Epoch 1787/3334\n",
            "Epoch 1787: Training Accuracy = 0.9414, Training Loss = 0.4174, Validation Accuracy = 0.4263, Validation Loss = 1.8723\n",
            "Epoch 1788/3334\n",
            "Epoch 1788: Training Accuracy = 0.9414, Training Loss = 0.4174, Validation Accuracy = 0.4263, Validation Loss = 1.8723\n",
            "Epoch 1789/3334\n",
            "Epoch 1789: Training Accuracy = 0.9805, Training Loss = 0.2247, Validation Accuracy = 0.4976, Validation Loss = 1.6192\n",
            "Epoch 1790/3334\n",
            "Epoch 1790: Training Accuracy = 0.9805, Training Loss = 0.2247, Validation Accuracy = 0.4976, Validation Loss = 1.6192\n",
            "Epoch 1791/3334\n",
            "Epoch 1791: Training Accuracy = 0.9941, Training Loss = 0.1166, Validation Accuracy = 0.5521, Validation Loss = 1.4731\n",
            "Epoch 1792/3334\n",
            "Epoch 1792: Training Accuracy = 0.9863, Training Loss = 0.1076, Validation Accuracy = 0.5819, Validation Loss = 1.3905\n",
            "Epoch 1793/3334\n",
            "Epoch 1793: Training Accuracy = 0.9863, Training Loss = 0.1076, Validation Accuracy = 0.5819, Validation Loss = 1.3905\n",
            "Epoch 1794/3334\n",
            "Epoch 1794: Training Accuracy = 0.9883, Training Loss = 0.0928, Validation Accuracy = 0.5884, Validation Loss = 1.3613\n",
            "Epoch 1795/3334\n",
            "Epoch 1795: Training Accuracy = 0.9883, Training Loss = 0.0928, Validation Accuracy = 0.5884, Validation Loss = 1.3613\n",
            "Epoch 1796/3334\n",
            "Epoch 1796: Training Accuracy = 0.9941, Training Loss = 0.0605, Validation Accuracy = 0.5965, Validation Loss = 1.3364\n",
            "Epoch 1797/3334\n",
            "Epoch 1797: Training Accuracy = 0.9961, Training Loss = 0.0542, Validation Accuracy = 0.5959, Validation Loss = 1.3396\n",
            "Epoch 1798/3334\n",
            "Epoch 1798: Training Accuracy = 0.9961, Training Loss = 0.0542, Validation Accuracy = 0.5959, Validation Loss = 1.3396\n",
            "Epoch 1799/3334\n",
            "Epoch 1799: Training Accuracy = 0.9863, Training Loss = 0.0853, Validation Accuracy = 0.6003, Validation Loss = 1.3296\n",
            "Epoch 1800/3334\n",
            "Epoch 1800: Training Accuracy = 0.9863, Training Loss = 0.0853, Validation Accuracy = 0.6003, Validation Loss = 1.3296\n",
            "Epoch 1801/3334\n",
            "Epoch 1801: Training Accuracy = 0.9902, Training Loss = 0.0703, Validation Accuracy = 0.6009, Validation Loss = 1.3430\n",
            "Epoch 1802/3334\n",
            "Epoch 1802: Training Accuracy = 0.9902, Training Loss = 0.0743, Validation Accuracy = 0.6030, Validation Loss = 1.3305\n",
            "Epoch 1803/3334\n",
            "Epoch 1803: Training Accuracy = 0.9902, Training Loss = 0.0743, Validation Accuracy = 0.6030, Validation Loss = 1.3305\n",
            "Epoch 1804/3334\n",
            "Epoch 1804: Training Accuracy = 0.9922, Training Loss = 0.0638, Validation Accuracy = 0.6077, Validation Loss = 1.3405\n",
            "Epoch 1805/3334\n",
            "Epoch 1805: Training Accuracy = 0.9922, Training Loss = 0.0638, Validation Accuracy = 0.6077, Validation Loss = 1.3405\n",
            "Epoch 1806/3334\n",
            "Epoch 1806: Training Accuracy = 0.9902, Training Loss = 0.0686, Validation Accuracy = 0.6085, Validation Loss = 1.3348\n",
            "Epoch 1807/3334\n",
            "Epoch 1807: Training Accuracy = 0.9902, Training Loss = 0.0746, Validation Accuracy = 0.6010, Validation Loss = 1.3504\n",
            "Epoch 1808/3334\n",
            "Epoch 1808: Training Accuracy = 0.9902, Training Loss = 0.0746, Validation Accuracy = 0.6010, Validation Loss = 1.3504\n",
            "Epoch 1809/3334\n",
            "Epoch 1809: Training Accuracy = 0.9863, Training Loss = 0.0884, Validation Accuracy = 0.6065, Validation Loss = 1.3539\n",
            "Epoch 1810/3334\n",
            "Epoch 1810: Training Accuracy = 0.9863, Training Loss = 0.0884, Validation Accuracy = 0.6065, Validation Loss = 1.3539\n",
            "Epoch 1811/3334\n",
            "Epoch 1811: Training Accuracy = 0.9844, Training Loss = 0.1111, Validation Accuracy = 0.5942, Validation Loss = 1.3949\n",
            "Epoch 1812/3334\n",
            "Epoch 1812: Training Accuracy = 0.9902, Training Loss = 0.1134, Validation Accuracy = 0.5635, Validation Loss = 1.4909\n",
            "Epoch 1813/3334\n",
            "Epoch 1813: Training Accuracy = 0.9902, Training Loss = 0.1134, Validation Accuracy = 0.5635, Validation Loss = 1.4909\n",
            "Epoch 1814/3334\n",
            "Epoch 1814: Training Accuracy = 0.9883, Training Loss = 0.2159, Validation Accuracy = 0.5418, Validation Loss = 1.5740\n",
            "Epoch 1815/3334\n",
            "Epoch 1815: Training Accuracy = 0.9883, Training Loss = 0.2159, Validation Accuracy = 0.5418, Validation Loss = 1.5740\n",
            "Epoch 1816/3334\n",
            "Epoch 1816: Training Accuracy = 0.9922, Training Loss = 0.1484, Validation Accuracy = 0.5734, Validation Loss = 1.4518\n",
            "Epoch 1817/3334\n",
            "Epoch 1817: Training Accuracy = 0.9922, Training Loss = 0.1048, Validation Accuracy = 0.5960, Validation Loss = 1.3820\n",
            "Epoch 1818/3334\n",
            "Epoch 1818: Training Accuracy = 0.9922, Training Loss = 0.1048, Validation Accuracy = 0.5960, Validation Loss = 1.3820\n",
            "Epoch 1819/3334\n",
            "Epoch 1819: Training Accuracy = 0.9883, Training Loss = 0.1125, Validation Accuracy = 0.6100, Validation Loss = 1.3086\n",
            "Epoch 1820/3334\n",
            "Epoch 1820: Training Accuracy = 0.9883, Training Loss = 0.1125, Validation Accuracy = 0.6100, Validation Loss = 1.3086\n",
            "Epoch 1821/3334\n",
            "Epoch 1821: Training Accuracy = 0.9941, Training Loss = 0.0637, Validation Accuracy = 0.6372, Validation Loss = 1.2457\n",
            "Epoch 1822/3334\n",
            "Epoch 1822: Training Accuracy = 0.9902, Training Loss = 0.0703, Validation Accuracy = 0.6639, Validation Loss = 1.1765\n",
            "Epoch 1823/3334\n",
            "Epoch 1823: Training Accuracy = 0.9902, Training Loss = 0.0703, Validation Accuracy = 0.6639, Validation Loss = 1.1765\n",
            "Epoch 1824/3334\n",
            "Epoch 1824: Training Accuracy = 0.9941, Training Loss = 0.0507, Validation Accuracy = 0.6545, Validation Loss = 1.1937\n",
            "Epoch 1825/3334\n",
            "Epoch 1825: Training Accuracy = 0.9941, Training Loss = 0.0507, Validation Accuracy = 0.6545, Validation Loss = 1.1937\n",
            "Epoch 1826/3334\n",
            "Epoch 1826: Training Accuracy = 0.9922, Training Loss = 0.0598, Validation Accuracy = 0.6589, Validation Loss = 1.1989\n",
            "Epoch 1827/3334\n",
            "Epoch 1827: Training Accuracy = 0.9941, Training Loss = 0.0520, Validation Accuracy = 0.6487, Validation Loss = 1.2041\n",
            "Epoch 1828/3334\n",
            "Epoch 1828: Training Accuracy = 0.9941, Training Loss = 0.0520, Validation Accuracy = 0.6487, Validation Loss = 1.2041\n",
            "Epoch 1829/3334\n",
            "Epoch 1829: Training Accuracy = 0.9980, Training Loss = 0.0368, Validation Accuracy = 0.6517, Validation Loss = 1.2019\n",
            "Epoch 1830/3334\n",
            "Epoch 1830: Training Accuracy = 0.9980, Training Loss = 0.0368, Validation Accuracy = 0.6517, Validation Loss = 1.2019\n",
            "Epoch 1831/3334\n",
            "Epoch 1831: Training Accuracy = 0.9902, Training Loss = 0.0772, Validation Accuracy = 0.6416, Validation Loss = 1.2540\n",
            "Epoch 1832/3334\n",
            "Epoch 1832: Training Accuracy = 0.7891, Training Loss = 1.1284, Validation Accuracy = 0.3364, Validation Loss = 2.4105\n",
            "Epoch 1833/3334\n",
            "Epoch 1833: Training Accuracy = 0.7891, Training Loss = 1.1284, Validation Accuracy = 0.3364, Validation Loss = 2.4105\n",
            "Epoch 1834/3334\n",
            "Epoch 1834: Training Accuracy = 0.9609, Training Loss = 0.3496, Validation Accuracy = 0.5402, Validation Loss = 1.5026\n",
            "Epoch 1835/3334\n",
            "Epoch 1835: Training Accuracy = 0.9609, Training Loss = 0.3496, Validation Accuracy = 0.5402, Validation Loss = 1.5026\n",
            "Epoch 1836/3334\n",
            "Epoch 1836: Training Accuracy = 0.9941, Training Loss = 0.1603, Validation Accuracy = 0.6024, Validation Loss = 1.2788\n",
            "Epoch 1837/3334\n",
            "Epoch 1837: Training Accuracy = 0.9883, Training Loss = 0.1273, Validation Accuracy = 0.6577, Validation Loss = 1.1355\n",
            "Epoch 1838/3334\n",
            "Epoch 1838: Training Accuracy = 0.9883, Training Loss = 0.1273, Validation Accuracy = 0.6577, Validation Loss = 1.1355\n",
            "Epoch 1839/3334\n",
            "Epoch 1839: Training Accuracy = 0.9863, Training Loss = 0.1075, Validation Accuracy = 0.6892, Validation Loss = 1.0739\n",
            "Epoch 1840/3334\n",
            "Epoch 1840: Training Accuracy = 0.9863, Training Loss = 0.1075, Validation Accuracy = 0.6892, Validation Loss = 1.0739\n",
            "Epoch 1841/3334\n",
            "Epoch 1841: Training Accuracy = 0.9883, Training Loss = 0.0802, Validation Accuracy = 0.7015, Validation Loss = 1.0301\n",
            "Epoch 1842/3334\n",
            "Epoch 1842: Training Accuracy = 0.9902, Training Loss = 0.0707, Validation Accuracy = 0.7137, Validation Loss = 1.0021\n",
            "Epoch 1843/3334\n",
            "Epoch 1843: Training Accuracy = 0.9902, Training Loss = 0.0707, Validation Accuracy = 0.7137, Validation Loss = 1.0021\n",
            "Epoch 1844/3334\n",
            "Epoch 1844: Training Accuracy = 0.9941, Training Loss = 0.0514, Validation Accuracy = 0.7141, Validation Loss = 0.9972\n",
            "Epoch 1845/3334\n",
            "Epoch 1845: Training Accuracy = 0.9941, Training Loss = 0.0514, Validation Accuracy = 0.7141, Validation Loss = 0.9972\n",
            "Epoch 1846/3334\n",
            "Epoch 1846: Training Accuracy = 0.9883, Training Loss = 0.0712, Validation Accuracy = 0.7193, Validation Loss = 0.9999\n",
            "Epoch 1847/3334\n",
            "Epoch 1847: Training Accuracy = 0.9941, Training Loss = 0.0534, Validation Accuracy = 0.7155, Validation Loss = 1.0171\n",
            "Epoch 1848/3334\n",
            "Epoch 1848: Training Accuracy = 0.9941, Training Loss = 0.0534, Validation Accuracy = 0.7155, Validation Loss = 1.0171\n",
            "Epoch 1849/3334\n",
            "Epoch 1849: Training Accuracy = 0.9863, Training Loss = 0.0798, Validation Accuracy = 0.7205, Validation Loss = 1.0019\n",
            "Epoch 1850/3334\n",
            "Epoch 1850: Training Accuracy = 0.9863, Training Loss = 0.0798, Validation Accuracy = 0.7205, Validation Loss = 1.0019\n",
            "Epoch 1851/3334\n",
            "Epoch 1851: Training Accuracy = 0.9922, Training Loss = 0.0560, Validation Accuracy = 0.7182, Validation Loss = 1.0024\n",
            "Epoch 1852/3334\n",
            "Epoch 1852: Training Accuracy = 0.9844, Training Loss = 0.0865, Validation Accuracy = 0.7184, Validation Loss = 1.0180\n",
            "Epoch 1853/3334\n",
            "Epoch 1853: Training Accuracy = 0.9844, Training Loss = 0.0865, Validation Accuracy = 0.7184, Validation Loss = 1.0180\n",
            "Epoch 1854/3334\n",
            "Epoch 1854: Training Accuracy = 0.9922, Training Loss = 0.0570, Validation Accuracy = 0.7191, Validation Loss = 1.0261\n",
            "Epoch 1855/3334\n",
            "Epoch 1855: Training Accuracy = 0.9922, Training Loss = 0.0570, Validation Accuracy = 0.7191, Validation Loss = 1.0261\n",
            "Epoch 1856/3334\n",
            "Epoch 1856: Training Accuracy = 0.9902, Training Loss = 0.0689, Validation Accuracy = 0.7111, Validation Loss = 1.0366\n",
            "Epoch 1857/3334\n",
            "Epoch 1857: Training Accuracy = 0.9824, Training Loss = 0.1013, Validation Accuracy = 0.7188, Validation Loss = 1.0278\n",
            "Epoch 1858/3334\n",
            "Epoch 1858: Training Accuracy = 0.9824, Training Loss = 0.1013, Validation Accuracy = 0.7188, Validation Loss = 1.0278\n",
            "Epoch 1859/3334\n",
            "Epoch 1859: Training Accuracy = 0.9922, Training Loss = 0.0644, Validation Accuracy = 0.7196, Validation Loss = 1.0277\n",
            "Epoch 1860/3334\n",
            "Epoch 1860: Training Accuracy = 0.9922, Training Loss = 0.0644, Validation Accuracy = 0.7196, Validation Loss = 1.0277\n",
            "Epoch 1861/3334\n",
            "Epoch 1861: Training Accuracy = 0.9883, Training Loss = 0.0808, Validation Accuracy = 0.7023, Validation Loss = 1.0676\n",
            "Epoch 1862/3334\n",
            "Epoch 1862: Training Accuracy = 0.9883, Training Loss = 0.1465, Validation Accuracy = 0.5297, Validation Loss = 1.6557\n",
            "Epoch 1863/3334\n",
            "Epoch 1863: Training Accuracy = 0.9883, Training Loss = 0.1465, Validation Accuracy = 0.5297, Validation Loss = 1.6557\n",
            "Epoch 1864/3334\n",
            "Epoch 1864: Training Accuracy = 0.8652, Training Loss = 0.7326, Validation Accuracy = 0.4800, Validation Loss = 1.8316\n",
            "Epoch 1865/3334\n",
            "Epoch 1865: Training Accuracy = 0.8652, Training Loss = 0.7326, Validation Accuracy = 0.4800, Validation Loss = 1.8316\n",
            "Epoch 1866/3334\n",
            "Epoch 1866: Training Accuracy = 0.9844, Training Loss = 0.2847, Validation Accuracy = 0.6126, Validation Loss = 1.3005\n",
            "Epoch 1867/3334\n",
            "Epoch 1867: Training Accuracy = 0.9922, Training Loss = 0.1695, Validation Accuracy = 0.7000, Validation Loss = 1.0646\n",
            "Epoch 1868/3334\n",
            "Epoch 1868: Training Accuracy = 0.9922, Training Loss = 0.1695, Validation Accuracy = 0.7000, Validation Loss = 1.0646\n",
            "Epoch 1869/3334\n",
            "Epoch 1869: Training Accuracy = 0.9863, Training Loss = 0.1209, Validation Accuracy = 0.7346, Validation Loss = 0.9516\n",
            "Epoch 1870/3334\n",
            "Epoch 1870: Training Accuracy = 0.9863, Training Loss = 0.1209, Validation Accuracy = 0.7346, Validation Loss = 0.9516\n",
            "Epoch 1871/3334\n",
            "Epoch 1871: Training Accuracy = 0.9824, Training Loss = 0.1122, Validation Accuracy = 0.7659, Validation Loss = 0.8827\n",
            "Epoch 1872/3334\n",
            "Epoch 1872: Training Accuracy = 0.9922, Training Loss = 0.0725, Validation Accuracy = 0.7802, Validation Loss = 0.8357\n",
            "Epoch 1873/3334\n",
            "Epoch 1873: Training Accuracy = 0.9922, Training Loss = 0.0725, Validation Accuracy = 0.7802, Validation Loss = 0.8357\n",
            "Epoch 1874/3334\n",
            "Epoch 1874: Training Accuracy = 0.9961, Training Loss = 0.0521, Validation Accuracy = 0.7902, Validation Loss = 0.8152\n",
            "Epoch 1875/3334\n",
            "Epoch 1875: Training Accuracy = 0.9961, Training Loss = 0.0521, Validation Accuracy = 0.7902, Validation Loss = 0.8152\n",
            "Epoch 1876/3334\n",
            "Epoch 1876: Training Accuracy = 0.9980, Training Loss = 0.0407, Validation Accuracy = 0.7790, Validation Loss = 0.8299\n",
            "Epoch 1877/3334\n",
            "Epoch 1877: Training Accuracy = 0.9922, Training Loss = 0.0634, Validation Accuracy = 0.7890, Validation Loss = 0.8172\n",
            "Epoch 1878/3334\n",
            "Epoch 1878: Training Accuracy = 0.9922, Training Loss = 0.0634, Validation Accuracy = 0.7890, Validation Loss = 0.8172\n",
            "Epoch 1879/3334\n",
            "Epoch 1879: Training Accuracy = 0.9883, Training Loss = 0.0810, Validation Accuracy = 0.7879, Validation Loss = 0.8102\n",
            "Epoch 1880/3334\n",
            "Epoch 1880: Training Accuracy = 0.9883, Training Loss = 0.0810, Validation Accuracy = 0.7879, Validation Loss = 0.8102\n",
            "Epoch 1881/3334\n",
            "Epoch 1881: Training Accuracy = 0.9941, Training Loss = 0.0578, Validation Accuracy = 0.7917, Validation Loss = 0.8194\n",
            "Epoch 1882/3334\n",
            "Epoch 1882: Training Accuracy = 0.9863, Training Loss = 0.0825, Validation Accuracy = 0.7908, Validation Loss = 0.8199\n",
            "Epoch 1883/3334\n",
            "Epoch 1883: Training Accuracy = 0.9863, Training Loss = 0.0825, Validation Accuracy = 0.7908, Validation Loss = 0.8199\n",
            "Epoch 1884/3334\n",
            "Epoch 1884: Training Accuracy = 0.9883, Training Loss = 0.0751, Validation Accuracy = 0.7869, Validation Loss = 0.8300\n",
            "Epoch 1885/3334\n",
            "Epoch 1885: Training Accuracy = 0.9883, Training Loss = 0.0751, Validation Accuracy = 0.7869, Validation Loss = 0.8300\n",
            "Epoch 1886/3334\n",
            "Epoch 1886: Training Accuracy = 0.9902, Training Loss = 0.0667, Validation Accuracy = 0.7849, Validation Loss = 0.8276\n",
            "Epoch 1887/3334\n",
            "Epoch 1887: Training Accuracy = 0.9922, Training Loss = 0.0656, Validation Accuracy = 0.7951, Validation Loss = 0.8191\n",
            "Epoch 1888/3334\n",
            "Epoch 1888: Training Accuracy = 0.9922, Training Loss = 0.0656, Validation Accuracy = 0.7951, Validation Loss = 0.8191\n",
            "Epoch 1889/3334\n",
            "Epoch 1889: Training Accuracy = 0.9844, Training Loss = 0.0930, Validation Accuracy = 0.7887, Validation Loss = 0.8463\n",
            "Epoch 1890/3334\n",
            "Epoch 1890: Training Accuracy = 0.9844, Training Loss = 0.0930, Validation Accuracy = 0.7887, Validation Loss = 0.8463\n",
            "Epoch 1891/3334\n",
            "Epoch 1891: Training Accuracy = 0.9902, Training Loss = 0.0796, Validation Accuracy = 0.7958, Validation Loss = 0.8415\n",
            "Epoch 1892/3334\n",
            "Epoch 1892: Training Accuracy = 0.9902, Training Loss = 0.1009, Validation Accuracy = 0.7360, Validation Loss = 0.9904\n",
            "Epoch 1893/3334\n",
            "Epoch 1893: Training Accuracy = 0.9902, Training Loss = 0.1009, Validation Accuracy = 0.7360, Validation Loss = 0.9904\n",
            "Epoch 1894/3334\n",
            "Epoch 1894: Training Accuracy = 0.9961, Training Loss = 0.0913, Validation Accuracy = 0.7299, Validation Loss = 1.0372\n",
            "Epoch 1895/3334\n",
            "Epoch 1895: Training Accuracy = 0.9961, Training Loss = 0.0913, Validation Accuracy = 0.7299, Validation Loss = 1.0372\n",
            "Epoch 1896/3334\n",
            "Epoch 1896: Training Accuracy = 0.9766, Training Loss = 0.1473, Validation Accuracy = 0.7237, Validation Loss = 1.0356\n",
            "Epoch 1897/3334\n",
            "Epoch 1897: Training Accuracy = 0.9863, Training Loss = 0.1241, Validation Accuracy = 0.7676, Validation Loss = 0.9276\n",
            "Epoch 1898/3334\n",
            "Epoch 1898: Training Accuracy = 0.9863, Training Loss = 0.1241, Validation Accuracy = 0.7676, Validation Loss = 0.9276\n",
            "Epoch 1899/3334\n",
            "Epoch 1899: Training Accuracy = 0.9980, Training Loss = 0.0606, Validation Accuracy = 0.7899, Validation Loss = 0.8183\n",
            "Epoch 1900/3334\n",
            "Epoch 1900: Training Accuracy = 0.9980, Training Loss = 0.0606, Validation Accuracy = 0.7899, Validation Loss = 0.8183\n",
            "Epoch 1901/3334\n",
            "Epoch 1901: Training Accuracy = 0.9902, Training Loss = 0.0692, Validation Accuracy = 0.8008, Validation Loss = 0.7953\n",
            "Epoch 1902/3334\n",
            "Epoch 1902: Training Accuracy = 0.9941, Training Loss = 0.0574, Validation Accuracy = 0.8054, Validation Loss = 0.7477\n",
            "Epoch 1903/3334\n",
            "Epoch 1903: Training Accuracy = 0.9941, Training Loss = 0.0574, Validation Accuracy = 0.8054, Validation Loss = 0.7477\n",
            "Epoch 1904/3334\n",
            "Epoch 1904: Training Accuracy = 0.9805, Training Loss = 0.0989, Validation Accuracy = 0.8198, Validation Loss = 0.7256\n",
            "Epoch 1905/3334\n",
            "Epoch 1905: Training Accuracy = 0.9805, Training Loss = 0.0989, Validation Accuracy = 0.8198, Validation Loss = 0.7256\n",
            "Epoch 1906/3334\n",
            "Epoch 1906: Training Accuracy = 0.9883, Training Loss = 0.0705, Validation Accuracy = 0.8228, Validation Loss = 0.7246\n",
            "Epoch 1907/3334\n",
            "Epoch 1907: Training Accuracy = 0.9922, Training Loss = 0.0547, Validation Accuracy = 0.8280, Validation Loss = 0.7084\n",
            "Epoch 1908/3334\n",
            "Epoch 1908: Training Accuracy = 0.9922, Training Loss = 0.0547, Validation Accuracy = 0.8280, Validation Loss = 0.7084\n",
            "Epoch 1909/3334\n",
            "Epoch 1909: Training Accuracy = 0.9980, Training Loss = 0.0331, Validation Accuracy = 0.8256, Validation Loss = 0.7111\n",
            "Epoch 1910/3334\n",
            "Epoch 1910: Training Accuracy = 0.9980, Training Loss = 0.0331, Validation Accuracy = 0.8256, Validation Loss = 0.7111\n",
            "Epoch 1911/3334\n",
            "Epoch 1911: Training Accuracy = 0.9863, Training Loss = 0.0742, Validation Accuracy = 0.8253, Validation Loss = 0.7277\n",
            "Epoch 1912/3334\n",
            "Epoch 1912: Training Accuracy = 0.9844, Training Loss = 0.0845, Validation Accuracy = 0.8301, Validation Loss = 0.7163\n",
            "Epoch 1913/3334\n",
            "Epoch 1913: Training Accuracy = 0.9844, Training Loss = 0.0845, Validation Accuracy = 0.8301, Validation Loss = 0.7163\n",
            "Epoch 1914/3334\n",
            "Epoch 1914: Training Accuracy = 0.9824, Training Loss = 0.0916, Validation Accuracy = 0.8206, Validation Loss = 0.7496\n",
            "Epoch 1915/3334\n",
            "Epoch 1915: Training Accuracy = 0.9824, Training Loss = 0.0916, Validation Accuracy = 0.8206, Validation Loss = 0.7496\n",
            "Epoch 1916/3334\n",
            "Epoch 1916: Training Accuracy = 0.8438, Training Loss = 0.6858, Validation Accuracy = 0.1769, Validation Loss = 3.8683\n",
            "Epoch 1917/3334\n",
            "Epoch 1917: Training Accuracy = 0.9082, Training Loss = 0.5691, Validation Accuracy = 0.5918, Validation Loss = 1.4471\n",
            "Epoch 1918/3334\n",
            "Epoch 1918: Training Accuracy = 0.9082, Training Loss = 0.5691, Validation Accuracy = 0.5918, Validation Loss = 1.4471\n",
            "Epoch 1919/3334\n",
            "Epoch 1919: Training Accuracy = 0.9824, Training Loss = 0.2466, Validation Accuracy = 0.7226, Validation Loss = 1.0325\n",
            "Epoch 1920/3334\n",
            "Epoch 1920: Training Accuracy = 0.9824, Training Loss = 0.2466, Validation Accuracy = 0.7226, Validation Loss = 1.0325\n",
            "Epoch 1921/3334\n",
            "Epoch 1921: Training Accuracy = 0.9883, Training Loss = 0.1401, Validation Accuracy = 0.7949, Validation Loss = 0.8066\n",
            "Epoch 1922/3334\n",
            "Epoch 1922: Training Accuracy = 0.9902, Training Loss = 0.0955, Validation Accuracy = 0.8313, Validation Loss = 0.6867\n",
            "Epoch 1923/3334\n",
            "Epoch 1923: Training Accuracy = 0.9902, Training Loss = 0.0955, Validation Accuracy = 0.8313, Validation Loss = 0.6867\n",
            "Epoch 1924/3334\n",
            "Epoch 1924: Training Accuracy = 0.9961, Training Loss = 0.0570, Validation Accuracy = 0.8533, Validation Loss = 0.6149\n",
            "Epoch 1925/3334\n",
            "Epoch 1925: Training Accuracy = 0.9961, Training Loss = 0.0570, Validation Accuracy = 0.8533, Validation Loss = 0.6149\n",
            "Epoch 1926/3334\n",
            "Epoch 1926: Training Accuracy = 0.9922, Training Loss = 0.0609, Validation Accuracy = 0.8640, Validation Loss = 0.5886\n",
            "Epoch 1927/3334\n",
            "Epoch 1927: Training Accuracy = 0.9961, Training Loss = 0.0447, Validation Accuracy = 0.8723, Validation Loss = 0.5621\n",
            "Epoch 1928/3334\n",
            "Epoch 1928: Training Accuracy = 0.9961, Training Loss = 0.0447, Validation Accuracy = 0.8723, Validation Loss = 0.5621\n",
            "Epoch 1929/3334\n",
            "Epoch 1929: Training Accuracy = 0.9941, Training Loss = 0.0555, Validation Accuracy = 0.8735, Validation Loss = 0.5629\n",
            "Epoch 1930/3334\n",
            "Epoch 1930: Training Accuracy = 0.9941, Training Loss = 0.0555, Validation Accuracy = 0.8735, Validation Loss = 0.5629\n",
            "Epoch 1931/3334\n",
            "Epoch 1931: Training Accuracy = 0.9922, Training Loss = 0.0589, Validation Accuracy = 0.8770, Validation Loss = 0.5610\n",
            "Epoch 1932/3334\n",
            "Epoch 1932: Training Accuracy = 0.9961, Training Loss = 0.0481, Validation Accuracy = 0.8748, Validation Loss = 0.5646\n",
            "Epoch 1933/3334\n",
            "Epoch 1933: Training Accuracy = 0.9961, Training Loss = 0.0481, Validation Accuracy = 0.8748, Validation Loss = 0.5646\n",
            "Epoch 1934/3334\n",
            "Epoch 1934: Training Accuracy = 0.9922, Training Loss = 0.0558, Validation Accuracy = 0.8767, Validation Loss = 0.5640\n",
            "Epoch 1935/3334\n",
            "Epoch 1935: Training Accuracy = 0.9922, Training Loss = 0.0558, Validation Accuracy = 0.8767, Validation Loss = 0.5640\n",
            "Epoch 1936/3334\n",
            "Epoch 1936: Training Accuracy = 0.9883, Training Loss = 0.0671, Validation Accuracy = 0.8675, Validation Loss = 0.5799\n",
            "Epoch 1937/3334\n",
            "Epoch 1937: Training Accuracy = 0.9922, Training Loss = 0.0577, Validation Accuracy = 0.8738, Validation Loss = 0.5724\n",
            "Epoch 1938/3334\n",
            "Epoch 1938: Training Accuracy = 0.9922, Training Loss = 0.0577, Validation Accuracy = 0.8738, Validation Loss = 0.5724\n",
            "Epoch 1939/3334\n",
            "Epoch 1939: Training Accuracy = 0.9883, Training Loss = 0.0718, Validation Accuracy = 0.8734, Validation Loss = 0.5792\n",
            "Epoch 1940/3334\n",
            "Epoch 1940: Training Accuracy = 0.9883, Training Loss = 0.0718, Validation Accuracy = 0.8734, Validation Loss = 0.5792\n",
            "Epoch 1941/3334\n",
            "Epoch 1941: Training Accuracy = 0.9902, Training Loss = 0.0633, Validation Accuracy = 0.8810, Validation Loss = 0.5652\n",
            "Epoch 1942/3334\n",
            "Epoch 1942: Training Accuracy = 0.9922, Training Loss = 0.0593, Validation Accuracy = 0.8670, Validation Loss = 0.6042\n",
            "Epoch 1943/3334\n",
            "Epoch 1943: Training Accuracy = 0.9922, Training Loss = 0.0593, Validation Accuracy = 0.8670, Validation Loss = 0.6042\n",
            "Epoch 1944/3334\n",
            "Epoch 1944: Training Accuracy = 0.9902, Training Loss = 0.0637, Validation Accuracy = 0.8690, Validation Loss = 0.6053\n",
            "Epoch 1945/3334\n",
            "Epoch 1945: Training Accuracy = 0.9902, Training Loss = 0.0637, Validation Accuracy = 0.8690, Validation Loss = 0.6053\n",
            "Epoch 1946/3334\n",
            "Epoch 1946: Training Accuracy = 0.9902, Training Loss = 0.0688, Validation Accuracy = 0.8755, Validation Loss = 0.5965\n",
            "Epoch 1947/3334\n",
            "Epoch 1947: Training Accuracy = 0.9961, Training Loss = 0.0525, Validation Accuracy = 0.8789, Validation Loss = 0.5857\n",
            "Epoch 1948/3334\n",
            "Epoch 1948: Training Accuracy = 0.9961, Training Loss = 0.0525, Validation Accuracy = 0.8789, Validation Loss = 0.5857\n",
            "Epoch 1949/3334\n",
            "Epoch 1949: Training Accuracy = 0.9863, Training Loss = 0.1034, Validation Accuracy = 0.8271, Validation Loss = 0.7635\n",
            "Epoch 1950/3334\n",
            "Epoch 1950: Training Accuracy = 0.9863, Training Loss = 0.1034, Validation Accuracy = 0.8271, Validation Loss = 0.7635\n",
            "Epoch 1951/3334\n",
            "Epoch 1951: Training Accuracy = 0.8770, Training Loss = 0.7104, Validation Accuracy = 0.5468, Validation Loss = 1.7145\n",
            "Epoch 1952/3334\n",
            "Epoch 1952: Training Accuracy = 0.9590, Training Loss = 0.3439, Validation Accuracy = 0.7656, Validation Loss = 0.9588\n",
            "Epoch 1953/3334\n",
            "Epoch 1953: Training Accuracy = 0.9590, Training Loss = 0.3439, Validation Accuracy = 0.7656, Validation Loss = 0.9588\n",
            "Epoch 1954/3334\n",
            "Epoch 1954: Training Accuracy = 0.9902, Training Loss = 0.1598, Validation Accuracy = 0.8231, Validation Loss = 0.7564\n",
            "Epoch 1955/3334\n",
            "Epoch 1955: Training Accuracy = 0.9902, Training Loss = 0.1598, Validation Accuracy = 0.8231, Validation Loss = 0.7564\n",
            "Epoch 1956/3334\n",
            "Epoch 1956: Training Accuracy = 0.9941, Training Loss = 0.0874, Validation Accuracy = 0.8585, Validation Loss = 0.6319\n",
            "Epoch 1957/3334\n",
            "Epoch 1957: Training Accuracy = 0.9941, Training Loss = 0.0694, Validation Accuracy = 0.8760, Validation Loss = 0.5560\n",
            "Epoch 1958/3334\n",
            "Epoch 1958: Training Accuracy = 0.9941, Training Loss = 0.0694, Validation Accuracy = 0.8760, Validation Loss = 0.5560\n",
            "Epoch 1959/3334\n",
            "Epoch 1959: Training Accuracy = 0.9902, Training Loss = 0.0732, Validation Accuracy = 0.8872, Validation Loss = 0.5179\n",
            "Epoch 1960/3334\n",
            "Epoch 1960: Training Accuracy = 0.9902, Training Loss = 0.0732, Validation Accuracy = 0.8872, Validation Loss = 0.5179\n",
            "Epoch 1961/3334\n",
            "Epoch 1961: Training Accuracy = 0.9922, Training Loss = 0.0599, Validation Accuracy = 0.8989, Validation Loss = 0.4933\n",
            "Epoch 1962/3334\n",
            "Epoch 1962: Training Accuracy = 0.9844, Training Loss = 0.0868, Validation Accuracy = 0.9013, Validation Loss = 0.4808\n",
            "Epoch 1963/3334\n",
            "Epoch 1963: Training Accuracy = 0.9844, Training Loss = 0.0868, Validation Accuracy = 0.9013, Validation Loss = 0.4808\n",
            "Epoch 1964/3334\n",
            "Epoch 1964: Training Accuracy = 0.9902, Training Loss = 0.0660, Validation Accuracy = 0.9001, Validation Loss = 0.4811\n",
            "Epoch 1965/3334\n",
            "Epoch 1965: Training Accuracy = 0.9902, Training Loss = 0.0660, Validation Accuracy = 0.9001, Validation Loss = 0.4811\n",
            "Epoch 1966/3334\n",
            "Epoch 1966: Training Accuracy = 0.9863, Training Loss = 0.0773, Validation Accuracy = 0.9036, Validation Loss = 0.4782\n",
            "Epoch 1967/3334\n",
            "Epoch 1967: Training Accuracy = 0.9902, Training Loss = 0.0655, Validation Accuracy = 0.9044, Validation Loss = 0.4745\n",
            "Epoch 1968/3334\n",
            "Epoch 1968: Training Accuracy = 0.9902, Training Loss = 0.0655, Validation Accuracy = 0.9044, Validation Loss = 0.4745\n",
            "Epoch 1969/3334\n",
            "Epoch 1969: Training Accuracy = 0.9922, Training Loss = 0.0615, Validation Accuracy = 0.9012, Validation Loss = 0.4811\n",
            "Epoch 1970/3334\n",
            "Epoch 1970: Training Accuracy = 0.9922, Training Loss = 0.0615, Validation Accuracy = 0.9012, Validation Loss = 0.4811\n",
            "Epoch 1971/3334\n",
            "Epoch 1971: Training Accuracy = 0.9844, Training Loss = 0.0846, Validation Accuracy = 0.9050, Validation Loss = 0.4762\n",
            "Epoch 1972/3334\n",
            "Epoch 1972: Training Accuracy = 0.9883, Training Loss = 0.0733, Validation Accuracy = 0.9092, Validation Loss = 0.4715\n",
            "Epoch 1973/3334\n",
            "Epoch 1973: Training Accuracy = 0.9883, Training Loss = 0.0733, Validation Accuracy = 0.9092, Validation Loss = 0.4715\n",
            "Epoch 1974/3334\n",
            "Epoch 1974: Training Accuracy = 0.9941, Training Loss = 0.0499, Validation Accuracy = 0.9031, Validation Loss = 0.4850\n",
            "Epoch 1975/3334\n",
            "Epoch 1975: Training Accuracy = 0.9941, Training Loss = 0.0499, Validation Accuracy = 0.9031, Validation Loss = 0.4850\n",
            "Epoch 1976/3334\n",
            "Epoch 1976: Training Accuracy = 0.9941, Training Loss = 0.0530, Validation Accuracy = 0.9051, Validation Loss = 0.4811\n",
            "Epoch 1977/3334\n",
            "Epoch 1977: Training Accuracy = 0.9902, Training Loss = 0.0699, Validation Accuracy = 0.9088, Validation Loss = 0.4775\n",
            "Epoch 1978/3334\n",
            "Epoch 1978: Training Accuracy = 0.9902, Training Loss = 0.0699, Validation Accuracy = 0.9088, Validation Loss = 0.4775\n",
            "Epoch 1979/3334\n",
            "Epoch 1979: Training Accuracy = 0.9902, Training Loss = 0.0703, Validation Accuracy = 0.9063, Validation Loss = 0.4874\n",
            "Epoch 1980/3334\n",
            "Epoch 1980: Training Accuracy = 0.9902, Training Loss = 0.0703, Validation Accuracy = 0.9063, Validation Loss = 0.4874\n",
            "Epoch 1981/3334\n",
            "Epoch 1981: Training Accuracy = 0.9883, Training Loss = 0.0734, Validation Accuracy = 0.9045, Validation Loss = 0.4923\n",
            "Epoch 1982/3334\n",
            "Epoch 1982: Training Accuracy = 0.9902, Training Loss = 0.0968, Validation Accuracy = 0.8663, Validation Loss = 0.6494\n",
            "Epoch 1983/3334\n",
            "Epoch 1983: Training Accuracy = 0.9902, Training Loss = 0.0968, Validation Accuracy = 0.8663, Validation Loss = 0.6494\n",
            "Epoch 1984/3334\n",
            "Epoch 1984: Training Accuracy = 0.9219, Training Loss = 0.4719, Validation Accuracy = 0.5573, Validation Loss = 1.5869\n",
            "Epoch 1985/3334\n",
            "Epoch 1985: Training Accuracy = 0.9219, Training Loss = 0.4719, Validation Accuracy = 0.5573, Validation Loss = 1.5869\n",
            "Epoch 1986/3334\n",
            "Epoch 1986: Training Accuracy = 0.9668, Training Loss = 0.3526, Validation Accuracy = 0.7275, Validation Loss = 1.0827\n",
            "Epoch 1987/3334\n",
            "Epoch 1987: Training Accuracy = 0.9883, Training Loss = 0.1781, Validation Accuracy = 0.8675, Validation Loss = 0.6485\n",
            "Epoch 1988/3334\n",
            "Epoch 1988: Training Accuracy = 0.9883, Training Loss = 0.1781, Validation Accuracy = 0.8675, Validation Loss = 0.6485\n",
            "Epoch 1989/3334\n",
            "Epoch 1989: Training Accuracy = 0.9941, Training Loss = 0.0920, Validation Accuracy = 0.9082, Validation Loss = 0.5111\n",
            "Epoch 1990/3334\n",
            "Epoch 1990: Training Accuracy = 0.9941, Training Loss = 0.0920, Validation Accuracy = 0.9082, Validation Loss = 0.5111\n",
            "Epoch 1991/3334\n",
            "Epoch 1991: Training Accuracy = 0.9941, Training Loss = 0.0624, Validation Accuracy = 0.9244, Validation Loss = 0.4283\n",
            "Epoch 1992/3334\n",
            "Epoch 1992: Training Accuracy = 0.9883, Training Loss = 0.0769, Validation Accuracy = 0.9300, Validation Loss = 0.3970\n",
            "Epoch 1993/3334\n",
            "Epoch 1993: Training Accuracy = 0.9883, Training Loss = 0.0769, Validation Accuracy = 0.9300, Validation Loss = 0.3970\n",
            "Epoch 1994/3334\n",
            "Epoch 1994: Training Accuracy = 0.9961, Training Loss = 0.0440, Validation Accuracy = 0.9340, Validation Loss = 0.3691\n",
            "Epoch 1995/3334\n",
            "Epoch 1995: Training Accuracy = 0.9961, Training Loss = 0.0440, Validation Accuracy = 0.9340, Validation Loss = 0.3691\n",
            "Epoch 1996/3334\n",
            "Epoch 1996: Training Accuracy = 0.9863, Training Loss = 0.0743, Validation Accuracy = 0.9332, Validation Loss = 0.3706\n",
            "Epoch 1997/3334\n",
            "Epoch 1997: Training Accuracy = 0.9902, Training Loss = 0.0616, Validation Accuracy = 0.9362, Validation Loss = 0.3675\n",
            "Epoch 1998/3334\n",
            "Epoch 1998: Training Accuracy = 0.9902, Training Loss = 0.0616, Validation Accuracy = 0.9362, Validation Loss = 0.3675\n",
            "Epoch 1999/3334\n",
            "Epoch 1999: Training Accuracy = 0.9961, Training Loss = 0.0405, Validation Accuracy = 0.9367, Validation Loss = 0.3643\n",
            "Epoch 2000/3334\n",
            "Epoch 2000: Training Accuracy = 0.9961, Training Loss = 0.0405, Validation Accuracy = 0.9367, Validation Loss = 0.3643\n",
            "Epoch 2001/3334\n",
            "Epoch 2001: Training Accuracy = 0.9941, Training Loss = 0.0453, Validation Accuracy = 0.9359, Validation Loss = 0.3664\n",
            "Epoch 2002/3334\n",
            "Epoch 2002: Training Accuracy = 0.9844, Training Loss = 0.0818, Validation Accuracy = 0.9370, Validation Loss = 0.3658\n",
            "Epoch 2003/3334\n",
            "Epoch 2003: Training Accuracy = 0.9844, Training Loss = 0.0818, Validation Accuracy = 0.9370, Validation Loss = 0.3658\n",
            "Epoch 2004/3334\n",
            "Epoch 2004: Training Accuracy = 0.9922, Training Loss = 0.0534, Validation Accuracy = 0.9347, Validation Loss = 0.3863\n",
            "Epoch 2005/3334\n",
            "Epoch 2005: Training Accuracy = 0.9922, Training Loss = 0.0534, Validation Accuracy = 0.9347, Validation Loss = 0.3863\n",
            "Epoch 2006/3334\n",
            "Epoch 2006: Training Accuracy = 0.9902, Training Loss = 0.0594, Validation Accuracy = 0.9399, Validation Loss = 0.3652\n",
            "Epoch 2007/3334\n",
            "Epoch 2007: Training Accuracy = 0.9863, Training Loss = 0.0762, Validation Accuracy = 0.9368, Validation Loss = 0.3731\n",
            "Epoch 2008/3334\n",
            "Epoch 2008: Training Accuracy = 0.9863, Training Loss = 0.0762, Validation Accuracy = 0.9368, Validation Loss = 0.3731\n",
            "Epoch 2009/3334\n",
            "Epoch 2009: Training Accuracy = 0.9844, Training Loss = 0.0814, Validation Accuracy = 0.9375, Validation Loss = 0.3765\n",
            "Epoch 2010/3334\n",
            "Epoch 2010: Training Accuracy = 0.9844, Training Loss = 0.0814, Validation Accuracy = 0.9375, Validation Loss = 0.3765\n",
            "Epoch 2011/3334\n",
            "Epoch 2011: Training Accuracy = 0.9941, Training Loss = 0.0526, Validation Accuracy = 0.9371, Validation Loss = 0.3773\n",
            "Epoch 2012/3334\n",
            "Epoch 2012: Training Accuracy = 0.9902, Training Loss = 0.0670, Validation Accuracy = 0.9400, Validation Loss = 0.3719\n",
            "Epoch 2013/3334\n",
            "Epoch 2013: Training Accuracy = 0.9902, Training Loss = 0.0670, Validation Accuracy = 0.9400, Validation Loss = 0.3719\n",
            "Epoch 2014/3334\n",
            "Epoch 2014: Training Accuracy = 0.9902, Training Loss = 0.0731, Validation Accuracy = 0.9311, Validation Loss = 0.3950\n",
            "Epoch 2015/3334\n",
            "Epoch 2015: Training Accuracy = 0.9902, Training Loss = 0.0731, Validation Accuracy = 0.9311, Validation Loss = 0.3950\n",
            "Epoch 2016/3334\n",
            "Epoch 2016: Training Accuracy = 0.9902, Training Loss = 0.0823, Validation Accuracy = 0.9057, Validation Loss = 0.5204\n",
            "Epoch 2017/3334\n",
            "Epoch 2017: Training Accuracy = 0.8652, Training Loss = 0.7648, Validation Accuracy = 0.6775, Validation Loss = 1.2931\n",
            "Epoch 2018/3334\n",
            "Epoch 2018: Training Accuracy = 0.8652, Training Loss = 0.7648, Validation Accuracy = 0.6775, Validation Loss = 1.2931\n",
            "Epoch 2019/3334\n",
            "Epoch 2019: Training Accuracy = 0.9609, Training Loss = 0.3250, Validation Accuracy = 0.8086, Validation Loss = 0.8175\n",
            "Epoch 2020/3334\n",
            "Epoch 2020: Training Accuracy = 0.9609, Training Loss = 0.3250, Validation Accuracy = 0.8086, Validation Loss = 0.8175\n",
            "Epoch 2021/3334\n",
            "Epoch 2021: Training Accuracy = 0.9883, Training Loss = 0.1662, Validation Accuracy = 0.8936, Validation Loss = 0.5472\n",
            "Epoch 2022/3334\n",
            "Epoch 2022: Training Accuracy = 0.9941, Training Loss = 0.0948, Validation Accuracy = 0.9286, Validation Loss = 0.4195\n",
            "Epoch 2023/3334\n",
            "Epoch 2023: Training Accuracy = 0.9941, Training Loss = 0.0948, Validation Accuracy = 0.9286, Validation Loss = 0.4195\n",
            "Epoch 2024/3334\n",
            "Epoch 2024: Training Accuracy = 0.9902, Training Loss = 0.0881, Validation Accuracy = 0.9378, Validation Loss = 0.3728\n",
            "Epoch 2025/3334\n",
            "Epoch 2025: Training Accuracy = 0.9902, Training Loss = 0.0881, Validation Accuracy = 0.9378, Validation Loss = 0.3728\n",
            "Epoch 2026/3334\n",
            "Epoch 2026: Training Accuracy = 0.9961, Training Loss = 0.0501, Validation Accuracy = 0.9414, Validation Loss = 0.3435\n",
            "Epoch 2027/3334\n",
            "Epoch 2027: Training Accuracy = 0.9922, Training Loss = 0.0604, Validation Accuracy = 0.9461, Validation Loss = 0.3271\n",
            "Epoch 2028/3334\n",
            "Epoch 2028: Training Accuracy = 0.9922, Training Loss = 0.0604, Validation Accuracy = 0.9461, Validation Loss = 0.3271\n",
            "Epoch 2029/3334\n",
            "Epoch 2029: Training Accuracy = 0.9883, Training Loss = 0.0718, Validation Accuracy = 0.9478, Validation Loss = 0.3226\n",
            "Epoch 2030/3334\n",
            "Epoch 2030: Training Accuracy = 0.9883, Training Loss = 0.0718, Validation Accuracy = 0.9478, Validation Loss = 0.3226\n",
            "Epoch 2031/3334\n",
            "Epoch 2031: Training Accuracy = 0.9883, Training Loss = 0.0700, Validation Accuracy = 0.9510, Validation Loss = 0.3124\n",
            "Epoch 2032/3334\n",
            "Epoch 2032: Training Accuracy = 0.9883, Training Loss = 0.0704, Validation Accuracy = 0.9511, Validation Loss = 0.3157\n",
            "Epoch 2033/3334\n",
            "Epoch 2033: Training Accuracy = 0.9883, Training Loss = 0.0704, Validation Accuracy = 0.9511, Validation Loss = 0.3157\n",
            "Epoch 2034/3334\n",
            "Epoch 2034: Training Accuracy = 0.9844, Training Loss = 0.0832, Validation Accuracy = 0.9501, Validation Loss = 0.3158\n",
            "Epoch 2035/3334\n",
            "Epoch 2035: Training Accuracy = 0.9844, Training Loss = 0.0832, Validation Accuracy = 0.9501, Validation Loss = 0.3158\n",
            "Epoch 2036/3334\n",
            "Epoch 2036: Training Accuracy = 0.9941, Training Loss = 0.0489, Validation Accuracy = 0.9534, Validation Loss = 0.3141\n",
            "Epoch 2037/3334\n",
            "Epoch 2037: Training Accuracy = 0.9902, Training Loss = 0.0629, Validation Accuracy = 0.9537, Validation Loss = 0.3097\n",
            "Epoch 2038/3334\n",
            "Epoch 2038: Training Accuracy = 0.9902, Training Loss = 0.0629, Validation Accuracy = 0.9537, Validation Loss = 0.3097\n",
            "Epoch 2039/3334\n",
            "Epoch 2039: Training Accuracy = 0.9883, Training Loss = 0.0687, Validation Accuracy = 0.9532, Validation Loss = 0.3160\n",
            "Epoch 2040/3334\n",
            "Epoch 2040: Training Accuracy = 0.9883, Training Loss = 0.0687, Validation Accuracy = 0.9532, Validation Loss = 0.3160\n",
            "Epoch 2041/3334\n",
            "Epoch 2041: Training Accuracy = 0.9883, Training Loss = 0.0696, Validation Accuracy = 0.9557, Validation Loss = 0.3115\n",
            "Epoch 2042/3334\n",
            "Epoch 2042: Training Accuracy = 0.9902, Training Loss = 0.0648, Validation Accuracy = 0.9554, Validation Loss = 0.3114\n",
            "Epoch 2043/3334\n",
            "Epoch 2043: Training Accuracy = 0.9902, Training Loss = 0.0648, Validation Accuracy = 0.9554, Validation Loss = 0.3114\n",
            "Epoch 2044/3334\n",
            "Epoch 2044: Training Accuracy = 0.9902, Training Loss = 0.0653, Validation Accuracy = 0.9546, Validation Loss = 0.3116\n",
            "Epoch 2045/3334\n",
            "Epoch 2045: Training Accuracy = 0.9902, Training Loss = 0.0653, Validation Accuracy = 0.9546, Validation Loss = 0.3116\n",
            "Epoch 2046/3334\n",
            "Epoch 2046: Training Accuracy = 0.9922, Training Loss = 0.0586, Validation Accuracy = 0.9535, Validation Loss = 0.3194\n",
            "Epoch 2047/3334\n",
            "Epoch 2047: Training Accuracy = 0.9863, Training Loss = 0.0798, Validation Accuracy = 0.9590, Validation Loss = 0.3185\n",
            "Epoch 2048/3334\n",
            "Epoch 2048: Training Accuracy = 0.9863, Training Loss = 0.0798, Validation Accuracy = 0.9590, Validation Loss = 0.3185\n",
            "Epoch 2049/3334\n",
            "Epoch 2049: Training Accuracy = 0.9902, Training Loss = 0.0689, Validation Accuracy = 0.9578, Validation Loss = 0.3306\n",
            "Epoch 2050/3334\n",
            "Epoch 2050: Training Accuracy = 0.9902, Training Loss = 0.0689, Validation Accuracy = 0.9578, Validation Loss = 0.3306\n",
            "Epoch 2051/3334\n",
            "Epoch 2051: Training Accuracy = 0.7461, Training Loss = 1.3276, Validation Accuracy = 0.5101, Validation Loss = 1.9089\n",
            "Epoch 2052/3334\n",
            "Epoch 2052: Training Accuracy = 0.9551, Training Loss = 0.4176, Validation Accuracy = 0.8562, Validation Loss = 0.7738\n",
            "Epoch 2053/3334\n",
            "Epoch 2053: Training Accuracy = 0.9551, Training Loss = 0.4176, Validation Accuracy = 0.8562, Validation Loss = 0.7738\n",
            "Epoch 2054/3334\n",
            "Epoch 2054: Training Accuracy = 0.9844, Training Loss = 0.2051, Validation Accuracy = 0.9214, Validation Loss = 0.4998\n",
            "Epoch 2055/3334\n",
            "Epoch 2055: Training Accuracy = 0.9844, Training Loss = 0.2051, Validation Accuracy = 0.9214, Validation Loss = 0.4998\n",
            "Epoch 2056/3334\n",
            "Epoch 2056: Training Accuracy = 0.9883, Training Loss = 0.1214, Validation Accuracy = 0.9514, Validation Loss = 0.3612\n",
            "Epoch 2057/3334\n",
            "Epoch 2057: Training Accuracy = 0.9922, Training Loss = 0.0798, Validation Accuracy = 0.9624, Validation Loss = 0.2976\n",
            "Epoch 2058/3334\n",
            "Epoch 2058: Training Accuracy = 0.9922, Training Loss = 0.0798, Validation Accuracy = 0.9624, Validation Loss = 0.2976\n",
            "Epoch 2059/3334\n",
            "Epoch 2059: Training Accuracy = 0.9863, Training Loss = 0.0851, Validation Accuracy = 0.9651, Validation Loss = 0.2701\n",
            "Epoch 2060/3334\n",
            "Epoch 2060: Training Accuracy = 0.9863, Training Loss = 0.0851, Validation Accuracy = 0.9651, Validation Loss = 0.2701\n",
            "Epoch 2061/3334\n",
            "Epoch 2061: Training Accuracy = 0.9961, Training Loss = 0.0455, Validation Accuracy = 0.9695, Validation Loss = 0.2503\n",
            "Epoch 2062/3334\n",
            "Epoch 2062: Training Accuracy = 0.9902, Training Loss = 0.0668, Validation Accuracy = 0.9718, Validation Loss = 0.2458\n",
            "Epoch 2063/3334\n",
            "Epoch 2063: Training Accuracy = 0.9902, Training Loss = 0.0668, Validation Accuracy = 0.9718, Validation Loss = 0.2458\n",
            "Epoch 2064/3334\n",
            "Epoch 2064: Training Accuracy = 0.9902, Training Loss = 0.0644, Validation Accuracy = 0.9742, Validation Loss = 0.2360\n",
            "Epoch 2065/3334\n",
            "Epoch 2065: Training Accuracy = 0.9902, Training Loss = 0.0644, Validation Accuracy = 0.9742, Validation Loss = 0.2360\n",
            "Epoch 2066/3334\n",
            "Epoch 2066: Training Accuracy = 0.9863, Training Loss = 0.0748, Validation Accuracy = 0.9750, Validation Loss = 0.2370\n",
            "Epoch 2067/3334\n",
            "Epoch 2067: Training Accuracy = 0.9824, Training Loss = 0.0909, Validation Accuracy = 0.9740, Validation Loss = 0.2402\n",
            "Epoch 2068/3334\n",
            "Epoch 2068: Training Accuracy = 0.9824, Training Loss = 0.0909, Validation Accuracy = 0.9740, Validation Loss = 0.2402\n",
            "Epoch 2069/3334\n",
            "Epoch 2069: Training Accuracy = 0.9922, Training Loss = 0.0549, Validation Accuracy = 0.9759, Validation Loss = 0.2382\n",
            "Epoch 2070/3334\n",
            "Epoch 2070: Training Accuracy = 0.9922, Training Loss = 0.0549, Validation Accuracy = 0.9759, Validation Loss = 0.2382\n",
            "Epoch 2071/3334\n",
            "Epoch 2071: Training Accuracy = 0.9883, Training Loss = 0.0701, Validation Accuracy = 0.9725, Validation Loss = 0.2482\n",
            "Epoch 2072/3334\n",
            "Epoch 2072: Training Accuracy = 0.9863, Training Loss = 0.0789, Validation Accuracy = 0.9757, Validation Loss = 0.2342\n",
            "Epoch 2073/3334\n",
            "Epoch 2073: Training Accuracy = 0.9863, Training Loss = 0.0789, Validation Accuracy = 0.9757, Validation Loss = 0.2342\n",
            "Epoch 2074/3334\n",
            "Epoch 2074: Training Accuracy = 0.9941, Training Loss = 0.0577, Validation Accuracy = 0.9759, Validation Loss = 0.2406\n",
            "Epoch 2075/3334\n",
            "Epoch 2075: Training Accuracy = 0.9941, Training Loss = 0.0577, Validation Accuracy = 0.9759, Validation Loss = 0.2406\n",
            "Epoch 2076/3334\n",
            "Epoch 2076: Training Accuracy = 0.9805, Training Loss = 0.0987, Validation Accuracy = 0.9766, Validation Loss = 0.2500\n",
            "Epoch 2077/3334\n",
            "Epoch 2077: Training Accuracy = 0.9922, Training Loss = 0.0594, Validation Accuracy = 0.9775, Validation Loss = 0.2394\n",
            "Epoch 2078/3334\n",
            "Epoch 2078: Training Accuracy = 0.9922, Training Loss = 0.0594, Validation Accuracy = 0.9775, Validation Loss = 0.2394\n",
            "Epoch 2079/3334\n",
            "Epoch 2079: Training Accuracy = 0.9883, Training Loss = 0.0732, Validation Accuracy = 0.9772, Validation Loss = 0.2451\n",
            "Epoch 2080/3334\n",
            "Epoch 2080: Training Accuracy = 0.9883, Training Loss = 0.0732, Validation Accuracy = 0.9772, Validation Loss = 0.2451\n",
            "Epoch 2081/3334\n",
            "Epoch 2081: Training Accuracy = 0.9863, Training Loss = 0.0759, Validation Accuracy = 0.9753, Validation Loss = 0.2573\n",
            "Epoch 2082/3334\n",
            "Epoch 2082: Training Accuracy = 0.9785, Training Loss = 0.1106, Validation Accuracy = 0.9701, Validation Loss = 0.2676\n",
            "Epoch 2083/3334\n",
            "Epoch 2083: Training Accuracy = 0.9785, Training Loss = 0.1106, Validation Accuracy = 0.9701, Validation Loss = 0.2676\n",
            "Epoch 2084/3334\n",
            "Epoch 2084: Training Accuracy = 0.9902, Training Loss = 0.0712, Validation Accuracy = 0.9713, Validation Loss = 0.2684\n",
            "Epoch 2085/3334\n",
            "Epoch 2085: Training Accuracy = 0.9902, Training Loss = 0.0712, Validation Accuracy = 0.9713, Validation Loss = 0.2684\n",
            "Epoch 2086/3334\n",
            "Epoch 2086: Training Accuracy = 0.9902, Training Loss = 0.0687, Validation Accuracy = 0.9736, Validation Loss = 0.2670\n",
            "Epoch 2087/3334\n",
            "Epoch 2087: Training Accuracy = 0.9902, Training Loss = 0.0800, Validation Accuracy = 0.9721, Validation Loss = 0.2648\n",
            "Epoch 2088/3334\n",
            "Epoch 2088: Training Accuracy = 0.9902, Training Loss = 0.0800, Validation Accuracy = 0.9721, Validation Loss = 0.2648\n",
            "Epoch 2089/3334\n",
            "Epoch 2089: Training Accuracy = 0.9863, Training Loss = 0.0896, Validation Accuracy = 0.9715, Validation Loss = 0.2548\n",
            "Epoch 2090/3334\n",
            "Epoch 2090: Training Accuracy = 0.9863, Training Loss = 0.0896, Validation Accuracy = 0.9715, Validation Loss = 0.2548\n",
            "Epoch 2091/3334\n",
            "Epoch 2091: Training Accuracy = 0.9863, Training Loss = 0.0829, Validation Accuracy = 0.9760, Validation Loss = 0.2457\n",
            "Epoch 2092/3334\n",
            "Epoch 2092: Training Accuracy = 0.9961, Training Loss = 0.0511, Validation Accuracy = 0.9745, Validation Loss = 0.2438\n",
            "Epoch 2093/3334\n",
            "Epoch 2093: Training Accuracy = 0.9961, Training Loss = 0.0511, Validation Accuracy = 0.9745, Validation Loss = 0.2438\n",
            "Epoch 2094/3334\n",
            "Epoch 2094: Training Accuracy = 0.6348, Training Loss = 1.4761, Validation Accuracy = 0.6700, Validation Loss = 1.2730\n",
            "Epoch 2095/3334\n",
            "Epoch 2095: Training Accuracy = 0.6348, Training Loss = 1.4761, Validation Accuracy = 0.6700, Validation Loss = 1.2730\n",
            "Epoch 2096/3334\n",
            "Epoch 2096: Training Accuracy = 0.9727, Training Loss = 0.3609, Validation Accuracy = 0.9085, Validation Loss = 0.6170\n",
            "Epoch 2097/3334\n",
            "Epoch 2097: Training Accuracy = 0.9902, Training Loss = 0.1523, Validation Accuracy = 0.9608, Validation Loss = 0.3676\n",
            "Epoch 2098/3334\n",
            "Epoch 2098: Training Accuracy = 0.9902, Training Loss = 0.1523, Validation Accuracy = 0.9608, Validation Loss = 0.3676\n",
            "Epoch 2099/3334\n",
            "Epoch 2099: Training Accuracy = 0.9941, Training Loss = 0.0789, Validation Accuracy = 0.9746, Validation Loss = 0.2685\n",
            "Epoch 2100/3334\n",
            "Epoch 2100: Training Accuracy = 0.9941, Training Loss = 0.0789, Validation Accuracy = 0.9746, Validation Loss = 0.2685\n",
            "Epoch 2101/3334\n",
            "Epoch 2101: Training Accuracy = 0.9902, Training Loss = 0.0744, Validation Accuracy = 0.9824, Validation Loss = 0.2125\n",
            "Epoch 2102/3334\n",
            "Epoch 2102: Training Accuracy = 0.9922, Training Loss = 0.0566, Validation Accuracy = 0.9842, Validation Loss = 0.1839\n",
            "Epoch 2103/3334\n",
            "Epoch 2103: Training Accuracy = 0.9922, Training Loss = 0.0566, Validation Accuracy = 0.9842, Validation Loss = 0.1839\n",
            "Epoch 2104/3334\n",
            "Epoch 2104: Training Accuracy = 0.9902, Training Loss = 0.0635, Validation Accuracy = 0.9851, Validation Loss = 0.1750\n",
            "Epoch 2105/3334\n",
            "Epoch 2105: Training Accuracy = 0.9902, Training Loss = 0.0635, Validation Accuracy = 0.9851, Validation Loss = 0.1750\n",
            "Epoch 2106/3334\n",
            "Epoch 2106: Training Accuracy = 0.9824, Training Loss = 0.0843, Validation Accuracy = 0.9854, Validation Loss = 0.1753\n",
            "Epoch 2107/3334\n",
            "Epoch 2107: Training Accuracy = 0.9922, Training Loss = 0.0491, Validation Accuracy = 0.9857, Validation Loss = 0.1717\n",
            "Epoch 2108/3334\n",
            "Epoch 2108: Training Accuracy = 0.9922, Training Loss = 0.0491, Validation Accuracy = 0.9857, Validation Loss = 0.1717\n",
            "Epoch 2109/3334\n",
            "Epoch 2109: Training Accuracy = 0.9922, Training Loss = 0.0484, Validation Accuracy = 0.9863, Validation Loss = 0.1702\n",
            "Epoch 2110/3334\n",
            "Epoch 2110: Training Accuracy = 0.9922, Training Loss = 0.0484, Validation Accuracy = 0.9863, Validation Loss = 0.1702\n",
            "Epoch 2111/3334\n",
            "Epoch 2111: Training Accuracy = 0.9902, Training Loss = 0.0549, Validation Accuracy = 0.9872, Validation Loss = 0.1721\n",
            "Epoch 2112/3334\n",
            "Epoch 2112: Training Accuracy = 0.9902, Training Loss = 0.0560, Validation Accuracy = 0.9860, Validation Loss = 0.1729\n",
            "Epoch 2113/3334\n",
            "Epoch 2113: Training Accuracy = 0.9902, Training Loss = 0.0560, Validation Accuracy = 0.9860, Validation Loss = 0.1729\n",
            "Epoch 2114/3334\n",
            "Epoch 2114: Training Accuracy = 0.9941, Training Loss = 0.0439, Validation Accuracy = 0.9868, Validation Loss = 0.1708\n",
            "Epoch 2115/3334\n",
            "Epoch 2115: Training Accuracy = 0.9941, Training Loss = 0.0439, Validation Accuracy = 0.9868, Validation Loss = 0.1708\n",
            "Epoch 2116/3334\n",
            "Epoch 2116: Training Accuracy = 0.9922, Training Loss = 0.0478, Validation Accuracy = 0.9863, Validation Loss = 0.1759\n",
            "Epoch 2117/3334\n",
            "Epoch 2117: Training Accuracy = 0.9844, Training Loss = 0.0805, Validation Accuracy = 0.9862, Validation Loss = 0.1756\n",
            "Epoch 2118/3334\n",
            "Epoch 2118: Training Accuracy = 0.9844, Training Loss = 0.0805, Validation Accuracy = 0.9862, Validation Loss = 0.1756\n",
            "Epoch 2119/3334\n",
            "Epoch 2119: Training Accuracy = 0.9902, Training Loss = 0.0560, Validation Accuracy = 0.9856, Validation Loss = 0.1718\n",
            "Epoch 2120/3334\n",
            "Epoch 2120: Training Accuracy = 0.9902, Training Loss = 0.0560, Validation Accuracy = 0.9856, Validation Loss = 0.1718\n",
            "Epoch 2121/3334\n",
            "Epoch 2121: Training Accuracy = 0.9941, Training Loss = 0.0413, Validation Accuracy = 0.9868, Validation Loss = 0.1727\n",
            "Epoch 2122/3334\n",
            "Epoch 2122: Training Accuracy = 0.9941, Training Loss = 0.0436, Validation Accuracy = 0.9869, Validation Loss = 0.1686\n",
            "Epoch 2123/3334\n",
            "Epoch 2123: Training Accuracy = 0.9941, Training Loss = 0.0436, Validation Accuracy = 0.9869, Validation Loss = 0.1686\n",
            "Epoch 2124/3334\n",
            "Epoch 2124: Training Accuracy = 0.9922, Training Loss = 0.0480, Validation Accuracy = 0.9871, Validation Loss = 0.1717\n",
            "Epoch 2125/3334\n",
            "Epoch 2125: Training Accuracy = 0.9922, Training Loss = 0.0480, Validation Accuracy = 0.9871, Validation Loss = 0.1717\n",
            "Epoch 2126/3334\n",
            "Epoch 2126: Training Accuracy = 0.9844, Training Loss = 0.0756, Validation Accuracy = 0.9856, Validation Loss = 0.1857\n",
            "Epoch 2127/3334\n",
            "Epoch 2127: Training Accuracy = 0.9883, Training Loss = 0.0676, Validation Accuracy = 0.9862, Validation Loss = 0.1827\n",
            "Epoch 2128/3334\n",
            "Epoch 2128: Training Accuracy = 0.9883, Training Loss = 0.0676, Validation Accuracy = 0.9862, Validation Loss = 0.1827\n",
            "Epoch 2129/3334\n",
            "Epoch 2129: Training Accuracy = 0.9902, Training Loss = 0.0589, Validation Accuracy = 0.9871, Validation Loss = 0.1770\n",
            "Epoch 2130/3334\n",
            "Epoch 2130: Training Accuracy = 0.9902, Training Loss = 0.0589, Validation Accuracy = 0.9871, Validation Loss = 0.1770\n",
            "Epoch 2131/3334\n",
            "Epoch 2131: Training Accuracy = 0.9922, Training Loss = 0.0515, Validation Accuracy = 0.9859, Validation Loss = 0.1882\n",
            "Epoch 2132/3334\n",
            "Epoch 2132: Training Accuracy = 0.9902, Training Loss = 0.0973, Validation Accuracy = 0.9302, Validation Loss = 0.5001\n",
            "Epoch 2133/3334\n",
            "Epoch 2133: Training Accuracy = 0.9902, Training Loss = 0.0973, Validation Accuracy = 0.9302, Validation Loss = 0.5001\n",
            "Epoch 2134/3334\n",
            "Epoch 2134: Training Accuracy = 0.8105, Training Loss = 0.9425, Validation Accuracy = 0.6771, Validation Loss = 1.3503\n",
            "Epoch 2135/3334\n",
            "Epoch 2135: Training Accuracy = 0.8105, Training Loss = 0.9425, Validation Accuracy = 0.6771, Validation Loss = 1.3503\n",
            "Epoch 2136/3334\n",
            "Epoch 2136: Training Accuracy = 0.9824, Training Loss = 0.2352, Validation Accuracy = 0.9139, Validation Loss = 0.5574\n",
            "Epoch 2137/3334\n",
            "Epoch 2137: Training Accuracy = 0.9883, Training Loss = 0.1333, Validation Accuracy = 0.9740, Validation Loss = 0.3126\n",
            "Epoch 2138/3334\n",
            "Epoch 2138: Training Accuracy = 0.9883, Training Loss = 0.1333, Validation Accuracy = 0.9740, Validation Loss = 0.3126\n",
            "Epoch 2139/3334\n",
            "Epoch 2139: Training Accuracy = 0.9922, Training Loss = 0.0807, Validation Accuracy = 0.9838, Validation Loss = 0.2256\n",
            "Epoch 2140/3334\n",
            "Epoch 2140: Training Accuracy = 0.9922, Training Loss = 0.0807, Validation Accuracy = 0.9838, Validation Loss = 0.2256\n",
            "Epoch 2141/3334\n",
            "Epoch 2141: Training Accuracy = 0.9844, Training Loss = 0.0961, Validation Accuracy = 0.9872, Validation Loss = 0.1828\n",
            "Epoch 2142/3334\n",
            "Epoch 2142: Training Accuracy = 0.9961, Training Loss = 0.0432, Validation Accuracy = 0.9876, Validation Loss = 0.1695\n",
            "Epoch 2143/3334\n",
            "Epoch 2143: Training Accuracy = 0.9961, Training Loss = 0.0432, Validation Accuracy = 0.9876, Validation Loss = 0.1695\n",
            "Epoch 2144/3334\n",
            "Epoch 2144: Training Accuracy = 0.9844, Training Loss = 0.0807, Validation Accuracy = 0.9880, Validation Loss = 0.1633\n",
            "Epoch 2145/3334\n",
            "Epoch 2145: Training Accuracy = 0.9844, Training Loss = 0.0807, Validation Accuracy = 0.9880, Validation Loss = 0.1633\n",
            "Epoch 2146/3334\n",
            "Epoch 2146: Training Accuracy = 0.9961, Training Loss = 0.0393, Validation Accuracy = 0.9882, Validation Loss = 0.1581\n",
            "Epoch 2147/3334\n",
            "Epoch 2147: Training Accuracy = 0.9844, Training Loss = 0.0790, Validation Accuracy = 0.9877, Validation Loss = 0.1575\n",
            "Epoch 2148/3334\n",
            "Epoch 2148: Training Accuracy = 0.9844, Training Loss = 0.0790, Validation Accuracy = 0.9877, Validation Loss = 0.1575\n",
            "Epoch 2149/3334\n",
            "Epoch 2149: Training Accuracy = 0.9824, Training Loss = 0.0877, Validation Accuracy = 0.9880, Validation Loss = 0.1561\n",
            "Epoch 2150/3334\n",
            "Epoch 2150: Training Accuracy = 0.9824, Training Loss = 0.0877, Validation Accuracy = 0.9880, Validation Loss = 0.1561\n",
            "Epoch 2151/3334\n",
            "Epoch 2151: Training Accuracy = 0.9902, Training Loss = 0.0595, Validation Accuracy = 0.9880, Validation Loss = 0.1558\n",
            "Epoch 2152/3334\n",
            "Epoch 2152: Training Accuracy = 0.9883, Training Loss = 0.0666, Validation Accuracy = 0.9889, Validation Loss = 0.1545\n",
            "Epoch 2153/3334\n",
            "Epoch 2153: Training Accuracy = 0.9883, Training Loss = 0.0666, Validation Accuracy = 0.9889, Validation Loss = 0.1545\n",
            "Epoch 2154/3334\n",
            "Epoch 2154: Training Accuracy = 0.9902, Training Loss = 0.0587, Validation Accuracy = 0.9888, Validation Loss = 0.1535\n",
            "Epoch 2155/3334\n",
            "Epoch 2155: Training Accuracy = 0.9902, Training Loss = 0.0587, Validation Accuracy = 0.9888, Validation Loss = 0.1535\n",
            "Epoch 2156/3334\n",
            "Epoch 2156: Training Accuracy = 0.9863, Training Loss = 0.0708, Validation Accuracy = 0.9886, Validation Loss = 0.1530\n",
            "Epoch 2157/3334\n",
            "Epoch 2157: Training Accuracy = 0.9941, Training Loss = 0.0454, Validation Accuracy = 0.9885, Validation Loss = 0.1524\n",
            "Epoch 2158/3334\n",
            "Epoch 2158: Training Accuracy = 0.9941, Training Loss = 0.0454, Validation Accuracy = 0.9885, Validation Loss = 0.1524\n",
            "Epoch 2159/3334\n",
            "Epoch 2159: Training Accuracy = 0.9902, Training Loss = 0.0582, Validation Accuracy = 0.9888, Validation Loss = 0.1518\n",
            "Epoch 2160/3334\n",
            "Epoch 2160: Training Accuracy = 0.9902, Training Loss = 0.0582, Validation Accuracy = 0.9888, Validation Loss = 0.1518\n",
            "Epoch 2161/3334\n",
            "Epoch 2161: Training Accuracy = 0.9961, Training Loss = 0.0375, Validation Accuracy = 0.9888, Validation Loss = 0.1538\n",
            "Epoch 2162/3334\n",
            "Epoch 2162: Training Accuracy = 0.9902, Training Loss = 0.0635, Validation Accuracy = 0.9882, Validation Loss = 0.1554\n",
            "Epoch 2163/3334\n",
            "Epoch 2163: Training Accuracy = 0.9902, Training Loss = 0.0635, Validation Accuracy = 0.9882, Validation Loss = 0.1554\n",
            "Epoch 2164/3334\n",
            "Epoch 2164: Training Accuracy = 0.9922, Training Loss = 0.0515, Validation Accuracy = 0.9891, Validation Loss = 0.1560\n",
            "Epoch 2165/3334\n",
            "Epoch 2165: Training Accuracy = 0.9922, Training Loss = 0.0515, Validation Accuracy = 0.9891, Validation Loss = 0.1560\n",
            "Epoch 2166/3334\n",
            "Epoch 2166: Training Accuracy = 0.9961, Training Loss = 0.0376, Validation Accuracy = 0.9883, Validation Loss = 0.1569\n",
            "Epoch 2167/3334\n",
            "Epoch 2167: Training Accuracy = 0.9844, Training Loss = 0.0835, Validation Accuracy = 0.9882, Validation Loss = 0.1590\n",
            "Epoch 2168/3334\n",
            "Epoch 2168: Training Accuracy = 0.9844, Training Loss = 0.0835, Validation Accuracy = 0.9882, Validation Loss = 0.1590\n",
            "Epoch 2169/3334\n",
            "Epoch 2169: Training Accuracy = 0.2695, Training Loss = 2.8103, Validation Accuracy = 0.3071, Validation Loss = 2.7625\n",
            "Epoch 2170/3334\n",
            "Epoch 2170: Training Accuracy = 0.2695, Training Loss = 2.8103, Validation Accuracy = 0.3071, Validation Loss = 2.7625\n",
            "Epoch 2171/3334\n",
            "Epoch 2171: Training Accuracy = 0.8066, Training Loss = 0.8627, Validation Accuracy = 0.7887, Validation Loss = 0.9952\n",
            "Epoch 2172/3334\n",
            "Epoch 2172: Training Accuracy = 0.9688, Training Loss = 0.2838, Validation Accuracy = 0.9367, Validation Loss = 0.4980\n",
            "Epoch 2173/3334\n",
            "Epoch 2173: Training Accuracy = 0.9688, Training Loss = 0.2838, Validation Accuracy = 0.9367, Validation Loss = 0.4980\n",
            "Epoch 2174/3334\n",
            "Epoch 2174: Training Accuracy = 0.9883, Training Loss = 0.1552, Validation Accuracy = 0.9807, Validation Loss = 0.2975\n",
            "Epoch 2175/3334\n",
            "Epoch 2175: Training Accuracy = 0.9883, Training Loss = 0.1552, Validation Accuracy = 0.9807, Validation Loss = 0.2975\n",
            "Epoch 2176/3334\n",
            "Epoch 2176: Training Accuracy = 0.9902, Training Loss = 0.0951, Validation Accuracy = 0.9885, Validation Loss = 0.2088\n",
            "Epoch 2177/3334\n",
            "Epoch 2177: Training Accuracy = 0.9863, Training Loss = 0.0903, Validation Accuracy = 0.9889, Validation Loss = 0.1775\n",
            "Epoch 2178/3334\n",
            "Epoch 2178: Training Accuracy = 0.9863, Training Loss = 0.0903, Validation Accuracy = 0.9889, Validation Loss = 0.1775\n",
            "Epoch 2179/3334\n",
            "Epoch 2179: Training Accuracy = 0.9863, Training Loss = 0.0917, Validation Accuracy = 0.9894, Validation Loss = 0.1587\n",
            "Epoch 2180/3334\n",
            "Epoch 2180: Training Accuracy = 0.9863, Training Loss = 0.0917, Validation Accuracy = 0.9894, Validation Loss = 0.1587\n",
            "Epoch 2181/3334\n",
            "Epoch 2181: Training Accuracy = 0.9883, Training Loss = 0.0740, Validation Accuracy = 0.9895, Validation Loss = 0.1517\n",
            "Epoch 2182/3334\n",
            "Epoch 2182: Training Accuracy = 0.9922, Training Loss = 0.0582, Validation Accuracy = 0.9894, Validation Loss = 0.1492\n",
            "Epoch 2183/3334\n",
            "Epoch 2183: Training Accuracy = 0.9922, Training Loss = 0.0582, Validation Accuracy = 0.9894, Validation Loss = 0.1492\n",
            "Epoch 2184/3334\n",
            "Epoch 2184: Training Accuracy = 0.9883, Training Loss = 0.0710, Validation Accuracy = 0.9895, Validation Loss = 0.1446\n",
            "Epoch 2185/3334\n",
            "Epoch 2185: Training Accuracy = 0.9883, Training Loss = 0.0710, Validation Accuracy = 0.9895, Validation Loss = 0.1446\n",
            "Epoch 2186/3334\n",
            "Epoch 2186: Training Accuracy = 0.9941, Training Loss = 0.0545, Validation Accuracy = 0.9894, Validation Loss = 0.1451\n",
            "Epoch 2187/3334\n",
            "Epoch 2187: Training Accuracy = 0.9883, Training Loss = 0.0691, Validation Accuracy = 0.9897, Validation Loss = 0.1434\n",
            "Epoch 2188/3334\n",
            "Epoch 2188: Training Accuracy = 0.9883, Training Loss = 0.0691, Validation Accuracy = 0.9897, Validation Loss = 0.1434\n",
            "Epoch 2189/3334\n",
            "Epoch 2189: Training Accuracy = 0.9863, Training Loss = 0.0764, Validation Accuracy = 0.9895, Validation Loss = 0.1421\n",
            "Epoch 2190/3334\n",
            "Epoch 2190: Training Accuracy = 0.9863, Training Loss = 0.0764, Validation Accuracy = 0.9895, Validation Loss = 0.1421\n",
            "Epoch 2191/3334\n",
            "Epoch 2191: Training Accuracy = 0.9902, Training Loss = 0.0603, Validation Accuracy = 0.9892, Validation Loss = 0.1428\n",
            "Epoch 2192/3334\n",
            "Epoch 2192: Training Accuracy = 0.9922, Training Loss = 0.0556, Validation Accuracy = 0.9895, Validation Loss = 0.1401\n",
            "Epoch 2193/3334\n",
            "Epoch 2193: Training Accuracy = 0.9922, Training Loss = 0.0556, Validation Accuracy = 0.9895, Validation Loss = 0.1401\n",
            "Epoch 2194/3334\n",
            "Epoch 2194: Training Accuracy = 0.9863, Training Loss = 0.0746, Validation Accuracy = 0.9895, Validation Loss = 0.1435\n",
            "Epoch 2195/3334\n",
            "Epoch 2195: Training Accuracy = 0.9863, Training Loss = 0.0746, Validation Accuracy = 0.9895, Validation Loss = 0.1435\n",
            "Epoch 2196/3334\n",
            "Epoch 2196: Training Accuracy = 0.9902, Training Loss = 0.0622, Validation Accuracy = 0.9895, Validation Loss = 0.1423\n",
            "Epoch 2197/3334\n",
            "Epoch 2197: Training Accuracy = 0.9883, Training Loss = 0.0700, Validation Accuracy = 0.9895, Validation Loss = 0.1393\n",
            "Epoch 2198/3334\n",
            "Epoch 2198: Training Accuracy = 0.9883, Training Loss = 0.0700, Validation Accuracy = 0.9895, Validation Loss = 0.1393\n",
            "Epoch 2199/3334\n",
            "Epoch 2199: Training Accuracy = 0.9902, Training Loss = 0.0639, Validation Accuracy = 0.9895, Validation Loss = 0.1443\n",
            "Epoch 2200/3334\n",
            "Epoch 2200: Training Accuracy = 0.9902, Training Loss = 0.0639, Validation Accuracy = 0.9895, Validation Loss = 0.1443\n",
            "Epoch 2201/3334\n",
            "Epoch 2201: Training Accuracy = 0.9941, Training Loss = 0.0561, Validation Accuracy = 0.9877, Validation Loss = 0.1689\n",
            "Epoch 2202/3334\n",
            "Epoch 2202: Training Accuracy = 0.9883, Training Loss = 0.0714, Validation Accuracy = 0.9895, Validation Loss = 0.1479\n",
            "Epoch 2203/3334\n",
            "Epoch 2203: Training Accuracy = 0.9883, Training Loss = 0.0714, Validation Accuracy = 0.9895, Validation Loss = 0.1479\n",
            "Epoch 2204/3334\n",
            "Epoch 2204: Training Accuracy = 0.9922, Training Loss = 0.0613, Validation Accuracy = 0.9894, Validation Loss = 0.1444\n",
            "Epoch 2205/3334\n",
            "Epoch 2205: Training Accuracy = 0.9922, Training Loss = 0.0613, Validation Accuracy = 0.9894, Validation Loss = 0.1444\n",
            "Epoch 2206/3334\n",
            "Epoch 2206: Training Accuracy = 0.9961, Training Loss = 0.0423, Validation Accuracy = 0.9889, Validation Loss = 0.1472\n",
            "Epoch 2207/3334\n",
            "Epoch 2207: Training Accuracy = 0.9160, Training Loss = 0.6513, Validation Accuracy = 0.1930, Validation Loss = 4.0928\n",
            "Epoch 2208/3334\n",
            "Epoch 2208: Training Accuracy = 0.9160, Training Loss = 0.6513, Validation Accuracy = 0.1930, Validation Loss = 4.0928\n",
            "Epoch 2209/3334\n",
            "Epoch 2209: Training Accuracy = 0.8496, Training Loss = 0.8206, Validation Accuracy = 0.8377, Validation Loss = 0.9379\n",
            "Epoch 2210/3334\n",
            "Epoch 2210: Training Accuracy = 0.8496, Training Loss = 0.8206, Validation Accuracy = 0.8377, Validation Loss = 0.9379\n",
            "Epoch 2211/3334\n",
            "Epoch 2211: Training Accuracy = 0.9863, Training Loss = 0.3032, Validation Accuracy = 0.9343, Validation Loss = 0.5339\n",
            "Epoch 2212/3334\n",
            "Epoch 2212: Training Accuracy = 0.9766, Training Loss = 0.2161, Validation Accuracy = 0.9819, Validation Loss = 0.2858\n",
            "Epoch 2213/3334\n",
            "Epoch 2213: Training Accuracy = 0.9766, Training Loss = 0.2161, Validation Accuracy = 0.9819, Validation Loss = 0.2858\n",
            "Epoch 2214/3334\n",
            "Epoch 2214: Training Accuracy = 0.9961, Training Loss = 0.0844, Validation Accuracy = 0.9882, Validation Loss = 0.2077\n",
            "Epoch 2215/3334\n",
            "Epoch 2215: Training Accuracy = 0.9961, Training Loss = 0.0844, Validation Accuracy = 0.9882, Validation Loss = 0.2077\n",
            "Epoch 2216/3334\n",
            "Epoch 2216: Training Accuracy = 0.9883, Training Loss = 0.0847, Validation Accuracy = 0.9895, Validation Loss = 0.1673\n",
            "Epoch 2217/3334\n",
            "Epoch 2217: Training Accuracy = 0.9941, Training Loss = 0.0586, Validation Accuracy = 0.9897, Validation Loss = 0.1475\n",
            "Epoch 2218/3334\n",
            "Epoch 2218: Training Accuracy = 0.9941, Training Loss = 0.0586, Validation Accuracy = 0.9897, Validation Loss = 0.1475\n",
            "Epoch 2219/3334\n",
            "Epoch 2219: Training Accuracy = 0.9883, Training Loss = 0.0742, Validation Accuracy = 0.9897, Validation Loss = 0.1404\n",
            "Epoch 2220/3334\n",
            "Epoch 2220: Training Accuracy = 0.9883, Training Loss = 0.0742, Validation Accuracy = 0.9897, Validation Loss = 0.1404\n",
            "Epoch 2221/3334\n",
            "Epoch 2221: Training Accuracy = 0.9922, Training Loss = 0.0594, Validation Accuracy = 0.9897, Validation Loss = 0.1385\n",
            "Epoch 2222/3334\n",
            "Epoch 2222: Training Accuracy = 0.9961, Training Loss = 0.0451, Validation Accuracy = 0.9897, Validation Loss = 0.1372\n",
            "Epoch 2223/3334\n",
            "Epoch 2223: Training Accuracy = 0.9961, Training Loss = 0.0451, Validation Accuracy = 0.9897, Validation Loss = 0.1372\n",
            "Epoch 2224/3334\n",
            "Epoch 2224: Training Accuracy = 0.9902, Training Loss = 0.0665, Validation Accuracy = 0.9897, Validation Loss = 0.1352\n",
            "Epoch 2225/3334\n",
            "Epoch 2225: Training Accuracy = 0.9902, Training Loss = 0.0665, Validation Accuracy = 0.9897, Validation Loss = 0.1352\n",
            "Epoch 2226/3334\n",
            "Epoch 2226: Training Accuracy = 0.9941, Training Loss = 0.0507, Validation Accuracy = 0.9897, Validation Loss = 0.1340\n",
            "Epoch 2227/3334\n",
            "Epoch 2227: Training Accuracy = 0.9863, Training Loss = 0.0814, Validation Accuracy = 0.9897, Validation Loss = 0.1364\n",
            "Epoch 2228/3334\n",
            "Epoch 2228: Training Accuracy = 0.9863, Training Loss = 0.0814, Validation Accuracy = 0.9897, Validation Loss = 0.1364\n",
            "Epoch 2229/3334\n",
            "Epoch 2229: Training Accuracy = 0.9922, Training Loss = 0.0585, Validation Accuracy = 0.9897, Validation Loss = 0.1335\n",
            "Epoch 2230/3334\n",
            "Epoch 2230: Training Accuracy = 0.9922, Training Loss = 0.0585, Validation Accuracy = 0.9897, Validation Loss = 0.1335\n",
            "Epoch 2231/3334\n",
            "Epoch 2231: Training Accuracy = 0.9922, Training Loss = 0.0562, Validation Accuracy = 0.9897, Validation Loss = 0.1344\n",
            "Epoch 2232/3334\n",
            "Epoch 2232: Training Accuracy = 0.9941, Training Loss = 0.0510, Validation Accuracy = 0.9897, Validation Loss = 0.1321\n",
            "Epoch 2233/3334\n",
            "Epoch 2233: Training Accuracy = 0.9941, Training Loss = 0.0510, Validation Accuracy = 0.9897, Validation Loss = 0.1321\n",
            "Epoch 2234/3334\n",
            "Epoch 2234: Training Accuracy = 0.9922, Training Loss = 0.0580, Validation Accuracy = 0.9897, Validation Loss = 0.1353\n",
            "Epoch 2235/3334\n",
            "Epoch 2235: Training Accuracy = 0.9922, Training Loss = 0.0580, Validation Accuracy = 0.9897, Validation Loss = 0.1353\n",
            "Epoch 2236/3334\n",
            "Epoch 2236: Training Accuracy = 0.9863, Training Loss = 0.0780, Validation Accuracy = 0.9897, Validation Loss = 0.1330\n",
            "Epoch 2237/3334\n",
            "Epoch 2237: Training Accuracy = 0.9863, Training Loss = 0.0791, Validation Accuracy = 0.9897, Validation Loss = 0.1372\n",
            "Epoch 2238/3334\n",
            "Epoch 2238: Training Accuracy = 0.9863, Training Loss = 0.0791, Validation Accuracy = 0.9897, Validation Loss = 0.1372\n",
            "Epoch 2239/3334\n",
            "Epoch 2239: Training Accuracy = 0.9883, Training Loss = 0.0728, Validation Accuracy = 0.9897, Validation Loss = 0.1396\n",
            "Epoch 2240/3334\n",
            "Epoch 2240: Training Accuracy = 0.9883, Training Loss = 0.0728, Validation Accuracy = 0.9897, Validation Loss = 0.1396\n",
            "Epoch 2241/3334\n",
            "Epoch 2241: Training Accuracy = 0.9766, Training Loss = 0.1117, Validation Accuracy = 0.9895, Validation Loss = 0.1397\n",
            "Epoch 2242/3334\n",
            "Epoch 2242: Training Accuracy = 0.9863, Training Loss = 0.0809, Validation Accuracy = 0.9897, Validation Loss = 0.1373\n",
            "Epoch 2243/3334\n",
            "Epoch 2243: Training Accuracy = 0.9863, Training Loss = 0.0809, Validation Accuracy = 0.9897, Validation Loss = 0.1373\n",
            "Epoch 2244/3334\n",
            "Epoch 2244: Training Accuracy = 0.9922, Training Loss = 0.0562, Validation Accuracy = 0.9894, Validation Loss = 0.1435\n",
            "Epoch 2245/3334\n",
            "Epoch 2245: Training Accuracy = 0.9922, Training Loss = 0.0562, Validation Accuracy = 0.9894, Validation Loss = 0.1435\n",
            "Epoch 2246/3334\n",
            "Epoch 2246: Training Accuracy = 0.6680, Training Loss = 1.4014, Validation Accuracy = 0.5506, Validation Loss = 1.7851\n",
            "Epoch 2247/3334\n",
            "Epoch 2247: Training Accuracy = 0.9395, Training Loss = 0.4885, Validation Accuracy = 0.9078, Validation Loss = 0.6327\n",
            "Epoch 2248/3334\n",
            "Epoch 2248: Training Accuracy = 0.9395, Training Loss = 0.4885, Validation Accuracy = 0.9078, Validation Loss = 0.6327\n",
            "Epoch 2249/3334\n",
            "Epoch 2249: Training Accuracy = 0.9844, Training Loss = 0.2303, Validation Accuracy = 0.9651, Validation Loss = 0.3868\n",
            "Epoch 2250/3334\n",
            "Epoch 2250: Training Accuracy = 0.9844, Training Loss = 0.2303, Validation Accuracy = 0.9651, Validation Loss = 0.3868\n",
            "Epoch 2251/3334\n",
            "Epoch 2251: Training Accuracy = 0.9902, Training Loss = 0.1254, Validation Accuracy = 0.9863, Validation Loss = 0.2370\n",
            "Epoch 2252/3334\n",
            "Epoch 2252: Training Accuracy = 0.9902, Training Loss = 0.0929, Validation Accuracy = 0.9894, Validation Loss = 0.1770\n",
            "Epoch 2253/3334\n",
            "Epoch 2253: Training Accuracy = 0.9902, Training Loss = 0.0929, Validation Accuracy = 0.9894, Validation Loss = 0.1770\n",
            "Epoch 2254/3334\n",
            "Epoch 2254: Training Accuracy = 0.9805, Training Loss = 0.1123, Validation Accuracy = 0.9897, Validation Loss = 0.1555\n",
            "Epoch 2255/3334\n",
            "Epoch 2255: Training Accuracy = 0.9805, Training Loss = 0.1123, Validation Accuracy = 0.9897, Validation Loss = 0.1555\n",
            "Epoch 2256/3334\n",
            "Epoch 2256: Training Accuracy = 0.9863, Training Loss = 0.0888, Validation Accuracy = 0.9897, Validation Loss = 0.1436\n",
            "Epoch 2257/3334\n",
            "Epoch 2257: Training Accuracy = 0.9863, Training Loss = 0.0834, Validation Accuracy = 0.9897, Validation Loss = 0.1376\n",
            "Epoch 2258/3334\n",
            "Epoch 2258: Training Accuracy = 0.9863, Training Loss = 0.0834, Validation Accuracy = 0.9897, Validation Loss = 0.1376\n",
            "Epoch 2259/3334\n",
            "Epoch 2259: Training Accuracy = 0.9883, Training Loss = 0.0804, Validation Accuracy = 0.9897, Validation Loss = 0.1359\n",
            "Epoch 2260/3334\n",
            "Epoch 2260: Training Accuracy = 0.9883, Training Loss = 0.0804, Validation Accuracy = 0.9897, Validation Loss = 0.1359\n",
            "Epoch 2261/3334\n",
            "Epoch 2261: Training Accuracy = 0.9863, Training Loss = 0.0792, Validation Accuracy = 0.9897, Validation Loss = 0.1340\n",
            "Epoch 2262/3334\n",
            "Epoch 2262: Training Accuracy = 0.9883, Training Loss = 0.0750, Validation Accuracy = 0.9897, Validation Loss = 0.1315\n",
            "Epoch 2263/3334\n",
            "Epoch 2263: Training Accuracy = 0.9883, Training Loss = 0.0750, Validation Accuracy = 0.9897, Validation Loss = 0.1315\n",
            "Epoch 2264/3334\n",
            "Epoch 2264: Training Accuracy = 0.9902, Training Loss = 0.0646, Validation Accuracy = 0.9897, Validation Loss = 0.1303\n",
            "Epoch 2265/3334\n",
            "Epoch 2265: Training Accuracy = 0.9902, Training Loss = 0.0646, Validation Accuracy = 0.9897, Validation Loss = 0.1303\n",
            "Epoch 2266/3334\n",
            "Epoch 2266: Training Accuracy = 0.9941, Training Loss = 0.0514, Validation Accuracy = 0.9897, Validation Loss = 0.1298\n",
            "Epoch 2267/3334\n",
            "Epoch 2267: Training Accuracy = 0.9902, Training Loss = 0.0650, Validation Accuracy = 0.9897, Validation Loss = 0.1299\n",
            "Epoch 2268/3334\n",
            "Epoch 2268: Training Accuracy = 0.9902, Training Loss = 0.0650, Validation Accuracy = 0.9897, Validation Loss = 0.1299\n",
            "Epoch 2269/3334\n",
            "Epoch 2269: Training Accuracy = 0.9902, Training Loss = 0.0629, Validation Accuracy = 0.9897, Validation Loss = 0.1297\n",
            "Epoch 2270/3334\n",
            "Epoch 2270: Training Accuracy = 0.9902, Training Loss = 0.0629, Validation Accuracy = 0.9897, Validation Loss = 0.1297\n",
            "Epoch 2271/3334\n",
            "Epoch 2271: Training Accuracy = 0.9922, Training Loss = 0.0552, Validation Accuracy = 0.9897, Validation Loss = 0.1297\n",
            "Epoch 2272/3334\n",
            "Epoch 2272: Training Accuracy = 0.9883, Training Loss = 0.0719, Validation Accuracy = 0.9897, Validation Loss = 0.1301\n",
            "Epoch 2273/3334\n",
            "Epoch 2273: Training Accuracy = 0.9883, Training Loss = 0.0719, Validation Accuracy = 0.9897, Validation Loss = 0.1301\n",
            "Epoch 2274/3334\n",
            "Epoch 2274: Training Accuracy = 0.9824, Training Loss = 0.0932, Validation Accuracy = 0.9897, Validation Loss = 0.1291\n",
            "Epoch 2275/3334\n",
            "Epoch 2275: Training Accuracy = 0.9824, Training Loss = 0.0932, Validation Accuracy = 0.9897, Validation Loss = 0.1291\n",
            "Epoch 2276/3334\n",
            "Epoch 2276: Training Accuracy = 0.9805, Training Loss = 0.0987, Validation Accuracy = 0.9897, Validation Loss = 0.1341\n",
            "Epoch 2277/3334\n",
            "Epoch 2277: Training Accuracy = 0.9961, Training Loss = 0.0568, Validation Accuracy = 0.9892, Validation Loss = 0.1571\n",
            "Epoch 2278/3334\n",
            "Epoch 2278: Training Accuracy = 0.9961, Training Loss = 0.0568, Validation Accuracy = 0.9892, Validation Loss = 0.1571\n",
            "Epoch 2279/3334\n",
            "Epoch 2279: Training Accuracy = 0.8848, Training Loss = 0.8355, Validation Accuracy = 0.8549, Validation Loss = 0.9308\n",
            "Epoch 2280/3334\n",
            "Epoch 2280: Training Accuracy = 0.8848, Training Loss = 0.8355, Validation Accuracy = 0.8549, Validation Loss = 0.9308\n",
            "Epoch 2281/3334\n",
            "Epoch 2281: Training Accuracy = 0.9824, Training Loss = 0.2537, Validation Accuracy = 0.9540, Validation Loss = 0.4372\n",
            "Epoch 2282/3334\n",
            "Epoch 2282: Training Accuracy = 0.9863, Training Loss = 0.1627, Validation Accuracy = 0.9831, Validation Loss = 0.2613\n",
            "Epoch 2283/3334\n",
            "Epoch 2283: Training Accuracy = 0.9863, Training Loss = 0.1627, Validation Accuracy = 0.9831, Validation Loss = 0.2613\n",
            "Epoch 2284/3334\n",
            "Epoch 2284: Training Accuracy = 0.9902, Training Loss = 0.1018, Validation Accuracy = 0.9897, Validation Loss = 0.1780\n",
            "Epoch 2285/3334\n",
            "Epoch 2285: Training Accuracy = 0.9902, Training Loss = 0.1018, Validation Accuracy = 0.9897, Validation Loss = 0.1780\n",
            "Epoch 2286/3334\n",
            "Epoch 2286: Training Accuracy = 0.9883, Training Loss = 0.0826, Validation Accuracy = 0.9895, Validation Loss = 0.1430\n",
            "Epoch 2287/3334\n",
            "Epoch 2287: Training Accuracy = 0.9902, Training Loss = 0.0697, Validation Accuracy = 0.9897, Validation Loss = 0.1287\n",
            "Epoch 2288/3334\n",
            "Epoch 2288: Training Accuracy = 0.9902, Training Loss = 0.0697, Validation Accuracy = 0.9897, Validation Loss = 0.1287\n",
            "Epoch 2289/3334\n",
            "Epoch 2289: Training Accuracy = 0.9922, Training Loss = 0.0649, Validation Accuracy = 0.9897, Validation Loss = 0.1248\n",
            "Epoch 2290/3334\n",
            "Epoch 2290: Training Accuracy = 0.9922, Training Loss = 0.0649, Validation Accuracy = 0.9897, Validation Loss = 0.1248\n",
            "Epoch 2291/3334\n",
            "Epoch 2291: Training Accuracy = 0.9922, Training Loss = 0.0575, Validation Accuracy = 0.9897, Validation Loss = 0.1224\n",
            "Epoch 2292/3334\n",
            "Epoch 2292: Training Accuracy = 0.9902, Training Loss = 0.0659, Validation Accuracy = 0.9897, Validation Loss = 0.1220\n",
            "Epoch 2293/3334\n",
            "Epoch 2293: Training Accuracy = 0.9902, Training Loss = 0.0659, Validation Accuracy = 0.9897, Validation Loss = 0.1220\n",
            "Epoch 2294/3334\n",
            "Epoch 2294: Training Accuracy = 0.9883, Training Loss = 0.0711, Validation Accuracy = 0.9897, Validation Loss = 0.1206\n",
            "Epoch 2295/3334\n",
            "Epoch 2295: Training Accuracy = 0.9883, Training Loss = 0.0711, Validation Accuracy = 0.9897, Validation Loss = 0.1206\n",
            "Epoch 2296/3334\n",
            "Epoch 2296: Training Accuracy = 0.9844, Training Loss = 0.0839, Validation Accuracy = 0.9897, Validation Loss = 0.1213\n",
            "Epoch 2297/3334\n",
            "Epoch 2297: Training Accuracy = 0.9980, Training Loss = 0.0363, Validation Accuracy = 0.9897, Validation Loss = 0.1202\n",
            "Epoch 2298/3334\n",
            "Epoch 2298: Training Accuracy = 0.9980, Training Loss = 0.0363, Validation Accuracy = 0.9897, Validation Loss = 0.1202\n",
            "Epoch 2299/3334\n",
            "Epoch 2299: Training Accuracy = 0.9902, Training Loss = 0.0628, Validation Accuracy = 0.9897, Validation Loss = 0.1217\n",
            "Epoch 2300/3334\n",
            "Epoch 2300: Training Accuracy = 0.9902, Training Loss = 0.0628, Validation Accuracy = 0.9897, Validation Loss = 0.1217\n",
            "Epoch 2301/3334\n",
            "Epoch 2301: Training Accuracy = 0.9883, Training Loss = 0.0696, Validation Accuracy = 0.9897, Validation Loss = 0.1213\n",
            "Epoch 2302/3334\n",
            "Epoch 2302: Training Accuracy = 0.9863, Training Loss = 0.0765, Validation Accuracy = 0.9897, Validation Loss = 0.1204\n",
            "Epoch 2303/3334\n",
            "Epoch 2303: Training Accuracy = 0.9863, Training Loss = 0.0765, Validation Accuracy = 0.9897, Validation Loss = 0.1204\n",
            "Epoch 2304/3334\n",
            "Epoch 2304: Training Accuracy = 0.9883, Training Loss = 0.0705, Validation Accuracy = 0.9897, Validation Loss = 0.1213\n",
            "Epoch 2305/3334\n",
            "Epoch 2305: Training Accuracy = 0.9883, Training Loss = 0.0705, Validation Accuracy = 0.9897, Validation Loss = 0.1213\n",
            "Epoch 2306/3334\n",
            "Epoch 2306: Training Accuracy = 0.9961, Training Loss = 0.0414, Validation Accuracy = 0.9897, Validation Loss = 0.1199\n",
            "Epoch 2307/3334\n",
            "Epoch 2307: Training Accuracy = 0.9902, Training Loss = 0.0634, Validation Accuracy = 0.9897, Validation Loss = 0.1198\n",
            "Epoch 2308/3334\n",
            "Epoch 2308: Training Accuracy = 0.9902, Training Loss = 0.0634, Validation Accuracy = 0.9897, Validation Loss = 0.1198\n",
            "Epoch 2309/3334\n",
            "Epoch 2309: Training Accuracy = 0.9863, Training Loss = 0.0802, Validation Accuracy = 0.9897, Validation Loss = 0.1231\n",
            "Epoch 2310/3334\n",
            "Epoch 2310: Training Accuracy = 0.9863, Training Loss = 0.0802, Validation Accuracy = 0.9897, Validation Loss = 0.1231\n",
            "Epoch 2311/3334\n",
            "Epoch 2311: Training Accuracy = 0.9922, Training Loss = 0.0568, Validation Accuracy = 0.9897, Validation Loss = 0.1244\n",
            "Epoch 2312/3334\n",
            "Epoch 2312: Training Accuracy = 0.9883, Training Loss = 0.0761, Validation Accuracy = 0.9897, Validation Loss = 0.1266\n",
            "Epoch 2313/3334\n",
            "Epoch 2313: Training Accuracy = 0.9883, Training Loss = 0.0761, Validation Accuracy = 0.9897, Validation Loss = 0.1266\n",
            "Epoch 2314/3334\n",
            "Epoch 2314: Training Accuracy = 0.2910, Training Loss = 2.7950, Validation Accuracy = 0.3991, Validation Loss = 2.4856\n",
            "Epoch 2315/3334\n",
            "Epoch 2315: Training Accuracy = 0.2910, Training Loss = 2.7950, Validation Accuracy = 0.3991, Validation Loss = 2.4856\n",
            "Epoch 2316/3334\n",
            "Epoch 2316: Training Accuracy = 0.8965, Training Loss = 0.7096, Validation Accuracy = 0.8222, Validation Loss = 0.9123\n",
            "Epoch 2317/3334\n",
            "Epoch 2317: Training Accuracy = 0.9590, Training Loss = 0.3535, Validation Accuracy = 0.9452, Validation Loss = 0.4753\n",
            "Epoch 2318/3334\n",
            "Epoch 2318: Training Accuracy = 0.9590, Training Loss = 0.3535, Validation Accuracy = 0.9452, Validation Loss = 0.4753\n",
            "Epoch 2319/3334\n",
            "Epoch 2319: Training Accuracy = 0.9863, Training Loss = 0.1769, Validation Accuracy = 0.9842, Validation Loss = 0.2645\n",
            "Epoch 2320/3334\n",
            "Epoch 2320: Training Accuracy = 0.9863, Training Loss = 0.1769, Validation Accuracy = 0.9842, Validation Loss = 0.2645\n",
            "Epoch 2321/3334\n",
            "Epoch 2321: Training Accuracy = 0.9863, Training Loss = 0.1212, Validation Accuracy = 0.9868, Validation Loss = 0.1923\n",
            "Epoch 2322/3334\n",
            "Epoch 2322: Training Accuracy = 0.9883, Training Loss = 0.0944, Validation Accuracy = 0.9894, Validation Loss = 0.1534\n",
            "Epoch 2323/3334\n",
            "Epoch 2323: Training Accuracy = 0.9883, Training Loss = 0.0944, Validation Accuracy = 0.9894, Validation Loss = 0.1534\n",
            "Epoch 2324/3334\n",
            "Epoch 2324: Training Accuracy = 0.9902, Training Loss = 0.0779, Validation Accuracy = 0.9897, Validation Loss = 0.1395\n",
            "Epoch 2325/3334\n",
            "Epoch 2325: Training Accuracy = 0.9902, Training Loss = 0.0779, Validation Accuracy = 0.9897, Validation Loss = 0.1395\n",
            "Epoch 2326/3334\n",
            "Epoch 2326: Training Accuracy = 0.9902, Training Loss = 0.0701, Validation Accuracy = 0.9897, Validation Loss = 0.1323\n",
            "Epoch 2327/3334\n",
            "Epoch 2327: Training Accuracy = 0.9902, Training Loss = 0.0695, Validation Accuracy = 0.9897, Validation Loss = 0.1284\n",
            "Epoch 2328/3334\n",
            "Epoch 2328: Training Accuracy = 0.9902, Training Loss = 0.0695, Validation Accuracy = 0.9897, Validation Loss = 0.1284\n",
            "Epoch 2329/3334\n",
            "Epoch 2329: Training Accuracy = 0.9902, Training Loss = 0.0672, Validation Accuracy = 0.9897, Validation Loss = 0.1258\n",
            "Epoch 2330/3334\n",
            "Epoch 2330: Training Accuracy = 0.9902, Training Loss = 0.0672, Validation Accuracy = 0.9897, Validation Loss = 0.1258\n",
            "Epoch 2331/3334\n",
            "Epoch 2331: Training Accuracy = 0.9883, Training Loss = 0.0721, Validation Accuracy = 0.9897, Validation Loss = 0.1243\n",
            "Epoch 2332/3334\n",
            "Epoch 2332: Training Accuracy = 0.9883, Training Loss = 0.0723, Validation Accuracy = 0.9897, Validation Loss = 0.1234\n",
            "Epoch 2333/3334\n",
            "Epoch 2333: Training Accuracy = 0.9883, Training Loss = 0.0723, Validation Accuracy = 0.9897, Validation Loss = 0.1234\n",
            "Epoch 2334/3334\n",
            "Epoch 2334: Training Accuracy = 0.9883, Training Loss = 0.0798, Validation Accuracy = 0.9897, Validation Loss = 0.1215\n",
            "Epoch 2335/3334\n",
            "Epoch 2335: Training Accuracy = 0.9883, Training Loss = 0.0798, Validation Accuracy = 0.9897, Validation Loss = 0.1215\n",
            "Epoch 2336/3334\n",
            "Epoch 2336: Training Accuracy = 0.9961, Training Loss = 0.0512, Validation Accuracy = 0.9897, Validation Loss = 0.1217\n",
            "Epoch 2337/3334\n",
            "Epoch 2337: Training Accuracy = 0.9883, Training Loss = 0.0740, Validation Accuracy = 0.9897, Validation Loss = 0.1209\n",
            "Epoch 2338/3334\n",
            "Epoch 2338: Training Accuracy = 0.9883, Training Loss = 0.0740, Validation Accuracy = 0.9897, Validation Loss = 0.1209\n",
            "Epoch 2339/3334\n",
            "Epoch 2339: Training Accuracy = 0.9941, Training Loss = 0.0502, Validation Accuracy = 0.9897, Validation Loss = 0.1232\n",
            "Epoch 2340/3334\n",
            "Epoch 2340: Training Accuracy = 0.9941, Training Loss = 0.0502, Validation Accuracy = 0.9897, Validation Loss = 0.1232\n",
            "Epoch 2341/3334\n",
            "Epoch 2341: Training Accuracy = 0.9902, Training Loss = 0.0644, Validation Accuracy = 0.9897, Validation Loss = 0.1206\n",
            "Epoch 2342/3334\n",
            "Epoch 2342: Training Accuracy = 0.9902, Training Loss = 0.0661, Validation Accuracy = 0.9897, Validation Loss = 0.1194\n",
            "Epoch 2343/3334\n",
            "Epoch 2343: Training Accuracy = 0.9902, Training Loss = 0.0661, Validation Accuracy = 0.9897, Validation Loss = 0.1194\n",
            "Epoch 2344/3334\n",
            "Epoch 2344: Training Accuracy = 0.9902, Training Loss = 0.0636, Validation Accuracy = 0.9897, Validation Loss = 0.1209\n",
            "Epoch 2345/3334\n",
            "Epoch 2345: Training Accuracy = 0.9902, Training Loss = 0.0636, Validation Accuracy = 0.9897, Validation Loss = 0.1209\n",
            "Epoch 2346/3334\n",
            "Epoch 2346: Training Accuracy = 0.9902, Training Loss = 0.0622, Validation Accuracy = 0.9897, Validation Loss = 0.1198\n",
            "Epoch 2347/3334\n",
            "Epoch 2347: Training Accuracy = 0.9883, Training Loss = 0.0729, Validation Accuracy = 0.9897, Validation Loss = 0.1201\n",
            "Epoch 2348/3334\n",
            "Epoch 2348: Training Accuracy = 0.9883, Training Loss = 0.0729, Validation Accuracy = 0.9897, Validation Loss = 0.1201\n",
            "Epoch 2349/3334\n",
            "Epoch 2349: Training Accuracy = 0.9941, Training Loss = 0.0562, Validation Accuracy = 0.9897, Validation Loss = 0.1267\n",
            "Epoch 2350/3334\n",
            "Epoch 2350: Training Accuracy = 0.9941, Training Loss = 0.0562, Validation Accuracy = 0.9897, Validation Loss = 0.1267\n",
            "Epoch 2351/3334\n",
            "Epoch 2351: Training Accuracy = 0.9922, Training Loss = 0.0674, Validation Accuracy = 0.9897, Validation Loss = 0.1379\n",
            "Epoch 2352/3334\n",
            "Epoch 2352: Training Accuracy = 0.5195, Training Loss = 2.0962, Validation Accuracy = 0.4554, Validation Loss = 2.0886\n",
            "Epoch 2353/3334\n",
            "Epoch 2353: Training Accuracy = 0.5195, Training Loss = 2.0962, Validation Accuracy = 0.4554, Validation Loss = 2.0886\n",
            "Epoch 2354/3334\n",
            "Epoch 2354: Training Accuracy = 0.9121, Training Loss = 0.5276, Validation Accuracy = 0.9241, Validation Loss = 0.5885\n",
            "Epoch 2355/3334\n",
            "Epoch 2355: Training Accuracy = 0.9121, Training Loss = 0.5276, Validation Accuracy = 0.9241, Validation Loss = 0.5885\n",
            "Epoch 2356/3334\n",
            "Epoch 2356: Training Accuracy = 0.9922, Training Loss = 0.2079, Validation Accuracy = 0.9766, Validation Loss = 0.3357\n",
            "Epoch 2357/3334\n",
            "Epoch 2357: Training Accuracy = 0.9902, Training Loss = 0.1378, Validation Accuracy = 0.9883, Validation Loss = 0.2125\n",
            "Epoch 2358/3334\n",
            "Epoch 2358: Training Accuracy = 0.9902, Training Loss = 0.1378, Validation Accuracy = 0.9883, Validation Loss = 0.2125\n",
            "Epoch 2359/3334\n",
            "Epoch 2359: Training Accuracy = 0.9844, Training Loss = 0.1193, Validation Accuracy = 0.9894, Validation Loss = 0.1668\n",
            "Epoch 2360/3334\n",
            "Epoch 2360: Training Accuracy = 0.9844, Training Loss = 0.1193, Validation Accuracy = 0.9894, Validation Loss = 0.1668\n",
            "Epoch 2361/3334\n",
            "Epoch 2361: Training Accuracy = 0.9844, Training Loss = 0.0995, Validation Accuracy = 0.9897, Validation Loss = 0.1417\n",
            "Epoch 2362/3334\n",
            "Epoch 2362: Training Accuracy = 0.9941, Training Loss = 0.0596, Validation Accuracy = 0.9897, Validation Loss = 0.1313\n",
            "Epoch 2363/3334\n",
            "Epoch 2363: Training Accuracy = 0.9941, Training Loss = 0.0596, Validation Accuracy = 0.9897, Validation Loss = 0.1313\n",
            "Epoch 2364/3334\n",
            "Epoch 2364: Training Accuracy = 0.9902, Training Loss = 0.0697, Validation Accuracy = 0.9897, Validation Loss = 0.1263\n",
            "Epoch 2365/3334\n",
            "Epoch 2365: Training Accuracy = 0.9902, Training Loss = 0.0697, Validation Accuracy = 0.9897, Validation Loss = 0.1263\n",
            "Epoch 2366/3334\n",
            "Epoch 2366: Training Accuracy = 0.9922, Training Loss = 0.0620, Validation Accuracy = 0.9897, Validation Loss = 0.1230\n",
            "Epoch 2367/3334\n",
            "Epoch 2367: Training Accuracy = 0.9883, Training Loss = 0.0771, Validation Accuracy = 0.9897, Validation Loss = 0.1219\n",
            "Epoch 2368/3334\n",
            "Epoch 2368: Training Accuracy = 0.9883, Training Loss = 0.0771, Validation Accuracy = 0.9897, Validation Loss = 0.1219\n",
            "Epoch 2369/3334\n",
            "Epoch 2369: Training Accuracy = 0.9961, Training Loss = 0.0478, Validation Accuracy = 0.9897, Validation Loss = 0.1210\n",
            "Epoch 2370/3334\n",
            "Epoch 2370: Training Accuracy = 0.9961, Training Loss = 0.0478, Validation Accuracy = 0.9897, Validation Loss = 0.1210\n",
            "Epoch 2371/3334\n",
            "Epoch 2371: Training Accuracy = 0.9824, Training Loss = 0.0918, Validation Accuracy = 0.9897, Validation Loss = 0.1198\n",
            "Epoch 2372/3334\n",
            "Epoch 2372: Training Accuracy = 0.9883, Training Loss = 0.0745, Validation Accuracy = 0.9897, Validation Loss = 0.1188\n",
            "Epoch 2373/3334\n",
            "Epoch 2373: Training Accuracy = 0.9883, Training Loss = 0.0745, Validation Accuracy = 0.9897, Validation Loss = 0.1188\n",
            "Epoch 2374/3334\n",
            "Epoch 2374: Training Accuracy = 0.9922, Training Loss = 0.0591, Validation Accuracy = 0.9897, Validation Loss = 0.1201\n",
            "Epoch 2375/3334\n",
            "Epoch 2375: Training Accuracy = 0.9922, Training Loss = 0.0591, Validation Accuracy = 0.9897, Validation Loss = 0.1201\n",
            "Epoch 2376/3334\n",
            "Epoch 2376: Training Accuracy = 0.9883, Training Loss = 0.0730, Validation Accuracy = 0.9897, Validation Loss = 0.1211\n",
            "Epoch 2377/3334\n",
            "Epoch 2377: Training Accuracy = 0.9863, Training Loss = 0.0810, Validation Accuracy = 0.9897, Validation Loss = 0.1181\n",
            "Epoch 2378/3334\n",
            "Epoch 2378: Training Accuracy = 0.9863, Training Loss = 0.0810, Validation Accuracy = 0.9897, Validation Loss = 0.1181\n",
            "Epoch 2379/3334\n",
            "Epoch 2379: Training Accuracy = 0.9922, Training Loss = 0.0587, Validation Accuracy = 0.9897, Validation Loss = 0.1179\n",
            "Epoch 2380/3334\n",
            "Epoch 2380: Training Accuracy = 0.9922, Training Loss = 0.0587, Validation Accuracy = 0.9897, Validation Loss = 0.1179\n",
            "Epoch 2381/3334\n",
            "Epoch 2381: Training Accuracy = 0.9941, Training Loss = 0.0497, Validation Accuracy = 0.9897, Validation Loss = 0.1185\n",
            "Epoch 2382/3334\n",
            "Epoch 2382: Training Accuracy = 0.9824, Training Loss = 0.0966, Validation Accuracy = 0.9897, Validation Loss = 0.1199\n",
            "Epoch 2383/3334\n",
            "Epoch 2383: Training Accuracy = 0.9824, Training Loss = 0.0966, Validation Accuracy = 0.9897, Validation Loss = 0.1199\n",
            "Epoch 2384/3334\n",
            "Epoch 2384: Training Accuracy = 0.9883, Training Loss = 0.0740, Validation Accuracy = 0.9897, Validation Loss = 0.1201\n",
            "Epoch 2385/3334\n",
            "Epoch 2385: Training Accuracy = 0.9883, Training Loss = 0.0740, Validation Accuracy = 0.9897, Validation Loss = 0.1201\n",
            "Epoch 2386/3334\n",
            "Epoch 2386: Training Accuracy = 0.9902, Training Loss = 0.0745, Validation Accuracy = 0.9888, Validation Loss = 0.1646\n",
            "Epoch 2387/3334\n",
            "Epoch 2387: Training Accuracy = 0.8320, Training Loss = 1.0197, Validation Accuracy = 0.7225, Validation Loss = 1.2227\n",
            "Epoch 2388/3334\n",
            "Epoch 2388: Training Accuracy = 0.8320, Training Loss = 1.0197, Validation Accuracy = 0.7225, Validation Loss = 1.2227\n",
            "Epoch 2389/3334\n",
            "Epoch 2389: Training Accuracy = 0.9473, Training Loss = 0.4490, Validation Accuracy = 0.9018, Validation Loss = 0.5986\n",
            "Epoch 2390/3334\n",
            "Epoch 2390: Training Accuracy = 0.9473, Training Loss = 0.4490, Validation Accuracy = 0.9018, Validation Loss = 0.5986\n",
            "Epoch 2391/3334\n",
            "Epoch 2391: Training Accuracy = 0.9844, Training Loss = 0.2359, Validation Accuracy = 0.9743, Validation Loss = 0.3114\n",
            "Epoch 2392/3334\n",
            "Epoch 2392: Training Accuracy = 0.9863, Training Loss = 0.1546, Validation Accuracy = 0.9862, Validation Loss = 0.2111\n",
            "Epoch 2393/3334\n",
            "Epoch 2393: Training Accuracy = 0.9863, Training Loss = 0.1546, Validation Accuracy = 0.9862, Validation Loss = 0.2111\n",
            "Epoch 2394/3334\n",
            "Epoch 2394: Training Accuracy = 0.9941, Training Loss = 0.0810, Validation Accuracy = 0.9891, Validation Loss = 0.1615\n",
            "Epoch 2395/3334\n",
            "Epoch 2395: Training Accuracy = 0.9941, Training Loss = 0.0810, Validation Accuracy = 0.9891, Validation Loss = 0.1615\n",
            "Epoch 2396/3334\n",
            "Epoch 2396: Training Accuracy = 0.9844, Training Loss = 0.0997, Validation Accuracy = 0.9895, Validation Loss = 0.1395\n",
            "Epoch 2397/3334\n",
            "Epoch 2397: Training Accuracy = 0.9883, Training Loss = 0.0803, Validation Accuracy = 0.9897, Validation Loss = 0.1287\n",
            "Epoch 2398/3334\n",
            "Epoch 2398: Training Accuracy = 0.9883, Training Loss = 0.0803, Validation Accuracy = 0.9897, Validation Loss = 0.1287\n",
            "Epoch 2399/3334\n",
            "Epoch 2399: Training Accuracy = 0.9883, Training Loss = 0.0767, Validation Accuracy = 0.9897, Validation Loss = 0.1255\n",
            "Epoch 2400/3334\n",
            "Epoch 2400: Training Accuracy = 0.9883, Training Loss = 0.0767, Validation Accuracy = 0.9897, Validation Loss = 0.1255\n",
            "Epoch 2401/3334\n",
            "Epoch 2401: Training Accuracy = 0.9883, Training Loss = 0.0767, Validation Accuracy = 0.9897, Validation Loss = 0.1228\n",
            "Epoch 2402/3334\n",
            "Epoch 2402: Training Accuracy = 0.9824, Training Loss = 0.0986, Validation Accuracy = 0.9897, Validation Loss = 0.1223\n",
            "Epoch 2403/3334\n",
            "Epoch 2403: Training Accuracy = 0.9824, Training Loss = 0.0986, Validation Accuracy = 0.9897, Validation Loss = 0.1223\n",
            "Epoch 2404/3334\n",
            "Epoch 2404: Training Accuracy = 0.9883, Training Loss = 0.0746, Validation Accuracy = 0.9897, Validation Loss = 0.1206\n",
            "Epoch 2405/3334\n",
            "Epoch 2405: Training Accuracy = 0.9883, Training Loss = 0.0746, Validation Accuracy = 0.9897, Validation Loss = 0.1206\n",
            "Epoch 2406/3334\n",
            "Epoch 2406: Training Accuracy = 0.9883, Training Loss = 0.0737, Validation Accuracy = 0.9897, Validation Loss = 0.1201\n",
            "Epoch 2407/3334\n",
            "Epoch 2407: Training Accuracy = 0.9961, Training Loss = 0.0526, Validation Accuracy = 0.9897, Validation Loss = 0.1194\n",
            "Epoch 2408/3334\n",
            "Epoch 2408: Training Accuracy = 0.9961, Training Loss = 0.0526, Validation Accuracy = 0.9897, Validation Loss = 0.1194\n",
            "Epoch 2409/3334\n",
            "Epoch 2409: Training Accuracy = 0.9863, Training Loss = 0.0817, Validation Accuracy = 0.9897, Validation Loss = 0.1193\n",
            "Epoch 2410/3334\n",
            "Epoch 2410: Training Accuracy = 0.9863, Training Loss = 0.0817, Validation Accuracy = 0.9897, Validation Loss = 0.1193\n",
            "Epoch 2411/3334\n",
            "Epoch 2411: Training Accuracy = 0.9883, Training Loss = 0.0732, Validation Accuracy = 0.9897, Validation Loss = 0.1183\n",
            "Epoch 2412/3334\n",
            "Epoch 2412: Training Accuracy = 0.9863, Training Loss = 0.0813, Validation Accuracy = 0.9897, Validation Loss = 0.1189\n",
            "Epoch 2413/3334\n",
            "Epoch 2413: Training Accuracy = 0.9863, Training Loss = 0.0813, Validation Accuracy = 0.9897, Validation Loss = 0.1189\n",
            "Epoch 2414/3334\n",
            "Epoch 2414: Training Accuracy = 0.9902, Training Loss = 0.0664, Validation Accuracy = 0.9897, Validation Loss = 0.1181\n",
            "Epoch 2415/3334\n",
            "Epoch 2415: Training Accuracy = 0.9902, Training Loss = 0.0664, Validation Accuracy = 0.9897, Validation Loss = 0.1181\n",
            "Epoch 2416/3334\n",
            "Epoch 2416: Training Accuracy = 0.9863, Training Loss = 0.0787, Validation Accuracy = 0.9897, Validation Loss = 0.1171\n",
            "Epoch 2417/3334\n",
            "Epoch 2417: Training Accuracy = 0.9883, Training Loss = 0.0729, Validation Accuracy = 0.9897, Validation Loss = 0.1170\n",
            "Epoch 2418/3334\n",
            "Epoch 2418: Training Accuracy = 0.9883, Training Loss = 0.0729, Validation Accuracy = 0.9897, Validation Loss = 0.1170\n",
            "Epoch 2419/3334\n",
            "Epoch 2419: Training Accuracy = 0.9863, Training Loss = 0.0882, Validation Accuracy = 0.9897, Validation Loss = 0.1739\n",
            "Epoch 2420/3334\n",
            "Epoch 2420: Training Accuracy = 0.9863, Training Loss = 0.0882, Validation Accuracy = 0.9897, Validation Loss = 0.1739\n",
            "Epoch 2421/3334\n",
            "Epoch 2421: Training Accuracy = 0.8184, Training Loss = 0.9880, Validation Accuracy = 0.8230, Validation Loss = 1.0518\n",
            "Epoch 2422/3334\n",
            "Epoch 2422: Training Accuracy = 0.9746, Training Loss = 0.3344, Validation Accuracy = 0.9680, Validation Loss = 0.4102\n",
            "Epoch 2423/3334\n",
            "Epoch 2423: Training Accuracy = 0.9746, Training Loss = 0.3344, Validation Accuracy = 0.9680, Validation Loss = 0.4102\n",
            "Epoch 2424/3334\n",
            "Epoch 2424: Training Accuracy = 0.9922, Training Loss = 0.1532, Validation Accuracy = 0.9857, Validation Loss = 0.2340\n",
            "Epoch 2425/3334\n",
            "Epoch 2425: Training Accuracy = 0.9922, Training Loss = 0.1532, Validation Accuracy = 0.9857, Validation Loss = 0.2340\n",
            "Epoch 2426/3334\n",
            "Epoch 2426: Training Accuracy = 0.9883, Training Loss = 0.1101, Validation Accuracy = 0.9894, Validation Loss = 0.1669\n",
            "Epoch 2427/3334\n",
            "Epoch 2427: Training Accuracy = 0.9902, Training Loss = 0.0837, Validation Accuracy = 0.9897, Validation Loss = 0.1360\n",
            "Epoch 2428/3334\n",
            "Epoch 2428: Training Accuracy = 0.9902, Training Loss = 0.0837, Validation Accuracy = 0.9897, Validation Loss = 0.1360\n",
            "Epoch 2429/3334\n",
            "Epoch 2429: Training Accuracy = 0.9824, Training Loss = 0.1003, Validation Accuracy = 0.9897, Validation Loss = 0.1245\n",
            "Epoch 2430/3334\n",
            "Epoch 2430: Training Accuracy = 0.9824, Training Loss = 0.1003, Validation Accuracy = 0.9897, Validation Loss = 0.1245\n",
            "Epoch 2431/3334\n",
            "Epoch 2431: Training Accuracy = 0.9961, Training Loss = 0.0479, Validation Accuracy = 0.9897, Validation Loss = 0.1191\n",
            "Epoch 2432/3334\n",
            "Epoch 2432: Training Accuracy = 0.9961, Training Loss = 0.0483, Validation Accuracy = 0.9897, Validation Loss = 0.1165\n",
            "Epoch 2433/3334\n",
            "Epoch 2433: Training Accuracy = 0.9961, Training Loss = 0.0483, Validation Accuracy = 0.9897, Validation Loss = 0.1165\n",
            "Epoch 2434/3334\n",
            "Epoch 2434: Training Accuracy = 0.9883, Training Loss = 0.0824, Validation Accuracy = 0.9897, Validation Loss = 0.1157\n",
            "Epoch 2435/3334\n",
            "Epoch 2435: Training Accuracy = 0.9883, Training Loss = 0.0824, Validation Accuracy = 0.9897, Validation Loss = 0.1157\n",
            "Epoch 2436/3334\n",
            "Epoch 2436: Training Accuracy = 0.9824, Training Loss = 0.0937, Validation Accuracy = 0.9897, Validation Loss = 0.1157\n",
            "Epoch 2437/3334\n",
            "Epoch 2437: Training Accuracy = 0.9922, Training Loss = 0.0610, Validation Accuracy = 0.9897, Validation Loss = 0.1155\n",
            "Epoch 2438/3334\n",
            "Epoch 2438: Training Accuracy = 0.9922, Training Loss = 0.0610, Validation Accuracy = 0.9897, Validation Loss = 0.1155\n",
            "Epoch 2439/3334\n",
            "Epoch 2439: Training Accuracy = 0.9902, Training Loss = 0.0676, Validation Accuracy = 0.9897, Validation Loss = 0.1148\n",
            "Epoch 2440/3334\n",
            "Epoch 2440: Training Accuracy = 0.9902, Training Loss = 0.0676, Validation Accuracy = 0.9897, Validation Loss = 0.1148\n",
            "Epoch 2441/3334\n",
            "Epoch 2441: Training Accuracy = 0.9863, Training Loss = 0.0790, Validation Accuracy = 0.9897, Validation Loss = 0.1147\n",
            "Epoch 2442/3334\n",
            "Epoch 2442: Training Accuracy = 0.9863, Training Loss = 0.0815, Validation Accuracy = 0.9897, Validation Loss = 0.1138\n",
            "Epoch 2443/3334\n",
            "Epoch 2443: Training Accuracy = 0.9863, Training Loss = 0.0815, Validation Accuracy = 0.9897, Validation Loss = 0.1138\n",
            "Epoch 2444/3334\n",
            "Epoch 2444: Training Accuracy = 0.9844, Training Loss = 0.0857, Validation Accuracy = 0.9897, Validation Loss = 0.1151\n",
            "Epoch 2445/3334\n",
            "Epoch 2445: Training Accuracy = 0.9844, Training Loss = 0.0857, Validation Accuracy = 0.9897, Validation Loss = 0.1151\n",
            "Epoch 2446/3334\n",
            "Epoch 2446: Training Accuracy = 0.9844, Training Loss = 0.0876, Validation Accuracy = 0.9897, Validation Loss = 0.1172\n",
            "Epoch 2447/3334\n",
            "Epoch 2447: Training Accuracy = 0.9902, Training Loss = 0.0689, Validation Accuracy = 0.9897, Validation Loss = 0.1137\n",
            "Epoch 2448/3334\n",
            "Epoch 2448: Training Accuracy = 0.9902, Training Loss = 0.0689, Validation Accuracy = 0.9897, Validation Loss = 0.1137\n",
            "Epoch 2449/3334\n",
            "Epoch 2449: Training Accuracy = 0.9824, Training Loss = 0.0957, Validation Accuracy = 0.9897, Validation Loss = 0.1177\n",
            "Epoch 2450/3334\n",
            "Epoch 2450: Training Accuracy = 0.9824, Training Loss = 0.0957, Validation Accuracy = 0.9897, Validation Loss = 0.1177\n",
            "Epoch 2451/3334\n",
            "Epoch 2451: Training Accuracy = 0.9727, Training Loss = 0.3837, Validation Accuracy = 0.1224, Validation Loss = 4.0385\n",
            "Epoch 2452/3334\n",
            "Epoch 2452: Training Accuracy = 0.8711, Training Loss = 0.8508, Validation Accuracy = 0.8306, Validation Loss = 0.9555\n",
            "Epoch 2453/3334\n",
            "Epoch 2453: Training Accuracy = 0.8711, Training Loss = 0.8508, Validation Accuracy = 0.8306, Validation Loss = 0.9555\n",
            "Epoch 2454/3334\n",
            "Epoch 2454: Training Accuracy = 0.9570, Training Loss = 0.3623, Validation Accuracy = 0.9625, Validation Loss = 0.4110\n",
            "Epoch 2455/3334\n",
            "Epoch 2455: Training Accuracy = 0.9570, Training Loss = 0.3623, Validation Accuracy = 0.9625, Validation Loss = 0.4110\n",
            "Epoch 2456/3334\n",
            "Epoch 2456: Training Accuracy = 0.9902, Training Loss = 0.1813, Validation Accuracy = 0.9794, Validation Loss = 0.2813\n",
            "Epoch 2457/3334\n",
            "Epoch 2457: Training Accuracy = 0.9922, Training Loss = 0.1181, Validation Accuracy = 0.9888, Validation Loss = 0.1837\n",
            "Epoch 2458/3334\n",
            "Epoch 2458: Training Accuracy = 0.9922, Training Loss = 0.1181, Validation Accuracy = 0.9888, Validation Loss = 0.1837\n",
            "Epoch 2459/3334\n",
            "Epoch 2459: Training Accuracy = 0.9883, Training Loss = 0.1032, Validation Accuracy = 0.9897, Validation Loss = 0.1508\n",
            "Epoch 2460/3334\n",
            "Epoch 2460: Training Accuracy = 0.9883, Training Loss = 0.1032, Validation Accuracy = 0.9897, Validation Loss = 0.1508\n",
            "Epoch 2461/3334\n",
            "Epoch 2461: Training Accuracy = 0.9941, Training Loss = 0.0715, Validation Accuracy = 0.9897, Validation Loss = 0.1375\n",
            "Epoch 2462/3334\n",
            "Epoch 2462: Training Accuracy = 0.9902, Training Loss = 0.0796, Validation Accuracy = 0.9897, Validation Loss = 0.1291\n",
            "Epoch 2463/3334\n",
            "Epoch 2463: Training Accuracy = 0.9902, Training Loss = 0.0796, Validation Accuracy = 0.9897, Validation Loss = 0.1291\n",
            "Epoch 2464/3334\n",
            "Epoch 2464: Training Accuracy = 0.9922, Training Loss = 0.0706, Validation Accuracy = 0.9897, Validation Loss = 0.1270\n",
            "Epoch 2465/3334\n",
            "Epoch 2465: Training Accuracy = 0.9922, Training Loss = 0.0706, Validation Accuracy = 0.9897, Validation Loss = 0.1270\n",
            "Epoch 2466/3334\n",
            "Epoch 2466: Training Accuracy = 0.9844, Training Loss = 0.0951, Validation Accuracy = 0.9897, Validation Loss = 0.1245\n",
            "Epoch 2467/3334\n",
            "Epoch 2467: Training Accuracy = 0.9941, Training Loss = 0.0595, Validation Accuracy = 0.9897, Validation Loss = 0.1213\n",
            "Epoch 2468/3334\n",
            "Epoch 2468: Training Accuracy = 0.9941, Training Loss = 0.0595, Validation Accuracy = 0.9897, Validation Loss = 0.1213\n",
            "Epoch 2469/3334\n",
            "Epoch 2469: Training Accuracy = 0.9941, Training Loss = 0.0589, Validation Accuracy = 0.9897, Validation Loss = 0.1212\n",
            "Epoch 2470/3334\n",
            "Epoch 2470: Training Accuracy = 0.9941, Training Loss = 0.0589, Validation Accuracy = 0.9897, Validation Loss = 0.1212\n",
            "Epoch 2471/3334\n",
            "Epoch 2471: Training Accuracy = 0.9941, Training Loss = 0.0560, Validation Accuracy = 0.9897, Validation Loss = 0.1199\n",
            "Epoch 2472/3334\n",
            "Epoch 2472: Training Accuracy = 0.9941, Training Loss = 0.0574, Validation Accuracy = 0.9897, Validation Loss = 0.1188\n",
            "Epoch 2473/3334\n",
            "Epoch 2473: Training Accuracy = 0.9941, Training Loss = 0.0574, Validation Accuracy = 0.9897, Validation Loss = 0.1188\n",
            "Epoch 2474/3334\n",
            "Epoch 2474: Training Accuracy = 0.9922, Training Loss = 0.0620, Validation Accuracy = 0.9897, Validation Loss = 0.1164\n",
            "Epoch 2475/3334\n",
            "Epoch 2475: Training Accuracy = 0.9922, Training Loss = 0.0620, Validation Accuracy = 0.9897, Validation Loss = 0.1164\n",
            "Epoch 2476/3334\n",
            "Epoch 2476: Training Accuracy = 0.9922, Training Loss = 0.0666, Validation Accuracy = 0.9897, Validation Loss = 0.1143\n",
            "Epoch 2477/3334\n",
            "Epoch 2477: Training Accuracy = 0.9844, Training Loss = 0.0904, Validation Accuracy = 0.9897, Validation Loss = 0.1141\n",
            "Epoch 2478/3334\n",
            "Epoch 2478: Training Accuracy = 0.9844, Training Loss = 0.0904, Validation Accuracy = 0.9897, Validation Loss = 0.1141\n",
            "Epoch 2479/3334\n",
            "Epoch 2479: Training Accuracy = 0.9922, Training Loss = 0.0681, Validation Accuracy = 0.9897, Validation Loss = 0.1160\n",
            "Epoch 2480/3334\n",
            "Epoch 2480: Training Accuracy = 0.9922, Training Loss = 0.0681, Validation Accuracy = 0.9897, Validation Loss = 0.1160\n",
            "Epoch 2481/3334\n",
            "Epoch 2481: Training Accuracy = 0.9824, Training Loss = 0.0932, Validation Accuracy = 0.9897, Validation Loss = 0.1211\n",
            "Epoch 2482/3334\n",
            "Epoch 2482: Training Accuracy = 0.6855, Training Loss = 1.3750, Validation Accuracy = 0.7566, Validation Loss = 1.1752\n",
            "Epoch 2483/3334\n",
            "Epoch 2483: Training Accuracy = 0.6855, Training Loss = 1.3750, Validation Accuracy = 0.7566, Validation Loss = 1.1752\n",
            "Epoch 2484/3334\n",
            "Epoch 2484: Training Accuracy = 0.9570, Training Loss = 0.4372, Validation Accuracy = 0.9496, Validation Loss = 0.4871\n",
            "Epoch 2485/3334\n",
            "Epoch 2485: Training Accuracy = 0.9570, Training Loss = 0.4372, Validation Accuracy = 0.9496, Validation Loss = 0.4871\n",
            "Epoch 2486/3334\n",
            "Epoch 2486: Training Accuracy = 0.9863, Training Loss = 0.2122, Validation Accuracy = 0.9797, Validation Loss = 0.2884\n",
            "Epoch 2487/3334\n",
            "Epoch 2487: Training Accuracy = 0.9883, Training Loss = 0.1410, Validation Accuracy = 0.9885, Validation Loss = 0.1852\n",
            "Epoch 2488/3334\n",
            "Epoch 2488: Training Accuracy = 0.9883, Training Loss = 0.1410, Validation Accuracy = 0.9885, Validation Loss = 0.1852\n",
            "Epoch 2489/3334\n",
            "Epoch 2489: Training Accuracy = 0.9922, Training Loss = 0.0867, Validation Accuracy = 0.9897, Validation Loss = 0.1492\n",
            "Epoch 2490/3334\n",
            "Epoch 2490: Training Accuracy = 0.9922, Training Loss = 0.0867, Validation Accuracy = 0.9897, Validation Loss = 0.1492\n",
            "Epoch 2491/3334\n",
            "Epoch 2491: Training Accuracy = 0.9922, Training Loss = 0.0715, Validation Accuracy = 0.9897, Validation Loss = 0.1324\n",
            "Epoch 2492/3334\n",
            "Epoch 2492: Training Accuracy = 0.9922, Training Loss = 0.0688, Validation Accuracy = 0.9897, Validation Loss = 0.1243\n",
            "Epoch 2493/3334\n",
            "Epoch 2493: Training Accuracy = 0.9922, Training Loss = 0.0688, Validation Accuracy = 0.9897, Validation Loss = 0.1243\n",
            "Epoch 2494/3334\n",
            "Epoch 2494: Training Accuracy = 0.9941, Training Loss = 0.0589, Validation Accuracy = 0.9897, Validation Loss = 0.1211\n",
            "Epoch 2495/3334\n",
            "Epoch 2495: Training Accuracy = 0.9941, Training Loss = 0.0589, Validation Accuracy = 0.9897, Validation Loss = 0.1211\n",
            "Epoch 2496/3334\n",
            "Epoch 2496: Training Accuracy = 0.9922, Training Loss = 0.0701, Validation Accuracy = 0.9897, Validation Loss = 0.1191\n",
            "Epoch 2497/3334\n",
            "Epoch 2497: Training Accuracy = 0.9902, Training Loss = 0.0713, Validation Accuracy = 0.9897, Validation Loss = 0.1174\n",
            "Epoch 2498/3334\n",
            "Epoch 2498: Training Accuracy = 0.9902, Training Loss = 0.0713, Validation Accuracy = 0.9897, Validation Loss = 0.1174\n",
            "Epoch 2499/3334\n",
            "Epoch 2499: Training Accuracy = 0.9883, Training Loss = 0.0782, Validation Accuracy = 0.9897, Validation Loss = 0.1163\n",
            "Epoch 2500/3334\n",
            "Epoch 2500: Training Accuracy = 0.9883, Training Loss = 0.0782, Validation Accuracy = 0.9897, Validation Loss = 0.1163\n",
            "Epoch 2501/3334\n",
            "Epoch 2501: Training Accuracy = 0.9902, Training Loss = 0.0710, Validation Accuracy = 0.9897, Validation Loss = 0.1167\n",
            "Epoch 2502/3334\n",
            "Epoch 2502: Training Accuracy = 0.9941, Training Loss = 0.0563, Validation Accuracy = 0.9897, Validation Loss = 0.1160\n",
            "Epoch 2503/3334\n",
            "Epoch 2503: Training Accuracy = 0.9941, Training Loss = 0.0563, Validation Accuracy = 0.9897, Validation Loss = 0.1160\n",
            "Epoch 2504/3334\n",
            "Epoch 2504: Training Accuracy = 0.9824, Training Loss = 0.0976, Validation Accuracy = 0.9897, Validation Loss = 0.1147\n",
            "Epoch 2505/3334\n",
            "Epoch 2505: Training Accuracy = 0.9824, Training Loss = 0.0976, Validation Accuracy = 0.9897, Validation Loss = 0.1147\n",
            "Epoch 2506/3334\n",
            "Epoch 2506: Training Accuracy = 0.9883, Training Loss = 0.0735, Validation Accuracy = 0.9897, Validation Loss = 0.1133\n",
            "Epoch 2507/3334\n",
            "Epoch 2507: Training Accuracy = 0.9941, Training Loss = 0.0542, Validation Accuracy = 0.9897, Validation Loss = 0.1132\n",
            "Epoch 2508/3334\n",
            "Epoch 2508: Training Accuracy = 0.9941, Training Loss = 0.0542, Validation Accuracy = 0.9897, Validation Loss = 0.1132\n",
            "Epoch 2509/3334\n",
            "Epoch 2509: Training Accuracy = 0.9883, Training Loss = 0.0759, Validation Accuracy = 0.9897, Validation Loss = 0.1133\n",
            "Epoch 2510/3334\n",
            "Epoch 2510: Training Accuracy = 0.9883, Training Loss = 0.0759, Validation Accuracy = 0.9897, Validation Loss = 0.1133\n",
            "Epoch 2511/3334\n",
            "Epoch 2511: Training Accuracy = 0.9902, Training Loss = 0.0661, Validation Accuracy = 0.9897, Validation Loss = 0.1137\n",
            "Epoch 2512/3334\n",
            "Epoch 2512: Training Accuracy = 0.9863, Training Loss = 0.0843, Validation Accuracy = 0.9897, Validation Loss = 0.1137\n",
            "Epoch 2513/3334\n",
            "Epoch 2513: Training Accuracy = 0.9863, Training Loss = 0.0843, Validation Accuracy = 0.9897, Validation Loss = 0.1137\n",
            "Epoch 2514/3334\n",
            "Epoch 2514: Training Accuracy = 0.9922, Training Loss = 0.0595, Validation Accuracy = 0.9897, Validation Loss = 0.1187\n",
            "Epoch 2515/3334\n",
            "Epoch 2515: Training Accuracy = 0.9922, Training Loss = 0.0595, Validation Accuracy = 0.9897, Validation Loss = 0.1187\n",
            "Epoch 2516/3334\n",
            "Epoch 2516: Training Accuracy = 0.9844, Training Loss = 0.0939, Validation Accuracy = 0.9897, Validation Loss = 0.1227\n",
            "Epoch 2517/3334\n",
            "Epoch 2517: Training Accuracy = 0.2168, Training Loss = 3.3576, Validation Accuracy = 0.3706, Validation Loss = 2.5913\n",
            "Epoch 2518/3334\n",
            "Epoch 2518: Training Accuracy = 0.2168, Training Loss = 3.3576, Validation Accuracy = 0.3706, Validation Loss = 2.5913\n",
            "Epoch 2519/3334\n",
            "Epoch 2519: Training Accuracy = 0.8574, Training Loss = 0.8017, Validation Accuracy = 0.8432, Validation Loss = 0.8763\n",
            "Epoch 2520/3334\n",
            "Epoch 2520: Training Accuracy = 0.8574, Training Loss = 0.8017, Validation Accuracy = 0.8432, Validation Loss = 0.8763\n",
            "Epoch 2521/3334\n",
            "Epoch 2521: Training Accuracy = 0.9785, Training Loss = 0.3071, Validation Accuracy = 0.9619, Validation Loss = 0.4000\n",
            "Epoch 2522/3334\n",
            "Epoch 2522: Training Accuracy = 0.9922, Training Loss = 0.1453, Validation Accuracy = 0.9866, Validation Loss = 0.2223\n",
            "Epoch 2523/3334\n",
            "Epoch 2523: Training Accuracy = 0.9922, Training Loss = 0.1453, Validation Accuracy = 0.9866, Validation Loss = 0.2223\n",
            "Epoch 2524/3334\n",
            "Epoch 2524: Training Accuracy = 0.9922, Training Loss = 0.1000, Validation Accuracy = 0.9897, Validation Loss = 0.1616\n",
            "Epoch 2525/3334\n",
            "Epoch 2525: Training Accuracy = 0.9922, Training Loss = 0.1000, Validation Accuracy = 0.9897, Validation Loss = 0.1616\n",
            "Epoch 2526/3334\n",
            "Epoch 2526: Training Accuracy = 0.9863, Training Loss = 0.0987, Validation Accuracy = 0.9897, Validation Loss = 0.1347\n",
            "Epoch 2527/3334\n",
            "Epoch 2527: Training Accuracy = 0.9922, Training Loss = 0.0697, Validation Accuracy = 0.9897, Validation Loss = 0.1247\n",
            "Epoch 2528/3334\n",
            "Epoch 2528: Training Accuracy = 0.9922, Training Loss = 0.0697, Validation Accuracy = 0.9897, Validation Loss = 0.1247\n",
            "Epoch 2529/3334\n",
            "Epoch 2529: Training Accuracy = 0.9902, Training Loss = 0.0778, Validation Accuracy = 0.9897, Validation Loss = 0.1184\n",
            "Epoch 2530/3334\n",
            "Epoch 2530: Training Accuracy = 0.9902, Training Loss = 0.0778, Validation Accuracy = 0.9897, Validation Loss = 0.1184\n",
            "Epoch 2531/3334\n",
            "Epoch 2531: Training Accuracy = 0.9863, Training Loss = 0.0825, Validation Accuracy = 0.9897, Validation Loss = 0.1168\n",
            "Epoch 2532/3334\n",
            "Epoch 2532: Training Accuracy = 0.9844, Training Loss = 0.0921, Validation Accuracy = 0.9897, Validation Loss = 0.1152\n",
            "Epoch 2533/3334\n",
            "Epoch 2533: Training Accuracy = 0.9844, Training Loss = 0.0921, Validation Accuracy = 0.9897, Validation Loss = 0.1152\n",
            "Epoch 2534/3334\n",
            "Epoch 2534: Training Accuracy = 0.9922, Training Loss = 0.0636, Validation Accuracy = 0.9897, Validation Loss = 0.1144\n",
            "Epoch 2535/3334\n",
            "Epoch 2535: Training Accuracy = 0.9922, Training Loss = 0.0636, Validation Accuracy = 0.9897, Validation Loss = 0.1144\n",
            "Epoch 2536/3334\n",
            "Epoch 2536: Training Accuracy = 0.9844, Training Loss = 0.0887, Validation Accuracy = 0.9897, Validation Loss = 0.1137\n",
            "Epoch 2537/3334\n",
            "Epoch 2537: Training Accuracy = 0.9902, Training Loss = 0.0703, Validation Accuracy = 0.9897, Validation Loss = 0.1133\n",
            "Epoch 2538/3334\n",
            "Epoch 2538: Training Accuracy = 0.9902, Training Loss = 0.0703, Validation Accuracy = 0.9897, Validation Loss = 0.1133\n",
            "Epoch 2539/3334\n",
            "Epoch 2539: Training Accuracy = 0.9922, Training Loss = 0.0664, Validation Accuracy = 0.9897, Validation Loss = 0.1131\n",
            "Epoch 2540/3334\n",
            "Epoch 2540: Training Accuracy = 0.9922, Training Loss = 0.0664, Validation Accuracy = 0.9897, Validation Loss = 0.1131\n",
            "Epoch 2541/3334\n",
            "Epoch 2541: Training Accuracy = 0.9922, Training Loss = 0.0624, Validation Accuracy = 0.9897, Validation Loss = 0.1147\n",
            "Epoch 2542/3334\n",
            "Epoch 2542: Training Accuracy = 0.9902, Training Loss = 0.0727, Validation Accuracy = 0.9897, Validation Loss = 0.1135\n",
            "Epoch 2543/3334\n",
            "Epoch 2543: Training Accuracy = 0.9902, Training Loss = 0.0727, Validation Accuracy = 0.9897, Validation Loss = 0.1135\n",
            "Epoch 2544/3334\n",
            "Epoch 2544: Training Accuracy = 0.9902, Training Loss = 0.0685, Validation Accuracy = 0.9897, Validation Loss = 0.1119\n",
            "Epoch 2545/3334\n",
            "Epoch 2545: Training Accuracy = 0.9902, Training Loss = 0.0685, Validation Accuracy = 0.9897, Validation Loss = 0.1119\n",
            "Epoch 2546/3334\n",
            "Epoch 2546: Training Accuracy = 0.9922, Training Loss = 0.0588, Validation Accuracy = 0.9897, Validation Loss = 0.1123\n",
            "Epoch 2547/3334\n",
            "Epoch 2547: Training Accuracy = 0.9902, Training Loss = 0.0692, Validation Accuracy = 0.9897, Validation Loss = 0.1138\n",
            "Epoch 2548/3334\n",
            "Epoch 2548: Training Accuracy = 0.9902, Training Loss = 0.0692, Validation Accuracy = 0.9897, Validation Loss = 0.1138\n",
            "Epoch 2549/3334\n",
            "Epoch 2549: Training Accuracy = 0.9980, Training Loss = 0.0395, Validation Accuracy = 0.9897, Validation Loss = 0.1127\n",
            "Epoch 2550/3334\n",
            "Epoch 2550: Training Accuracy = 0.9980, Training Loss = 0.0395, Validation Accuracy = 0.9897, Validation Loss = 0.1127\n",
            "Epoch 2551/3334\n",
            "Epoch 2551: Training Accuracy = 0.9922, Training Loss = 0.0600, Validation Accuracy = 0.9897, Validation Loss = 0.1161\n",
            "Epoch 2552/3334\n",
            "Epoch 2552: Training Accuracy = 0.9922, Training Loss = 0.1708, Validation Accuracy = 0.4315, Validation Loss = 2.3367\n",
            "Epoch 2553/3334\n",
            "Epoch 2553: Training Accuracy = 0.9922, Training Loss = 0.1708, Validation Accuracy = 0.4315, Validation Loss = 2.3367\n",
            "Epoch 2554/3334\n",
            "Epoch 2554: Training Accuracy = 0.8379, Training Loss = 0.8793, Validation Accuracy = 0.8417, Validation Loss = 0.9026\n",
            "Epoch 2555/3334\n",
            "Epoch 2555: Training Accuracy = 0.8379, Training Loss = 0.8793, Validation Accuracy = 0.8417, Validation Loss = 0.9026\n",
            "Epoch 2556/3334\n",
            "Epoch 2556: Training Accuracy = 0.9746, Training Loss = 0.3022, Validation Accuracy = 0.9652, Validation Loss = 0.3755\n",
            "Epoch 2557/3334\n",
            "Epoch 2557: Training Accuracy = 0.9883, Training Loss = 0.1581, Validation Accuracy = 0.9874, Validation Loss = 0.2078\n",
            "Epoch 2558/3334\n",
            "Epoch 2558: Training Accuracy = 0.9883, Training Loss = 0.1581, Validation Accuracy = 0.9874, Validation Loss = 0.2078\n",
            "Epoch 2559/3334\n",
            "Epoch 2559: Training Accuracy = 0.9941, Training Loss = 0.0830, Validation Accuracy = 0.9894, Validation Loss = 0.1499\n",
            "Epoch 2560/3334\n",
            "Epoch 2560: Training Accuracy = 0.9941, Training Loss = 0.0830, Validation Accuracy = 0.9894, Validation Loss = 0.1499\n",
            "Epoch 2561/3334\n",
            "Epoch 2561: Training Accuracy = 0.9941, Training Loss = 0.0695, Validation Accuracy = 0.9897, Validation Loss = 0.1252\n",
            "Epoch 2562/3334\n",
            "Epoch 2562: Training Accuracy = 0.9941, Training Loss = 0.0581, Validation Accuracy = 0.9897, Validation Loss = 0.1167\n",
            "Epoch 2563/3334\n",
            "Epoch 2563: Training Accuracy = 0.9941, Training Loss = 0.0581, Validation Accuracy = 0.9897, Validation Loss = 0.1167\n",
            "Epoch 2564/3334\n",
            "Epoch 2564: Training Accuracy = 0.9883, Training Loss = 0.0771, Validation Accuracy = 0.9897, Validation Loss = 0.1135\n",
            "Epoch 2565/3334\n",
            "Epoch 2565: Training Accuracy = 0.9883, Training Loss = 0.0771, Validation Accuracy = 0.9897, Validation Loss = 0.1135\n",
            "Epoch 2566/3334\n",
            "Epoch 2566: Training Accuracy = 0.9922, Training Loss = 0.0611, Validation Accuracy = 0.9897, Validation Loss = 0.1117\n",
            "Epoch 2567/3334\n",
            "Epoch 2567: Training Accuracy = 0.9824, Training Loss = 0.0984, Validation Accuracy = 0.9897, Validation Loss = 0.1118\n",
            "Epoch 2568/3334\n",
            "Epoch 2568: Training Accuracy = 0.9824, Training Loss = 0.0984, Validation Accuracy = 0.9897, Validation Loss = 0.1118\n",
            "Epoch 2569/3334\n",
            "Epoch 2569: Training Accuracy = 0.9941, Training Loss = 0.0525, Validation Accuracy = 0.9897, Validation Loss = 0.1102\n",
            "Epoch 2570/3334\n",
            "Epoch 2570: Training Accuracy = 0.9941, Training Loss = 0.0525, Validation Accuracy = 0.9897, Validation Loss = 0.1102\n",
            "Epoch 2571/3334\n",
            "Epoch 2571: Training Accuracy = 0.9922, Training Loss = 0.0594, Validation Accuracy = 0.9897, Validation Loss = 0.1098\n",
            "Epoch 2572/3334\n",
            "Epoch 2572: Training Accuracy = 0.9824, Training Loss = 0.0970, Validation Accuracy = 0.9897, Validation Loss = 0.1103\n",
            "Epoch 2573/3334\n",
            "Epoch 2573: Training Accuracy = 0.9824, Training Loss = 0.0970, Validation Accuracy = 0.9897, Validation Loss = 0.1103\n",
            "Epoch 2574/3334\n",
            "Epoch 2574: Training Accuracy = 0.9941, Training Loss = 0.0525, Validation Accuracy = 0.9897, Validation Loss = 0.1101\n",
            "Epoch 2575/3334\n",
            "Epoch 2575: Training Accuracy = 0.9941, Training Loss = 0.0525, Validation Accuracy = 0.9897, Validation Loss = 0.1101\n",
            "Epoch 2576/3334\n",
            "Epoch 2576: Training Accuracy = 0.9941, Training Loss = 0.0572, Validation Accuracy = 0.9897, Validation Loss = 0.1097\n",
            "Epoch 2577/3334\n",
            "Epoch 2577: Training Accuracy = 0.9941, Training Loss = 0.0541, Validation Accuracy = 0.9897, Validation Loss = 0.1093\n",
            "Epoch 2578/3334\n",
            "Epoch 2578: Training Accuracy = 0.9941, Training Loss = 0.0541, Validation Accuracy = 0.9897, Validation Loss = 0.1093\n",
            "Epoch 2579/3334\n",
            "Epoch 2579: Training Accuracy = 0.9902, Training Loss = 0.0725, Validation Accuracy = 0.9897, Validation Loss = 0.1103\n",
            "Epoch 2580/3334\n",
            "Epoch 2580: Training Accuracy = 0.9902, Training Loss = 0.0725, Validation Accuracy = 0.9897, Validation Loss = 0.1103\n",
            "Epoch 2581/3334\n",
            "Epoch 2581: Training Accuracy = 0.9922, Training Loss = 0.0613, Validation Accuracy = 0.9897, Validation Loss = 0.1106\n",
            "Epoch 2582/3334\n",
            "Epoch 2582: Training Accuracy = 0.9824, Training Loss = 0.0938, Validation Accuracy = 0.9897, Validation Loss = 0.1133\n",
            "Epoch 2583/3334\n",
            "Epoch 2583: Training Accuracy = 0.9824, Training Loss = 0.0938, Validation Accuracy = 0.9897, Validation Loss = 0.1133\n",
            "Epoch 2584/3334\n",
            "Epoch 2584: Training Accuracy = 0.9961, Training Loss = 0.0478, Validation Accuracy = 0.9897, Validation Loss = 0.1137\n",
            "Epoch 2585/3334\n",
            "Epoch 2585: Training Accuracy = 0.9961, Training Loss = 0.0478, Validation Accuracy = 0.9897, Validation Loss = 0.1137\n",
            "Epoch 2586/3334\n",
            "Epoch 2586: Training Accuracy = 0.4805, Training Loss = 2.0512, Validation Accuracy = 0.5767, Validation Loss = 1.6633\n",
            "Epoch 2587/3334\n",
            "Epoch 2587: Training Accuracy = 0.9199, Training Loss = 0.6439, Validation Accuracy = 0.8737, Validation Loss = 0.7632\n",
            "Epoch 2588/3334\n",
            "Epoch 2588: Training Accuracy = 0.9199, Training Loss = 0.6439, Validation Accuracy = 0.8737, Validation Loss = 0.7632\n",
            "Epoch 2589/3334\n",
            "Epoch 2589: Training Accuracy = 0.9727, Training Loss = 0.3192, Validation Accuracy = 0.9760, Validation Loss = 0.3618\n",
            "Epoch 2590/3334\n",
            "Epoch 2590: Training Accuracy = 0.9727, Training Loss = 0.3192, Validation Accuracy = 0.9760, Validation Loss = 0.3618\n",
            "Epoch 2591/3334\n",
            "Epoch 2591: Training Accuracy = 0.9883, Training Loss = 0.1582, Validation Accuracy = 0.9883, Validation Loss = 0.2129\n",
            "Epoch 2592/3334\n",
            "Epoch 2592: Training Accuracy = 0.9902, Training Loss = 0.1034, Validation Accuracy = 0.9897, Validation Loss = 0.1535\n",
            "Epoch 2593/3334\n",
            "Epoch 2593: Training Accuracy = 0.9902, Training Loss = 0.1034, Validation Accuracy = 0.9897, Validation Loss = 0.1535\n",
            "Epoch 2594/3334\n",
            "Epoch 2594: Training Accuracy = 0.9902, Training Loss = 0.0853, Validation Accuracy = 0.9897, Validation Loss = 0.1325\n",
            "Epoch 2595/3334\n",
            "Epoch 2595: Training Accuracy = 0.9902, Training Loss = 0.0853, Validation Accuracy = 0.9897, Validation Loss = 0.1325\n",
            "Epoch 2596/3334\n",
            "Epoch 2596: Training Accuracy = 0.9883, Training Loss = 0.0832, Validation Accuracy = 0.9897, Validation Loss = 0.1210\n",
            "Epoch 2597/3334\n",
            "Epoch 2597: Training Accuracy = 0.9863, Training Loss = 0.0873, Validation Accuracy = 0.9897, Validation Loss = 0.1174\n",
            "Epoch 2598/3334\n",
            "Epoch 2598: Training Accuracy = 0.9863, Training Loss = 0.0873, Validation Accuracy = 0.9897, Validation Loss = 0.1174\n",
            "Epoch 2599/3334\n",
            "Epoch 2599: Training Accuracy = 0.9961, Training Loss = 0.0542, Validation Accuracy = 0.9897, Validation Loss = 0.1129\n",
            "Epoch 2600/3334\n",
            "Epoch 2600: Training Accuracy = 0.9961, Training Loss = 0.0542, Validation Accuracy = 0.9897, Validation Loss = 0.1129\n",
            "Epoch 2601/3334\n",
            "Epoch 2601: Training Accuracy = 0.9941, Training Loss = 0.0542, Validation Accuracy = 0.9897, Validation Loss = 0.1113\n",
            "Epoch 2602/3334\n",
            "Epoch 2602: Training Accuracy = 0.9902, Training Loss = 0.0729, Validation Accuracy = 0.9897, Validation Loss = 0.1100\n",
            "Epoch 2603/3334\n",
            "Epoch 2603: Training Accuracy = 0.9902, Training Loss = 0.0729, Validation Accuracy = 0.9897, Validation Loss = 0.1100\n",
            "Epoch 2604/3334\n",
            "Epoch 2604: Training Accuracy = 0.9902, Training Loss = 0.0660, Validation Accuracy = 0.9897, Validation Loss = 0.1102\n",
            "Epoch 2605/3334\n",
            "Epoch 2605: Training Accuracy = 0.9902, Training Loss = 0.0660, Validation Accuracy = 0.9897, Validation Loss = 0.1102\n",
            "Epoch 2606/3334\n",
            "Epoch 2606: Training Accuracy = 0.9805, Training Loss = 0.1072, Validation Accuracy = 0.9897, Validation Loss = 0.1076\n",
            "Epoch 2607/3334\n",
            "Epoch 2607: Training Accuracy = 0.9961, Training Loss = 0.0460, Validation Accuracy = 0.9897, Validation Loss = 0.1083\n",
            "Epoch 2608/3334\n",
            "Epoch 2608: Training Accuracy = 0.9961, Training Loss = 0.0460, Validation Accuracy = 0.9897, Validation Loss = 0.1083\n",
            "Epoch 2609/3334\n",
            "Epoch 2609: Training Accuracy = 0.9902, Training Loss = 0.0648, Validation Accuracy = 0.9897, Validation Loss = 0.1083\n",
            "Epoch 2610/3334\n",
            "Epoch 2610: Training Accuracy = 0.9902, Training Loss = 0.0648, Validation Accuracy = 0.9897, Validation Loss = 0.1083\n",
            "Epoch 2611/3334\n",
            "Epoch 2611: Training Accuracy = 0.9961, Training Loss = 0.0438, Validation Accuracy = 0.9897, Validation Loss = 0.1107\n",
            "Epoch 2612/3334\n",
            "Epoch 2612: Training Accuracy = 0.9902, Training Loss = 0.0709, Validation Accuracy = 0.9897, Validation Loss = 0.1089\n",
            "Epoch 2613/3334\n",
            "Epoch 2613: Training Accuracy = 0.9902, Training Loss = 0.0709, Validation Accuracy = 0.9897, Validation Loss = 0.1089\n",
            "Epoch 2614/3334\n",
            "Epoch 2614: Training Accuracy = 0.9922, Training Loss = 0.0605, Validation Accuracy = 0.9897, Validation Loss = 0.1079\n",
            "Epoch 2615/3334\n",
            "Epoch 2615: Training Accuracy = 0.9922, Training Loss = 0.0605, Validation Accuracy = 0.9897, Validation Loss = 0.1079\n",
            "Epoch 2616/3334\n",
            "Epoch 2616: Training Accuracy = 0.9922, Training Loss = 0.0570, Validation Accuracy = 0.9897, Validation Loss = 0.1071\n",
            "Epoch 2617/3334\n",
            "Epoch 2617: Training Accuracy = 0.9922, Training Loss = 0.0608, Validation Accuracy = 0.9897, Validation Loss = 0.1095\n",
            "Epoch 2618/3334\n",
            "Epoch 2618: Training Accuracy = 0.9922, Training Loss = 0.0608, Validation Accuracy = 0.9897, Validation Loss = 0.1095\n",
            "Epoch 2619/3334\n",
            "Epoch 2619: Training Accuracy = 0.9922, Training Loss = 0.0667, Validation Accuracy = 0.9897, Validation Loss = 0.1211\n",
            "Epoch 2620/3334\n",
            "Epoch 2620: Training Accuracy = 0.9922, Training Loss = 0.0667, Validation Accuracy = 0.9897, Validation Loss = 0.1211\n",
            "Epoch 2621/3334\n",
            "Epoch 2621: Training Accuracy = 0.5781, Training Loss = 1.7609, Validation Accuracy = 0.5509, Validation Loss = 1.7629\n",
            "Epoch 2622/3334\n",
            "Epoch 2622: Training Accuracy = 0.9453, Training Loss = 0.5279, Validation Accuracy = 0.9101, Validation Loss = 0.6428\n",
            "Epoch 2623/3334\n",
            "Epoch 2623: Training Accuracy = 0.9453, Training Loss = 0.5279, Validation Accuracy = 0.9101, Validation Loss = 0.6428\n",
            "Epoch 2624/3334\n",
            "Epoch 2624: Training Accuracy = 0.9863, Training Loss = 0.2398, Validation Accuracy = 0.9844, Validation Loss = 0.2774\n",
            "Epoch 2625/3334\n",
            "Epoch 2625: Training Accuracy = 0.9863, Training Loss = 0.2398, Validation Accuracy = 0.9844, Validation Loss = 0.2774\n",
            "Epoch 2626/3334\n",
            "Epoch 2626: Training Accuracy = 0.9922, Training Loss = 0.1182, Validation Accuracy = 0.9897, Validation Loss = 0.1863\n",
            "Epoch 2627/3334\n",
            "Epoch 2627: Training Accuracy = 0.9902, Training Loss = 0.0938, Validation Accuracy = 0.9897, Validation Loss = 0.1414\n",
            "Epoch 2628/3334\n",
            "Epoch 2628: Training Accuracy = 0.9902, Training Loss = 0.0938, Validation Accuracy = 0.9897, Validation Loss = 0.1414\n",
            "Epoch 2629/3334\n",
            "Epoch 2629: Training Accuracy = 0.9863, Training Loss = 0.0928, Validation Accuracy = 0.9897, Validation Loss = 0.1238\n",
            "Epoch 2630/3334\n",
            "Epoch 2630: Training Accuracy = 0.9863, Training Loss = 0.0928, Validation Accuracy = 0.9897, Validation Loss = 0.1238\n",
            "Epoch 2631/3334\n",
            "Epoch 2631: Training Accuracy = 0.9961, Training Loss = 0.0507, Validation Accuracy = 0.9897, Validation Loss = 0.1159\n",
            "Epoch 2632/3334\n",
            "Epoch 2632: Training Accuracy = 0.9883, Training Loss = 0.0770, Validation Accuracy = 0.9897, Validation Loss = 0.1123\n",
            "Epoch 2633/3334\n",
            "Epoch 2633: Training Accuracy = 0.9883, Training Loss = 0.0770, Validation Accuracy = 0.9897, Validation Loss = 0.1123\n",
            "Epoch 2634/3334\n",
            "Epoch 2634: Training Accuracy = 0.9922, Training Loss = 0.0656, Validation Accuracy = 0.9897, Validation Loss = 0.1107\n",
            "Epoch 2635/3334\n",
            "Epoch 2635: Training Accuracy = 0.9922, Training Loss = 0.0656, Validation Accuracy = 0.9897, Validation Loss = 0.1107\n",
            "Epoch 2636/3334\n",
            "Epoch 2636: Training Accuracy = 0.9902, Training Loss = 0.0672, Validation Accuracy = 0.9897, Validation Loss = 0.1107\n",
            "Epoch 2637/3334\n",
            "Epoch 2637: Training Accuracy = 0.9863, Training Loss = 0.0812, Validation Accuracy = 0.9897, Validation Loss = 0.1089\n",
            "Epoch 2638/3334\n",
            "Epoch 2638: Training Accuracy = 0.9863, Training Loss = 0.0812, Validation Accuracy = 0.9897, Validation Loss = 0.1089\n",
            "Epoch 2639/3334\n",
            "Epoch 2639: Training Accuracy = 0.9902, Training Loss = 0.0682, Validation Accuracy = 0.9897, Validation Loss = 0.1085\n",
            "Epoch 2640/3334\n",
            "Epoch 2640: Training Accuracy = 0.9902, Training Loss = 0.0682, Validation Accuracy = 0.9897, Validation Loss = 0.1085\n",
            "Epoch 2641/3334\n",
            "Epoch 2641: Training Accuracy = 0.9922, Training Loss = 0.0653, Validation Accuracy = 0.9897, Validation Loss = 0.1083\n",
            "Epoch 2642/3334\n",
            "Epoch 2642: Training Accuracy = 0.9863, Training Loss = 0.0800, Validation Accuracy = 0.9897, Validation Loss = 0.1060\n",
            "Epoch 2643/3334\n",
            "Epoch 2643: Training Accuracy = 0.9863, Training Loss = 0.0800, Validation Accuracy = 0.9897, Validation Loss = 0.1060\n",
            "Epoch 2644/3334\n",
            "Epoch 2644: Training Accuracy = 0.9941, Training Loss = 0.0569, Validation Accuracy = 0.9897, Validation Loss = 0.1072\n",
            "Epoch 2645/3334\n",
            "Epoch 2645: Training Accuracy = 0.9941, Training Loss = 0.0569, Validation Accuracy = 0.9897, Validation Loss = 0.1072\n",
            "Epoch 2646/3334\n",
            "Epoch 2646: Training Accuracy = 0.9863, Training Loss = 0.0813, Validation Accuracy = 0.9897, Validation Loss = 0.1070\n",
            "Epoch 2647/3334\n",
            "Epoch 2647: Training Accuracy = 0.9883, Training Loss = 0.0735, Validation Accuracy = 0.9897, Validation Loss = 0.1066\n",
            "Epoch 2648/3334\n",
            "Epoch 2648: Training Accuracy = 0.9883, Training Loss = 0.0735, Validation Accuracy = 0.9897, Validation Loss = 0.1066\n",
            "Epoch 2649/3334\n",
            "Epoch 2649: Training Accuracy = 0.9922, Training Loss = 0.0579, Validation Accuracy = 0.9897, Validation Loss = 0.1063\n",
            "Epoch 2650/3334\n",
            "Epoch 2650: Training Accuracy = 0.9922, Training Loss = 0.0579, Validation Accuracy = 0.9897, Validation Loss = 0.1063\n",
            "Epoch 2651/3334\n",
            "Epoch 2651: Training Accuracy = 0.9805, Training Loss = 0.1013, Validation Accuracy = 0.9897, Validation Loss = 0.1104\n",
            "Epoch 2652/3334\n",
            "Epoch 2652: Training Accuracy = 0.9883, Training Loss = 0.0791, Validation Accuracy = 0.9897, Validation Loss = 0.1148\n",
            "Epoch 2653/3334\n",
            "Epoch 2653: Training Accuracy = 0.9883, Training Loss = 0.0791, Validation Accuracy = 0.9897, Validation Loss = 0.1148\n",
            "Epoch 2654/3334\n",
            "Epoch 2654: Training Accuracy = 0.9883, Training Loss = 0.0780, Validation Accuracy = 0.9897, Validation Loss = 0.1249\n",
            "Epoch 2655/3334\n",
            "Epoch 2655: Training Accuracy = 0.9883, Training Loss = 0.0780, Validation Accuracy = 0.9897, Validation Loss = 0.1249\n",
            "Epoch 2656/3334\n",
            "Epoch 2656: Training Accuracy = 0.5605, Training Loss = 1.8748, Validation Accuracy = 0.5910, Validation Loss = 1.7554\n",
            "Epoch 2657/3334\n",
            "Epoch 2657: Training Accuracy = 0.9395, Training Loss = 0.5577, Validation Accuracy = 0.9265, Validation Loss = 0.6054\n",
            "Epoch 2658/3334\n",
            "Epoch 2658: Training Accuracy = 0.9395, Training Loss = 0.5577, Validation Accuracy = 0.9265, Validation Loss = 0.6054\n",
            "Epoch 2659/3334\n",
            "Epoch 2659: Training Accuracy = 0.9961, Training Loss = 0.2050, Validation Accuracy = 0.9825, Validation Loss = 0.3154\n",
            "Epoch 2660/3334\n",
            "Epoch 2660: Training Accuracy = 0.9961, Training Loss = 0.2050, Validation Accuracy = 0.9825, Validation Loss = 0.3154\n",
            "Epoch 2661/3334\n",
            "Epoch 2661: Training Accuracy = 0.9922, Training Loss = 0.1423, Validation Accuracy = 0.9880, Validation Loss = 0.2133\n",
            "Epoch 2662/3334\n",
            "Epoch 2662: Training Accuracy = 0.9922, Training Loss = 0.1106, Validation Accuracy = 0.9897, Validation Loss = 0.1615\n",
            "Epoch 2663/3334\n",
            "Epoch 2663: Training Accuracy = 0.9922, Training Loss = 0.1106, Validation Accuracy = 0.9897, Validation Loss = 0.1615\n",
            "Epoch 2664/3334\n",
            "Epoch 2664: Training Accuracy = 0.9883, Training Loss = 0.1022, Validation Accuracy = 0.9897, Validation Loss = 0.1421\n",
            "Epoch 2665/3334\n",
            "Epoch 2665: Training Accuracy = 0.9883, Training Loss = 0.1022, Validation Accuracy = 0.9897, Validation Loss = 0.1421\n",
            "Epoch 2666/3334\n",
            "Epoch 2666: Training Accuracy = 0.9844, Training Loss = 0.1033, Validation Accuracy = 0.9897, Validation Loss = 0.1338\n",
            "Epoch 2667/3334\n",
            "Epoch 2667: Training Accuracy = 0.9883, Training Loss = 0.0872, Validation Accuracy = 0.9897, Validation Loss = 0.1279\n",
            "Epoch 2668/3334\n",
            "Epoch 2668: Training Accuracy = 0.9883, Training Loss = 0.0872, Validation Accuracy = 0.9897, Validation Loss = 0.1279\n",
            "Epoch 2669/3334\n",
            "Epoch 2669: Training Accuracy = 0.9902, Training Loss = 0.0792, Validation Accuracy = 0.9897, Validation Loss = 0.1256\n",
            "Epoch 2670/3334\n",
            "Epoch 2670: Training Accuracy = 0.9902, Training Loss = 0.0792, Validation Accuracy = 0.9897, Validation Loss = 0.1256\n",
            "Epoch 2671/3334\n",
            "Epoch 2671: Training Accuracy = 0.9902, Training Loss = 0.0758, Validation Accuracy = 0.9897, Validation Loss = 0.1231\n",
            "Epoch 2672/3334\n",
            "Epoch 2672: Training Accuracy = 0.9902, Training Loss = 0.0774, Validation Accuracy = 0.9897, Validation Loss = 0.1225\n",
            "Epoch 2673/3334\n",
            "Epoch 2673: Training Accuracy = 0.9902, Training Loss = 0.0774, Validation Accuracy = 0.9897, Validation Loss = 0.1225\n",
            "Epoch 2674/3334\n",
            "Epoch 2674: Training Accuracy = 0.9941, Training Loss = 0.0642, Validation Accuracy = 0.9897, Validation Loss = 0.1209\n",
            "Epoch 2675/3334\n",
            "Epoch 2675: Training Accuracy = 0.9941, Training Loss = 0.0642, Validation Accuracy = 0.9897, Validation Loss = 0.1209\n",
            "Epoch 2676/3334\n",
            "Epoch 2676: Training Accuracy = 0.9902, Training Loss = 0.0767, Validation Accuracy = 0.9897, Validation Loss = 0.1214\n",
            "Epoch 2677/3334\n",
            "Epoch 2677: Training Accuracy = 0.9902, Training Loss = 0.0777, Validation Accuracy = 0.9897, Validation Loss = 0.1202\n",
            "Epoch 2678/3334\n",
            "Epoch 2678: Training Accuracy = 0.9902, Training Loss = 0.0777, Validation Accuracy = 0.9897, Validation Loss = 0.1202\n",
            "Epoch 2679/3334\n",
            "Epoch 2679: Training Accuracy = 0.9961, Training Loss = 0.0619, Validation Accuracy = 0.9897, Validation Loss = 0.1189\n",
            "Epoch 2680/3334\n",
            "Epoch 2680: Training Accuracy = 0.9961, Training Loss = 0.0619, Validation Accuracy = 0.9897, Validation Loss = 0.1189\n",
            "Epoch 2681/3334\n",
            "Epoch 2681: Training Accuracy = 0.9902, Training Loss = 0.0757, Validation Accuracy = 0.9897, Validation Loss = 0.1250\n",
            "Epoch 2682/3334\n",
            "Epoch 2682: Training Accuracy = 0.9922, Training Loss = 0.0790, Validation Accuracy = 0.9897, Validation Loss = 0.1224\n",
            "Epoch 2683/3334\n",
            "Epoch 2683: Training Accuracy = 0.9922, Training Loss = 0.0790, Validation Accuracy = 0.9897, Validation Loss = 0.1224\n",
            "Epoch 2684/3334\n",
            "Epoch 2684: Training Accuracy = 0.5273, Training Loss = 1.5527, Validation Accuracy = 0.3017, Validation Loss = 2.3917\n",
            "Epoch 2685/3334\n",
            "Epoch 2685: Training Accuracy = 0.5273, Training Loss = 1.5527, Validation Accuracy = 0.3017, Validation Loss = 2.3917\n",
            "Epoch 2686/3334\n",
            "Epoch 2686: Training Accuracy = 0.7402, Training Loss = 1.5265, Validation Accuracy = 0.7058, Validation Loss = 1.4631\n",
            "Epoch 2687/3334\n",
            "Epoch 2687: Training Accuracy = 0.9688, Training Loss = 0.4862, Validation Accuracy = 0.9514, Validation Loss = 0.5397\n",
            "Epoch 2688/3334\n",
            "Epoch 2688: Training Accuracy = 0.9688, Training Loss = 0.4862, Validation Accuracy = 0.9514, Validation Loss = 0.5397\n",
            "Epoch 2689/3334\n",
            "Epoch 2689: Training Accuracy = 0.9883, Training Loss = 0.1962, Validation Accuracy = 0.9827, Validation Loss = 0.2781\n",
            "Epoch 2690/3334\n",
            "Epoch 2690: Training Accuracy = 0.9883, Training Loss = 0.1962, Validation Accuracy = 0.9827, Validation Loss = 0.2781\n",
            "Epoch 2691/3334\n",
            "Epoch 2691: Training Accuracy = 0.9922, Training Loss = 0.1258, Validation Accuracy = 0.9891, Validation Loss = 0.1897\n",
            "Epoch 2692/3334\n",
            "Epoch 2692: Training Accuracy = 0.9902, Training Loss = 0.1050, Validation Accuracy = 0.9894, Validation Loss = 0.1525\n",
            "Epoch 2693/3334\n",
            "Epoch 2693: Training Accuracy = 0.9902, Training Loss = 0.1050, Validation Accuracy = 0.9894, Validation Loss = 0.1525\n",
            "Epoch 2694/3334\n",
            "Epoch 2694: Training Accuracy = 0.9902, Training Loss = 0.0897, Validation Accuracy = 0.9897, Validation Loss = 0.1350\n",
            "Epoch 2695/3334\n",
            "Epoch 2695: Training Accuracy = 0.9902, Training Loss = 0.0897, Validation Accuracy = 0.9897, Validation Loss = 0.1350\n",
            "Epoch 2696/3334\n",
            "Epoch 2696: Training Accuracy = 0.9883, Training Loss = 0.0847, Validation Accuracy = 0.9895, Validation Loss = 0.1263\n",
            "Epoch 2697/3334\n",
            "Epoch 2697: Training Accuracy = 0.9902, Training Loss = 0.0778, Validation Accuracy = 0.9897, Validation Loss = 0.1216\n",
            "Epoch 2698/3334\n",
            "Epoch 2698: Training Accuracy = 0.9902, Training Loss = 0.0778, Validation Accuracy = 0.9897, Validation Loss = 0.1216\n",
            "Epoch 2699/3334\n",
            "Epoch 2699: Training Accuracy = 0.9961, Training Loss = 0.0614, Validation Accuracy = 0.9897, Validation Loss = 0.1205\n",
            "Epoch 2700/3334\n",
            "Epoch 2700: Training Accuracy = 0.9961, Training Loss = 0.0614, Validation Accuracy = 0.9897, Validation Loss = 0.1205\n",
            "Epoch 2701/3334\n",
            "Epoch 2701: Training Accuracy = 0.9883, Training Loss = 0.0813, Validation Accuracy = 0.9897, Validation Loss = 0.1203\n",
            "Epoch 2702/3334\n",
            "Epoch 2702: Training Accuracy = 0.9824, Training Loss = 0.1033, Validation Accuracy = 0.9897, Validation Loss = 0.1176\n",
            "Epoch 2703/3334\n",
            "Epoch 2703: Training Accuracy = 0.9824, Training Loss = 0.1033, Validation Accuracy = 0.9897, Validation Loss = 0.1176\n",
            "Epoch 2704/3334\n",
            "Epoch 2704: Training Accuracy = 0.9941, Training Loss = 0.0596, Validation Accuracy = 0.9897, Validation Loss = 0.1180\n",
            "Epoch 2705/3334\n",
            "Epoch 2705: Training Accuracy = 0.9941, Training Loss = 0.0596, Validation Accuracy = 0.9897, Validation Loss = 0.1180\n",
            "Epoch 2706/3334\n",
            "Epoch 2706: Training Accuracy = 0.9902, Training Loss = 0.0724, Validation Accuracy = 0.9897, Validation Loss = 0.1158\n",
            "Epoch 2707/3334\n",
            "Epoch 2707: Training Accuracy = 0.9863, Training Loss = 0.0885, Validation Accuracy = 0.9897, Validation Loss = 0.1174\n",
            "Epoch 2708/3334\n",
            "Epoch 2708: Training Accuracy = 0.9863, Training Loss = 0.0885, Validation Accuracy = 0.9897, Validation Loss = 0.1174\n",
            "Epoch 2709/3334\n",
            "Epoch 2709: Training Accuracy = 0.9844, Training Loss = 0.0964, Validation Accuracy = 0.9897, Validation Loss = 0.1162\n",
            "Epoch 2710/3334\n",
            "Epoch 2710: Training Accuracy = 0.9844, Training Loss = 0.0964, Validation Accuracy = 0.9897, Validation Loss = 0.1162\n",
            "Epoch 2711/3334\n",
            "Epoch 2711: Training Accuracy = 0.9941, Training Loss = 0.0595, Validation Accuracy = 0.9897, Validation Loss = 0.1203\n",
            "Epoch 2712/3334\n",
            "Epoch 2712: Training Accuracy = 0.9844, Training Loss = 0.1005, Validation Accuracy = 0.9897, Validation Loss = 0.1156\n",
            "Epoch 2713/3334\n",
            "Epoch 2713: Training Accuracy = 0.9844, Training Loss = 0.1005, Validation Accuracy = 0.9897, Validation Loss = 0.1156\n",
            "Epoch 2714/3334\n",
            "Epoch 2714: Training Accuracy = 0.9824, Training Loss = 0.1035, Validation Accuracy = 0.9897, Validation Loss = 0.1219\n",
            "Epoch 2715/3334\n",
            "Epoch 2715: Training Accuracy = 0.9824, Training Loss = 0.1035, Validation Accuracy = 0.9897, Validation Loss = 0.1219\n",
            "Epoch 2716/3334\n",
            "Epoch 2716: Training Accuracy = 0.9883, Training Loss = 0.0895, Validation Accuracy = 0.9897, Validation Loss = 0.1188\n",
            "Epoch 2717/3334\n",
            "Epoch 2717: Training Accuracy = 0.9922, Training Loss = 0.0693, Validation Accuracy = 0.9897, Validation Loss = 0.1136\n",
            "Epoch 2718/3334\n",
            "Epoch 2718: Training Accuracy = 0.9922, Training Loss = 0.0693, Validation Accuracy = 0.9897, Validation Loss = 0.1136\n",
            "Epoch 2719/3334\n",
            "Epoch 2719: Training Accuracy = 0.9824, Training Loss = 0.1011, Validation Accuracy = 0.9897, Validation Loss = 0.1171\n",
            "Epoch 2720/3334\n",
            "Epoch 2720: Training Accuracy = 0.9824, Training Loss = 0.1011, Validation Accuracy = 0.9897, Validation Loss = 0.1171\n",
            "Epoch 2721/3334\n",
            "Epoch 2721: Training Accuracy = 0.9902, Training Loss = 0.0830, Validation Accuracy = 0.9894, Validation Loss = 0.1239\n",
            "Epoch 2722/3334\n",
            "Epoch 2722: Training Accuracy = 0.9941, Training Loss = 0.0667, Validation Accuracy = 0.9897, Validation Loss = 0.1264\n",
            "Epoch 2723/3334\n",
            "Epoch 2723: Training Accuracy = 0.9941, Training Loss = 0.0667, Validation Accuracy = 0.9897, Validation Loss = 0.1264\n",
            "Epoch 2724/3334\n",
            "Epoch 2724: Training Accuracy = 0.9883, Training Loss = 0.1226, Validation Accuracy = 0.9698, Validation Loss = 0.3152\n",
            "Epoch 2725/3334\n",
            "Epoch 2725: Training Accuracy = 0.9883, Training Loss = 0.1226, Validation Accuracy = 0.9698, Validation Loss = 0.3152\n",
            "Epoch 2726/3334\n",
            "Epoch 2726: Training Accuracy = 0.9180, Training Loss = 0.5733, Validation Accuracy = 0.8863, Validation Loss = 0.7249\n",
            "Epoch 2727/3334\n",
            "Epoch 2727: Training Accuracy = 0.9863, Training Loss = 0.2338, Validation Accuracy = 0.9769, Validation Loss = 0.3099\n",
            "Epoch 2728/3334\n",
            "Epoch 2728: Training Accuracy = 0.9863, Training Loss = 0.2338, Validation Accuracy = 0.9769, Validation Loss = 0.3099\n",
            "Epoch 2729/3334\n",
            "Epoch 2729: Training Accuracy = 0.9922, Training Loss = 0.1266, Validation Accuracy = 0.9892, Validation Loss = 0.1737\n",
            "Epoch 2730/3334\n",
            "Epoch 2730: Training Accuracy = 0.9922, Training Loss = 0.1266, Validation Accuracy = 0.9892, Validation Loss = 0.1737\n",
            "Epoch 2731/3334\n",
            "Epoch 2731: Training Accuracy = 0.9863, Training Loss = 0.0945, Validation Accuracy = 0.9897, Validation Loss = 0.1321\n",
            "Epoch 2732/3334\n",
            "Epoch 2732: Training Accuracy = 0.9922, Training Loss = 0.0640, Validation Accuracy = 0.9897, Validation Loss = 0.1139\n",
            "Epoch 2733/3334\n",
            "Epoch 2733: Training Accuracy = 0.9922, Training Loss = 0.0640, Validation Accuracy = 0.9897, Validation Loss = 0.1139\n",
            "Epoch 2734/3334\n",
            "Epoch 2734: Training Accuracy = 0.9844, Training Loss = 0.0865, Validation Accuracy = 0.9897, Validation Loss = 0.1069\n",
            "Epoch 2735/3334\n",
            "Epoch 2735: Training Accuracy = 0.9844, Training Loss = 0.0865, Validation Accuracy = 0.9897, Validation Loss = 0.1069\n",
            "Epoch 2736/3334\n",
            "Epoch 2736: Training Accuracy = 0.9824, Training Loss = 0.0897, Validation Accuracy = 0.9897, Validation Loss = 0.1040\n",
            "Epoch 2737/3334\n",
            "Epoch 2737: Training Accuracy = 0.9863, Training Loss = 0.0781, Validation Accuracy = 0.9897, Validation Loss = 0.1035\n",
            "Epoch 2738/3334\n",
            "Epoch 2738: Training Accuracy = 0.9863, Training Loss = 0.0781, Validation Accuracy = 0.9897, Validation Loss = 0.1035\n",
            "Epoch 2739/3334\n",
            "Epoch 2739: Training Accuracy = 0.9902, Training Loss = 0.0619, Validation Accuracy = 0.9897, Validation Loss = 0.1039\n",
            "Epoch 2740/3334\n",
            "Epoch 2740: Training Accuracy = 0.9902, Training Loss = 0.0619, Validation Accuracy = 0.9897, Validation Loss = 0.1039\n",
            "Epoch 2741/3334\n",
            "Epoch 2741: Training Accuracy = 0.9902, Training Loss = 0.0625, Validation Accuracy = 0.9897, Validation Loss = 0.1036\n",
            "Epoch 2742/3334\n",
            "Epoch 2742: Training Accuracy = 0.9941, Training Loss = 0.0493, Validation Accuracy = 0.9897, Validation Loss = 0.1040\n",
            "Epoch 2743/3334\n",
            "Epoch 2743: Training Accuracy = 0.9941, Training Loss = 0.0493, Validation Accuracy = 0.9897, Validation Loss = 0.1040\n",
            "Epoch 2744/3334\n",
            "Epoch 2744: Training Accuracy = 0.9941, Training Loss = 0.0479, Validation Accuracy = 0.9897, Validation Loss = 0.1027\n",
            "Epoch 2745/3334\n",
            "Epoch 2745: Training Accuracy = 0.9941, Training Loss = 0.0479, Validation Accuracy = 0.9897, Validation Loss = 0.1027\n",
            "Epoch 2746/3334\n",
            "Epoch 2746: Training Accuracy = 0.9941, Training Loss = 0.0476, Validation Accuracy = 0.9897, Validation Loss = 0.1018\n",
            "Epoch 2747/3334\n",
            "Epoch 2747: Training Accuracy = 0.9922, Training Loss = 0.0538, Validation Accuracy = 0.9897, Validation Loss = 0.1015\n",
            "Epoch 2748/3334\n",
            "Epoch 2748: Training Accuracy = 0.9922, Training Loss = 0.0538, Validation Accuracy = 0.9897, Validation Loss = 0.1015\n",
            "Epoch 2749/3334\n",
            "Epoch 2749: Training Accuracy = 0.9922, Training Loss = 0.0527, Validation Accuracy = 0.9897, Validation Loss = 0.1002\n",
            "Epoch 2750/3334\n",
            "Epoch 2750: Training Accuracy = 0.9922, Training Loss = 0.0527, Validation Accuracy = 0.9897, Validation Loss = 0.1002\n",
            "Epoch 2751/3334\n",
            "Epoch 2751: Training Accuracy = 0.9902, Training Loss = 0.0600, Validation Accuracy = 0.9897, Validation Loss = 0.0999\n",
            "Epoch 2752/3334\n",
            "Epoch 2752: Training Accuracy = 0.9922, Training Loss = 0.0551, Validation Accuracy = 0.9897, Validation Loss = 0.1003\n",
            "Epoch 2753/3334\n",
            "Epoch 2753: Training Accuracy = 0.9922, Training Loss = 0.0551, Validation Accuracy = 0.9897, Validation Loss = 0.1003\n",
            "Epoch 2754/3334\n",
            "Epoch 2754: Training Accuracy = 0.9922, Training Loss = 0.0551, Validation Accuracy = 0.9897, Validation Loss = 0.0987\n",
            "Epoch 2755/3334\n",
            "Epoch 2755: Training Accuracy = 0.9922, Training Loss = 0.0551, Validation Accuracy = 0.9897, Validation Loss = 0.0987\n",
            "Epoch 2756/3334\n",
            "Epoch 2756: Training Accuracy = 0.9922, Training Loss = 0.0508, Validation Accuracy = 0.9897, Validation Loss = 0.1003\n",
            "Epoch 2757/3334\n",
            "Epoch 2757: Training Accuracy = 0.9902, Training Loss = 0.0604, Validation Accuracy = 0.9897, Validation Loss = 0.1014\n",
            "Epoch 2758/3334\n",
            "Epoch 2758: Training Accuracy = 0.9902, Training Loss = 0.0604, Validation Accuracy = 0.9897, Validation Loss = 0.1014\n",
            "Epoch 2759/3334\n",
            "Epoch 2759: Training Accuracy = 0.9941, Training Loss = 0.0683, Validation Accuracy = 0.9865, Validation Loss = 0.2092\n",
            "Epoch 2760/3334\n",
            "Epoch 2760: Training Accuracy = 0.9941, Training Loss = 0.0683, Validation Accuracy = 0.9865, Validation Loss = 0.2092\n",
            "Epoch 2761/3334\n",
            "Epoch 2761: Training Accuracy = 0.6992, Training Loss = 1.3260, Validation Accuracy = 0.7503, Validation Loss = 1.2446\n",
            "Epoch 2762/3334\n",
            "Epoch 2762: Training Accuracy = 0.9707, Training Loss = 0.4142, Validation Accuracy = 0.9743, Validation Loss = 0.3913\n",
            "Epoch 2763/3334\n",
            "Epoch 2763: Training Accuracy = 0.9707, Training Loss = 0.4142, Validation Accuracy = 0.9743, Validation Loss = 0.3913\n",
            "Epoch 2764/3334\n",
            "Epoch 2764: Training Accuracy = 0.9902, Training Loss = 0.1595, Validation Accuracy = 0.9876, Validation Loss = 0.2209\n",
            "Epoch 2765/3334\n",
            "Epoch 2765: Training Accuracy = 0.9902, Training Loss = 0.1595, Validation Accuracy = 0.9876, Validation Loss = 0.2209\n",
            "Epoch 2766/3334\n",
            "Epoch 2766: Training Accuracy = 0.9883, Training Loss = 0.1084, Validation Accuracy = 0.9894, Validation Loss = 0.1556\n",
            "Epoch 2767/3334\n",
            "Epoch 2767: Training Accuracy = 0.9961, Training Loss = 0.0622, Validation Accuracy = 0.9897, Validation Loss = 0.1264\n",
            "Epoch 2768/3334\n",
            "Epoch 2768: Training Accuracy = 0.9961, Training Loss = 0.0622, Validation Accuracy = 0.9897, Validation Loss = 0.1264\n",
            "Epoch 2769/3334\n",
            "Epoch 2769: Training Accuracy = 0.9863, Training Loss = 0.0841, Validation Accuracy = 0.9897, Validation Loss = 0.1129\n",
            "Epoch 2770/3334\n",
            "Epoch 2770: Training Accuracy = 0.9863, Training Loss = 0.0841, Validation Accuracy = 0.9897, Validation Loss = 0.1129\n",
            "Epoch 2771/3334\n",
            "Epoch 2771: Training Accuracy = 0.9844, Training Loss = 0.0857, Validation Accuracy = 0.9897, Validation Loss = 0.1073\n",
            "Epoch 2772/3334\n",
            "Epoch 2772: Training Accuracy = 0.9922, Training Loss = 0.0568, Validation Accuracy = 0.9897, Validation Loss = 0.1044\n",
            "Epoch 2773/3334\n",
            "Epoch 2773: Training Accuracy = 0.9922, Training Loss = 0.0568, Validation Accuracy = 0.9897, Validation Loss = 0.1044\n",
            "Epoch 2774/3334\n",
            "Epoch 2774: Training Accuracy = 0.9902, Training Loss = 0.0631, Validation Accuracy = 0.9897, Validation Loss = 0.1021\n",
            "Epoch 2775/3334\n",
            "Epoch 2775: Training Accuracy = 0.9902, Training Loss = 0.0631, Validation Accuracy = 0.9897, Validation Loss = 0.1021\n",
            "Epoch 2776/3334\n",
            "Epoch 2776: Training Accuracy = 0.9863, Training Loss = 0.0741, Validation Accuracy = 0.9897, Validation Loss = 0.1023\n",
            "Epoch 2777/3334\n",
            "Epoch 2777: Training Accuracy = 0.9883, Training Loss = 0.0693, Validation Accuracy = 0.9897, Validation Loss = 0.1017\n",
            "Epoch 2778/3334\n",
            "Epoch 2778: Training Accuracy = 0.9883, Training Loss = 0.0693, Validation Accuracy = 0.9897, Validation Loss = 0.1017\n",
            "Epoch 2779/3334\n",
            "Epoch 2779: Training Accuracy = 0.9844, Training Loss = 0.0818, Validation Accuracy = 0.9897, Validation Loss = 0.1016\n",
            "Epoch 2780/3334\n",
            "Epoch 2780: Training Accuracy = 0.9844, Training Loss = 0.0818, Validation Accuracy = 0.9897, Validation Loss = 0.1016\n",
            "Epoch 2781/3334\n",
            "Epoch 2781: Training Accuracy = 0.9863, Training Loss = 0.0746, Validation Accuracy = 0.9897, Validation Loss = 0.1007\n",
            "Epoch 2782/3334\n",
            "Epoch 2782: Training Accuracy = 0.9941, Training Loss = 0.0493, Validation Accuracy = 0.9897, Validation Loss = 0.1013\n",
            "Epoch 2783/3334\n",
            "Epoch 2783: Training Accuracy = 0.9941, Training Loss = 0.0493, Validation Accuracy = 0.9897, Validation Loss = 0.1013\n",
            "Epoch 2784/3334\n",
            "Epoch 2784: Training Accuracy = 0.9883, Training Loss = 0.0689, Validation Accuracy = 0.9897, Validation Loss = 0.1037\n",
            "Epoch 2785/3334\n",
            "Epoch 2785: Training Accuracy = 0.9883, Training Loss = 0.0689, Validation Accuracy = 0.9897, Validation Loss = 0.1037\n",
            "Epoch 2786/3334\n",
            "Epoch 2786: Training Accuracy = 0.9883, Training Loss = 0.0699, Validation Accuracy = 0.9897, Validation Loss = 0.1010\n",
            "Epoch 2787/3334\n",
            "Epoch 2787: Training Accuracy = 0.9941, Training Loss = 0.0473, Validation Accuracy = 0.9897, Validation Loss = 0.0989\n",
            "Epoch 2788/3334\n",
            "Epoch 2788: Training Accuracy = 0.9941, Training Loss = 0.0473, Validation Accuracy = 0.9897, Validation Loss = 0.0989\n",
            "Epoch 2789/3334\n",
            "Epoch 2789: Training Accuracy = 0.9844, Training Loss = 0.0826, Validation Accuracy = 0.9897, Validation Loss = 0.0994\n",
            "Epoch 2790/3334\n",
            "Epoch 2790: Training Accuracy = 0.9844, Training Loss = 0.0826, Validation Accuracy = 0.9897, Validation Loss = 0.0994\n",
            "Epoch 2791/3334\n",
            "Epoch 2791: Training Accuracy = 0.9941, Training Loss = 0.0457, Validation Accuracy = 0.9897, Validation Loss = 0.1022\n",
            "Epoch 2792/3334\n",
            "Epoch 2792: Training Accuracy = 0.9883, Training Loss = 0.0659, Validation Accuracy = 0.9897, Validation Loss = 0.1008\n",
            "Epoch 2793/3334\n",
            "Epoch 2793: Training Accuracy = 0.9883, Training Loss = 0.0659, Validation Accuracy = 0.9897, Validation Loss = 0.1008\n",
            "Epoch 2794/3334\n",
            "Epoch 2794: Training Accuracy = 0.9941, Training Loss = 0.0609, Validation Accuracy = 0.9897, Validation Loss = 0.1097\n",
            "Epoch 2795/3334\n",
            "Epoch 2795: Training Accuracy = 0.9941, Training Loss = 0.0609, Validation Accuracy = 0.9897, Validation Loss = 0.1097\n",
            "Epoch 2796/3334\n",
            "Epoch 2796: Training Accuracy = 0.4395, Training Loss = 2.2797, Validation Accuracy = 0.2751, Validation Loss = 2.9288\n",
            "Epoch 2797/3334\n",
            "Epoch 2797: Training Accuracy = 0.8047, Training Loss = 0.9138, Validation Accuracy = 0.8224, Validation Loss = 0.9107\n",
            "Epoch 2798/3334\n",
            "Epoch 2798: Training Accuracy = 0.8047, Training Loss = 0.9138, Validation Accuracy = 0.8224, Validation Loss = 0.9107\n",
            "Epoch 2799/3334\n",
            "Epoch 2799: Training Accuracy = 0.9531, Training Loss = 0.3446, Validation Accuracy = 0.9493, Validation Loss = 0.4121\n",
            "Epoch 2800/3334\n",
            "Epoch 2800: Training Accuracy = 0.9531, Training Loss = 0.3446, Validation Accuracy = 0.9493, Validation Loss = 0.4121\n",
            "Epoch 2801/3334\n",
            "Epoch 2801: Training Accuracy = 0.9941, Training Loss = 0.1445, Validation Accuracy = 0.9866, Validation Loss = 0.2159\n",
            "Epoch 2802/3334\n",
            "Epoch 2802: Training Accuracy = 0.9961, Training Loss = 0.0865, Validation Accuracy = 0.9894, Validation Loss = 0.1483\n",
            "Epoch 2803/3334\n",
            "Epoch 2803: Training Accuracy = 0.9961, Training Loss = 0.0865, Validation Accuracy = 0.9894, Validation Loss = 0.1483\n",
            "Epoch 2804/3334\n",
            "Epoch 2804: Training Accuracy = 0.9883, Training Loss = 0.0848, Validation Accuracy = 0.9897, Validation Loss = 0.1221\n",
            "Epoch 2805/3334\n",
            "Epoch 2805: Training Accuracy = 0.9883, Training Loss = 0.0848, Validation Accuracy = 0.9897, Validation Loss = 0.1221\n",
            "Epoch 2806/3334\n",
            "Epoch 2806: Training Accuracy = 0.9922, Training Loss = 0.0622, Validation Accuracy = 0.9897, Validation Loss = 0.1112\n",
            "Epoch 2807/3334\n",
            "Epoch 2807: Training Accuracy = 0.9941, Training Loss = 0.0525, Validation Accuracy = 0.9897, Validation Loss = 0.1069\n",
            "Epoch 2808/3334\n",
            "Epoch 2808: Training Accuracy = 0.9941, Training Loss = 0.0525, Validation Accuracy = 0.9897, Validation Loss = 0.1069\n",
            "Epoch 2809/3334\n",
            "Epoch 2809: Training Accuracy = 0.9863, Training Loss = 0.0783, Validation Accuracy = 0.9897, Validation Loss = 0.1039\n",
            "Epoch 2810/3334\n",
            "Epoch 2810: Training Accuracy = 0.9863, Training Loss = 0.0783, Validation Accuracy = 0.9897, Validation Loss = 0.1039\n",
            "Epoch 2811/3334\n",
            "Epoch 2811: Training Accuracy = 0.9902, Training Loss = 0.0630, Validation Accuracy = 0.9897, Validation Loss = 0.1032\n",
            "Epoch 2812/3334\n",
            "Epoch 2812: Training Accuracy = 0.9961, Training Loss = 0.0432, Validation Accuracy = 0.9897, Validation Loss = 0.1037\n",
            "Epoch 2813/3334\n",
            "Epoch 2813: Training Accuracy = 0.9961, Training Loss = 0.0432, Validation Accuracy = 0.9897, Validation Loss = 0.1037\n",
            "Epoch 2814/3334\n",
            "Epoch 2814: Training Accuracy = 0.9941, Training Loss = 0.0481, Validation Accuracy = 0.9897, Validation Loss = 0.1034\n",
            "Epoch 2815/3334\n",
            "Epoch 2815: Training Accuracy = 0.9941, Training Loss = 0.0481, Validation Accuracy = 0.9897, Validation Loss = 0.1034\n",
            "Epoch 2816/3334\n",
            "Epoch 2816: Training Accuracy = 0.9941, Training Loss = 0.0484, Validation Accuracy = 0.9897, Validation Loss = 0.1033\n",
            "Epoch 2817/3334\n",
            "Epoch 2817: Training Accuracy = 0.9902, Training Loss = 0.0627, Validation Accuracy = 0.9897, Validation Loss = 0.1025\n",
            "Epoch 2818/3334\n",
            "Epoch 2818: Training Accuracy = 0.9902, Training Loss = 0.0627, Validation Accuracy = 0.9897, Validation Loss = 0.1025\n",
            "Epoch 2819/3334\n",
            "Epoch 2819: Training Accuracy = 0.9941, Training Loss = 0.0479, Validation Accuracy = 0.9897, Validation Loss = 0.1033\n",
            "Epoch 2820/3334\n",
            "Epoch 2820: Training Accuracy = 0.9941, Training Loss = 0.0479, Validation Accuracy = 0.9897, Validation Loss = 0.1033\n",
            "Epoch 2821/3334\n",
            "Epoch 2821: Training Accuracy = 0.9941, Training Loss = 0.0502, Validation Accuracy = 0.9897, Validation Loss = 0.1020\n",
            "Epoch 2822/3334\n",
            "Epoch 2822: Training Accuracy = 0.9941, Training Loss = 0.0498, Validation Accuracy = 0.9897, Validation Loss = 0.1000\n",
            "Epoch 2823/3334\n",
            "Epoch 2823: Training Accuracy = 0.9941, Training Loss = 0.0498, Validation Accuracy = 0.9897, Validation Loss = 0.1000\n",
            "Epoch 2824/3334\n",
            "Epoch 2824: Training Accuracy = 0.9941, Training Loss = 0.0470, Validation Accuracy = 0.9897, Validation Loss = 0.1041\n",
            "Epoch 2825/3334\n",
            "Epoch 2825: Training Accuracy = 0.9941, Training Loss = 0.0470, Validation Accuracy = 0.9897, Validation Loss = 0.1041\n",
            "Epoch 2826/3334\n",
            "Epoch 2826: Training Accuracy = 0.9961, Training Loss = 0.0427, Validation Accuracy = 0.9897, Validation Loss = 0.1012\n",
            "Epoch 2827/3334\n",
            "Epoch 2827: Training Accuracy = 0.9941, Training Loss = 0.0579, Validation Accuracy = 0.9897, Validation Loss = 0.1154\n",
            "Epoch 2828/3334\n",
            "Epoch 2828: Training Accuracy = 0.9941, Training Loss = 0.0579, Validation Accuracy = 0.9897, Validation Loss = 0.1154\n",
            "Epoch 2829/3334\n",
            "Epoch 2829: Training Accuracy = 0.7891, Training Loss = 1.2058, Validation Accuracy = 0.7875, Validation Loss = 1.1948\n",
            "Epoch 2830/3334\n",
            "Epoch 2830: Training Accuracy = 0.7891, Training Loss = 1.2058, Validation Accuracy = 0.7875, Validation Loss = 1.1948\n",
            "Epoch 2831/3334\n",
            "Epoch 2831: Training Accuracy = 0.9805, Training Loss = 0.3394, Validation Accuracy = 0.9643, Validation Loss = 0.4276\n",
            "Epoch 2832/3334\n",
            "Epoch 2832: Training Accuracy = 0.9883, Training Loss = 0.1696, Validation Accuracy = 0.9883, Validation Loss = 0.2274\n",
            "Epoch 2833/3334\n",
            "Epoch 2833: Training Accuracy = 0.9883, Training Loss = 0.1696, Validation Accuracy = 0.9883, Validation Loss = 0.2274\n",
            "Epoch 2834/3334\n",
            "Epoch 2834: Training Accuracy = 0.9941, Training Loss = 0.0891, Validation Accuracy = 0.9897, Validation Loss = 0.1460\n",
            "Epoch 2835/3334\n",
            "Epoch 2835: Training Accuracy = 0.9941, Training Loss = 0.0891, Validation Accuracy = 0.9897, Validation Loss = 0.1460\n",
            "Epoch 2836/3334\n",
            "Epoch 2836: Training Accuracy = 0.9922, Training Loss = 0.0707, Validation Accuracy = 0.9897, Validation Loss = 0.1240\n",
            "Epoch 2837/3334\n",
            "Epoch 2837: Training Accuracy = 0.9883, Training Loss = 0.0762, Validation Accuracy = 0.9897, Validation Loss = 0.1126\n",
            "Epoch 2838/3334\n",
            "Epoch 2838: Training Accuracy = 0.9883, Training Loss = 0.0762, Validation Accuracy = 0.9897, Validation Loss = 0.1126\n",
            "Epoch 2839/3334\n",
            "Epoch 2839: Training Accuracy = 0.9844, Training Loss = 0.0837, Validation Accuracy = 0.9897, Validation Loss = 0.1053\n",
            "Epoch 2840/3334\n",
            "Epoch 2840: Training Accuracy = 0.9844, Training Loss = 0.0837, Validation Accuracy = 0.9897, Validation Loss = 0.1053\n",
            "Epoch 2841/3334\n",
            "Epoch 2841: Training Accuracy = 0.9922, Training Loss = 0.0565, Validation Accuracy = 0.9897, Validation Loss = 0.1032\n",
            "Epoch 2842/3334\n",
            "Epoch 2842: Training Accuracy = 0.9922, Training Loss = 0.0559, Validation Accuracy = 0.9897, Validation Loss = 0.1019\n",
            "Epoch 2843/3334\n",
            "Epoch 2843: Training Accuracy = 0.9922, Training Loss = 0.0559, Validation Accuracy = 0.9897, Validation Loss = 0.1019\n",
            "Epoch 2844/3334\n",
            "Epoch 2844: Training Accuracy = 0.9902, Training Loss = 0.0623, Validation Accuracy = 0.9897, Validation Loss = 0.1011\n",
            "Epoch 2845/3334\n",
            "Epoch 2845: Training Accuracy = 0.9902, Training Loss = 0.0623, Validation Accuracy = 0.9897, Validation Loss = 0.1011\n",
            "Epoch 2846/3334\n",
            "Epoch 2846: Training Accuracy = 0.9902, Training Loss = 0.0622, Validation Accuracy = 0.9897, Validation Loss = 0.1004\n",
            "Epoch 2847/3334\n",
            "Epoch 2847: Training Accuracy = 0.9922, Training Loss = 0.0549, Validation Accuracy = 0.9897, Validation Loss = 0.1006\n",
            "Epoch 2848/3334\n",
            "Epoch 2848: Training Accuracy = 0.9922, Training Loss = 0.0549, Validation Accuracy = 0.9897, Validation Loss = 0.1006\n",
            "Epoch 2849/3334\n",
            "Epoch 2849: Training Accuracy = 0.9902, Training Loss = 0.0623, Validation Accuracy = 0.9897, Validation Loss = 0.1008\n",
            "Epoch 2850/3334\n",
            "Epoch 2850: Training Accuracy = 0.9902, Training Loss = 0.0623, Validation Accuracy = 0.9897, Validation Loss = 0.1008\n",
            "Epoch 2851/3334\n",
            "Epoch 2851: Training Accuracy = 0.9922, Training Loss = 0.0551, Validation Accuracy = 0.9897, Validation Loss = 0.1002\n",
            "Epoch 2852/3334\n",
            "Epoch 2852: Training Accuracy = 0.9922, Training Loss = 0.0555, Validation Accuracy = 0.9897, Validation Loss = 0.1007\n",
            "Epoch 2853/3334\n",
            "Epoch 2853: Training Accuracy = 0.9922, Training Loss = 0.0555, Validation Accuracy = 0.9897, Validation Loss = 0.1007\n",
            "Epoch 2854/3334\n",
            "Epoch 2854: Training Accuracy = 0.9844, Training Loss = 0.0787, Validation Accuracy = 0.9897, Validation Loss = 0.1004\n",
            "Epoch 2855/3334\n",
            "Epoch 2855: Training Accuracy = 0.9844, Training Loss = 0.0787, Validation Accuracy = 0.9897, Validation Loss = 0.1004\n",
            "Epoch 2856/3334\n",
            "Epoch 2856: Training Accuracy = 0.9941, Training Loss = 0.0521, Validation Accuracy = 0.9897, Validation Loss = 0.0993\n",
            "Epoch 2857/3334\n",
            "Epoch 2857: Training Accuracy = 0.9805, Training Loss = 0.0956, Validation Accuracy = 0.9897, Validation Loss = 0.0995\n",
            "Epoch 2858/3334\n",
            "Epoch 2858: Training Accuracy = 0.9805, Training Loss = 0.0956, Validation Accuracy = 0.9897, Validation Loss = 0.0995\n",
            "Epoch 2859/3334\n",
            "Epoch 2859: Training Accuracy = 0.9844, Training Loss = 0.0813, Validation Accuracy = 0.9897, Validation Loss = 0.1007\n",
            "Epoch 2860/3334\n",
            "Epoch 2860: Training Accuracy = 0.9844, Training Loss = 0.0813, Validation Accuracy = 0.9897, Validation Loss = 0.1007\n",
            "Epoch 2861/3334\n",
            "Epoch 2861: Training Accuracy = 0.9941, Training Loss = 0.0542, Validation Accuracy = 0.9897, Validation Loss = 0.1087\n",
            "Epoch 2862/3334\n",
            "Epoch 2862: Training Accuracy = 0.9941, Training Loss = 0.0503, Validation Accuracy = 0.9897, Validation Loss = 0.1046\n",
            "Epoch 2863/3334\n",
            "Epoch 2863: Training Accuracy = 0.9941, Training Loss = 0.0503, Validation Accuracy = 0.9897, Validation Loss = 0.1046\n",
            "Epoch 2864/3334\n",
            "Epoch 2864: Training Accuracy = 0.8516, Training Loss = 0.9401, Validation Accuracy = 0.7991, Validation Loss = 1.0965\n",
            "Epoch 2865/3334\n",
            "Epoch 2865: Training Accuracy = 0.8516, Training Loss = 0.9401, Validation Accuracy = 0.7991, Validation Loss = 1.0965\n",
            "Epoch 2866/3334\n",
            "Epoch 2866: Training Accuracy = 0.9668, Training Loss = 0.3996, Validation Accuracy = 0.9535, Validation Loss = 0.4785\n",
            "Epoch 2867/3334\n",
            "Epoch 2867: Training Accuracy = 0.9883, Training Loss = 0.1800, Validation Accuracy = 0.9853, Validation Loss = 0.2539\n",
            "Epoch 2868/3334\n",
            "Epoch 2868: Training Accuracy = 0.9883, Training Loss = 0.1800, Validation Accuracy = 0.9853, Validation Loss = 0.2539\n",
            "Epoch 2869/3334\n",
            "Epoch 2869: Training Accuracy = 0.9863, Training Loss = 0.1342, Validation Accuracy = 0.9892, Validation Loss = 0.1687\n",
            "Epoch 2870/3334\n",
            "Epoch 2870: Training Accuracy = 0.9863, Training Loss = 0.1342, Validation Accuracy = 0.9892, Validation Loss = 0.1687\n",
            "Epoch 2871/3334\n",
            "Epoch 2871: Training Accuracy = 0.9922, Training Loss = 0.0813, Validation Accuracy = 0.9897, Validation Loss = 0.1331\n",
            "Epoch 2872/3334\n",
            "Epoch 2872: Training Accuracy = 0.9863, Training Loss = 0.0957, Validation Accuracy = 0.9897, Validation Loss = 0.1170\n",
            "Epoch 2873/3334\n",
            "Epoch 2873: Training Accuracy = 0.9863, Training Loss = 0.0957, Validation Accuracy = 0.9897, Validation Loss = 0.1170\n",
            "Epoch 2874/3334\n",
            "Epoch 2874: Training Accuracy = 0.9844, Training Loss = 0.0916, Validation Accuracy = 0.9897, Validation Loss = 0.1105\n",
            "Epoch 2875/3334\n",
            "Epoch 2875: Training Accuracy = 0.9844, Training Loss = 0.0916, Validation Accuracy = 0.9897, Validation Loss = 0.1105\n",
            "Epoch 2876/3334\n",
            "Epoch 2876: Training Accuracy = 0.9844, Training Loss = 0.0858, Validation Accuracy = 0.9897, Validation Loss = 0.1073\n",
            "Epoch 2877/3334\n",
            "Epoch 2877: Training Accuracy = 0.9883, Training Loss = 0.0717, Validation Accuracy = 0.9897, Validation Loss = 0.1057\n",
            "Epoch 2878/3334\n",
            "Epoch 2878: Training Accuracy = 0.9883, Training Loss = 0.0717, Validation Accuracy = 0.9897, Validation Loss = 0.1057\n",
            "Epoch 2879/3334\n",
            "Epoch 2879: Training Accuracy = 0.9902, Training Loss = 0.0708, Validation Accuracy = 0.9897, Validation Loss = 0.1057\n",
            "Epoch 2880/3334\n",
            "Epoch 2880: Training Accuracy = 0.9902, Training Loss = 0.0708, Validation Accuracy = 0.9897, Validation Loss = 0.1057\n",
            "Epoch 2881/3334\n",
            "Epoch 2881: Training Accuracy = 0.9883, Training Loss = 0.0706, Validation Accuracy = 0.9897, Validation Loss = 0.1029\n",
            "Epoch 2882/3334\n",
            "Epoch 2882: Training Accuracy = 0.9902, Training Loss = 0.0680, Validation Accuracy = 0.9897, Validation Loss = 0.1017\n",
            "Epoch 2883/3334\n",
            "Epoch 2883: Training Accuracy = 0.9902, Training Loss = 0.0680, Validation Accuracy = 0.9897, Validation Loss = 0.1017\n",
            "Epoch 2884/3334\n",
            "Epoch 2884: Training Accuracy = 0.9941, Training Loss = 0.0484, Validation Accuracy = 0.9897, Validation Loss = 0.1009\n",
            "Epoch 2885/3334\n",
            "Epoch 2885: Training Accuracy = 0.9941, Training Loss = 0.0484, Validation Accuracy = 0.9897, Validation Loss = 0.1009\n",
            "Epoch 2886/3334\n",
            "Epoch 2886: Training Accuracy = 0.9941, Training Loss = 0.0488, Validation Accuracy = 0.9897, Validation Loss = 0.1020\n",
            "Epoch 2887/3334\n",
            "Epoch 2887: Training Accuracy = 0.9883, Training Loss = 0.0683, Validation Accuracy = 0.9897, Validation Loss = 0.1006\n",
            "Epoch 2888/3334\n",
            "Epoch 2888: Training Accuracy = 0.9883, Training Loss = 0.0683, Validation Accuracy = 0.9897, Validation Loss = 0.1006\n",
            "Epoch 2889/3334\n",
            "Epoch 2889: Training Accuracy = 0.9961, Training Loss = 0.0417, Validation Accuracy = 0.9897, Validation Loss = 0.1003\n",
            "Epoch 2890/3334\n",
            "Epoch 2890: Training Accuracy = 0.9961, Training Loss = 0.0417, Validation Accuracy = 0.9897, Validation Loss = 0.1003\n",
            "Epoch 2891/3334\n",
            "Epoch 2891: Training Accuracy = 0.9922, Training Loss = 0.0561, Validation Accuracy = 0.9897, Validation Loss = 0.1006\n",
            "Epoch 2892/3334\n",
            "Epoch 2892: Training Accuracy = 0.9980, Training Loss = 0.0361, Validation Accuracy = 0.9897, Validation Loss = 0.1008\n",
            "Epoch 2893/3334\n",
            "Epoch 2893: Training Accuracy = 0.9980, Training Loss = 0.0361, Validation Accuracy = 0.9897, Validation Loss = 0.1008\n",
            "Epoch 2894/3334\n",
            "Epoch 2894: Training Accuracy = 0.9922, Training Loss = 0.0560, Validation Accuracy = 0.9897, Validation Loss = 0.1007\n",
            "Epoch 2895/3334\n",
            "Epoch 2895: Training Accuracy = 0.9922, Training Loss = 0.0560, Validation Accuracy = 0.9897, Validation Loss = 0.1007\n",
            "Epoch 2896/3334\n",
            "Epoch 2896: Training Accuracy = 0.9902, Training Loss = 0.0642, Validation Accuracy = 0.9897, Validation Loss = 0.1028\n",
            "Epoch 2897/3334\n",
            "Epoch 2897: Training Accuracy = 0.9961, Training Loss = 0.0476, Validation Accuracy = 0.9897, Validation Loss = 0.1006\n",
            "Epoch 2898/3334\n",
            "Epoch 2898: Training Accuracy = 0.9961, Training Loss = 0.0476, Validation Accuracy = 0.9897, Validation Loss = 0.1006\n",
            "Epoch 2899/3334\n",
            "Epoch 2899: Training Accuracy = 0.9863, Training Loss = 0.0802, Validation Accuracy = 0.9897, Validation Loss = 0.1026\n",
            "Epoch 2900/3334\n",
            "Epoch 2900: Training Accuracy = 0.9863, Training Loss = 0.0802, Validation Accuracy = 0.9897, Validation Loss = 0.1026\n",
            "Epoch 2901/3334\n",
            "Epoch 2901: Training Accuracy = 0.3574, Training Loss = 2.4131, Validation Accuracy = 0.4532, Validation Loss = 2.2753\n",
            "Epoch 2902/3334\n",
            "Epoch 2902: Training Accuracy = 0.9102, Training Loss = 0.7010, Validation Accuracy = 0.9144, Validation Loss = 0.7035\n",
            "Epoch 2903/3334\n",
            "Epoch 2903: Training Accuracy = 0.9102, Training Loss = 0.7010, Validation Accuracy = 0.9144, Validation Loss = 0.7035\n",
            "Epoch 2904/3334\n",
            "Epoch 2904: Training Accuracy = 0.9824, Training Loss = 0.2615, Validation Accuracy = 0.9750, Validation Loss = 0.3479\n",
            "Epoch 2905/3334\n",
            "Epoch 2905: Training Accuracy = 0.9824, Training Loss = 0.2615, Validation Accuracy = 0.9750, Validation Loss = 0.3479\n",
            "Epoch 2906/3334\n",
            "Epoch 2906: Training Accuracy = 0.9922, Training Loss = 0.1265, Validation Accuracy = 0.9889, Validation Loss = 0.1940\n",
            "Epoch 2907/3334\n",
            "Epoch 2907: Training Accuracy = 0.9941, Training Loss = 0.0829, Validation Accuracy = 0.9897, Validation Loss = 0.1396\n",
            "Epoch 2908/3334\n",
            "Epoch 2908: Training Accuracy = 0.9941, Training Loss = 0.0829, Validation Accuracy = 0.9897, Validation Loss = 0.1396\n",
            "Epoch 2909/3334\n",
            "Epoch 2909: Training Accuracy = 0.9863, Training Loss = 0.0910, Validation Accuracy = 0.9897, Validation Loss = 0.1181\n",
            "Epoch 2910/3334\n",
            "Epoch 2910: Training Accuracy = 0.9863, Training Loss = 0.0910, Validation Accuracy = 0.9897, Validation Loss = 0.1181\n",
            "Epoch 2911/3334\n",
            "Epoch 2911: Training Accuracy = 0.9961, Training Loss = 0.0465, Validation Accuracy = 0.9897, Validation Loss = 0.1099\n",
            "Epoch 2912/3334\n",
            "Epoch 2912: Training Accuracy = 0.9941, Training Loss = 0.0506, Validation Accuracy = 0.9897, Validation Loss = 0.1054\n",
            "Epoch 2913/3334\n",
            "Epoch 2913: Training Accuracy = 0.9941, Training Loss = 0.0506, Validation Accuracy = 0.9897, Validation Loss = 0.1054\n",
            "Epoch 2914/3334\n",
            "Epoch 2914: Training Accuracy = 0.9922, Training Loss = 0.0595, Validation Accuracy = 0.9897, Validation Loss = 0.1039\n",
            "Epoch 2915/3334\n",
            "Epoch 2915: Training Accuracy = 0.9922, Training Loss = 0.0595, Validation Accuracy = 0.9897, Validation Loss = 0.1039\n",
            "Epoch 2916/3334\n",
            "Epoch 2916: Training Accuracy = 0.9863, Training Loss = 0.0759, Validation Accuracy = 0.9897, Validation Loss = 0.1037\n",
            "Epoch 2917/3334\n",
            "Epoch 2917: Training Accuracy = 0.9844, Training Loss = 0.0873, Validation Accuracy = 0.9897, Validation Loss = 0.1028\n",
            "Epoch 2918/3334\n",
            "Epoch 2918: Training Accuracy = 0.9844, Training Loss = 0.0873, Validation Accuracy = 0.9897, Validation Loss = 0.1028\n",
            "Epoch 2919/3334\n",
            "Epoch 2919: Training Accuracy = 0.9824, Training Loss = 0.0895, Validation Accuracy = 0.9897, Validation Loss = 0.1019\n",
            "Epoch 2920/3334\n",
            "Epoch 2920: Training Accuracy = 0.9824, Training Loss = 0.0895, Validation Accuracy = 0.9897, Validation Loss = 0.1019\n",
            "Epoch 2921/3334\n",
            "Epoch 2921: Training Accuracy = 0.9902, Training Loss = 0.0613, Validation Accuracy = 0.9897, Validation Loss = 0.1006\n",
            "Epoch 2922/3334\n",
            "Epoch 2922: Training Accuracy = 0.9863, Training Loss = 0.0738, Validation Accuracy = 0.9897, Validation Loss = 0.0991\n",
            "Epoch 2923/3334\n",
            "Epoch 2923: Training Accuracy = 0.9863, Training Loss = 0.0738, Validation Accuracy = 0.9897, Validation Loss = 0.0991\n",
            "Epoch 2924/3334\n",
            "Epoch 2924: Training Accuracy = 0.9844, Training Loss = 0.0794, Validation Accuracy = 0.9897, Validation Loss = 0.0988\n",
            "Epoch 2925/3334\n",
            "Epoch 2925: Training Accuracy = 0.9844, Training Loss = 0.0794, Validation Accuracy = 0.9897, Validation Loss = 0.0988\n",
            "Epoch 2926/3334\n",
            "Epoch 2926: Training Accuracy = 0.9922, Training Loss = 0.0541, Validation Accuracy = 0.9897, Validation Loss = 0.0995\n",
            "Epoch 2927/3334\n",
            "Epoch 2927: Training Accuracy = 0.9844, Training Loss = 0.0827, Validation Accuracy = 0.9897, Validation Loss = 0.0978\n",
            "Epoch 2928/3334\n",
            "Epoch 2928: Training Accuracy = 0.9844, Training Loss = 0.0827, Validation Accuracy = 0.9897, Validation Loss = 0.0978\n",
            "Epoch 2929/3334\n",
            "Epoch 2929: Training Accuracy = 0.9883, Training Loss = 0.0731, Validation Accuracy = 0.9897, Validation Loss = 0.1004\n",
            "Epoch 2930/3334\n",
            "Epoch 2930: Training Accuracy = 0.9883, Training Loss = 0.0731, Validation Accuracy = 0.9897, Validation Loss = 0.1004\n",
            "Epoch 2931/3334\n",
            "Epoch 2931: Training Accuracy = 0.9863, Training Loss = 0.0779, Validation Accuracy = 0.9897, Validation Loss = 0.1075\n",
            "Epoch 2932/3334\n",
            "Epoch 2932: Training Accuracy = 0.6406, Training Loss = 1.5131, Validation Accuracy = 0.6334, Validation Loss = 1.5957\n",
            "Epoch 2933/3334\n",
            "Epoch 2933: Training Accuracy = 0.6406, Training Loss = 1.5131, Validation Accuracy = 0.6334, Validation Loss = 1.5957\n",
            "Epoch 2934/3334\n",
            "Epoch 2934: Training Accuracy = 0.9023, Training Loss = 0.5548, Validation Accuracy = 0.9320, Validation Loss = 0.6007\n",
            "Epoch 2935/3334\n",
            "Epoch 2935: Training Accuracy = 0.9023, Training Loss = 0.5548, Validation Accuracy = 0.9320, Validation Loss = 0.6007\n",
            "Epoch 2936/3334\n",
            "Epoch 2936: Training Accuracy = 0.9844, Training Loss = 0.2119, Validation Accuracy = 0.9769, Validation Loss = 0.3066\n",
            "Epoch 2937/3334\n",
            "Epoch 2937: Training Accuracy = 0.9941, Training Loss = 0.1163, Validation Accuracy = 0.9895, Validation Loss = 0.1864\n",
            "Epoch 2938/3334\n",
            "Epoch 2938: Training Accuracy = 0.9941, Training Loss = 0.1163, Validation Accuracy = 0.9895, Validation Loss = 0.1864\n",
            "Epoch 2939/3334\n",
            "Epoch 2939: Training Accuracy = 0.9941, Training Loss = 0.0783, Validation Accuracy = 0.9895, Validation Loss = 0.1398\n",
            "Epoch 2940/3334\n",
            "Epoch 2940: Training Accuracy = 0.9941, Training Loss = 0.0783, Validation Accuracy = 0.9895, Validation Loss = 0.1398\n",
            "Epoch 2941/3334\n",
            "Epoch 2941: Training Accuracy = 0.9922, Training Loss = 0.0715, Validation Accuracy = 0.9897, Validation Loss = 0.1214\n",
            "Epoch 2942/3334\n",
            "Epoch 2942: Training Accuracy = 0.9902, Training Loss = 0.0799, Validation Accuracy = 0.9897, Validation Loss = 0.1146\n",
            "Epoch 2943/3334\n",
            "Epoch 2943: Training Accuracy = 0.9902, Training Loss = 0.0799, Validation Accuracy = 0.9897, Validation Loss = 0.1146\n",
            "Epoch 2944/3334\n",
            "Epoch 2944: Training Accuracy = 0.9941, Training Loss = 0.0567, Validation Accuracy = 0.9897, Validation Loss = 0.1119\n",
            "Epoch 2945/3334\n",
            "Epoch 2945: Training Accuracy = 0.9941, Training Loss = 0.0567, Validation Accuracy = 0.9897, Validation Loss = 0.1119\n",
            "Epoch 2946/3334\n",
            "Epoch 2946: Training Accuracy = 0.9883, Training Loss = 0.0742, Validation Accuracy = 0.9897, Validation Loss = 0.1090\n",
            "Epoch 2947/3334\n",
            "Epoch 2947: Training Accuracy = 0.9805, Training Loss = 0.1037, Validation Accuracy = 0.9897, Validation Loss = 0.1081\n",
            "Epoch 2948/3334\n",
            "Epoch 2948: Training Accuracy = 0.9805, Training Loss = 0.1037, Validation Accuracy = 0.9897, Validation Loss = 0.1081\n",
            "Epoch 2949/3334\n",
            "Epoch 2949: Training Accuracy = 0.9785, Training Loss = 0.1069, Validation Accuracy = 0.9897, Validation Loss = 0.1058\n",
            "Epoch 2950/3334\n",
            "Epoch 2950: Training Accuracy = 0.9785, Training Loss = 0.1069, Validation Accuracy = 0.9897, Validation Loss = 0.1058\n",
            "Epoch 2951/3334\n",
            "Epoch 2951: Training Accuracy = 0.9922, Training Loss = 0.0584, Validation Accuracy = 0.9897, Validation Loss = 0.1047\n",
            "Epoch 2952/3334\n",
            "Epoch 2952: Training Accuracy = 0.9941, Training Loss = 0.0522, Validation Accuracy = 0.9897, Validation Loss = 0.1034\n",
            "Epoch 2953/3334\n",
            "Epoch 2953: Training Accuracy = 0.9941, Training Loss = 0.0522, Validation Accuracy = 0.9897, Validation Loss = 0.1034\n",
            "Epoch 2954/3334\n",
            "Epoch 2954: Training Accuracy = 0.9961, Training Loss = 0.0493, Validation Accuracy = 0.9897, Validation Loss = 0.1017\n",
            "Epoch 2955/3334\n",
            "Epoch 2955: Training Accuracy = 0.9961, Training Loss = 0.0493, Validation Accuracy = 0.9897, Validation Loss = 0.1017\n",
            "Epoch 2956/3334\n",
            "Epoch 2956: Training Accuracy = 0.9902, Training Loss = 0.0617, Validation Accuracy = 0.9897, Validation Loss = 0.1007\n",
            "Epoch 2957/3334\n",
            "Epoch 2957: Training Accuracy = 0.9902, Training Loss = 0.0642, Validation Accuracy = 0.9897, Validation Loss = 0.0997\n",
            "Epoch 2958/3334\n",
            "Epoch 2958: Training Accuracy = 0.9902, Training Loss = 0.0642, Validation Accuracy = 0.9897, Validation Loss = 0.0997\n",
            "Epoch 2959/3334\n",
            "Epoch 2959: Training Accuracy = 0.9863, Training Loss = 0.0744, Validation Accuracy = 0.9897, Validation Loss = 0.1013\n",
            "Epoch 2960/3334\n",
            "Epoch 2960: Training Accuracy = 0.9863, Training Loss = 0.0744, Validation Accuracy = 0.9897, Validation Loss = 0.1013\n",
            "Epoch 2961/3334\n",
            "Epoch 2961: Training Accuracy = 0.9922, Training Loss = 0.0587, Validation Accuracy = 0.9897, Validation Loss = 0.1012\n",
            "Epoch 2962/3334\n",
            "Epoch 2962: Training Accuracy = 0.9863, Training Loss = 0.0841, Validation Accuracy = 0.9897, Validation Loss = 0.1062\n",
            "Epoch 2963/3334\n",
            "Epoch 2963: Training Accuracy = 0.9863, Training Loss = 0.0841, Validation Accuracy = 0.9897, Validation Loss = 0.1062\n",
            "Epoch 2964/3334\n",
            "Epoch 2964: Training Accuracy = 0.3359, Training Loss = 2.7878, Validation Accuracy = 0.3091, Validation Loss = 2.6934\n",
            "Epoch 2965/3334\n",
            "Epoch 2965: Training Accuracy = 0.3359, Training Loss = 2.7878, Validation Accuracy = 0.3091, Validation Loss = 2.6934\n",
            "Epoch 2966/3334\n",
            "Epoch 2966: Training Accuracy = 0.7969, Training Loss = 1.0332, Validation Accuracy = 0.8480, Validation Loss = 0.8882\n",
            "Epoch 2967/3334\n",
            "Epoch 2967: Training Accuracy = 0.9785, Training Loss = 0.3207, Validation Accuracy = 0.9715, Validation Loss = 0.3765\n",
            "Epoch 2968/3334\n",
            "Epoch 2968: Training Accuracy = 0.9785, Training Loss = 0.3207, Validation Accuracy = 0.9715, Validation Loss = 0.3765\n",
            "Epoch 2969/3334\n",
            "Epoch 2969: Training Accuracy = 0.9863, Training Loss = 0.1781, Validation Accuracy = 0.9872, Validation Loss = 0.2142\n",
            "Epoch 2970/3334\n",
            "Epoch 2970: Training Accuracy = 0.9863, Training Loss = 0.1781, Validation Accuracy = 0.9872, Validation Loss = 0.2142\n",
            "Epoch 2971/3334\n",
            "Epoch 2971: Training Accuracy = 0.9980, Training Loss = 0.0769, Validation Accuracy = 0.9894, Validation Loss = 0.1554\n",
            "Epoch 2972/3334\n",
            "Epoch 2972: Training Accuracy = 0.9902, Training Loss = 0.0850, Validation Accuracy = 0.9897, Validation Loss = 0.1297\n",
            "Epoch 2973/3334\n",
            "Epoch 2973: Training Accuracy = 0.9902, Training Loss = 0.0850, Validation Accuracy = 0.9897, Validation Loss = 0.1297\n",
            "Epoch 2974/3334\n",
            "Epoch 2974: Training Accuracy = 0.9902, Training Loss = 0.0723, Validation Accuracy = 0.9897, Validation Loss = 0.1144\n",
            "Epoch 2975/3334\n",
            "Epoch 2975: Training Accuracy = 0.9902, Training Loss = 0.0723, Validation Accuracy = 0.9897, Validation Loss = 0.1144\n",
            "Epoch 2976/3334\n",
            "Epoch 2976: Training Accuracy = 0.9941, Training Loss = 0.0545, Validation Accuracy = 0.9897, Validation Loss = 0.1094\n",
            "Epoch 2977/3334\n",
            "Epoch 2977: Training Accuracy = 0.9941, Training Loss = 0.0520, Validation Accuracy = 0.9897, Validation Loss = 0.1056\n",
            "Epoch 2978/3334\n",
            "Epoch 2978: Training Accuracy = 0.9941, Training Loss = 0.0520, Validation Accuracy = 0.9897, Validation Loss = 0.1056\n",
            "Epoch 2979/3334\n",
            "Epoch 2979: Training Accuracy = 0.9941, Training Loss = 0.0526, Validation Accuracy = 0.9897, Validation Loss = 0.1040\n",
            "Epoch 2980/3334\n",
            "Epoch 2980: Training Accuracy = 0.9941, Training Loss = 0.0526, Validation Accuracy = 0.9897, Validation Loss = 0.1040\n",
            "Epoch 2981/3334\n",
            "Epoch 2981: Training Accuracy = 0.9863, Training Loss = 0.0784, Validation Accuracy = 0.9897, Validation Loss = 0.1041\n",
            "Epoch 2982/3334\n",
            "Epoch 2982: Training Accuracy = 0.9922, Training Loss = 0.0584, Validation Accuracy = 0.9897, Validation Loss = 0.1031\n",
            "Epoch 2983/3334\n",
            "Epoch 2983: Training Accuracy = 0.9922, Training Loss = 0.0584, Validation Accuracy = 0.9897, Validation Loss = 0.1031\n",
            "Epoch 2984/3334\n",
            "Epoch 2984: Training Accuracy = 0.9863, Training Loss = 0.0769, Validation Accuracy = 0.9897, Validation Loss = 0.1020\n",
            "Epoch 2985/3334\n",
            "Epoch 2985: Training Accuracy = 0.9863, Training Loss = 0.0769, Validation Accuracy = 0.9897, Validation Loss = 0.1020\n",
            "Epoch 2986/3334\n",
            "Epoch 2986: Training Accuracy = 0.9863, Training Loss = 0.0759, Validation Accuracy = 0.9897, Validation Loss = 0.1013\n",
            "Epoch 2987/3334\n",
            "Epoch 2987: Training Accuracy = 0.9863, Training Loss = 0.0837, Validation Accuracy = 0.9897, Validation Loss = 0.1007\n",
            "Epoch 2988/3334\n",
            "Epoch 2988: Training Accuracy = 0.9863, Training Loss = 0.0837, Validation Accuracy = 0.9897, Validation Loss = 0.1007\n",
            "Epoch 2989/3334\n",
            "Epoch 2989: Training Accuracy = 0.9922, Training Loss = 0.0568, Validation Accuracy = 0.9897, Validation Loss = 0.1006\n",
            "Epoch 2990/3334\n",
            "Epoch 2990: Training Accuracy = 0.9922, Training Loss = 0.0568, Validation Accuracy = 0.9897, Validation Loss = 0.1006\n",
            "Epoch 2991/3334\n",
            "Epoch 2991: Training Accuracy = 0.9863, Training Loss = 0.0765, Validation Accuracy = 0.9897, Validation Loss = 0.1001\n",
            "Epoch 2992/3334\n",
            "Epoch 2992: Training Accuracy = 0.9961, Training Loss = 0.0425, Validation Accuracy = 0.9897, Validation Loss = 0.1024\n",
            "Epoch 2993/3334\n",
            "Epoch 2993: Training Accuracy = 0.9961, Training Loss = 0.0425, Validation Accuracy = 0.9897, Validation Loss = 0.1024\n",
            "Epoch 2994/3334\n",
            "Epoch 2994: Training Accuracy = 0.9844, Training Loss = 0.0868, Validation Accuracy = 0.9897, Validation Loss = 0.1025\n",
            "Epoch 2995/3334\n",
            "Epoch 2995: Training Accuracy = 0.9844, Training Loss = 0.0868, Validation Accuracy = 0.9897, Validation Loss = 0.1025\n",
            "Epoch 2996/3334\n",
            "Epoch 2996: Training Accuracy = 0.9941, Training Loss = 0.0538, Validation Accuracy = 0.9897, Validation Loss = 0.1028\n",
            "Epoch 2997/3334\n",
            "Epoch 2997: Training Accuracy = 0.9883, Training Loss = 0.0732, Validation Accuracy = 0.9897, Validation Loss = 0.1070\n",
            "Epoch 2998/3334\n",
            "Epoch 2998: Training Accuracy = 0.9883, Training Loss = 0.0732, Validation Accuracy = 0.9897, Validation Loss = 0.1070\n",
            "Epoch 2999/3334\n",
            "Epoch 2999: Training Accuracy = 0.9863, Training Loss = 0.0766, Validation Accuracy = 0.9897, Validation Loss = 0.1000\n",
            "Epoch 3000/3334\n",
            "Epoch 3000: Training Accuracy = 0.9863, Training Loss = 0.0766, Validation Accuracy = 0.9897, Validation Loss = 0.1000\n",
            "Epoch 3001/3334\n",
            "Epoch 3001: Training Accuracy = 0.9922, Training Loss = 0.0637, Validation Accuracy = 0.9892, Validation Loss = 0.1265\n",
            "Epoch 3002/3334\n",
            "Epoch 3002: Training Accuracy = 0.6484, Training Loss = 1.4013, Validation Accuracy = 0.6839, Validation Loss = 1.4420\n",
            "Epoch 3003/3334\n",
            "Epoch 3003: Training Accuracy = 0.6484, Training Loss = 1.4013, Validation Accuracy = 0.6839, Validation Loss = 1.4420\n",
            "Epoch 3004/3334\n",
            "Epoch 3004: Training Accuracy = 0.9805, Training Loss = 0.3850, Validation Accuracy = 0.9277, Validation Loss = 0.5884\n",
            "Epoch 3005/3334\n",
            "Epoch 3005: Training Accuracy = 0.9805, Training Loss = 0.3850, Validation Accuracy = 0.9277, Validation Loss = 0.5884\n",
            "Epoch 3006/3334\n",
            "Epoch 3006: Training Accuracy = 0.9844, Training Loss = 0.2173, Validation Accuracy = 0.9841, Validation Loss = 0.2736\n",
            "Epoch 3007/3334\n",
            "Epoch 3007: Training Accuracy = 0.9844, Training Loss = 0.1421, Validation Accuracy = 0.9892, Validation Loss = 0.1707\n",
            "Epoch 3008/3334\n",
            "Epoch 3008: Training Accuracy = 0.9844, Training Loss = 0.1421, Validation Accuracy = 0.9892, Validation Loss = 0.1707\n",
            "Epoch 3009/3334\n",
            "Epoch 3009: Training Accuracy = 0.9883, Training Loss = 0.0943, Validation Accuracy = 0.9897, Validation Loss = 0.1329\n",
            "Epoch 3010/3334\n",
            "Epoch 3010: Training Accuracy = 0.9883, Training Loss = 0.0943, Validation Accuracy = 0.9897, Validation Loss = 0.1329\n",
            "Epoch 3011/3334\n",
            "Epoch 3011: Training Accuracy = 0.9863, Training Loss = 0.0881, Validation Accuracy = 0.9897, Validation Loss = 0.1170\n",
            "Epoch 3012/3334\n",
            "Epoch 3012: Training Accuracy = 0.9941, Training Loss = 0.0550, Validation Accuracy = 0.9897, Validation Loss = 0.1089\n",
            "Epoch 3013/3334\n",
            "Epoch 3013: Training Accuracy = 0.9941, Training Loss = 0.0550, Validation Accuracy = 0.9897, Validation Loss = 0.1089\n",
            "Epoch 3014/3334\n",
            "Epoch 3014: Training Accuracy = 0.9922, Training Loss = 0.0594, Validation Accuracy = 0.9897, Validation Loss = 0.1052\n",
            "Epoch 3015/3334\n",
            "Epoch 3015: Training Accuracy = 0.9922, Training Loss = 0.0594, Validation Accuracy = 0.9897, Validation Loss = 0.1052\n",
            "Epoch 3016/3334\n",
            "Epoch 3016: Training Accuracy = 0.9863, Training Loss = 0.0791, Validation Accuracy = 0.9897, Validation Loss = 0.1038\n",
            "Epoch 3017/3334\n",
            "Epoch 3017: Training Accuracy = 0.9863, Training Loss = 0.0794, Validation Accuracy = 0.9897, Validation Loss = 0.1029\n",
            "Epoch 3018/3334\n",
            "Epoch 3018: Training Accuracy = 0.9863, Training Loss = 0.0794, Validation Accuracy = 0.9897, Validation Loss = 0.1029\n",
            "Epoch 3019/3334\n",
            "Epoch 3019: Training Accuracy = 0.9980, Training Loss = 0.0421, Validation Accuracy = 0.9897, Validation Loss = 0.1020\n",
            "Epoch 3020/3334\n",
            "Epoch 3020: Training Accuracy = 0.9980, Training Loss = 0.0421, Validation Accuracy = 0.9897, Validation Loss = 0.1020\n",
            "Epoch 3021/3334\n",
            "Epoch 3021: Training Accuracy = 0.9902, Training Loss = 0.0695, Validation Accuracy = 0.9897, Validation Loss = 0.1012\n",
            "Epoch 3022/3334\n",
            "Epoch 3022: Training Accuracy = 0.9922, Training Loss = 0.0577, Validation Accuracy = 0.9897, Validation Loss = 0.1019\n",
            "Epoch 3023/3334\n",
            "Epoch 3023: Training Accuracy = 0.9922, Training Loss = 0.0577, Validation Accuracy = 0.9897, Validation Loss = 0.1019\n",
            "Epoch 3024/3334\n",
            "Epoch 3024: Training Accuracy = 0.9883, Training Loss = 0.0700, Validation Accuracy = 0.9897, Validation Loss = 0.1008\n",
            "Epoch 3025/3334\n",
            "Epoch 3025: Training Accuracy = 0.9883, Training Loss = 0.0700, Validation Accuracy = 0.9897, Validation Loss = 0.1008\n",
            "Epoch 3026/3334\n",
            "Epoch 3026: Training Accuracy = 0.9902, Training Loss = 0.0622, Validation Accuracy = 0.9897, Validation Loss = 0.0995\n",
            "Epoch 3027/3334\n",
            "Epoch 3027: Training Accuracy = 0.9863, Training Loss = 0.0768, Validation Accuracy = 0.9897, Validation Loss = 0.0990\n",
            "Epoch 3028/3334\n",
            "Epoch 3028: Training Accuracy = 0.9863, Training Loss = 0.0768, Validation Accuracy = 0.9897, Validation Loss = 0.0990\n",
            "Epoch 3029/3334\n",
            "Epoch 3029: Training Accuracy = 0.9883, Training Loss = 0.0695, Validation Accuracy = 0.9897, Validation Loss = 0.1005\n",
            "Epoch 3030/3334\n",
            "Epoch 3030: Training Accuracy = 0.9883, Training Loss = 0.0695, Validation Accuracy = 0.9897, Validation Loss = 0.1005\n",
            "Epoch 3031/3334\n",
            "Epoch 3031: Training Accuracy = 0.9883, Training Loss = 0.0688, Validation Accuracy = 0.9897, Validation Loss = 0.1007\n",
            "Epoch 3032/3334\n",
            "Epoch 3032: Training Accuracy = 0.9941, Training Loss = 0.0506, Validation Accuracy = 0.9897, Validation Loss = 0.1002\n",
            "Epoch 3033/3334\n",
            "Epoch 3033: Training Accuracy = 0.9941, Training Loss = 0.0506, Validation Accuracy = 0.9897, Validation Loss = 0.1002\n",
            "Epoch 3034/3334\n",
            "Epoch 3034: Training Accuracy = 0.9941, Training Loss = 0.0635, Validation Accuracy = 0.9897, Validation Loss = 0.1210\n",
            "Epoch 3035/3334\n",
            "Epoch 3035: Training Accuracy = 0.9941, Training Loss = 0.0635, Validation Accuracy = 0.9897, Validation Loss = 0.1210\n",
            "Epoch 3036/3334\n",
            "Epoch 3036: Training Accuracy = 0.5938, Training Loss = 1.8322, Validation Accuracy = 0.5543, Validation Loss = 1.8051\n",
            "Epoch 3037/3334\n",
            "Epoch 3037: Training Accuracy = 0.9551, Training Loss = 0.4601, Validation Accuracy = 0.9294, Validation Loss = 0.5736\n",
            "Epoch 3038/3334\n",
            "Epoch 3038: Training Accuracy = 0.9551, Training Loss = 0.4601, Validation Accuracy = 0.9294, Validation Loss = 0.5736\n",
            "Epoch 3039/3334\n",
            "Epoch 3039: Training Accuracy = 0.9766, Training Loss = 0.2773, Validation Accuracy = 0.9853, Validation Loss = 0.2703\n",
            "Epoch 3040/3334\n",
            "Epoch 3040: Training Accuracy = 0.9766, Training Loss = 0.2773, Validation Accuracy = 0.9853, Validation Loss = 0.2703\n",
            "Epoch 3041/3334\n",
            "Epoch 3041: Training Accuracy = 0.9863, Training Loss = 0.1543, Validation Accuracy = 0.9894, Validation Loss = 0.1872\n",
            "Epoch 3042/3334\n",
            "Epoch 3042: Training Accuracy = 0.9902, Training Loss = 0.0952, Validation Accuracy = 0.9895, Validation Loss = 0.1411\n",
            "Epoch 3043/3334\n",
            "Epoch 3043: Training Accuracy = 0.9902, Training Loss = 0.0952, Validation Accuracy = 0.9895, Validation Loss = 0.1411\n",
            "Epoch 3044/3334\n",
            "Epoch 3044: Training Accuracy = 0.9941, Training Loss = 0.0655, Validation Accuracy = 0.9897, Validation Loss = 0.1213\n",
            "Epoch 3045/3334\n",
            "Epoch 3045: Training Accuracy = 0.9941, Training Loss = 0.0655, Validation Accuracy = 0.9897, Validation Loss = 0.1213\n",
            "Epoch 3046/3334\n",
            "Epoch 3046: Training Accuracy = 0.9863, Training Loss = 0.0863, Validation Accuracy = 0.9897, Validation Loss = 0.1127\n",
            "Epoch 3047/3334\n",
            "Epoch 3047: Training Accuracy = 0.9902, Training Loss = 0.0693, Validation Accuracy = 0.9897, Validation Loss = 0.1095\n",
            "Epoch 3048/3334\n",
            "Epoch 3048: Training Accuracy = 0.9902, Training Loss = 0.0693, Validation Accuracy = 0.9897, Validation Loss = 0.1095\n",
            "Epoch 3049/3334\n",
            "Epoch 3049: Training Accuracy = 0.9863, Training Loss = 0.0813, Validation Accuracy = 0.9897, Validation Loss = 0.1067\n",
            "Epoch 3050/3334\n",
            "Epoch 3050: Training Accuracy = 0.9863, Training Loss = 0.0813, Validation Accuracy = 0.9897, Validation Loss = 0.1067\n",
            "Epoch 3051/3334\n",
            "Epoch 3051: Training Accuracy = 0.9922, Training Loss = 0.0583, Validation Accuracy = 0.9897, Validation Loss = 0.1064\n",
            "Epoch 3052/3334\n",
            "Epoch 3052: Training Accuracy = 0.9941, Training Loss = 0.0519, Validation Accuracy = 0.9897, Validation Loss = 0.1049\n",
            "Epoch 3053/3334\n",
            "Epoch 3053: Training Accuracy = 0.9941, Training Loss = 0.0519, Validation Accuracy = 0.9897, Validation Loss = 0.1049\n",
            "Epoch 3054/3334\n",
            "Epoch 3054: Training Accuracy = 0.9941, Training Loss = 0.0528, Validation Accuracy = 0.9897, Validation Loss = 0.1044\n",
            "Epoch 3055/3334\n",
            "Epoch 3055: Training Accuracy = 0.9941, Training Loss = 0.0528, Validation Accuracy = 0.9897, Validation Loss = 0.1044\n",
            "Epoch 3056/3334\n",
            "Epoch 3056: Training Accuracy = 0.9922, Training Loss = 0.0581, Validation Accuracy = 0.9897, Validation Loss = 0.1038\n",
            "Epoch 3057/3334\n",
            "Epoch 3057: Training Accuracy = 0.9902, Training Loss = 0.0645, Validation Accuracy = 0.9897, Validation Loss = 0.1024\n",
            "Epoch 3058/3334\n",
            "Epoch 3058: Training Accuracy = 0.9902, Training Loss = 0.0645, Validation Accuracy = 0.9897, Validation Loss = 0.1024\n",
            "Epoch 3059/3334\n",
            "Epoch 3059: Training Accuracy = 0.9863, Training Loss = 0.0769, Validation Accuracy = 0.9897, Validation Loss = 0.1015\n",
            "Epoch 3060/3334\n",
            "Epoch 3060: Training Accuracy = 0.9863, Training Loss = 0.0769, Validation Accuracy = 0.9897, Validation Loss = 0.1015\n",
            "Epoch 3061/3334\n",
            "Epoch 3061: Training Accuracy = 0.9922, Training Loss = 0.0612, Validation Accuracy = 0.9897, Validation Loss = 0.0996\n",
            "Epoch 3062/3334\n",
            "Epoch 3062: Training Accuracy = 0.9941, Training Loss = 0.0491, Validation Accuracy = 0.9897, Validation Loss = 0.1009\n",
            "Epoch 3063/3334\n",
            "Epoch 3063: Training Accuracy = 0.9941, Training Loss = 0.0491, Validation Accuracy = 0.9897, Validation Loss = 0.1009\n",
            "Epoch 3064/3334\n",
            "Epoch 3064: Training Accuracy = 0.9844, Training Loss = 0.0801, Validation Accuracy = 0.9897, Validation Loss = 0.0989\n",
            "Epoch 3065/3334\n",
            "Epoch 3065: Training Accuracy = 0.9844, Training Loss = 0.0801, Validation Accuracy = 0.9897, Validation Loss = 0.0989\n",
            "Epoch 3066/3334\n",
            "Epoch 3066: Training Accuracy = 0.9824, Training Loss = 0.0880, Validation Accuracy = 0.9897, Validation Loss = 0.0993\n",
            "Epoch 3067/3334\n",
            "Epoch 3067: Training Accuracy = 0.9941, Training Loss = 0.0502, Validation Accuracy = 0.9897, Validation Loss = 0.1013\n",
            "Epoch 3068/3334\n",
            "Epoch 3068: Training Accuracy = 0.9941, Training Loss = 0.0502, Validation Accuracy = 0.9897, Validation Loss = 0.1013\n",
            "Epoch 3069/3334\n",
            "Epoch 3069: Training Accuracy = 0.9941, Training Loss = 0.0565, Validation Accuracy = 0.9897, Validation Loss = 0.1027\n",
            "Epoch 3070/3334\n",
            "Epoch 3070: Training Accuracy = 0.9941, Training Loss = 0.0565, Validation Accuracy = 0.9897, Validation Loss = 0.1027\n",
            "Epoch 3071/3334\n",
            "Epoch 3071: Training Accuracy = 0.5996, Training Loss = 1.9060, Validation Accuracy = 0.5772, Validation Loss = 1.8719\n",
            "Epoch 3072/3334\n",
            "Epoch 3072: Training Accuracy = 0.9355, Training Loss = 0.5763, Validation Accuracy = 0.8921, Validation Loss = 0.7295\n",
            "Epoch 3073/3334\n",
            "Epoch 3073: Training Accuracy = 0.9355, Training Loss = 0.5763, Validation Accuracy = 0.8921, Validation Loss = 0.7295\n",
            "Epoch 3074/3334\n",
            "Epoch 3074: Training Accuracy = 0.9844, Training Loss = 0.2717, Validation Accuracy = 0.9822, Validation Loss = 0.3018\n",
            "Epoch 3075/3334\n",
            "Epoch 3075: Training Accuracy = 0.9844, Training Loss = 0.2717, Validation Accuracy = 0.9822, Validation Loss = 0.3018\n",
            "Epoch 3076/3334\n",
            "Epoch 3076: Training Accuracy = 0.9844, Training Loss = 0.1668, Validation Accuracy = 0.9889, Validation Loss = 0.1852\n",
            "Epoch 3077/3334\n",
            "Epoch 3077: Training Accuracy = 0.9961, Training Loss = 0.0730, Validation Accuracy = 0.9897, Validation Loss = 0.1386\n",
            "Epoch 3078/3334\n",
            "Epoch 3078: Training Accuracy = 0.9961, Training Loss = 0.0730, Validation Accuracy = 0.9897, Validation Loss = 0.1386\n",
            "Epoch 3079/3334\n",
            "Epoch 3079: Training Accuracy = 0.9863, Training Loss = 0.0895, Validation Accuracy = 0.9897, Validation Loss = 0.1187\n",
            "Epoch 3080/3334\n",
            "Epoch 3080: Training Accuracy = 0.9863, Training Loss = 0.0895, Validation Accuracy = 0.9897, Validation Loss = 0.1187\n",
            "Epoch 3081/3334\n",
            "Epoch 3081: Training Accuracy = 0.9961, Training Loss = 0.0471, Validation Accuracy = 0.9897, Validation Loss = 0.1094\n",
            "Epoch 3082/3334\n",
            "Epoch 3082: Training Accuracy = 0.9863, Training Loss = 0.0806, Validation Accuracy = 0.9897, Validation Loss = 0.1048\n",
            "Epoch 3083/3334\n",
            "Epoch 3083: Training Accuracy = 0.9863, Training Loss = 0.0806, Validation Accuracy = 0.9897, Validation Loss = 0.1048\n",
            "Epoch 3084/3334\n",
            "Epoch 3084: Training Accuracy = 0.9805, Training Loss = 0.0985, Validation Accuracy = 0.9897, Validation Loss = 0.1037\n",
            "Epoch 3085/3334\n",
            "Epoch 3085: Training Accuracy = 0.9805, Training Loss = 0.0985, Validation Accuracy = 0.9897, Validation Loss = 0.1037\n",
            "Epoch 3086/3334\n",
            "Epoch 3086: Training Accuracy = 0.9922, Training Loss = 0.0624, Validation Accuracy = 0.9897, Validation Loss = 0.1029\n",
            "Epoch 3087/3334\n",
            "Epoch 3087: Training Accuracy = 0.9863, Training Loss = 0.0766, Validation Accuracy = 0.9897, Validation Loss = 0.1008\n",
            "Epoch 3088/3334\n",
            "Epoch 3088: Training Accuracy = 0.9863, Training Loss = 0.0766, Validation Accuracy = 0.9897, Validation Loss = 0.1008\n",
            "Epoch 3089/3334\n",
            "Epoch 3089: Training Accuracy = 0.9824, Training Loss = 0.0896, Validation Accuracy = 0.9897, Validation Loss = 0.1002\n",
            "Epoch 3090/3334\n",
            "Epoch 3090: Training Accuracy = 0.9824, Training Loss = 0.0896, Validation Accuracy = 0.9897, Validation Loss = 0.1002\n",
            "Epoch 3091/3334\n",
            "Epoch 3091: Training Accuracy = 0.9863, Training Loss = 0.0821, Validation Accuracy = 0.9897, Validation Loss = 0.0996\n",
            "Epoch 3092/3334\n",
            "Epoch 3092: Training Accuracy = 0.9883, Training Loss = 0.0690, Validation Accuracy = 0.9897, Validation Loss = 0.0982\n",
            "Epoch 3093/3334\n",
            "Epoch 3093: Training Accuracy = 0.9883, Training Loss = 0.0690, Validation Accuracy = 0.9897, Validation Loss = 0.0982\n",
            "Epoch 3094/3334\n",
            "Epoch 3094: Training Accuracy = 0.9883, Training Loss = 0.0681, Validation Accuracy = 0.9897, Validation Loss = 0.0984\n",
            "Epoch 3095/3334\n",
            "Epoch 3095: Training Accuracy = 0.9883, Training Loss = 0.0681, Validation Accuracy = 0.9897, Validation Loss = 0.0984\n",
            "Epoch 3096/3334\n",
            "Epoch 3096: Training Accuracy = 0.9883, Training Loss = 0.0676, Validation Accuracy = 0.9897, Validation Loss = 0.0973\n",
            "Epoch 3097/3334\n",
            "Epoch 3097: Training Accuracy = 0.9902, Training Loss = 0.0672, Validation Accuracy = 0.9897, Validation Loss = 0.0985\n",
            "Epoch 3098/3334\n",
            "Epoch 3098: Training Accuracy = 0.9902, Training Loss = 0.0672, Validation Accuracy = 0.9897, Validation Loss = 0.0985\n",
            "Epoch 3099/3334\n",
            "Epoch 3099: Training Accuracy = 0.9922, Training Loss = 0.0539, Validation Accuracy = 0.9897, Validation Loss = 0.0969\n",
            "Epoch 3100/3334\n",
            "Epoch 3100: Training Accuracy = 0.9922, Training Loss = 0.0539, Validation Accuracy = 0.9897, Validation Loss = 0.0969\n",
            "Epoch 3101/3334\n",
            "Epoch 3101: Training Accuracy = 0.9922, Training Loss = 0.0562, Validation Accuracy = 0.9897, Validation Loss = 0.0984\n",
            "Epoch 3102/3334\n",
            "Epoch 3102: Training Accuracy = 0.9922, Training Loss = 0.0927, Validation Accuracy = 0.8705, Validation Loss = 0.7047\n",
            "Epoch 3103/3334\n",
            "Epoch 3103: Training Accuracy = 0.9922, Training Loss = 0.0927, Validation Accuracy = 0.8705, Validation Loss = 0.7047\n",
            "Epoch 3104/3334\n",
            "Epoch 3104: Training Accuracy = 0.5625, Training Loss = 1.8951, Validation Accuracy = 0.6057, Validation Loss = 1.7998\n",
            "Epoch 3105/3334\n",
            "Epoch 3105: Training Accuracy = 0.5625, Training Loss = 1.8951, Validation Accuracy = 0.6057, Validation Loss = 1.7998\n",
            "Epoch 3106/3334\n",
            "Epoch 3106: Training Accuracy = 0.9258, Training Loss = 0.5926, Validation Accuracy = 0.9025, Validation Loss = 0.7067\n",
            "Epoch 3107/3334\n",
            "Epoch 3107: Training Accuracy = 0.9863, Training Loss = 0.2434, Validation Accuracy = 0.9856, Validation Loss = 0.2863\n",
            "Epoch 3108/3334\n",
            "Epoch 3108: Training Accuracy = 0.9863, Training Loss = 0.2434, Validation Accuracy = 0.9856, Validation Loss = 0.2863\n",
            "Epoch 3109/3334\n",
            "Epoch 3109: Training Accuracy = 0.9961, Training Loss = 0.1256, Validation Accuracy = 0.9895, Validation Loss = 0.1898\n",
            "Epoch 3110/3334\n",
            "Epoch 3110: Training Accuracy = 0.9961, Training Loss = 0.1256, Validation Accuracy = 0.9895, Validation Loss = 0.1898\n",
            "Epoch 3111/3334\n",
            "Epoch 3111: Training Accuracy = 0.9863, Training Loss = 0.1049, Validation Accuracy = 0.9897, Validation Loss = 0.1377\n",
            "Epoch 3112/3334\n",
            "Epoch 3112: Training Accuracy = 0.9941, Training Loss = 0.0638, Validation Accuracy = 0.9897, Validation Loss = 0.1177\n",
            "Epoch 3113/3334\n",
            "Epoch 3113: Training Accuracy = 0.9941, Training Loss = 0.0638, Validation Accuracy = 0.9897, Validation Loss = 0.1177\n",
            "Epoch 3114/3334\n",
            "Epoch 3114: Training Accuracy = 0.9941, Training Loss = 0.0549, Validation Accuracy = 0.9897, Validation Loss = 0.1090\n",
            "Epoch 3115/3334\n",
            "Epoch 3115: Training Accuracy = 0.9941, Training Loss = 0.0549, Validation Accuracy = 0.9897, Validation Loss = 0.1090\n",
            "Epoch 3116/3334\n",
            "Epoch 3116: Training Accuracy = 0.9883, Training Loss = 0.0733, Validation Accuracy = 0.9897, Validation Loss = 0.1056\n",
            "Epoch 3117/3334\n",
            "Epoch 3117: Training Accuracy = 0.9902, Training Loss = 0.0665, Validation Accuracy = 0.9897, Validation Loss = 0.1037\n",
            "Epoch 3118/3334\n",
            "Epoch 3118: Training Accuracy = 0.9902, Training Loss = 0.0665, Validation Accuracy = 0.9897, Validation Loss = 0.1037\n",
            "Epoch 3119/3334\n",
            "Epoch 3119: Training Accuracy = 0.9902, Training Loss = 0.0650, Validation Accuracy = 0.9897, Validation Loss = 0.1026\n",
            "Epoch 3120/3334\n",
            "Epoch 3120: Training Accuracy = 0.9902, Training Loss = 0.0650, Validation Accuracy = 0.9897, Validation Loss = 0.1026\n",
            "Epoch 3121/3334\n",
            "Epoch 3121: Training Accuracy = 0.9941, Training Loss = 0.0566, Validation Accuracy = 0.9897, Validation Loss = 0.1009\n",
            "Epoch 3122/3334\n",
            "Epoch 3122: Training Accuracy = 0.9902, Training Loss = 0.0713, Validation Accuracy = 0.9897, Validation Loss = 0.1016\n",
            "Epoch 3123/3334\n",
            "Epoch 3123: Training Accuracy = 0.9902, Training Loss = 0.0713, Validation Accuracy = 0.9897, Validation Loss = 0.1016\n",
            "Epoch 3124/3334\n",
            "Epoch 3124: Training Accuracy = 0.9922, Training Loss = 0.0568, Validation Accuracy = 0.9897, Validation Loss = 0.1004\n",
            "Epoch 3125/3334\n",
            "Epoch 3125: Training Accuracy = 0.9922, Training Loss = 0.0568, Validation Accuracy = 0.9897, Validation Loss = 0.1004\n",
            "Epoch 3126/3334\n",
            "Epoch 3126: Training Accuracy = 0.9824, Training Loss = 0.0931, Validation Accuracy = 0.9897, Validation Loss = 0.0999\n",
            "Epoch 3127/3334\n",
            "Epoch 3127: Training Accuracy = 0.9922, Training Loss = 0.0557, Validation Accuracy = 0.9897, Validation Loss = 0.0997\n",
            "Epoch 3128/3334\n",
            "Epoch 3128: Training Accuracy = 0.9922, Training Loss = 0.0557, Validation Accuracy = 0.9897, Validation Loss = 0.0997\n",
            "Epoch 3129/3334\n",
            "Epoch 3129: Training Accuracy = 0.9844, Training Loss = 0.0853, Validation Accuracy = 0.9897, Validation Loss = 0.0995\n",
            "Epoch 3130/3334\n",
            "Epoch 3130: Training Accuracy = 0.9844, Training Loss = 0.0853, Validation Accuracy = 0.9897, Validation Loss = 0.0995\n",
            "Epoch 3131/3334\n",
            "Epoch 3131: Training Accuracy = 0.9883, Training Loss = 0.0691, Validation Accuracy = 0.9897, Validation Loss = 0.0986\n",
            "Epoch 3132/3334\n",
            "Epoch 3132: Training Accuracy = 0.9980, Training Loss = 0.0366, Validation Accuracy = 0.9897, Validation Loss = 0.1002\n",
            "Epoch 3133/3334\n",
            "Epoch 3133: Training Accuracy = 0.9980, Training Loss = 0.0366, Validation Accuracy = 0.9897, Validation Loss = 0.1002\n",
            "Epoch 3134/3334\n",
            "Epoch 3134: Training Accuracy = 0.9922, Training Loss = 0.0725, Validation Accuracy = 0.9897, Validation Loss = 0.1227\n",
            "Epoch 3135/3334\n",
            "Epoch 3135: Training Accuracy = 0.9922, Training Loss = 0.0725, Validation Accuracy = 0.9897, Validation Loss = 0.1227\n",
            "Epoch 3136/3334\n",
            "Epoch 3136: Training Accuracy = 0.5410, Training Loss = 1.6758, Validation Accuracy = 0.5795, Validation Loss = 1.6713\n",
            "Epoch 3137/3334\n",
            "Epoch 3137: Training Accuracy = 0.9609, Training Loss = 0.4129, Validation Accuracy = 0.9639, Validation Loss = 0.4453\n",
            "Epoch 3138/3334\n",
            "Epoch 3138: Training Accuracy = 0.9609, Training Loss = 0.4129, Validation Accuracy = 0.9639, Validation Loss = 0.4453\n",
            "Epoch 3139/3334\n",
            "Epoch 3139: Training Accuracy = 0.9805, Training Loss = 0.2269, Validation Accuracy = 0.9859, Validation Loss = 0.2432\n",
            "Epoch 3140/3334\n",
            "Epoch 3140: Training Accuracy = 0.9805, Training Loss = 0.2269, Validation Accuracy = 0.9859, Validation Loss = 0.2432\n",
            "Epoch 3141/3334\n",
            "Epoch 3141: Training Accuracy = 0.9883, Training Loss = 0.1117, Validation Accuracy = 0.9894, Validation Loss = 0.1469\n",
            "Epoch 3142/3334\n",
            "Epoch 3142: Training Accuracy = 0.9941, Training Loss = 0.0656, Validation Accuracy = 0.9897, Validation Loss = 0.1200\n",
            "Epoch 3143/3334\n",
            "Epoch 3143: Training Accuracy = 0.9941, Training Loss = 0.0656, Validation Accuracy = 0.9897, Validation Loss = 0.1200\n",
            "Epoch 3144/3334\n",
            "Epoch 3144: Training Accuracy = 0.9883, Training Loss = 0.0782, Validation Accuracy = 0.9897, Validation Loss = 0.1084\n",
            "Epoch 3145/3334\n",
            "Epoch 3145: Training Accuracy = 0.9883, Training Loss = 0.0782, Validation Accuracy = 0.9897, Validation Loss = 0.1084\n",
            "Epoch 3146/3334\n",
            "Epoch 3146: Training Accuracy = 0.9844, Training Loss = 0.0860, Validation Accuracy = 0.9897, Validation Loss = 0.1030\n",
            "Epoch 3147/3334\n",
            "Epoch 3147: Training Accuracy = 0.9922, Training Loss = 0.0573, Validation Accuracy = 0.9897, Validation Loss = 0.1008\n",
            "Epoch 3148/3334\n",
            "Epoch 3148: Training Accuracy = 0.9922, Training Loss = 0.0573, Validation Accuracy = 0.9897, Validation Loss = 0.1008\n",
            "Epoch 3149/3334\n",
            "Epoch 3149: Training Accuracy = 0.9941, Training Loss = 0.0491, Validation Accuracy = 0.9897, Validation Loss = 0.0994\n",
            "Epoch 3150/3334\n",
            "Epoch 3150: Training Accuracy = 0.9941, Training Loss = 0.0491, Validation Accuracy = 0.9897, Validation Loss = 0.0994\n",
            "Epoch 3151/3334\n",
            "Epoch 3151: Training Accuracy = 0.9941, Training Loss = 0.0483, Validation Accuracy = 0.9897, Validation Loss = 0.0999\n",
            "Epoch 3152/3334\n",
            "Epoch 3152: Training Accuracy = 0.9863, Training Loss = 0.0773, Validation Accuracy = 0.9897, Validation Loss = 0.0990\n",
            "Epoch 3153/3334\n",
            "Epoch 3153: Training Accuracy = 0.9863, Training Loss = 0.0773, Validation Accuracy = 0.9897, Validation Loss = 0.0990\n",
            "Epoch 3154/3334\n",
            "Epoch 3154: Training Accuracy = 0.9922, Training Loss = 0.0619, Validation Accuracy = 0.9897, Validation Loss = 0.0996\n",
            "Epoch 3155/3334\n",
            "Epoch 3155: Training Accuracy = 0.9922, Training Loss = 0.0619, Validation Accuracy = 0.9897, Validation Loss = 0.0996\n",
            "Epoch 3156/3334\n",
            "Epoch 3156: Training Accuracy = 0.9902, Training Loss = 0.0611, Validation Accuracy = 0.9897, Validation Loss = 0.0993\n",
            "Epoch 3157/3334\n",
            "Epoch 3157: Training Accuracy = 0.9941, Training Loss = 0.0483, Validation Accuracy = 0.9897, Validation Loss = 0.0984\n",
            "Epoch 3158/3334\n",
            "Epoch 3158: Training Accuracy = 0.9941, Training Loss = 0.0483, Validation Accuracy = 0.9897, Validation Loss = 0.0984\n",
            "Epoch 3159/3334\n",
            "Epoch 3159: Training Accuracy = 0.9902, Training Loss = 0.0613, Validation Accuracy = 0.9897, Validation Loss = 0.0971\n",
            "Epoch 3160/3334\n",
            "Epoch 3160: Training Accuracy = 0.9902, Training Loss = 0.0613, Validation Accuracy = 0.9897, Validation Loss = 0.0971\n",
            "Epoch 3161/3334\n",
            "Epoch 3161: Training Accuracy = 0.9863, Training Loss = 0.0733, Validation Accuracy = 0.9897, Validation Loss = 0.0975\n",
            "Epoch 3162/3334\n",
            "Epoch 3162: Training Accuracy = 0.9863, Training Loss = 0.0747, Validation Accuracy = 0.9897, Validation Loss = 0.0973\n",
            "Epoch 3163/3334\n",
            "Epoch 3163: Training Accuracy = 0.9863, Training Loss = 0.0747, Validation Accuracy = 0.9897, Validation Loss = 0.0973\n",
            "Epoch 3164/3334\n",
            "Epoch 3164: Training Accuracy = 0.9941, Training Loss = 0.0477, Validation Accuracy = 0.9897, Validation Loss = 0.0954\n",
            "Epoch 3165/3334\n",
            "Epoch 3165: Training Accuracy = 0.9941, Training Loss = 0.0477, Validation Accuracy = 0.9897, Validation Loss = 0.0954\n",
            "Epoch 3166/3334\n",
            "Epoch 3166: Training Accuracy = 0.9922, Training Loss = 0.0559, Validation Accuracy = 0.9897, Validation Loss = 0.1015\n",
            "Epoch 3167/3334\n",
            "Epoch 3167: Training Accuracy = 0.9941, Training Loss = 0.0489, Validation Accuracy = 0.9897, Validation Loss = 0.1009\n",
            "Epoch 3168/3334\n",
            "Epoch 3168: Training Accuracy = 0.9941, Training Loss = 0.0489, Validation Accuracy = 0.9897, Validation Loss = 0.1009\n",
            "Epoch 3169/3334\n",
            "Epoch 3169: Training Accuracy = 0.9902, Training Loss = 0.0743, Validation Accuracy = 0.9894, Validation Loss = 0.1415\n",
            "Epoch 3170/3334\n",
            "Epoch 3170: Training Accuracy = 0.9902, Training Loss = 0.0743, Validation Accuracy = 0.9894, Validation Loss = 0.1415\n",
            "Epoch 3171/3334\n",
            "Epoch 3171: Training Accuracy = 0.7715, Training Loss = 1.0922, Validation Accuracy = 0.7960, Validation Loss = 1.0657\n",
            "Epoch 3172/3334\n",
            "Epoch 3172: Training Accuracy = 0.9766, Training Loss = 0.3445, Validation Accuracy = 0.9774, Validation Loss = 0.3828\n",
            "Epoch 3173/3334\n",
            "Epoch 3173: Training Accuracy = 0.9766, Training Loss = 0.3445, Validation Accuracy = 0.9774, Validation Loss = 0.3828\n",
            "Epoch 3174/3334\n",
            "Epoch 3174: Training Accuracy = 0.9941, Training Loss = 0.1504, Validation Accuracy = 0.9880, Validation Loss = 0.2229\n",
            "Epoch 3175/3334\n",
            "Epoch 3175: Training Accuracy = 0.9941, Training Loss = 0.1504, Validation Accuracy = 0.9880, Validation Loss = 0.2229\n",
            "Epoch 3176/3334\n",
            "Epoch 3176: Training Accuracy = 0.9941, Training Loss = 0.0906, Validation Accuracy = 0.9897, Validation Loss = 0.1473\n",
            "Epoch 3177/3334\n",
            "Epoch 3177: Training Accuracy = 0.9922, Training Loss = 0.0741, Validation Accuracy = 0.9897, Validation Loss = 0.1238\n",
            "Epoch 3178/3334\n",
            "Epoch 3178: Training Accuracy = 0.9922, Training Loss = 0.0741, Validation Accuracy = 0.9897, Validation Loss = 0.1238\n",
            "Epoch 3179/3334\n",
            "Epoch 3179: Training Accuracy = 0.9922, Training Loss = 0.0635, Validation Accuracy = 0.9897, Validation Loss = 0.1110\n",
            "Epoch 3180/3334\n",
            "Epoch 3180: Training Accuracy = 0.9922, Training Loss = 0.0635, Validation Accuracy = 0.9897, Validation Loss = 0.1110\n",
            "Epoch 3181/3334\n",
            "Epoch 3181: Training Accuracy = 0.9941, Training Loss = 0.0580, Validation Accuracy = 0.9897, Validation Loss = 0.1052\n",
            "Epoch 3182/3334\n",
            "Epoch 3182: Training Accuracy = 0.9941, Training Loss = 0.0519, Validation Accuracy = 0.9897, Validation Loss = 0.1035\n",
            "Epoch 3183/3334\n",
            "Epoch 3183: Training Accuracy = 0.9941, Training Loss = 0.0519, Validation Accuracy = 0.9897, Validation Loss = 0.1035\n",
            "Epoch 3184/3334\n",
            "Epoch 3184: Training Accuracy = 0.9961, Training Loss = 0.0427, Validation Accuracy = 0.9897, Validation Loss = 0.1019\n",
            "Epoch 3185/3334\n",
            "Epoch 3185: Training Accuracy = 0.9961, Training Loss = 0.0427, Validation Accuracy = 0.9897, Validation Loss = 0.1019\n",
            "Epoch 3186/3334\n",
            "Epoch 3186: Training Accuracy = 0.9883, Training Loss = 0.0694, Validation Accuracy = 0.9897, Validation Loss = 0.1017\n",
            "Epoch 3187/3334\n",
            "Epoch 3187: Training Accuracy = 0.9922, Training Loss = 0.0569, Validation Accuracy = 0.9897, Validation Loss = 0.1003\n",
            "Epoch 3188/3334\n",
            "Epoch 3188: Training Accuracy = 0.9922, Training Loss = 0.0569, Validation Accuracy = 0.9897, Validation Loss = 0.1003\n",
            "Epoch 3189/3334\n",
            "Epoch 3189: Training Accuracy = 0.9883, Training Loss = 0.0692, Validation Accuracy = 0.9897, Validation Loss = 0.0997\n",
            "Epoch 3190/3334\n",
            "Epoch 3190: Training Accuracy = 0.9883, Training Loss = 0.0692, Validation Accuracy = 0.9897, Validation Loss = 0.0997\n",
            "Epoch 3191/3334\n",
            "Epoch 3191: Training Accuracy = 0.9922, Training Loss = 0.0544, Validation Accuracy = 0.9897, Validation Loss = 0.0997\n",
            "Epoch 3192/3334\n",
            "Epoch 3192: Training Accuracy = 0.9922, Training Loss = 0.0543, Validation Accuracy = 0.9897, Validation Loss = 0.0983\n",
            "Epoch 3193/3334\n",
            "Epoch 3193: Training Accuracy = 0.9922, Training Loss = 0.0543, Validation Accuracy = 0.9897, Validation Loss = 0.0983\n",
            "Epoch 3194/3334\n",
            "Epoch 3194: Training Accuracy = 0.9805, Training Loss = 0.0945, Validation Accuracy = 0.9897, Validation Loss = 0.0970\n",
            "Epoch 3195/3334\n",
            "Epoch 3195: Training Accuracy = 0.9805, Training Loss = 0.0945, Validation Accuracy = 0.9897, Validation Loss = 0.0970\n",
            "Epoch 3196/3334\n",
            "Epoch 3196: Training Accuracy = 0.9941, Training Loss = 0.0462, Validation Accuracy = 0.9897, Validation Loss = 0.0982\n",
            "Epoch 3197/3334\n",
            "Epoch 3197: Training Accuracy = 0.9863, Training Loss = 0.0740, Validation Accuracy = 0.9897, Validation Loss = 0.0965\n",
            "Epoch 3198/3334\n",
            "Epoch 3198: Training Accuracy = 0.9863, Training Loss = 0.0740, Validation Accuracy = 0.9897, Validation Loss = 0.0965\n",
            "Epoch 3199/3334\n",
            "Epoch 3199: Training Accuracy = 0.9883, Training Loss = 0.0652, Validation Accuracy = 0.9897, Validation Loss = 0.0987\n",
            "Epoch 3200/3334\n",
            "Epoch 3200: Training Accuracy = 0.9883, Training Loss = 0.0652, Validation Accuracy = 0.9897, Validation Loss = 0.0987\n",
            "Epoch 3201/3334\n",
            "Epoch 3201: Training Accuracy = 0.9941, Training Loss = 0.0548, Validation Accuracy = 0.9897, Validation Loss = 0.0990\n",
            "Epoch 3202/3334\n",
            "Epoch 3202: Training Accuracy = 0.9902, Training Loss = 0.0659, Validation Accuracy = 0.9897, Validation Loss = 0.1008\n",
            "Epoch 3203/3334\n",
            "Epoch 3203: Training Accuracy = 0.9902, Training Loss = 0.0659, Validation Accuracy = 0.9897, Validation Loss = 0.1008\n",
            "Epoch 3204/3334\n",
            "Epoch 3204: Training Accuracy = 0.9883, Training Loss = 0.0680, Validation Accuracy = 0.9897, Validation Loss = 0.1040\n",
            "Epoch 3205/3334\n",
            "Epoch 3205: Training Accuracy = 0.9883, Training Loss = 0.0680, Validation Accuracy = 0.9897, Validation Loss = 0.1040\n",
            "Epoch 3206/3334\n",
            "Epoch 3206: Training Accuracy = 0.6562, Training Loss = 1.4857, Validation Accuracy = 0.3981, Validation Loss = 2.5070\n",
            "Epoch 3207/3334\n",
            "Epoch 3207: Training Accuracy = 0.8438, Training Loss = 0.8736, Validation Accuracy = 0.8811, Validation Loss = 0.8084\n",
            "Epoch 3208/3334\n",
            "Epoch 3208: Training Accuracy = 0.8438, Training Loss = 0.8736, Validation Accuracy = 0.8811, Validation Loss = 0.8084\n",
            "Epoch 3209/3334\n",
            "Epoch 3209: Training Accuracy = 0.9844, Training Loss = 0.2917, Validation Accuracy = 0.9789, Validation Loss = 0.3538\n",
            "Epoch 3210/3334\n",
            "Epoch 3210: Training Accuracy = 0.9844, Training Loss = 0.2917, Validation Accuracy = 0.9789, Validation Loss = 0.3538\n",
            "Epoch 3211/3334\n",
            "Epoch 3211: Training Accuracy = 0.9922, Training Loss = 0.1529, Validation Accuracy = 0.9877, Validation Loss = 0.2190\n",
            "Epoch 3212/3334\n",
            "Epoch 3212: Training Accuracy = 0.9863, Training Loss = 0.1189, Validation Accuracy = 0.9897, Validation Loss = 0.1462\n",
            "Epoch 3213/3334\n",
            "Epoch 3213: Training Accuracy = 0.9863, Training Loss = 0.1189, Validation Accuracy = 0.9897, Validation Loss = 0.1462\n",
            "Epoch 3214/3334\n",
            "Epoch 3214: Training Accuracy = 0.9863, Training Loss = 0.0978, Validation Accuracy = 0.9897, Validation Loss = 0.1221\n",
            "Epoch 3215/3334\n",
            "Epoch 3215: Training Accuracy = 0.9863, Training Loss = 0.0978, Validation Accuracy = 0.9897, Validation Loss = 0.1221\n",
            "Epoch 3216/3334\n",
            "Epoch 3216: Training Accuracy = 0.9902, Training Loss = 0.0719, Validation Accuracy = 0.9897, Validation Loss = 0.1137\n",
            "Epoch 3217/3334\n",
            "Epoch 3217: Training Accuracy = 0.9883, Training Loss = 0.0790, Validation Accuracy = 0.9897, Validation Loss = 0.1093\n",
            "Epoch 3218/3334\n",
            "Epoch 3218: Training Accuracy = 0.9883, Training Loss = 0.0790, Validation Accuracy = 0.9897, Validation Loss = 0.1093\n",
            "Epoch 3219/3334\n",
            "Epoch 3219: Training Accuracy = 0.9941, Training Loss = 0.0522, Validation Accuracy = 0.9897, Validation Loss = 0.1052\n",
            "Epoch 3220/3334\n",
            "Epoch 3220: Training Accuracy = 0.9941, Training Loss = 0.0522, Validation Accuracy = 0.9897, Validation Loss = 0.1052\n",
            "Epoch 3221/3334\n",
            "Epoch 3221: Training Accuracy = 0.9902, Training Loss = 0.0673, Validation Accuracy = 0.9897, Validation Loss = 0.1047\n",
            "Epoch 3222/3334\n",
            "Epoch 3222: Training Accuracy = 0.9922, Training Loss = 0.0603, Validation Accuracy = 0.9897, Validation Loss = 0.1052\n",
            "Epoch 3223/3334\n",
            "Epoch 3223: Training Accuracy = 0.9922, Training Loss = 0.0603, Validation Accuracy = 0.9897, Validation Loss = 0.1052\n",
            "Epoch 3224/3334\n",
            "Epoch 3224: Training Accuracy = 0.9902, Training Loss = 0.0648, Validation Accuracy = 0.9897, Validation Loss = 0.1051\n",
            "Epoch 3225/3334\n",
            "Epoch 3225: Training Accuracy = 0.9902, Training Loss = 0.0648, Validation Accuracy = 0.9897, Validation Loss = 0.1051\n",
            "Epoch 3226/3334\n",
            "Epoch 3226: Training Accuracy = 0.9961, Training Loss = 0.0440, Validation Accuracy = 0.9897, Validation Loss = 0.1044\n",
            "Epoch 3227/3334\n",
            "Epoch 3227: Training Accuracy = 0.9863, Training Loss = 0.0802, Validation Accuracy = 0.9897, Validation Loss = 0.1043\n",
            "Epoch 3228/3334\n",
            "Epoch 3228: Training Accuracy = 0.9863, Training Loss = 0.0802, Validation Accuracy = 0.9897, Validation Loss = 0.1043\n",
            "Epoch 3229/3334\n",
            "Epoch 3229: Training Accuracy = 0.9922, Training Loss = 0.0586, Validation Accuracy = 0.9897, Validation Loss = 0.1031\n",
            "Epoch 3230/3334\n",
            "Epoch 3230: Training Accuracy = 0.9922, Training Loss = 0.0586, Validation Accuracy = 0.9897, Validation Loss = 0.1031\n",
            "Epoch 3231/3334\n",
            "Epoch 3231: Training Accuracy = 0.9941, Training Loss = 0.0544, Validation Accuracy = 0.9897, Validation Loss = 0.1009\n",
            "Epoch 3232/3334\n",
            "Epoch 3232: Training Accuracy = 0.9863, Training Loss = 0.0804, Validation Accuracy = 0.9897, Validation Loss = 0.1044\n",
            "Epoch 3233/3334\n",
            "Epoch 3233: Training Accuracy = 0.9863, Training Loss = 0.0804, Validation Accuracy = 0.9897, Validation Loss = 0.1044\n",
            "Epoch 3234/3334\n",
            "Epoch 3234: Training Accuracy = 0.9902, Training Loss = 0.0639, Validation Accuracy = 0.9897, Validation Loss = 0.1006\n",
            "Epoch 3235/3334\n",
            "Epoch 3235: Training Accuracy = 0.9902, Training Loss = 0.0639, Validation Accuracy = 0.9897, Validation Loss = 0.1006\n",
            "Epoch 3236/3334\n",
            "Epoch 3236: Training Accuracy = 0.9980, Training Loss = 0.0352, Validation Accuracy = 0.9897, Validation Loss = 0.1016\n",
            "Epoch 3237/3334\n",
            "Epoch 3237: Training Accuracy = 0.9805, Training Loss = 0.0996, Validation Accuracy = 0.9897, Validation Loss = 0.0988\n",
            "Epoch 3238/3334\n",
            "Epoch 3238: Training Accuracy = 0.9805, Training Loss = 0.0996, Validation Accuracy = 0.9897, Validation Loss = 0.0988\n",
            "Epoch 3239/3334\n",
            "Epoch 3239: Training Accuracy = 0.9922, Training Loss = 0.0633, Validation Accuracy = 0.9897, Validation Loss = 0.1071\n",
            "Epoch 3240/3334\n",
            "Epoch 3240: Training Accuracy = 0.9922, Training Loss = 0.0633, Validation Accuracy = 0.9897, Validation Loss = 0.1071\n",
            "Epoch 3241/3334\n",
            "Epoch 3241: Training Accuracy = 0.6660, Training Loss = 1.9536, Validation Accuracy = 0.4189, Validation Loss = 2.4929\n",
            "Epoch 3242/3334\n",
            "Epoch 3242: Training Accuracy = 0.9629, Training Loss = 0.5302, Validation Accuracy = 0.9206, Validation Loss = 0.6462\n",
            "Epoch 3243/3334\n",
            "Epoch 3243: Training Accuracy = 0.9629, Training Loss = 0.5302, Validation Accuracy = 0.9206, Validation Loss = 0.6462\n",
            "Epoch 3244/3334\n",
            "Epoch 3244: Training Accuracy = 0.9961, Training Loss = 0.1834, Validation Accuracy = 0.9856, Validation Loss = 0.2894\n",
            "Epoch 3245/3334\n",
            "Epoch 3245: Training Accuracy = 0.9961, Training Loss = 0.1834, Validation Accuracy = 0.9856, Validation Loss = 0.2894\n",
            "Epoch 3246/3334\n",
            "Epoch 3246: Training Accuracy = 0.9902, Training Loss = 0.1355, Validation Accuracy = 0.9891, Validation Loss = 0.1907\n",
            "Epoch 3247/3334\n",
            "Epoch 3247: Training Accuracy = 0.9902, Training Loss = 0.0869, Validation Accuracy = 0.9895, Validation Loss = 0.1305\n",
            "Epoch 3248/3334\n",
            "Epoch 3248: Training Accuracy = 0.9902, Training Loss = 0.0869, Validation Accuracy = 0.9895, Validation Loss = 0.1305\n",
            "Epoch 3249/3334\n",
            "Epoch 3249: Training Accuracy = 0.9980, Training Loss = 0.0462, Validation Accuracy = 0.9897, Validation Loss = 0.1122\n",
            "Epoch 3250/3334\n",
            "Epoch 3250: Training Accuracy = 0.9980, Training Loss = 0.0462, Validation Accuracy = 0.9897, Validation Loss = 0.1122\n",
            "Epoch 3251/3334\n",
            "Epoch 3251: Training Accuracy = 0.9844, Training Loss = 0.0843, Validation Accuracy = 0.9897, Validation Loss = 0.1052\n",
            "Epoch 3252/3334\n",
            "Epoch 3252: Training Accuracy = 0.9961, Training Loss = 0.0433, Validation Accuracy = 0.9897, Validation Loss = 0.1013\n",
            "Epoch 3253/3334\n",
            "Epoch 3253: Training Accuracy = 0.9961, Training Loss = 0.0433, Validation Accuracy = 0.9897, Validation Loss = 0.1013\n",
            "Epoch 3254/3334\n",
            "Epoch 3254: Training Accuracy = 0.9785, Training Loss = 0.1031, Validation Accuracy = 0.9897, Validation Loss = 0.0989\n",
            "Epoch 3255/3334\n",
            "Epoch 3255: Training Accuracy = 0.9785, Training Loss = 0.1031, Validation Accuracy = 0.9897, Validation Loss = 0.0989\n",
            "Epoch 3256/3334\n",
            "Epoch 3256: Training Accuracy = 0.9883, Training Loss = 0.0669, Validation Accuracy = 0.9897, Validation Loss = 0.0980\n",
            "Epoch 3257/3334\n",
            "Epoch 3257: Training Accuracy = 0.9902, Training Loss = 0.0628, Validation Accuracy = 0.9897, Validation Loss = 0.0999\n",
            "Epoch 3258/3334\n",
            "Epoch 3258: Training Accuracy = 0.9902, Training Loss = 0.0628, Validation Accuracy = 0.9897, Validation Loss = 0.0999\n",
            "Epoch 3259/3334\n",
            "Epoch 3259: Training Accuracy = 0.9941, Training Loss = 0.0468, Validation Accuracy = 0.9897, Validation Loss = 0.0964\n",
            "Epoch 3260/3334\n",
            "Epoch 3260: Training Accuracy = 0.9941, Training Loss = 0.0468, Validation Accuracy = 0.9897, Validation Loss = 0.0964\n",
            "Epoch 3261/3334\n",
            "Epoch 3261: Training Accuracy = 0.9863, Training Loss = 0.0726, Validation Accuracy = 0.9897, Validation Loss = 0.0967\n",
            "Epoch 3262/3334\n",
            "Epoch 3262: Training Accuracy = 0.9902, Training Loss = 0.0602, Validation Accuracy = 0.9897, Validation Loss = 0.0953\n",
            "Epoch 3263/3334\n",
            "Epoch 3263: Training Accuracy = 0.9902, Training Loss = 0.0602, Validation Accuracy = 0.9897, Validation Loss = 0.0953\n",
            "Epoch 3264/3334\n",
            "Epoch 3264: Training Accuracy = 0.9941, Training Loss = 0.0444, Validation Accuracy = 0.9897, Validation Loss = 0.0943\n",
            "Epoch 3265/3334\n",
            "Epoch 3265: Training Accuracy = 0.9941, Training Loss = 0.0444, Validation Accuracy = 0.9897, Validation Loss = 0.0943\n",
            "Epoch 3266/3334\n",
            "Epoch 3266: Training Accuracy = 0.9863, Training Loss = 0.0699, Validation Accuracy = 0.9897, Validation Loss = 0.0958\n",
            "Epoch 3267/3334\n",
            "Epoch 3267: Training Accuracy = 0.9941, Training Loss = 0.0446, Validation Accuracy = 0.9897, Validation Loss = 0.0926\n",
            "Epoch 3268/3334\n",
            "Epoch 3268: Training Accuracy = 0.9941, Training Loss = 0.0446, Validation Accuracy = 0.9897, Validation Loss = 0.0926\n",
            "Epoch 3269/3334\n",
            "Epoch 3269: Training Accuracy = 0.9863, Training Loss = 0.0709, Validation Accuracy = 0.9897, Validation Loss = 0.0956\n",
            "Epoch 3270/3334\n",
            "Epoch 3270: Training Accuracy = 0.9863, Training Loss = 0.0709, Validation Accuracy = 0.9897, Validation Loss = 0.0956\n",
            "Epoch 3271/3334\n",
            "Epoch 3271: Training Accuracy = 0.9961, Training Loss = 0.0394, Validation Accuracy = 0.9897, Validation Loss = 0.0962\n",
            "Epoch 3272/3334\n",
            "Epoch 3272: Training Accuracy = 0.9902, Training Loss = 0.0635, Validation Accuracy = 0.9897, Validation Loss = 0.0982\n",
            "Epoch 3273/3334\n",
            "Epoch 3273: Training Accuracy = 0.9902, Training Loss = 0.0635, Validation Accuracy = 0.9897, Validation Loss = 0.0982\n",
            "Epoch 3274/3334\n",
            "Epoch 3274: Training Accuracy = 0.9863, Training Loss = 0.0895, Validation Accuracy = 0.9842, Validation Loss = 0.2436\n",
            "Epoch 3275/3334\n",
            "Epoch 3275: Training Accuracy = 0.9863, Training Loss = 0.0895, Validation Accuracy = 0.9842, Validation Loss = 0.2436\n",
            "Epoch 3276/3334\n",
            "Epoch 3276: Training Accuracy = 0.6191, Training Loss = 1.6774, Validation Accuracy = 0.6548, Validation Loss = 1.5167\n",
            "Epoch 3277/3334\n",
            "Epoch 3277: Training Accuracy = 0.9102, Training Loss = 0.5850, Validation Accuracy = 0.9233, Validation Loss = 0.6046\n",
            "Epoch 3278/3334\n",
            "Epoch 3278: Training Accuracy = 0.9102, Training Loss = 0.5850, Validation Accuracy = 0.9233, Validation Loss = 0.6046\n",
            "Epoch 3279/3334\n",
            "Epoch 3279: Training Accuracy = 0.9707, Training Loss = 0.2934, Validation Accuracy = 0.9772, Validation Loss = 0.3093\n",
            "Epoch 3280/3334\n",
            "Epoch 3280: Training Accuracy = 0.9707, Training Loss = 0.2934, Validation Accuracy = 0.9772, Validation Loss = 0.3093\n",
            "Epoch 3281/3334\n",
            "Epoch 3281: Training Accuracy = 0.9902, Training Loss = 0.1240, Validation Accuracy = 0.9886, Validation Loss = 0.1754\n",
            "Epoch 3282/3334\n",
            "Epoch 3282: Training Accuracy = 0.9863, Training Loss = 0.1066, Validation Accuracy = 0.9897, Validation Loss = 0.1355\n",
            "Epoch 3283/3334\n",
            "Epoch 3283: Training Accuracy = 0.9863, Training Loss = 0.1066, Validation Accuracy = 0.9897, Validation Loss = 0.1355\n",
            "Epoch 3284/3334\n",
            "Epoch 3284: Training Accuracy = 0.9824, Training Loss = 0.1110, Validation Accuracy = 0.9897, Validation Loss = 0.1178\n",
            "Epoch 3285/3334\n",
            "Epoch 3285: Training Accuracy = 0.9824, Training Loss = 0.1110, Validation Accuracy = 0.9897, Validation Loss = 0.1178\n",
            "Epoch 3286/3334\n",
            "Epoch 3286: Training Accuracy = 0.9941, Training Loss = 0.0543, Validation Accuracy = 0.9897, Validation Loss = 0.1098\n",
            "Epoch 3287/3334\n",
            "Epoch 3287: Training Accuracy = 0.9922, Training Loss = 0.0670, Validation Accuracy = 0.9897, Validation Loss = 0.1055\n",
            "Epoch 3288/3334\n",
            "Epoch 3288: Training Accuracy = 0.9922, Training Loss = 0.0670, Validation Accuracy = 0.9897, Validation Loss = 0.1055\n",
            "Epoch 3289/3334\n",
            "Epoch 3289: Training Accuracy = 0.9883, Training Loss = 0.0733, Validation Accuracy = 0.9897, Validation Loss = 0.1041\n",
            "Epoch 3290/3334\n",
            "Epoch 3290: Training Accuracy = 0.9883, Training Loss = 0.0733, Validation Accuracy = 0.9897, Validation Loss = 0.1041\n",
            "Epoch 3291/3334\n",
            "Epoch 3291: Training Accuracy = 0.9922, Training Loss = 0.0641, Validation Accuracy = 0.9897, Validation Loss = 0.1033\n",
            "Epoch 3292/3334\n",
            "Epoch 3292: Training Accuracy = 0.9863, Training Loss = 0.0773, Validation Accuracy = 0.9897, Validation Loss = 0.1025\n",
            "Epoch 3293/3334\n",
            "Epoch 3293: Training Accuracy = 0.9863, Training Loss = 0.0773, Validation Accuracy = 0.9897, Validation Loss = 0.1025\n",
            "Epoch 3294/3334\n",
            "Epoch 3294: Training Accuracy = 0.9785, Training Loss = 0.1063, Validation Accuracy = 0.9897, Validation Loss = 0.1013\n",
            "Epoch 3295/3334\n",
            "Epoch 3295: Training Accuracy = 0.9785, Training Loss = 0.1063, Validation Accuracy = 0.9897, Validation Loss = 0.1013\n",
            "Epoch 3296/3334\n",
            "Epoch 3296: Training Accuracy = 0.9941, Training Loss = 0.0494, Validation Accuracy = 0.9897, Validation Loss = 0.1015\n",
            "Epoch 3297/3334\n",
            "Epoch 3297: Training Accuracy = 0.9844, Training Loss = 0.0859, Validation Accuracy = 0.9897, Validation Loss = 0.1012\n",
            "Epoch 3298/3334\n",
            "Epoch 3298: Training Accuracy = 0.9844, Training Loss = 0.0859, Validation Accuracy = 0.9897, Validation Loss = 0.1012\n",
            "Epoch 3299/3334\n",
            "Epoch 3299: Training Accuracy = 0.9863, Training Loss = 0.0761, Validation Accuracy = 0.9897, Validation Loss = 0.1023\n",
            "Epoch 3300/3334\n",
            "Epoch 3300: Training Accuracy = 0.9863, Training Loss = 0.0761, Validation Accuracy = 0.9897, Validation Loss = 0.1023\n",
            "Epoch 3301/3334\n",
            "Epoch 3301: Training Accuracy = 0.9844, Training Loss = 0.0812, Validation Accuracy = 0.9897, Validation Loss = 0.0996\n",
            "Epoch 3302/3334\n",
            "Epoch 3302: Training Accuracy = 0.9863, Training Loss = 0.0816, Validation Accuracy = 0.9897, Validation Loss = 0.1004\n",
            "Epoch 3303/3334\n",
            "Epoch 3303: Training Accuracy = 0.9863, Training Loss = 0.0816, Validation Accuracy = 0.9897, Validation Loss = 0.1004\n",
            "Epoch 3304/3334\n",
            "Epoch 3304: Training Accuracy = 0.9863, Training Loss = 0.0807, Validation Accuracy = 0.9897, Validation Loss = 0.0973\n",
            "Epoch 3305/3334\n",
            "Epoch 3305: Training Accuracy = 0.9863, Training Loss = 0.0807, Validation Accuracy = 0.9897, Validation Loss = 0.0973\n",
            "Epoch 3306/3334\n",
            "Epoch 3306: Training Accuracy = 0.9902, Training Loss = 0.0607, Validation Accuracy = 0.9897, Validation Loss = 0.0989\n",
            "Epoch 3307/3334\n",
            "Epoch 3307: Training Accuracy = 0.9941, Training Loss = 0.0513, Validation Accuracy = 0.9897, Validation Loss = 0.0989\n",
            "Epoch 3308/3334\n",
            "Epoch 3308: Training Accuracy = 0.9941, Training Loss = 0.0513, Validation Accuracy = 0.9897, Validation Loss = 0.0989\n",
            "Epoch 3309/3334\n",
            "Epoch 3309: Training Accuracy = 0.9961, Training Loss = 0.0497, Validation Accuracy = 0.9897, Validation Loss = 0.1071\n",
            "Epoch 3310/3334\n",
            "Epoch 3310: Training Accuracy = 0.9961, Training Loss = 0.0497, Validation Accuracy = 0.9897, Validation Loss = 0.1071\n",
            "Epoch 3311/3334\n",
            "Epoch 3311: Training Accuracy = 0.4316, Training Loss = 2.3707, Validation Accuracy = 0.5276, Validation Loss = 2.0602\n",
            "Epoch 3312/3334\n",
            "Epoch 3312: Training Accuracy = 0.9316, Training Loss = 0.5524, Validation Accuracy = 0.9238, Validation Loss = 0.5883\n",
            "Epoch 3313/3334\n",
            "Epoch 3313: Training Accuracy = 0.9316, Training Loss = 0.5524, Validation Accuracy = 0.9238, Validation Loss = 0.5883\n",
            "Epoch 3314/3334\n",
            "Epoch 3314: Training Accuracy = 0.9863, Training Loss = 0.2391, Validation Accuracy = 0.9818, Validation Loss = 0.3013\n",
            "Epoch 3315/3334\n",
            "Epoch 3315: Training Accuracy = 0.9863, Training Loss = 0.2391, Validation Accuracy = 0.9818, Validation Loss = 0.3013\n",
            "Epoch 3316/3334\n",
            "Epoch 3316: Training Accuracy = 0.9922, Training Loss = 0.1139, Validation Accuracy = 0.9894, Validation Loss = 0.1769\n",
            "Epoch 3317/3334\n",
            "Epoch 3317: Training Accuracy = 0.9863, Training Loss = 0.1089, Validation Accuracy = 0.9897, Validation Loss = 0.1365\n",
            "Epoch 3318/3334\n",
            "Epoch 3318: Training Accuracy = 0.9863, Training Loss = 0.1089, Validation Accuracy = 0.9897, Validation Loss = 0.1365\n",
            "Epoch 3319/3334\n",
            "Epoch 3319: Training Accuracy = 0.9922, Training Loss = 0.0721, Validation Accuracy = 0.9897, Validation Loss = 0.1222\n",
            "Epoch 3320/3334\n",
            "Epoch 3320: Training Accuracy = 0.9922, Training Loss = 0.0721, Validation Accuracy = 0.9897, Validation Loss = 0.1222\n",
            "Epoch 3321/3334\n",
            "Epoch 3321: Training Accuracy = 0.9902, Training Loss = 0.0769, Validation Accuracy = 0.9897, Validation Loss = 0.1139\n",
            "Epoch 3322/3334\n",
            "Epoch 3322: Training Accuracy = 0.9941, Training Loss = 0.0588, Validation Accuracy = 0.9897, Validation Loss = 0.1117\n",
            "Epoch 3323/3334\n",
            "Epoch 3323: Training Accuracy = 0.9941, Training Loss = 0.0588, Validation Accuracy = 0.9897, Validation Loss = 0.1117\n",
            "Epoch 3324/3334\n",
            "Epoch 3324: Training Accuracy = 0.9824, Training Loss = 0.0952, Validation Accuracy = 0.9897, Validation Loss = 0.1081\n",
            "Epoch 3325/3334\n",
            "Epoch 3325: Training Accuracy = 0.9824, Training Loss = 0.0952, Validation Accuracy = 0.9897, Validation Loss = 0.1081\n",
            "Epoch 3326/3334\n",
            "Epoch 3326: Training Accuracy = 0.9824, Training Loss = 0.0951, Validation Accuracy = 0.9897, Validation Loss = 0.1074\n",
            "Epoch 3327/3334\n",
            "Epoch 3327: Training Accuracy = 0.9922, Training Loss = 0.0625, Validation Accuracy = 0.9897, Validation Loss = 0.1074\n",
            "Epoch 3328/3334\n",
            "Epoch 3328: Training Accuracy = 0.9922, Training Loss = 0.0625, Validation Accuracy = 0.9897, Validation Loss = 0.1074\n",
            "Epoch 3329/3334\n",
            "Epoch 3329: Training Accuracy = 0.9902, Training Loss = 0.0671, Validation Accuracy = 0.9897, Validation Loss = 0.1094\n",
            "Epoch 3330/3334\n",
            "Epoch 3330: Training Accuracy = 0.9902, Training Loss = 0.0671, Validation Accuracy = 0.9897, Validation Loss = 0.1094\n",
            "Epoch 3331/3334\n",
            "Epoch 3331: Training Accuracy = 0.9863, Training Loss = 0.0872, Validation Accuracy = 0.9897, Validation Loss = 0.1069\n",
            "Epoch 3332/3334\n",
            "Epoch 3332: Training Accuracy = 0.9902, Training Loss = 0.0673, Validation Accuracy = 0.9897, Validation Loss = 0.1072\n",
            "Epoch 3333/3334\n",
            "Epoch 3333: Training Accuracy = 0.9902, Training Loss = 0.0673, Validation Accuracy = 0.9897, Validation Loss = 0.1072\n",
            "Epoch 3334/3334\n",
            "Epoch 3334: Training Accuracy = 0.9902, Training Loss = 0.0673, Validation Accuracy = 0.9897, Validation Loss = 0.1072\n",
            "Stopping early as maximum number of steps has been reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}