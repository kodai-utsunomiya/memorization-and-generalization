{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsb+a+R4XiQZjCnrqRDdXE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kodai-utsunomiya/memorization-and-generalization/blob/main/numerical_experiments/exp_3/exp_3_v5_frozen_ntk_dynamics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class BinaryDataset:\n",
        "    def __init__(self, n, k, train_size, test_size, data_seed, normalize=False, device=None):\n",
        "        self.n = n\n",
        "        self.k = k\n",
        "        self.train_size = train_size\n",
        "        self.test_size = test_size\n",
        "        self.data_seed = data_seed\n",
        "        self.normalize = normalize\n",
        "        self.device = device\n",
        "\n",
        "        (self.train_inputs, self.train_outputs), (self.test_inputs, self.test_outputs) = self._prepare_data()\n",
        "\n",
        "    def _prepare_data(self):\n",
        "        np.random.seed(self.data_seed)\n",
        "        total_size = self.train_size + self.test_size\n",
        "\n",
        "        binary_strings = {tuple(np.random.randint(2, size=self.n)) for _ in range(total_size)}\n",
        "        while len(binary_strings) < total_size:\n",
        "            binary_strings.add(tuple(np.random.randint(2, size=self.n)))\n",
        "\n",
        "        binary_strings = list(binary_strings)\n",
        "        inputs = np.array(binary_strings, dtype=np.float32)\n",
        "        outputs = np.sum(inputs[:, :self.k], axis=-1) % 2\n",
        "\n",
        "        # # 出力ラベルを 0 -> -1, 1 -> 1 に変換（ヒンジ損失用）\n",
        "        # outputs = 2 * outputs - 1\n",
        "\n",
        "        # データの正規化を行う場合\n",
        "        if self.normalize:\n",
        "            inputs = (inputs - inputs.mean(axis=0))\n",
        "            norm = np.linalg.norm(inputs, axis=1, keepdims=True)\n",
        "            inputs = (inputs / np.maximum(norm, 1e-8))  # ゼロ除算防止\n",
        "\n",
        "        indices = np.random.permutation(total_size)\n",
        "        train_indices, test_indices = indices[:self.train_size], indices[self.train_size:]\n",
        "\n",
        "        train_inputs = torch.tensor(inputs[train_indices], dtype=torch.float32).to(self.device)\n",
        "        train_outputs = torch.tensor(outputs[train_indices], dtype=torch.float32).to(self.device)\n",
        "        test_inputs = torch.tensor(inputs[test_indices], dtype=torch.float32).to(self.device)\n",
        "        test_outputs = torch.tensor(outputs[test_indices], dtype=torch.float32).to(self.device)\n",
        "\n",
        "        return (train_inputs, train_outputs), (test_inputs, test_outputs)\n",
        "\n",
        "    def get_data(self):\n",
        "        return (self.train_inputs, self.train_outputs), (self.test_inputs, self.test_outputs)\n",
        "\n",
        "\n",
        "###################################################################\n",
        "\n",
        "import functools\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FC(nn.Module):\n",
        "    def __init__(self, d, h, L, act, bias=False):\n",
        "        super().__init__()\n",
        "\n",
        "        hh = d\n",
        "        for i in range(L):\n",
        "            W = torch.randn(h, hh)\n",
        "\n",
        "            n = max(1, 128 * 256 // hh)\n",
        "            W = nn.ParameterList([nn.Parameter(W[j: j+n]) for j in range(0, len(W), n)])\n",
        "\n",
        "            setattr(self, \"W{}\".format(i), W)\n",
        "            if bias:\n",
        "                self.register_parameter(\"B{}\".format(i), nn.Parameter(torch.zeros(h)))\n",
        "            hh = h\n",
        "\n",
        "        self.register_parameter(\"W{}\".format(L), nn.Parameter(torch.randn(1, hh)))\n",
        "        if bias:\n",
        "            self.register_parameter(\"B{}\".format(L), nn.Parameter(torch.zeros(1)))\n",
        "\n",
        "        self.L = L\n",
        "        self.act = act\n",
        "        self.bias = bias\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(self.L + 1):\n",
        "            W = getattr(self, \"W{}\".format(i))\n",
        "\n",
        "            if isinstance(W, nn.ParameterList):\n",
        "                W = torch.cat(list(W))\n",
        "\n",
        "            if self.bias:\n",
        "                B = self.bias * getattr(self, \"B{}\".format(i))\n",
        "            else:\n",
        "                B = 0\n",
        "\n",
        "            h = x.size(1)\n",
        "\n",
        "            if i < self.L:\n",
        "                x = x @ (W.t() / h ** 0.5)\n",
        "                x = self.act(x + B)\n",
        "            else:\n",
        "                x = x @ (W.t() / h ** 0.5) + B\n",
        "\n",
        "        return x.view(-1)\n",
        "\n",
        "#################################################################################\n",
        "def gradient(outputs, inputs, grad_outputs=None, retain_graph=None, create_graph=False):\n",
        "    r'''\n",
        "    Compute the gradient of `outputs` with respect to `inputs`\n",
        "    ```\n",
        "    gradient(x.sum(), x)\n",
        "    gradient((x * y).sum(), [x, y])\n",
        "    ```\n",
        "    '''\n",
        "    if torch.is_tensor(inputs):\n",
        "        inputs = [inputs]\n",
        "    else:\n",
        "        inputs = list(inputs)\n",
        "    grads = torch.autograd.grad(outputs, inputs, grad_outputs,\n",
        "                                allow_unused=True,\n",
        "                                retain_graph=retain_graph,\n",
        "                                create_graph=create_graph)\n",
        "    grads = [x if x is not None else torch.zeros_like(y) for x, y in zip(grads, inputs)]\n",
        "    return torch.cat([x.contiguous().view(-1) for x in grads])\n",
        "\n",
        "########################################################################################\n",
        "def compute_kernels(f, xtr, xte):\n",
        "\n",
        "    ktrtr = xtr.new_zeros(len(xtr), len(xtr))\n",
        "    ktetr = xtr.new_zeros(len(xte), len(xtr))\n",
        "    ktete = xtr.new_zeros(len(xte), len(xte))\n",
        "\n",
        "    params = []\n",
        "    current = []\n",
        "    for p in sorted(f.parameters(), key=lambda p: p.numel(), reverse=True):\n",
        "        current.append(p)\n",
        "        if sum(p.numel() for p in current) > 2e9 // (8 * (len(xtr) + len(xte))):\n",
        "            if len(current) > 1:\n",
        "                params.append(current[:-1])\n",
        "                current = current[-1:]\n",
        "            else:\n",
        "                params.append(current)\n",
        "                current = []\n",
        "    if len(current) > 0:\n",
        "        params.append(current)\n",
        "\n",
        "    for i, p in enumerate(params):\n",
        "        print(\"[{}/{}] [len={} numel={}]\".format(i, len(params), len(p), sum(x.numel() for x in p)), flush=True)\n",
        "\n",
        "        jtr = xtr.new_empty(len(xtr), sum(u.numel() for u in p))  # (P, N~)\n",
        "        jte = xte.new_empty(len(xte), sum(u.numel() for u in p))  # (P, N~)\n",
        "\n",
        "        for j, x in enumerate(xtr):\n",
        "            jtr[j] = gradient(f(x[None]), p)  # (N~)\n",
        "\n",
        "        for j, x in enumerate(xte):\n",
        "            jte[j] = gradient(f(x[None]), p)  # (N~)\n",
        "\n",
        "        ktrtr.add_(jtr @ jtr.t())\n",
        "        ktetr.add_(jte @ jtr.t())\n",
        "        ktete.add_(jte @ jte.t())\n",
        "        del jtr, jte\n",
        "\n",
        "    return ktrtr, ktetr, ktete"
      ],
      "metadata": {
        "id": "vNMYzp4WJ1uv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frozen NTK dynamics"
      ],
      "metadata": {
        "id": "R3WTZB4qy6xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import itertools\n",
        "import math\n",
        "from time import perf_counter\n",
        "\n",
        "def loglinspace(rate, step, end=None):\n",
        "    t = 0\n",
        "    while end is None or t <= end:\n",
        "        yield t\n",
        "        t = int(t + 1 + step * (1 - math.exp(-t * rate / step)))\n",
        "\n",
        "def train_kernel(args, ktrtr, ytr, tau, max_walltime, alpha, learning_rate, loss_prim, max_dgrad=math.inf, max_dout=math.inf):\n",
        "    # 初期化\n",
        "    otr = torch.zeros(len(ytr), dtype=ktrtr.dtype, device=ktrtr.device)\n",
        "    gradient_update = torch.clone(otr)\n",
        "\n",
        "    last_lr_change_step = 0  # 最後に学習率が変更されたステップ\n",
        "\n",
        "    checkpoint_generator = loglinspace(0.01, 100)\n",
        "    checkpoint = next(checkpoint_generator)  # 最初のチェックポイント\n",
        "    start_time = perf_counter()  # 経過時間計測の開始\n",
        "    converged = False\n",
        "\n",
        "    # 初期の損失関数の勾配を計算\n",
        "    lprim = loss_prim(otr, ytr)\n",
        "    grad = ktrtr @ lprim / len(ytr)\n",
        "\n",
        "    # メインループ\n",
        "    for step in itertools.count():\n",
        "        if step >= args.max_step:\n",
        "            break\n",
        "\n",
        "        # 現在の状態を保存\n",
        "        state = copy.deepcopy((otr, gradient_update))\n",
        "\n",
        "        while True:\n",
        "            gradient_update = -grad.clone()\n",
        "\n",
        "            # 出力を更新\n",
        "            otr = otr + learning_rate * gradient_update\n",
        "\n",
        "            # 新しい勾配を計算\n",
        "            lprim = loss_prim(otr, ytr)\n",
        "            new_grad = ktrtr @ lprim / len(ytr)\n",
        "\n",
        "            # 出力変化量 (dout) の計算\n",
        "            dout = (learning_rate * alpha * gradient_update).abs().max().item()\n",
        "\n",
        "            # 勾配の変化量 (dgrad) の計算\n",
        "            if grad.norm() == 0 or new_grad.norm() == 0:\n",
        "                dgrad = 0\n",
        "            else:\n",
        "                dgrad = ((grad - new_grad).norm() ** 2 / (grad.norm() * new_grad.norm())).item()\n",
        "\n",
        "            # 変化量が許容範囲内なら学習率を調整\n",
        "            if dgrad < max_dgrad and dout < max_dout:\n",
        "                if dgrad < 0.1 * max_dgrad and dout < 0.1 * max_dout:\n",
        "                    learning_rate *= 1.1  # 学習率を大きくする\n",
        "                break\n",
        "\n",
        "            # 学習率を小さくする\n",
        "            learning_rate /= 10\n",
        "\n",
        "            print(\"[Step {:d}/{:d}] [Progress: {:.2%}] [learning rate: {:.1e}]\".format(step, args.max_step, step / args.max_step, learning_rate), flush=True)\n",
        "\n",
        "            # 状態をリセット\n",
        "            last_lr_change_step = step\n",
        "            otr, gradient_update = state\n",
        "\n",
        "        # 勾配を更新\n",
        "        grad = new_grad\n",
        "\n",
        "        save = False\n",
        "        if step == checkpoint:\n",
        "            checkpoint = next(checkpoint_generator)\n",
        "            assert checkpoint > step\n",
        "            save = True\n",
        "\n",
        "        if save:\n",
        "            state = {\n",
        "                'step': step,\n",
        "                'wall': perf_counter() - start_time,\n",
        "                'learning_rate': learning_rate,\n",
        "                'dgrad': dgrad,\n",
        "                'dout': dout,\n",
        "                'grad_norm': grad.norm().item(),\n",
        "            }\n",
        "            yield otr, gradient_update, grad, state, converged\n",
        "\n",
        "        if converged:\n",
        "            break\n",
        "\n",
        "        # 最大経過時間を超えたら終了\n",
        "        if perf_counter() > start_time + max_walltime:\n",
        "            break\n",
        "\n",
        "        # 出力に NaN が含まれていたら終了\n",
        "        if torch.isnan(otr).any():\n",
        "            break"
      ],
      "metadata": {
        "id": "fkHYa7LT0ik_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "from functools import partial\n",
        "from time import perf_counter\n",
        "\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.device = 'cpu'\n",
        "        self.init_seed = 0\n",
        "        self.data_seed = 0\n",
        "        self.batch_seed = 0\n",
        "        self.max_step = 50000\n",
        "        self.n = 13\n",
        "        self.k = 3\n",
        "        self.train_size = 3000\n",
        "        self.test_size = 1900\n",
        "        self.normalize = False\n",
        "        self.bias = True\n",
        "        self.L = 3\n",
        "        self.h = 50\n",
        "        self.learning_rate = 0.01\n",
        "        self.init_kernel = 1\n",
        "        self.store_kernel = 0\n",
        "        self.delta_kernel = 0\n",
        "        self.save_outputs = 0\n",
        "        self.alpha = 1\n",
        "        self.f0 = 1\n",
        "        self.train_time = 18000\n",
        "        self.max_dgrad = 1e-4\n",
        "        self.max_dout = 0.1\n",
        "        self.loss = 'cross_entropy'\n",
        "        self.pickle = 'results.pkl'\n",
        "        self.track_test_metrics = True\n",
        "\n",
        "def loss_func(args, outputs, targets):\n",
        "    if args.loss == 'mse':\n",
        "        return ((targets - outputs) ** 2).mean()\n",
        "    elif args.loss == 'cross_entropy':\n",
        "        return F.binary_cross_entropy_with_logits(outputs, targets)\n",
        "\n",
        "def loss_func_prime(args, outputs, targets):\n",
        "    if args.loss == 'mse':\n",
        "        return -2 * (targets - outputs) / outputs.size(0)\n",
        "    elif args.loss == 'cross_entropy':\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        grad = probs - targets\n",
        "        return grad / outputs.size(0)\n",
        "\n",
        "def run_kernel(args, ktrtr, ktetr, ktete, f, xtr, ytr, xte, yte):\n",
        "    assert args.f0 == 1\n",
        "\n",
        "    dynamics = []\n",
        "    step_counter = 0\n",
        "\n",
        "    tau = 0\n",
        "\n",
        "    for otr, _gradient_update, _grad, state, _converged in train_kernel(args, ktrtr, ytr, tau, args.train_time, args.alpha, args.learning_rate, partial(loss_func_prime, args), args.max_dgrad, args.max_dout):\n",
        "        step_counter += 1\n",
        "\n",
        "        preds = torch.sigmoid(otr) > 0.5\n",
        "        train_accuracy = (preds.int() == ytr.int()).float().mean().item()\n",
        "\n",
        "        state['train'] = {\n",
        "            'loss': loss_func(args, otr, ytr).item(),\n",
        "            'aloss': args.alpha * loss_func(args, otr, ytr).item(),\n",
        "            'accuracy': train_accuracy,\n",
        "            'dfnorm': otr.pow(2).mean().sqrt(),\n",
        "            'outputs': otr if args.save_outputs else None,\n",
        "            'labels': ytr if args.save_outputs else None,\n",
        "        }\n",
        "\n",
        "        if args.track_test_metrics and step_counter % 50 == 0:\n",
        "            c = torch.linalg.lstsq(ktrtr, otr.view(-1, 1)).solution.flatten()\n",
        "\n",
        "            if len(xte) > len(xtr):\n",
        "                a = gradient(f(xtr) @ c, f.parameters())\n",
        "                ote = torch.stack([gradient(f(x[None]), f.parameters()) @ a for x in xte])\n",
        "            else:\n",
        "                ote = ktetr @ c\n",
        "\n",
        "            test_loss = loss_func(args, ote, yte).item()\n",
        "            test_preds = torch.sigmoid(ote) > 0.5\n",
        "            test_accuracy = (test_preds.int() == yte.int()).float().mean().item()\n",
        "\n",
        "            state['test'] = {\n",
        "                'loss': test_loss,\n",
        "                'accuracy': test_accuracy,\n",
        "            }\n",
        "\n",
        "            print(f\"[Step {state['step']:d}/{args.max_step}] [Time: {state['wall']:.0f}s] \"\n",
        "                  f\"[Train Loss: {state['train']['loss']:.2e}] [Train Acc: {state['train']['accuracy']:.2f}] \"\n",
        "                  f\"[Eval Loss: {state['test']['loss']:.2e}] [Eval Acc: {state['test']['accuracy']:.2f}]\",\n",
        "                  flush=True)\n",
        "        else:\n",
        "            state['test'] = {\n",
        "                'loss': None,\n",
        "                'accuracy': None,\n",
        "            }\n",
        "\n",
        "            print(f\"[Step {state['step']:d}/{args.max_step}] [Time: {state['wall']:.0f}s] \"\n",
        "                  f\"[Train Loss: {state['train']['aloss']:.2e}] [Train Acc: {state['train']['accuracy']:.2f}]\",\n",
        "                  flush=True)\n",
        "\n",
        "        dynamics.append(state)\n",
        "\n",
        "    c = torch.linalg.lstsq(ktrtr, otr.view(-1, 1)).solution.flatten()\n",
        "    if len(xte) > len(xtr):\n",
        "        a = gradient(f(xtr) @ c, f.parameters())\n",
        "        ote = torch.stack([gradient(f(x[None]), f.parameters()) @ a for x in xte])\n",
        "    else:\n",
        "        ote = ktetr @ c\n",
        "\n",
        "    final_test_loss = loss_func(args, ote, yte).item()\n",
        "    final_test_preds = torch.sigmoid(ote) > 0.5\n",
        "    final_test_accuracy = (final_test_preds.int() == yte.int()).float().mean().item()\n",
        "\n",
        "    dynamics[-1]['test'] = {\n",
        "        'loss': final_test_loss,\n",
        "        'accuracy': final_test_accuracy,\n",
        "    }\n",
        "\n",
        "    out = {\n",
        "        'dynamics': dynamics,\n",
        "        'train': {\n",
        "            'outputs': otr,\n",
        "            'labels': ytr,\n",
        "        },\n",
        "        'test': {\n",
        "            'outputs': ote,\n",
        "            'labels': yte,\n",
        "        },\n",
        "        'kernel': {\n",
        "            'train': {\n",
        "                'value': ktrtr.cpu() if args.store_kernel == 1 else None,\n",
        "            },\n",
        "            'test': {\n",
        "                'value': ktete.cpu() if args.store_kernel == 1 else None,\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "\n",
        "    return out\n",
        "\n",
        "def execute(args):\n",
        "    torch.set_default_dtype(torch.float64)\n",
        "\n",
        "    dataset = BinaryDataset(args.n, args.k, args.train_size, args.test_size, args.data_seed, args.normalize, args.device)\n",
        "    (xtr, ytr), (xte, yte) = dataset.get_data()\n",
        "\n",
        "    xtr = xtr.type(torch.get_default_dtype())\n",
        "    xte = xte.type(torch.get_default_dtype())\n",
        "    ytr = ytr.type(torch.get_default_dtype())\n",
        "    yte = yte.type(torch.get_default_dtype())\n",
        "\n",
        "    torch.manual_seed(args.init_seed + hash(args.alpha))\n",
        "\n",
        "    act = lambda x: 2 ** 0.5 * torch.relu(x)\n",
        "\n",
        "    xtr = xtr.flatten(1)\n",
        "    xte = xte.flatten(1)\n",
        "    f = FC(xtr.size(1), args.h, args.L, act, args.bias).to(args.device)\n",
        "\n",
        "    if args.delta_kernel == 1 or args.init_kernel == 1:\n",
        "        init_kernel = compute_kernels(f, xtr, xte[:len(xtr)])\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    if args.init_kernel == 1:\n",
        "        results['init_kernel'] = run_kernel(args, *init_kernel, f, xtr, ytr, xte, yte)\n",
        "\n",
        "    if args.delta_kernel == 1:\n",
        "        init_kernel = (init_kernel[0].cpu(), init_kernel[2].cpu())\n",
        "    elif args.init_kernel == 1:\n",
        "        del init_kernel\n",
        "\n",
        "    return {\n",
        "        'args': args,\n",
        "        'results': results\n",
        "    }\n",
        "\n",
        "\n",
        "#####################################\n",
        "\n",
        "args = Args()\n",
        "results_to_save = {'args': args}\n",
        "\n",
        "try:\n",
        "    results = execute(args)\n",
        "    results_to_save.update(results)\n",
        "\n",
        "    with open(args.pickle, 'wb') as f:\n",
        "        torch.save(results_to_save, f)\n",
        "except:\n",
        "    os.remove(args.pickle)\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSMuQJmHzct5",
        "outputId": "fcf17fd5-4346-4591-c87a-8bbeb1c5233f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0/1] [len=8 numel=5851]\n",
            "[Step 0/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 1/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 2/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 3/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 4/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 5/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 6/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 7/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 8/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 9/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 10/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 11/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 12/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 13/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 14/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 15/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 16/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 17/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 18/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 19/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 20/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 21/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 22/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 23/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 24/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 25/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 26/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 27/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 28/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 29/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 30/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 31/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 32/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 33/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 34/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 35/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 36/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 37/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 38/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 39/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 40/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 41/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 42/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 43/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 44/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 45/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 46/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 47/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 48/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 49/50000] [Time: 1s] [Train Loss: 6.93e-01] [Train Acc: 0.57] [Eval Loss: 6.93e-01] [Eval Acc: 0.54]\n",
            "[Step 50/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 51/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 52/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 53/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 54/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 55/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 56/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 57/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 58/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 59/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 60/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 61/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 62/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 63/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 64/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 65/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 66/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 67/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 68/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 69/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 70/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 71/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 72/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 73/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 74/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 75/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 76/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 77/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 78/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 79/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 80/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 81/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 82/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 83/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 84/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 85/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 86/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 87/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 88/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 89/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 90/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 91/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 92/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 93/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 94/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 95/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 96/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 97/50000] [Time: 4s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 98/50000] [Time: 4s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 99/50000] [Time: 4s] [Train Loss: 6.93e-01] [Train Acc: 0.56] [Eval Loss: 6.93e-01] [Eval Acc: 0.54]\n",
            "[Step 100/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 101/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 103/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 105/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 107/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 109/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 111/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 113/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 115/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 117/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 119/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 121/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 123/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 125/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 127/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 129/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 131/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 133/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 135/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 137/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 139/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 141/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 143/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 145/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 147/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 149/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 151/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 153/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 155/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 157/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 159/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 161/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 163/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 165/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 167/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 169/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 171/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 173/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 175/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 177/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 179/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 181/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 183/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 185/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 187/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 189/50000] [Time: 6s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 191/50000] [Time: 6s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 193/50000] [Time: 6s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 195/50000] [Time: 6s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 197/50000] [Time: 6s] [Train Loss: 6.92e-01] [Train Acc: 0.57] [Eval Loss: 6.93e-01] [Eval Acc: 0.55]\n",
            "[Step 199/50000] [Time: 8s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 201/50000] [Time: 8s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 203/50000] [Time: 8s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 206/50000] [Time: 8s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 209/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 212/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 215/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 218/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 221/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 224/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 227/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 230/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 233/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 236/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 239/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 242/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 245/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 248/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 251/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 254/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 257/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 260/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 263/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 266/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.57]\n",
            "[Step 269/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.57]\n",
            "[Step 272/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 275/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 278/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 281/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 284/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 287/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 290/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 293/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 296/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 299/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 302/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 305/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 309/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 313/50000] [Time: 9s] [Train Loss: 6.87e-01] [Train Acc: 0.58]\n",
            "[Step 317/50000] [Time: 9s] [Train Loss: 6.87e-01] [Train Acc: 0.58]\n",
            "[Step 321/50000] [Time: 9s] [Train Loss: 6.87e-01] [Train Acc: 0.58]\n",
            "[Step 325/50000] [Time: 9s] [Train Loss: 6.87e-01] [Train Acc: 0.58]\n",
            "[Step 329/50000] [Time: 9s] [Train Loss: 6.87e-01] [Train Acc: 0.58]\n",
            "[Step 333/50000] [Time: 9s] [Train Loss: 6.87e-01] [Train Acc: 0.58]\n",
            "[Step 337/50000] [Time: 9s] [Train Loss: 6.86e-01] [Train Acc: 0.58]\n",
            "[Step 341/50000] [Time: 10s] [Train Loss: 6.86e-01] [Train Acc: 0.58]\n",
            "[Step 345/50000] [Time: 10s] [Train Loss: 6.86e-01] [Train Acc: 0.58]\n",
            "[Step 349/50000] [Time: 10s] [Train Loss: 6.86e-01] [Train Acc: 0.58]\n",
            "[Step 353/50000] [Time: 10s] [Train Loss: 6.86e-01] [Train Acc: 0.58]\n",
            "[Step 357/50000] [Time: 10s] [Train Loss: 6.86e-01] [Train Acc: 0.58] [Eval Loss: 6.88e-01] [Eval Acc: 0.57]\n",
            "[Step 361/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.58]\n",
            "[Step 365/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.58]\n",
            "[Step 369/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.59]\n",
            "[Step 373/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.59]\n",
            "[Step 377/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.59]\n",
            "[Step 381/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.59]\n",
            "[Step 385/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.59]\n",
            "[Step 389/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.59]\n",
            "[Step 393/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.59]\n",
            "[Step 397/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.59]\n",
            "[Step 401/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.59]\n",
            "[Step 405/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.59]\n",
            "[Step 409/50000] [Time: 12s] [Train Loss: 6.83e-01] [Train Acc: 0.59]\n",
            "[Step 414/50000] [Time: 12s] [Train Loss: 6.83e-01] [Train Acc: 0.59]\n",
            "[Step 419/50000] [Time: 12s] [Train Loss: 6.83e-01] [Train Acc: 0.59]\n",
            "[Step 424/50000] [Time: 12s] [Train Loss: 6.83e-01] [Train Acc: 0.59]\n",
            "[Step 429/50000] [Time: 12s] [Train Loss: 6.83e-01] [Train Acc: 0.59]\n",
            "[Step 434/50000] [Time: 12s] [Train Loss: 6.82e-01] [Train Acc: 0.59]\n",
            "[Step 439/50000] [Time: 12s] [Train Loss: 6.82e-01] [Train Acc: 0.59]\n",
            "[Step 444/50000] [Time: 12s] [Train Loss: 6.82e-01] [Train Acc: 0.59]\n",
            "[Step 449/50000] [Time: 12s] [Train Loss: 6.82e-01] [Train Acc: 0.59]\n",
            "[Step 454/50000] [Time: 12s] [Train Loss: 6.81e-01] [Train Acc: 0.59]\n",
            "[Step 459/50000] [Time: 12s] [Train Loss: 6.81e-01] [Train Acc: 0.59]\n",
            "[Step 464/50000] [Time: 12s] [Train Loss: 6.81e-01] [Train Acc: 0.59]\n",
            "[Step 469/50000] [Time: 12s] [Train Loss: 6.81e-01] [Train Acc: 0.59]\n",
            "[Step 474/50000] [Time: 12s] [Train Loss: 6.81e-01] [Train Acc: 0.59]\n",
            "[Step 479/50000] [Time: 12s] [Train Loss: 6.80e-01] [Train Acc: 0.59]\n",
            "[Step 484/50000] [Time: 13s] [Train Loss: 6.80e-01] [Train Acc: 0.59]\n",
            "[Step 489/50000] [Time: 13s] [Train Loss: 6.80e-01] [Train Acc: 0.59]\n",
            "[Step 494/50000] [Time: 13s] [Train Loss: 6.80e-01] [Train Acc: 0.59]\n",
            "[Step 499/50000] [Time: 13s] [Train Loss: 6.80e-01] [Train Acc: 0.59]\n",
            "[Step 504/50000] [Time: 13s] [Train Loss: 6.79e-01] [Train Acc: 0.59]\n",
            "[Step 509/50000] [Time: 13s] [Train Loss: 6.79e-01] [Train Acc: 0.59]\n",
            "[Step 514/50000] [Time: 13s] [Train Loss: 6.79e-01] [Train Acc: 0.59]\n",
            "[Step 520/50000] [Time: 13s] [Train Loss: 6.79e-01] [Train Acc: 0.59]\n",
            "[Step 526/50000] [Time: 13s] [Train Loss: 6.78e-01] [Train Acc: 0.59]\n",
            "[Step 532/50000] [Time: 13s] [Train Loss: 6.78e-01] [Train Acc: 0.59]\n",
            "[Step 538/50000] [Time: 13s] [Train Loss: 6.78e-01] [Train Acc: 0.59]\n",
            "[Step 544/50000] [Time: 13s] [Train Loss: 6.78e-01] [Train Acc: 0.59]\n",
            "[Step 550/50000] [Time: 13s] [Train Loss: 6.77e-01] [Train Acc: 0.59]\n",
            "[Step 556/50000] [Time: 13s] [Train Loss: 6.77e-01] [Train Acc: 0.59]\n",
            "[Step 562/50000] [Time: 13s] [Train Loss: 6.77e-01] [Train Acc: 0.59]\n",
            "[Step 568/50000] [Time: 13s] [Train Loss: 6.77e-01] [Train Acc: 0.59]\n",
            "[Step 574/50000] [Time: 13s] [Train Loss: 6.76e-01] [Train Acc: 0.59]\n",
            "[Step 580/50000] [Time: 13s] [Train Loss: 6.76e-01] [Train Acc: 0.60]\n",
            "[Step 586/50000] [Time: 13s] [Train Loss: 6.76e-01] [Train Acc: 0.60]\n",
            "[Step 592/50000] [Time: 13s] [Train Loss: 6.76e-01] [Train Acc: 0.60]\n",
            "[Step 598/50000] [Time: 13s] [Train Loss: 6.75e-01] [Train Acc: 0.60]\n",
            "[Step 604/50000] [Time: 13s] [Train Loss: 6.75e-01] [Train Acc: 0.60]\n",
            "[Step 610/50000] [Time: 13s] [Train Loss: 6.75e-01] [Train Acc: 0.60] [Eval Loss: 6.83e-01] [Eval Acc: 0.58]\n",
            "[Step 616/50000] [Time: 16s] [Train Loss: 6.74e-01] [Train Acc: 0.60]\n",
            "[Step 622/50000] [Time: 17s] [Train Loss: 6.74e-01] [Train Acc: 0.60]\n",
            "[Step 629/50000] [Time: 17s] [Train Loss: 6.74e-01] [Train Acc: 0.60]\n",
            "[Step 636/50000] [Time: 17s] [Train Loss: 6.74e-01] [Train Acc: 0.60]\n",
            "[Step 643/50000] [Time: 17s] [Train Loss: 6.73e-01] [Train Acc: 0.60]\n",
            "[Step 650/50000] [Time: 17s] [Train Loss: 6.73e-01] [Train Acc: 0.60]\n",
            "[Step 657/50000] [Time: 17s] [Train Loss: 6.73e-01] [Train Acc: 0.60]\n",
            "[Step 664/50000] [Time: 17s] [Train Loss: 6.72e-01] [Train Acc: 0.61]\n",
            "[Step 671/50000] [Time: 17s] [Train Loss: 6.72e-01] [Train Acc: 0.61]\n",
            "[Step 678/50000] [Time: 17s] [Train Loss: 6.71e-01] [Train Acc: 0.61]\n",
            "[Step 685/50000] [Time: 17s] [Train Loss: 6.71e-01] [Train Acc: 0.61]\n",
            "[Step 692/50000] [Time: 17s] [Train Loss: 6.71e-01] [Train Acc: 0.61]\n",
            "[Step 699/50000] [Time: 17s] [Train Loss: 6.70e-01] [Train Acc: 0.61]\n",
            "[Step 706/50000] [Time: 17s] [Train Loss: 6.70e-01] [Train Acc: 0.61]\n",
            "[Step 713/50000] [Time: 18s] [Train Loss: 6.70e-01] [Train Acc: 0.61]\n",
            "[Step 720/50000] [Time: 18s] [Train Loss: 6.69e-01] [Train Acc: 0.61]\n",
            "[Step 727/50000] [Time: 18s] [Train Loss: 6.69e-01] [Train Acc: 0.61]\n",
            "[Step 735/50000] [Time: 18s] [Train Loss: 6.68e-01] [Train Acc: 0.61]\n",
            "[Step 743/50000] [Time: 18s] [Train Loss: 6.68e-01] [Train Acc: 0.61]\n",
            "[Step 751/50000] [Time: 18s] [Train Loss: 6.67e-01] [Train Acc: 0.61]\n",
            "[Step 759/50000] [Time: 18s] [Train Loss: 6.67e-01] [Train Acc: 0.61]\n",
            "[Step 767/50000] [Time: 18s] [Train Loss: 6.66e-01] [Train Acc: 0.61]\n",
            "[Step 775/50000] [Time: 18s] [Train Loss: 6.66e-01] [Train Acc: 0.61]\n",
            "[Step 783/50000] [Time: 18s] [Train Loss: 6.65e-01] [Train Acc: 0.61]\n",
            "[Step 791/50000] [Time: 18s] [Train Loss: 6.65e-01] [Train Acc: 0.61]\n",
            "[Step 799/50000] [Time: 18s] [Train Loss: 6.64e-01] [Train Acc: 0.61]\n",
            "[Step 807/50000] [Time: 18s] [Train Loss: 6.64e-01] [Train Acc: 0.62]\n",
            "[Step 815/50000] [Time: 18s] [Train Loss: 6.63e-01] [Train Acc: 0.62]\n",
            "[Step 823/50000] [Time: 18s] [Train Loss: 6.63e-01] [Train Acc: 0.62]\n",
            "[Step 831/50000] [Time: 18s] [Train Loss: 6.62e-01] [Train Acc: 0.62]\n",
            "[Step 839/50000] [Time: 18s] [Train Loss: 6.62e-01] [Train Acc: 0.62]\n",
            "[Step 848/50000] [Time: 18s] [Train Loss: 6.61e-01] [Train Acc: 0.62]\n",
            "[Step 857/50000] [Time: 19s] [Train Loss: 6.60e-01] [Train Acc: 0.62]\n",
            "[Step 866/50000] [Time: 19s] [Train Loss: 6.60e-01] [Train Acc: 0.62]\n",
            "[Step 875/50000] [Time: 19s] [Train Loss: 6.59e-01] [Train Acc: 0.62]\n",
            "[Step 884/50000] [Time: 19s] [Train Loss: 6.58e-01] [Train Acc: 0.62]\n",
            "[Step 893/50000] [Time: 19s] [Train Loss: 6.58e-01] [Train Acc: 0.63]\n",
            "[Step 902/50000] [Time: 19s] [Train Loss: 6.57e-01] [Train Acc: 0.63]\n",
            "[Step 911/50000] [Time: 19s] [Train Loss: 6.56e-01] [Train Acc: 0.63]\n",
            "[Step 920/50000] [Time: 19s] [Train Loss: 6.55e-01] [Train Acc: 0.63]\n",
            "[Step 929/50000] [Time: 19s] [Train Loss: 6.55e-01] [Train Acc: 0.63]\n",
            "[Step 938/50000] [Time: 19s] [Train Loss: 6.54e-01] [Train Acc: 0.64]\n",
            "[Step 947/50000] [Time: 19s] [Train Loss: 6.53e-01] [Train Acc: 0.64]\n",
            "[Step 957/50000] [Time: 19s] [Train Loss: 6.52e-01] [Train Acc: 0.64]\n",
            "[Step 967/50000] [Time: 19s] [Train Loss: 6.51e-01] [Train Acc: 0.64]\n",
            "[Step 977/50000] [Time: 19s] [Train Loss: 6.50e-01] [Train Acc: 0.64]\n",
            "[Step 987/50000] [Time: 19s] [Train Loss: 6.50e-01] [Train Acc: 0.64]\n",
            "[Step 997/50000] [Time: 19s] [Train Loss: 6.49e-01] [Train Acc: 0.64]\n",
            "[Step 1007/50000] [Time: 20s] [Train Loss: 6.48e-01] [Train Acc: 0.64]\n",
            "[Step 1017/50000] [Time: 20s] [Train Loss: 6.47e-01] [Train Acc: 0.65] [Eval Loss: 6.71e-01] [Eval Acc: 0.60]\n",
            "[Step 1027/50000] [Time: 22s] [Train Loss: 6.46e-01] [Train Acc: 0.65]\n",
            "[Step 1037/50000] [Time: 22s] [Train Loss: 6.45e-01] [Train Acc: 0.65]\n",
            "[Step 1047/50000] [Time: 22s] [Train Loss: 6.44e-01] [Train Acc: 0.65]\n",
            "[Step 1057/50000] [Time: 22s] [Train Loss: 6.43e-01] [Train Acc: 0.65]\n",
            "[Step 1068/50000] [Time: 22s] [Train Loss: 6.41e-01] [Train Acc: 0.65]\n",
            "[Step 1079/50000] [Time: 22s] [Train Loss: 6.40e-01] [Train Acc: 0.65]\n",
            "[Step 1090/50000] [Time: 22s] [Train Loss: 6.39e-01] [Train Acc: 0.66]\n",
            "[Step 1101/50000] [Time: 22s] [Train Loss: 6.38e-01] [Train Acc: 0.66]\n",
            "[Step 1112/50000] [Time: 22s] [Train Loss: 6.36e-01] [Train Acc: 0.66]\n",
            "[Step 1123/50000] [Time: 22s] [Train Loss: 6.35e-01] [Train Acc: 0.67]\n",
            "[Step 1134/50000] [Time: 22s] [Train Loss: 6.34e-01] [Train Acc: 0.67]\n",
            "[Step 1145/50000] [Time: 22s] [Train Loss: 6.32e-01] [Train Acc: 0.67]\n",
            "[Step 1155/50000] [Progress: 2.31%] [learning rate: 6.2e+02]\n",
            "[Step 1156/50000] [Time: 22s] [Train Loss: 6.31e-01] [Train Acc: 0.67]\n",
            "[Step 1167/50000] [Time: 23s] [Train Loss: 6.31e-01] [Train Acc: 0.67]\n",
            "[Step 1179/50000] [Time: 23s] [Train Loss: 6.30e-01] [Train Acc: 0.67]\n",
            "[Step 1191/50000] [Time: 23s] [Train Loss: 6.28e-01] [Train Acc: 0.68]\n",
            "[Step 1202/50000] [Progress: 2.40%] [learning rate: 7.4e+02]\n",
            "[Step 1203/50000] [Time: 23s] [Train Loss: 6.27e-01] [Train Acc: 0.68]\n",
            "[Step 1215/50000] [Time: 23s] [Train Loss: 6.26e-01] [Train Acc: 0.68]\n",
            "[Step 1227/50000] [Time: 23s] [Train Loss: 6.25e-01] [Train Acc: 0.68]\n",
            "[Step 1239/50000] [Time: 23s] [Train Loss: 6.24e-01] [Train Acc: 0.68]\n",
            "[Step 1243/50000] [Progress: 2.49%] [learning rate: 8.1e+02]\n",
            "[Step 1251/50000] [Time: 23s] [Train Loss: 6.23e-01] [Train Acc: 0.68]\n",
            "[Step 1263/50000] [Time: 23s] [Train Loss: 6.22e-01] [Train Acc: 0.69]\n",
            "[Step 1275/50000] [Time: 23s] [Train Loss: 6.20e-01] [Train Acc: 0.69]\n",
            "[Step 1281/50000] [Progress: 2.56%] [learning rate: 8.7e+02]\n",
            "[Step 1287/50000] [Time: 23s] [Train Loss: 6.20e-01] [Train Acc: 0.69]\n",
            "[Step 1300/50000] [Time: 23s] [Train Loss: 6.19e-01] [Train Acc: 0.69]\n",
            "[Step 1313/50000] [Time: 24s] [Train Loss: 6.17e-01] [Train Acc: 0.69]\n",
            "[Step 1318/50000] [Progress: 2.64%] [learning rate: 9.5e+02]\n",
            "[Step 1326/50000] [Time: 24s] [Train Loss: 6.16e-01] [Train Acc: 0.69]\n",
            "[Step 1339/50000] [Time: 24s] [Train Loss: 6.15e-01] [Train Acc: 0.69]\n",
            "[Step 1352/50000] [Time: 24s] [Train Loss: 6.13e-01] [Train Acc: 0.69]\n",
            "[Step 1354/50000] [Progress: 2.71%] [learning rate: 1.0e+03]\n",
            "[Step 1365/50000] [Time: 24s] [Train Loss: 6.13e-01] [Train Acc: 0.69]\n",
            "[Step 1378/50000] [Time: 24s] [Train Loss: 6.11e-01] [Train Acc: 0.69]\n",
            "[Step 1389/50000] [Progress: 2.78%] [learning rate: 1.1e+03]\n",
            "[Step 1391/50000] [Time: 24s] [Train Loss: 6.10e-01] [Train Acc: 0.70]\n",
            "[Step 1404/50000] [Time: 24s] [Train Loss: 6.09e-01] [Train Acc: 0.70]\n",
            "[Step 1418/50000] [Time: 24s] [Train Loss: 6.07e-01] [Train Acc: 0.70]\n",
            "[Step 1423/50000] [Progress: 2.85%] [learning rate: 1.2e+03]\n",
            "[Step 1432/50000] [Time: 24s] [Train Loss: 6.06e-01] [Train Acc: 0.70]\n",
            "[Step 1446/50000] [Time: 24s] [Train Loss: 6.05e-01] [Train Acc: 0.70]\n",
            "[Step 1456/50000] [Progress: 2.91%] [learning rate: 1.3e+03]\n",
            "[Step 1460/50000] [Time: 25s] [Train Loss: 6.03e-01] [Train Acc: 0.70]\n",
            "[Step 1474/50000] [Time: 25s] [Train Loss: 6.02e-01] [Train Acc: 0.71]\n",
            "[Step 1488/50000] [Time: 25s] [Train Loss: 6.00e-01] [Train Acc: 0.71]\n",
            "[Step 1489/50000] [Progress: 2.98%] [learning rate: 1.4e+03]\n",
            "[Step 1502/50000] [Time: 25s] [Train Loss: 5.99e-01] [Train Acc: 0.71]\n",
            "[Step 1516/50000] [Time: 25s] [Train Loss: 5.97e-01] [Train Acc: 0.71]\n",
            "[Step 1522/50000] [Progress: 3.04%] [learning rate: 1.5e+03]\n",
            "[Step 1531/50000] [Time: 25s] [Train Loss: 5.96e-01] [Train Acc: 0.71]\n",
            "[Step 1546/50000] [Time: 25s] [Train Loss: 5.94e-01] [Train Acc: 0.71]\n",
            "[Step 1554/50000] [Progress: 3.11%] [learning rate: 1.7e+03]\n",
            "[Step 1561/50000] [Time: 25s] [Train Loss: 5.93e-01] [Train Acc: 0.71]\n",
            "[Step 1576/50000] [Time: 25s] [Train Loss: 5.91e-01] [Train Acc: 0.71]\n",
            "[Step 1583/50000] [Progress: 3.17%] [learning rate: 1.8e+03]\n",
            "[Step 1591/50000] [Time: 26s] [Train Loss: 5.89e-01] [Train Acc: 0.71]\n",
            "[Step 1606/50000] [Time: 26s] [Train Loss: 5.88e-01] [Train Acc: 0.72]\n",
            "[Step 1611/50000] [Progress: 3.22%] [learning rate: 1.9e+03]\n",
            "[Step 1621/50000] [Time: 26s] [Train Loss: 5.86e-01] [Train Acc: 0.72]\n",
            "[Step 1636/50000] [Time: 26s] [Train Loss: 5.84e-01] [Train Acc: 0.72]\n",
            "[Step 1638/50000] [Progress: 3.28%] [learning rate: 2.1e+03]\n",
            "[Step 1652/50000] [Time: 26s] [Train Loss: 5.83e-01] [Train Acc: 0.72] [Eval Loss: 6.45e-01] [Eval Acc: 0.64]\n",
            "[Step 1665/50000] [Progress: 3.33%] [learning rate: 2.1e+03]\n",
            "[Step 1668/50000] [Time: 28s] [Train Loss: 5.81e-01] [Train Acc: 0.72]\n",
            "[Step 1684/50000] [Time: 28s] [Train Loss: 5.80e-01] [Train Acc: 0.72]\n",
            "[Step 1692/50000] [Progress: 3.38%] [learning rate: 2.2e+03]\n",
            "[Step 1700/50000] [Time: 28s] [Train Loss: 5.78e-01] [Train Acc: 0.73]\n",
            "[Step 1716/50000] [Time: 28s] [Train Loss: 5.76e-01] [Train Acc: 0.73]\n",
            "[Step 1718/50000] [Progress: 3.44%] [learning rate: 2.2e+03]\n",
            "[Step 1732/50000] [Time: 28s] [Train Loss: 5.75e-01] [Train Acc: 0.73]\n",
            "[Step 1744/50000] [Progress: 3.49%] [learning rate: 2.2e+03]\n",
            "[Step 1748/50000] [Time: 28s] [Train Loss: 5.73e-01] [Train Acc: 0.74]\n",
            "[Step 1765/50000] [Time: 28s] [Train Loss: 5.72e-01] [Train Acc: 0.74]\n",
            "[Step 1769/50000] [Progress: 3.54%] [learning rate: 2.1e+03]\n",
            "[Step 1782/50000] [Time: 29s] [Train Loss: 5.71e-01] [Train Acc: 0.74]\n",
            "[Step 1796/50000] [Progress: 3.59%] [learning rate: 2.3e+03]\n",
            "[Step 1799/50000] [Time: 29s] [Train Loss: 5.69e-01] [Train Acc: 0.74]\n",
            "[Step 1816/50000] [Time: 29s] [Train Loss: 5.67e-01] [Train Acc: 0.74]\n",
            "[Step 1822/50000] [Progress: 3.64%] [learning rate: 2.3e+03]\n",
            "[Step 1833/50000] [Time: 29s] [Train Loss: 5.66e-01] [Train Acc: 0.75]\n",
            "[Step 1846/50000] [Progress: 3.69%] [learning rate: 2.3e+03]\n",
            "[Step 1850/50000] [Time: 29s] [Train Loss: 5.64e-01] [Train Acc: 0.75]\n",
            "[Step 1867/50000] [Time: 29s] [Train Loss: 5.63e-01] [Train Acc: 0.75]\n",
            "[Step 1871/50000] [Progress: 3.74%] [learning rate: 2.2e+03]\n",
            "[Step 1885/50000] [Time: 29s] [Train Loss: 5.62e-01] [Train Acc: 0.75]\n",
            "[Step 1897/50000] [Progress: 3.79%] [learning rate: 2.2e+03]\n",
            "[Step 1903/50000] [Time: 30s] [Train Loss: 5.60e-01] [Train Acc: 0.75]\n",
            "[Step 1921/50000] [Time: 30s] [Train Loss: 5.58e-01] [Train Acc: 0.75]\n",
            "[Step 1922/50000] [Progress: 3.84%] [learning rate: 2.2e+03]\n",
            "[Step 1939/50000] [Time: 30s] [Train Loss: 5.57e-01] [Train Acc: 0.75]\n",
            "[Step 1947/50000] [Progress: 3.89%] [learning rate: 2.3e+03]\n",
            "[Step 1957/50000] [Time: 30s] [Train Loss: 5.56e-01] [Train Acc: 0.75]\n",
            "[Step 1973/50000] [Progress: 3.95%] [learning rate: 2.5e+03]\n",
            "[Step 1975/50000] [Time: 30s] [Train Loss: 5.54e-01] [Train Acc: 0.76]\n",
            "[Step 1993/50000] [Time: 30s] [Train Loss: 5.53e-01] [Train Acc: 0.76]\n",
            "[Step 1997/50000] [Progress: 3.99%] [learning rate: 2.3e+03]\n",
            "[Step 2012/50000] [Time: 30s] [Train Loss: 5.51e-01] [Train Acc: 0.76]\n",
            "[Step 2022/50000] [Progress: 4.04%] [learning rate: 2.2e+03]\n",
            "[Step 2031/50000] [Time: 31s] [Train Loss: 5.50e-01] [Train Acc: 0.76]\n",
            "[Step 2048/50000] [Progress: 4.10%] [learning rate: 2.4e+03]\n",
            "[Step 2050/50000] [Time: 31s] [Train Loss: 5.48e-01] [Train Acc: 0.76]\n",
            "[Step 2069/50000] [Time: 31s] [Train Loss: 5.47e-01] [Train Acc: 0.76]\n",
            "[Step 2072/50000] [Progress: 4.14%] [learning rate: 2.2e+03]\n",
            "[Step 2088/50000] [Time: 31s] [Train Loss: 5.46e-01] [Train Acc: 0.76]\n",
            "[Step 2099/50000] [Progress: 4.20%] [learning rate: 2.3e+03]\n",
            "[Step 2107/50000] [Time: 31s] [Train Loss: 5.44e-01] [Train Acc: 0.77]\n",
            "[Step 2124/50000] [Progress: 4.25%] [learning rate: 2.3e+03]\n",
            "[Step 2126/50000] [Time: 31s] [Train Loss: 5.42e-01] [Train Acc: 0.77]\n",
            "[Step 2146/50000] [Time: 31s] [Train Loss: 5.41e-01] [Train Acc: 0.77]\n",
            "[Step 2150/50000] [Progress: 4.30%] [learning rate: 2.3e+03]\n",
            "[Step 2166/50000] [Time: 32s] [Train Loss: 5.40e-01] [Train Acc: 0.77]\n",
            "[Step 2176/50000] [Progress: 4.35%] [learning rate: 2.2e+03]\n",
            "[Step 2186/50000] [Time: 32s] [Train Loss: 5.39e-01] [Train Acc: 0.77]\n",
            "[Step 2201/50000] [Progress: 4.40%] [learning rate: 2.2e+03]\n",
            "[Step 2206/50000] [Time: 32s] [Train Loss: 5.37e-01] [Train Acc: 0.77]\n",
            "[Step 2226/50000] [Progress: 4.45%] [learning rate: 2.4e+03]\n",
            "[Step 2226/50000] [Time: 32s] [Train Loss: 5.36e-01] [Train Acc: 0.77]\n",
            "[Step 2246/50000] [Time: 32s] [Train Loss: 5.34e-01] [Train Acc: 0.78]\n",
            "[Step 2251/50000] [Progress: 4.50%] [learning rate: 2.6e+03]\n",
            "[Step 2267/50000] [Time: 32s] [Train Loss: 5.33e-01] [Train Acc: 0.78]\n",
            "[Step 2274/50000] [Progress: 4.55%] [learning rate: 2.1e+03]\n",
            "[Step 2288/50000] [Time: 32s] [Train Loss: 5.32e-01] [Train Acc: 0.78]\n",
            "[Step 2300/50000] [Progress: 4.60%] [learning rate: 2.3e+03]\n",
            "[Step 2309/50000] [Time: 32s] [Train Loss: 5.30e-01] [Train Acc: 0.78]\n",
            "[Step 2325/50000] [Progress: 4.65%] [learning rate: 2.3e+03]\n",
            "[Step 2330/50000] [Time: 33s] [Train Loss: 5.29e-01] [Train Acc: 0.78]\n",
            "[Step 2351/50000] [Progress: 4.70%] [learning rate: 2.4e+03]\n",
            "[Step 2351/50000] [Time: 33s] [Train Loss: 5.27e-01] [Train Acc: 0.78]\n",
            "[Step 2372/50000] [Time: 33s] [Train Loss: 5.26e-01] [Train Acc: 0.78]\n",
            "[Step 2375/50000] [Progress: 4.75%] [learning rate: 2.4e+03]\n",
            "[Step 2394/50000] [Time: 33s] [Train Loss: 5.25e-01] [Train Acc: 0.78]\n",
            "[Step 2400/50000] [Progress: 4.80%] [learning rate: 2.4e+03]\n",
            "[Step 2416/50000] [Time: 33s] [Train Loss: 5.24e-01] [Train Acc: 0.78]\n",
            "[Step 2424/50000] [Progress: 4.85%] [learning rate: 2.3e+03]\n",
            "[Step 2438/50000] [Time: 33s] [Train Loss: 5.22e-01] [Train Acc: 0.78]\n",
            "[Step 2449/50000] [Progress: 4.90%] [learning rate: 2.3e+03]\n",
            "[Step 2460/50000] [Time: 33s] [Train Loss: 5.21e-01] [Train Acc: 0.78]\n",
            "[Step 2475/50000] [Progress: 4.95%] [learning rate: 2.5e+03]\n",
            "[Step 2482/50000] [Time: 34s] [Train Loss: 5.20e-01] [Train Acc: 0.78]\n",
            "[Step 2499/50000] [Progress: 5.00%] [learning rate: 2.2e+03]\n",
            "[Step 2504/50000] [Time: 34s] [Train Loss: 5.18e-01] [Train Acc: 0.78]\n",
            "[Step 2526/50000] [Progress: 5.05%] [learning rate: 2.7e+03]\n",
            "[Step 2527/50000] [Time: 34s] [Train Loss: 5.17e-01] [Train Acc: 0.79]\n",
            "[Step 2549/50000] [Progress: 5.10%] [learning rate: 2.2e+03]\n",
            "[Step 2550/50000] [Time: 34s] [Train Loss: 5.15e-01] [Train Acc: 0.79]\n",
            "[Step 2573/50000] [Time: 34s] [Train Loss: 5.14e-01] [Train Acc: 0.79]\n",
            "[Step 2575/50000] [Progress: 5.15%] [learning rate: 2.3e+03]\n",
            "[Step 2596/50000] [Time: 34s] [Train Loss: 5.13e-01] [Train Acc: 0.79]\n",
            "[Step 2600/50000] [Progress: 5.20%] [learning rate: 2.3e+03]\n",
            "[Step 2619/50000] [Time: 35s] [Train Loss: 5.12e-01] [Train Acc: 0.79] [Eval Loss: 6.11e-01] [Eval Acc: 0.68]\n",
            "[Step 2626/50000] [Progress: 5.25%] [learning rate: 2.3e+03]\n",
            "[Step 2643/50000] [Time: 37s] [Train Loss: 5.11e-01] [Train Acc: 0.79]\n",
            "[Step 2652/50000] [Progress: 5.30%] [learning rate: 2.5e+03]\n",
            "[Step 2667/50000] [Time: 37s] [Train Loss: 5.09e-01] [Train Acc: 0.79]\n",
            "[Step 2679/50000] [Progress: 5.36%] [learning rate: 2.7e+03]\n",
            "[Step 2691/50000] [Time: 37s] [Train Loss: 5.08e-01] [Train Acc: 0.79]\n",
            "[Step 2701/50000] [Progress: 5.40%] [learning rate: 2.2e+03]\n",
            "[Step 2715/50000] [Time: 38s] [Train Loss: 5.07e-01] [Train Acc: 0.79]\n",
            "[Step 2727/50000] [Progress: 5.45%] [learning rate: 2.6e+03]\n",
            "[Step 2739/50000] [Time: 38s] [Train Loss: 5.05e-01] [Train Acc: 0.79]\n",
            "[Step 2750/50000] [Progress: 5.50%] [learning rate: 2.3e+03]\n",
            "[Step 2763/50000] [Time: 38s] [Train Loss: 5.04e-01] [Train Acc: 0.79]\n",
            "[Step 2775/50000] [Progress: 5.55%] [learning rate: 2.5e+03]\n",
            "[Step 2788/50000] [Time: 38s] [Train Loss: 5.03e-01] [Train Acc: 0.79]\n",
            "[Step 2799/50000] [Progress: 5.60%] [learning rate: 2.5e+03]\n",
            "[Step 2813/50000] [Time: 38s] [Train Loss: 5.02e-01] [Train Acc: 0.79]\n",
            "[Step 2824/50000] [Progress: 5.65%] [learning rate: 2.4e+03]\n",
            "[Step 2838/50000] [Time: 38s] [Train Loss: 5.00e-01] [Train Acc: 0.80]\n",
            "[Step 2848/50000] [Progress: 5.70%] [learning rate: 2.4e+03]\n",
            "[Step 2863/50000] [Time: 39s] [Train Loss: 4.99e-01] [Train Acc: 0.80]\n",
            "[Step 2873/50000] [Progress: 5.75%] [learning rate: 2.4e+03]\n",
            "[Step 2888/50000] [Time: 39s] [Train Loss: 4.98e-01] [Train Acc: 0.80]\n",
            "[Step 2899/50000] [Progress: 5.80%] [learning rate: 2.6e+03]\n",
            "[Step 2914/50000] [Time: 39s] [Train Loss: 4.96e-01] [Train Acc: 0.80]\n",
            "[Step 2923/50000] [Progress: 5.85%] [learning rate: 2.3e+03]\n",
            "[Step 2940/50000] [Time: 39s] [Train Loss: 4.95e-01] [Train Acc: 0.80]\n",
            "[Step 2950/50000] [Progress: 5.90%] [learning rate: 2.7e+03]\n",
            "[Step 2966/50000] [Time: 39s] [Train Loss: 4.94e-01] [Train Acc: 0.80]\n",
            "[Step 2973/50000] [Progress: 5.95%] [learning rate: 2.2e+03]\n",
            "[Step 2992/50000] [Time: 40s] [Train Loss: 4.93e-01] [Train Acc: 0.80]\n",
            "[Step 2999/50000] [Progress: 6.00%] [learning rate: 2.4e+03]\n",
            "[Step 3018/50000] [Time: 40s] [Train Loss: 4.91e-01] [Train Acc: 0.80]\n",
            "[Step 3023/50000] [Progress: 6.05%] [learning rate: 2.4e+03]\n",
            "[Step 3045/50000] [Time: 40s] [Train Loss: 4.90e-01] [Train Acc: 0.80]\n",
            "[Step 3048/50000] [Progress: 6.10%] [learning rate: 2.6e+03]\n",
            "[Step 3072/50000] [Progress: 6.14%] [learning rate: 2.3e+03]\n",
            "[Step 3072/50000] [Time: 40s] [Train Loss: 4.89e-01] [Train Acc: 0.80]\n",
            "[Step 3099/50000] [Time: 40s] [Train Loss: 4.87e-01] [Train Acc: 0.80]\n",
            "[Step 3100/50000] [Progress: 6.20%] [learning rate: 2.7e+03]\n",
            "[Step 3123/50000] [Progress: 6.25%] [learning rate: 2.2e+03]\n",
            "[Step 3126/50000] [Time: 40s] [Train Loss: 4.86e-01] [Train Acc: 0.80]\n",
            "[Step 3150/50000] [Progress: 6.30%] [learning rate: 2.7e+03]\n",
            "[Step 3153/50000] [Time: 41s] [Train Loss: 4.85e-01] [Train Acc: 0.80]\n",
            "[Step 3173/50000] [Progress: 6.35%] [learning rate: 2.2e+03]\n",
            "[Step 3181/50000] [Time: 41s] [Train Loss: 4.84e-01] [Train Acc: 0.81]\n",
            "[Step 3200/50000] [Progress: 6.40%] [learning rate: 2.6e+03]\n",
            "[Step 3209/50000] [Time: 41s] [Train Loss: 4.83e-01] [Train Acc: 0.81]\n",
            "[Step 3225/50000] [Progress: 6.45%] [learning rate: 2.5e+03]\n",
            "[Step 3237/50000] [Time: 41s] [Train Loss: 4.81e-01] [Train Acc: 0.81]\n",
            "[Step 3250/50000] [Progress: 6.50%] [learning rate: 2.8e+03]\n",
            "[Step 3265/50000] [Time: 42s] [Train Loss: 4.80e-01] [Train Acc: 0.81]\n",
            "[Step 3273/50000] [Progress: 6.55%] [learning rate: 2.2e+03]\n",
            "[Step 3293/50000] [Time: 42s] [Train Loss: 4.79e-01] [Train Acc: 0.81]\n",
            "[Step 3301/50000] [Progress: 6.60%] [learning rate: 2.7e+03]\n",
            "[Step 3322/50000] [Time: 42s] [Train Loss: 4.78e-01] [Train Acc: 0.81]\n",
            "[Step 3325/50000] [Progress: 6.65%] [learning rate: 2.4e+03]\n",
            "[Step 3350/50000] [Progress: 6.70%] [learning rate: 2.6e+03]\n",
            "[Step 3351/50000] [Time: 42s] [Train Loss: 4.76e-01] [Train Acc: 0.81]\n",
            "[Step 3375/50000] [Progress: 6.75%] [learning rate: 2.6e+03]\n",
            "[Step 3380/50000] [Time: 42s] [Train Loss: 4.75e-01] [Train Acc: 0.81]\n",
            "[Step 3401/50000] [Progress: 6.80%] [learning rate: 2.5e+03]\n",
            "[Step 3409/50000] [Time: 43s] [Train Loss: 4.74e-01] [Train Acc: 0.81]\n",
            "[Step 3425/50000] [Progress: 6.85%] [learning rate: 2.5e+03]\n",
            "[Step 3438/50000] [Time: 43s] [Train Loss: 4.73e-01] [Train Acc: 0.81]\n",
            "[Step 3450/50000] [Progress: 6.90%] [learning rate: 2.4e+03]\n",
            "[Step 3468/50000] [Time: 43s] [Train Loss: 4.72e-01] [Train Acc: 0.81]\n",
            "[Step 3476/50000] [Progress: 6.95%] [learning rate: 2.7e+03]\n",
            "[Step 3498/50000] [Time: 43s] [Train Loss: 4.70e-01] [Train Acc: 0.82]\n",
            "[Step 3500/50000] [Progress: 7.00%] [learning rate: 2.4e+03]\n",
            "[Step 3528/50000] [Progress: 7.06%] [learning rate: 2.8e+03]\n",
            "[Step 3528/50000] [Time: 44s] [Train Loss: 4.69e-01] [Train Acc: 0.82]\n",
            "[Step 3552/50000] [Progress: 7.10%] [learning rate: 2.5e+03]\n",
            "[Step 3558/50000] [Time: 44s] [Train Loss: 4.68e-01] [Train Acc: 0.82]\n",
            "[Step 3577/50000] [Progress: 7.15%] [learning rate: 2.5e+03]\n",
            "[Step 3588/50000] [Time: 44s] [Train Loss: 4.67e-01] [Train Acc: 0.82]\n",
            "[Step 3603/50000] [Progress: 7.21%] [learning rate: 2.5e+03]\n",
            "[Step 3619/50000] [Time: 44s] [Train Loss: 4.66e-01] [Train Acc: 0.82]\n",
            "[Step 3628/50000] [Progress: 7.26%] [learning rate: 2.4e+03]\n",
            "[Step 3650/50000] [Time: 44s] [Train Loss: 4.64e-01] [Train Acc: 0.82]\n",
            "[Step 3655/50000] [Progress: 7.31%] [learning rate: 2.6e+03]\n",
            "[Step 3681/50000] [Time: 45s] [Train Loss: 4.63e-01] [Train Acc: 0.82]\n",
            "[Step 3682/50000] [Progress: 7.36%] [learning rate: 2.8e+03]\n",
            "[Step 3707/50000] [Progress: 7.41%] [learning rate: 2.5e+03]\n",
            "[Step 3712/50000] [Time: 45s] [Train Loss: 4.62e-01] [Train Acc: 0.82]\n",
            "[Step 3733/50000] [Progress: 7.47%] [learning rate: 2.5e+03]\n",
            "[Step 3744/50000] [Time: 45s] [Train Loss: 4.61e-01] [Train Acc: 0.82]\n",
            "[Step 3759/50000] [Progress: 7.52%] [learning rate: 2.5e+03]\n",
            "[Step 3776/50000] [Time: 45s] [Train Loss: 4.60e-01] [Train Acc: 0.82]\n",
            "[Step 3784/50000] [Progress: 7.57%] [learning rate: 2.4e+03]\n",
            "[Step 3808/50000] [Time: 45s] [Train Loss: 4.58e-01] [Train Acc: 0.82]\n",
            "[Step 3810/50000] [Progress: 7.62%] [learning rate: 2.6e+03]\n",
            "[Step 3836/50000] [Progress: 7.67%] [learning rate: 2.9e+03]\n",
            "[Step 3840/50000] [Time: 46s] [Train Loss: 4.57e-01] [Train Acc: 0.82]\n",
            "[Step 3859/50000] [Progress: 7.72%] [learning rate: 2.3e+03]\n",
            "[Step 3872/50000] [Time: 46s] [Train Loss: 4.56e-01] [Train Acc: 0.82]\n",
            "[Step 3885/50000] [Progress: 7.77%] [learning rate: 2.5e+03]\n",
            "[Step 3905/50000] [Time: 46s] [Train Loss: 4.55e-01] [Train Acc: 0.82]\n",
            "[Step 3910/50000] [Progress: 7.82%] [learning rate: 2.5e+03]\n",
            "[Step 3936/50000] [Progress: 7.87%] [learning rate: 2.7e+03]\n",
            "[Step 3938/50000] [Time: 46s] [Train Loss: 4.54e-01] [Train Acc: 0.82]\n",
            "[Step 3961/50000] [Progress: 7.92%] [learning rate: 2.6e+03]\n",
            "[Step 3971/50000] [Time: 47s] [Train Loss: 4.52e-01] [Train Acc: 0.82]\n",
            "[Step 3987/50000] [Progress: 7.97%] [learning rate: 2.6e+03]\n",
            "[Step 4004/50000] [Time: 47s] [Train Loss: 4.51e-01] [Train Acc: 0.83]\n",
            "[Step 4011/50000] [Progress: 8.02%] [learning rate: 2.6e+03]\n",
            "[Step 4036/50000] [Progress: 8.07%] [learning rate: 2.5e+03]\n",
            "[Step 4037/50000] [Time: 47s] [Train Loss: 4.50e-01] [Train Acc: 0.83] [Eval Loss: 5.80e-01] [Eval Acc: 0.71]\n",
            "[Step 4062/50000] [Progress: 8.12%] [learning rate: 2.7e+03]\n",
            "[Step 4071/50000] [Time: 49s] [Train Loss: 4.49e-01] [Train Acc: 0.83]\n",
            "[Step 4086/50000] [Progress: 8.17%] [learning rate: 2.5e+03]\n",
            "[Step 4105/50000] [Time: 49s] [Train Loss: 4.48e-01] [Train Acc: 0.83]\n",
            "[Step 4113/50000] [Progress: 8.23%] [learning rate: 2.9e+03]\n",
            "[Step 4136/50000] [Progress: 8.27%] [learning rate: 2.4e+03]\n",
            "[Step 4139/50000] [Time: 49s] [Train Loss: 4.47e-01] [Train Acc: 0.83]\n",
            "[Step 4162/50000] [Progress: 8.32%] [learning rate: 2.6e+03]\n",
            "[Step 4173/50000] [Time: 49s] [Train Loss: 4.46e-01] [Train Acc: 0.83]\n",
            "[Step 4187/50000] [Progress: 8.37%] [learning rate: 2.5e+03]\n",
            "[Step 4208/50000] [Time: 50s] [Train Loss: 4.44e-01] [Train Acc: 0.83]\n",
            "[Step 4213/50000] [Progress: 8.43%] [learning rate: 2.5e+03]\n",
            "[Step 4238/50000] [Progress: 8.48%] [learning rate: 2.7e+03]\n",
            "[Step 4243/50000] [Time: 50s] [Train Loss: 4.43e-01] [Train Acc: 0.83]\n",
            "[Step 4263/50000] [Progress: 8.53%] [learning rate: 2.7e+03]\n",
            "[Step 4278/50000] [Time: 50s] [Train Loss: 4.42e-01] [Train Acc: 0.83]\n",
            "[Step 4287/50000] [Progress: 8.57%] [learning rate: 2.6e+03]\n",
            "[Step 4312/50000] [Progress: 8.62%] [learning rate: 2.6e+03]\n",
            "[Step 4313/50000] [Time: 50s] [Train Loss: 4.41e-01] [Train Acc: 0.83]\n",
            "[Step 4338/50000] [Progress: 8.68%] [learning rate: 2.6e+03]\n",
            "[Step 4349/50000] [Time: 51s] [Train Loss: 4.40e-01] [Train Acc: 0.84]\n",
            "[Step 4363/50000] [Progress: 8.73%] [learning rate: 2.5e+03]\n",
            "[Step 4385/50000] [Time: 51s] [Train Loss: 4.39e-01] [Train Acc: 0.84]\n",
            "[Step 4388/50000] [Progress: 8.78%] [learning rate: 2.7e+03]\n",
            "[Step 4414/50000] [Progress: 8.83%] [learning rate: 2.9e+03]\n",
            "[Step 4421/50000] [Time: 51s] [Train Loss: 4.37e-01] [Train Acc: 0.84]\n",
            "[Step 4438/50000] [Progress: 8.88%] [learning rate: 2.6e+03]\n",
            "[Step 4457/50000] [Time: 51s] [Train Loss: 4.36e-01] [Train Acc: 0.84]\n",
            "[Step 4463/50000] [Progress: 8.93%] [learning rate: 2.6e+03]\n",
            "[Step 4489/50000] [Progress: 8.98%] [learning rate: 2.6e+03]\n",
            "[Step 4493/50000] [Time: 52s] [Train Loss: 4.35e-01] [Train Acc: 0.84]\n",
            "[Step 4514/50000] [Progress: 9.03%] [learning rate: 2.5e+03]\n",
            "[Step 4530/50000] [Time: 52s] [Train Loss: 4.34e-01] [Train Acc: 0.84]\n",
            "[Step 4540/50000] [Progress: 9.08%] [learning rate: 2.7e+03]\n",
            "[Step 4567/50000] [Progress: 9.13%] [learning rate: 3.0e+03]\n",
            "[Step 4567/50000] [Time: 52s] [Train Loss: 4.33e-01] [Train Acc: 0.84]\n",
            "[Step 4591/50000] [Progress: 9.18%] [learning rate: 2.7e+03]\n",
            "[Step 4604/50000] [Time: 52s] [Train Loss: 4.32e-01] [Train Acc: 0.84]\n",
            "[Step 4616/50000] [Progress: 9.23%] [learning rate: 2.6e+03]\n",
            "[Step 4641/50000] [Time: 53s] [Train Loss: 4.31e-01] [Train Acc: 0.84]\n",
            "[Step 4642/50000] [Progress: 9.28%] [learning rate: 2.6e+03]\n",
            "[Step 4667/50000] [Progress: 9.33%] [learning rate: 2.5e+03]\n",
            "[Step 4679/50000] [Time: 53s] [Train Loss: 4.30e-01] [Train Acc: 0.84]\n",
            "[Step 4693/50000] [Progress: 9.39%] [learning rate: 2.7e+03]\n",
            "[Step 4717/50000] [Time: 53s] [Train Loss: 4.28e-01] [Train Acc: 0.84]\n",
            "[Step 4719/50000] [Progress: 9.44%] [learning rate: 3.0e+03]\n",
            "[Step 4742/50000] [Progress: 9.48%] [learning rate: 2.4e+03]\n",
            "[Step 4755/50000] [Time: 54s] [Train Loss: 4.27e-01] [Train Acc: 0.84]\n",
            "[Step 4769/50000] [Progress: 9.54%] [learning rate: 2.9e+03]\n",
            "[Step 4792/50000] [Progress: 9.58%] [learning rate: 2.6e+03]\n",
            "[Step 4793/50000] [Time: 54s] [Train Loss: 4.26e-01] [Train Acc: 0.84]\n",
            "[Step 4817/50000] [Progress: 9.63%] [learning rate: 2.8e+03]\n",
            "[Step 4832/50000] [Time: 54s] [Train Loss: 4.25e-01] [Train Acc: 0.84]\n",
            "[Step 4842/50000] [Progress: 9.68%] [learning rate: 2.8e+03]\n",
            "[Step 4868/50000] [Progress: 9.74%] [learning rate: 2.7e+03]\n",
            "[Step 4871/50000] [Time: 54s] [Train Loss: 4.24e-01] [Train Acc: 0.84]\n",
            "[Step 4892/50000] [Progress: 9.78%] [learning rate: 2.7e+03]\n",
            "[Step 4910/50000] [Time: 55s] [Train Loss: 4.23e-01] [Train Acc: 0.84]\n",
            "[Step 4917/50000] [Progress: 9.83%] [learning rate: 2.6e+03]\n",
            "[Step 4943/50000] [Progress: 9.89%] [learning rate: 2.9e+03]\n",
            "[Step 4949/50000] [Time: 55s] [Train Loss: 4.22e-01] [Train Acc: 0.84]\n",
            "[Step 4967/50000] [Progress: 9.93%] [learning rate: 2.6e+03]\n",
            "[Step 4989/50000] [Time: 55s] [Train Loss: 4.21e-01] [Train Acc: 0.84]\n",
            "[Step 4995/50000] [Progress: 9.99%] [learning rate: 3.0e+03]\n",
            "[Step 5019/50000] [Progress: 10.04%] [learning rate: 2.7e+03]\n",
            "[Step 5029/50000] [Time: 56s] [Train Loss: 4.20e-01] [Train Acc: 0.84]\n",
            "[Step 5044/50000] [Progress: 10.09%] [learning rate: 2.7e+03]\n",
            "[Step 5069/50000] [Time: 56s] [Train Loss: 4.18e-01] [Train Acc: 0.84]\n",
            "[Step 5070/50000] [Progress: 10.14%] [learning rate: 2.6e+03]\n",
            "[Step 5096/50000] [Progress: 10.19%] [learning rate: 2.9e+03]\n",
            "[Step 5109/50000] [Time: 56s] [Train Loss: 4.18e-01] [Train Acc: 0.85]\n",
            "[Step 5120/50000] [Progress: 10.24%] [learning rate: 2.6e+03]\n",
            "[Step 5146/50000] [Progress: 10.29%] [learning rate: 3.1e+03]\n",
            "[Step 5150/50000] [Time: 57s] [Train Loss: 4.16e-01] [Train Acc: 0.85]\n",
            "[Step 5169/50000] [Progress: 10.34%] [learning rate: 2.5e+03]\n",
            "[Step 5191/50000] [Time: 57s] [Train Loss: 4.15e-01] [Train Acc: 0.85]\n",
            "[Step 5195/50000] [Progress: 10.39%] [learning rate: 2.7e+03]\n",
            "[Step 5221/50000] [Progress: 10.44%] [learning rate: 2.9e+03]\n",
            "[Step 5232/50000] [Time: 57s] [Train Loss: 4.14e-01] [Train Acc: 0.85]\n",
            "[Step 5244/50000] [Progress: 10.49%] [learning rate: 2.6e+03]\n",
            "[Step 5270/50000] [Progress: 10.54%] [learning rate: 2.8e+03]\n",
            "[Step 5273/50000] [Time: 57s] [Train Loss: 4.13e-01] [Train Acc: 0.85]\n",
            "[Step 5297/50000] [Progress: 10.59%] [learning rate: 3.1e+03]\n",
            "[Step 5314/50000] [Time: 58s] [Train Loss: 4.12e-01] [Train Acc: 0.85]\n",
            "[Step 5321/50000] [Progress: 10.64%] [learning rate: 2.8e+03]\n",
            "[Step 5346/50000] [Progress: 10.69%] [learning rate: 2.7e+03]\n",
            "[Step 5356/50000] [Time: 58s] [Train Loss: 4.11e-01] [Train Acc: 0.85]\n",
            "[Step 5372/50000] [Progress: 10.74%] [learning rate: 2.7e+03]\n",
            "[Step 5398/50000] [Time: 58s] [Train Loss: 4.10e-01] [Train Acc: 0.85]\n",
            "[Step 5399/50000] [Progress: 10.80%] [learning rate: 2.9e+03]\n",
            "[Step 5424/50000] [Progress: 10.85%] [learning rate: 2.9e+03]\n",
            "[Step 5440/50000] [Time: 59s] [Train Loss: 4.09e-01] [Train Acc: 0.85]\n",
            "[Step 5450/50000] [Progress: 10.90%] [learning rate: 3.4e+03]\n",
            "[Step 5470/50000] [Progress: 10.94%] [learning rate: 2.3e+03]\n",
            "[Step 5482/50000] [Time: 59s] [Train Loss: 4.08e-01] [Train Acc: 0.85]\n",
            "[Step 5498/50000] [Progress: 11.00%] [learning rate: 3.0e+03]\n",
            "[Step 5523/50000] [Progress: 11.05%] [learning rate: 2.7e+03]\n",
            "[Step 5525/50000] [Time: 59s] [Train Loss: 4.07e-01] [Train Acc: 0.85]\n",
            "[Step 5549/50000] [Progress: 11.10%] [learning rate: 2.9e+03]\n",
            "[Step 5568/50000] [Time: 59s] [Train Loss: 4.06e-01] [Train Acc: 0.85]\n",
            "[Step 5573/50000] [Progress: 11.15%] [learning rate: 2.9e+03]\n",
            "[Step 5598/50000] [Progress: 11.20%] [learning rate: 3.1e+03]\n",
            "[Step 5611/50000] [Time: 60s] [Train Loss: 4.05e-01] [Train Acc: 0.85]\n",
            "[Step 5621/50000] [Progress: 11.24%] [learning rate: 2.5e+03]\n",
            "[Step 5648/50000] [Progress: 11.30%] [learning rate: 3.0e+03]\n",
            "[Step 5654/50000] [Time: 60s] [Train Loss: 4.03e-01] [Train Acc: 0.85]\n",
            "[Step 5671/50000] [Progress: 11.34%] [learning rate: 2.7e+03]\n",
            "[Step 5696/50000] [Progress: 11.39%] [learning rate: 2.9e+03]\n",
            "[Step 5698/50000] [Time: 60s] [Train Loss: 4.02e-01] [Train Acc: 0.85]\n",
            "[Step 5720/50000] [Progress: 11.44%] [learning rate: 2.9e+03]\n",
            "[Step 5742/50000] [Time: 61s] [Train Loss: 4.01e-01] [Train Acc: 0.85]\n",
            "[Step 5745/50000] [Progress: 11.49%] [learning rate: 3.1e+03]\n",
            "[Step 5768/50000] [Progress: 11.54%] [learning rate: 2.5e+03]\n",
            "[Step 5786/50000] [Time: 61s] [Train Loss: 4.00e-01] [Train Acc: 0.85]\n",
            "[Step 5795/50000] [Progress: 11.59%] [learning rate: 3.0e+03]\n",
            "[Step 5818/50000] [Progress: 11.64%] [learning rate: 2.7e+03]\n",
            "[Step 5830/50000] [Time: 61s] [Train Loss: 3.99e-01] [Train Acc: 0.85]\n",
            "[Step 5843/50000] [Progress: 11.69%] [learning rate: 2.9e+03]\n",
            "[Step 5867/50000] [Progress: 11.73%] [learning rate: 2.9e+03]\n",
            "[Step 5875/50000] [Time: 62s] [Train Loss: 3.98e-01] [Train Acc: 0.85]\n",
            "[Step 5892/50000] [Progress: 11.78%] [learning rate: 2.8e+03]\n",
            "[Step 5916/50000] [Progress: 11.83%] [learning rate: 2.8e+03]\n",
            "[Step 5920/50000] [Time: 62s] [Train Loss: 3.97e-01] [Train Acc: 0.85]\n",
            "[Step 5941/50000] [Progress: 11.88%] [learning rate: 2.8e+03]\n",
            "[Step 5965/50000] [Time: 62s] [Train Loss: 3.96e-01] [Train Acc: 0.85]\n",
            "[Step 5967/50000] [Progress: 11.93%] [learning rate: 3.0e+03]\n",
            "[Step 5990/50000] [Progress: 11.98%] [learning rate: 2.7e+03]\n",
            "[Step 6010/50000] [Time: 62s] [Train Loss: 3.95e-01] [Train Acc: 0.85] [Eval Loss: 5.54e-01] [Eval Acc: 0.72]\n",
            "[Step 6016/50000] [Progress: 12.03%] [learning rate: 3.2e+03]\n",
            "[Step 6039/50000] [Progress: 12.08%] [learning rate: 2.6e+03]\n",
            "[Step 6056/50000] [Time: 64s] [Train Loss: 3.94e-01] [Train Acc: 0.86]\n",
            "[Step 6065/50000] [Progress: 12.13%] [learning rate: 2.8e+03]\n",
            "[Step 6089/50000] [Progress: 12.18%] [learning rate: 2.8e+03]\n",
            "[Step 6102/50000] [Time: 65s] [Train Loss: 3.93e-01] [Train Acc: 0.86]\n",
            "[Step 6114/50000] [Progress: 12.23%] [learning rate: 3.0e+03]\n",
            "[Step 6138/50000] [Progress: 12.28%] [learning rate: 2.7e+03]\n",
            "[Step 6148/50000] [Time: 65s] [Train Loss: 3.92e-01] [Train Acc: 0.86]\n",
            "[Step 6165/50000] [Progress: 12.33%] [learning rate: 3.2e+03]\n",
            "[Step 6188/50000] [Progress: 12.38%] [learning rate: 2.6e+03]\n",
            "[Step 6194/50000] [Time: 65s] [Train Loss: 3.91e-01] [Train Acc: 0.86]\n",
            "[Step 6214/50000] [Progress: 12.43%] [learning rate: 2.8e+03]\n",
            "[Step 6240/50000] [Progress: 12.48%] [learning rate: 3.1e+03]\n",
            "[Step 6241/50000] [Time: 66s] [Train Loss: 3.90e-01] [Train Acc: 0.86]\n",
            "[Step 6263/50000] [Progress: 12.53%] [learning rate: 2.5e+03]\n",
            "[Step 6288/50000] [Time: 66s] [Train Loss: 3.89e-01] [Train Acc: 0.86]\n",
            "[Step 6290/50000] [Progress: 12.58%] [learning rate: 3.0e+03]\n",
            "[Step 6316/50000] [Progress: 12.63%] [learning rate: 3.2e+03]\n",
            "[Step 6335/50000] [Time: 66s] [Train Loss: 3.88e-01] [Train Acc: 0.86]\n",
            "[Step 6339/50000] [Progress: 12.68%] [learning rate: 2.6e+03]\n",
            "[Step 6366/50000] [Progress: 12.73%] [learning rate: 3.1e+03]\n",
            "[Step 6382/50000] [Time: 67s] [Train Loss: 3.87e-01] [Train Acc: 0.86]\n",
            "[Step 6389/50000] [Progress: 12.78%] [learning rate: 2.8e+03]\n",
            "[Step 6414/50000] [Progress: 12.83%] [learning rate: 2.8e+03]\n",
            "[Step 6430/50000] [Time: 67s] [Train Loss: 3.86e-01] [Train Acc: 0.86]\n",
            "[Step 6439/50000] [Progress: 12.88%] [learning rate: 3.0e+03]\n",
            "[Step 6464/50000] [Progress: 12.93%] [learning rate: 2.9e+03]\n",
            "[Step 6478/50000] [Time: 67s] [Train Loss: 3.85e-01] [Train Acc: 0.86]\n",
            "[Step 6490/50000] [Progress: 12.98%] [learning rate: 2.9e+03]\n",
            "[Step 6514/50000] [Progress: 13.03%] [learning rate: 2.9e+03]\n",
            "[Step 6526/50000] [Time: 68s] [Train Loss: 3.84e-01] [Train Acc: 0.86]\n",
            "[Step 6539/50000] [Progress: 13.08%] [learning rate: 2.8e+03]\n",
            "[Step 6565/50000] [Progress: 13.13%] [learning rate: 3.0e+03]\n",
            "[Step 6574/50000] [Time: 68s] [Train Loss: 3.83e-01] [Train Acc: 0.86]\n",
            "[Step 6589/50000] [Progress: 13.18%] [learning rate: 2.7e+03]\n",
            "[Step 6615/50000] [Progress: 13.23%] [learning rate: 3.3e+03]\n",
            "[Step 6623/50000] [Time: 69s] [Train Loss: 3.82e-01] [Train Acc: 0.86]\n",
            "[Step 6638/50000] [Progress: 13.28%] [learning rate: 2.6e+03]\n",
            "[Step 6664/50000] [Progress: 13.33%] [learning rate: 2.9e+03]\n",
            "[Step 6672/50000] [Time: 69s] [Train Loss: 3.81e-01] [Train Acc: 0.86]\n",
            "[Step 6688/50000] [Progress: 13.38%] [learning rate: 2.8e+03]\n",
            "[Step 6713/50000] [Progress: 13.43%] [learning rate: 3.1e+03]\n",
            "[Step 6721/50000] [Time: 69s] [Train Loss: 3.80e-01] [Train Acc: 0.86]\n",
            "[Step 6737/50000] [Progress: 13.47%] [learning rate: 2.7e+03]\n",
            "[Step 6763/50000] [Progress: 13.53%] [learning rate: 3.3e+03]\n",
            "[Step 6770/50000] [Time: 70s] [Train Loss: 3.79e-01] [Train Acc: 0.86]\n",
            "[Step 6786/50000] [Progress: 13.57%] [learning rate: 2.7e+03]\n",
            "[Step 6812/50000] [Progress: 13.62%] [learning rate: 2.9e+03]\n",
            "[Step 6820/50000] [Time: 70s] [Train Loss: 3.78e-01] [Train Acc: 0.86]\n",
            "[Step 6837/50000] [Progress: 13.67%] [learning rate: 2.8e+03]\n",
            "[Step 6863/50000] [Progress: 13.73%] [learning rate: 3.1e+03]\n",
            "[Step 6870/50000] [Time: 70s] [Train Loss: 3.77e-01] [Train Acc: 0.86]\n",
            "[Step 6887/50000] [Progress: 13.77%] [learning rate: 2.8e+03]\n",
            "[Step 6914/50000] [Progress: 13.83%] [learning rate: 3.3e+03]\n",
            "[Step 6920/50000] [Time: 71s] [Train Loss: 3.76e-01] [Train Acc: 0.86]\n",
            "[Step 6938/50000] [Progress: 13.88%] [learning rate: 2.9e+03]\n",
            "[Step 6963/50000] [Progress: 13.93%] [learning rate: 2.9e+03]\n",
            "[Step 6970/50000] [Time: 71s] [Train Loss: 3.75e-01] [Train Acc: 0.86]\n",
            "[Step 6989/50000] [Progress: 13.98%] [learning rate: 3.1e+03]\n",
            "[Step 7012/50000] [Progress: 14.02%] [learning rate: 2.8e+03]\n",
            "[Step 7021/50000] [Time: 71s] [Train Loss: 3.74e-01] [Train Acc: 0.87]\n",
            "[Step 7038/50000] [Progress: 14.08%] [learning rate: 3.0e+03]\n",
            "[Step 7066/50000] [Progress: 14.13%] [learning rate: 3.6e+03]\n",
            "[Step 7072/50000] [Time: 72s] [Train Loss: 3.73e-01] [Train Acc: 0.87]\n",
            "[Step 7089/50000] [Progress: 14.18%] [learning rate: 3.0e+03]\n",
            "[Step 7114/50000] [Progress: 14.23%] [learning rate: 2.9e+03]\n",
            "[Step 7123/50000] [Time: 72s] [Train Loss: 3.72e-01] [Train Acc: 0.87]\n",
            "[Step 7140/50000] [Progress: 14.28%] [learning rate: 2.9e+03]\n",
            "[Step 7165/50000] [Progress: 14.33%] [learning rate: 2.8e+03]\n",
            "[Step 7174/50000] [Time: 72s] [Train Loss: 3.71e-01] [Train Acc: 0.87]\n",
            "[Step 7192/50000] [Progress: 14.38%] [learning rate: 3.4e+03]\n",
            "[Step 7216/50000] [Progress: 14.43%] [learning rate: 3.0e+03]\n",
            "[Step 7226/50000] [Time: 73s] [Train Loss: 3.70e-01] [Train Acc: 0.87]\n",
            "[Step 7242/50000] [Progress: 14.48%] [learning rate: 3.0e+03]\n",
            "[Step 7268/50000] [Progress: 14.54%] [learning rate: 2.9e+03]\n",
            "[Step 7278/50000] [Time: 73s] [Train Loss: 3.69e-01] [Train Acc: 0.87]\n",
            "[Step 7293/50000] [Progress: 14.59%] [learning rate: 2.9e+03]\n",
            "[Step 7319/50000] [Progress: 14.64%] [learning rate: 3.1e+03]\n",
            "[Step 7330/50000] [Time: 73s] [Train Loss: 3.68e-01] [Train Acc: 0.87]\n",
            "[Step 7343/50000] [Progress: 14.69%] [learning rate: 3.1e+03]\n",
            "[Step 7368/50000] [Progress: 14.74%] [learning rate: 3.3e+03]\n",
            "[Step 7382/50000] [Time: 74s] [Train Loss: 3.67e-01] [Train Acc: 0.87]\n",
            "[Step 7391/50000] [Progress: 14.78%] [learning rate: 2.7e+03]\n",
            "[Step 7418/50000] [Progress: 14.84%] [learning rate: 3.2e+03]\n",
            "[Step 7435/50000] [Time: 74s] [Train Loss: 3.66e-01] [Train Acc: 0.87]\n",
            "[Step 7441/50000] [Progress: 14.88%] [learning rate: 2.9e+03]\n",
            "[Step 7466/50000] [Progress: 14.93%] [learning rate: 3.1e+03]\n",
            "[Step 7488/50000] [Time: 75s] [Train Loss: 3.65e-01] [Train Acc: 0.87]\n",
            "[Step 7490/50000] [Progress: 14.98%] [learning rate: 3.1e+03]\n",
            "[Step 7515/50000] [Progress: 15.03%] [learning rate: 3.3e+03]\n",
            "[Step 7538/50000] [Progress: 15.08%] [learning rate: 2.7e+03]\n",
            "[Step 7541/50000] [Time: 75s] [Train Loss: 3.64e-01] [Train Acc: 0.87]\n",
            "[Step 7565/50000] [Progress: 15.13%] [learning rate: 3.2e+03]\n",
            "[Step 7588/50000] [Progress: 15.18%] [learning rate: 2.6e+03]\n",
            "[Step 7594/50000] [Time: 75s] [Train Loss: 3.63e-01] [Train Acc: 0.87]\n",
            "[Step 7615/50000] [Progress: 15.23%] [learning rate: 3.1e+03]\n",
            "[Step 7641/50000] [Progress: 15.28%] [learning rate: 3.1e+03]\n",
            "[Step 7648/50000] [Time: 76s] [Train Loss: 3.63e-01] [Train Acc: 0.87]\n",
            "[Step 7667/50000] [Progress: 15.33%] [learning rate: 3.4e+03]\n",
            "[Step 7690/50000] [Progress: 15.38%] [learning rate: 2.7e+03]\n",
            "[Step 7702/50000] [Time: 76s] [Train Loss: 3.62e-01] [Train Acc: 0.87]\n",
            "[Step 7717/50000] [Progress: 15.43%] [learning rate: 3.3e+03]\n",
            "[Step 7740/50000] [Progress: 15.48%] [learning rate: 2.9e+03]\n",
            "[Step 7756/50000] [Time: 76s] [Train Loss: 3.61e-01] [Train Acc: 0.87]\n",
            "[Step 7765/50000] [Progress: 15.53%] [learning rate: 3.2e+03]\n",
            "[Step 7789/50000] [Progress: 15.58%] [learning rate: 3.1e+03]\n",
            "[Step 7810/50000] [Time: 77s] [Train Loss: 3.60e-01] [Train Acc: 0.87]\n",
            "[Step 7814/50000] [Progress: 15.63%] [learning rate: 3.1e+03]\n",
            "[Step 7838/50000] [Progress: 15.68%] [learning rate: 3.0e+03]\n",
            "[Step 7863/50000] [Progress: 15.73%] [learning rate: 3.0e+03]\n",
            "[Step 7865/50000] [Time: 77s] [Train Loss: 3.59e-01] [Train Acc: 0.87]\n",
            "[Step 7889/50000] [Progress: 15.78%] [learning rate: 3.2e+03]\n",
            "[Step 7913/50000] [Progress: 15.83%] [learning rate: 2.9e+03]\n",
            "[Step 7920/50000] [Time: 78s] [Train Loss: 3.58e-01] [Train Acc: 0.87]\n",
            "[Step 7940/50000] [Progress: 15.88%] [learning rate: 3.1e+03]\n",
            "[Step 7965/50000] [Progress: 15.93%] [learning rate: 3.1e+03]\n",
            "[Step 7975/50000] [Time: 78s] [Train Loss: 3.57e-01] [Train Acc: 0.88]\n",
            "[Step 7991/50000] [Progress: 15.98%] [learning rate: 3.0e+03]\n",
            "[Step 8017/50000] [Progress: 16.03%] [learning rate: 3.0e+03]\n",
            "[Step 8030/50000] [Time: 78s] [Train Loss: 3.56e-01] [Train Acc: 0.88]\n",
            "[Step 8042/50000] [Progress: 16.08%] [learning rate: 2.9e+03]\n",
            "[Step 8069/50000] [Progress: 16.14%] [learning rate: 3.2e+03]\n",
            "[Step 8086/50000] [Time: 79s] [Train Loss: 3.55e-01] [Train Acc: 0.88]\n",
            "[Step 8095/50000] [Progress: 16.19%] [learning rate: 3.1e+03]\n",
            "[Step 8121/50000] [Progress: 16.24%] [learning rate: 3.1e+03]\n",
            "[Step 8142/50000] [Time: 79s] [Train Loss: 3.54e-01] [Train Acc: 0.88]\n",
            "[Step 8145/50000] [Progress: 16.29%] [learning rate: 3.0e+03]\n",
            "[Step 8170/50000] [Progress: 16.34%] [learning rate: 3.0e+03]\n",
            "[Step 8196/50000] [Progress: 16.39%] [learning rate: 3.2e+03]\n",
            "[Step 8198/50000] [Time: 79s] [Train Loss: 3.53e-01] [Train Acc: 0.88]\n",
            "[Step 8220/50000] [Progress: 16.44%] [learning rate: 2.9e+03]\n",
            "[Step 8247/50000] [Progress: 16.49%] [learning rate: 3.5e+03]\n",
            "[Step 8254/50000] [Time: 80s] [Train Loss: 3.52e-01] [Train Acc: 0.88]\n",
            "[Step 8270/50000] [Progress: 16.54%] [learning rate: 2.8e+03]\n",
            "[Step 8296/50000] [Progress: 16.59%] [learning rate: 3.1e+03]\n",
            "[Step 8311/50000] [Time: 80s] [Train Loss: 3.51e-01] [Train Acc: 0.88]\n",
            "[Step 8320/50000] [Progress: 16.64%] [learning rate: 3.0e+03]\n",
            "[Step 8345/50000] [Progress: 16.69%] [learning rate: 3.0e+03]\n",
            "[Step 8368/50000] [Time: 81s] [Train Loss: 3.50e-01] [Train Acc: 0.88]\n",
            "[Step 8370/50000] [Progress: 16.74%] [learning rate: 3.2e+03]\n",
            "[Step 8394/50000] [Progress: 16.79%] [learning rate: 3.2e+03]\n",
            "[Step 8419/50000] [Progress: 16.84%] [learning rate: 3.1e+03]\n",
            "[Step 8425/50000] [Time: 81s] [Train Loss: 3.50e-01] [Train Acc: 0.88]\n",
            "[Step 8445/50000] [Progress: 16.89%] [learning rate: 3.1e+03]\n",
            "[Step 8469/50000] [Progress: 16.94%] [learning rate: 3.0e+03]\n",
            "[Step 8482/50000] [Time: 82s] [Train Loss: 3.49e-01] [Train Acc: 0.88]\n",
            "[Step 8494/50000] [Progress: 16.99%] [learning rate: 3.3e+03]\n",
            "[Step 8518/50000] [Progress: 17.04%] [learning rate: 2.9e+03]\n",
            "[Step 8540/50000] [Time: 82s] [Train Loss: 3.48e-01] [Train Acc: 0.88]\n",
            "[Step 8545/50000] [Progress: 17.09%] [learning rate: 3.5e+03]\n",
            "[Step 8568/50000] [Progress: 17.14%] [learning rate: 2.8e+03]\n",
            "[Step 8595/50000] [Progress: 17.19%] [learning rate: 3.4e+03]\n",
            "[Step 8598/50000] [Time: 83s] [Train Loss: 3.47e-01] [Train Acc: 0.88] [Eval Loss: 5.34e-01] [Eval Acc: 0.74]\n",
            "[Step 8618/50000] [Progress: 17.24%] [learning rate: 3.0e+03]\n",
            "[Step 8643/50000] [Progress: 17.29%] [learning rate: 3.0e+03]\n",
            "[Step 8656/50000] [Time: 85s] [Train Loss: 3.46e-01] [Train Acc: 0.88]\n",
            "[Step 8670/50000] [Progress: 17.34%] [learning rate: 3.2e+03]\n",
            "[Step 8696/50000] [Progress: 17.39%] [learning rate: 3.2e+03]\n",
            "[Step 8714/50000] [Time: 85s] [Train Loss: 3.45e-01] [Train Acc: 0.88]\n",
            "[Step 8722/50000] [Progress: 17.44%] [learning rate: 3.5e+03]\n",
            "[Step 8745/50000] [Progress: 17.49%] [learning rate: 2.8e+03]\n",
            "[Step 8772/50000] [Progress: 17.54%] [learning rate: 3.4e+03]\n",
            "[Step 8773/50000] [Time: 85s] [Train Loss: 3.44e-01] [Train Acc: 0.88]\n",
            "[Step 8795/50000] [Progress: 17.59%] [learning rate: 3.0e+03]\n",
            "[Step 8821/50000] [Progress: 17.64%] [learning rate: 3.3e+03]\n",
            "[Step 8832/50000] [Time: 86s] [Train Loss: 3.43e-01] [Train Acc: 0.88]\n",
            "[Step 8847/50000] [Progress: 17.69%] [learning rate: 3.2e+03]\n",
            "[Step 8873/50000] [Progress: 17.75%] [learning rate: 3.5e+03]\n",
            "[Step 8891/50000] [Time: 86s] [Train Loss: 3.42e-01] [Train Acc: 0.88]\n",
            "[Step 8896/50000] [Progress: 17.79%] [learning rate: 2.8e+03]\n",
            "[Step 8923/50000] [Progress: 17.85%] [learning rate: 3.4e+03]\n",
            "[Step 8946/50000] [Progress: 17.89%] [learning rate: 3.0e+03]\n",
            "[Step 8950/50000] [Time: 87s] [Train Loss: 3.42e-01] [Train Acc: 0.88]\n",
            "[Step 8971/50000] [Progress: 17.94%] [learning rate: 3.3e+03]\n",
            "[Step 8996/50000] [Progress: 17.99%] [learning rate: 3.2e+03]\n",
            "[Step 9010/50000] [Time: 87s] [Train Loss: 3.41e-01] [Train Acc: 0.88]\n",
            "[Step 9022/50000] [Progress: 18.04%] [learning rate: 3.2e+03]\n",
            "[Step 9046/50000] [Progress: 18.09%] [learning rate: 3.1e+03]\n",
            "[Step 9070/50000] [Time: 87s] [Train Loss: 3.40e-01] [Train Acc: 0.88]\n",
            "[Step 9071/50000] [Progress: 18.14%] [learning rate: 3.1e+03]\n",
            "[Step 9097/50000] [Progress: 18.19%] [learning rate: 3.3e+03]\n",
            "[Step 9121/50000] [Progress: 18.24%] [learning rate: 3.0e+03]\n",
            "[Step 9130/50000] [Time: 88s] [Train Loss: 3.39e-01] [Train Acc: 0.88]\n",
            "[Step 9148/50000] [Progress: 18.30%] [learning rate: 3.6e+03]\n",
            "[Step 9171/50000] [Progress: 18.34%] [learning rate: 3.2e+03]\n",
            "[Step 9190/50000] [Time: 88s] [Train Loss: 3.38e-01] [Train Acc: 0.89]\n",
            "[Step 9195/50000] [Progress: 18.39%] [learning rate: 3.1e+03]\n",
            "[Step 9220/50000] [Progress: 18.44%] [learning rate: 3.1e+03]\n",
            "[Step 9245/50000] [Progress: 18.49%] [learning rate: 3.0e+03]\n",
            "[Step 9251/50000] [Time: 89s] [Train Loss: 3.37e-01] [Train Acc: 0.89]\n",
            "[Step 9272/50000] [Progress: 18.54%] [learning rate: 3.3e+03]\n",
            "[Step 9298/50000] [Progress: 18.60%] [learning rate: 3.3e+03]\n",
            "[Step 9312/50000] [Time: 89s] [Train Loss: 3.36e-01] [Train Acc: 0.89]\n",
            "[Step 9324/50000] [Progress: 18.65%] [learning rate: 3.5e+03]\n",
            "[Step 9347/50000] [Progress: 18.69%] [learning rate: 2.9e+03]\n",
            "[Step 9373/50000] [Time: 89s] [Train Loss: 3.35e-01] [Train Acc: 0.89]\n",
            "[Step 9374/50000] [Progress: 18.75%] [learning rate: 3.4e+03]\n",
            "[Step 9397/50000] [Progress: 18.79%] [learning rate: 3.1e+03]\n",
            "[Step 9423/50000] [Progress: 18.85%] [learning rate: 3.3e+03]\n",
            "[Step 9434/50000] [Time: 90s] [Train Loss: 3.35e-01] [Train Acc: 0.89]\n",
            "[Step 9449/50000] [Progress: 18.90%] [learning rate: 3.3e+03]\n",
            "[Step 9475/50000] [Progress: 18.95%] [learning rate: 3.5e+03]\n",
            "[Step 9496/50000] [Time: 90s] [Train Loss: 3.34e-01] [Train Acc: 0.89]\n",
            "[Step 9498/50000] [Progress: 19.00%] [learning rate: 2.9e+03]\n",
            "[Step 9525/50000] [Progress: 19.05%] [learning rate: 3.4e+03]\n",
            "[Step 9548/50000] [Progress: 19.10%] [learning rate: 3.1e+03]\n",
            "[Step 9558/50000] [Time: 91s] [Train Loss: 3.33e-01] [Train Acc: 0.89]\n",
            "[Step 9574/50000] [Progress: 19.15%] [learning rate: 3.3e+03]\n",
            "[Step 9600/50000] [Progress: 19.20%] [learning rate: 3.3e+03]\n",
            "[Step 9620/50000] [Time: 91s] [Train Loss: 3.32e-01] [Train Acc: 0.89]\n",
            "[Step 9626/50000] [Progress: 19.25%] [learning rate: 3.6e+03]\n",
            "[Step 9649/50000] [Progress: 19.30%] [learning rate: 2.9e+03]\n",
            "[Step 9676/50000] [Progress: 19.35%] [learning rate: 3.4e+03]\n",
            "[Step 9682/50000] [Time: 92s] [Train Loss: 3.31e-01] [Train Acc: 0.89]\n",
            "[Step 9699/50000] [Progress: 19.40%] [learning rate: 3.1e+03]\n",
            "[Step 9724/50000] [Progress: 19.45%] [learning rate: 3.3e+03]\n",
            "[Step 9745/50000] [Time: 92s] [Train Loss: 3.30e-01] [Train Acc: 0.89]\n",
            "[Step 9749/50000] [Progress: 19.50%] [learning rate: 3.3e+03]\n",
            "[Step 9775/50000] [Progress: 19.55%] [learning rate: 3.6e+03]\n",
            "[Step 9798/50000] [Progress: 19.60%] [learning rate: 2.9e+03]\n",
            "[Step 9808/50000] [Time: 92s] [Train Loss: 3.29e-01] [Train Acc: 0.89]\n",
            "[Step 9825/50000] [Progress: 19.65%] [learning rate: 3.5e+03]\n",
            "[Step 9848/50000] [Progress: 19.70%] [learning rate: 3.1e+03]\n",
            "[Step 9871/50000] [Time: 93s] [Train Loss: 3.29e-01] [Train Acc: 0.89]\n",
            "[Step 9874/50000] [Progress: 19.75%] [learning rate: 3.4e+03]\n",
            "[Step 9900/50000] [Progress: 19.80%] [learning rate: 3.3e+03]\n",
            "[Step 9926/50000] [Progress: 19.85%] [learning rate: 3.6e+03]\n",
            "[Step 9934/50000] [Time: 93s] [Train Loss: 3.28e-01] [Train Acc: 0.89]\n",
            "[Step 9949/50000] [Progress: 19.90%] [learning rate: 2.9e+03]\n",
            "[Step 9976/50000] [Progress: 19.95%] [learning rate: 3.5e+03]\n",
            "[Step 9997/50000] [Time: 94s] [Train Loss: 3.27e-01] [Train Acc: 0.89]\n",
            "[Step 9999/50000] [Progress: 20.00%] [learning rate: 3.1e+03]\n",
            "[Step 10025/50000] [Progress: 20.05%] [learning rate: 3.4e+03]\n",
            "[Step 10051/50000] [Progress: 20.10%] [learning rate: 3.3e+03]\n",
            "[Step 10061/50000] [Time: 94s] [Train Loss: 3.26e-01] [Train Acc: 0.89]\n",
            "[Step 10077/50000] [Progress: 20.15%] [learning rate: 3.6e+03]\n",
            "[Step 10100/50000] [Progress: 20.20%] [learning rate: 2.9e+03]\n",
            "[Step 10125/50000] [Time: 95s] [Train Loss: 3.25e-01] [Train Acc: 0.89]\n",
            "[Step 10127/50000] [Progress: 20.25%] [learning rate: 3.5e+03]\n",
            "[Step 10150/50000] [Progress: 20.30%] [learning rate: 3.1e+03]\n",
            "[Step 10176/50000] [Progress: 20.35%] [learning rate: 3.4e+03]\n",
            "[Step 10189/50000] [Time: 95s] [Train Loss: 3.24e-01] [Train Acc: 0.89]\n",
            "[Step 10202/50000] [Progress: 20.40%] [learning rate: 3.3e+03]\n",
            "[Step 10228/50000] [Progress: 20.46%] [learning rate: 3.6e+03]\n",
            "[Step 10251/50000] [Progress: 20.50%] [learning rate: 2.9e+03]\n",
            "[Step 10253/50000] [Time: 96s] [Train Loss: 3.24e-01] [Train Acc: 0.89]\n",
            "[Step 10278/50000] [Progress: 20.56%] [learning rate: 3.5e+03]\n",
            "[Step 10301/50000] [Progress: 20.60%] [learning rate: 3.1e+03]\n",
            "[Step 10318/50000] [Time: 96s] [Train Loss: 3.23e-01] [Train Acc: 0.89]\n",
            "[Step 10327/50000] [Progress: 20.65%] [learning rate: 3.4e+03]\n",
            "[Step 10353/50000] [Progress: 20.71%] [learning rate: 3.4e+03]\n",
            "[Step 10379/50000] [Progress: 20.76%] [learning rate: 3.6e+03]\n",
            "[Step 10383/50000] [Time: 97s] [Train Loss: 3.22e-01] [Train Acc: 0.89]\n",
            "[Step 10402/50000] [Progress: 20.80%] [learning rate: 3.0e+03]\n",
            "[Step 10429/50000] [Progress: 20.86%] [learning rate: 3.5e+03]\n",
            "[Step 10448/50000] [Time: 97s] [Train Loss: 3.21e-01] [Train Acc: 0.90]\n",
            "[Step 10452/50000] [Progress: 20.90%] [learning rate: 3.2e+03]\n",
            "[Step 10478/50000] [Progress: 20.96%] [learning rate: 3.4e+03]\n",
            "[Step 10504/50000] [Progress: 21.01%] [learning rate: 3.4e+03]\n",
            "[Step 10513/50000] [Time: 98s] [Train Loss: 3.20e-01] [Train Acc: 0.90]\n",
            "[Step 10530/50000] [Progress: 21.06%] [learning rate: 3.7e+03]\n",
            "[Step 10553/50000] [Progress: 21.11%] [learning rate: 3.0e+03]\n",
            "[Step 10579/50000] [Time: 98s] [Train Loss: 3.19e-01] [Train Acc: 0.90]\n",
            "[Step 10580/50000] [Progress: 21.16%] [learning rate: 3.5e+03]\n",
            "[Step 10603/50000] [Progress: 21.21%] [learning rate: 3.2e+03]\n",
            "[Step 10628/50000] [Progress: 21.26%] [learning rate: 3.4e+03]\n",
            "[Step 10645/50000] [Time: 98s] [Train Loss: 3.19e-01] [Train Acc: 0.90]\n",
            "[Step 10653/50000] [Progress: 21.31%] [learning rate: 3.4e+03]\n",
            "[Step 10679/50000] [Progress: 21.36%] [learning rate: 3.7e+03]\n",
            "[Step 10702/50000] [Progress: 21.40%] [learning rate: 3.0e+03]\n",
            "[Step 10711/50000] [Time: 99s] [Train Loss: 3.18e-01] [Train Acc: 0.90]\n",
            "[Step 10729/50000] [Progress: 21.46%] [learning rate: 3.6e+03]\n",
            "[Step 10752/50000] [Progress: 21.50%] [learning rate: 3.2e+03]\n",
            "[Step 10777/50000] [Time: 99s] [Train Loss: 3.17e-01] [Train Acc: 0.90]\n",
            "[Step 10778/50000] [Progress: 21.56%] [learning rate: 3.5e+03]\n",
            "[Step 10804/50000] [Progress: 21.61%] [learning rate: 3.4e+03]\n",
            "[Step 10830/50000] [Progress: 21.66%] [learning rate: 3.7e+03]\n",
            "[Step 10843/50000] [Time: 100s] [Train Loss: 3.16e-01] [Train Acc: 0.90]\n",
            "[Step 10853/50000] [Progress: 21.71%] [learning rate: 3.0e+03]\n",
            "[Step 10880/50000] [Progress: 21.76%] [learning rate: 3.6e+03]\n",
            "[Step 10903/50000] [Progress: 21.81%] [learning rate: 3.2e+03]\n",
            "[Step 10910/50000] [Time: 100s] [Train Loss: 3.15e-01] [Train Acc: 0.90]\n",
            "[Step 10928/50000] [Progress: 21.86%] [learning rate: 3.5e+03]\n",
            "[Step 10953/50000] [Progress: 21.91%] [learning rate: 3.4e+03]\n",
            "[Step 10977/50000] [Time: 101s] [Train Loss: 3.15e-01] [Train Acc: 0.90]\n",
            "[Step 10979/50000] [Progress: 21.96%] [learning rate: 3.7e+03]\n",
            "[Step 11002/50000] [Progress: 22.00%] [learning rate: 3.0e+03]\n",
            "[Step 11029/50000] [Progress: 22.06%] [learning rate: 3.6e+03]\n",
            "[Step 11044/50000] [Time: 101s] [Train Loss: 3.14e-01] [Train Acc: 0.90]\n",
            "[Step 11052/50000] [Progress: 22.10%] [learning rate: 3.2e+03]\n",
            "[Step 11077/50000] [Progress: 22.15%] [learning rate: 3.5e+03]\n",
            "[Step 11102/50000] [Progress: 22.20%] [learning rate: 3.4e+03]\n",
            "[Step 11111/50000] [Time: 102s] [Train Loss: 3.13e-01] [Train Acc: 0.90]\n",
            "[Step 11128/50000] [Progress: 22.26%] [learning rate: 3.4e+03]\n",
            "[Step 11152/50000] [Progress: 22.30%] [learning rate: 3.3e+03]\n",
            "[Step 11177/50000] [Progress: 22.35%] [learning rate: 3.3e+03]\n",
            "[Step 11179/50000] [Time: 102s] [Train Loss: 3.12e-01] [Train Acc: 0.90]\n",
            "[Step 11203/50000] [Progress: 22.41%] [learning rate: 3.6e+03]\n",
            "[Step 11227/50000] [Progress: 22.45%] [learning rate: 3.2e+03]\n",
            "[Step 11247/50000] [Time: 103s] [Train Loss: 3.11e-01] [Train Acc: 0.90]\n",
            "[Step 11254/50000] [Progress: 22.51%] [learning rate: 3.8e+03]\n",
            "[Step 11277/50000] [Progress: 22.55%] [learning rate: 3.1e+03]\n",
            "[Step 11303/50000] [Progress: 22.61%] [learning rate: 3.3e+03]\n",
            "[Step 11315/50000] [Time: 103s] [Train Loss: 3.11e-01] [Train Acc: 0.90]\n",
            "[Step 11327/50000] [Progress: 22.65%] [learning rate: 3.3e+03]\n",
            "[Step 11352/50000] [Progress: 22.70%] [learning rate: 3.6e+03]\n",
            "[Step 11376/50000] [Progress: 22.75%] [learning rate: 3.2e+03]\n",
            "[Step 11383/50000] [Time: 104s] [Train Loss: 3.10e-01] [Train Acc: 0.90]\n",
            "[Step 11403/50000] [Progress: 22.81%] [learning rate: 3.8e+03]\n",
            "[Step 11426/50000] [Progress: 22.85%] [learning rate: 3.1e+03]\n",
            "[Step 11451/50000] [Time: 104s] [Train Loss: 3.09e-01] [Train Acc: 0.90]\n",
            "[Step 11452/50000] [Progress: 22.90%] [learning rate: 3.4e+03]\n",
            "[Step 11478/50000] [Progress: 22.96%] [learning rate: 3.6e+03]\n",
            "[Step 11501/50000] [Progress: 23.00%] [learning rate: 3.0e+03]\n",
            "[Step 11520/50000] [Time: 104s] [Train Loss: 3.08e-01] [Train Acc: 0.90]\n",
            "[Step 11528/50000] [Progress: 23.06%] [learning rate: 3.5e+03]\n",
            "[Step 11554/50000] [Progress: 23.11%] [learning rate: 3.5e+03]\n",
            "[Step 11580/50000] [Progress: 23.16%] [learning rate: 3.8e+03]\n",
            "[Step 11589/50000] [Time: 105s] [Train Loss: 3.08e-01] [Train Acc: 0.91]\n",
            "[Step 11603/50000] [Progress: 23.21%] [learning rate: 3.1e+03]\n",
            "[Step 11630/50000] [Progress: 23.26%] [learning rate: 3.7e+03]\n",
            "[Step 11653/50000] [Progress: 23.31%] [learning rate: 3.3e+03]\n",
            "[Step 11658/50000] [Time: 105s] [Train Loss: 3.07e-01] [Train Acc: 0.91]\n",
            "[Step 11679/50000] [Progress: 23.36%] [learning rate: 3.5e+03]\n",
            "[Step 11705/50000] [Progress: 23.41%] [learning rate: 3.5e+03]\n",
            "[Step 11727/50000] [Time: 106s] [Train Loss: 3.06e-01] [Train Acc: 0.91]\n",
            "[Step 11731/50000] [Progress: 23.46%] [learning rate: 3.4e+03]\n",
            "[Step 11755/50000] [Progress: 23.51%] [learning rate: 3.4e+03]\n",
            "[Step 11780/50000] [Progress: 23.56%] [learning rate: 3.3e+03]\n",
            "[Step 11797/50000] [Time: 106s] [Train Loss: 3.05e-01] [Train Acc: 0.91] [Eval Loss: 5.19e-01] [Eval Acc: 0.75]\n",
            "[Step 11806/50000] [Progress: 23.61%] [learning rate: 3.6e+03]\n",
            "[Step 11830/50000] [Progress: 23.66%] [learning rate: 3.2e+03]\n",
            "[Step 11857/50000] [Progress: 23.71%] [learning rate: 3.9e+03]\n",
            "[Step 11867/50000] [Time: 109s] [Train Loss: 3.04e-01] [Train Acc: 0.91]\n",
            "[Step 11880/50000] [Progress: 23.76%] [learning rate: 3.1e+03]\n",
            "[Step 11906/50000] [Progress: 23.81%] [learning rate: 3.4e+03]\n",
            "[Step 11932/50000] [Progress: 23.86%] [learning rate: 3.7e+03]\n",
            "[Step 11937/50000] [Time: 109s] [Train Loss: 3.04e-01] [Train Acc: 0.91]\n",
            "[Step 11955/50000] [Progress: 23.91%] [learning rate: 3.0e+03]\n",
            "[Step 11982/50000] [Progress: 23.96%] [learning rate: 3.6e+03]\n",
            "[Step 12007/50000] [Time: 110s] [Train Loss: 3.03e-01] [Train Acc: 0.91]\n",
            "[Step 12008/50000] [Progress: 24.02%] [learning rate: 3.5e+03]\n",
            "[Step 12034/50000] [Progress: 24.07%] [learning rate: 3.8e+03]\n",
            "[Step 12057/50000] [Progress: 24.11%] [learning rate: 3.1e+03]\n",
            "[Step 12077/50000] [Time: 110s] [Train Loss: 3.02e-01] [Train Acc: 0.91]\n",
            "[Step 12084/50000] [Progress: 24.17%] [learning rate: 3.7e+03]\n",
            "[Step 12107/50000] [Progress: 24.21%] [learning rate: 3.3e+03]\n",
            "[Step 12132/50000] [Progress: 24.26%] [learning rate: 3.6e+03]\n",
            "[Step 12148/50000] [Time: 111s] [Train Loss: 3.01e-01] [Train Acc: 0.91]\n",
            "[Step 12156/50000] [Progress: 24.31%] [learning rate: 3.5e+03]\n",
            "[Step 12181/50000] [Progress: 24.36%] [learning rate: 3.5e+03]\n",
            "[Step 12205/50000] [Progress: 24.41%] [learning rate: 3.4e+03]\n",
            "[Step 12219/50000] [Time: 111s] [Train Loss: 3.01e-01] [Train Acc: 0.91]\n",
            "[Step 12230/50000] [Progress: 24.46%] [learning rate: 3.4e+03]\n",
            "[Step 12256/50000] [Progress: 24.51%] [learning rate: 3.7e+03]\n",
            "[Step 12280/50000] [Progress: 24.56%] [learning rate: 3.3e+03]\n",
            "[Step 12290/50000] [Time: 112s] [Train Loss: 3.00e-01] [Train Acc: 0.91]\n",
            "[Step 12307/50000] [Progress: 24.61%] [learning rate: 3.6e+03]\n",
            "[Step 12332/50000] [Progress: 24.66%] [learning rate: 3.5e+03]\n",
            "[Step 12358/50000] [Progress: 24.72%] [learning rate: 3.4e+03]\n",
            "[Step 12361/50000] [Time: 112s] [Train Loss: 2.99e-01] [Train Acc: 0.91]\n",
            "[Step 12384/50000] [Progress: 24.77%] [learning rate: 3.4e+03]\n",
            "[Step 12409/50000] [Progress: 24.82%] [learning rate: 3.3e+03]\n",
            "[Step 12432/50000] [Time: 113s] [Train Loss: 2.98e-01] [Train Acc: 0.91]\n",
            "[Step 12436/50000] [Progress: 24.87%] [learning rate: 3.6e+03]\n",
            "[Step 12461/50000] [Progress: 24.92%] [learning rate: 3.6e+03]\n",
            "[Step 12486/50000] [Progress: 24.97%] [learning rate: 3.9e+03]\n",
            "[Step 12504/50000] [Time: 113s] [Train Loss: 2.98e-01] [Train Acc: 0.91]\n",
            "[Step 12509/50000] [Progress: 25.02%] [learning rate: 3.1e+03]\n",
            "[Step 12536/50000] [Progress: 25.07%] [learning rate: 3.8e+03]\n",
            "[Step 12559/50000] [Progress: 25.12%] [learning rate: 3.4e+03]\n",
            "[Step 12576/50000] [Time: 114s] [Train Loss: 2.97e-01] [Train Acc: 0.91]\n",
            "[Step 12584/50000] [Progress: 25.17%] [learning rate: 3.6e+03]\n",
            "[Step 12608/50000] [Progress: 25.22%] [learning rate: 3.6e+03]\n",
            "[Step 12633/50000] [Progress: 25.27%] [learning rate: 3.5e+03]\n",
            "[Step 12648/50000] [Time: 114s] [Train Loss: 2.96e-01] [Train Acc: 0.91]\n",
            "[Step 12657/50000] [Progress: 25.31%] [learning rate: 3.5e+03]\n",
            "[Step 12682/50000] [Progress: 25.36%] [learning rate: 3.4e+03]\n",
            "[Step 12708/50000] [Progress: 25.42%] [learning rate: 3.7e+03]\n",
            "[Step 12720/50000] [Time: 115s] [Train Loss: 2.96e-01] [Train Acc: 0.91]\n",
            "[Step 12731/50000] [Progress: 25.46%] [learning rate: 3.3e+03]\n",
            "[Step 12757/50000] [Progress: 25.51%] [learning rate: 3.6e+03]\n",
            "[Step 12782/50000] [Progress: 25.56%] [learning rate: 3.5e+03]\n",
            "[Step 12792/50000] [Time: 115s] [Train Loss: 2.95e-01] [Train Acc: 0.91]\n",
            "[Step 12806/50000] [Progress: 25.61%] [learning rate: 3.5e+03]\n",
            "[Step 12831/50000] [Progress: 25.66%] [learning rate: 3.4e+03]\n",
            "[Step 12857/50000] [Progress: 25.71%] [learning rate: 3.4e+03]\n",
            "[Step 12865/50000] [Time: 116s] [Train Loss: 2.94e-01] [Train Acc: 0.91]\n",
            "[Step 12882/50000] [Progress: 25.76%] [learning rate: 3.3e+03]\n",
            "[Step 12908/50000] [Progress: 25.82%] [learning rate: 3.6e+03]\n",
            "[Step 12935/50000] [Progress: 25.87%] [learning rate: 3.9e+03]\n",
            "[Step 12938/50000] [Time: 116s] [Train Loss: 2.93e-01] [Train Acc: 0.91]\n",
            "[Step 12959/50000] [Progress: 25.92%] [learning rate: 3.5e+03]\n",
            "[Step 12984/50000] [Progress: 25.97%] [learning rate: 3.5e+03]\n",
            "[Step 13010/50000] [Progress: 26.02%] [learning rate: 3.4e+03]\n",
            "[Step 13011/50000] [Time: 117s] [Train Loss: 2.93e-01] [Train Acc: 0.91]\n",
            "[Step 13035/50000] [Progress: 26.07%] [learning rate: 3.4e+03]\n",
            "[Step 13062/50000] [Progress: 26.12%] [learning rate: 4.0e+03]\n",
            "[Step 13084/50000] [Time: 117s] [Train Loss: 2.92e-01] [Train Acc: 0.91]\n",
            "[Step 13085/50000] [Progress: 26.17%] [learning rate: 3.6e+03]\n",
            "[Step 13110/50000] [Progress: 26.22%] [learning rate: 3.5e+03]\n",
            "[Step 13136/50000] [Progress: 26.27%] [learning rate: 3.5e+03]\n",
            "[Step 13157/50000] [Time: 118s] [Train Loss: 2.91e-01] [Train Acc: 0.91]\n",
            "[Step 13161/50000] [Progress: 26.32%] [learning rate: 3.4e+03]\n",
            "[Step 13187/50000] [Progress: 26.37%] [learning rate: 3.7e+03]\n",
            "[Step 13211/50000] [Progress: 26.42%] [learning rate: 3.7e+03]\n",
            "[Step 13231/50000] [Time: 118s] [Train Loss: 2.90e-01] [Train Acc: 0.91]\n",
            "[Step 13237/50000] [Progress: 26.47%] [learning rate: 4.0e+03]\n",
            "[Step 13261/50000] [Progress: 26.52%] [learning rate: 3.5e+03]\n",
            "[Step 13286/50000] [Progress: 26.57%] [learning rate: 3.5e+03]\n",
            "[Step 13305/50000] [Time: 119s] [Train Loss: 2.90e-01] [Train Acc: 0.91]\n",
            "[Step 13312/50000] [Progress: 26.62%] [learning rate: 3.4e+03]\n",
            "[Step 13337/50000] [Progress: 26.67%] [learning rate: 3.4e+03]\n",
            "[Step 13364/50000] [Progress: 26.73%] [learning rate: 4.0e+03]\n",
            "[Step 13379/50000] [Time: 120s] [Train Loss: 2.89e-01] [Train Acc: 0.91]\n",
            "[Step 13388/50000] [Progress: 26.78%] [learning rate: 4.0e+03]\n",
            "[Step 13411/50000] [Progress: 26.82%] [learning rate: 3.2e+03]\n",
            "[Step 13437/50000] [Progress: 26.87%] [learning rate: 3.5e+03]\n",
            "[Step 13453/50000] [Time: 120s] [Train Loss: 2.88e-01] [Train Acc: 0.91]\n",
            "[Step 13461/50000] [Progress: 26.92%] [learning rate: 3.5e+03]\n",
            "[Step 13486/50000] [Progress: 26.97%] [learning rate: 3.7e+03]\n",
            "[Step 13510/50000] [Progress: 27.02%] [learning rate: 3.3e+03]\n",
            "[Step 13527/50000] [Time: 121s] [Train Loss: 2.88e-01] [Train Acc: 0.91]\n",
            "[Step 13537/50000] [Progress: 27.07%] [learning rate: 4.4e+03]\n",
            "[Step 13558/50000] [Progress: 27.12%] [learning rate: 3.0e+03]\n",
            "[Step 13587/50000] [Progress: 27.17%] [learning rate: 3.9e+03]\n",
            "[Step 13602/50000] [Time: 121s] [Train Loss: 2.87e-01] [Train Acc: 0.91]\n",
            "[Step 13612/50000] [Progress: 27.22%] [learning rate: 3.5e+03]\n",
            "[Step 13638/50000] [Progress: 27.28%] [learning rate: 3.8e+03]\n",
            "[Step 13662/50000] [Progress: 27.32%] [learning rate: 3.4e+03]\n",
            "[Step 13677/50000] [Time: 122s] [Train Loss: 2.86e-01] [Train Acc: 0.91]\n",
            "[Step 13689/50000] [Progress: 27.38%] [learning rate: 4.0e+03]\n",
            "[Step 13714/50000] [Progress: 27.43%] [learning rate: 3.6e+03]\n",
            "[Step 13740/50000] [Progress: 27.48%] [learning rate: 3.5e+03]\n",
            "[Step 13752/50000] [Time: 122s] [Train Loss: 2.85e-01] [Train Acc: 0.91]\n",
            "[Step 13766/50000] [Progress: 27.53%] [learning rate: 3.5e+03]\n",
            "[Step 13791/50000] [Progress: 27.58%] [learning rate: 3.4e+03]\n",
            "[Step 13816/50000] [Progress: 27.63%] [learning rate: 3.7e+03]\n",
            "[Step 13827/50000] [Time: 123s] [Train Loss: 2.85e-01] [Train Acc: 0.91]\n",
            "[Step 13841/50000] [Progress: 27.68%] [learning rate: 4.0e+03]\n",
            "[Step 13864/50000] [Progress: 27.73%] [learning rate: 3.3e+03]\n",
            "[Step 13891/50000] [Progress: 27.78%] [learning rate: 3.9e+03]\n",
            "[Step 13902/50000] [Time: 123s] [Train Loss: 2.84e-01] [Train Acc: 0.91]\n",
            "[Step 13914/50000] [Progress: 27.83%] [learning rate: 3.5e+03]\n",
            "[Step 13939/50000] [Progress: 27.88%] [learning rate: 3.4e+03]\n",
            "[Step 13964/50000] [Progress: 27.93%] [learning rate: 3.7e+03]\n",
            "[Step 13978/50000] [Time: 124s] [Train Loss: 2.83e-01] [Train Acc: 0.91]\n",
            "[Step 13989/50000] [Progress: 27.98%] [learning rate: 4.0e+03]\n",
            "[Step 14012/50000] [Progress: 28.02%] [learning rate: 3.3e+03]\n",
            "[Step 14039/50000] [Progress: 28.08%] [learning rate: 3.9e+03]\n",
            "[Step 14054/50000] [Time: 124s] [Train Loss: 2.83e-01] [Train Acc: 0.92]\n",
            "[Step 14062/50000] [Progress: 28.12%] [learning rate: 3.5e+03]\n",
            "[Step 14087/50000] [Progress: 28.17%] [learning rate: 3.5e+03]\n",
            "[Step 14112/50000] [Progress: 28.22%] [learning rate: 3.8e+03]\n",
            "[Step 14130/50000] [Time: 125s] [Train Loss: 2.82e-01] [Train Acc: 0.92]\n",
            "[Step 14137/50000] [Progress: 28.27%] [learning rate: 3.7e+03]\n",
            "[Step 14163/50000] [Progress: 28.33%] [learning rate: 4.0e+03]\n",
            "[Step 14186/50000] [Progress: 28.37%] [learning rate: 3.3e+03]\n",
            "[Step 14206/50000] [Time: 126s] [Train Loss: 2.81e-01] [Train Acc: 0.92]\n",
            "[Step 14213/50000] [Progress: 28.43%] [learning rate: 3.9e+03]\n",
            "[Step 14236/50000] [Progress: 28.47%] [learning rate: 3.5e+03]\n",
            "[Step 14262/50000] [Progress: 28.52%] [learning rate: 3.8e+03]\n",
            "[Step 14282/50000] [Time: 126s] [Train Loss: 2.81e-01] [Train Acc: 0.92]\n",
            "[Step 14288/50000] [Progress: 28.58%] [learning rate: 4.1e+03]\n",
            "[Step 14311/50000] [Progress: 28.62%] [learning rate: 3.3e+03]\n",
            "[Step 14338/50000] [Progress: 28.68%] [learning rate: 4.0e+03]\n",
            "[Step 14359/50000] [Time: 127s] [Train Loss: 2.80e-01] [Train Acc: 0.92]\n",
            "[Step 14361/50000] [Progress: 28.72%] [learning rate: 3.2e+03]\n",
            "[Step 14387/50000] [Progress: 28.77%] [learning rate: 3.8e+03]\n",
            "[Step 14411/50000] [Progress: 28.82%] [learning rate: 3.4e+03]\n",
            "[Step 14436/50000] [Time: 127s] [Train Loss: 2.79e-01] [Train Acc: 0.92]\n",
            "[Step 14437/50000] [Progress: 28.87%] [learning rate: 4.1e+03]\n",
            "[Step 14460/50000] [Progress: 28.92%] [learning rate: 3.3e+03]\n",
            "[Step 14487/50000] [Progress: 28.97%] [learning rate: 4.0e+03]\n",
            "[Step 14510/50000] [Progress: 29.02%] [learning rate: 3.2e+03]\n",
            "[Step 14513/50000] [Time: 128s] [Train Loss: 2.79e-01] [Train Acc: 0.92]\n",
            "[Step 14536/50000] [Progress: 29.07%] [learning rate: 3.9e+03]\n",
            "[Step 14560/50000] [Progress: 29.12%] [learning rate: 3.5e+03]\n",
            "[Step 14588/50000] [Progress: 29.18%] [learning rate: 4.1e+03]\n",
            "[Step 14590/50000] [Time: 128s] [Train Loss: 2.78e-01] [Train Acc: 0.92]\n",
            "[Step 14612/50000] [Progress: 29.22%] [learning rate: 3.7e+03]\n",
            "[Step 14637/50000] [Progress: 29.27%] [learning rate: 3.6e+03]\n",
            "[Step 14663/50000] [Progress: 29.33%] [learning rate: 3.6e+03]\n",
            "[Step 14667/50000] [Time: 129s] [Train Loss: 2.77e-01] [Train Acc: 0.92]\n",
            "[Step 14688/50000] [Progress: 29.38%] [learning rate: 3.5e+03]\n",
            "[Step 14715/50000] [Progress: 29.43%] [learning rate: 3.8e+03]\n",
            "[Step 14741/50000] [Progress: 29.48%] [learning rate: 3.8e+03]\n",
            "[Step 14744/50000] [Time: 129s] [Train Loss: 2.76e-01] [Train Acc: 0.92]\n",
            "[Step 14767/50000] [Progress: 29.53%] [learning rate: 4.1e+03]\n",
            "[Step 14790/50000] [Progress: 29.58%] [learning rate: 3.3e+03]\n",
            "[Step 14817/50000] [Progress: 29.63%] [learning rate: 4.0e+03]\n",
            "[Step 14822/50000] [Time: 130s] [Train Loss: 2.76e-01] [Train Acc: 0.92]\n",
            "[Step 14840/50000] [Progress: 29.68%] [learning rate: 3.5e+03]\n",
            "[Step 14865/50000] [Progress: 29.73%] [learning rate: 3.8e+03]\n",
            "[Step 14890/50000] [Progress: 29.78%] [learning rate: 3.8e+03]\n",
            "[Step 14900/50000] [Time: 130s] [Train Loss: 2.75e-01] [Train Acc: 0.92]\n",
            "[Step 14916/50000] [Progress: 29.83%] [learning rate: 3.7e+03]\n",
            "[Step 14940/50000] [Progress: 29.88%] [learning rate: 3.7e+03]\n",
            "[Step 14965/50000] [Progress: 29.93%] [learning rate: 3.6e+03]\n",
            "[Step 14978/50000] [Time: 131s] [Train Loss: 2.75e-01] [Train Acc: 0.92]\n",
            "[Step 14991/50000] [Progress: 29.98%] [learning rate: 3.9e+03]\n",
            "[Step 15015/50000] [Progress: 30.03%] [learning rate: 3.5e+03]\n",
            "[Step 15042/50000] [Progress: 30.08%] [learning rate: 4.2e+03]\n",
            "[Step 15056/50000] [Time: 131s] [Train Loss: 2.74e-01] [Train Acc: 0.92]\n",
            "[Step 15065/50000] [Progress: 30.13%] [learning rate: 3.4e+03]\n",
            "[Step 15091/50000] [Progress: 30.18%] [learning rate: 3.7e+03]\n",
            "[Step 15117/50000] [Progress: 30.23%] [learning rate: 4.0e+03]\n",
            "[Step 15134/50000] [Time: 132s] [Train Loss: 2.73e-01] [Train Acc: 0.92]\n",
            "[Step 15140/50000] [Progress: 30.28%] [learning rate: 3.2e+03]\n",
            "[Step 15167/50000] [Progress: 30.33%] [learning rate: 3.9e+03]\n",
            "[Step 15193/50000] [Progress: 30.39%] [learning rate: 3.8e+03]\n",
            "[Step 15212/50000] [Time: 133s] [Train Loss: 2.73e-01] [Train Acc: 0.92]\n",
            "[Step 15219/50000] [Progress: 30.44%] [learning rate: 4.1e+03]\n",
            "[Step 15242/50000] [Progress: 30.48%] [learning rate: 3.4e+03]\n",
            "[Step 15269/50000] [Progress: 30.54%] [learning rate: 4.0e+03]\n",
            "[Step 15291/50000] [Time: 133s] [Train Loss: 2.72e-01] [Train Acc: 0.92]\n",
            "[Step 15292/50000] [Progress: 30.58%] [learning rate: 3.6e+03]\n",
            "[Step 15317/50000] [Progress: 30.63%] [learning rate: 3.9e+03]\n",
            "[Step 15341/50000] [Progress: 30.68%] [learning rate: 3.8e+03]\n",
            "[Step 15366/50000] [Progress: 30.73%] [learning rate: 3.8e+03]\n",
            "[Step 15370/50000] [Time: 134s] [Train Loss: 2.71e-01] [Train Acc: 0.92]\n",
            "[Step 15390/50000] [Progress: 30.78%] [learning rate: 3.7e+03]\n",
            "[Step 15415/50000] [Progress: 30.83%] [learning rate: 3.7e+03]\n",
            "[Step 15441/50000] [Progress: 30.88%] [learning rate: 4.0e+03]\n",
            "[Step 15449/50000] [Time: 134s] [Train Loss: 2.71e-01] [Train Acc: 0.92]\n",
            "[Step 15464/50000] [Progress: 30.93%] [learning rate: 3.5e+03]\n",
            "[Step 15490/50000] [Progress: 30.98%] [learning rate: 3.8e+03]\n",
            "[Step 15515/50000] [Progress: 31.03%] [learning rate: 3.8e+03]\n",
            "[Step 15528/50000] [Time: 135s] [Train Loss: 2.70e-01] [Train Acc: 0.92] [Eval Loss: 5.11e-01] [Eval Acc: 0.76]\n",
            "[Step 15539/50000] [Progress: 31.08%] [learning rate: 3.7e+03]\n",
            "[Step 15564/50000] [Progress: 31.13%] [learning rate: 3.7e+03]\n",
            "[Step 15590/50000] [Progress: 31.18%] [learning rate: 3.6e+03]\n",
            "[Step 15607/50000] [Time: 137s] [Train Loss: 2.69e-01] [Train Acc: 0.92]\n",
            "[Step 15615/50000] [Progress: 31.23%] [learning rate: 3.6e+03]\n",
            "[Step 15641/50000] [Progress: 31.28%] [learning rate: 3.9e+03]\n",
            "[Step 15668/50000] [Progress: 31.34%] [learning rate: 4.2e+03]\n",
            "[Step 15687/50000] [Time: 138s] [Train Loss: 2.69e-01] [Train Acc: 0.92]\n",
            "[Step 15692/50000] [Progress: 31.38%] [learning rate: 3.7e+03]\n",
            "[Step 15717/50000] [Progress: 31.43%] [learning rate: 3.7e+03]\n",
            "[Step 15743/50000] [Progress: 31.49%] [learning rate: 3.6e+03]\n",
            "[Step 15767/50000] [Time: 138s] [Train Loss: 2.68e-01] [Train Acc: 0.92]\n",
            "[Step 15768/50000] [Progress: 31.54%] [learning rate: 3.6e+03]\n",
            "[Step 15793/50000] [Progress: 31.59%] [learning rate: 3.9e+03]\n",
            "[Step 15819/50000] [Progress: 31.64%] [learning rate: 4.6e+03]\n",
            "[Step 15839/50000] [Progress: 31.68%] [learning rate: 3.1e+03]\n",
            "[Step 15847/50000] [Time: 139s] [Train Loss: 2.67e-01] [Train Acc: 0.92]\n",
            "[Step 15867/50000] [Progress: 31.73%] [learning rate: 4.1e+03]\n",
            "[Step 15892/50000] [Progress: 31.78%] [learning rate: 3.7e+03]\n",
            "[Step 15918/50000] [Progress: 31.84%] [learning rate: 4.0e+03]\n",
            "[Step 15927/50000] [Time: 139s] [Train Loss: 2.67e-01] [Train Acc: 0.92]\n",
            "[Step 15942/50000] [Progress: 31.88%] [learning rate: 3.5e+03]\n",
            "[Step 15969/50000] [Progress: 31.94%] [learning rate: 4.6e+03]\n",
            "[Step 15990/50000] [Progress: 31.98%] [learning rate: 3.1e+03]\n",
            "[Step 16007/50000] [Time: 140s] [Train Loss: 2.66e-01] [Train Acc: 0.92]\n",
            "[Step 16019/50000] [Progress: 32.04%] [learning rate: 4.1e+03]\n",
            "[Step 16044/50000] [Progress: 32.09%] [learning rate: 3.7e+03]\n",
            "[Step 16070/50000] [Progress: 32.14%] [learning rate: 4.0e+03]\n",
            "[Step 16087/50000] [Time: 140s] [Train Loss: 2.65e-01] [Train Acc: 0.92]\n",
            "[Step 16094/50000] [Progress: 32.19%] [learning rate: 3.6e+03]\n",
            "[Step 16122/50000] [Progress: 32.24%] [learning rate: 4.7e+03]\n",
            "[Step 16143/50000] [Progress: 32.29%] [learning rate: 3.1e+03]\n",
            "[Step 16167/50000] [Time: 141s] [Train Loss: 2.65e-01] [Train Acc: 0.92]\n",
            "[Step 16172/50000] [Progress: 32.34%] [learning rate: 4.1e+03]\n",
            "[Step 16197/50000] [Progress: 32.39%] [learning rate: 3.7e+03]\n",
            "[Step 16223/50000] [Progress: 32.45%] [learning rate: 4.0e+03]\n",
            "[Step 16247/50000] [Progress: 32.49%] [learning rate: 3.6e+03]\n",
            "[Step 16248/50000] [Time: 141s] [Train Loss: 2.64e-01] [Train Acc: 0.92]\n",
            "[Step 16275/50000] [Progress: 32.55%] [learning rate: 4.3e+03]\n",
            "[Step 16298/50000] [Progress: 32.60%] [learning rate: 3.5e+03]\n",
            "[Step 16325/50000] [Progress: 32.65%] [learning rate: 4.1e+03]\n",
            "[Step 16329/50000] [Time: 142s] [Train Loss: 2.64e-01] [Train Acc: 0.92]\n",
            "[Step 16348/50000] [Progress: 32.70%] [learning rate: 3.4e+03]\n",
            "[Step 16374/50000] [Progress: 32.75%] [learning rate: 4.0e+03]\n",
            "[Step 16398/50000] [Progress: 32.80%] [learning rate: 3.6e+03]\n",
            "[Step 16410/50000] [Time: 143s] [Train Loss: 2.63e-01] [Train Acc: 0.92]\n",
            "[Step 16424/50000] [Progress: 32.85%] [learning rate: 4.3e+03]\n",
            "[Step 16447/50000] [Progress: 32.89%] [learning rate: 3.5e+03]\n",
            "[Step 16474/50000] [Progress: 32.95%] [learning rate: 4.2e+03]\n",
            "[Step 16491/50000] [Time: 143s] [Train Loss: 2.62e-01] [Train Acc: 0.92]\n",
            "[Step 16497/50000] [Progress: 32.99%] [learning rate: 3.7e+03]\n",
            "[Step 16522/50000] [Progress: 33.04%] [learning rate: 3.7e+03]\n",
            "[Step 16547/50000] [Progress: 33.09%] [learning rate: 4.0e+03]\n",
            "[Step 16572/50000] [Progress: 33.14%] [learning rate: 3.9e+03]\n",
            "[Step 16572/50000] [Time: 144s] [Train Loss: 2.62e-01] [Train Acc: 0.92]\n",
            "[Step 16598/50000] [Progress: 33.20%] [learning rate: 3.8e+03]\n",
            "[Step 16622/50000] [Progress: 33.24%] [learning rate: 3.8e+03]\n",
            "[Step 16647/50000] [Progress: 33.29%] [learning rate: 3.7e+03]\n",
            "[Step 16653/50000] [Time: 144s] [Train Loss: 2.61e-01] [Train Acc: 0.93]\n",
            "[Step 16673/50000] [Progress: 33.35%] [learning rate: 4.0e+03]\n",
            "[Step 16697/50000] [Progress: 33.39%] [learning rate: 3.6e+03]\n",
            "[Step 16725/50000] [Progress: 33.45%] [learning rate: 4.3e+03]\n",
            "[Step 16735/50000] [Time: 145s] [Train Loss: 2.60e-01] [Train Acc: 0.93]\n",
            "[Step 16749/50000] [Progress: 33.50%] [learning rate: 3.9e+03]\n",
            "[Step 16774/50000] [Progress: 33.55%] [learning rate: 3.8e+03]\n",
            "[Step 16800/50000] [Progress: 33.60%] [learning rate: 3.8e+03]\n",
            "[Step 16817/50000] [Time: 146s] [Train Loss: 2.60e-01] [Train Acc: 0.93]\n",
            "[Step 16825/50000] [Progress: 33.65%] [learning rate: 3.7e+03]\n",
            "[Step 16852/50000] [Progress: 33.70%] [learning rate: 4.0e+03]\n",
            "[Step 16878/50000] [Progress: 33.76%] [learning rate: 3.9e+03]\n",
            "[Step 16899/50000] [Time: 146s] [Train Loss: 2.59e-01] [Train Acc: 0.93]\n",
            "[Step 16904/50000] [Progress: 33.81%] [learning rate: 4.3e+03]\n",
            "[Step 16927/50000] [Progress: 33.85%] [learning rate: 3.5e+03]\n",
            "[Step 16954/50000] [Progress: 33.91%] [learning rate: 4.1e+03]\n",
            "[Step 16977/50000] [Progress: 33.95%] [learning rate: 3.7e+03]\n",
            "[Step 16981/50000] [Time: 147s] [Train Loss: 2.59e-01] [Train Acc: 0.93]\n",
            "[Step 17002/50000] [Progress: 34.00%] [learning rate: 4.0e+03]\n",
            "[Step 17027/50000] [Progress: 34.05%] [learning rate: 4.0e+03]\n",
            "[Step 17053/50000] [Progress: 34.11%] [learning rate: 3.9e+03]\n",
            "[Step 17063/50000] [Time: 148s] [Train Loss: 2.58e-01] [Train Acc: 0.93]\n",
            "[Step 17077/50000] [Progress: 34.15%] [learning rate: 3.8e+03]\n",
            "[Step 17102/50000] [Progress: 34.20%] [learning rate: 3.8e+03]\n",
            "[Step 17128/50000] [Progress: 34.26%] [learning rate: 4.1e+03]\n",
            "[Step 17145/50000] [Time: 148s] [Train Loss: 2.57e-01] [Train Acc: 0.93]\n",
            "[Step 17152/50000] [Progress: 34.30%] [learning rate: 3.7e+03]\n",
            "[Step 17179/50000] [Progress: 34.36%] [learning rate: 4.0e+03]\n",
            "[Step 17204/50000] [Progress: 34.41%] [learning rate: 3.9e+03]\n",
            "[Step 17227/50000] [Time: 149s] [Train Loss: 2.57e-01] [Train Acc: 0.93]\n",
            "[Step 17230/50000] [Progress: 34.46%] [learning rate: 3.9e+03]\n",
            "[Step 17256/50000] [Progress: 34.51%] [learning rate: 3.8e+03]\n",
            "[Step 17281/50000] [Progress: 34.56%] [learning rate: 3.7e+03]\n",
            "[Step 17308/50000] [Progress: 34.62%] [learning rate: 4.1e+03]\n",
            "[Step 17310/50000] [Time: 149s] [Train Loss: 2.56e-01] [Train Acc: 0.93]\n",
            "[Step 17333/50000] [Progress: 34.67%] [learning rate: 4.0e+03]\n",
            "[Step 17358/50000] [Progress: 34.72%] [learning rate: 4.3e+03]\n",
            "[Step 17381/50000] [Progress: 34.76%] [learning rate: 3.5e+03]\n",
            "[Step 17393/50000] [Time: 150s] [Train Loss: 2.56e-01] [Train Acc: 0.93]\n",
            "[Step 17408/50000] [Progress: 34.82%] [learning rate: 4.2e+03]\n",
            "[Step 17431/50000] [Progress: 34.86%] [learning rate: 3.8e+03]\n",
            "[Step 17456/50000] [Progress: 34.91%] [learning rate: 4.1e+03]\n",
            "[Step 17476/50000] [Time: 150s] [Train Loss: 2.55e-01] [Train Acc: 0.93]\n",
            "[Step 17480/50000] [Progress: 34.96%] [learning rate: 4.0e+03]\n",
            "[Step 17505/50000] [Progress: 35.01%] [learning rate: 4.3e+03]\n",
            "[Step 17528/50000] [Progress: 35.06%] [learning rate: 3.5e+03]\n",
            "[Step 17555/50000] [Progress: 35.11%] [learning rate: 4.2e+03]\n",
            "[Step 17559/50000] [Time: 151s] [Train Loss: 2.54e-01] [Train Acc: 0.93]\n",
            "[Step 17578/50000] [Progress: 35.16%] [learning rate: 3.4e+03]\n",
            "[Step 17605/50000] [Progress: 35.21%] [learning rate: 4.1e+03]\n",
            "[Step 17630/50000] [Progress: 35.26%] [learning rate: 4.0e+03]\n",
            "[Step 17642/50000] [Time: 152s] [Train Loss: 2.54e-01] [Train Acc: 0.93]\n",
            "[Step 17656/50000] [Progress: 35.31%] [learning rate: 4.4e+03]\n",
            "[Step 17680/50000] [Progress: 35.36%] [learning rate: 3.9e+03]\n",
            "[Step 17705/50000] [Progress: 35.41%] [learning rate: 3.9e+03]\n",
            "[Step 17725/50000] [Time: 152s] [Train Loss: 2.53e-01] [Train Acc: 0.93]\n",
            "[Step 17731/50000] [Progress: 35.46%] [learning rate: 3.8e+03]\n",
            "[Step 17756/50000] [Progress: 35.51%] [learning rate: 3.7e+03]\n",
            "[Step 17781/50000] [Progress: 35.56%] [learning rate: 4.1e+03]\n",
            "[Step 17808/50000] [Progress: 35.62%] [learning rate: 5.3e+03]\n",
            "[Step 17809/50000] [Time: 153s] [Train Loss: 2.53e-01] [Train Acc: 0.93]\n",
            "[Step 17825/50000] [Progress: 35.65%] [learning rate: 2.4e+03]\n",
            "[Step 17856/50000] [Progress: 35.71%] [learning rate: 4.7e+03]\n",
            "[Step 17877/50000] [Progress: 35.75%] [learning rate: 3.2e+03]\n",
            "[Step 17893/50000] [Time: 153s] [Train Loss: 2.52e-01] [Train Acc: 0.93]\n",
            "[Step 17905/50000] [Progress: 35.81%] [learning rate: 4.5e+03]\n",
            "[Step 17927/50000] [Progress: 35.85%] [learning rate: 3.4e+03]\n",
            "[Step 17955/50000] [Progress: 35.91%] [learning rate: 4.8e+03]\n",
            "[Step 17976/50000] [Progress: 35.95%] [learning rate: 3.3e+03]\n",
            "[Step 17977/50000] [Time: 154s] [Train Loss: 2.51e-01] [Train Acc: 0.93]\n",
            "[Step 18005/50000] [Progress: 36.01%] [learning rate: 4.3e+03]\n",
            "[Step 18029/50000] [Progress: 36.06%] [learning rate: 3.8e+03]\n",
            "[Step 18054/50000] [Progress: 36.11%] [learning rate: 4.1e+03]\n",
            "[Step 18061/50000] [Time: 154s] [Train Loss: 2.51e-01] [Train Acc: 0.93]\n",
            "[Step 18078/50000] [Progress: 36.16%] [learning rate: 3.7e+03]\n",
            "[Step 18106/50000] [Progress: 36.21%] [learning rate: 4.4e+03]\n",
            "[Step 18129/50000] [Progress: 36.26%] [learning rate: 3.6e+03]\n",
            "[Step 18145/50000] [Time: 155s] [Train Loss: 2.50e-01] [Train Acc: 0.93]\n",
            "[Step 18156/50000] [Progress: 36.31%] [learning rate: 4.3e+03]\n",
            "[Step 18179/50000] [Progress: 36.36%] [learning rate: 3.5e+03]\n",
            "[Step 18205/50000] [Progress: 36.41%] [learning rate: 4.2e+03]\n",
            "[Step 18229/50000] [Progress: 36.46%] [learning rate: 3.7e+03]\n",
            "[Step 18229/50000] [Time: 155s] [Train Loss: 2.50e-01] [Train Acc: 0.93]\n",
            "[Step 18255/50000] [Progress: 36.51%] [learning rate: 4.4e+03]\n",
            "[Step 18278/50000] [Progress: 36.56%] [learning rate: 3.6e+03]\n",
            "[Step 18305/50000] [Progress: 36.61%] [learning rate: 4.3e+03]\n",
            "[Step 18313/50000] [Time: 156s] [Train Loss: 2.49e-01] [Train Acc: 0.93]\n",
            "[Step 18328/50000] [Progress: 36.66%] [learning rate: 3.9e+03]\n",
            "[Step 18353/50000] [Progress: 36.71%] [learning rate: 3.8e+03]\n",
            "[Step 18378/50000] [Progress: 36.76%] [learning rate: 4.1e+03]\n",
            "[Step 18397/50000] [Time: 157s] [Train Loss: 2.49e-01] [Train Acc: 0.93]\n",
            "[Step 18403/50000] [Progress: 36.81%] [learning rate: 4.1e+03]\n",
            "[Step 18429/50000] [Progress: 36.86%] [learning rate: 4.0e+03]\n",
            "[Step 18453/50000] [Progress: 36.91%] [learning rate: 3.9e+03]\n",
            "[Step 18478/50000] [Progress: 36.96%] [learning rate: 3.9e+03]\n",
            "[Step 18482/50000] [Time: 157s] [Train Loss: 2.48e-01] [Train Acc: 0.93]\n",
            "[Step 18504/50000] [Progress: 37.01%] [learning rate: 4.2e+03]\n",
            "[Step 18528/50000] [Progress: 37.06%] [learning rate: 3.8e+03]\n",
            "[Step 18555/50000] [Progress: 37.11%] [learning rate: 4.5e+03]\n",
            "[Step 18567/50000] [Time: 158s] [Train Loss: 2.47e-01] [Train Acc: 0.93]\n",
            "[Step 18578/50000] [Progress: 37.16%] [learning rate: 3.7e+03]\n",
            "[Step 18604/50000] [Progress: 37.21%] [learning rate: 4.0e+03]\n",
            "[Step 18628/50000] [Progress: 37.26%] [learning rate: 3.9e+03]\n",
            "[Step 18652/50000] [Time: 159s] [Train Loss: 2.47e-01] [Train Acc: 0.93]\n",
            "[Step 18653/50000] [Progress: 37.31%] [learning rate: 4.2e+03]\n",
            "[Step 18677/50000] [Progress: 37.35%] [learning rate: 3.8e+03]\n",
            "[Step 18704/50000] [Progress: 37.41%] [learning rate: 4.5e+03]\n",
            "[Step 18727/50000] [Progress: 37.45%] [learning rate: 3.7e+03]\n",
            "[Step 18737/50000] [Time: 159s] [Train Loss: 2.46e-01] [Train Acc: 0.93]\n",
            "[Step 18754/50000] [Progress: 37.51%] [learning rate: 4.4e+03]\n",
            "[Step 18777/50000] [Progress: 37.55%] [learning rate: 3.9e+03]\n",
            "[Step 18802/50000] [Progress: 37.60%] [learning rate: 3.9e+03]\n",
            "[Step 18822/50000] [Time: 160s] [Train Loss: 2.46e-01] [Train Acc: 0.93]\n",
            "[Step 18829/50000] [Progress: 37.66%] [learning rate: 4.2e+03]\n",
            "[Step 18855/50000] [Progress: 37.71%] [learning rate: 4.1e+03]\n",
            "[Step 18881/50000] [Progress: 37.76%] [learning rate: 4.5e+03]\n",
            "[Step 18904/50000] [Progress: 37.81%] [learning rate: 3.6e+03]\n",
            "[Step 18907/50000] [Time: 160s] [Train Loss: 2.45e-01] [Train Acc: 0.93]\n",
            "[Step 18931/50000] [Progress: 37.86%] [learning rate: 4.3e+03]\n",
            "[Step 18954/50000] [Progress: 37.91%] [learning rate: 3.9e+03]\n",
            "[Step 18979/50000] [Progress: 37.96%] [learning rate: 4.2e+03]\n",
            "[Step 18992/50000] [Time: 161s] [Train Loss: 2.45e-01] [Train Acc: 0.93]\n",
            "[Step 19003/50000] [Progress: 38.01%] [learning rate: 4.1e+03]\n",
            "[Step 19028/50000] [Progress: 38.06%] [learning rate: 4.1e+03]\n",
            "[Step 19052/50000] [Progress: 38.10%] [learning rate: 4.0e+03]\n",
            "[Step 19077/50000] [Progress: 38.15%] [learning rate: 4.0e+03]\n",
            "[Step 19078/50000] [Time: 162s] [Train Loss: 2.44e-01] [Train Acc: 0.93]\n",
            "[Step 19103/50000] [Progress: 38.21%] [learning rate: 4.3e+03]\n",
            "[Step 19126/50000] [Progress: 38.25%] [learning rate: 3.8e+03]\n",
            "[Step 19152/50000] [Progress: 38.30%] [learning rate: 4.2e+03]\n",
            "[Step 19164/50000] [Time: 162s] [Train Loss: 2.44e-01] [Train Acc: 0.93]\n",
            "[Step 19177/50000] [Progress: 38.35%] [learning rate: 4.1e+03]\n",
            "[Step 19201/50000] [Progress: 38.40%] [learning rate: 4.0e+03]\n",
            "[Step 19226/50000] [Progress: 38.45%] [learning rate: 4.0e+03]\n",
            "[Step 19250/50000] [Time: 163s] [Train Loss: 2.43e-01] [Train Acc: 0.93]\n",
            "[Step 19252/50000] [Progress: 38.50%] [learning rate: 3.9e+03]\n",
            "[Step 19277/50000] [Progress: 38.55%] [learning rate: 3.9e+03]\n",
            "[Step 19303/50000] [Progress: 38.61%] [learning rate: 4.2e+03]\n",
            "[Step 19330/50000] [Progress: 38.66%] [learning rate: 4.5e+03]\n",
            "[Step 19336/50000] [Time: 163s] [Train Loss: 2.42e-01] [Train Acc: 0.93]\n",
            "[Step 19352/50000] [Progress: 38.70%] [learning rate: 3.7e+03]\n",
            "[Step 19378/50000] [Progress: 38.76%] [learning rate: 4.4e+03]\n",
            "[Step 19401/50000] [Progress: 38.80%] [learning rate: 3.9e+03]\n",
            "[Step 19422/50000] [Time: 164s] [Train Loss: 2.42e-01] [Train Acc: 0.93]\n",
            "[Step 19426/50000] [Progress: 38.85%] [learning rate: 4.3e+03]\n",
            "[Step 19450/50000] [Progress: 38.90%] [learning rate: 3.8e+03]\n",
            "[Step 19479/50000] [Progress: 38.96%] [learning rate: 5.0e+03]\n",
            "[Step 19502/50000] [Progress: 39.00%] [learning rate: 3.7e+03]\n",
            "[Step 19508/50000] [Time: 165s] [Train Loss: 2.41e-01] [Train Acc: 0.93]\n",
            "[Step 19528/50000] [Progress: 39.06%] [learning rate: 4.0e+03]\n",
            "[Step 19553/50000] [Progress: 39.11%] [learning rate: 3.9e+03]\n",
            "[Step 19579/50000] [Progress: 39.16%] [learning rate: 4.3e+03]\n",
            "[Step 19594/50000] [Time: 165s] [Train Loss: 2.41e-01] [Train Acc: 0.93]\n",
            "[Step 19603/50000] [Progress: 39.21%] [learning rate: 3.8e+03]\n",
            "[Step 19631/50000] [Progress: 39.26%] [learning rate: 5.0e+03]\n",
            "[Step 19652/50000] [Progress: 39.30%] [learning rate: 3.4e+03]\n",
            "[Step 19680/50000] [Time: 166s] [Train Loss: 2.40e-01] [Train Acc: 0.93] [Eval Loss: 5.07e-01] [Eval Acc: 0.77]\n",
            "[Step 19681/50000] [Progress: 39.36%] [learning rate: 4.4e+03]\n",
            "[Step 19705/50000] [Progress: 39.41%] [learning rate: 4.0e+03]\n",
            "[Step 19730/50000] [Progress: 39.46%] [learning rate: 4.3e+03]\n",
            "[Step 19754/50000] [Progress: 39.51%] [learning rate: 3.8e+03]\n",
            "[Step 19767/50000] [Time: 168s] [Train Loss: 2.40e-01] [Train Acc: 0.93]\n",
            "[Step 19782/50000] [Progress: 39.56%] [learning rate: 4.6e+03]\n",
            "[Step 19806/50000] [Progress: 39.61%] [learning rate: 4.1e+03]\n",
            "[Step 19831/50000] [Progress: 39.66%] [learning rate: 4.0e+03]\n",
            "[Step 19854/50000] [Time: 169s] [Train Loss: 2.39e-01] [Train Acc: 0.93]\n",
            "[Step 19857/50000] [Progress: 39.71%] [learning rate: 4.0e+03]\n",
            "[Step 19882/50000] [Progress: 39.76%] [learning rate: 3.9e+03]\n",
            "[Step 19909/50000] [Progress: 39.82%] [learning rate: 4.2e+03]\n",
            "[Step 19935/50000] [Progress: 39.87%] [learning rate: 4.6e+03]\n",
            "[Step 19941/50000] [Time: 170s] [Train Loss: 2.39e-01] [Train Acc: 0.93]\n",
            "[Step 19958/50000] [Progress: 39.92%] [learning rate: 3.7e+03]\n",
            "[Step 19985/50000] [Progress: 39.97%] [learning rate: 4.5e+03]\n",
            "[Step 20008/50000] [Progress: 40.02%] [learning rate: 4.0e+03]\n",
            "[Step 20028/50000] [Time: 171s] [Train Loss: 2.38e-01] [Train Acc: 0.93]\n",
            "[Step 20033/50000] [Progress: 40.07%] [learning rate: 3.9e+03]\n",
            "[Step 20060/50000] [Progress: 40.12%] [learning rate: 4.3e+03]\n",
            "[Step 20086/50000] [Progress: 40.17%] [learning rate: 4.2e+03]\n",
            "[Step 20111/50000] [Progress: 40.22%] [learning rate: 4.1e+03]\n",
            "[Step 20115/50000] [Time: 171s] [Train Loss: 2.38e-01] [Train Acc: 0.94]\n",
            "[Step 20137/50000] [Progress: 40.27%] [learning rate: 4.1e+03]\n",
            "[Step 20163/50000] [Progress: 40.33%] [learning rate: 4.0e+03]\n",
            "[Step 20188/50000] [Progress: 40.38%] [learning rate: 4.0e+03]\n",
            "[Step 20202/50000] [Time: 172s] [Train Loss: 2.37e-01] [Train Acc: 0.94]\n",
            "[Step 20215/50000] [Progress: 40.43%] [learning rate: 4.3e+03]\n",
            "[Step 20241/50000] [Progress: 40.48%] [learning rate: 4.2e+03]\n",
            "[Step 20267/50000] [Progress: 40.53%] [learning rate: 4.6e+03]\n",
            "[Step 20289/50000] [Time: 173s] [Train Loss: 2.36e-01] [Train Acc: 0.94]\n",
            "[Step 20290/50000] [Progress: 40.58%] [learning rate: 3.7e+03]\n",
            "[Step 20317/50000] [Progress: 40.63%] [learning rate: 4.4e+03]\n",
            "[Step 20340/50000] [Progress: 40.68%] [learning rate: 4.0e+03]\n",
            "[Step 20365/50000] [Progress: 40.73%] [learning rate: 4.3e+03]\n",
            "[Step 20376/50000] [Time: 173s] [Train Loss: 2.36e-01] [Train Acc: 0.94]\n",
            "[Step 20389/50000] [Progress: 40.78%] [learning rate: 4.2e+03]\n",
            "[Step 20414/50000] [Progress: 40.83%] [learning rate: 4.2e+03]\n",
            "[Step 20438/50000] [Progress: 40.88%] [learning rate: 4.1e+03]\n",
            "[Step 20463/50000] [Progress: 40.93%] [learning rate: 4.1e+03]\n",
            "[Step 20463/50000] [Time: 174s] [Train Loss: 2.35e-01] [Train Acc: 0.94]\n",
            "[Step 20489/50000] [Progress: 40.98%] [learning rate: 4.4e+03]\n",
            "[Step 20512/50000] [Progress: 41.02%] [learning rate: 3.9e+03]\n",
            "[Step 20538/50000] [Progress: 41.08%] [learning rate: 4.7e+03]\n",
            "[Step 20551/50000] [Time: 175s] [Train Loss: 2.35e-01] [Train Acc: 0.94]\n",
            "[Step 20561/50000] [Progress: 41.12%] [learning rate: 3.8e+03]\n",
            "[Step 20587/50000] [Progress: 41.17%] [learning rate: 4.1e+03]\n",
            "[Step 20611/50000] [Progress: 41.22%] [learning rate: 4.1e+03]\n",
            "[Step 20636/50000] [Progress: 41.27%] [learning rate: 4.0e+03]\n",
            "[Step 20639/50000] [Time: 175s] [Train Loss: 2.34e-01] [Train Acc: 0.94]\n",
            "[Step 20661/50000] [Progress: 41.32%] [learning rate: 3.9e+03]\n",
            "[Step 20687/50000] [Progress: 41.37%] [learning rate: 4.3e+03]\n",
            "[Step 20714/50000] [Progress: 41.43%] [learning rate: 4.6e+03]\n",
            "[Step 20727/50000] [Time: 176s] [Train Loss: 2.34e-01] [Train Acc: 0.94]\n",
            "[Step 20738/50000] [Progress: 41.48%] [learning rate: 4.2e+03]\n",
            "[Step 20763/50000] [Progress: 41.53%] [learning rate: 4.1e+03]\n",
            "[Step 20789/50000] [Progress: 41.58%] [learning rate: 4.0e+03]\n",
            "[Step 20814/50000] [Progress: 41.63%] [learning rate: 4.0e+03]\n",
            "[Step 20815/50000] [Time: 177s] [Train Loss: 2.33e-01] [Train Acc: 0.94]\n",
            "[Step 20839/50000] [Progress: 41.68%] [learning rate: 4.3e+03]\n",
            "[Step 20865/50000] [Progress: 41.73%] [learning rate: 5.1e+03]\n",
            "[Step 20886/50000] [Progress: 41.77%] [learning rate: 3.4e+03]\n",
            "[Step 20903/50000] [Time: 178s] [Train Loss: 2.33e-01] [Train Acc: 0.94]\n",
            "[Step 20915/50000] [Progress: 41.83%] [learning rate: 4.5e+03]\n",
            "[Step 20940/50000] [Progress: 41.88%] [learning rate: 4.0e+03]\n",
            "[Step 20966/50000] [Progress: 41.93%] [learning rate: 4.4e+03]\n",
            "[Step 20990/50000] [Progress: 41.98%] [learning rate: 3.9e+03]\n",
            "[Step 20991/50000] [Time: 178s] [Train Loss: 2.32e-01] [Train Acc: 0.94]\n",
            "[Step 21017/50000] [Progress: 42.03%] [learning rate: 4.7e+03]\n",
            "[Step 21041/50000] [Progress: 42.08%] [learning rate: 4.2e+03]\n",
            "[Step 21066/50000] [Progress: 42.13%] [learning rate: 4.1e+03]\n",
            "[Step 21079/50000] [Time: 179s] [Train Loss: 2.32e-01] [Train Acc: 0.94]\n",
            "[Step 21092/50000] [Progress: 42.18%] [learning rate: 4.5e+03]\n",
            "[Step 21115/50000] [Progress: 42.23%] [learning rate: 4.0e+03]\n",
            "[Step 21141/50000] [Progress: 42.28%] [learning rate: 4.3e+03]\n",
            "[Step 21167/50000] [Progress: 42.33%] [learning rate: 4.7e+03]\n",
            "[Step 21167/50000] [Time: 179s] [Train Loss: 2.31e-01] [Train Acc: 0.94]\n",
            "[Step 21190/50000] [Progress: 42.38%] [learning rate: 3.8e+03]\n",
            "[Step 21217/50000] [Progress: 42.43%] [learning rate: 4.6e+03]\n",
            "[Step 21240/50000] [Progress: 42.48%] [learning rate: 4.1e+03]\n",
            "[Step 21255/50000] [Time: 180s] [Train Loss: 2.31e-01] [Train Acc: 0.94]\n",
            "[Step 21265/50000] [Progress: 42.53%] [learning rate: 4.0e+03]\n",
            "[Step 21290/50000] [Progress: 42.58%] [learning rate: 4.4e+03]\n",
            "[Step 21315/50000] [Progress: 42.63%] [learning rate: 4.3e+03]\n",
            "[Step 21341/50000] [Progress: 42.68%] [learning rate: 4.2e+03]\n",
            "[Step 21344/50000] [Time: 181s] [Train Loss: 2.30e-01] [Train Acc: 0.94]\n",
            "[Step 21365/50000] [Progress: 42.73%] [learning rate: 4.2e+03]\n",
            "[Step 21390/50000] [Progress: 42.78%] [learning rate: 4.1e+03]\n",
            "[Step 21416/50000] [Progress: 42.83%] [learning rate: 4.4e+03]\n",
            "[Step 21433/50000] [Time: 181s] [Train Loss: 2.30e-01] [Train Acc: 0.94]\n",
            "[Step 21440/50000] [Progress: 42.88%] [learning rate: 4.0e+03]\n",
            "[Step 21468/50000] [Progress: 42.94%] [learning rate: 4.7e+03]\n",
            "[Step 21492/50000] [Progress: 42.98%] [learning rate: 4.2e+03]\n",
            "[Step 21517/50000] [Progress: 43.03%] [learning rate: 4.2e+03]\n",
            "[Step 21522/50000] [Time: 182s] [Train Loss: 2.29e-01] [Train Acc: 0.94]\n",
            "[Step 21543/50000] [Progress: 43.09%] [learning rate: 4.1e+03]\n",
            "[Step 21568/50000] [Progress: 43.14%] [learning rate: 4.1e+03]\n",
            "[Step 21595/50000] [Progress: 43.19%] [learning rate: 4.4e+03]\n",
            "[Step 21611/50000] [Time: 182s] [Train Loss: 2.29e-01] [Train Acc: 0.94]\n",
            "[Step 21621/50000] [Progress: 43.24%] [learning rate: 4.3e+03]\n",
            "[Step 21647/50000] [Progress: 43.29%] [learning rate: 4.7e+03]\n",
            "[Step 21670/50000] [Progress: 43.34%] [learning rate: 3.8e+03]\n",
            "[Step 21697/50000] [Progress: 43.39%] [learning rate: 4.5e+03]\n",
            "[Step 21700/50000] [Time: 183s] [Train Loss: 2.28e-01] [Train Acc: 0.94]\n",
            "[Step 21720/50000] [Progress: 43.44%] [learning rate: 4.1e+03]\n",
            "[Step 21745/50000] [Progress: 43.49%] [learning rate: 4.4e+03]\n",
            "[Step 21769/50000] [Progress: 43.54%] [learning rate: 4.3e+03]\n",
            "[Step 21789/50000] [Time: 184s] [Train Loss: 2.28e-01] [Train Acc: 0.94]\n",
            "[Step 21794/50000] [Progress: 43.59%] [learning rate: 4.7e+03]\n",
            "[Step 21817/50000] [Progress: 43.63%] [learning rate: 3.8e+03]\n",
            "[Step 21844/50000] [Progress: 43.69%] [learning rate: 4.6e+03]\n",
            "[Step 21867/50000] [Progress: 43.73%] [learning rate: 4.1e+03]\n",
            "[Step 21878/50000] [Time: 184s] [Train Loss: 2.27e-01] [Train Acc: 0.94]\n",
            "[Step 21892/50000] [Progress: 43.78%] [learning rate: 4.4e+03]\n",
            "[Step 21916/50000] [Progress: 43.83%] [learning rate: 4.4e+03]\n",
            "[Step 21941/50000] [Progress: 43.88%] [learning rate: 4.3e+03]\n",
            "[Step 21965/50000] [Progress: 43.93%] [learning rate: 4.2e+03]\n",
            "[Step 21967/50000] [Time: 186s] [Train Loss: 2.27e-01] [Train Acc: 0.94]\n",
            "[Step 21990/50000] [Progress: 43.98%] [learning rate: 4.2e+03]\n",
            "[Step 22016/50000] [Progress: 44.03%] [learning rate: 4.5e+03]\n",
            "[Step 22039/50000] [Progress: 44.08%] [learning rate: 4.0e+03]\n",
            "[Step 22056/50000] [Time: 186s] [Train Loss: 2.26e-01] [Train Acc: 0.94]\n",
            "[Step 22065/50000] [Progress: 44.13%] [learning rate: 4.4e+03]\n",
            "[Step 22092/50000] [Progress: 44.18%] [learning rate: 4.8e+03]\n",
            "[Step 22116/50000] [Progress: 44.23%] [learning rate: 4.3e+03]\n",
            "[Step 22141/50000] [Progress: 44.28%] [learning rate: 4.2e+03]\n",
            "[Step 22145/50000] [Time: 187s] [Train Loss: 2.26e-01] [Train Acc: 0.94]\n",
            "[Step 22167/50000] [Progress: 44.33%] [learning rate: 4.5e+03]\n",
            "[Step 22190/50000] [Progress: 44.38%] [learning rate: 4.1e+03]\n",
            "[Step 22216/50000] [Progress: 44.43%] [learning rate: 4.4e+03]\n",
            "[Step 22235/50000] [Time: 188s] [Train Loss: 2.25e-01] [Train Acc: 0.94]\n",
            "[Step 22244/50000] [Progress: 44.49%] [learning rate: 5.8e+03]\n",
            "[Step 22261/50000] [Progress: 44.52%] [learning rate: 2.7e+03]\n",
            "[Step 22293/50000] [Progress: 44.59%] [learning rate: 5.1e+03]\n",
            "[Step 22316/50000] [Progress: 44.63%] [learning rate: 3.8e+03]\n",
            "[Step 22325/50000] [Time: 189s] [Train Loss: 2.25e-01] [Train Acc: 0.94]\n",
            "[Step 22344/50000] [Progress: 44.69%] [learning rate: 4.5e+03]\n",
            "[Step 22370/50000] [Progress: 44.74%] [learning rate: 4.4e+03]\n",
            "[Step 22397/50000] [Progress: 44.79%] [learning rate: 4.8e+03]\n",
            "[Step 22415/50000] [Time: 190s] [Train Loss: 2.24e-01] [Train Acc: 0.94]\n",
            "[Step 22421/50000] [Progress: 44.84%] [learning rate: 4.3e+03]\n",
            "[Step 22446/50000] [Progress: 44.89%] [learning rate: 4.2e+03]\n",
            "[Step 22472/50000] [Progress: 44.94%] [learning rate: 4.2e+03]\n",
            "[Step 22498/50000] [Progress: 45.00%] [learning rate: 4.5e+03]\n",
            "[Step 22505/50000] [Time: 191s] [Train Loss: 2.24e-01] [Train Acc: 0.94]\n",
            "[Step 22522/50000] [Progress: 45.04%] [learning rate: 4.0e+03]\n",
            "[Step 22548/50000] [Progress: 45.10%] [learning rate: 4.8e+03]\n",
            "[Step 22571/50000] [Progress: 45.14%] [learning rate: 3.9e+03]\n",
            "[Step 22595/50000] [Time: 191s] [Train Loss: 2.23e-01] [Train Acc: 0.94]\n",
            "[Step 22597/50000] [Progress: 45.19%] [learning rate: 4.2e+03]\n",
            "[Step 22622/50000] [Progress: 45.24%] [learning rate: 4.2e+03]\n",
            "[Step 22648/50000] [Progress: 45.30%] [learning rate: 4.5e+03]\n",
            "[Step 22672/50000] [Progress: 45.34%] [learning rate: 4.1e+03]\n",
            "[Step 22685/50000] [Time: 192s] [Train Loss: 2.23e-01] [Train Acc: 0.94]\n",
            "[Step 22700/50000] [Progress: 45.40%] [learning rate: 4.8e+03]\n",
            "[Step 22724/50000] [Progress: 45.45%] [learning rate: 4.3e+03]\n",
            "[Step 22749/50000] [Progress: 45.50%] [learning rate: 4.3e+03]\n",
            "[Step 22775/50000] [Progress: 45.55%] [learning rate: 4.2e+03]\n",
            "[Step 22775/50000] [Time: 193s] [Train Loss: 2.22e-01] [Train Acc: 0.94]\n",
            "[Step 22801/50000] [Progress: 45.60%] [learning rate: 4.6e+03]\n",
            "[Step 22825/50000] [Progress: 45.65%] [learning rate: 4.1e+03]\n",
            "[Step 22853/50000] [Progress: 45.71%] [learning rate: 4.9e+03]\n",
            "[Step 22865/50000] [Time: 194s] [Train Loss: 2.22e-01] [Train Acc: 0.94]\n",
            "[Step 22877/50000] [Progress: 45.75%] [learning rate: 4.4e+03]\n",
            "[Step 22902/50000] [Progress: 45.80%] [learning rate: 4.3e+03]\n",
            "[Step 22928/50000] [Progress: 45.86%] [learning rate: 4.2e+03]\n",
            "[Step 22953/50000] [Progress: 45.91%] [learning rate: 4.2e+03]\n",
            "[Step 22955/50000] [Time: 195s] [Train Loss: 2.21e-01] [Train Acc: 0.94]\n",
            "[Step 22980/50000] [Progress: 45.96%] [learning rate: 4.5e+03]\n",
            "[Step 23006/50000] [Progress: 46.01%] [learning rate: 4.4e+03]\n",
            "[Step 23032/50000] [Progress: 46.06%] [learning rate: 4.8e+03]\n",
            "[Step 23045/50000] [Time: 195s] [Train Loss: 2.21e-01] [Train Acc: 0.94]\n",
            "[Step 23055/50000] [Progress: 46.11%] [learning rate: 3.9e+03]\n",
            "[Step 23082/50000] [Progress: 46.16%] [learning rate: 4.7e+03]\n",
            "[Step 23105/50000] [Progress: 46.21%] [learning rate: 4.2e+03]\n",
            "[Step 23130/50000] [Progress: 46.26%] [learning rate: 4.5e+03]\n",
            "[Step 23136/50000] [Time: 196s] [Train Loss: 2.20e-01] [Train Acc: 0.94]\n",
            "[Step 23154/50000] [Progress: 46.31%] [learning rate: 4.5e+03]\n",
            "[Step 23179/50000] [Progress: 46.36%] [learning rate: 4.4e+03]\n",
            "[Step 23203/50000] [Progress: 46.41%] [learning rate: 4.3e+03]\n",
            "[Step 23227/50000] [Time: 197s] [Train Loss: 2.20e-01] [Train Acc: 0.94]\n",
            "[Step 23228/50000] [Progress: 46.46%] [learning rate: 4.3e+03]\n",
            "[Step 23254/50000] [Progress: 46.51%] [learning rate: 4.6e+03]\n",
            "[Step 23277/50000] [Progress: 46.55%] [learning rate: 4.1e+03]\n",
            "[Step 23303/50000] [Progress: 46.61%] [learning rate: 4.5e+03]\n",
            "[Step 23318/50000] [Time: 197s] [Train Loss: 2.19e-01] [Train Acc: 0.94]\n",
            "[Step 23328/50000] [Progress: 46.66%] [learning rate: 4.4e+03]\n",
            "[Step 23352/50000] [Progress: 46.70%] [learning rate: 4.3e+03]\n",
            "[Step 23377/50000] [Progress: 46.75%] [learning rate: 4.3e+03]\n",
            "[Step 23403/50000] [Progress: 46.81%] [learning rate: 4.2e+03]\n",
            "[Step 23409/50000] [Time: 198s] [Train Loss: 2.19e-01] [Train Acc: 0.94]\n",
            "[Step 23428/50000] [Progress: 46.86%] [learning rate: 4.2e+03]\n",
            "[Step 23454/50000] [Progress: 46.91%] [learning rate: 4.5e+03]\n",
            "[Step 23481/50000] [Progress: 46.96%] [learning rate: 4.9e+03]\n",
            "[Step 23500/50000] [Time: 199s] [Train Loss: 2.18e-01] [Train Acc: 0.94]\n",
            "[Step 23505/50000] [Progress: 47.01%] [learning rate: 4.4e+03]\n",
            "[Step 23530/50000] [Progress: 47.06%] [learning rate: 4.3e+03]\n",
            "[Step 23556/50000] [Progress: 47.11%] [learning rate: 4.7e+03]\n",
            "[Step 23579/50000] [Progress: 47.16%] [learning rate: 4.2e+03]\n",
            "[Step 23591/50000] [Time: 200s] [Train Loss: 2.18e-01] [Train Acc: 0.94]\n",
            "[Step 23605/50000] [Progress: 47.21%] [learning rate: 4.5e+03]\n",
            "[Step 23632/50000] [Progress: 47.26%] [learning rate: 5.4e+03]\n",
            "[Step 23652/50000] [Progress: 47.30%] [learning rate: 3.6e+03]\n",
            "[Step 23680/50000] [Progress: 47.36%] [learning rate: 4.7e+03]\n",
            "[Step 23682/50000] [Time: 200s] [Train Loss: 2.18e-01] [Train Acc: 0.94]\n",
            "[Step 23705/50000] [Progress: 47.41%] [learning rate: 4.3e+03]\n",
            "[Step 23731/50000] [Progress: 47.46%] [learning rate: 4.6e+03]\n",
            "[Step 23755/50000] [Progress: 47.51%] [learning rate: 4.1e+03]\n",
            "[Step 23773/50000] [Time: 201s] [Train Loss: 2.17e-01] [Train Acc: 0.94]\n",
            "[Step 23783/50000] [Progress: 47.57%] [learning rate: 4.9e+03]\n",
            "[Step 23806/50000] [Progress: 47.61%] [learning rate: 4.0e+03]\n",
            "[Step 23833/50000] [Progress: 47.67%] [learning rate: 4.8e+03]\n",
            "[Step 23856/50000] [Progress: 47.71%] [learning rate: 3.9e+03]\n",
            "[Step 23864/50000] [Time: 201s] [Train Loss: 2.17e-01] [Train Acc: 0.94]\n",
            "[Step 23882/50000] [Progress: 47.76%] [learning rate: 4.6e+03]\n",
            "[Step 23906/50000] [Progress: 47.81%] [learning rate: 4.1e+03]\n",
            "[Step 23932/50000] [Progress: 47.86%] [learning rate: 4.9e+03]\n",
            "[Step 23955/50000] [Progress: 47.91%] [learning rate: 4.0e+03]\n",
            "[Step 23955/50000] [Time: 202s] [Train Loss: 2.16e-01] [Train Acc: 0.94]\n",
            "[Step 23982/50000] [Progress: 47.96%] [learning rate: 4.8e+03]\n",
            "[Step 24005/50000] [Progress: 48.01%] [learning rate: 3.9e+03]\n",
            "[Step 24031/50000] [Progress: 48.06%] [learning rate: 4.6e+03]\n",
            "[Step 24046/50000] [Time: 203s] [Train Loss: 2.16e-01] [Train Acc: 0.94]\n",
            "[Step 24055/50000] [Progress: 48.11%] [learning rate: 4.2e+03]\n",
            "[Step 24081/50000] [Progress: 48.16%] [learning rate: 4.5e+03]\n",
            "[Step 24106/50000] [Progress: 48.21%] [learning rate: 4.4e+03]\n",
            "[Step 24132/50000] [Progress: 48.26%] [learning rate: 4.4e+03]\n",
            "[Step 24137/50000] [Time: 203s] [Train Loss: 2.15e-01] [Train Acc: 0.95] [Eval Loss: 5.06e-01] [Eval Acc: 0.77]\n",
            "[Step 24158/50000] [Progress: 48.32%] [learning rate: 4.3e+03]\n",
            "[Step 24183/50000] [Progress: 48.37%] [learning rate: 4.2e+03]\n",
            "[Step 24210/50000] [Progress: 48.42%] [learning rate: 4.6e+03]\n",
            "[Step 24229/50000] [Time: 206s] [Train Loss: 2.15e-01] [Train Acc: 0.95]\n",
            "[Step 24236/50000] [Progress: 48.47%] [learning rate: 4.5e+03]\n",
            "[Step 24262/50000] [Progress: 48.52%] [learning rate: 4.5e+03]\n",
            "[Step 24286/50000] [Progress: 48.57%] [learning rate: 4.4e+03]\n",
            "[Step 24311/50000] [Progress: 48.62%] [learning rate: 4.3e+03]\n",
            "[Step 24321/50000] [Time: 207s] [Train Loss: 2.14e-01] [Train Acc: 0.95]\n",
            "[Step 24337/50000] [Progress: 48.67%] [learning rate: 4.7e+03]\n",
            "[Step 24361/50000] [Progress: 48.72%] [learning rate: 4.2e+03]\n",
            "[Step 24388/50000] [Progress: 48.78%] [learning rate: 5.0e+03]\n",
            "[Step 24411/50000] [Progress: 48.82%] [learning rate: 4.1e+03]\n",
            "[Step 24413/50000] [Time: 207s] [Train Loss: 2.14e-01] [Train Acc: 0.95]\n",
            "[Step 24437/50000] [Progress: 48.87%] [learning rate: 4.4e+03]\n",
            "[Step 24461/50000] [Progress: 48.92%] [learning rate: 4.3e+03]\n",
            "[Step 24486/50000] [Progress: 48.97%] [learning rate: 4.3e+03]\n",
            "[Step 24505/50000] [Time: 208s] [Train Loss: 2.13e-01] [Train Acc: 0.95]\n",
            "[Step 24511/50000] [Progress: 49.02%] [learning rate: 4.2e+03]\n",
            "[Step 24537/50000] [Progress: 49.07%] [learning rate: 4.6e+03]\n",
            "[Step 24563/50000] [Progress: 49.13%] [learning rate: 5.0e+03]\n",
            "[Step 24586/50000] [Progress: 49.17%] [learning rate: 4.0e+03]\n",
            "[Step 24597/50000] [Time: 209s] [Train Loss: 2.13e-01] [Train Acc: 0.95]\n",
            "[Step 24612/50000] [Progress: 49.22%] [learning rate: 4.4e+03]\n",
            "[Step 24637/50000] [Progress: 49.27%] [learning rate: 4.3e+03]\n",
            "[Step 24663/50000] [Progress: 49.33%] [learning rate: 4.7e+03]\n",
            "[Step 24687/50000] [Progress: 49.37%] [learning rate: 4.2e+03]\n",
            "[Step 24689/50000] [Time: 210s] [Train Loss: 2.13e-01] [Train Acc: 0.95]\n",
            "[Step 24714/50000] [Progress: 49.43%] [learning rate: 5.5e+03]\n",
            "[Step 24734/50000] [Progress: 49.47%] [learning rate: 3.7e+03]\n",
            "[Step 24762/50000] [Progress: 49.52%] [learning rate: 4.8e+03]\n",
            "[Step 24781/50000] [Time: 210s] [Train Loss: 2.12e-01] [Train Acc: 0.95]\n",
            "[Step 24787/50000] [Progress: 49.57%] [learning rate: 4.3e+03]\n",
            "[Step 24813/50000] [Progress: 49.63%] [learning rate: 4.7e+03]\n",
            "[Step 24837/50000] [Progress: 49.67%] [learning rate: 4.2e+03]\n",
            "[Step 24864/50000] [Progress: 49.73%] [learning rate: 5.5e+03]\n",
            "[Step 24873/50000] [Time: 211s] [Train Loss: 2.12e-01] [Train Acc: 0.95]\n",
            "[Step 24884/50000] [Progress: 49.77%] [learning rate: 3.7e+03]\n",
            "[Step 24912/50000] [Progress: 49.82%] [learning rate: 4.8e+03]\n",
            "[Step 24937/50000] [Progress: 49.87%] [learning rate: 4.3e+03]\n",
            "[Step 24963/50000] [Progress: 49.93%] [learning rate: 4.7e+03]\n",
            "[Step 24965/50000] [Time: 212s] [Train Loss: 2.11e-01] [Train Acc: 0.95]\n",
            "[Step 24987/50000] [Progress: 49.97%] [learning rate: 4.2e+03]\n",
            "[Step 25013/50000] [Progress: 50.03%] [learning rate: 5.0e+03]\n",
            "[Step 25036/50000] [Progress: 50.07%] [learning rate: 4.1e+03]\n",
            "[Step 25057/50000] [Time: 213s] [Train Loss: 2.11e-01] [Train Acc: 0.95]\n",
            "[Step 25062/50000] [Progress: 50.12%] [learning rate: 4.4e+03]\n",
            "[Step 25086/50000] [Progress: 50.17%] [learning rate: 4.4e+03]\n",
            "[Step 25111/50000] [Progress: 50.22%] [learning rate: 4.7e+03]\n",
            "[Step 25135/50000] [Progress: 50.27%] [learning rate: 4.2e+03]\n",
            "[Step 25149/50000] [Time: 214s] [Train Loss: 2.10e-01] [Train Acc: 0.95]\n",
            "[Step 25163/50000] [Progress: 50.33%] [learning rate: 5.0e+03]\n",
            "[Step 25187/50000] [Progress: 50.37%] [learning rate: 4.5e+03]\n",
            "[Step 25212/50000] [Progress: 50.42%] [learning rate: 4.4e+03]\n",
            "[Step 25238/50000] [Progress: 50.48%] [learning rate: 4.4e+03]\n",
            "[Step 25241/50000] [Time: 215s] [Train Loss: 2.10e-01] [Train Acc: 0.95]\n",
            "[Step 25263/50000] [Progress: 50.53%] [learning rate: 4.3e+03]\n",
            "[Step 25290/50000] [Progress: 50.58%] [learning rate: 4.7e+03]\n",
            "[Step 25316/50000] [Progress: 50.63%] [learning rate: 4.6e+03]\n",
            "[Step 25333/50000] [Time: 215s] [Train Loss: 2.09e-01] [Train Acc: 0.95]\n",
            "[Step 25340/50000] [Progress: 50.68%] [learning rate: 4.5e+03]\n",
            "[Step 25365/50000] [Progress: 50.73%] [learning rate: 4.5e+03]\n",
            "[Step 25391/50000] [Progress: 50.78%] [learning rate: 4.4e+03]\n",
            "[Step 25416/50000] [Progress: 50.83%] [learning rate: 4.3e+03]\n",
            "[Step 25426/50000] [Time: 216s] [Train Loss: 2.09e-01] [Train Acc: 0.95]\n",
            "[Step 25443/50000] [Progress: 50.89%] [learning rate: 4.7e+03]\n",
            "[Step 25469/50000] [Progress: 50.94%] [learning rate: 4.6e+03]\n",
            "[Step 25495/50000] [Progress: 50.99%] [learning rate: 5.0e+03]\n",
            "[Step 25518/50000] [Progress: 51.04%] [learning rate: 4.1e+03]\n",
            "[Step 25519/50000] [Time: 217s] [Train Loss: 2.09e-01] [Train Acc: 0.95]\n",
            "[Step 25545/50000] [Progress: 51.09%] [learning rate: 4.9e+03]\n",
            "[Step 25568/50000] [Progress: 51.14%] [learning rate: 4.4e+03]\n",
            "[Step 25593/50000] [Progress: 51.19%] [learning rate: 4.7e+03]\n",
            "[Step 25612/50000] [Time: 217s] [Train Loss: 2.08e-01] [Train Acc: 0.95]\n",
            "[Step 25617/50000] [Progress: 51.23%] [learning rate: 4.6e+03]\n",
            "[Step 25642/50000] [Progress: 51.28%] [learning rate: 5.0e+03]\n",
            "[Step 25665/50000] [Progress: 51.33%] [learning rate: 4.1e+03]\n",
            "[Step 25692/50000] [Progress: 51.38%] [learning rate: 4.9e+03]\n",
            "[Step 25705/50000] [Time: 218s] [Train Loss: 2.08e-01] [Train Acc: 0.95]\n",
            "[Step 25715/50000] [Progress: 51.43%] [learning rate: 4.4e+03]\n",
            "[Step 25740/50000] [Progress: 51.48%] [learning rate: 4.7e+03]\n",
            "[Step 25764/50000] [Progress: 51.53%] [learning rate: 4.2e+03]\n",
            "[Step 25791/50000] [Progress: 51.58%] [learning rate: 5.1e+03]\n",
            "[Step 25798/50000] [Time: 219s] [Train Loss: 2.07e-01] [Train Acc: 0.95]\n",
            "[Step 25815/50000] [Progress: 51.63%] [learning rate: 4.5e+03]\n",
            "[Step 25840/50000] [Progress: 51.68%] [learning rate: 4.5e+03]\n",
            "[Step 25866/50000] [Progress: 51.73%] [learning rate: 4.4e+03]\n",
            "[Step 25891/50000] [Progress: 51.78%] [learning rate: 4.3e+03]\n",
            "[Step 25891/50000] [Time: 220s] [Train Loss: 2.07e-01] [Train Acc: 0.95]\n",
            "[Step 25917/50000] [Progress: 51.83%] [learning rate: 4.7e+03]\n",
            "[Step 25944/50000] [Progress: 51.89%] [learning rate: 5.1e+03]\n",
            "[Step 25966/50000] [Progress: 51.93%] [learning rate: 4.1e+03]\n",
            "[Step 25984/50000] [Time: 221s] [Train Loss: 2.06e-01] [Train Acc: 0.95]\n",
            "[Step 25992/50000] [Progress: 51.98%] [learning rate: 4.9e+03]\n",
            "[Step 26015/50000] [Progress: 52.03%] [learning rate: 4.4e+03]\n",
            "[Step 26040/50000] [Progress: 52.08%] [learning rate: 4.3e+03]\n",
            "[Step 26065/50000] [Progress: 52.13%] [learning rate: 4.7e+03]\n",
            "[Step 26077/50000] [Time: 222s] [Train Loss: 2.06e-01] [Train Acc: 0.95]\n",
            "[Step 26091/50000] [Progress: 52.18%] [learning rate: 5.1e+03]\n",
            "[Step 26115/50000] [Progress: 52.23%] [learning rate: 4.6e+03]\n",
            "[Step 26140/50000] [Progress: 52.28%] [learning rate: 4.5e+03]\n",
            "[Step 26166/50000] [Progress: 52.33%] [learning rate: 4.4e+03]\n",
            "[Step 26170/50000] [Time: 223s] [Train Loss: 2.06e-01] [Train Acc: 0.95]\n",
            "[Step 26191/50000] [Progress: 52.38%] [learning rate: 4.4e+03]\n",
            "[Step 26218/50000] [Progress: 52.44%] [learning rate: 4.7e+03]\n",
            "[Step 26244/50000] [Progress: 52.49%] [learning rate: 5.1e+03]\n",
            "[Step 26263/50000] [Time: 225s] [Train Loss: 2.05e-01] [Train Acc: 0.95]\n",
            "[Step 26267/50000] [Progress: 52.53%] [learning rate: 4.2e+03]\n",
            "[Step 26293/50000] [Progress: 52.59%] [learning rate: 4.5e+03]\n",
            "[Step 26318/50000] [Progress: 52.64%] [learning rate: 4.5e+03]\n",
            "[Step 26344/50000] [Progress: 52.69%] [learning rate: 4.8e+03]\n",
            "[Step 26356/50000] [Time: 226s] [Train Loss: 2.05e-01] [Train Acc: 0.95]\n",
            "[Step 26368/50000] [Progress: 52.74%] [learning rate: 4.3e+03]\n",
            "[Step 26395/50000] [Progress: 52.79%] [learning rate: 5.1e+03]\n",
            "[Step 26418/50000] [Progress: 52.84%] [learning rate: 4.2e+03]\n",
            "[Step 26444/50000] [Progress: 52.89%] [learning rate: 4.5e+03]\n",
            "[Step 26449/50000] [Time: 227s] [Train Loss: 2.04e-01] [Train Acc: 0.95]\n",
            "[Step 26469/50000] [Progress: 52.94%] [learning rate: 4.5e+03]\n",
            "[Step 26495/50000] [Progress: 52.99%] [learning rate: 4.4e+03]\n",
            "[Step 26520/50000] [Progress: 53.04%] [learning rate: 4.8e+03]\n",
            "[Step 26542/50000] [Time: 228s] [Train Loss: 2.04e-01] [Train Acc: 0.95]\n",
            "[Step 26544/50000] [Progress: 53.09%] [learning rate: 4.7e+03]\n",
            "[Step 26569/50000] [Progress: 53.14%] [learning rate: 4.6e+03]\n",
            "[Step 26593/50000] [Progress: 53.19%] [learning rate: 4.6e+03]\n",
            "[Step 26618/50000] [Progress: 53.24%] [learning rate: 4.5e+03]\n",
            "[Step 26635/50000] [Time: 228s] [Train Loss: 2.03e-01] [Train Acc: 0.95]\n",
            "[Step 26644/50000] [Progress: 53.29%] [learning rate: 4.9e+03]\n",
            "[Step 26668/50000] [Progress: 53.34%] [learning rate: 4.4e+03]\n",
            "[Step 26695/50000] [Progress: 53.39%] [learning rate: 5.2e+03]\n",
            "[Step 26718/50000] [Progress: 53.44%] [learning rate: 4.2e+03]\n",
            "[Step 26729/50000] [Time: 229s] [Train Loss: 2.03e-01] [Train Acc: 0.95]\n",
            "[Step 26744/50000] [Progress: 53.49%] [learning rate: 4.6e+03]\n",
            "[Step 26770/50000] [Progress: 53.54%] [learning rate: 5.0e+03]\n",
            "[Step 26793/50000] [Progress: 53.59%] [learning rate: 4.0e+03]\n",
            "[Step 26820/50000] [Progress: 53.64%] [learning rate: 4.8e+03]\n",
            "[Step 26823/50000] [Time: 230s] [Train Loss: 2.03e-01] [Train Acc: 0.95]\n",
            "[Step 26845/50000] [Progress: 53.69%] [learning rate: 4.7e+03]\n",
            "[Step 26870/50000] [Progress: 53.74%] [learning rate: 5.1e+03]\n",
            "[Step 26893/50000] [Progress: 53.79%] [learning rate: 4.2e+03]\n",
            "[Step 26917/50000] [Time: 230s] [Train Loss: 2.02e-01] [Train Acc: 0.95]\n",
            "[Step 26920/50000] [Progress: 53.84%] [learning rate: 5.0e+03]\n",
            "[Step 26943/50000] [Progress: 53.89%] [learning rate: 4.5e+03]\n",
            "[Step 26968/50000] [Progress: 53.94%] [learning rate: 4.8e+03]\n",
            "[Step 26992/50000] [Progress: 53.98%] [learning rate: 4.8e+03]\n",
            "[Step 27011/50000] [Time: 231s] [Train Loss: 2.02e-01] [Train Acc: 0.95]\n",
            "[Step 27017/50000] [Progress: 54.03%] [learning rate: 5.2e+03]\n",
            "[Step 27040/50000] [Progress: 54.08%] [learning rate: 4.2e+03]\n",
            "[Step 27067/50000] [Progress: 54.13%] [learning rate: 5.0e+03]\n",
            "[Step 27090/50000] [Progress: 54.18%] [learning rate: 4.5e+03]\n",
            "[Step 27105/50000] [Time: 232s] [Train Loss: 2.01e-01] [Train Acc: 0.95]\n",
            "[Step 27115/50000] [Progress: 54.23%] [learning rate: 4.9e+03]\n",
            "[Step 27139/50000] [Progress: 54.28%] [learning rate: 4.3e+03]\n",
            "[Step 27166/50000] [Progress: 54.33%] [learning rate: 5.2e+03]\n",
            "[Step 27188/50000] [Progress: 54.38%] [learning rate: 4.2e+03]\n",
            "[Step 27199/50000] [Time: 232s] [Train Loss: 2.01e-01] [Train Acc: 0.95]\n",
            "[Step 27214/50000] [Progress: 54.43%] [learning rate: 5.0e+03]\n",
            "[Step 27237/50000] [Progress: 54.47%] [learning rate: 4.5e+03]\n",
            "[Step 27262/50000] [Progress: 54.52%] [learning rate: 4.4e+03]\n",
            "[Step 27287/50000] [Progress: 54.57%] [learning rate: 4.8e+03]\n",
            "[Step 27293/50000] [Time: 234s] [Train Loss: 2.01e-01] [Train Acc: 0.95]\n",
            "[Step 27312/50000] [Progress: 54.62%] [learning rate: 5.2e+03]\n",
            "[Step 27335/50000] [Progress: 54.67%] [learning rate: 4.2e+03]\n",
            "[Step 27362/50000] [Progress: 54.72%] [learning rate: 5.1e+03]\n",
            "[Step 27385/50000] [Progress: 54.77%] [learning rate: 4.1e+03]\n",
            "[Step 27387/50000] [Time: 234s] [Train Loss: 2.00e-01] [Train Acc: 0.95]\n",
            "[Step 27412/50000] [Progress: 54.82%] [learning rate: 4.9e+03]\n",
            "[Step 27437/50000] [Progress: 54.87%] [learning rate: 4.4e+03]\n",
            "[Step 27463/50000] [Progress: 54.93%] [learning rate: 5.2e+03]\n",
            "[Step 27481/50000] [Time: 235s] [Train Loss: 2.00e-01] [Train Acc: 0.95]\n",
            "[Step 27486/50000] [Progress: 54.97%] [learning rate: 4.3e+03]\n",
            "[Step 27513/50000] [Progress: 55.03%] [learning rate: 5.1e+03]\n",
            "[Step 27536/50000] [Progress: 55.07%] [learning rate: 4.1e+03]\n",
            "[Step 27562/50000] [Progress: 55.12%] [learning rate: 4.9e+03]\n",
            "[Step 27575/50000] [Time: 236s] [Train Loss: 1.99e-01] [Train Acc: 0.95]\n",
            "[Step 27586/50000] [Progress: 55.17%] [learning rate: 4.4e+03]\n",
            "[Step 27612/50000] [Progress: 55.22%] [learning rate: 4.8e+03]\n",
            "[Step 27636/50000] [Progress: 55.27%] [learning rate: 4.7e+03]\n",
            "[Step 27661/50000] [Progress: 55.32%] [learning rate: 4.6e+03]\n",
            "[Step 27669/50000] [Time: 236s] [Train Loss: 1.99e-01] [Train Acc: 0.95]\n",
            "[Step 27687/50000] [Progress: 55.37%] [learning rate: 4.6e+03]\n",
            "[Step 27712/50000] [Progress: 55.42%] [learning rate: 4.5e+03]\n",
            "[Step 27739/50000] [Progress: 55.48%] [learning rate: 4.9e+03]\n",
            "[Step 27763/50000] [Time: 237s] [Train Loss: 1.98e-01] [Train Acc: 0.95]\n",
            "[Step 27765/50000] [Progress: 55.53%] [learning rate: 4.8e+03]\n",
            "[Step 27791/50000] [Progress: 55.58%] [learning rate: 5.2e+03]\n",
            "[Step 27814/50000] [Progress: 55.63%] [learning rate: 4.2e+03]\n",
            "[Step 27841/50000] [Progress: 55.68%] [learning rate: 5.0e+03]\n",
            "[Step 27857/50000] [Time: 238s] [Train Loss: 1.98e-01] [Train Acc: 0.95]\n",
            "[Step 27864/50000] [Progress: 55.73%] [learning rate: 4.5e+03]\n",
            "[Step 27889/50000] [Progress: 55.78%] [learning rate: 4.9e+03]\n",
            "[Step 27913/50000] [Progress: 55.83%] [learning rate: 4.8e+03]\n",
            "[Step 27938/50000] [Progress: 55.88%] [learning rate: 4.7e+03]\n",
            "[Step 27951/50000] [Time: 239s] [Train Loss: 1.98e-01] [Train Acc: 0.95]\n",
            "[Step 27962/50000] [Progress: 55.92%] [learning rate: 4.7e+03]\n",
            "[Step 27987/50000] [Progress: 55.97%] [learning rate: 4.6e+03]\n",
            "[Step 28013/50000] [Progress: 56.03%] [learning rate: 5.0e+03]\n",
            "[Step 28036/50000] [Progress: 56.07%] [learning rate: 4.5e+03]\n",
            "[Step 28045/50000] [Time: 239s] [Train Loss: 1.97e-01] [Train Acc: 0.95]\n",
            "[Step 28062/50000] [Progress: 56.12%] [learning rate: 4.8e+03]\n",
            "[Step 28087/50000] [Progress: 56.17%] [learning rate: 5.2e+03]\n",
            "[Step 28110/50000] [Progress: 56.22%] [learning rate: 4.3e+03]\n",
            "[Step 28137/50000] [Progress: 56.27%] [learning rate: 5.1e+03]\n",
            "[Step 28139/50000] [Time: 240s] [Train Loss: 1.97e-01] [Train Acc: 0.95]\n",
            "[Step 28160/50000] [Progress: 56.32%] [learning rate: 4.1e+03]\n",
            "[Step 28187/50000] [Progress: 56.37%] [learning rate: 4.9e+03]\n",
            "[Step 28212/50000] [Progress: 56.42%] [learning rate: 4.9e+03]\n",
            "[Step 28234/50000] [Time: 241s] [Train Loss: 1.96e-01] [Train Acc: 0.95]\n",
            "[Step 28238/50000] [Progress: 56.48%] [learning rate: 5.3e+03]\n",
            "[Step 28261/50000] [Progress: 56.52%] [learning rate: 4.3e+03]\n",
            "[Step 28288/50000] [Progress: 56.58%] [learning rate: 5.1e+03]\n",
            "[Step 28311/50000] [Progress: 56.62%] [learning rate: 4.2e+03]\n",
            "[Step 28329/50000] [Time: 242s] [Train Loss: 1.96e-01] [Train Acc: 0.95]\n",
            "[Step 28337/50000] [Progress: 56.67%] [learning rate: 5.0e+03]\n",
            "[Step 28361/50000] [Progress: 56.72%] [learning rate: 4.4e+03]\n",
            "[Step 28388/50000] [Progress: 56.78%] [learning rate: 5.3e+03]\n",
            "[Step 28412/50000] [Progress: 56.82%] [learning rate: 4.7e+03]\n",
            "[Step 28424/50000] [Time: 242s] [Train Loss: 1.96e-01] [Train Acc: 0.95]\n",
            "[Step 28437/50000] [Progress: 56.87%] [learning rate: 4.7e+03]\n",
            "[Step 28463/50000] [Progress: 56.93%] [learning rate: 4.6e+03]\n",
            "[Step 28488/50000] [Progress: 56.98%] [learning rate: 4.5e+03]\n",
            "[Step 28515/50000] [Progress: 57.03%] [learning rate: 4.9e+03]\n",
            "[Step 28519/50000] [Time: 243s] [Train Loss: 1.95e-01] [Train Acc: 0.95]\n",
            "[Step 28541/50000] [Progress: 57.08%] [learning rate: 5.3e+03]\n",
            "[Step 28564/50000] [Progress: 57.13%] [learning rate: 4.3e+03]\n",
            "[Step 28591/50000] [Progress: 57.18%] [learning rate: 5.2e+03]\n",
            "[Step 28614/50000] [Progress: 57.23%] [learning rate: 4.6e+03]\n",
            "[Step 28614/50000] [Time: 244s] [Train Loss: 1.95e-01] [Train Acc: 0.95]\n",
            "[Step 28639/50000] [Progress: 57.28%] [learning rate: 4.5e+03]\n",
            "[Step 28666/50000] [Progress: 57.33%] [learning rate: 4.9e+03]\n",
            "[Step 28692/50000] [Progress: 57.38%] [learning rate: 4.9e+03]\n",
            "[Step 28709/50000] [Time: 245s] [Train Loss: 1.95e-01] [Train Acc: 0.95]\n",
            "[Step 28717/50000] [Progress: 57.43%] [learning rate: 4.8e+03]\n",
            "[Step 28743/50000] [Progress: 57.49%] [learning rate: 4.7e+03]\n",
            "[Step 28769/50000] [Progress: 57.54%] [learning rate: 4.6e+03]\n",
            "[Step 28794/50000] [Progress: 57.59%] [learning rate: 4.6e+03]\n",
            "[Step 28804/50000] [Time: 245s] [Train Loss: 1.94e-01] [Train Acc: 0.95] [Eval Loss: 5.09e-01] [Eval Acc: 0.78]\n",
            "[Step 28821/50000] [Progress: 57.64%] [learning rate: 4.9e+03]\n",
            "[Step 28847/50000] [Progress: 57.69%] [learning rate: 4.9e+03]\n",
            "[Step 28873/50000] [Progress: 57.75%] [learning rate: 4.8e+03]\n",
            "[Step 28897/50000] [Progress: 57.79%] [learning rate: 4.7e+03]\n",
            "[Step 28899/50000] [Time: 248s] [Train Loss: 1.94e-01] [Train Acc: 0.95]\n",
            "[Step 28922/50000] [Progress: 57.84%] [learning rate: 4.7e+03]\n",
            "[Step 28948/50000] [Progress: 57.90%] [learning rate: 5.0e+03]\n",
            "[Step 28972/50000] [Progress: 57.94%] [learning rate: 4.5e+03]\n",
            "[Step 28994/50000] [Time: 248s] [Train Loss: 1.93e-01] [Train Acc: 0.95]\n",
            "[Step 28999/50000] [Progress: 58.00%] [learning rate: 4.9e+03]\n",
            "[Step 29024/50000] [Progress: 58.05%] [learning rate: 4.8e+03]\n",
            "[Step 29050/50000] [Progress: 58.10%] [learning rate: 4.8e+03]\n",
            "[Step 29074/50000] [Progress: 58.15%] [learning rate: 4.7e+03]\n",
            "[Step 29089/50000] [Time: 249s] [Train Loss: 1.93e-01] [Train Acc: 0.95]\n",
            "[Step 29099/50000] [Progress: 58.20%] [learning rate: 4.6e+03]\n",
            "[Step 29124/50000] [Progress: 58.25%] [learning rate: 4.5e+03]\n",
            "[Step 29150/50000] [Progress: 58.30%] [learning rate: 4.9e+03]\n",
            "[Step 29176/50000] [Progress: 58.35%] [learning rate: 5.3e+03]\n",
            "[Step 29184/50000] [Time: 250s] [Train Loss: 1.93e-01] [Train Acc: 0.95]\n",
            "[Step 29199/50000] [Progress: 58.40%] [learning rate: 4.3e+03]\n",
            "[Step 29225/50000] [Progress: 58.45%] [learning rate: 4.7e+03]\n",
            "[Step 29250/50000] [Progress: 58.50%] [learning rate: 4.6e+03]\n",
            "[Step 29276/50000] [Progress: 58.55%] [learning rate: 5.0e+03]\n",
            "[Step 29279/50000] [Time: 250s] [Train Loss: 1.92e-01] [Train Acc: 0.95]\n",
            "[Step 29300/50000] [Progress: 58.60%] [learning rate: 4.5e+03]\n",
            "[Step 29328/50000] [Progress: 58.66%] [learning rate: 5.9e+03]\n",
            "[Step 29351/50000] [Progress: 58.70%] [learning rate: 4.8e+03]\n",
            "[Step 29374/50000] [Time: 251s] [Train Loss: 1.92e-01] [Train Acc: 0.95]\n",
            "[Step 29376/50000] [Progress: 58.75%] [learning rate: 4.7e+03]\n",
            "[Step 29402/50000] [Progress: 58.80%] [learning rate: 4.7e+03]\n",
            "[Step 29427/50000] [Progress: 58.85%] [learning rate: 4.6e+03]\n",
            "[Step 29454/50000] [Progress: 58.91%] [learning rate: 5.0e+03]\n",
            "[Step 29469/50000] [Time: 252s] [Train Loss: 1.91e-01] [Train Acc: 0.95]\n",
            "[Step 29481/50000] [Progress: 58.96%] [learning rate: 5.4e+03]\n",
            "[Step 29505/50000] [Progress: 59.01%] [learning rate: 4.8e+03]\n",
            "[Step 29530/50000] [Progress: 59.06%] [learning rate: 4.7e+03]\n",
            "[Step 29556/50000] [Progress: 59.11%] [learning rate: 4.7e+03]\n",
            "[Step 29564/50000] [Time: 253s] [Train Loss: 1.91e-01] [Train Acc: 0.95]\n",
            "[Step 29581/50000] [Progress: 59.16%] [learning rate: 4.6e+03]\n",
            "[Step 29608/50000] [Progress: 59.22%] [learning rate: 5.0e+03]\n",
            "[Step 29634/50000] [Progress: 59.27%] [learning rate: 5.4e+03]\n",
            "[Step 29657/50000] [Progress: 59.31%] [learning rate: 4.4e+03]\n",
            "[Step 29659/50000] [Time: 253s] [Train Loss: 1.91e-01] [Train Acc: 0.95]\n",
            "[Step 29683/50000] [Progress: 59.37%] [learning rate: 4.8e+03]\n",
            "[Step 29709/50000] [Progress: 59.42%] [learning rate: 5.2e+03]\n",
            "[Step 29732/50000] [Progress: 59.46%] [learning rate: 4.6e+03]\n",
            "[Step 29754/50000] [Time: 254s] [Train Loss: 1.90e-01] [Train Acc: 0.95]\n",
            "[Step 29757/50000] [Progress: 59.51%] [learning rate: 5.0e+03]\n",
            "[Step 29782/50000] [Progress: 59.56%] [learning rate: 4.9e+03]\n",
            "[Step 29808/50000] [Progress: 59.62%] [learning rate: 4.9e+03]\n",
            "[Step 29832/50000] [Progress: 59.66%] [learning rate: 4.8e+03]\n",
            "[Step 29849/50000] [Time: 255s] [Train Loss: 1.90e-01] [Train Acc: 0.95]\n",
            "[Step 29857/50000] [Progress: 59.71%] [learning rate: 4.7e+03]\n",
            "[Step 29883/50000] [Progress: 59.77%] [learning rate: 5.1e+03]\n",
            "[Step 29907/50000] [Progress: 59.81%] [learning rate: 4.6e+03]\n",
            "[Step 29934/50000] [Progress: 59.87%] [learning rate: 5.4e+03]\n",
            "[Step 29944/50000] [Time: 255s] [Train Loss: 1.90e-01] [Train Acc: 0.95]\n",
            "[Step 29957/50000] [Progress: 59.91%] [learning rate: 4.4e+03]\n",
            "[Step 29983/50000] [Progress: 59.97%] [learning rate: 4.8e+03]\n",
            "[Step 30007/50000] [Progress: 60.01%] [learning rate: 4.7e+03]\n",
            "[Step 30032/50000] [Progress: 60.06%] [learning rate: 4.7e+03]\n",
            "[Step 30039/50000] [Time: 256s] [Train Loss: 1.89e-01] [Train Acc: 0.95]\n",
            "[Step 30057/50000] [Progress: 60.11%] [learning rate: 5.1e+03]\n",
            "[Step 30081/50000] [Progress: 60.16%] [learning rate: 5.0e+03]\n",
            "[Step 30106/50000] [Progress: 60.21%] [learning rate: 4.9e+03]\n",
            "[Step 30132/50000] [Progress: 60.26%] [learning rate: 4.8e+03]\n",
            "[Step 30135/50000] [Time: 257s] [Train Loss: 1.89e-01] [Train Acc: 0.95]\n",
            "[Step 30156/50000] [Progress: 60.31%] [learning rate: 4.8e+03]\n",
            "[Step 30181/50000] [Progress: 60.36%] [learning rate: 4.7e+03]\n",
            "[Step 30206/50000] [Progress: 60.41%] [learning rate: 4.6e+03]\n",
            "[Step 30231/50000] [Time: 257s] [Train Loss: 1.88e-01] [Train Acc: 0.96]\n",
            "[Step 30232/50000] [Progress: 60.46%] [learning rate: 5.0e+03]\n",
            "[Step 30259/50000] [Progress: 60.52%] [learning rate: 5.4e+03]\n",
            "[Step 30283/50000] [Progress: 60.57%] [learning rate: 4.8e+03]\n",
            "[Step 30308/50000] [Progress: 60.62%] [learning rate: 4.8e+03]\n",
            "[Step 30327/50000] [Time: 258s] [Train Loss: 1.88e-01] [Train Acc: 0.96]\n",
            "[Step 30334/50000] [Progress: 60.67%] [learning rate: 4.7e+03]\n",
            "[Step 30359/50000] [Progress: 60.72%] [learning rate: 4.6e+03]\n",
            "[Step 30386/50000] [Progress: 60.77%] [learning rate: 5.0e+03]\n",
            "[Step 30412/50000] [Progress: 60.82%] [learning rate: 5.4e+03]\n",
            "[Step 30423/50000] [Time: 259s] [Train Loss: 1.88e-01] [Train Acc: 0.96]\n",
            "[Step 30435/50000] [Progress: 60.87%] [learning rate: 4.4e+03]\n",
            "[Step 30462/50000] [Progress: 60.92%] [learning rate: 5.3e+03]\n",
            "[Step 30485/50000] [Progress: 60.97%] [learning rate: 4.3e+03]\n",
            "[Step 30511/50000] [Progress: 61.02%] [learning rate: 5.1e+03]\n",
            "[Step 30519/50000] [Time: 259s] [Train Loss: 1.87e-01] [Train Acc: 0.96]\n",
            "[Step 30535/50000] [Progress: 61.07%] [learning rate: 4.6e+03]\n",
            "[Step 30562/50000] [Progress: 61.12%] [learning rate: 5.5e+03]\n",
            "[Step 30586/50000] [Progress: 61.17%] [learning rate: 4.9e+03]\n",
            "[Step 30611/50000] [Progress: 61.22%] [learning rate: 4.8e+03]\n",
            "[Step 30615/50000] [Time: 260s] [Train Loss: 1.87e-01] [Train Acc: 0.96]\n",
            "[Step 30637/50000] [Progress: 61.27%] [learning rate: 4.7e+03]\n",
            "[Step 30663/50000] [Progress: 61.33%] [learning rate: 5.1e+03]\n",
            "[Step 30687/50000] [Progress: 61.37%] [learning rate: 4.6e+03]\n",
            "[Step 30711/50000] [Time: 261s] [Train Loss: 1.87e-01] [Train Acc: 0.96]\n",
            "[Step 30713/50000] [Progress: 61.43%] [learning rate: 5.5e+03]\n",
            "[Step 30736/50000] [Progress: 61.47%] [learning rate: 4.5e+03]\n",
            "[Step 30763/50000] [Progress: 61.53%] [learning rate: 5.3e+03]\n",
            "[Step 30786/50000] [Progress: 61.57%] [learning rate: 4.8e+03]\n",
            "[Step 30807/50000] [Time: 261s] [Train Loss: 1.86e-01] [Train Acc: 0.96]\n",
            "[Step 30811/50000] [Progress: 61.62%] [learning rate: 4.7e+03]\n",
            "[Step 30836/50000] [Progress: 61.67%] [learning rate: 4.6e+03]\n",
            "[Step 30862/50000] [Progress: 61.72%] [learning rate: 5.5e+03]\n",
            "[Step 30885/50000] [Progress: 61.77%] [learning rate: 4.5e+03]\n",
            "[Step 30903/50000] [Time: 262s] [Train Loss: 1.86e-01] [Train Acc: 0.96]\n",
            "[Step 30912/50000] [Progress: 61.82%] [learning rate: 5.3e+03]\n",
            "[Step 30935/50000] [Progress: 61.87%] [learning rate: 4.4e+03]\n",
            "[Step 30961/50000] [Progress: 61.92%] [learning rate: 5.2e+03]\n",
            "[Step 30985/50000] [Progress: 61.97%] [learning rate: 4.6e+03]\n",
            "[Step 30999/50000] [Time: 263s] [Train Loss: 1.85e-01] [Train Acc: 0.96]\n",
            "[Step 31012/50000] [Progress: 62.02%] [learning rate: 5.5e+03]\n",
            "[Step 31035/50000] [Progress: 62.07%] [learning rate: 4.5e+03]\n",
            "[Step 31061/50000] [Progress: 62.12%] [learning rate: 4.9e+03]\n",
            "[Step 31085/50000] [Progress: 62.17%] [learning rate: 4.8e+03]\n",
            "[Step 31095/50000] [Time: 264s] [Train Loss: 1.85e-01] [Train Acc: 0.96]\n",
            "[Step 31110/50000] [Progress: 62.22%] [learning rate: 4.7e+03]\n",
            "[Step 31135/50000] [Progress: 62.27%] [learning rate: 5.1e+03]\n",
            "[Step 31159/50000] [Progress: 62.32%] [learning rate: 4.6e+03]\n",
            "[Step 31186/50000] [Progress: 62.37%] [learning rate: 5.5e+03]\n",
            "[Step 31191/50000] [Time: 265s] [Train Loss: 1.85e-01] [Train Acc: 0.96]\n",
            "[Step 31210/50000] [Progress: 62.42%] [learning rate: 4.9e+03]\n",
            "[Step 31235/50000] [Progress: 62.47%] [learning rate: 4.8e+03]\n",
            "[Step 31261/50000] [Progress: 62.52%] [learning rate: 4.8e+03]\n",
            "[Step 31286/50000] [Progress: 62.57%] [learning rate: 4.7e+03]\n",
            "[Step 31287/50000] [Time: 265s] [Train Loss: 1.84e-01] [Train Acc: 0.96]\n",
            "[Step 31311/50000] [Progress: 62.62%] [learning rate: 5.1e+03]\n",
            "[Step 31337/50000] [Progress: 62.67%] [learning rate: 5.5e+03]\n",
            "[Step 31361/50000] [Progress: 62.72%] [learning rate: 4.9e+03]\n",
            "[Step 31383/50000] [Time: 266s] [Train Loss: 1.84e-01] [Train Acc: 0.96]\n",
            "[Step 31386/50000] [Progress: 62.77%] [learning rate: 4.9e+03]\n",
            "[Step 31412/50000] [Progress: 62.82%] [learning rate: 5.3e+03]\n",
            "[Step 31435/50000] [Progress: 62.87%] [learning rate: 4.7e+03]\n",
            "[Step 31461/50000] [Progress: 62.92%] [learning rate: 5.1e+03]\n",
            "[Step 31479/50000] [Time: 267s] [Train Loss: 1.84e-01] [Train Acc: 0.96]\n",
            "[Step 31488/50000] [Progress: 62.98%] [learning rate: 5.5e+03]\n",
            "[Step 31513/50000] [Progress: 63.03%] [learning rate: 5.0e+03]\n",
            "[Step 31539/50000] [Progress: 63.08%] [learning rate: 4.9e+03]\n",
            "[Step 31565/50000] [Progress: 63.13%] [learning rate: 4.8e+03]\n",
            "[Step 31575/50000] [Time: 268s] [Train Loss: 1.83e-01] [Train Acc: 0.96]\n",
            "[Step 31590/50000] [Progress: 63.18%] [learning rate: 4.7e+03]\n",
            "[Step 31615/50000] [Progress: 63.23%] [learning rate: 5.1e+03]\n",
            "[Step 31640/50000] [Progress: 63.28%] [learning rate: 5.0e+03]\n",
            "[Step 31664/50000] [Progress: 63.33%] [learning rate: 5.0e+03]\n",
            "[Step 31671/50000] [Time: 269s] [Train Loss: 1.83e-01] [Train Acc: 0.96]\n",
            "[Step 31689/50000] [Progress: 63.38%] [learning rate: 4.9e+03]\n",
            "[Step 31715/50000] [Progress: 63.43%] [learning rate: 4.8e+03]\n",
            "[Step 31740/50000] [Progress: 63.48%] [learning rate: 4.8e+03]\n",
            "[Step 31767/50000] [Progress: 63.53%] [learning rate: 5.1e+03]\n",
            "[Step 31767/50000] [Time: 269s] [Train Loss: 1.83e-01] [Train Acc: 0.96]\n",
            "[Step 31793/50000] [Progress: 63.59%] [learning rate: 5.6e+03]\n",
            "[Step 31816/50000] [Progress: 63.63%] [learning rate: 4.5e+03]\n",
            "[Step 31843/50000] [Progress: 63.69%] [learning rate: 5.4e+03]\n",
            "[Step 31863/50000] [Time: 270s] [Train Loss: 1.82e-01] [Train Acc: 0.96]\n",
            "[Step 31866/50000] [Progress: 63.73%] [learning rate: 4.4e+03]\n",
            "[Step 31892/50000] [Progress: 63.78%] [learning rate: 5.3e+03]\n",
            "[Step 31916/50000] [Progress: 63.83%] [learning rate: 4.7e+03]\n",
            "[Step 31943/50000] [Progress: 63.89%] [learning rate: 5.6e+03]\n",
            "[Step 31959/50000] [Time: 271s] [Train Loss: 1.82e-01] [Train Acc: 0.96]\n",
            "[Step 31966/50000] [Progress: 63.93%] [learning rate: 5.0e+03]\n",
            "[Step 31991/50000] [Progress: 63.98%] [learning rate: 4.9e+03]\n",
            "[Step 32017/50000] [Progress: 64.03%] [learning rate: 4.9e+03]\n",
            "[Step 32043/50000] [Progress: 64.09%] [learning rate: 5.3e+03]\n",
            "[Step 32055/50000] [Time: 271s] [Train Loss: 1.82e-01] [Train Acc: 0.96]\n",
            "[Step 32067/50000] [Progress: 64.13%] [learning rate: 4.7e+03]\n",
            "[Step 32094/50000] [Progress: 64.19%] [learning rate: 5.6e+03]\n",
            "[Step 32117/50000] [Progress: 64.23%] [learning rate: 4.6e+03]\n",
            "[Step 32143/50000] [Progress: 64.29%] [learning rate: 5.0e+03]\n",
            "[Step 32151/50000] [Time: 272s] [Train Loss: 1.81e-01] [Train Acc: 0.96]\n",
            "[Step 32169/50000] [Progress: 64.34%] [learning rate: 5.4e+03]\n",
            "[Step 32192/50000] [Progress: 64.38%] [learning rate: 4.4e+03]\n",
            "[Step 32219/50000] [Progress: 64.44%] [learning rate: 5.2e+03]\n",
            "[Step 32244/50000] [Progress: 64.49%] [learning rate: 5.1e+03]\n",
            "[Step 32247/50000] [Time: 273s] [Train Loss: 1.81e-01] [Train Acc: 0.96]\n",
            "[Step 32269/50000] [Progress: 64.54%] [learning rate: 5.6e+03]\n",
            "[Step 32292/50000] [Progress: 64.58%] [learning rate: 4.5e+03]\n",
            "[Step 32319/50000] [Progress: 64.64%] [learning rate: 5.4e+03]\n",
            "[Step 32342/50000] [Progress: 64.68%] [learning rate: 4.8e+03]\n",
            "[Step 32344/50000] [Time: 274s] [Train Loss: 1.81e-01] [Train Acc: 0.96]\n",
            "[Step 32367/50000] [Progress: 64.73%] [learning rate: 5.2e+03]\n",
            "[Step 32391/50000] [Progress: 64.78%] [learning rate: 4.7e+03]\n",
            "[Step 32418/50000] [Progress: 64.84%] [learning rate: 6.2e+03]\n",
            "[Step 32439/50000] [Progress: 64.88%] [learning rate: 4.1e+03]\n",
            "[Step 32441/50000] [Time: 274s] [Train Loss: 1.80e-01] [Train Acc: 0.96]\n",
            "[Step 32466/50000] [Progress: 64.93%] [learning rate: 5.4e+03]\n",
            "[Step 32489/50000] [Progress: 64.98%] [learning rate: 4.9e+03]\n",
            "[Step 32514/50000] [Progress: 65.03%] [learning rate: 4.8e+03]\n",
            "[Step 32538/50000] [Time: 275s] [Train Loss: 1.80e-01] [Train Acc: 0.96]\n",
            "[Step 32539/50000] [Progress: 65.08%] [learning rate: 5.2e+03]\n",
            "[Step 32564/50000] [Progress: 65.13%] [learning rate: 5.6e+03]\n",
            "[Step 32587/50000] [Progress: 65.17%] [learning rate: 4.6e+03]\n",
            "[Step 32613/50000] [Progress: 65.23%] [learning rate: 5.0e+03]\n",
            "[Step 32635/50000] [Time: 276s] [Train Loss: 1.79e-01] [Train Acc: 0.96]\n",
            "[Step 32637/50000] [Progress: 65.27%] [learning rate: 4.9e+03]\n",
            "[Step 32662/50000] [Progress: 65.32%] [learning rate: 5.3e+03]\n",
            "[Step 32686/50000] [Progress: 65.37%] [learning rate: 4.7e+03]\n",
            "[Step 32714/50000] [Progress: 65.43%] [learning rate: 5.6e+03]\n",
            "[Step 32732/50000] [Time: 277s] [Train Loss: 1.79e-01] [Train Acc: 0.96]\n",
            "[Step 32739/50000] [Progress: 65.48%] [learning rate: 5.1e+03]\n",
            "[Step 32765/50000] [Progress: 65.53%] [learning rate: 5.0e+03]\n",
            "[Step 32791/50000] [Progress: 65.58%] [learning rate: 4.9e+03]\n",
            "[Step 32816/50000] [Progress: 65.63%] [learning rate: 4.8e+03]\n",
            "[Step 32829/50000] [Time: 277s] [Train Loss: 1.79e-01] [Train Acc: 0.96]\n",
            "[Step 32843/50000] [Progress: 65.69%] [learning rate: 5.2e+03]\n",
            "[Step 32869/50000] [Progress: 65.74%] [learning rate: 5.2e+03]\n",
            "[Step 32893/50000] [Progress: 65.79%] [learning rate: 5.1e+03]\n",
            "[Step 32918/50000] [Progress: 65.84%] [learning rate: 5.0e+03]\n",
            "[Step 32926/50000] [Time: 278s] [Train Loss: 1.78e-01] [Train Acc: 0.96]\n",
            "[Step 32944/50000] [Progress: 65.89%] [learning rate: 4.9e+03]\n",
            "[Step 32969/50000] [Progress: 65.94%] [learning rate: 4.9e+03]\n",
            "[Step 32996/50000] [Progress: 65.99%] [learning rate: 5.3e+03]\n",
            "[Step 33022/50000] [Progress: 66.04%] [learning rate: 5.2e+03]\n",
            "[Step 33023/50000] [Time: 279s] [Train Loss: 1.78e-01] [Train Acc: 0.96]\n",
            "[Step 33048/50000] [Progress: 66.10%] [learning rate: 5.6e+03]\n",
            "[Step 33071/50000] [Progress: 66.14%] [learning rate: 4.6e+03]\n",
            "[Step 33098/50000] [Progress: 66.20%] [learning rate: 5.4e+03]\n",
            "[Step 33120/50000] [Time: 279s] [Train Loss: 1.78e-01] [Train Acc: 0.96]\n",
            "[Step 33121/50000] [Progress: 66.24%] [learning rate: 4.9e+03]\n",
            "[Step 33146/50000] [Progress: 66.29%] [learning rate: 5.3e+03]\n",
            "[Step 33170/50000] [Progress: 66.34%] [learning rate: 5.2e+03]\n",
            "[Step 33195/50000] [Progress: 66.39%] [learning rate: 5.1e+03]\n",
            "[Step 33217/50000] [Time: 280s] [Train Loss: 1.77e-01] [Train Acc: 0.96]\n",
            "[Step 33219/50000] [Progress: 66.44%] [learning rate: 5.0e+03]\n",
            "[Step 33244/50000] [Progress: 66.49%] [learning rate: 5.0e+03]\n",
            "[Step 33270/50000] [Progress: 66.54%] [learning rate: 5.4e+03]\n",
            "[Step 33293/50000] [Progress: 66.59%] [learning rate: 4.8e+03]\n",
            "[Step 33314/50000] [Time: 281s] [Train Loss: 1.77e-01] [Train Acc: 0.96]\n",
            "[Step 33319/50000] [Progress: 66.64%] [learning rate: 5.2e+03]\n",
            "[Step 33346/50000] [Progress: 66.69%] [learning rate: 5.7e+03]\n",
            "[Step 33368/50000] [Progress: 66.74%] [learning rate: 4.6e+03]\n",
            "[Step 33394/50000] [Progress: 66.79%] [learning rate: 5.5e+03]\n",
            "[Step 33411/50000] [Time: 282s] [Train Loss: 1.77e-01] [Train Acc: 0.96]\n",
            "[Step 33417/50000] [Progress: 66.83%] [learning rate: 4.9e+03]\n",
            "[Step 33442/50000] [Progress: 66.88%] [learning rate: 5.3e+03]\n",
            "[Step 33466/50000] [Progress: 66.93%] [learning rate: 4.8e+03]\n",
            "[Step 33495/50000] [Progress: 66.99%] [learning rate: 6.3e+03]\n",
            "[Step 33508/50000] [Time: 282s] [Train Loss: 1.76e-01] [Train Acc: 0.96]\n",
            "[Step 33518/50000] [Progress: 67.04%] [learning rate: 5.1e+03]\n",
            "[Step 33543/50000] [Progress: 67.09%] [learning rate: 5.0e+03]\n",
            "[Step 33569/50000] [Progress: 67.14%] [learning rate: 4.9e+03]\n",
            "[Step 33595/50000] [Progress: 67.19%] [learning rate: 5.4e+03]\n",
            "[Step 33605/50000] [Time: 283s] [Train Loss: 1.76e-01] [Train Acc: 0.96] [Eval Loss: 5.13e-01] [Eval Acc: 0.78]\n",
            "[Step 33619/50000] [Progress: 67.24%] [learning rate: 5.3e+03]\n",
            "[Step 33644/50000] [Progress: 67.29%] [learning rate: 5.2e+03]\n",
            "[Step 33670/50000] [Progress: 67.34%] [learning rate: 5.6e+03]\n",
            "[Step 33693/50000] [Progress: 67.39%] [learning rate: 4.6e+03]\n",
            "[Step 33702/50000] [Time: 285s] [Train Loss: 1.76e-01] [Train Acc: 0.96]\n",
            "[Step 33720/50000] [Progress: 67.44%] [learning rate: 5.5e+03]\n",
            "[Step 33743/50000] [Progress: 67.49%] [learning rate: 4.9e+03]\n",
            "[Step 33769/50000] [Progress: 67.54%] [learning rate: 5.3e+03]\n",
            "[Step 33795/50000] [Progress: 67.59%] [learning rate: 5.2e+03]\n",
            "[Step 33799/50000] [Time: 286s] [Train Loss: 1.75e-01] [Train Acc: 0.96]\n",
            "[Step 33819/50000] [Progress: 67.64%] [learning rate: 5.1e+03]\n",
            "[Step 33844/50000] [Progress: 67.69%] [learning rate: 5.1e+03]\n",
            "[Step 33870/50000] [Progress: 67.74%] [learning rate: 5.0e+03]\n",
            "[Step 33895/50000] [Progress: 67.79%] [learning rate: 4.9e+03]\n",
            "[Step 33896/50000] [Time: 287s] [Train Loss: 1.75e-01] [Train Acc: 0.96]\n",
            "[Step 33922/50000] [Progress: 67.84%] [learning rate: 5.3e+03]\n",
            "[Step 33948/50000] [Progress: 67.90%] [learning rate: 5.2e+03]\n",
            "[Step 33974/50000] [Progress: 67.95%] [learning rate: 5.7e+03]\n",
            "[Step 33993/50000] [Time: 287s] [Train Loss: 1.75e-01] [Train Acc: 0.96]\n",
            "[Step 33997/50000] [Progress: 67.99%] [learning rate: 4.6e+03]\n",
            "[Step 34024/50000] [Progress: 68.05%] [learning rate: 5.5e+03]\n",
            "[Step 34047/50000] [Progress: 68.09%] [learning rate: 4.9e+03]\n",
            "[Step 34072/50000] [Progress: 68.14%] [learning rate: 5.3e+03]\n",
            "[Step 34090/50000] [Time: 288s] [Train Loss: 1.74e-01] [Train Acc: 0.96]\n",
            "[Step 34096/50000] [Progress: 68.19%] [learning rate: 5.3e+03]\n",
            "[Step 34121/50000] [Progress: 68.24%] [learning rate: 5.7e+03]\n",
            "[Step 34144/50000] [Progress: 68.29%] [learning rate: 4.6e+03]\n",
            "[Step 34171/50000] [Progress: 68.34%] [learning rate: 5.5e+03]\n",
            "[Step 34187/50000] [Time: 289s] [Train Loss: 1.74e-01] [Train Acc: 0.96]\n",
            "[Step 34194/50000] [Progress: 68.39%] [learning rate: 5.0e+03]\n",
            "[Step 34219/50000] [Progress: 68.44%] [learning rate: 5.4e+03]\n",
            "[Step 34243/50000] [Progress: 68.49%] [learning rate: 5.3e+03]\n",
            "[Step 34268/50000] [Progress: 68.54%] [learning rate: 5.7e+03]\n",
            "[Step 34284/50000] [Time: 290s] [Train Loss: 1.74e-01] [Train Acc: 0.96]\n",
            "[Step 34291/50000] [Progress: 68.58%] [learning rate: 4.7e+03]\n",
            "[Step 34318/50000] [Progress: 68.64%] [learning rate: 5.6e+03]\n",
            "[Step 34341/50000] [Progress: 68.68%] [learning rate: 4.5e+03]\n",
            "[Step 34368/50000] [Progress: 68.74%] [learning rate: 5.4e+03]\n",
            "[Step 34381/50000] [Time: 291s] [Train Loss: 1.73e-01] [Train Acc: 0.96]\n",
            "[Step 34393/50000] [Progress: 68.79%] [learning rate: 5.3e+03]\n",
            "[Step 34420/50000] [Progress: 68.84%] [learning rate: 6.3e+03]\n",
            "[Step 34443/50000] [Progress: 68.89%] [learning rate: 5.1e+03]\n",
            "[Step 34468/50000] [Progress: 68.94%] [learning rate: 5.1e+03]\n",
            "[Step 34478/50000] [Time: 291s] [Train Loss: 1.73e-01] [Train Acc: 0.96]\n",
            "[Step 34494/50000] [Progress: 68.99%] [learning rate: 5.0e+03]\n",
            "[Step 34519/50000] [Progress: 69.04%] [learning rate: 4.9e+03]\n",
            "[Step 34544/50000] [Progress: 69.09%] [learning rate: 5.3e+03]\n",
            "[Step 34569/50000] [Progress: 69.14%] [learning rate: 5.8e+03]\n",
            "[Step 34575/50000] [Time: 292s] [Train Loss: 1.73e-01] [Train Acc: 0.96]\n",
            "[Step 34592/50000] [Progress: 69.18%] [learning rate: 4.7e+03]\n",
            "[Step 34619/50000] [Progress: 69.24%] [learning rate: 5.6e+03]\n",
            "[Step 34642/50000] [Progress: 69.28%] [learning rate: 5.0e+03]\n",
            "[Step 34667/50000] [Progress: 69.33%] [learning rate: 4.9e+03]\n",
            "[Step 34672/50000] [Time: 293s] [Train Loss: 1.72e-01] [Train Acc: 0.96]\n",
            "[Step 34692/50000] [Progress: 69.38%] [learning rate: 5.4e+03]\n",
            "[Step 34717/50000] [Progress: 69.43%] [learning rate: 5.3e+03]\n",
            "[Step 34743/50000] [Progress: 69.49%] [learning rate: 5.7e+03]\n",
            "[Step 34766/50000] [Progress: 69.53%] [learning rate: 4.7e+03]\n",
            "[Step 34769/50000] [Time: 294s] [Train Loss: 1.72e-01] [Train Acc: 0.96]\n",
            "[Step 34793/50000] [Progress: 69.59%] [learning rate: 5.5e+03]\n",
            "[Step 34816/50000] [Progress: 69.63%] [learning rate: 5.0e+03]\n",
            "[Step 34841/50000] [Progress: 69.68%] [learning rate: 5.4e+03]\n",
            "[Step 34866/50000] [Progress: 69.73%] [learning rate: 5.3e+03]\n",
            "[Step 34866/50000] [Time: 294s] [Train Loss: 1.72e-01] [Train Acc: 0.96]\n",
            "[Step 34892/50000] [Progress: 69.78%] [learning rate: 5.7e+03]\n",
            "[Step 34915/50000] [Progress: 69.83%] [learning rate: 4.7e+03]\n",
            "[Step 34942/50000] [Progress: 69.88%] [learning rate: 5.6e+03]\n",
            "[Step 34963/50000] [Time: 295s] [Train Loss: 1.72e-01] [Train Acc: 0.96]\n",
            "[Step 34965/50000] [Progress: 69.93%] [learning rate: 5.0e+03]\n",
            "[Step 34990/50000] [Progress: 69.98%] [learning rate: 5.4e+03]\n",
            "[Step 35015/50000] [Progress: 70.03%] [learning rate: 5.3e+03]\n",
            "[Step 35041/50000] [Progress: 70.08%] [learning rate: 5.2e+03]\n",
            "[Step 35060/50000] [Time: 296s] [Train Loss: 1.71e-01] [Train Acc: 0.96]\n",
            "[Step 35065/50000] [Progress: 70.13%] [learning rate: 5.2e+03]\n",
            "[Step 35090/50000] [Progress: 70.18%] [learning rate: 5.1e+03]\n",
            "[Step 35116/50000] [Progress: 70.23%] [learning rate: 5.5e+03]\n",
            "[Step 35139/50000] [Progress: 70.28%] [learning rate: 4.9e+03]\n",
            "[Step 35157/50000] [Time: 296s] [Train Loss: 1.71e-01] [Train Acc: 0.96]\n",
            "[Step 35165/50000] [Progress: 70.33%] [learning rate: 5.3e+03]\n",
            "[Step 35190/50000] [Progress: 70.38%] [learning rate: 5.3e+03]\n",
            "[Step 35214/50000] [Progress: 70.43%] [learning rate: 5.2e+03]\n",
            "[Step 35239/50000] [Progress: 70.48%] [learning rate: 5.1e+03]\n",
            "[Step 35255/50000] [Time: 297s] [Train Loss: 1.71e-01] [Train Acc: 0.96]\n",
            "[Step 35265/50000] [Progress: 70.53%] [learning rate: 5.0e+03]\n",
            "[Step 35290/50000] [Progress: 70.58%] [learning rate: 5.0e+03]\n",
            "[Step 35316/50000] [Progress: 70.63%] [learning rate: 5.4e+03]\n",
            "[Step 35343/50000] [Progress: 70.69%] [learning rate: 5.8e+03]\n",
            "[Step 35353/50000] [Time: 298s] [Train Loss: 1.70e-01] [Train Acc: 0.96]\n",
            "[Step 35366/50000] [Progress: 70.73%] [learning rate: 4.7e+03]\n",
            "[Step 35393/50000] [Progress: 70.79%] [learning rate: 5.6e+03]\n",
            "[Step 35416/50000] [Progress: 70.83%] [learning rate: 4.6e+03]\n",
            "[Step 35442/50000] [Progress: 70.88%] [learning rate: 5.5e+03]\n",
            "[Step 35451/50000] [Time: 298s] [Train Loss: 1.70e-01] [Train Acc: 0.96]\n",
            "[Step 35466/50000] [Progress: 70.93%] [learning rate: 5.4e+03]\n",
            "[Step 35491/50000] [Progress: 70.98%] [learning rate: 5.8e+03]\n",
            "[Step 35514/50000] [Progress: 71.03%] [learning rate: 4.8e+03]\n",
            "[Step 35541/50000] [Progress: 71.08%] [learning rate: 5.7e+03]\n",
            "[Step 35549/50000] [Time: 299s] [Train Loss: 1.70e-01] [Train Acc: 0.96]\n",
            "[Step 35564/50000] [Progress: 71.13%] [learning rate: 5.1e+03]\n",
            "[Step 35589/50000] [Progress: 71.18%] [learning rate: 5.0e+03]\n",
            "[Step 35614/50000] [Progress: 71.23%] [learning rate: 5.4e+03]\n",
            "[Step 35639/50000] [Progress: 71.28%] [learning rate: 5.3e+03]\n",
            "[Step 35647/50000] [Time: 300s] [Train Loss: 1.69e-01] [Train Acc: 0.97]\n",
            "[Step 35663/50000] [Progress: 71.33%] [learning rate: 5.3e+03]\n",
            "[Step 35688/50000] [Progress: 71.38%] [learning rate: 5.2e+03]\n",
            "[Step 35714/50000] [Progress: 71.43%] [learning rate: 5.1e+03]\n",
            "[Step 35739/50000] [Progress: 71.48%] [learning rate: 5.0e+03]\n",
            "[Step 35745/50000] [Time: 301s] [Train Loss: 1.69e-01] [Train Acc: 0.97]\n",
            "[Step 35766/50000] [Progress: 71.53%] [learning rate: 5.4e+03]\n",
            "[Step 35792/50000] [Progress: 71.58%] [learning rate: 5.4e+03]\n",
            "[Step 35818/50000] [Progress: 71.64%] [learning rate: 5.8e+03]\n",
            "[Step 35841/50000] [Progress: 71.68%] [learning rate: 4.7e+03]\n",
            "[Step 35843/50000] [Time: 301s] [Train Loss: 1.69e-01] [Train Acc: 0.97]\n",
            "[Step 35868/50000] [Progress: 71.74%] [learning rate: 5.6e+03]\n",
            "[Step 35891/50000] [Progress: 71.78%] [learning rate: 5.0e+03]\n",
            "[Step 35917/50000] [Progress: 71.83%] [learning rate: 5.5e+03]\n",
            "[Step 35941/50000] [Time: 302s] [Train Loss: 1.68e-01] [Train Acc: 0.97]\n",
            "[Step 35943/50000] [Progress: 71.89%] [learning rate: 5.4e+03]\n",
            "[Step 35969/50000] [Progress: 71.94%] [learning rate: 5.3e+03]\n",
            "[Step 35993/50000] [Progress: 71.99%] [learning rate: 5.2e+03]\n",
            "[Step 36018/50000] [Progress: 72.04%] [learning rate: 5.1e+03]\n",
            "[Step 36039/50000] [Time: 303s] [Train Loss: 1.68e-01] [Train Acc: 0.97]\n",
            "[Step 36044/50000] [Progress: 72.09%] [learning rate: 5.6e+03]\n",
            "[Step 36068/50000] [Progress: 72.14%] [learning rate: 5.0e+03]\n",
            "[Step 36095/50000] [Progress: 72.19%] [learning rate: 5.4e+03]\n",
            "[Step 36120/50000] [Progress: 72.24%] [learning rate: 5.3e+03]\n",
            "[Step 36137/50000] [Time: 304s] [Train Loss: 1.68e-01] [Train Acc: 0.97]\n",
            "[Step 36146/50000] [Progress: 72.29%] [learning rate: 5.2e+03]\n",
            "[Step 36170/50000] [Progress: 72.34%] [learning rate: 5.2e+03]\n",
            "[Step 36195/50000] [Progress: 72.39%] [learning rate: 5.1e+03]\n",
            "[Step 36220/50000] [Progress: 72.44%] [learning rate: 5.0e+03]\n",
            "[Step 36235/50000] [Time: 305s] [Train Loss: 1.67e-01] [Train Acc: 0.97]\n",
            "[Step 36245/50000] [Progress: 72.49%] [learning rate: 5.4e+03]\n",
            "[Step 36271/50000] [Progress: 72.54%] [learning rate: 5.9e+03]\n",
            "[Step 36295/50000] [Progress: 72.59%] [learning rate: 5.3e+03]\n",
            "[Step 36320/50000] [Progress: 72.64%] [learning rate: 5.2e+03]\n",
            "[Step 36333/50000] [Time: 305s] [Train Loss: 1.67e-01] [Train Acc: 0.97]\n",
            "[Step 36346/50000] [Progress: 72.69%] [learning rate: 5.1e+03]\n",
            "[Step 36371/50000] [Progress: 72.74%] [learning rate: 5.0e+03]\n",
            "[Step 36396/50000] [Progress: 72.79%] [learning rate: 5.5e+03]\n",
            "[Step 36422/50000] [Progress: 72.84%] [learning rate: 5.9e+03]\n",
            "[Step 36431/50000] [Time: 306s] [Train Loss: 1.67e-01] [Train Acc: 0.97]\n",
            "[Step 36446/50000] [Progress: 72.89%] [learning rate: 5.3e+03]\n",
            "[Step 36471/50000] [Progress: 72.94%] [learning rate: 5.2e+03]\n",
            "[Step 36497/50000] [Progress: 72.99%] [learning rate: 5.1e+03]\n",
            "[Step 36522/50000] [Progress: 73.04%] [learning rate: 5.1e+03]\n",
            "[Step 36529/50000] [Time: 307s] [Train Loss: 1.66e-01] [Train Acc: 0.97]\n",
            "[Step 36549/50000] [Progress: 73.10%] [learning rate: 5.5e+03]\n",
            "[Step 36575/50000] [Progress: 73.15%] [learning rate: 5.9e+03]\n",
            "[Step 36598/50000] [Progress: 73.20%] [learning rate: 4.8e+03]\n",
            "[Step 36624/50000] [Progress: 73.25%] [learning rate: 5.2e+03]\n",
            "[Step 36627/50000] [Time: 307s] [Train Loss: 1.66e-01] [Train Acc: 0.97]\n",
            "[Step 36649/50000] [Progress: 73.30%] [learning rate: 5.2e+03]\n",
            "[Step 36675/50000] [Progress: 73.35%] [learning rate: 5.6e+03]\n",
            "[Step 36699/50000] [Progress: 73.40%] [learning rate: 5.0e+03]\n",
            "[Step 36725/50000] [Time: 308s] [Train Loss: 1.66e-01] [Train Acc: 0.97]\n",
            "[Step 36726/50000] [Progress: 73.45%] [learning rate: 6.0e+03]\n",
            "[Step 36749/50000] [Progress: 73.50%] [learning rate: 4.9e+03]\n",
            "[Step 36775/50000] [Progress: 73.55%] [learning rate: 5.3e+03]\n",
            "[Step 36800/50000] [Progress: 73.60%] [learning rate: 5.2e+03]\n",
            "[Step 36823/50000] [Time: 309s] [Train Loss: 1.66e-01] [Train Acc: 0.97]\n",
            "[Step 36826/50000] [Progress: 73.65%] [learning rate: 5.1e+03]\n",
            "[Step 36851/50000] [Progress: 73.70%] [learning rate: 5.5e+03]\n",
            "[Step 36875/50000] [Progress: 73.75%] [learning rate: 5.4e+03]\n",
            "[Step 36900/50000] [Progress: 73.80%] [learning rate: 5.4e+03]\n",
            "[Step 36921/50000] [Time: 310s] [Train Loss: 1.65e-01] [Train Acc: 0.97]\n",
            "[Step 36924/50000] [Progress: 73.85%] [learning rate: 5.3e+03]\n",
            "[Step 36949/50000] [Progress: 73.90%] [learning rate: 5.2e+03]\n",
            "[Step 36975/50000] [Progress: 73.95%] [learning rate: 5.6e+03]\n",
            "[Step 36998/50000] [Progress: 74.00%] [learning rate: 5.1e+03]\n",
            "[Step 37019/50000] [Time: 310s] [Train Loss: 1.65e-01] [Train Acc: 0.97]\n",
            "[Step 37024/50000] [Progress: 74.05%] [learning rate: 6.0e+03]\n",
            "[Step 37047/50000] [Progress: 74.09%] [learning rate: 4.9e+03]\n",
            "[Step 37073/50000] [Progress: 74.15%] [learning rate: 5.3e+03]\n",
            "[Step 37097/50000] [Progress: 74.19%] [learning rate: 5.2e+03]\n",
            "[Step 37117/50000] [Time: 311s] [Train Loss: 1.65e-01] [Train Acc: 0.97]\n",
            "[Step 37122/50000] [Progress: 74.24%] [learning rate: 5.2e+03]\n",
            "[Step 37147/50000] [Progress: 74.29%] [learning rate: 5.1e+03]\n",
            "[Step 37173/50000] [Progress: 74.35%] [learning rate: 5.5e+03]\n",
            "[Step 37200/50000] [Progress: 74.40%] [learning rate: 6.0e+03]\n",
            "[Step 37215/50000] [Time: 312s] [Train Loss: 1.64e-01] [Train Acc: 0.97]\n",
            "[Step 37224/50000] [Progress: 74.45%] [learning rate: 5.3e+03]\n",
            "[Step 37249/50000] [Progress: 74.50%] [learning rate: 5.3e+03]\n",
            "[Step 37275/50000] [Progress: 74.55%] [learning rate: 5.2e+03]\n",
            "[Step 37300/50000] [Progress: 74.60%] [learning rate: 5.1e+03]\n",
            "[Step 37313/50000] [Time: 313s] [Train Loss: 1.64e-01] [Train Acc: 0.97]\n",
            "[Step 37325/50000] [Progress: 74.65%] [learning rate: 5.5e+03]\n",
            "[Step 37351/50000] [Progress: 74.70%] [learning rate: 6.0e+03]\n",
            "[Step 37375/50000] [Progress: 74.75%] [learning rate: 5.4e+03]\n",
            "[Step 37400/50000] [Progress: 74.80%] [learning rate: 5.3e+03]\n",
            "[Step 37411/50000] [Time: 313s] [Train Loss: 1.64e-01] [Train Acc: 0.97]\n",
            "[Step 37426/50000] [Progress: 74.85%] [learning rate: 5.7e+03]\n",
            "[Step 37449/50000] [Progress: 74.90%] [learning rate: 5.1e+03]\n",
            "[Step 37475/50000] [Progress: 74.95%] [learning rate: 5.5e+03]\n",
            "[Step 37501/50000] [Progress: 75.00%] [learning rate: 6.0e+03]\n",
            "[Step 37509/50000] [Time: 314s] [Train Loss: 1.63e-01] [Train Acc: 0.97]\n",
            "[Step 37524/50000] [Progress: 75.05%] [learning rate: 4.9e+03]\n",
            "[Step 37551/50000] [Progress: 75.10%] [learning rate: 5.8e+03]\n",
            "[Step 37574/50000] [Progress: 75.15%] [learning rate: 4.7e+03]\n",
            "[Step 37600/50000] [Progress: 75.20%] [learning rate: 5.7e+03]\n",
            "[Step 37607/50000] [Time: 315s] [Train Loss: 1.63e-01] [Train Acc: 0.97]\n",
            "[Step 37624/50000] [Progress: 75.25%] [learning rate: 5.1e+03]\n",
            "[Step 37650/50000] [Progress: 75.30%] [learning rate: 6.0e+03]\n",
            "[Step 37673/50000] [Progress: 75.35%] [learning rate: 4.9e+03]\n",
            "[Step 37700/50000] [Progress: 75.40%] [learning rate: 5.9e+03]\n",
            "[Step 37705/50000] [Time: 316s] [Train Loss: 1.63e-01] [Train Acc: 0.97]\n",
            "[Step 37723/50000] [Progress: 75.45%] [learning rate: 4.8e+03]\n",
            "[Step 37749/50000] [Progress: 75.50%] [learning rate: 5.7e+03]\n",
            "[Step 37773/50000] [Progress: 75.55%] [learning rate: 5.1e+03]\n",
            "[Step 37800/50000] [Progress: 75.60%] [learning rate: 6.1e+03]\n",
            "[Step 37803/50000] [Time: 317s] [Train Loss: 1.63e-01] [Train Acc: 0.97]\n",
            "[Step 37823/50000] [Progress: 75.65%] [learning rate: 5.4e+03]\n",
            "[Step 37847/50000] [Progress: 75.69%] [learning rate: 5.3e+03]\n",
            "[Step 37872/50000] [Progress: 75.74%] [learning rate: 5.3e+03]\n",
            "[Step 37898/50000] [Progress: 75.80%] [learning rate: 5.7e+03]\n",
            "[Step 37901/50000] [Time: 317s] [Train Loss: 1.62e-01] [Train Acc: 0.97]\n",
            "[Step 37922/50000] [Progress: 75.84%] [learning rate: 5.1e+03]\n",
            "[Step 37949/50000] [Progress: 75.90%] [learning rate: 6.1e+03]\n",
            "[Step 37972/50000] [Progress: 75.94%] [learning rate: 5.0e+03]\n",
            "[Step 37998/50000] [Progress: 76.00%] [learning rate: 5.4e+03]\n",
            "[Step 37999/50000] [Time: 318s] [Train Loss: 1.62e-01] [Train Acc: 0.97]\n",
            "[Step 38022/50000] [Progress: 76.04%] [learning rate: 5.3e+03]\n",
            "[Step 38047/50000] [Progress: 76.09%] [learning rate: 5.2e+03]\n",
            "[Step 38072/50000] [Progress: 76.14%] [learning rate: 5.1e+03]\n",
            "[Step 38097/50000] [Time: 319s] [Train Loss: 1.62e-01] [Train Acc: 0.97]\n",
            "[Step 38098/50000] [Progress: 76.20%] [learning rate: 5.6e+03]\n",
            "[Step 38125/50000] [Progress: 76.25%] [learning rate: 6.0e+03]\n",
            "[Step 38149/50000] [Progress: 76.30%] [learning rate: 5.4e+03]\n",
            "[Step 38174/50000] [Progress: 76.35%] [learning rate: 5.3e+03]\n",
            "[Step 38195/50000] [Time: 319s] [Train Loss: 1.61e-01] [Train Acc: 0.97]\n",
            "[Step 38200/50000] [Progress: 76.40%] [learning rate: 5.2e+03]\n",
            "[Step 38225/50000] [Progress: 76.45%] [learning rate: 5.2e+03]\n",
            "[Step 38252/50000] [Progress: 76.50%] [learning rate: 5.6e+03]\n",
            "[Step 38278/50000] [Progress: 76.56%] [learning rate: 6.1e+03]\n",
            "[Step 38293/50000] [Time: 320s] [Train Loss: 1.61e-01] [Train Acc: 0.97]\n",
            "[Step 38302/50000] [Progress: 76.60%] [learning rate: 5.4e+03]\n",
            "[Step 38327/50000] [Progress: 76.65%] [learning rate: 5.3e+03]\n",
            "[Step 38353/50000] [Progress: 76.71%] [learning rate: 5.3e+03]\n",
            "[Step 38378/50000] [Progress: 76.76%] [learning rate: 5.2e+03]\n",
            "[Step 38391/50000] [Time: 321s] [Train Loss: 1.61e-01] [Train Acc: 0.97]\n",
            "[Step 38405/50000] [Progress: 76.81%] [learning rate: 5.6e+03]\n",
            "[Step 38430/50000] [Progress: 76.86%] [learning rate: 5.5e+03]\n",
            "[Step 38456/50000] [Progress: 76.91%] [learning rate: 5.4e+03]\n",
            "[Step 38480/50000] [Progress: 76.96%] [learning rate: 5.4e+03]\n",
            "[Step 38489/50000] [Time: 322s] [Train Loss: 1.61e-01] [Train Acc: 0.97] [Eval Loss: 5.19e-01] [Eval Acc: 0.77]\n",
            "[Step 38505/50000] [Progress: 77.01%] [learning rate: 5.3e+03]\n",
            "[Step 38531/50000] [Progress: 77.06%] [learning rate: 5.7e+03]\n",
            "[Step 38555/50000] [Progress: 77.11%] [learning rate: 5.1e+03]\n",
            "[Step 38581/50000] [Progress: 77.16%] [learning rate: 6.1e+03]\n",
            "[Step 38587/50000] [Time: 324s] [Train Loss: 1.60e-01] [Train Acc: 0.97]\n",
            "[Step 38604/50000] [Progress: 77.21%] [learning rate: 5.0e+03]\n",
            "[Step 38631/50000] [Progress: 77.26%] [learning rate: 5.9e+03]\n",
            "[Step 38654/50000] [Progress: 77.31%] [learning rate: 4.8e+03]\n",
            "[Step 38680/50000] [Progress: 77.36%] [learning rate: 5.7e+03]\n",
            "[Step 38685/50000] [Time: 325s] [Train Loss: 1.60e-01] [Train Acc: 0.97]\n",
            "[Step 38704/50000] [Progress: 77.41%] [learning rate: 5.1e+03]\n",
            "[Step 38731/50000] [Progress: 77.46%] [learning rate: 6.1e+03]\n",
            "[Step 38754/50000] [Progress: 77.51%] [learning rate: 5.5e+03]\n",
            "[Step 38778/50000] [Progress: 77.56%] [learning rate: 5.4e+03]\n",
            "[Step 38783/50000] [Time: 325s] [Train Loss: 1.60e-01] [Train Acc: 0.97]\n",
            "[Step 38803/50000] [Progress: 77.61%] [learning rate: 5.3e+03]\n",
            "[Step 38829/50000] [Progress: 77.66%] [learning rate: 5.8e+03]\n",
            "[Step 38853/50000] [Progress: 77.71%] [learning rate: 5.2e+03]\n",
            "[Step 38880/50000] [Progress: 77.76%] [learning rate: 6.2e+03]\n",
            "[Step 38881/50000] [Time: 326s] [Train Loss: 1.59e-01] [Train Acc: 0.97]\n",
            "[Step 38903/50000] [Progress: 77.81%] [learning rate: 5.0e+03]\n",
            "[Step 38929/50000] [Progress: 77.86%] [learning rate: 5.4e+03]\n",
            "[Step 38953/50000] [Progress: 77.91%] [learning rate: 5.4e+03]\n",
            "[Step 38978/50000] [Progress: 77.96%] [learning rate: 5.3e+03]\n",
            "[Step 38979/50000] [Time: 327s] [Train Loss: 1.59e-01] [Train Acc: 0.97]\n",
            "[Step 39003/50000] [Progress: 78.01%] [learning rate: 5.2e+03]\n",
            "[Step 39029/50000] [Progress: 78.06%] [learning rate: 5.6e+03]\n",
            "[Step 39056/50000] [Progress: 78.11%] [learning rate: 6.1e+03]\n",
            "[Step 39077/50000] [Time: 328s] [Train Loss: 1.59e-01] [Train Acc: 0.97]\n",
            "[Step 39080/50000] [Progress: 78.16%] [learning rate: 5.5e+03]\n",
            "[Step 39105/50000] [Progress: 78.21%] [learning rate: 5.4e+03]\n",
            "[Step 39131/50000] [Progress: 78.26%] [learning rate: 5.3e+03]\n",
            "[Step 39158/50000] [Progress: 78.32%] [learning rate: 5.7e+03]\n",
            "[Step 39175/50000] [Time: 329s] [Train Loss: 1.59e-01] [Train Acc: 0.97]\n",
            "[Step 39183/50000] [Progress: 78.37%] [learning rate: 5.7e+03]\n",
            "[Step 39209/50000] [Progress: 78.42%] [learning rate: 6.1e+03]\n",
            "[Step 39231/50000] [Progress: 78.46%] [learning rate: 5.0e+03]\n",
            "[Step 39257/50000] [Progress: 78.51%] [learning rate: 5.9e+03]\n",
            "[Step 39274/50000] [Time: 329s] [Train Loss: 1.58e-01] [Train Acc: 0.97]\n",
            "[Step 39280/50000] [Progress: 78.56%] [learning rate: 5.3e+03]\n",
            "[Step 39305/50000] [Progress: 78.61%] [learning rate: 5.2e+03]\n",
            "[Step 39330/50000] [Progress: 78.66%] [learning rate: 5.7e+03]\n",
            "[Step 39355/50000] [Progress: 78.71%] [learning rate: 6.2e+03]\n",
            "[Step 39373/50000] [Time: 330s] [Train Loss: 1.58e-01] [Train Acc: 0.97]\n",
            "[Step 39378/50000] [Progress: 78.76%] [learning rate: 5.0e+03]\n",
            "[Step 39405/50000] [Progress: 78.81%] [learning rate: 6.0e+03]\n",
            "[Step 39428/50000] [Progress: 78.86%] [learning rate: 4.9e+03]\n",
            "[Step 39455/50000] [Progress: 78.91%] [learning rate: 5.8e+03]\n",
            "[Step 39472/50000] [Time: 331s] [Train Loss: 1.58e-01] [Train Acc: 0.97]\n",
            "[Step 39480/50000] [Progress: 78.96%] [learning rate: 5.2e+03]\n",
            "[Step 39506/50000] [Progress: 79.01%] [learning rate: 6.2e+03]\n",
            "[Step 39529/50000] [Progress: 79.06%] [learning rate: 5.0e+03]\n",
            "[Step 39556/50000] [Progress: 79.11%] [learning rate: 6.0e+03]\n",
            "[Step 39571/50000] [Time: 332s] [Train Loss: 1.57e-01] [Train Acc: 0.97]\n",
            "[Step 39579/50000] [Progress: 79.16%] [learning rate: 4.9e+03]\n",
            "[Step 39605/50000] [Progress: 79.21%] [learning rate: 5.8e+03]\n",
            "[Step 39629/50000] [Progress: 79.26%] [learning rate: 5.2e+03]\n",
            "[Step 39656/50000] [Progress: 79.31%] [learning rate: 6.2e+03]\n",
            "[Step 39670/50000] [Time: 332s] [Train Loss: 1.57e-01] [Train Acc: 0.97]\n",
            "[Step 39679/50000] [Progress: 79.36%] [learning rate: 5.6e+03]\n",
            "[Step 39703/50000] [Progress: 79.41%] [learning rate: 5.5e+03]\n",
            "[Step 39728/50000] [Progress: 79.46%] [learning rate: 5.4e+03]\n",
            "[Step 39754/50000] [Progress: 79.51%] [learning rate: 5.8e+03]\n",
            "[Step 39769/50000] [Time: 333s] [Train Loss: 1.57e-01] [Train Acc: 0.97]\n",
            "[Step 39778/50000] [Progress: 79.56%] [learning rate: 5.2e+03]\n",
            "[Step 39805/50000] [Progress: 79.61%] [learning rate: 6.2e+03]\n",
            "[Step 39828/50000] [Progress: 79.66%] [learning rate: 5.1e+03]\n",
            "[Step 39854/50000] [Progress: 79.71%] [learning rate: 5.5e+03]\n",
            "[Step 39868/50000] [Time: 334s] [Train Loss: 1.57e-01] [Train Acc: 0.97]\n",
            "[Step 39878/50000] [Progress: 79.76%] [learning rate: 5.4e+03]\n",
            "[Step 39903/50000] [Progress: 79.81%] [learning rate: 5.3e+03]\n",
            "[Step 39928/50000] [Progress: 79.86%] [learning rate: 5.3e+03]\n",
            "[Step 39954/50000] [Progress: 79.91%] [learning rate: 5.7e+03]\n",
            "[Step 39967/50000] [Time: 335s] [Train Loss: 1.56e-01] [Train Acc: 0.97]\n",
            "[Step 39981/50000] [Progress: 79.96%] [learning rate: 6.2e+03]\n",
            "[Step 40005/50000] [Progress: 80.01%] [learning rate: 5.5e+03]\n",
            "[Step 40030/50000] [Progress: 80.06%] [learning rate: 5.4e+03]\n",
            "[Step 40056/50000] [Progress: 80.11%] [learning rate: 5.4e+03]\n",
            "[Step 40066/50000] [Time: 336s] [Train Loss: 1.56e-01] [Train Acc: 0.97]\n",
            "[Step 40081/50000] [Progress: 80.16%] [learning rate: 5.3e+03]\n",
            "[Step 40108/50000] [Progress: 80.22%] [learning rate: 5.7e+03]\n",
            "[Step 40134/50000] [Progress: 80.27%] [learning rate: 6.2e+03]\n",
            "[Step 40158/50000] [Progress: 80.32%] [learning rate: 5.5e+03]\n",
            "[Step 40165/50000] [Time: 336s] [Train Loss: 1.56e-01] [Train Acc: 0.97]\n",
            "[Step 40183/50000] [Progress: 80.37%] [learning rate: 5.5e+03]\n",
            "[Step 40209/50000] [Progress: 80.42%] [learning rate: 5.4e+03]\n",
            "[Step 40234/50000] [Progress: 80.47%] [learning rate: 5.3e+03]\n",
            "[Step 40261/50000] [Progress: 80.52%] [learning rate: 5.7e+03]\n",
            "[Step 40264/50000] [Time: 337s] [Train Loss: 1.55e-01] [Train Acc: 0.97]\n",
            "[Step 40286/50000] [Progress: 80.57%] [learning rate: 5.7e+03]\n",
            "[Step 40312/50000] [Progress: 80.62%] [learning rate: 5.6e+03]\n",
            "[Step 40336/50000] [Progress: 80.67%] [learning rate: 5.5e+03]\n",
            "[Step 40361/50000] [Progress: 80.72%] [learning rate: 5.4e+03]\n",
            "[Step 40363/50000] [Time: 338s] [Train Loss: 1.55e-01] [Train Acc: 0.97]\n",
            "[Step 40387/50000] [Progress: 80.77%] [learning rate: 5.9e+03]\n",
            "[Step 40411/50000] [Progress: 80.82%] [learning rate: 5.2e+03]\n",
            "[Step 40439/50000] [Progress: 80.88%] [learning rate: 6.3e+03]\n",
            "[Step 40462/50000] [Time: 338s] [Train Loss: 1.55e-01] [Train Acc: 0.97]\n",
            "[Step 40463/50000] [Progress: 80.93%] [learning rate: 5.6e+03]\n",
            "[Step 40488/50000] [Progress: 80.98%] [learning rate: 5.5e+03]\n",
            "[Step 40514/50000] [Progress: 81.03%] [learning rate: 5.4e+03]\n",
            "[Step 40539/50000] [Progress: 81.08%] [learning rate: 5.3e+03]\n",
            "[Step 40561/50000] [Time: 339s] [Train Loss: 1.55e-01] [Train Acc: 0.97]\n",
            "[Step 40566/50000] [Progress: 81.13%] [learning rate: 5.8e+03]\n",
            "[Step 40592/50000] [Progress: 81.18%] [learning rate: 5.7e+03]\n",
            "[Step 40618/50000] [Progress: 81.24%] [learning rate: 6.2e+03]\n",
            "[Step 40641/50000] [Progress: 81.28%] [learning rate: 5.0e+03]\n",
            "[Step 40660/50000] [Time: 340s] [Train Loss: 1.54e-01] [Train Acc: 0.97]\n",
            "[Step 40668/50000] [Progress: 81.34%] [learning rate: 6.0e+03]\n",
            "[Step 40691/50000] [Progress: 81.38%] [learning rate: 5.4e+03]\n",
            "[Step 40716/50000] [Progress: 81.43%] [learning rate: 5.8e+03]\n",
            "[Step 40740/50000] [Progress: 81.48%] [learning rate: 5.7e+03]\n",
            "[Step 40759/50000] [Time: 341s] [Train Loss: 1.54e-01] [Train Acc: 0.97]\n",
            "[Step 40765/50000] [Progress: 81.53%] [learning rate: 6.2e+03]\n",
            "[Step 40788/50000] [Progress: 81.58%] [learning rate: 5.1e+03]\n",
            "[Step 40815/50000] [Progress: 81.63%] [learning rate: 6.0e+03]\n",
            "[Step 40838/50000] [Progress: 81.68%] [learning rate: 4.9e+03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "def load_results(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        data = torch.load(f, weights_only=False)\n",
        "    args = data.get('args', None)\n",
        "    results = data.get('results', None)\n",
        "\n",
        "    if results is None:\n",
        "        print(f\"No results found in {filename}\")\n",
        "        return None, None\n",
        "\n",
        "    if 'init_kernel' in results:\n",
        "        dynamics = results['init_kernel'].get('dynamics', [])\n",
        "        final_results = results['init_kernel']\n",
        "    else:\n",
        "        print(f\"No 'init_kernel' key found in {filename}\")\n",
        "        return None, None\n",
        "\n",
        "    return args, final_results, dynamics\n",
        "\n",
        "def plot_training_results(args, dynamics):\n",
        "    if args is None or dynamics is None:\n",
        "        print(\"No data to plot.\")\n",
        "        return\n",
        "\n",
        "    steps = [state['step'] for state in dynamics]\n",
        "    train_losses = [state['train']['loss'] for state in dynamics]\n",
        "    train_accuracies = [state['train']['accuracy'] for state in dynamics]\n",
        "\n",
        "    plt.figure(figsize=(9, 5))\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(steps, train_losses, label='Train Loss', color='blue')\n",
        "    if args.track_test_metrics:\n",
        "        test_steps = [state['step'] for state in dynamics if state['test']['loss'] is not None]\n",
        "        test_losses = [state['test']['loss'] for state in dynamics if state['test']['loss'] is not None]\n",
        "        plt.plot(test_steps, test_losses, label='Test Loss', color='red')\n",
        "    plt.xlabel('Step')\n",
        "    # plt.xscale('log')\n",
        "    plt.yscale('log')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(steps, train_accuracies, label='Train Accuracy', color='blue')\n",
        "    if args.track_test_metrics:\n",
        "        test_steps = [state['step'] for state in dynamics if state['test']['accuracy'] is not None]\n",
        "        test_accuracies = [state['test']['accuracy'] for state in dynamics if state['test']['accuracy'] is not None]\n",
        "        plt.plot(test_steps, test_accuracies, label='Test Accuracy', color='red')\n",
        "    plt.xlabel('Step')\n",
        "    # plt.xscale('log')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# テストとトレーニングの出力とラベルの最初の100個を表示する関数\n",
        "def print_outputs_labels(final_results, num_samples=100):\n",
        "    # Training data display\n",
        "    if final_results is None or 'train' not in final_results:\n",
        "        print(\"No train results found in the final results.\")\n",
        "    else:\n",
        "        train_outputs = final_results['train']['outputs']\n",
        "        train_labels = final_results['train']['labels']\n",
        "\n",
        "        if train_outputs is not None and train_labels is not None:\n",
        "            print(f\"\\nFirst {num_samples} Train Outputs:\")\n",
        "            print(train_outputs[:num_samples])\n",
        "\n",
        "            print(f\"\\nFirst {num_samples} Train Labels:\")\n",
        "            print(train_labels[:num_samples])\n",
        "        else:\n",
        "            print(\"Train outputs or labels not found.\")\n",
        "\n",
        "    # Test data display\n",
        "    if final_results is None or 'test' not in final_results:\n",
        "        print(\"No test results found in the final results.\")\n",
        "    else:\n",
        "        test_outputs = final_results['test']['outputs']\n",
        "        test_labels = final_results['test']['labels']\n",
        "\n",
        "        if test_outputs is not None and test_labels is not None:\n",
        "            print(f\"\\nFirst {num_samples} Test Outputs:\")\n",
        "            print(test_outputs[:num_samples])\n",
        "\n",
        "            print(f\"\\nFirst {num_samples} Test Labels:\")\n",
        "            print(test_labels[:num_samples])\n",
        "        else:\n",
        "            print(\"Test outputs or labels not found.\")\n",
        "\n",
        "filename = 'results.pkl'\n",
        "args, final_results, dynamics = load_results(filename)\n",
        "\n",
        "\n",
        "plot_training_results(args, dynamics)\n",
        "\n",
        "# トレーニングとテスト出力とラベルの最初の100個を表示\n",
        "print_outputs_labels(final_results, num_samples=100)\n",
        "\n",
        "\n",
        "# Calculate and display final test accuracy\n",
        "if final_results is not None and 'test' in final_results:\n",
        "    test_outputs = final_results['test']['outputs']\n",
        "    test_labels = final_results['test']['labels']\n",
        "    if test_outputs is not None and test_labels is not None:\n",
        "        test_preds = torch.sigmoid(test_outputs) > 0.5\n",
        "        test_accuracy = (test_preds.int() == test_labels.int()).float().mean().item()\n",
        "        print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n",
        "    else:\n",
        "        print(\"Test outputs or labels not found.\")\n",
        "else:\n",
        "    print(\"No test results found in the final results.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "busmySOVucH0",
        "outputId": "d2ee45c9-938d-4af1-ba7a-9b738a4a1161"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First 100 Train Outputs:\n",
            "tensor([ 4.3608,  3.0876, -3.6204,  4.7701,  1.6177, -2.3560, -1.6627, -0.6476,\n",
            "        -0.0862,  2.9219,  4.1155,  6.1505,  2.0947, -2.9837, -1.6973,  0.8027,\n",
            "        -3.3366,  3.1938, -1.4903,  3.4511,  1.9733, -7.1531,  5.9211,  4.3814,\n",
            "        -1.3333,  1.5393,  6.8501,  5.3228,  2.6696,  3.4502,  3.3537, -5.0362,\n",
            "         2.2694,  1.6062, -2.4426,  1.8086,  4.8716, -3.3782,  1.4697,  1.5617,\n",
            "        -2.2715,  2.3956, -2.0794, -1.6324, -5.6512, -2.5626,  5.5744,  0.1727,\n",
            "        -5.0574,  6.7551, -4.1601, -0.0989, -5.2585,  4.5904, -2.9573,  1.6531,\n",
            "         1.7166, -0.3993,  2.7776, -3.6832, -0.1788, -1.7351,  1.9970,  5.2168,\n",
            "        -3.5106, -4.4169,  6.4136, -1.7332, -8.5486,  0.7694, -4.8700,  8.1185,\n",
            "         2.1177,  3.5342,  1.4491,  0.2521,  4.4976,  7.3665,  2.6435,  2.3864,\n",
            "        -4.7190,  3.7756,  2.6326,  2.1277,  2.9645,  4.5208, -5.1278,  3.5505,\n",
            "         5.3586, -6.6160,  3.7203,  4.8991,  6.6004, -3.1968,  6.1535, -2.2456,\n",
            "        -1.8547, -0.8579,  3.1523, -6.3581])\n",
            "\n",
            "First 100 Train Labels:\n",
            "tensor([1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
            "        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
            "        1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
            "        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
            "        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
            "        1., 1., 1., 0., 1., 0., 0., 0., 1., 0.])\n",
            "\n",
            "First 100 Test Outputs:\n",
            "tensor([ 0.4864,  1.5325, -7.8903, -1.8447, -1.9054, -3.2085, -1.4838,  2.5991,\n",
            "         2.8214, -1.8870, -4.4383,  1.1636,  2.6992,  6.7939,  4.9027,  4.6564,\n",
            "         4.3060,  2.0350,  5.0581, -3.8775, -0.0544,  0.9139,  1.0828, -4.8313,\n",
            "        -1.4606, -0.3445, -3.9115, -0.6122, -1.3524,  3.8292,  4.1445, -1.7646,\n",
            "         6.7597,  1.3923,  1.3520,  2.9589,  2.1256, -5.6783, -2.4122, -1.3124,\n",
            "         6.4886, -1.5440,  7.3454,  5.0420,  2.7052,  4.6265,  0.2346,  3.2671,\n",
            "         2.5553,  2.7259, -0.0801,  1.2950,  3.9679,  4.1274, -5.6791,  5.3617,\n",
            "        -4.8908,  1.9402, -1.2276,  2.0081,  3.9700, -1.7448, -5.5141,  7.3647,\n",
            "         0.1492,  0.9947,  1.3893,  0.0692,  3.4807, -0.8419,  1.5442, -0.6486,\n",
            "         0.8674,  0.4439,  5.7843,  2.6664,  3.2780,  2.9794,  1.9543,  0.0697,\n",
            "        -0.3106,  4.8821, -0.3949,  4.8861,  0.4193, -1.0347,  2.1591, -0.8132,\n",
            "        -2.3337,  4.0226,  1.8874,  4.0696,  4.5837,  3.3260,  1.5470, -3.1695,\n",
            "        -0.5486,  0.5326,  0.3307,  4.2177])\n",
            "\n",
            "First 100 Test Labels:\n",
            "tensor([1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
            "        1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
            "        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
            "        1., 1., 1., 1., 0., 0., 0., 1., 0., 1.])\n",
            "Final Test Accuracy: 0.7689\n"
          ]
        }
      ]
    }
  ]
}