{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCHDjoF9zn4lBiFq7wcEYC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kodai-utsunomiya/memorization-and-generalization/blob/main/numerical_experiments/exp_3/exp_3_v5_frozen_ntk_dynamics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class BinaryDataset:\n",
        "    def __init__(self, n, k, train_size, test_size, data_seed, normalize=False, device=None):\n",
        "        self.n = n\n",
        "        self.k = k\n",
        "        self.train_size = train_size\n",
        "        self.test_size = test_size\n",
        "        self.data_seed = data_seed\n",
        "        self.normalize = normalize\n",
        "        self.device = device\n",
        "\n",
        "        (self.train_inputs, self.train_outputs), (self.test_inputs, self.test_outputs) = self._prepare_data()\n",
        "\n",
        "    def _prepare_data(self):\n",
        "        np.random.seed(self.data_seed)\n",
        "        total_size = self.train_size + self.test_size\n",
        "\n",
        "        binary_strings = {tuple(np.random.randint(2, size=self.n)) for _ in range(total_size)}\n",
        "        while len(binary_strings) < total_size:\n",
        "            binary_strings.add(tuple(np.random.randint(2, size=self.n)))\n",
        "\n",
        "        binary_strings = list(binary_strings)\n",
        "        inputs = np.array(binary_strings, dtype=np.float32)\n",
        "        outputs = np.sum(inputs[:, :self.k], axis=-1) % 2\n",
        "\n",
        "        # # 出力ラベルを 0 -> -1, 1 -> 1 に変換（ヒンジ損失用）\n",
        "        # outputs = 2 * outputs - 1\n",
        "\n",
        "        # データの正規化を行う場合\n",
        "        if self.normalize:\n",
        "            inputs = (inputs - inputs.mean(axis=0))\n",
        "            norm = np.linalg.norm(inputs, axis=1, keepdims=True)\n",
        "            inputs = (inputs / np.maximum(norm, 1e-8))  # ゼロ除算防止\n",
        "\n",
        "        indices = np.random.permutation(total_size)\n",
        "        train_indices, test_indices = indices[:self.train_size], indices[self.train_size:]\n",
        "\n",
        "        train_inputs = torch.tensor(inputs[train_indices], dtype=torch.float32).to(self.device)\n",
        "        train_outputs = torch.tensor(outputs[train_indices], dtype=torch.float32).to(self.device)\n",
        "        test_inputs = torch.tensor(inputs[test_indices], dtype=torch.float32).to(self.device)\n",
        "        test_outputs = torch.tensor(outputs[test_indices], dtype=torch.float32).to(self.device)\n",
        "\n",
        "        return (train_inputs, train_outputs), (test_inputs, test_outputs)\n",
        "\n",
        "    def get_data(self):\n",
        "        return (self.train_inputs, self.train_outputs), (self.test_inputs, self.test_outputs)\n",
        "\n",
        "\n",
        "###################################################################\n",
        "\n",
        "import functools\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FC(nn.Module):\n",
        "    def __init__(self, d, h, L, act, bias=False):\n",
        "        super().__init__()\n",
        "\n",
        "        hh = d\n",
        "        for i in range(L):\n",
        "            W = torch.randn(h, hh)\n",
        "\n",
        "            n = max(1, 128 * 256 // hh)\n",
        "            W = nn.ParameterList([nn.Parameter(W[j: j+n]) for j in range(0, len(W), n)])\n",
        "\n",
        "            setattr(self, \"W{}\".format(i), W)\n",
        "            if bias:\n",
        "                self.register_parameter(\"B{}\".format(i), nn.Parameter(torch.zeros(h)))\n",
        "            hh = h\n",
        "\n",
        "        self.register_parameter(\"W{}\".format(L), nn.Parameter(torch.randn(1, hh)))\n",
        "        if bias:\n",
        "            self.register_parameter(\"B{}\".format(L), nn.Parameter(torch.zeros(1)))\n",
        "\n",
        "        self.L = L\n",
        "        self.act = act\n",
        "        self.bias = bias\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(self.L + 1):\n",
        "            W = getattr(self, \"W{}\".format(i))\n",
        "\n",
        "            if isinstance(W, nn.ParameterList):\n",
        "                W = torch.cat(list(W))\n",
        "\n",
        "            if self.bias:\n",
        "                B = self.bias * getattr(self, \"B{}\".format(i))\n",
        "            else:\n",
        "                B = 0\n",
        "\n",
        "            h = x.size(1)\n",
        "\n",
        "            if i < self.L:\n",
        "                x = x @ (W.t() / h ** 0.5)\n",
        "                x = self.act(x + B)\n",
        "            else:\n",
        "                x = x @ (W.t() / h ** 0.5) + B\n",
        "\n",
        "        return x.view(-1)\n",
        "\n",
        "#################################################################################\n",
        "def gradient(outputs, inputs, grad_outputs=None, retain_graph=None, create_graph=False):\n",
        "    r'''\n",
        "    Compute the gradient of `outputs` with respect to `inputs`\n",
        "    ```\n",
        "    gradient(x.sum(), x)\n",
        "    gradient((x * y).sum(), [x, y])\n",
        "    ```\n",
        "    '''\n",
        "    if torch.is_tensor(inputs):\n",
        "        inputs = [inputs]\n",
        "    else:\n",
        "        inputs = list(inputs)\n",
        "    grads = torch.autograd.grad(outputs, inputs, grad_outputs,\n",
        "                                allow_unused=True,\n",
        "                                retain_graph=retain_graph,\n",
        "                                create_graph=create_graph)\n",
        "    grads = [x if x is not None else torch.zeros_like(y) for x, y in zip(grads, inputs)]\n",
        "    return torch.cat([x.contiguous().view(-1) for x in grads])\n",
        "\n",
        "########################################################################################\n",
        "def compute_kernels(f, xtr, xte):\n",
        "\n",
        "    ktrtr = xtr.new_zeros(len(xtr), len(xtr))\n",
        "    ktetr = xtr.new_zeros(len(xte), len(xtr))\n",
        "    ktete = xtr.new_zeros(len(xte), len(xte))\n",
        "\n",
        "    params = []\n",
        "    current = []\n",
        "    for p in sorted(f.parameters(), key=lambda p: p.numel(), reverse=True):\n",
        "        current.append(p)\n",
        "        if sum(p.numel() for p in current) > 2e9 // (8 * (len(xtr) + len(xte))):\n",
        "            if len(current) > 1:\n",
        "                params.append(current[:-1])\n",
        "                current = current[-1:]\n",
        "            else:\n",
        "                params.append(current)\n",
        "                current = []\n",
        "    if len(current) > 0:\n",
        "        params.append(current)\n",
        "\n",
        "    for i, p in enumerate(params):\n",
        "        print(\"[{}/{}] [len={} numel={}]\".format(i, len(params), len(p), sum(x.numel() for x in p)), flush=True)\n",
        "\n",
        "        jtr = xtr.new_empty(len(xtr), sum(u.numel() for u in p))  # (P, N~)\n",
        "        jte = xte.new_empty(len(xte), sum(u.numel() for u in p))  # (P, N~)\n",
        "\n",
        "        for j, x in enumerate(xtr):\n",
        "            jtr[j] = gradient(f(x[None]), p)  # (N~)\n",
        "\n",
        "        for j, x in enumerate(xte):\n",
        "            jte[j] = gradient(f(x[None]), p)  # (N~)\n",
        "\n",
        "        ktrtr.add_(jtr @ jtr.t())\n",
        "        ktetr.add_(jte @ jtr.t())\n",
        "        ktete.add_(jte @ jte.t())\n",
        "        del jtr, jte\n",
        "\n",
        "    return ktrtr, ktetr, ktete"
      ],
      "metadata": {
        "id": "vNMYzp4WJ1uv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frozen NTK dynamics"
      ],
      "metadata": {
        "id": "R3WTZB4qy6xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import itertools\n",
        "import math\n",
        "from time import perf_counter\n",
        "\n",
        "def loglinspace(rate, step, end=None):\n",
        "    t = 0\n",
        "    while end is None or t <= end:\n",
        "        yield t\n",
        "        t = int(t + 1 + step * (1 - math.exp(-t * rate / step)))\n",
        "\n",
        "def train_kernel(args, ktrtr, ytr, tau, max_walltime, alpha, learning_rate, loss_prim, max_dgrad=math.inf, max_dout=math.inf):\n",
        "    # 初期化\n",
        "    otr = torch.zeros(len(ytr), dtype=ktrtr.dtype, device=ktrtr.device)\n",
        "    gradient_update = torch.clone(otr)\n",
        "\n",
        "    last_lr_change_step = 0  # 最後に学習率が変更されたステップ\n",
        "\n",
        "    checkpoint_generator = loglinspace(0.01, 100)\n",
        "    checkpoint = next(checkpoint_generator)  # 最初のチェックポイント\n",
        "    start_time = perf_counter()  # 経過時間計測の開始\n",
        "    converged = False\n",
        "\n",
        "    # 初期の損失関数の勾配を計算\n",
        "    lprim = loss_prim(otr, ytr)\n",
        "    grad = ktrtr @ lprim / len(ytr)\n",
        "\n",
        "    # メインループ\n",
        "    for step in itertools.count():\n",
        "        if step >= args.max_step:\n",
        "            break\n",
        "\n",
        "        # 現在の状態を保存\n",
        "        state = copy.deepcopy((otr, gradient_update))\n",
        "\n",
        "        while True:\n",
        "            gradient_update = -grad.clone()\n",
        "\n",
        "            # 出力を更新\n",
        "            otr = otr + learning_rate * gradient_update\n",
        "\n",
        "            # 新しい勾配を計算\n",
        "            lprim = loss_prim(otr, ytr)\n",
        "            new_grad = ktrtr @ lprim / len(ytr)\n",
        "\n",
        "            # 出力変化量 (dout) の計算\n",
        "            dout = (learning_rate * alpha * gradient_update).abs().max().item()\n",
        "\n",
        "            # 勾配の変化量 (dgrad) の計算\n",
        "            if grad.norm() == 0 or new_grad.norm() == 0:\n",
        "                dgrad = 0\n",
        "            else:\n",
        "                dgrad = ((grad - new_grad).norm() ** 2 / (grad.norm() * new_grad.norm())).item()\n",
        "\n",
        "            # 変化量が許容範囲内なら学習率を調整\n",
        "            if dgrad < max_dgrad and dout < max_dout:\n",
        "                if dgrad < 0.1 * max_dgrad and dout < 0.1 * max_dout:\n",
        "                    learning_rate *= 1.1  # 学習率を大きくする\n",
        "                break\n",
        "\n",
        "            # 学習率を小さくする\n",
        "            learning_rate /= 10\n",
        "\n",
        "            print(\"[Step {:d}/{:d}] [Progress: {:.2%}] [learning rate: {:.1e}]\".format(step, args.max_step, step / args.max_step, learning_rate), flush=True)\n",
        "\n",
        "            # 状態をリセット\n",
        "            last_lr_change_step = step\n",
        "            otr, gradient_update = state\n",
        "\n",
        "        # 勾配を更新\n",
        "        grad = new_grad\n",
        "\n",
        "        save = False\n",
        "        if step == checkpoint:\n",
        "            checkpoint = next(checkpoint_generator)\n",
        "            assert checkpoint > step\n",
        "            save = True\n",
        "\n",
        "        if save:\n",
        "            state = {\n",
        "                'step': step,\n",
        "                'wall': perf_counter() - start_time,\n",
        "                'learning_rate': learning_rate,\n",
        "                'dgrad': dgrad,\n",
        "                'dout': dout,\n",
        "                'grad_norm': grad.norm().item(),\n",
        "            }\n",
        "            yield otr, gradient_update, grad, state, converged\n",
        "\n",
        "        if converged:\n",
        "            break\n",
        "\n",
        "        # 最大経過時間を超えたら終了\n",
        "        if perf_counter() > start_time + max_walltime:\n",
        "            break\n",
        "\n",
        "        # 出力に NaN が含まれていたら終了\n",
        "        if torch.isnan(otr).any():\n",
        "            break"
      ],
      "metadata": {
        "id": "fkHYa7LT0ik_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "from functools import partial\n",
        "from time import perf_counter\n",
        "\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.device = 'cpu'\n",
        "        self.init_seed = 0\n",
        "        self.data_seed = 0\n",
        "        self.batch_seed = 0\n",
        "        self.max_step = 50000\n",
        "        self.n = 13\n",
        "        self.k = 3\n",
        "        self.train_size = 3000\n",
        "        self.test_size = 1900\n",
        "        self.normalize = False\n",
        "        self.bias = True\n",
        "        self.L = 3\n",
        "        self.h = 50\n",
        "        self.learning_rate = 0.01\n",
        "        self.init_kernel = 1\n",
        "        self.store_kernel = 0\n",
        "        self.delta_kernel = 0\n",
        "        self.save_outputs = 0\n",
        "        self.alpha = 1\n",
        "        self.f0 = 1\n",
        "        self.train_time = 18000\n",
        "        self.max_dgrad = 1e-4\n",
        "        self.max_dout = 0.1\n",
        "        self.loss = 'cross_entropy'\n",
        "        self.pickle = 'results.pkl'\n",
        "        self.track_test_metrics = True\n",
        "\n",
        "def loss_func(args, outputs, targets):\n",
        "    if args.loss == 'mse':\n",
        "        return ((targets - outputs) ** 2).mean()\n",
        "    elif args.loss == 'cross_entropy':\n",
        "        return F.binary_cross_entropy_with_logits(outputs, targets)\n",
        "\n",
        "def loss_func_prime(args, outputs, targets):\n",
        "    if args.loss == 'mse':\n",
        "        return -2 * (targets - outputs) / outputs.size(0)\n",
        "    elif args.loss == 'cross_entropy':\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        grad = probs - targets\n",
        "        return grad / outputs.size(0)\n",
        "\n",
        "def run_kernel(args, ktrtr, ktetr, ktete, f, xtr, ytr, xte, yte):\n",
        "    assert args.f0 == 1\n",
        "\n",
        "    dynamics = []\n",
        "    step_counter = 0\n",
        "\n",
        "    tau = 0\n",
        "\n",
        "    for otr, _gradient_update, _grad, state, _converged in train_kernel(args, ktrtr, ytr, tau, args.train_time, args.alpha, args.learning_rate, partial(loss_func_prime, args), args.max_dgrad, args.max_dout):\n",
        "        step_counter += 1\n",
        "\n",
        "        preds = torch.sigmoid(otr) > 0.5\n",
        "        train_accuracy = (preds.int() == ytr.int()).float().mean().item()\n",
        "\n",
        "        state['train'] = {\n",
        "            'loss': loss_func(args, otr, ytr).item(),\n",
        "            'aloss': args.alpha * loss_func(args, otr, ytr).item(),\n",
        "            'accuracy': train_accuracy,\n",
        "            'dfnorm': otr.pow(2).mean().sqrt(),\n",
        "            'outputs': otr if args.save_outputs else None,\n",
        "            'labels': ytr if args.save_outputs else None,\n",
        "        }\n",
        "\n",
        "        if args.track_test_metrics and step_counter % 50 == 0:\n",
        "            c = torch.linalg.lstsq(ktrtr, otr.view(-1, 1)).solution.flatten()\n",
        "\n",
        "            if len(xte) > len(xtr):\n",
        "                a = gradient(f(xtr) @ c, f.parameters())\n",
        "                ote = torch.stack([gradient(f(x[None]), f.parameters()) @ a for x in xte])\n",
        "            else:\n",
        "                ote = ktetr @ c\n",
        "\n",
        "            test_loss = loss_func(args, ote, yte).item()\n",
        "            test_preds = torch.sigmoid(ote) > 0.5\n",
        "            test_accuracy = (test_preds.int() == yte.int()).float().mean().item()\n",
        "\n",
        "            state['test'] = {\n",
        "                'loss': test_loss,\n",
        "                'accuracy': test_accuracy,\n",
        "            }\n",
        "\n",
        "            print(f\"[Step {state['step']:d}/{args.max_step}] [Time: {state['wall']:.0f}s] \"\n",
        "                  f\"[Train Loss: {state['train']['loss']:.2e}] [Train Acc: {state['train']['accuracy']:.2f}] \"\n",
        "                  f\"[Eval Loss: {state['test']['loss']:.2e}] [Eval Acc: {state['test']['accuracy']:.2f}]\",\n",
        "                  flush=True)\n",
        "        else:\n",
        "            state['test'] = {\n",
        "                'loss': None,\n",
        "                'accuracy': None,\n",
        "            }\n",
        "\n",
        "            print(f\"[Step {state['step']:d}/{args.max_step}] [Time: {state['wall']:.0f}s] \"\n",
        "                  f\"[Train Loss: {state['train']['aloss']:.2e}] [Train Acc: {state['train']['accuracy']:.2f}]\",\n",
        "                  flush=True)\n",
        "\n",
        "        dynamics.append(state)\n",
        "\n",
        "    c = torch.linalg.lstsq(ktrtr, otr.view(-1, 1)).solution.flatten()\n",
        "    if len(xte) > len(xtr):\n",
        "        a = gradient(f(xtr) @ c, f.parameters())\n",
        "        ote = torch.stack([gradient(f(x[None]), f.parameters()) @ a for x in xte])\n",
        "    else:\n",
        "        ote = ktetr @ c\n",
        "\n",
        "    final_test_loss = loss_func(args, ote, yte).item()\n",
        "    final_test_preds = torch.sigmoid(ote) > 0.5\n",
        "    final_test_accuracy = (final_test_preds.int() == yte.int()).float().mean().item()\n",
        "\n",
        "    dynamics[-1]['test'] = {\n",
        "        'loss': final_test_loss,\n",
        "        'accuracy': final_test_accuracy,\n",
        "    }\n",
        "\n",
        "    out = {\n",
        "        'dynamics': dynamics,\n",
        "        'train': {\n",
        "            'outputs': otr,\n",
        "            'labels': ytr,\n",
        "        },\n",
        "        'test': {\n",
        "            'outputs': ote,\n",
        "            'labels': yte,\n",
        "        },\n",
        "        'kernel': {\n",
        "            'train': {\n",
        "                'value': ktrtr.cpu() if args.store_kernel == 1 else None,\n",
        "            },\n",
        "            'test': {\n",
        "                'value': ktete.cpu() if args.store_kernel == 1 else None,\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "\n",
        "    return out\n",
        "\n",
        "def execute(args):\n",
        "    torch.set_default_dtype(torch.float64)\n",
        "\n",
        "    dataset = BinaryDataset(args.n, args.k, args.train_size, args.test_size, args.data_seed, args.normalize, args.device)\n",
        "    (xtr, ytr), (xte, yte) = dataset.get_data()\n",
        "\n",
        "    xtr = xtr.type(torch.get_default_dtype())\n",
        "    xte = xte.type(torch.get_default_dtype())\n",
        "    ytr = ytr.type(torch.get_default_dtype())\n",
        "    yte = yte.type(torch.get_default_dtype())\n",
        "\n",
        "    torch.manual_seed(args.init_seed + hash(args.alpha))\n",
        "\n",
        "    act = lambda x: 2 ** 0.5 * torch.relu(x)\n",
        "\n",
        "    xtr = xtr.flatten(1)\n",
        "    xte = xte.flatten(1)\n",
        "    f = FC(xtr.size(1), args.h, args.L, act, args.bias).to(args.device)\n",
        "\n",
        "    if args.delta_kernel == 1 or args.init_kernel == 1:\n",
        "        init_kernel = compute_kernels(f, xtr, xte[:len(xtr)])\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    if args.init_kernel == 1:\n",
        "        results['init_kernel'] = run_kernel(args, *init_kernel, f, xtr, ytr, xte, yte)\n",
        "\n",
        "    if args.delta_kernel == 1:\n",
        "        init_kernel = (init_kernel[0].cpu(), init_kernel[2].cpu())\n",
        "    elif args.init_kernel == 1:\n",
        "        del init_kernel\n",
        "\n",
        "    return {\n",
        "        'args': args,\n",
        "        'results': results\n",
        "    }\n",
        "\n",
        "\n",
        "#####################################\n",
        "\n",
        "args = Args()\n",
        "results_to_save = {'args': args}\n",
        "\n",
        "try:\n",
        "    results = execute(args)\n",
        "    results_to_save.update(results)\n",
        "\n",
        "    with open(args.pickle, 'wb') as f:\n",
        "        torch.save(results_to_save, f)\n",
        "except:\n",
        "    os.remove(args.pickle)\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSMuQJmHzct5",
        "outputId": "fcf17fd5-4346-4591-c87a-8bbeb1c5233f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0/1] [len=8 numel=5851]\n",
            "[Step 0/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 1/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 2/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 3/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 4/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 5/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 6/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 7/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 8/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 9/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 10/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 11/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 12/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 13/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 14/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 15/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 16/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 17/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 18/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 19/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 20/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 21/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 22/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 23/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 24/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 25/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 26/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 27/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 28/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 29/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 30/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 31/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 32/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 33/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 34/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 35/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 36/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 37/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 38/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 39/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 40/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 41/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 42/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 43/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 44/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 45/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 46/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 47/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 48/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 49/50000] [Time: 1s] [Train Loss: 6.93e-01] [Train Acc: 0.57] [Eval Loss: 6.93e-01] [Eval Acc: 0.54]\n",
            "[Step 50/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 51/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 52/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 53/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 54/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 55/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 56/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 57/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 58/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 59/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 60/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 61/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 62/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 63/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 64/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 65/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 66/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 67/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 68/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 69/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 70/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 71/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 72/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 73/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 74/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 75/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 76/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 77/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 78/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 79/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 80/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 81/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 82/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 83/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 84/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 85/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 86/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 87/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 88/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 89/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 90/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 91/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 92/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 93/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 94/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 95/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 96/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 97/50000] [Time: 4s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 98/50000] [Time: 4s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 99/50000] [Time: 4s] [Train Loss: 6.93e-01] [Train Acc: 0.56] [Eval Loss: 6.93e-01] [Eval Acc: 0.54]\n",
            "[Step 100/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 101/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 103/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 105/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 107/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 109/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 111/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 113/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 115/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 117/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 119/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 121/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 123/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 125/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 127/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 129/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 131/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 133/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 135/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 137/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 139/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 141/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 143/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 145/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 147/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 149/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 151/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 153/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 155/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 157/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 159/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 161/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 163/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 165/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 167/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 169/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 171/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 173/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 175/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 177/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 179/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 181/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 183/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 185/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 187/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 189/50000] [Time: 6s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 191/50000] [Time: 6s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 193/50000] [Time: 6s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 195/50000] [Time: 6s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 197/50000] [Time: 6s] [Train Loss: 6.92e-01] [Train Acc: 0.57] [Eval Loss: 6.93e-01] [Eval Acc: 0.55]\n",
            "[Step 199/50000] [Time: 8s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 201/50000] [Time: 8s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 203/50000] [Time: 8s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 206/50000] [Time: 8s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 209/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 212/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 215/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 218/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 221/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 224/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 227/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 230/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 233/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 236/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 239/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 242/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 245/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 248/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 251/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 254/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 257/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 260/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 263/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 266/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.57]\n",
            "[Step 269/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.57]\n",
            "[Step 272/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 275/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 278/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 281/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 284/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 287/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 290/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 293/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 296/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 299/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 302/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 305/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 309/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 313/50000] [Time: 9s] [Train Loss: 6.87e-01] [Train Acc: 0.58]\n",
            "[Step 317/50000] [Time: 9s] [Train Loss: 6.87e-01] [Train Acc: 0.58]\n",
            "[Step 321/50000] [Time: 9s] [Train Loss: 6.87e-01] [Train Acc: 0.58]\n",
            "[Step 325/50000] [Time: 9s] [Train Loss: 6.87e-01] [Train Acc: 0.58]\n",
            "[Step 329/50000] [Time: 9s] [Train Loss: 6.87e-01] [Train Acc: 0.58]\n",
            "[Step 333/50000] [Time: 9s] [Train Loss: 6.87e-01] [Train Acc: 0.58]\n",
            "[Step 337/50000] [Time: 9s] [Train Loss: 6.86e-01] [Train Acc: 0.58]\n",
            "[Step 341/50000] [Time: 10s] [Train Loss: 6.86e-01] [Train Acc: 0.58]\n",
            "[Step 345/50000] [Time: 10s] [Train Loss: 6.86e-01] [Train Acc: 0.58]\n",
            "[Step 349/50000] [Time: 10s] [Train Loss: 6.86e-01] [Train Acc: 0.58]\n",
            "[Step 353/50000] [Time: 10s] [Train Loss: 6.86e-01] [Train Acc: 0.58]\n",
            "[Step 357/50000] [Time: 10s] [Train Loss: 6.86e-01] [Train Acc: 0.58] [Eval Loss: 6.88e-01] [Eval Acc: 0.57]\n",
            "[Step 361/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.58]\n",
            "[Step 365/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.58]\n",
            "[Step 369/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.59]\n",
            "[Step 373/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.59]\n",
            "[Step 377/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.59]\n",
            "[Step 381/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.59]\n",
            "[Step 385/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.59]\n",
            "[Step 389/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.59]\n",
            "[Step 393/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.59]\n",
            "[Step 397/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.59]\n",
            "[Step 401/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.59]\n",
            "[Step 405/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.59]\n",
            "[Step 409/50000] [Time: 12s] [Train Loss: 6.83e-01] [Train Acc: 0.59]\n",
            "[Step 414/50000] [Time: 12s] [Train Loss: 6.83e-01] [Train Acc: 0.59]\n",
            "[Step 419/50000] [Time: 12s] [Train Loss: 6.83e-01] [Train Acc: 0.59]\n",
            "[Step 424/50000] [Time: 12s] [Train Loss: 6.83e-01] [Train Acc: 0.59]\n",
            "[Step 429/50000] [Time: 12s] [Train Loss: 6.83e-01] [Train Acc: 0.59]\n",
            "[Step 434/50000] [Time: 12s] [Train Loss: 6.82e-01] [Train Acc: 0.59]\n",
            "[Step 439/50000] [Time: 12s] [Train Loss: 6.82e-01] [Train Acc: 0.59]\n",
            "[Step 444/50000] [Time: 12s] [Train Loss: 6.82e-01] [Train Acc: 0.59]\n",
            "[Step 449/50000] [Time: 12s] [Train Loss: 6.82e-01] [Train Acc: 0.59]\n",
            "[Step 454/50000] [Time: 12s] [Train Loss: 6.81e-01] [Train Acc: 0.59]\n",
            "[Step 459/50000] [Time: 12s] [Train Loss: 6.81e-01] [Train Acc: 0.59]\n",
            "[Step 464/50000] [Time: 12s] [Train Loss: 6.81e-01] [Train Acc: 0.59]\n",
            "[Step 469/50000] [Time: 12s] [Train Loss: 6.81e-01] [Train Acc: 0.59]\n",
            "[Step 474/50000] [Time: 12s] [Train Loss: 6.81e-01] [Train Acc: 0.59]\n",
            "[Step 479/50000] [Time: 12s] [Train Loss: 6.80e-01] [Train Acc: 0.59]\n",
            "[Step 484/50000] [Time: 13s] [Train Loss: 6.80e-01] [Train Acc: 0.59]\n",
            "[Step 489/50000] [Time: 13s] [Train Loss: 6.80e-01] [Train Acc: 0.59]\n",
            "[Step 494/50000] [Time: 13s] [Train Loss: 6.80e-01] [Train Acc: 0.59]\n",
            "[Step 499/50000] [Time: 13s] [Train Loss: 6.80e-01] [Train Acc: 0.59]\n",
            "[Step 504/50000] [Time: 13s] [Train Loss: 6.79e-01] [Train Acc: 0.59]\n",
            "[Step 509/50000] [Time: 13s] [Train Loss: 6.79e-01] [Train Acc: 0.59]\n",
            "[Step 514/50000] [Time: 13s] [Train Loss: 6.79e-01] [Train Acc: 0.59]\n",
            "[Step 520/50000] [Time: 13s] [Train Loss: 6.79e-01] [Train Acc: 0.59]\n",
            "[Step 526/50000] [Time: 13s] [Train Loss: 6.78e-01] [Train Acc: 0.59]\n",
            "[Step 532/50000] [Time: 13s] [Train Loss: 6.78e-01] [Train Acc: 0.59]\n",
            "[Step 538/50000] [Time: 13s] [Train Loss: 6.78e-01] [Train Acc: 0.59]\n",
            "[Step 544/50000] [Time: 13s] [Train Loss: 6.78e-01] [Train Acc: 0.59]\n",
            "[Step 550/50000] [Time: 13s] [Train Loss: 6.77e-01] [Train Acc: 0.59]\n",
            "[Step 556/50000] [Time: 13s] [Train Loss: 6.77e-01] [Train Acc: 0.59]\n",
            "[Step 562/50000] [Time: 13s] [Train Loss: 6.77e-01] [Train Acc: 0.59]\n",
            "[Step 568/50000] [Time: 13s] [Train Loss: 6.77e-01] [Train Acc: 0.59]\n",
            "[Step 574/50000] [Time: 13s] [Train Loss: 6.76e-01] [Train Acc: 0.59]\n",
            "[Step 580/50000] [Time: 13s] [Train Loss: 6.76e-01] [Train Acc: 0.60]\n",
            "[Step 586/50000] [Time: 13s] [Train Loss: 6.76e-01] [Train Acc: 0.60]\n",
            "[Step 592/50000] [Time: 13s] [Train Loss: 6.76e-01] [Train Acc: 0.60]\n",
            "[Step 598/50000] [Time: 13s] [Train Loss: 6.75e-01] [Train Acc: 0.60]\n",
            "[Step 604/50000] [Time: 13s] [Train Loss: 6.75e-01] [Train Acc: 0.60]\n",
            "[Step 610/50000] [Time: 13s] [Train Loss: 6.75e-01] [Train Acc: 0.60] [Eval Loss: 6.83e-01] [Eval Acc: 0.58]\n",
            "[Step 616/50000] [Time: 16s] [Train Loss: 6.74e-01] [Train Acc: 0.60]\n",
            "[Step 622/50000] [Time: 17s] [Train Loss: 6.74e-01] [Train Acc: 0.60]\n",
            "[Step 629/50000] [Time: 17s] [Train Loss: 6.74e-01] [Train Acc: 0.60]\n",
            "[Step 636/50000] [Time: 17s] [Train Loss: 6.74e-01] [Train Acc: 0.60]\n",
            "[Step 643/50000] [Time: 17s] [Train Loss: 6.73e-01] [Train Acc: 0.60]\n",
            "[Step 650/50000] [Time: 17s] [Train Loss: 6.73e-01] [Train Acc: 0.60]\n",
            "[Step 657/50000] [Time: 17s] [Train Loss: 6.73e-01] [Train Acc: 0.60]\n",
            "[Step 664/50000] [Time: 17s] [Train Loss: 6.72e-01] [Train Acc: 0.61]\n",
            "[Step 671/50000] [Time: 17s] [Train Loss: 6.72e-01] [Train Acc: 0.61]\n",
            "[Step 678/50000] [Time: 17s] [Train Loss: 6.71e-01] [Train Acc: 0.61]\n",
            "[Step 685/50000] [Time: 17s] [Train Loss: 6.71e-01] [Train Acc: 0.61]\n",
            "[Step 692/50000] [Time: 17s] [Train Loss: 6.71e-01] [Train Acc: 0.61]\n",
            "[Step 699/50000] [Time: 17s] [Train Loss: 6.70e-01] [Train Acc: 0.61]\n",
            "[Step 706/50000] [Time: 17s] [Train Loss: 6.70e-01] [Train Acc: 0.61]\n",
            "[Step 713/50000] [Time: 18s] [Train Loss: 6.70e-01] [Train Acc: 0.61]\n",
            "[Step 720/50000] [Time: 18s] [Train Loss: 6.69e-01] [Train Acc: 0.61]\n",
            "[Step 727/50000] [Time: 18s] [Train Loss: 6.69e-01] [Train Acc: 0.61]\n",
            "[Step 735/50000] [Time: 18s] [Train Loss: 6.68e-01] [Train Acc: 0.61]\n",
            "[Step 743/50000] [Time: 18s] [Train Loss: 6.68e-01] [Train Acc: 0.61]\n",
            "[Step 751/50000] [Time: 18s] [Train Loss: 6.67e-01] [Train Acc: 0.61]\n",
            "[Step 759/50000] [Time: 18s] [Train Loss: 6.67e-01] [Train Acc: 0.61]\n",
            "[Step 767/50000] [Time: 18s] [Train Loss: 6.66e-01] [Train Acc: 0.61]\n",
            "[Step 775/50000] [Time: 18s] [Train Loss: 6.66e-01] [Train Acc: 0.61]\n",
            "[Step 783/50000] [Time: 18s] [Train Loss: 6.65e-01] [Train Acc: 0.61]\n",
            "[Step 791/50000] [Time: 18s] [Train Loss: 6.65e-01] [Train Acc: 0.61]\n",
            "[Step 799/50000] [Time: 18s] [Train Loss: 6.64e-01] [Train Acc: 0.61]\n",
            "[Step 807/50000] [Time: 18s] [Train Loss: 6.64e-01] [Train Acc: 0.62]\n",
            "[Step 815/50000] [Time: 18s] [Train Loss: 6.63e-01] [Train Acc: 0.62]\n",
            "[Step 823/50000] [Time: 18s] [Train Loss: 6.63e-01] [Train Acc: 0.62]\n",
            "[Step 831/50000] [Time: 18s] [Train Loss: 6.62e-01] [Train Acc: 0.62]\n",
            "[Step 839/50000] [Time: 18s] [Train Loss: 6.62e-01] [Train Acc: 0.62]\n",
            "[Step 848/50000] [Time: 18s] [Train Loss: 6.61e-01] [Train Acc: 0.62]\n",
            "[Step 857/50000] [Time: 19s] [Train Loss: 6.60e-01] [Train Acc: 0.62]\n",
            "[Step 866/50000] [Time: 19s] [Train Loss: 6.60e-01] [Train Acc: 0.62]\n",
            "[Step 875/50000] [Time: 19s] [Train Loss: 6.59e-01] [Train Acc: 0.62]\n",
            "[Step 884/50000] [Time: 19s] [Train Loss: 6.58e-01] [Train Acc: 0.62]\n",
            "[Step 893/50000] [Time: 19s] [Train Loss: 6.58e-01] [Train Acc: 0.63]\n",
            "[Step 902/50000] [Time: 19s] [Train Loss: 6.57e-01] [Train Acc: 0.63]\n",
            "[Step 911/50000] [Time: 19s] [Train Loss: 6.56e-01] [Train Acc: 0.63]\n",
            "[Step 920/50000] [Time: 19s] [Train Loss: 6.55e-01] [Train Acc: 0.63]\n",
            "[Step 929/50000] [Time: 19s] [Train Loss: 6.55e-01] [Train Acc: 0.63]\n",
            "[Step 938/50000] [Time: 19s] [Train Loss: 6.54e-01] [Train Acc: 0.64]\n",
            "[Step 947/50000] [Time: 19s] [Train Loss: 6.53e-01] [Train Acc: 0.64]\n",
            "[Step 957/50000] [Time: 19s] [Train Loss: 6.52e-01] [Train Acc: 0.64]\n",
            "[Step 967/50000] [Time: 19s] [Train Loss: 6.51e-01] [Train Acc: 0.64]\n",
            "[Step 977/50000] [Time: 19s] [Train Loss: 6.50e-01] [Train Acc: 0.64]\n",
            "[Step 987/50000] [Time: 19s] [Train Loss: 6.50e-01] [Train Acc: 0.64]\n",
            "[Step 997/50000] [Time: 19s] [Train Loss: 6.49e-01] [Train Acc: 0.64]\n",
            "[Step 1007/50000] [Time: 20s] [Train Loss: 6.48e-01] [Train Acc: 0.64]\n",
            "[Step 1017/50000] [Time: 20s] [Train Loss: 6.47e-01] [Train Acc: 0.65] [Eval Loss: 6.71e-01] [Eval Acc: 0.60]\n",
            "[Step 1027/50000] [Time: 22s] [Train Loss: 6.46e-01] [Train Acc: 0.65]\n",
            "[Step 1037/50000] [Time: 22s] [Train Loss: 6.45e-01] [Train Acc: 0.65]\n",
            "[Step 1047/50000] [Time: 22s] [Train Loss: 6.44e-01] [Train Acc: 0.65]\n",
            "[Step 1057/50000] [Time: 22s] [Train Loss: 6.43e-01] [Train Acc: 0.65]\n",
            "[Step 1068/50000] [Time: 22s] [Train Loss: 6.41e-01] [Train Acc: 0.65]\n",
            "[Step 1079/50000] [Time: 22s] [Train Loss: 6.40e-01] [Train Acc: 0.65]\n",
            "[Step 1090/50000] [Time: 22s] [Train Loss: 6.39e-01] [Train Acc: 0.66]\n",
            "[Step 1101/50000] [Time: 22s] [Train Loss: 6.38e-01] [Train Acc: 0.66]\n",
            "[Step 1112/50000] [Time: 22s] [Train Loss: 6.36e-01] [Train Acc: 0.66]\n",
            "[Step 1123/50000] [Time: 22s] [Train Loss: 6.35e-01] [Train Acc: 0.67]\n",
            "[Step 1134/50000] [Time: 22s] [Train Loss: 6.34e-01] [Train Acc: 0.67]\n",
            "[Step 1145/50000] [Time: 22s] [Train Loss: 6.32e-01] [Train Acc: 0.67]\n",
            "[Step 1155/50000] [Progress: 2.31%] [learning rate: 6.2e+02]\n",
            "[Step 1156/50000] [Time: 22s] [Train Loss: 6.31e-01] [Train Acc: 0.67]\n",
            "[Step 1167/50000] [Time: 23s] [Train Loss: 6.31e-01] [Train Acc: 0.67]\n",
            "[Step 1179/50000] [Time: 23s] [Train Loss: 6.30e-01] [Train Acc: 0.67]\n",
            "[Step 1191/50000] [Time: 23s] [Train Loss: 6.28e-01] [Train Acc: 0.68]\n",
            "[Step 1202/50000] [Progress: 2.40%] [learning rate: 7.4e+02]\n",
            "[Step 1203/50000] [Time: 23s] [Train Loss: 6.27e-01] [Train Acc: 0.68]\n",
            "[Step 1215/50000] [Time: 23s] [Train Loss: 6.26e-01] [Train Acc: 0.68]\n",
            "[Step 1227/50000] [Time: 23s] [Train Loss: 6.25e-01] [Train Acc: 0.68]\n",
            "[Step 1239/50000] [Time: 23s] [Train Loss: 6.24e-01] [Train Acc: 0.68]\n",
            "[Step 1243/50000] [Progress: 2.49%] [learning rate: 8.1e+02]\n",
            "[Step 1251/50000] [Time: 23s] [Train Loss: 6.23e-01] [Train Acc: 0.68]\n",
            "[Step 1263/50000] [Time: 23s] [Train Loss: 6.22e-01] [Train Acc: 0.69]\n",
            "[Step 1275/50000] [Time: 23s] [Train Loss: 6.20e-01] [Train Acc: 0.69]\n",
            "[Step 1281/50000] [Progress: 2.56%] [learning rate: 8.7e+02]\n",
            "[Step 1287/50000] [Time: 23s] [Train Loss: 6.20e-01] [Train Acc: 0.69]\n",
            "[Step 1300/50000] [Time: 23s] [Train Loss: 6.19e-01] [Train Acc: 0.69]\n",
            "[Step 1313/50000] [Time: 24s] [Train Loss: 6.17e-01] [Train Acc: 0.69]\n",
            "[Step 1318/50000] [Progress: 2.64%] [learning rate: 9.5e+02]\n",
            "[Step 1326/50000] [Time: 24s] [Train Loss: 6.16e-01] [Train Acc: 0.69]\n",
            "[Step 1339/50000] [Time: 24s] [Train Loss: 6.15e-01] [Train Acc: 0.69]\n",
            "[Step 1352/50000] [Time: 24s] [Train Loss: 6.13e-01] [Train Acc: 0.69]\n",
            "[Step 1354/50000] [Progress: 2.71%] [learning rate: 1.0e+03]\n",
            "[Step 1365/50000] [Time: 24s] [Train Loss: 6.13e-01] [Train Acc: 0.69]\n",
            "[Step 1378/50000] [Time: 24s] [Train Loss: 6.11e-01] [Train Acc: 0.69]\n",
            "[Step 1389/50000] [Progress: 2.78%] [learning rate: 1.1e+03]\n",
            "[Step 1391/50000] [Time: 24s] [Train Loss: 6.10e-01] [Train Acc: 0.70]\n",
            "[Step 1404/50000] [Time: 24s] [Train Loss: 6.09e-01] [Train Acc: 0.70]\n",
            "[Step 1418/50000] [Time: 24s] [Train Loss: 6.07e-01] [Train Acc: 0.70]\n",
            "[Step 1423/50000] [Progress: 2.85%] [learning rate: 1.2e+03]\n",
            "[Step 1432/50000] [Time: 24s] [Train Loss: 6.06e-01] [Train Acc: 0.70]\n",
            "[Step 1446/50000] [Time: 24s] [Train Loss: 6.05e-01] [Train Acc: 0.70]\n",
            "[Step 1456/50000] [Progress: 2.91%] [learning rate: 1.3e+03]\n",
            "[Step 1460/50000] [Time: 25s] [Train Loss: 6.03e-01] [Train Acc: 0.70]\n",
            "[Step 1474/50000] [Time: 25s] [Train Loss: 6.02e-01] [Train Acc: 0.71]\n",
            "[Step 1488/50000] [Time: 25s] [Train Loss: 6.00e-01] [Train Acc: 0.71]\n",
            "[Step 1489/50000] [Progress: 2.98%] [learning rate: 1.4e+03]\n",
            "[Step 1502/50000] [Time: 25s] [Train Loss: 5.99e-01] [Train Acc: 0.71]\n",
            "[Step 1516/50000] [Time: 25s] [Train Loss: 5.97e-01] [Train Acc: 0.71]\n",
            "[Step 1522/50000] [Progress: 3.04%] [learning rate: 1.5e+03]\n",
            "[Step 1531/50000] [Time: 25s] [Train Loss: 5.96e-01] [Train Acc: 0.71]\n",
            "[Step 1546/50000] [Time: 25s] [Train Loss: 5.94e-01] [Train Acc: 0.71]\n",
            "[Step 1554/50000] [Progress: 3.11%] [learning rate: 1.7e+03]\n",
            "[Step 1561/50000] [Time: 25s] [Train Loss: 5.93e-01] [Train Acc: 0.71]\n",
            "[Step 1576/50000] [Time: 25s] [Train Loss: 5.91e-01] [Train Acc: 0.71]\n",
            "[Step 1583/50000] [Progress: 3.17%] [learning rate: 1.8e+03]\n",
            "[Step 1591/50000] [Time: 26s] [Train Loss: 5.89e-01] [Train Acc: 0.71]\n",
            "[Step 1606/50000] [Time: 26s] [Train Loss: 5.88e-01] [Train Acc: 0.72]\n",
            "[Step 1611/50000] [Progress: 3.22%] [learning rate: 1.9e+03]\n",
            "[Step 1621/50000] [Time: 26s] [Train Loss: 5.86e-01] [Train Acc: 0.72]\n",
            "[Step 1636/50000] [Time: 26s] [Train Loss: 5.84e-01] [Train Acc: 0.72]\n",
            "[Step 1638/50000] [Progress: 3.28%] [learning rate: 2.1e+03]\n",
            "[Step 1652/50000] [Time: 26s] [Train Loss: 5.83e-01] [Train Acc: 0.72] [Eval Loss: 6.45e-01] [Eval Acc: 0.64]\n",
            "[Step 1665/50000] [Progress: 3.33%] [learning rate: 2.1e+03]\n",
            "[Step 1668/50000] [Time: 28s] [Train Loss: 5.81e-01] [Train Acc: 0.72]\n",
            "[Step 1684/50000] [Time: 28s] [Train Loss: 5.80e-01] [Train Acc: 0.72]\n",
            "[Step 1692/50000] [Progress: 3.38%] [learning rate: 2.2e+03]\n",
            "[Step 1700/50000] [Time: 28s] [Train Loss: 5.78e-01] [Train Acc: 0.73]\n",
            "[Step 1716/50000] [Time: 28s] [Train Loss: 5.76e-01] [Train Acc: 0.73]\n",
            "[Step 1718/50000] [Progress: 3.44%] [learning rate: 2.2e+03]\n",
            "[Step 1732/50000] [Time: 28s] [Train Loss: 5.75e-01] [Train Acc: 0.73]\n",
            "[Step 1744/50000] [Progress: 3.49%] [learning rate: 2.2e+03]\n",
            "[Step 1748/50000] [Time: 28s] [Train Loss: 5.73e-01] [Train Acc: 0.74]\n",
            "[Step 1765/50000] [Time: 28s] [Train Loss: 5.72e-01] [Train Acc: 0.74]\n",
            "[Step 1769/50000] [Progress: 3.54%] [learning rate: 2.1e+03]\n",
            "[Step 1782/50000] [Time: 29s] [Train Loss: 5.71e-01] [Train Acc: 0.74]\n",
            "[Step 1796/50000] [Progress: 3.59%] [learning rate: 2.3e+03]\n",
            "[Step 1799/50000] [Time: 29s] [Train Loss: 5.69e-01] [Train Acc: 0.74]\n",
            "[Step 1816/50000] [Time: 29s] [Train Loss: 5.67e-01] [Train Acc: 0.74]\n",
            "[Step 1822/50000] [Progress: 3.64%] [learning rate: 2.3e+03]\n",
            "[Step 1833/50000] [Time: 29s] [Train Loss: 5.66e-01] [Train Acc: 0.75]\n",
            "[Step 1846/50000] [Progress: 3.69%] [learning rate: 2.3e+03]\n",
            "[Step 1850/50000] [Time: 29s] [Train Loss: 5.64e-01] [Train Acc: 0.75]\n",
            "[Step 1867/50000] [Time: 29s] [Train Loss: 5.63e-01] [Train Acc: 0.75]\n",
            "[Step 1871/50000] [Progress: 3.74%] [learning rate: 2.2e+03]\n",
            "[Step 1885/50000] [Time: 29s] [Train Loss: 5.62e-01] [Train Acc: 0.75]\n",
            "[Step 1897/50000] [Progress: 3.79%] [learning rate: 2.2e+03]\n",
            "[Step 1903/50000] [Time: 30s] [Train Loss: 5.60e-01] [Train Acc: 0.75]\n",
            "[Step 1921/50000] [Time: 30s] [Train Loss: 5.58e-01] [Train Acc: 0.75]\n",
            "[Step 1922/50000] [Progress: 3.84%] [learning rate: 2.2e+03]\n",
            "[Step 1939/50000] [Time: 30s] [Train Loss: 5.57e-01] [Train Acc: 0.75]\n",
            "[Step 1947/50000] [Progress: 3.89%] [learning rate: 2.3e+03]\n",
            "[Step 1957/50000] [Time: 30s] [Train Loss: 5.56e-01] [Train Acc: 0.75]\n",
            "[Step 1973/50000] [Progress: 3.95%] [learning rate: 2.5e+03]\n",
            "[Step 1975/50000] [Time: 30s] [Train Loss: 5.54e-01] [Train Acc: 0.76]\n",
            "[Step 1993/50000] [Time: 30s] [Train Loss: 5.53e-01] [Train Acc: 0.76]\n",
            "[Step 1997/50000] [Progress: 3.99%] [learning rate: 2.3e+03]\n",
            "[Step 2012/50000] [Time: 30s] [Train Loss: 5.51e-01] [Train Acc: 0.76]\n",
            "[Step 2022/50000] [Progress: 4.04%] [learning rate: 2.2e+03]\n",
            "[Step 2031/50000] [Time: 31s] [Train Loss: 5.50e-01] [Train Acc: 0.76]\n",
            "[Step 2048/50000] [Progress: 4.10%] [learning rate: 2.4e+03]\n",
            "[Step 2050/50000] [Time: 31s] [Train Loss: 5.48e-01] [Train Acc: 0.76]\n",
            "[Step 2069/50000] [Time: 31s] [Train Loss: 5.47e-01] [Train Acc: 0.76]\n",
            "[Step 2072/50000] [Progress: 4.14%] [learning rate: 2.2e+03]\n",
            "[Step 2088/50000] [Time: 31s] [Train Loss: 5.46e-01] [Train Acc: 0.76]\n",
            "[Step 2099/50000] [Progress: 4.20%] [learning rate: 2.3e+03]\n",
            "[Step 2107/50000] [Time: 31s] [Train Loss: 5.44e-01] [Train Acc: 0.77]\n",
            "[Step 2124/50000] [Progress: 4.25%] [learning rate: 2.3e+03]\n",
            "[Step 2126/50000] [Time: 31s] [Train Loss: 5.42e-01] [Train Acc: 0.77]\n",
            "[Step 2146/50000] [Time: 31s] [Train Loss: 5.41e-01] [Train Acc: 0.77]\n",
            "[Step 2150/50000] [Progress: 4.30%] [learning rate: 2.3e+03]\n",
            "[Step 2166/50000] [Time: 32s] [Train Loss: 5.40e-01] [Train Acc: 0.77]\n",
            "[Step 2176/50000] [Progress: 4.35%] [learning rate: 2.2e+03]\n",
            "[Step 2186/50000] [Time: 32s] [Train Loss: 5.39e-01] [Train Acc: 0.77]\n",
            "[Step 2201/50000] [Progress: 4.40%] [learning rate: 2.2e+03]\n",
            "[Step 2206/50000] [Time: 32s] [Train Loss: 5.37e-01] [Train Acc: 0.77]\n",
            "[Step 2226/50000] [Progress: 4.45%] [learning rate: 2.4e+03]\n",
            "[Step 2226/50000] [Time: 32s] [Train Loss: 5.36e-01] [Train Acc: 0.77]\n",
            "[Step 2246/50000] [Time: 32s] [Train Loss: 5.34e-01] [Train Acc: 0.78]\n",
            "[Step 2251/50000] [Progress: 4.50%] [learning rate: 2.6e+03]\n",
            "[Step 2267/50000] [Time: 32s] [Train Loss: 5.33e-01] [Train Acc: 0.78]\n",
            "[Step 2274/50000] [Progress: 4.55%] [learning rate: 2.1e+03]\n",
            "[Step 2288/50000] [Time: 32s] [Train Loss: 5.32e-01] [Train Acc: 0.78]\n",
            "[Step 2300/50000] [Progress: 4.60%] [learning rate: 2.3e+03]\n",
            "[Step 2309/50000] [Time: 32s] [Train Loss: 5.30e-01] [Train Acc: 0.78]\n",
            "[Step 2325/50000] [Progress: 4.65%] [learning rate: 2.3e+03]\n",
            "[Step 2330/50000] [Time: 33s] [Train Loss: 5.29e-01] [Train Acc: 0.78]\n",
            "[Step 2351/50000] [Progress: 4.70%] [learning rate: 2.4e+03]\n",
            "[Step 2351/50000] [Time: 33s] [Train Loss: 5.27e-01] [Train Acc: 0.78]\n",
            "[Step 2372/50000] [Time: 33s] [Train Loss: 5.26e-01] [Train Acc: 0.78]\n",
            "[Step 2375/50000] [Progress: 4.75%] [learning rate: 2.4e+03]\n",
            "[Step 2394/50000] [Time: 33s] [Train Loss: 5.25e-01] [Train Acc: 0.78]\n",
            "[Step 2400/50000] [Progress: 4.80%] [learning rate: 2.4e+03]\n",
            "[Step 2416/50000] [Time: 33s] [Train Loss: 5.24e-01] [Train Acc: 0.78]\n",
            "[Step 2424/50000] [Progress: 4.85%] [learning rate: 2.3e+03]\n",
            "[Step 2438/50000] [Time: 33s] [Train Loss: 5.22e-01] [Train Acc: 0.78]\n",
            "[Step 2449/50000] [Progress: 4.90%] [learning rate: 2.3e+03]\n",
            "[Step 2460/50000] [Time: 33s] [Train Loss: 5.21e-01] [Train Acc: 0.78]\n",
            "[Step 2475/50000] [Progress: 4.95%] [learning rate: 2.5e+03]\n",
            "[Step 2482/50000] [Time: 34s] [Train Loss: 5.20e-01] [Train Acc: 0.78]\n",
            "[Step 2499/50000] [Progress: 5.00%] [learning rate: 2.2e+03]\n",
            "[Step 2504/50000] [Time: 34s] [Train Loss: 5.18e-01] [Train Acc: 0.78]\n",
            "[Step 2526/50000] [Progress: 5.05%] [learning rate: 2.7e+03]\n",
            "[Step 2527/50000] [Time: 34s] [Train Loss: 5.17e-01] [Train Acc: 0.79]\n",
            "[Step 2549/50000] [Progress: 5.10%] [learning rate: 2.2e+03]\n",
            "[Step 2550/50000] [Time: 34s] [Train Loss: 5.15e-01] [Train Acc: 0.79]\n",
            "[Step 2573/50000] [Time: 34s] [Train Loss: 5.14e-01] [Train Acc: 0.79]\n",
            "[Step 2575/50000] [Progress: 5.15%] [learning rate: 2.3e+03]\n",
            "[Step 2596/50000] [Time: 34s] [Train Loss: 5.13e-01] [Train Acc: 0.79]\n",
            "[Step 2600/50000] [Progress: 5.20%] [learning rate: 2.3e+03]\n",
            "[Step 2619/50000] [Time: 35s] [Train Loss: 5.12e-01] [Train Acc: 0.79] [Eval Loss: 6.11e-01] [Eval Acc: 0.68]\n",
            "[Step 2626/50000] [Progress: 5.25%] [learning rate: 2.3e+03]\n",
            "[Step 2643/50000] [Time: 37s] [Train Loss: 5.11e-01] [Train Acc: 0.79]\n",
            "[Step 2652/50000] [Progress: 5.30%] [learning rate: 2.5e+03]\n",
            "[Step 2667/50000] [Time: 37s] [Train Loss: 5.09e-01] [Train Acc: 0.79]\n",
            "[Step 2679/50000] [Progress: 5.36%] [learning rate: 2.7e+03]\n",
            "[Step 2691/50000] [Time: 37s] [Train Loss: 5.08e-01] [Train Acc: 0.79]\n",
            "[Step 2701/50000] [Progress: 5.40%] [learning rate: 2.2e+03]\n",
            "[Step 2715/50000] [Time: 38s] [Train Loss: 5.07e-01] [Train Acc: 0.79]\n",
            "[Step 2727/50000] [Progress: 5.45%] [learning rate: 2.6e+03]\n",
            "[Step 2739/50000] [Time: 38s] [Train Loss: 5.05e-01] [Train Acc: 0.79]\n",
            "[Step 2750/50000] [Progress: 5.50%] [learning rate: 2.3e+03]\n",
            "[Step 2763/50000] [Time: 38s] [Train Loss: 5.04e-01] [Train Acc: 0.79]\n",
            "[Step 2775/50000] [Progress: 5.55%] [learning rate: 2.5e+03]\n",
            "[Step 2788/50000] [Time: 38s] [Train Loss: 5.03e-01] [Train Acc: 0.79]\n",
            "[Step 2799/50000] [Progress: 5.60%] [learning rate: 2.5e+03]\n",
            "[Step 2813/50000] [Time: 38s] [Train Loss: 5.02e-01] [Train Acc: 0.79]\n",
            "[Step 2824/50000] [Progress: 5.65%] [learning rate: 2.4e+03]\n",
            "[Step 2838/50000] [Time: 38s] [Train Loss: 5.00e-01] [Train Acc: 0.80]\n",
            "[Step 2848/50000] [Progress: 5.70%] [learning rate: 2.4e+03]\n",
            "[Step 2863/50000] [Time: 39s] [Train Loss: 4.99e-01] [Train Acc: 0.80]\n",
            "[Step 2873/50000] [Progress: 5.75%] [learning rate: 2.4e+03]\n",
            "[Step 2888/50000] [Time: 39s] [Train Loss: 4.98e-01] [Train Acc: 0.80]\n",
            "[Step 2899/50000] [Progress: 5.80%] [learning rate: 2.6e+03]\n",
            "[Step 2914/50000] [Time: 39s] [Train Loss: 4.96e-01] [Train Acc: 0.80]\n",
            "[Step 2923/50000] [Progress: 5.85%] [learning rate: 2.3e+03]\n",
            "[Step 2940/50000] [Time: 39s] [Train Loss: 4.95e-01] [Train Acc: 0.80]\n",
            "[Step 2950/50000] [Progress: 5.90%] [learning rate: 2.7e+03]\n",
            "[Step 2966/50000] [Time: 39s] [Train Loss: 4.94e-01] [Train Acc: 0.80]\n",
            "[Step 2973/50000] [Progress: 5.95%] [learning rate: 2.2e+03]\n",
            "[Step 2992/50000] [Time: 40s] [Train Loss: 4.93e-01] [Train Acc: 0.80]\n",
            "[Step 2999/50000] [Progress: 6.00%] [learning rate: 2.4e+03]\n",
            "[Step 3018/50000] [Time: 40s] [Train Loss: 4.91e-01] [Train Acc: 0.80]\n",
            "[Step 3023/50000] [Progress: 6.05%] [learning rate: 2.4e+03]\n",
            "[Step 3045/50000] [Time: 40s] [Train Loss: 4.90e-01] [Train Acc: 0.80]\n",
            "[Step 3048/50000] [Progress: 6.10%] [learning rate: 2.6e+03]\n",
            "[Step 3072/50000] [Progress: 6.14%] [learning rate: 2.3e+03]\n",
            "[Step 3072/50000] [Time: 40s] [Train Loss: 4.89e-01] [Train Acc: 0.80]\n",
            "[Step 3099/50000] [Time: 40s] [Train Loss: 4.87e-01] [Train Acc: 0.80]\n",
            "[Step 3100/50000] [Progress: 6.20%] [learning rate: 2.7e+03]\n",
            "[Step 3123/50000] [Progress: 6.25%] [learning rate: 2.2e+03]\n",
            "[Step 3126/50000] [Time: 40s] [Train Loss: 4.86e-01] [Train Acc: 0.80]\n",
            "[Step 3150/50000] [Progress: 6.30%] [learning rate: 2.7e+03]\n",
            "[Step 3153/50000] [Time: 41s] [Train Loss: 4.85e-01] [Train Acc: 0.80]\n",
            "[Step 3173/50000] [Progress: 6.35%] [learning rate: 2.2e+03]\n",
            "[Step 3181/50000] [Time: 41s] [Train Loss: 4.84e-01] [Train Acc: 0.81]\n",
            "[Step 3200/50000] [Progress: 6.40%] [learning rate: 2.6e+03]\n",
            "[Step 3209/50000] [Time: 41s] [Train Loss: 4.83e-01] [Train Acc: 0.81]\n",
            "[Step 3225/50000] [Progress: 6.45%] [learning rate: 2.5e+03]\n",
            "[Step 3237/50000] [Time: 41s] [Train Loss: 4.81e-01] [Train Acc: 0.81]\n",
            "[Step 3250/50000] [Progress: 6.50%] [learning rate: 2.8e+03]\n",
            "[Step 3265/50000] [Time: 42s] [Train Loss: 4.80e-01] [Train Acc: 0.81]\n",
            "[Step 3273/50000] [Progress: 6.55%] [learning rate: 2.2e+03]\n",
            "[Step 3293/50000] [Time: 42s] [Train Loss: 4.79e-01] [Train Acc: 0.81]\n",
            "[Step 3301/50000] [Progress: 6.60%] [learning rate: 2.7e+03]\n",
            "[Step 3322/50000] [Time: 42s] [Train Loss: 4.78e-01] [Train Acc: 0.81]\n",
            "[Step 3325/50000] [Progress: 6.65%] [learning rate: 2.4e+03]\n",
            "[Step 3350/50000] [Progress: 6.70%] [learning rate: 2.6e+03]\n",
            "[Step 3351/50000] [Time: 42s] [Train Loss: 4.76e-01] [Train Acc: 0.81]\n",
            "[Step 3375/50000] [Progress: 6.75%] [learning rate: 2.6e+03]\n",
            "[Step 3380/50000] [Time: 42s] [Train Loss: 4.75e-01] [Train Acc: 0.81]\n",
            "[Step 3401/50000] [Progress: 6.80%] [learning rate: 2.5e+03]\n",
            "[Step 3409/50000] [Time: 43s] [Train Loss: 4.74e-01] [Train Acc: 0.81]\n",
            "[Step 3425/50000] [Progress: 6.85%] [learning rate: 2.5e+03]\n",
            "[Step 3438/50000] [Time: 43s] [Train Loss: 4.73e-01] [Train Acc: 0.81]\n",
            "[Step 3450/50000] [Progress: 6.90%] [learning rate: 2.4e+03]\n",
            "[Step 3468/50000] [Time: 43s] [Train Loss: 4.72e-01] [Train Acc: 0.81]\n",
            "[Step 3476/50000] [Progress: 6.95%] [learning rate: 2.7e+03]\n",
            "[Step 3498/50000] [Time: 43s] [Train Loss: 4.70e-01] [Train Acc: 0.82]\n",
            "[Step 3500/50000] [Progress: 7.00%] [learning rate: 2.4e+03]\n",
            "[Step 3528/50000] [Progress: 7.06%] [learning rate: 2.8e+03]\n",
            "[Step 3528/50000] [Time: 44s] [Train Loss: 4.69e-01] [Train Acc: 0.82]\n",
            "[Step 3552/50000] [Progress: 7.10%] [learning rate: 2.5e+03]\n",
            "[Step 3558/50000] [Time: 44s] [Train Loss: 4.68e-01] [Train Acc: 0.82]\n",
            "[Step 3577/50000] [Progress: 7.15%] [learning rate: 2.5e+03]\n",
            "[Step 3588/50000] [Time: 44s] [Train Loss: 4.67e-01] [Train Acc: 0.82]\n",
            "[Step 3603/50000] [Progress: 7.21%] [learning rate: 2.5e+03]\n",
            "[Step 3619/50000] [Time: 44s] [Train Loss: 4.66e-01] [Train Acc: 0.82]\n",
            "[Step 3628/50000] [Progress: 7.26%] [learning rate: 2.4e+03]\n",
            "[Step 3650/50000] [Time: 44s] [Train Loss: 4.64e-01] [Train Acc: 0.82]\n",
            "[Step 3655/50000] [Progress: 7.31%] [learning rate: 2.6e+03]\n",
            "[Step 3681/50000] [Time: 45s] [Train Loss: 4.63e-01] [Train Acc: 0.82]\n",
            "[Step 3682/50000] [Progress: 7.36%] [learning rate: 2.8e+03]\n",
            "[Step 3707/50000] [Progress: 7.41%] [learning rate: 2.5e+03]\n",
            "[Step 3712/50000] [Time: 45s] [Train Loss: 4.62e-01] [Train Acc: 0.82]\n",
            "[Step 3733/50000] [Progress: 7.47%] [learning rate: 2.5e+03]\n",
            "[Step 3744/50000] [Time: 45s] [Train Loss: 4.61e-01] [Train Acc: 0.82]\n",
            "[Step 3759/50000] [Progress: 7.52%] [learning rate: 2.5e+03]\n",
            "[Step 3776/50000] [Time: 45s] [Train Loss: 4.60e-01] [Train Acc: 0.82]\n",
            "[Step 3784/50000] [Progress: 7.57%] [learning rate: 2.4e+03]\n",
            "[Step 3808/50000] [Time: 45s] [Train Loss: 4.58e-01] [Train Acc: 0.82]\n",
            "[Step 3810/50000] [Progress: 7.62%] [learning rate: 2.6e+03]\n",
            "[Step 3836/50000] [Progress: 7.67%] [learning rate: 2.9e+03]\n",
            "[Step 3840/50000] [Time: 46s] [Train Loss: 4.57e-01] [Train Acc: 0.82]\n",
            "[Step 3859/50000] [Progress: 7.72%] [learning rate: 2.3e+03]\n",
            "[Step 3872/50000] [Time: 46s] [Train Loss: 4.56e-01] [Train Acc: 0.82]\n",
            "[Step 3885/50000] [Progress: 7.77%] [learning rate: 2.5e+03]\n",
            "[Step 3905/50000] [Time: 46s] [Train Loss: 4.55e-01] [Train Acc: 0.82]\n",
            "[Step 3910/50000] [Progress: 7.82%] [learning rate: 2.5e+03]\n",
            "[Step 3936/50000] [Progress: 7.87%] [learning rate: 2.7e+03]\n",
            "[Step 3938/50000] [Time: 46s] [Train Loss: 4.54e-01] [Train Acc: 0.82]\n",
            "[Step 3961/50000] [Progress: 7.92%] [learning rate: 2.6e+03]\n",
            "[Step 3971/50000] [Time: 47s] [Train Loss: 4.52e-01] [Train Acc: 0.82]\n",
            "[Step 3987/50000] [Progress: 7.97%] [learning rate: 2.6e+03]\n",
            "[Step 4004/50000] [Time: 47s] [Train Loss: 4.51e-01] [Train Acc: 0.83]\n",
            "[Step 4011/50000] [Progress: 8.02%] [learning rate: 2.6e+03]\n",
            "[Step 4036/50000] [Progress: 8.07%] [learning rate: 2.5e+03]\n",
            "[Step 4037/50000] [Time: 47s] [Train Loss: 4.50e-01] [Train Acc: 0.83] [Eval Loss: 5.80e-01] [Eval Acc: 0.71]\n",
            "[Step 4062/50000] [Progress: 8.12%] [learning rate: 2.7e+03]\n",
            "[Step 4071/50000] [Time: 49s] [Train Loss: 4.49e-01] [Train Acc: 0.83]\n",
            "[Step 4086/50000] [Progress: 8.17%] [learning rate: 2.5e+03]\n",
            "[Step 4105/50000] [Time: 49s] [Train Loss: 4.48e-01] [Train Acc: 0.83]\n",
            "[Step 4113/50000] [Progress: 8.23%] [learning rate: 2.9e+03]\n",
            "[Step 4136/50000] [Progress: 8.27%] [learning rate: 2.4e+03]\n",
            "[Step 4139/50000] [Time: 49s] [Train Loss: 4.47e-01] [Train Acc: 0.83]\n",
            "[Step 4162/50000] [Progress: 8.32%] [learning rate: 2.6e+03]\n",
            "[Step 4173/50000] [Time: 49s] [Train Loss: 4.46e-01] [Train Acc: 0.83]\n",
            "[Step 4187/50000] [Progress: 8.37%] [learning rate: 2.5e+03]\n",
            "[Step 4208/50000] [Time: 50s] [Train Loss: 4.44e-01] [Train Acc: 0.83]\n",
            "[Step 4213/50000] [Progress: 8.43%] [learning rate: 2.5e+03]\n",
            "[Step 4238/50000] [Progress: 8.48%] [learning rate: 2.7e+03]\n",
            "[Step 4243/50000] [Time: 50s] [Train Loss: 4.43e-01] [Train Acc: 0.83]\n",
            "[Step 4263/50000] [Progress: 8.53%] [learning rate: 2.7e+03]\n",
            "[Step 4278/50000] [Time: 50s] [Train Loss: 4.42e-01] [Train Acc: 0.83]\n",
            "[Step 4287/50000] [Progress: 8.57%] [learning rate: 2.6e+03]\n",
            "[Step 4312/50000] [Progress: 8.62%] [learning rate: 2.6e+03]\n",
            "[Step 4313/50000] [Time: 50s] [Train Loss: 4.41e-01] [Train Acc: 0.83]\n",
            "[Step 4338/50000] [Progress: 8.68%] [learning rate: 2.6e+03]\n",
            "[Step 4349/50000] [Time: 51s] [Train Loss: 4.40e-01] [Train Acc: 0.84]\n",
            "[Step 4363/50000] [Progress: 8.73%] [learning rate: 2.5e+03]\n",
            "[Step 4385/50000] [Time: 51s] [Train Loss: 4.39e-01] [Train Acc: 0.84]\n",
            "[Step 4388/50000] [Progress: 8.78%] [learning rate: 2.7e+03]\n",
            "[Step 4414/50000] [Progress: 8.83%] [learning rate: 2.9e+03]\n",
            "[Step 4421/50000] [Time: 51s] [Train Loss: 4.37e-01] [Train Acc: 0.84]\n",
            "[Step 4438/50000] [Progress: 8.88%] [learning rate: 2.6e+03]\n",
            "[Step 4457/50000] [Time: 51s] [Train Loss: 4.36e-01] [Train Acc: 0.84]\n",
            "[Step 4463/50000] [Progress: 8.93%] [learning rate: 2.6e+03]\n",
            "[Step 4489/50000] [Progress: 8.98%] [learning rate: 2.6e+03]\n",
            "[Step 4493/50000] [Time: 52s] [Train Loss: 4.35e-01] [Train Acc: 0.84]\n",
            "[Step 4514/50000] [Progress: 9.03%] [learning rate: 2.5e+03]\n",
            "[Step 4530/50000] [Time: 52s] [Train Loss: 4.34e-01] [Train Acc: 0.84]\n",
            "[Step 4540/50000] [Progress: 9.08%] [learning rate: 2.7e+03]\n",
            "[Step 4567/50000] [Progress: 9.13%] [learning rate: 3.0e+03]\n",
            "[Step 4567/50000] [Time: 52s] [Train Loss: 4.33e-01] [Train Acc: 0.84]\n",
            "[Step 4591/50000] [Progress: 9.18%] [learning rate: 2.7e+03]\n",
            "[Step 4604/50000] [Time: 52s] [Train Loss: 4.32e-01] [Train Acc: 0.84]\n",
            "[Step 4616/50000] [Progress: 9.23%] [learning rate: 2.6e+03]\n",
            "[Step 4641/50000] [Time: 53s] [Train Loss: 4.31e-01] [Train Acc: 0.84]\n",
            "[Step 4642/50000] [Progress: 9.28%] [learning rate: 2.6e+03]\n",
            "[Step 4667/50000] [Progress: 9.33%] [learning rate: 2.5e+03]\n",
            "[Step 4679/50000] [Time: 53s] [Train Loss: 4.30e-01] [Train Acc: 0.84]\n",
            "[Step 4693/50000] [Progress: 9.39%] [learning rate: 2.7e+03]\n",
            "[Step 4717/50000] [Time: 53s] [Train Loss: 4.28e-01] [Train Acc: 0.84]\n",
            "[Step 4719/50000] [Progress: 9.44%] [learning rate: 3.0e+03]\n",
            "[Step 4742/50000] [Progress: 9.48%] [learning rate: 2.4e+03]\n",
            "[Step 4755/50000] [Time: 54s] [Train Loss: 4.27e-01] [Train Acc: 0.84]\n",
            "[Step 4769/50000] [Progress: 9.54%] [learning rate: 2.9e+03]\n",
            "[Step 4792/50000] [Progress: 9.58%] [learning rate: 2.6e+03]\n",
            "[Step 4793/50000] [Time: 54s] [Train Loss: 4.26e-01] [Train Acc: 0.84]\n",
            "[Step 4817/50000] [Progress: 9.63%] [learning rate: 2.8e+03]\n",
            "[Step 4832/50000] [Time: 54s] [Train Loss: 4.25e-01] [Train Acc: 0.84]\n",
            "[Step 4842/50000] [Progress: 9.68%] [learning rate: 2.8e+03]\n",
            "[Step 4868/50000] [Progress: 9.74%] [learning rate: 2.7e+03]\n",
            "[Step 4871/50000] [Time: 54s] [Train Loss: 4.24e-01] [Train Acc: 0.84]\n",
            "[Step 4892/50000] [Progress: 9.78%] [learning rate: 2.7e+03]\n",
            "[Step 4910/50000] [Time: 55s] [Train Loss: 4.23e-01] [Train Acc: 0.84]\n",
            "[Step 4917/50000] [Progress: 9.83%] [learning rate: 2.6e+03]\n",
            "[Step 4943/50000] [Progress: 9.89%] [learning rate: 2.9e+03]\n",
            "[Step 4949/50000] [Time: 55s] [Train Loss: 4.22e-01] [Train Acc: 0.84]\n",
            "[Step 4967/50000] [Progress: 9.93%] [learning rate: 2.6e+03]\n",
            "[Step 4989/50000] [Time: 55s] [Train Loss: 4.21e-01] [Train Acc: 0.84]\n",
            "[Step 4995/50000] [Progress: 9.99%] [learning rate: 3.0e+03]\n",
            "[Step 5019/50000] [Progress: 10.04%] [learning rate: 2.7e+03]\n",
            "[Step 5029/50000] [Time: 56s] [Train Loss: 4.20e-01] [Train Acc: 0.84]\n",
            "[Step 5044/50000] [Progress: 10.09%] [learning rate: 2.7e+03]\n",
            "[Step 5069/50000] [Time: 56s] [Train Loss: 4.18e-01] [Train Acc: 0.84]\n",
            "[Step 5070/50000] [Progress: 10.14%] [learning rate: 2.6e+03]\n",
            "[Step 5096/50000] [Progress: 10.19%] [learning rate: 2.9e+03]\n",
            "[Step 5109/50000] [Time: 56s] [Train Loss: 4.18e-01] [Train Acc: 0.85]\n",
            "[Step 5120/50000] [Progress: 10.24%] [learning rate: 2.6e+03]\n",
            "[Step 5146/50000] [Progress: 10.29%] [learning rate: 3.1e+03]\n",
            "[Step 5150/50000] [Time: 57s] [Train Loss: 4.16e-01] [Train Acc: 0.85]\n",
            "[Step 5169/50000] [Progress: 10.34%] [learning rate: 2.5e+03]\n",
            "[Step 5191/50000] [Time: 57s] [Train Loss: 4.15e-01] [Train Acc: 0.85]\n",
            "[Step 5195/50000] [Progress: 10.39%] [learning rate: 2.7e+03]\n",
            "[Step 5221/50000] [Progress: 10.44%] [learning rate: 2.9e+03]\n",
            "[Step 5232/50000] [Time: 57s] [Train Loss: 4.14e-01] [Train Acc: 0.85]\n",
            "[Step 5244/50000] [Progress: 10.49%] [learning rate: 2.6e+03]\n",
            "[Step 5270/50000] [Progress: 10.54%] [learning rate: 2.8e+03]\n",
            "[Step 5273/50000] [Time: 57s] [Train Loss: 4.13e-01] [Train Acc: 0.85]\n",
            "[Step 5297/50000] [Progress: 10.59%] [learning rate: 3.1e+03]\n",
            "[Step 5314/50000] [Time: 58s] [Train Loss: 4.12e-01] [Train Acc: 0.85]\n",
            "[Step 5321/50000] [Progress: 10.64%] [learning rate: 2.8e+03]\n",
            "[Step 5346/50000] [Progress: 10.69%] [learning rate: 2.7e+03]\n",
            "[Step 5356/50000] [Time: 58s] [Train Loss: 4.11e-01] [Train Acc: 0.85]\n",
            "[Step 5372/50000] [Progress: 10.74%] [learning rate: 2.7e+03]\n",
            "[Step 5398/50000] [Time: 58s] [Train Loss: 4.10e-01] [Train Acc: 0.85]\n",
            "[Step 5399/50000] [Progress: 10.80%] [learning rate: 2.9e+03]\n",
            "[Step 5424/50000] [Progress: 10.85%] [learning rate: 2.9e+03]\n",
            "[Step 5440/50000] [Time: 59s] [Train Loss: 4.09e-01] [Train Acc: 0.85]\n",
            "[Step 5450/50000] [Progress: 10.90%] [learning rate: 3.4e+03]\n",
            "[Step 5470/50000] [Progress: 10.94%] [learning rate: 2.3e+03]\n",
            "[Step 5482/50000] [Time: 59s] [Train Loss: 4.08e-01] [Train Acc: 0.85]\n",
            "[Step 5498/50000] [Progress: 11.00%] [learning rate: 3.0e+03]\n",
            "[Step 5523/50000] [Progress: 11.05%] [learning rate: 2.7e+03]\n",
            "[Step 5525/50000] [Time: 59s] [Train Loss: 4.07e-01] [Train Acc: 0.85]\n",
            "[Step 5549/50000] [Progress: 11.10%] [learning rate: 2.9e+03]\n",
            "[Step 5568/50000] [Time: 59s] [Train Loss: 4.06e-01] [Train Acc: 0.85]\n",
            "[Step 5573/50000] [Progress: 11.15%] [learning rate: 2.9e+03]\n",
            "[Step 5598/50000] [Progress: 11.20%] [learning rate: 3.1e+03]\n",
            "[Step 5611/50000] [Time: 60s] [Train Loss: 4.05e-01] [Train Acc: 0.85]\n",
            "[Step 5621/50000] [Progress: 11.24%] [learning rate: 2.5e+03]\n",
            "[Step 5648/50000] [Progress: 11.30%] [learning rate: 3.0e+03]\n",
            "[Step 5654/50000] [Time: 60s] [Train Loss: 4.03e-01] [Train Acc: 0.85]\n",
            "[Step 5671/50000] [Progress: 11.34%] [learning rate: 2.7e+03]\n",
            "[Step 5696/50000] [Progress: 11.39%] [learning rate: 2.9e+03]\n",
            "[Step 5698/50000] [Time: 60s] [Train Loss: 4.02e-01] [Train Acc: 0.85]\n",
            "[Step 5720/50000] [Progress: 11.44%] [learning rate: 2.9e+03]\n",
            "[Step 5742/50000] [Time: 61s] [Train Loss: 4.01e-01] [Train Acc: 0.85]\n",
            "[Step 5745/50000] [Progress: 11.49%] [learning rate: 3.1e+03]\n",
            "[Step 5768/50000] [Progress: 11.54%] [learning rate: 2.5e+03]\n",
            "[Step 5786/50000] [Time: 61s] [Train Loss: 4.00e-01] [Train Acc: 0.85]\n",
            "[Step 5795/50000] [Progress: 11.59%] [learning rate: 3.0e+03]\n",
            "[Step 5818/50000] [Progress: 11.64%] [learning rate: 2.7e+03]\n",
            "[Step 5830/50000] [Time: 61s] [Train Loss: 3.99e-01] [Train Acc: 0.85]\n",
            "[Step 5843/50000] [Progress: 11.69%] [learning rate: 2.9e+03]\n",
            "[Step 5867/50000] [Progress: 11.73%] [learning rate: 2.9e+03]\n",
            "[Step 5875/50000] [Time: 62s] [Train Loss: 3.98e-01] [Train Acc: 0.85]\n",
            "[Step 5892/50000] [Progress: 11.78%] [learning rate: 2.8e+03]\n",
            "[Step 5916/50000] [Progress: 11.83%] [learning rate: 2.8e+03]\n",
            "[Step 5920/50000] [Time: 62s] [Train Loss: 3.97e-01] [Train Acc: 0.85]\n",
            "[Step 5941/50000] [Progress: 11.88%] [learning rate: 2.8e+03]\n",
            "[Step 5965/50000] [Time: 62s] [Train Loss: 3.96e-01] [Train Acc: 0.85]\n",
            "[Step 5967/50000] [Progress: 11.93%] [learning rate: 3.0e+03]\n",
            "[Step 5990/50000] [Progress: 11.98%] [learning rate: 2.7e+03]\n",
            "[Step 6010/50000] [Time: 62s] [Train Loss: 3.95e-01] [Train Acc: 0.85] [Eval Loss: 5.54e-01] [Eval Acc: 0.72]\n",
            "[Step 6016/50000] [Progress: 12.03%] [learning rate: 3.2e+03]\n",
            "[Step 6039/50000] [Progress: 12.08%] [learning rate: 2.6e+03]\n",
            "[Step 6056/50000] [Time: 64s] [Train Loss: 3.94e-01] [Train Acc: 0.86]\n",
            "[Step 6065/50000] [Progress: 12.13%] [learning rate: 2.8e+03]\n",
            "[Step 6089/50000] [Progress: 12.18%] [learning rate: 2.8e+03]\n",
            "[Step 6102/50000] [Time: 65s] [Train Loss: 3.93e-01] [Train Acc: 0.86]\n",
            "[Step 6114/50000] [Progress: 12.23%] [learning rate: 3.0e+03]\n",
            "[Step 6138/50000] [Progress: 12.28%] [learning rate: 2.7e+03]\n",
            "[Step 6148/50000] [Time: 65s] [Train Loss: 3.92e-01] [Train Acc: 0.86]\n",
            "[Step 6165/50000] [Progress: 12.33%] [learning rate: 3.2e+03]\n",
            "[Step 6188/50000] [Progress: 12.38%] [learning rate: 2.6e+03]\n",
            "[Step 6194/50000] [Time: 65s] [Train Loss: 3.91e-01] [Train Acc: 0.86]\n",
            "[Step 6214/50000] [Progress: 12.43%] [learning rate: 2.8e+03]\n",
            "[Step 6240/50000] [Progress: 12.48%] [learning rate: 3.1e+03]\n",
            "[Step 6241/50000] [Time: 66s] [Train Loss: 3.90e-01] [Train Acc: 0.86]\n",
            "[Step 6263/50000] [Progress: 12.53%] [learning rate: 2.5e+03]\n",
            "[Step 6288/50000] [Time: 66s] [Train Loss: 3.89e-01] [Train Acc: 0.86]\n",
            "[Step 6290/50000] [Progress: 12.58%] [learning rate: 3.0e+03]\n",
            "[Step 6316/50000] [Progress: 12.63%] [learning rate: 3.2e+03]\n",
            "[Step 6335/50000] [Time: 66s] [Train Loss: 3.88e-01] [Train Acc: 0.86]\n",
            "[Step 6339/50000] [Progress: 12.68%] [learning rate: 2.6e+03]\n",
            "[Step 6366/50000] [Progress: 12.73%] [learning rate: 3.1e+03]\n",
            "[Step 6382/50000] [Time: 67s] [Train Loss: 3.87e-01] [Train Acc: 0.86]\n",
            "[Step 6389/50000] [Progress: 12.78%] [learning rate: 2.8e+03]\n",
            "[Step 6414/50000] [Progress: 12.83%] [learning rate: 2.8e+03]\n",
            "[Step 6430/50000] [Time: 67s] [Train Loss: 3.86e-01] [Train Acc: 0.86]\n",
            "[Step 6439/50000] [Progress: 12.88%] [learning rate: 3.0e+03]\n",
            "[Step 6464/50000] [Progress: 12.93%] [learning rate: 2.9e+03]\n",
            "[Step 6478/50000] [Time: 67s] [Train Loss: 3.85e-01] [Train Acc: 0.86]\n",
            "[Step 6490/50000] [Progress: 12.98%] [learning rate: 2.9e+03]\n",
            "[Step 6514/50000] [Progress: 13.03%] [learning rate: 2.9e+03]\n",
            "[Step 6526/50000] [Time: 68s] [Train Loss: 3.84e-01] [Train Acc: 0.86]\n",
            "[Step 6539/50000] [Progress: 13.08%] [learning rate: 2.8e+03]\n",
            "[Step 6565/50000] [Progress: 13.13%] [learning rate: 3.0e+03]\n",
            "[Step 6574/50000] [Time: 68s] [Train Loss: 3.83e-01] [Train Acc: 0.86]\n",
            "[Step 6589/50000] [Progress: 13.18%] [learning rate: 2.7e+03]\n",
            "[Step 6615/50000] [Progress: 13.23%] [learning rate: 3.3e+03]\n",
            "[Step 6623/50000] [Time: 69s] [Train Loss: 3.82e-01] [Train Acc: 0.86]\n",
            "[Step 6638/50000] [Progress: 13.28%] [learning rate: 2.6e+03]\n",
            "[Step 6664/50000] [Progress: 13.33%] [learning rate: 2.9e+03]\n",
            "[Step 6672/50000] [Time: 69s] [Train Loss: 3.81e-01] [Train Acc: 0.86]\n",
            "[Step 6688/50000] [Progress: 13.38%] [learning rate: 2.8e+03]\n",
            "[Step 6713/50000] [Progress: 13.43%] [learning rate: 3.1e+03]\n",
            "[Step 6721/50000] [Time: 69s] [Train Loss: 3.80e-01] [Train Acc: 0.86]\n",
            "[Step 6737/50000] [Progress: 13.47%] [learning rate: 2.7e+03]\n",
            "[Step 6763/50000] [Progress: 13.53%] [learning rate: 3.3e+03]\n",
            "[Step 6770/50000] [Time: 70s] [Train Loss: 3.79e-01] [Train Acc: 0.86]\n",
            "[Step 6786/50000] [Progress: 13.57%] [learning rate: 2.7e+03]\n",
            "[Step 6812/50000] [Progress: 13.62%] [learning rate: 2.9e+03]\n",
            "[Step 6820/50000] [Time: 70s] [Train Loss: 3.78e-01] [Train Acc: 0.86]\n",
            "[Step 6837/50000] [Progress: 13.67%] [learning rate: 2.8e+03]\n",
            "[Step 6863/50000] [Progress: 13.73%] [learning rate: 3.1e+03]\n",
            "[Step 6870/50000] [Time: 70s] [Train Loss: 3.77e-01] [Train Acc: 0.86]\n",
            "[Step 6887/50000] [Progress: 13.77%] [learning rate: 2.8e+03]\n",
            "[Step 6914/50000] [Progress: 13.83%] [learning rate: 3.3e+03]\n",
            "[Step 6920/50000] [Time: 71s] [Train Loss: 3.76e-01] [Train Acc: 0.86]\n",
            "[Step 6938/50000] [Progress: 13.88%] [learning rate: 2.9e+03]\n",
            "[Step 6963/50000] [Progress: 13.93%] [learning rate: 2.9e+03]\n",
            "[Step 6970/50000] [Time: 71s] [Train Loss: 3.75e-01] [Train Acc: 0.86]\n",
            "[Step 6989/50000] [Progress: 13.98%] [learning rate: 3.1e+03]\n",
            "[Step 7012/50000] [Progress: 14.02%] [learning rate: 2.8e+03]\n",
            "[Step 7021/50000] [Time: 71s] [Train Loss: 3.74e-01] [Train Acc: 0.87]\n",
            "[Step 7038/50000] [Progress: 14.08%] [learning rate: 3.0e+03]\n",
            "[Step 7066/50000] [Progress: 14.13%] [learning rate: 3.6e+03]\n",
            "[Step 7072/50000] [Time: 72s] [Train Loss: 3.73e-01] [Train Acc: 0.87]\n",
            "[Step 7089/50000] [Progress: 14.18%] [learning rate: 3.0e+03]\n",
            "[Step 7114/50000] [Progress: 14.23%] [learning rate: 2.9e+03]\n",
            "[Step 7123/50000] [Time: 72s] [Train Loss: 3.72e-01] [Train Acc: 0.87]\n",
            "[Step 7140/50000] [Progress: 14.28%] [learning rate: 2.9e+03]\n",
            "[Step 7165/50000] [Progress: 14.33%] [learning rate: 2.8e+03]\n",
            "[Step 7174/50000] [Time: 72s] [Train Loss: 3.71e-01] [Train Acc: 0.87]\n",
            "[Step 7192/50000] [Progress: 14.38%] [learning rate: 3.4e+03]\n",
            "[Step 7216/50000] [Progress: 14.43%] [learning rate: 3.0e+03]\n",
            "[Step 7226/50000] [Time: 73s] [Train Loss: 3.70e-01] [Train Acc: 0.87]\n",
            "[Step 7242/50000] [Progress: 14.48%] [learning rate: 3.0e+03]\n",
            "[Step 7268/50000] [Progress: 14.54%] [learning rate: 2.9e+03]\n",
            "[Step 7278/50000] [Time: 73s] [Train Loss: 3.69e-01] [Train Acc: 0.87]\n",
            "[Step 7293/50000] [Progress: 14.59%] [learning rate: 2.9e+03]\n",
            "[Step 7319/50000] [Progress: 14.64%] [learning rate: 3.1e+03]\n",
            "[Step 7330/50000] [Time: 73s] [Train Loss: 3.68e-01] [Train Acc: 0.87]\n",
            "[Step 7343/50000] [Progress: 14.69%] [learning rate: 3.1e+03]\n",
            "[Step 7368/50000] [Progress: 14.74%] [learning rate: 3.3e+03]\n",
            "[Step 7382/50000] [Time: 74s] [Train Loss: 3.67e-01] [Train Acc: 0.87]\n",
            "[Step 7391/50000] [Progress: 14.78%] [learning rate: 2.7e+03]\n",
            "[Step 7418/50000] [Progress: 14.84%] [learning rate: 3.2e+03]\n",
            "[Step 7435/50000] [Time: 74s] [Train Loss: 3.66e-01] [Train Acc: 0.87]\n",
            "[Step 7441/50000] [Progress: 14.88%] [learning rate: 2.9e+03]\n",
            "[Step 7466/50000] [Progress: 14.93%] [learning rate: 3.1e+03]\n",
            "[Step 7488/50000] [Time: 75s] [Train Loss: 3.65e-01] [Train Acc: 0.87]\n",
            "[Step 7490/50000] [Progress: 14.98%] [learning rate: 3.1e+03]\n",
            "[Step 7515/50000] [Progress: 15.03%] [learning rate: 3.3e+03]\n",
            "[Step 7538/50000] [Progress: 15.08%] [learning rate: 2.7e+03]\n",
            "[Step 7541/50000] [Time: 75s] [Train Loss: 3.64e-01] [Train Acc: 0.87]\n",
            "[Step 7565/50000] [Progress: 15.13%] [learning rate: 3.2e+03]\n",
            "[Step 7588/50000] [Progress: 15.18%] [learning rate: 2.6e+03]\n",
            "[Step 7594/50000] [Time: 75s] [Train Loss: 3.63e-01] [Train Acc: 0.87]\n",
            "[Step 7615/50000] [Progress: 15.23%] [learning rate: 3.1e+03]\n",
            "[Step 7641/50000] [Progress: 15.28%] [learning rate: 3.1e+03]\n",
            "[Step 7648/50000] [Time: 76s] [Train Loss: 3.63e-01] [Train Acc: 0.87]\n",
            "[Step 7667/50000] [Progress: 15.33%] [learning rate: 3.4e+03]\n",
            "[Step 7690/50000] [Progress: 15.38%] [learning rate: 2.7e+03]\n",
            "[Step 7702/50000] [Time: 76s] [Train Loss: 3.62e-01] [Train Acc: 0.87]\n",
            "[Step 7717/50000] [Progress: 15.43%] [learning rate: 3.3e+03]\n",
            "[Step 7740/50000] [Progress: 15.48%] [learning rate: 2.9e+03]\n",
            "[Step 7756/50000] [Time: 76s] [Train Loss: 3.61e-01] [Train Acc: 0.87]\n",
            "[Step 7765/50000] [Progress: 15.53%] [learning rate: 3.2e+03]\n",
            "[Step 7789/50000] [Progress: 15.58%] [learning rate: 3.1e+03]\n",
            "[Step 7810/50000] [Time: 77s] [Train Loss: 3.60e-01] [Train Acc: 0.87]\n",
            "[Step 7814/50000] [Progress: 15.63%] [learning rate: 3.1e+03]\n",
            "[Step 7838/50000] [Progress: 15.68%] [learning rate: 3.0e+03]\n",
            "[Step 7863/50000] [Progress: 15.73%] [learning rate: 3.0e+03]\n",
            "[Step 7865/50000] [Time: 77s] [Train Loss: 3.59e-01] [Train Acc: 0.87]\n",
            "[Step 7889/50000] [Progress: 15.78%] [learning rate: 3.2e+03]\n",
            "[Step 7913/50000] [Progress: 15.83%] [learning rate: 2.9e+03]\n",
            "[Step 7920/50000] [Time: 78s] [Train Loss: 3.58e-01] [Train Acc: 0.87]\n",
            "[Step 7940/50000] [Progress: 15.88%] [learning rate: 3.1e+03]\n",
            "[Step 7965/50000] [Progress: 15.93%] [learning rate: 3.1e+03]\n",
            "[Step 7975/50000] [Time: 78s] [Train Loss: 3.57e-01] [Train Acc: 0.88]\n",
            "[Step 7991/50000] [Progress: 15.98%] [learning rate: 3.0e+03]\n",
            "[Step 8017/50000] [Progress: 16.03%] [learning rate: 3.0e+03]\n",
            "[Step 8030/50000] [Time: 78s] [Train Loss: 3.56e-01] [Train Acc: 0.88]\n",
            "[Step 8042/50000] [Progress: 16.08%] [learning rate: 2.9e+03]\n",
            "[Step 8069/50000] [Progress: 16.14%] [learning rate: 3.2e+03]\n",
            "[Step 8086/50000] [Time: 79s] [Train Loss: 3.55e-01] [Train Acc: 0.88]\n",
            "[Step 8095/50000] [Progress: 16.19%] [learning rate: 3.1e+03]\n",
            "[Step 8121/50000] [Progress: 16.24%] [learning rate: 3.1e+03]\n",
            "[Step 8142/50000] [Time: 79s] [Train Loss: 3.54e-01] [Train Acc: 0.88]\n",
            "[Step 8145/50000] [Progress: 16.29%] [learning rate: 3.0e+03]\n",
            "[Step 8170/50000] [Progress: 16.34%] [learning rate: 3.0e+03]\n",
            "[Step 8196/50000] [Progress: 16.39%] [learning rate: 3.2e+03]\n",
            "[Step 8198/50000] [Time: 79s] [Train Loss: 3.53e-01] [Train Acc: 0.88]\n",
            "[Step 8220/50000] [Progress: 16.44%] [learning rate: 2.9e+03]\n",
            "[Step 8247/50000] [Progress: 16.49%] [learning rate: 3.5e+03]\n",
            "[Step 8254/50000] [Time: 80s] [Train Loss: 3.52e-01] [Train Acc: 0.88]\n",
            "[Step 8270/50000] [Progress: 16.54%] [learning rate: 2.8e+03]\n",
            "[Step 8296/50000] [Progress: 16.59%] [learning rate: 3.1e+03]\n",
            "[Step 8311/50000] [Time: 80s] [Train Loss: 3.51e-01] [Train Acc: 0.88]\n",
            "[Step 8320/50000] [Progress: 16.64%] [learning rate: 3.0e+03]\n",
            "[Step 8345/50000] [Progress: 16.69%] [learning rate: 3.0e+03]\n",
            "[Step 8368/50000] [Time: 81s] [Train Loss: 3.50e-01] [Train Acc: 0.88]\n",
            "[Step 8370/50000] [Progress: 16.74%] [learning rate: 3.2e+03]\n",
            "[Step 8394/50000] [Progress: 16.79%] [learning rate: 3.2e+03]\n",
            "[Step 8419/50000] [Progress: 16.84%] [learning rate: 3.1e+03]\n",
            "[Step 8425/50000] [Time: 81s] [Train Loss: 3.50e-01] [Train Acc: 0.88]\n",
            "[Step 8445/50000] [Progress: 16.89%] [learning rate: 3.1e+03]\n",
            "[Step 8469/50000] [Progress: 16.94%] [learning rate: 3.0e+03]\n",
            "[Step 8482/50000] [Time: 82s] [Train Loss: 3.49e-01] [Train Acc: 0.88]\n",
            "[Step 8494/50000] [Progress: 16.99%] [learning rate: 3.3e+03]\n",
            "[Step 8518/50000] [Progress: 17.04%] [learning rate: 2.9e+03]\n",
            "[Step 8540/50000] [Time: 82s] [Train Loss: 3.48e-01] [Train Acc: 0.88]\n",
            "[Step 8545/50000] [Progress: 17.09%] [learning rate: 3.5e+03]\n",
            "[Step 8568/50000] [Progress: 17.14%] [learning rate: 2.8e+03]\n",
            "[Step 8595/50000] [Progress: 17.19%] [learning rate: 3.4e+03]\n",
            "[Step 8598/50000] [Time: 83s] [Train Loss: 3.47e-01] [Train Acc: 0.88] [Eval Loss: 5.34e-01] [Eval Acc: 0.74]\n",
            "[Step 8618/50000] [Progress: 17.24%] [learning rate: 3.0e+03]\n",
            "[Step 8643/50000] [Progress: 17.29%] [learning rate: 3.0e+03]\n",
            "[Step 8656/50000] [Time: 85s] [Train Loss: 3.46e-01] [Train Acc: 0.88]\n",
            "[Step 8670/50000] [Progress: 17.34%] [learning rate: 3.2e+03]\n",
            "[Step 8696/50000] [Progress: 17.39%] [learning rate: 3.2e+03]\n",
            "[Step 8714/50000] [Time: 85s] [Train Loss: 3.45e-01] [Train Acc: 0.88]\n",
            "[Step 8722/50000] [Progress: 17.44%] [learning rate: 3.5e+03]\n",
            "[Step 8745/50000] [Progress: 17.49%] [learning rate: 2.8e+03]\n",
            "[Step 8772/50000] [Progress: 17.54%] [learning rate: 3.4e+03]\n",
            "[Step 8773/50000] [Time: 85s] [Train Loss: 3.44e-01] [Train Acc: 0.88]\n",
            "[Step 8795/50000] [Progress: 17.59%] [learning rate: 3.0e+03]\n",
            "[Step 8821/50000] [Progress: 17.64%] [learning rate: 3.3e+03]\n",
            "[Step 8832/50000] [Time: 86s] [Train Loss: 3.43e-01] [Train Acc: 0.88]\n",
            "[Step 8847/50000] [Progress: 17.69%] [learning rate: 3.2e+03]\n",
            "[Step 8873/50000] [Progress: 17.75%] [learning rate: 3.5e+03]\n",
            "[Step 8891/50000] [Time: 86s] [Train Loss: 3.42e-01] [Train Acc: 0.88]\n",
            "[Step 8896/50000] [Progress: 17.79%] [learning rate: 2.8e+03]\n",
            "[Step 8923/50000] [Progress: 17.85%] [learning rate: 3.4e+03]\n",
            "[Step 8946/50000] [Progress: 17.89%] [learning rate: 3.0e+03]\n",
            "[Step 8950/50000] [Time: 87s] [Train Loss: 3.42e-01] [Train Acc: 0.88]\n",
            "[Step 8971/50000] [Progress: 17.94%] [learning rate: 3.3e+03]\n",
            "[Step 8996/50000] [Progress: 17.99%] [learning rate: 3.2e+03]\n",
            "[Step 9010/50000] [Time: 87s] [Train Loss: 3.41e-01] [Train Acc: 0.88]\n",
            "[Step 9022/50000] [Progress: 18.04%] [learning rate: 3.2e+03]\n",
            "[Step 9046/50000] [Progress: 18.09%] [learning rate: 3.1e+03]\n",
            "[Step 9070/50000] [Time: 87s] [Train Loss: 3.40e-01] [Train Acc: 0.88]\n",
            "[Step 9071/50000] [Progress: 18.14%] [learning rate: 3.1e+03]\n",
            "[Step 9097/50000] [Progress: 18.19%] [learning rate: 3.3e+03]\n",
            "[Step 9121/50000] [Progress: 18.24%] [learning rate: 3.0e+03]\n",
            "[Step 9130/50000] [Time: 88s] [Train Loss: 3.39e-01] [Train Acc: 0.88]\n",
            "[Step 9148/50000] [Progress: 18.30%] [learning rate: 3.6e+03]\n",
            "[Step 9171/50000] [Progress: 18.34%] [learning rate: 3.2e+03]\n",
            "[Step 9190/50000] [Time: 88s] [Train Loss: 3.38e-01] [Train Acc: 0.89]\n",
            "[Step 9195/50000] [Progress: 18.39%] [learning rate: 3.1e+03]\n",
            "[Step 9220/50000] [Progress: 18.44%] [learning rate: 3.1e+03]\n",
            "[Step 9245/50000] [Progress: 18.49%] [learning rate: 3.0e+03]\n",
            "[Step 9251/50000] [Time: 89s] [Train Loss: 3.37e-01] [Train Acc: 0.89]\n",
            "[Step 9272/50000] [Progress: 18.54%] [learning rate: 3.3e+03]\n",
            "[Step 9298/50000] [Progress: 18.60%] [learning rate: 3.3e+03]\n",
            "[Step 9312/50000] [Time: 89s] [Train Loss: 3.36e-01] [Train Acc: 0.89]\n",
            "[Step 9324/50000] [Progress: 18.65%] [learning rate: 3.5e+03]\n",
            "[Step 9347/50000] [Progress: 18.69%] [learning rate: 2.9e+03]\n",
            "[Step 9373/50000] [Time: 89s] [Train Loss: 3.35e-01] [Train Acc: 0.89]\n",
            "[Step 9374/50000] [Progress: 18.75%] [learning rate: 3.4e+03]\n",
            "[Step 9397/50000] [Progress: 18.79%] [learning rate: 3.1e+03]\n",
            "[Step 9423/50000] [Progress: 18.85%] [learning rate: 3.3e+03]\n",
            "[Step 9434/50000] [Time: 90s] [Train Loss: 3.35e-01] [Train Acc: 0.89]\n",
            "[Step 9449/50000] [Progress: 18.90%] [learning rate: 3.3e+03]\n",
            "[Step 9475/50000] [Progress: 18.95%] [learning rate: 3.5e+03]\n",
            "[Step 9496/50000] [Time: 90s] [Train Loss: 3.34e-01] [Train Acc: 0.89]\n",
            "[Step 9498/50000] [Progress: 19.00%] [learning rate: 2.9e+03]\n",
            "[Step 9525/50000] [Progress: 19.05%] [learning rate: 3.4e+03]\n",
            "[Step 9548/50000] [Progress: 19.10%] [learning rate: 3.1e+03]\n",
            "[Step 9558/50000] [Time: 91s] [Train Loss: 3.33e-01] [Train Acc: 0.89]\n",
            "[Step 9574/50000] [Progress: 19.15%] [learning rate: 3.3e+03]\n",
            "[Step 9600/50000] [Progress: 19.20%] [learning rate: 3.3e+03]\n",
            "[Step 9620/50000] [Time: 91s] [Train Loss: 3.32e-01] [Train Acc: 0.89]\n",
            "[Step 9626/50000] [Progress: 19.25%] [learning rate: 3.6e+03]\n",
            "[Step 9649/50000] [Progress: 19.30%] [learning rate: 2.9e+03]\n",
            "[Step 9676/50000] [Progress: 19.35%] [learning rate: 3.4e+03]\n",
            "[Step 9682/50000] [Time: 92s] [Train Loss: 3.31e-01] [Train Acc: 0.89]\n",
            "[Step 9699/50000] [Progress: 19.40%] [learning rate: 3.1e+03]\n",
            "[Step 9724/50000] [Progress: 19.45%] [learning rate: 3.3e+03]\n",
            "[Step 9745/50000] [Time: 92s] [Train Loss: 3.30e-01] [Train Acc: 0.89]\n",
            "[Step 9749/50000] [Progress: 19.50%] [learning rate: 3.3e+03]\n",
            "[Step 9775/50000] [Progress: 19.55%] [learning rate: 3.6e+03]\n",
            "[Step 9798/50000] [Progress: 19.60%] [learning rate: 2.9e+03]\n",
            "[Step 9808/50000] [Time: 92s] [Train Loss: 3.29e-01] [Train Acc: 0.89]\n",
            "[Step 9825/50000] [Progress: 19.65%] [learning rate: 3.5e+03]\n",
            "[Step 9848/50000] [Progress: 19.70%] [learning rate: 3.1e+03]\n",
            "[Step 9871/50000] [Time: 93s] [Train Loss: 3.29e-01] [Train Acc: 0.89]\n",
            "[Step 9874/50000] [Progress: 19.75%] [learning rate: 3.4e+03]\n",
            "[Step 9900/50000] [Progress: 19.80%] [learning rate: 3.3e+03]\n",
            "[Step 9926/50000] [Progress: 19.85%] [learning rate: 3.6e+03]\n",
            "[Step 9934/50000] [Time: 93s] [Train Loss: 3.28e-01] [Train Acc: 0.89]\n",
            "[Step 9949/50000] [Progress: 19.90%] [learning rate: 2.9e+03]\n",
            "[Step 9976/50000] [Progress: 19.95%] [learning rate: 3.5e+03]\n",
            "[Step 9997/50000] [Time: 94s] [Train Loss: 3.27e-01] [Train Acc: 0.89]\n",
            "[Step 9999/50000] [Progress: 20.00%] [learning rate: 3.1e+03]\n",
            "[Step 10025/50000] [Progress: 20.05%] [learning rate: 3.4e+03]\n",
            "[Step 10051/50000] [Progress: 20.10%] [learning rate: 3.3e+03]\n",
            "[Step 10061/50000] [Time: 94s] [Train Loss: 3.26e-01] [Train Acc: 0.89]\n",
            "[Step 10077/50000] [Progress: 20.15%] [learning rate: 3.6e+03]\n",
            "[Step 10100/50000] [Progress: 20.20%] [learning rate: 2.9e+03]\n",
            "[Step 10125/50000] [Time: 95s] [Train Loss: 3.25e-01] [Train Acc: 0.89]\n",
            "[Step 10127/50000] [Progress: 20.25%] [learning rate: 3.5e+03]\n",
            "[Step 10150/50000] [Progress: 20.30%] [learning rate: 3.1e+03]\n",
            "[Step 10176/50000] [Progress: 20.35%] [learning rate: 3.4e+03]\n",
            "[Step 10189/50000] [Time: 95s] [Train Loss: 3.24e-01] [Train Acc: 0.89]\n",
            "[Step 10202/50000] [Progress: 20.40%] [learning rate: 3.3e+03]\n",
            "[Step 10228/50000] [Progress: 20.46%] [learning rate: 3.6e+03]\n",
            "[Step 10251/50000] [Progress: 20.50%] [learning rate: 2.9e+03]\n",
            "[Step 10253/50000] [Time: 96s] [Train Loss: 3.24e-01] [Train Acc: 0.89]\n",
            "[Step 10278/50000] [Progress: 20.56%] [learning rate: 3.5e+03]\n",
            "[Step 10301/50000] [Progress: 20.60%] [learning rate: 3.1e+03]\n",
            "[Step 10318/50000] [Time: 96s] [Train Loss: 3.23e-01] [Train Acc: 0.89]\n",
            "[Step 10327/50000] [Progress: 20.65%] [learning rate: 3.4e+03]\n",
            "[Step 10353/50000] [Progress: 20.71%] [learning rate: 3.4e+03]\n",
            "[Step 10379/50000] [Progress: 20.76%] [learning rate: 3.6e+03]\n",
            "[Step 10383/50000] [Time: 97s] [Train Loss: 3.22e-01] [Train Acc: 0.89]\n",
            "[Step 10402/50000] [Progress: 20.80%] [learning rate: 3.0e+03]\n",
            "[Step 10429/50000] [Progress: 20.86%] [learning rate: 3.5e+03]\n",
            "[Step 10448/50000] [Time: 97s] [Train Loss: 3.21e-01] [Train Acc: 0.90]\n",
            "[Step 10452/50000] [Progress: 20.90%] [learning rate: 3.2e+03]\n",
            "[Step 10478/50000] [Progress: 20.96%] [learning rate: 3.4e+03]\n",
            "[Step 10504/50000] [Progress: 21.01%] [learning rate: 3.4e+03]\n",
            "[Step 10513/50000] [Time: 98s] [Train Loss: 3.20e-01] [Train Acc: 0.90]\n",
            "[Step 10530/50000] [Progress: 21.06%] [learning rate: 3.7e+03]\n",
            "[Step 10553/50000] [Progress: 21.11%] [learning rate: 3.0e+03]\n",
            "[Step 10579/50000] [Time: 98s] [Train Loss: 3.19e-01] [Train Acc: 0.90]\n",
            "[Step 10580/50000] [Progress: 21.16%] [learning rate: 3.5e+03]\n",
            "[Step 10603/50000] [Progress: 21.21%] [learning rate: 3.2e+03]\n",
            "[Step 10628/50000] [Progress: 21.26%] [learning rate: 3.4e+03]\n",
            "[Step 10645/50000] [Time: 98s] [Train Loss: 3.19e-01] [Train Acc: 0.90]\n",
            "[Step 10653/50000] [Progress: 21.31%] [learning rate: 3.4e+03]\n",
            "[Step 10679/50000] [Progress: 21.36%] [learning rate: 3.7e+03]\n",
            "[Step 10702/50000] [Progress: 21.40%] [learning rate: 3.0e+03]\n",
            "[Step 10711/50000] [Time: 99s] [Train Loss: 3.18e-01] [Train Acc: 0.90]\n",
            "[Step 10729/50000] [Progress: 21.46%] [learning rate: 3.6e+03]\n",
            "[Step 10752/50000] [Progress: 21.50%] [learning rate: 3.2e+03]\n",
            "[Step 10777/50000] [Time: 99s] [Train Loss: 3.17e-01] [Train Acc: 0.90]\n",
            "[Step 10778/50000] [Progress: 21.56%] [learning rate: 3.5e+03]\n",
            "[Step 10804/50000] [Progress: 21.61%] [learning rate: 3.4e+03]\n",
            "[Step 10830/50000] [Progress: 21.66%] [learning rate: 3.7e+03]\n",
            "[Step 10843/50000] [Time: 100s] [Train Loss: 3.16e-01] [Train Acc: 0.90]\n",
            "[Step 10853/50000] [Progress: 21.71%] [learning rate: 3.0e+03]\n",
            "[Step 10880/50000] [Progress: 21.76%] [learning rate: 3.6e+03]\n",
            "[Step 10903/50000] [Progress: 21.81%] [learning rate: 3.2e+03]\n",
            "[Step 10910/50000] [Time: 100s] [Train Loss: 3.15e-01] [Train Acc: 0.90]\n",
            "[Step 10928/50000] [Progress: 21.86%] [learning rate: 3.5e+03]\n",
            "[Step 10953/50000] [Progress: 21.91%] [learning rate: 3.4e+03]\n",
            "[Step 10977/50000] [Time: 101s] [Train Loss: 3.15e-01] [Train Acc: 0.90]\n",
            "[Step 10979/50000] [Progress: 21.96%] [learning rate: 3.7e+03]\n",
            "[Step 11002/50000] [Progress: 22.00%] [learning rate: 3.0e+03]\n",
            "[Step 11029/50000] [Progress: 22.06%] [learning rate: 3.6e+03]\n",
            "[Step 11044/50000] [Time: 101s] [Train Loss: 3.14e-01] [Train Acc: 0.90]\n",
            "[Step 11052/50000] [Progress: 22.10%] [learning rate: 3.2e+03]\n",
            "[Step 11077/50000] [Progress: 22.15%] [learning rate: 3.5e+03]\n",
            "[Step 11102/50000] [Progress: 22.20%] [learning rate: 3.4e+03]\n",
            "[Step 11111/50000] [Time: 102s] [Train Loss: 3.13e-01] [Train Acc: 0.90]\n",
            "[Step 11128/50000] [Progress: 22.26%] [learning rate: 3.4e+03]\n",
            "[Step 11152/50000] [Progress: 22.30%] [learning rate: 3.3e+03]\n",
            "[Step 11177/50000] [Progress: 22.35%] [learning rate: 3.3e+03]\n",
            "[Step 11179/50000] [Time: 102s] [Train Loss: 3.12e-01] [Train Acc: 0.90]\n",
            "[Step 11203/50000] [Progress: 22.41%] [learning rate: 3.6e+03]\n",
            "[Step 11227/50000] [Progress: 22.45%] [learning rate: 3.2e+03]\n",
            "[Step 11247/50000] [Time: 103s] [Train Loss: 3.11e-01] [Train Acc: 0.90]\n",
            "[Step 11254/50000] [Progress: 22.51%] [learning rate: 3.8e+03]\n",
            "[Step 11277/50000] [Progress: 22.55%] [learning rate: 3.1e+03]\n",
            "[Step 11303/50000] [Progress: 22.61%] [learning rate: 3.3e+03]\n",
            "[Step 11315/50000] [Time: 103s] [Train Loss: 3.11e-01] [Train Acc: 0.90]\n",
            "[Step 11327/50000] [Progress: 22.65%] [learning rate: 3.3e+03]\n",
            "[Step 11352/50000] [Progress: 22.70%] [learning rate: 3.6e+03]\n",
            "[Step 11376/50000] [Progress: 22.75%] [learning rate: 3.2e+03]\n",
            "[Step 11383/50000] [Time: 104s] [Train Loss: 3.10e-01] [Train Acc: 0.90]\n",
            "[Step 11403/50000] [Progress: 22.81%] [learning rate: 3.8e+03]\n",
            "[Step 11426/50000] [Progress: 22.85%] [learning rate: 3.1e+03]\n",
            "[Step 11451/50000] [Time: 104s] [Train Loss: 3.09e-01] [Train Acc: 0.90]\n",
            "[Step 11452/50000] [Progress: 22.90%] [learning rate: 3.4e+03]\n",
            "[Step 11478/50000] [Progress: 22.96%] [learning rate: 3.6e+03]\n",
            "[Step 11501/50000] [Progress: 23.00%] [learning rate: 3.0e+03]\n",
            "[Step 11520/50000] [Time: 104s] [Train Loss: 3.08e-01] [Train Acc: 0.90]\n",
            "[Step 11528/50000] [Progress: 23.06%] [learning rate: 3.5e+03]\n",
            "[Step 11554/50000] [Progress: 23.11%] [learning rate: 3.5e+03]\n",
            "[Step 11580/50000] [Progress: 23.16%] [learning rate: 3.8e+03]\n",
            "[Step 11589/50000] [Time: 105s] [Train Loss: 3.08e-01] [Train Acc: 0.91]\n",
            "[Step 11603/50000] [Progress: 23.21%] [learning rate: 3.1e+03]\n",
            "[Step 11630/50000] [Progress: 23.26%] [learning rate: 3.7e+03]\n",
            "[Step 11653/50000] [Progress: 23.31%] [learning rate: 3.3e+03]\n",
            "[Step 11658/50000] [Time: 105s] [Train Loss: 3.07e-01] [Train Acc: 0.91]\n",
            "[Step 11679/50000] [Progress: 23.36%] [learning rate: 3.5e+03]\n",
            "[Step 11705/50000] [Progress: 23.41%] [learning rate: 3.5e+03]\n",
            "[Step 11727/50000] [Time: 106s] [Train Loss: 3.06e-01] [Train Acc: 0.91]\n",
            "[Step 11731/50000] [Progress: 23.46%] [learning rate: 3.4e+03]\n",
            "[Step 11755/50000] [Progress: 23.51%] [learning rate: 3.4e+03]\n",
            "[Step 11780/50000] [Progress: 23.56%] [learning rate: 3.3e+03]\n",
            "[Step 11797/50000] [Time: 106s] [Train Loss: 3.05e-01] [Train Acc: 0.91] [Eval Loss: 5.19e-01] [Eval Acc: 0.75]\n",
            "[Step 11806/50000] [Progress: 23.61%] [learning rate: 3.6e+03]\n",
            "[Step 11830/50000] [Progress: 23.66%] [learning rate: 3.2e+03]\n",
            "[Step 11857/50000] [Progress: 23.71%] [learning rate: 3.9e+03]\n",
            "[Step 11867/50000] [Time: 109s] [Train Loss: 3.04e-01] [Train Acc: 0.91]\n",
            "[Step 11880/50000] [Progress: 23.76%] [learning rate: 3.1e+03]\n",
            "[Step 11906/50000] [Progress: 23.81%] [learning rate: 3.4e+03]\n",
            "[Step 11932/50000] [Progress: 23.86%] [learning rate: 3.7e+03]\n",
            "[Step 11937/50000] [Time: 109s] [Train Loss: 3.04e-01] [Train Acc: 0.91]\n",
            "[Step 11955/50000] [Progress: 23.91%] [learning rate: 3.0e+03]\n",
            "[Step 11982/50000] [Progress: 23.96%] [learning rate: 3.6e+03]\n",
            "[Step 12007/50000] [Time: 110s] [Train Loss: 3.03e-01] [Train Acc: 0.91]\n",
            "[Step 12008/50000] [Progress: 24.02%] [learning rate: 3.5e+03]\n",
            "[Step 12034/50000] [Progress: 24.07%] [learning rate: 3.8e+03]\n",
            "[Step 12057/50000] [Progress: 24.11%] [learning rate: 3.1e+03]\n",
            "[Step 12077/50000] [Time: 110s] [Train Loss: 3.02e-01] [Train Acc: 0.91]\n",
            "[Step 12084/50000] [Progress: 24.17%] [learning rate: 3.7e+03]\n",
            "[Step 12107/50000] [Progress: 24.21%] [learning rate: 3.3e+03]\n",
            "[Step 12132/50000] [Progress: 24.26%] [learning rate: 3.6e+03]\n",
            "[Step 12148/50000] [Time: 111s] [Train Loss: 3.01e-01] [Train Acc: 0.91]\n",
            "[Step 12156/50000] [Progress: 24.31%] [learning rate: 3.5e+03]\n",
            "[Step 12181/50000] [Progress: 24.36%] [learning rate: 3.5e+03]\n",
            "[Step 12205/50000] [Progress: 24.41%] [learning rate: 3.4e+03]\n",
            "[Step 12219/50000] [Time: 111s] [Train Loss: 3.01e-01] [Train Acc: 0.91]\n",
            "[Step 12230/50000] [Progress: 24.46%] [learning rate: 3.4e+03]\n",
            "[Step 12256/50000] [Progress: 24.51%] [learning rate: 3.7e+03]\n",
            "[Step 12280/50000] [Progress: 24.56%] [learning rate: 3.3e+03]\n",
            "[Step 12290/50000] [Time: 112s] [Train Loss: 3.00e-01] [Train Acc: 0.91]\n",
            "[Step 12307/50000] [Progress: 24.61%] [learning rate: 3.6e+03]\n",
            "[Step 12332/50000] [Progress: 24.66%] [learning rate: 3.5e+03]\n",
            "[Step 12358/50000] [Progress: 24.72%] [learning rate: 3.4e+03]\n",
            "[Step 12361/50000] [Time: 112s] [Train Loss: 2.99e-01] [Train Acc: 0.91]\n",
            "[Step 12384/50000] [Progress: 24.77%] [learning rate: 3.4e+03]\n",
            "[Step 12409/50000] [Progress: 24.82%] [learning rate: 3.3e+03]\n",
            "[Step 12432/50000] [Time: 113s] [Train Loss: 2.98e-01] [Train Acc: 0.91]\n",
            "[Step 12436/50000] [Progress: 24.87%] [learning rate: 3.6e+03]\n",
            "[Step 12461/50000] [Progress: 24.92%] [learning rate: 3.6e+03]\n",
            "[Step 12486/50000] [Progress: 24.97%] [learning rate: 3.9e+03]\n",
            "[Step 12504/50000] [Time: 113s] [Train Loss: 2.98e-01] [Train Acc: 0.91]\n",
            "[Step 12509/50000] [Progress: 25.02%] [learning rate: 3.1e+03]\n",
            "[Step 12536/50000] [Progress: 25.07%] [learning rate: 3.8e+03]\n",
            "[Step 12559/50000] [Progress: 25.12%] [learning rate: 3.4e+03]\n",
            "[Step 12576/50000] [Time: 114s] [Train Loss: 2.97e-01] [Train Acc: 0.91]\n",
            "[Step 12584/50000] [Progress: 25.17%] [learning rate: 3.6e+03]\n",
            "[Step 12608/50000] [Progress: 25.22%] [learning rate: 3.6e+03]\n",
            "[Step 12633/50000] [Progress: 25.27%] [learning rate: 3.5e+03]\n",
            "[Step 12648/50000] [Time: 114s] [Train Loss: 2.96e-01] [Train Acc: 0.91]\n",
            "[Step 12657/50000] [Progress: 25.31%] [learning rate: 3.5e+03]\n",
            "[Step 12682/50000] [Progress: 25.36%] [learning rate: 3.4e+03]\n",
            "[Step 12708/50000] [Progress: 25.42%] [learning rate: 3.7e+03]\n",
            "[Step 12720/50000] [Time: 115s] [Train Loss: 2.96e-01] [Train Acc: 0.91]\n",
            "[Step 12731/50000] [Progress: 25.46%] [learning rate: 3.3e+03]\n",
            "[Step 12757/50000] [Progress: 25.51%] [learning rate: 3.6e+03]\n",
            "[Step 12782/50000] [Progress: 25.56%] [learning rate: 3.5e+03]\n",
            "[Step 12792/50000] [Time: 115s] [Train Loss: 2.95e-01] [Train Acc: 0.91]\n",
            "[Step 12806/50000] [Progress: 25.61%] [learning rate: 3.5e+03]\n",
            "[Step 12831/50000] [Progress: 25.66%] [learning rate: 3.4e+03]\n",
            "[Step 12857/50000] [Progress: 25.71%] [learning rate: 3.4e+03]\n",
            "[Step 12865/50000] [Time: 116s] [Train Loss: 2.94e-01] [Train Acc: 0.91]\n",
            "[Step 12882/50000] [Progress: 25.76%] [learning rate: 3.3e+03]\n",
            "[Step 12908/50000] [Progress: 25.82%] [learning rate: 3.6e+03]\n",
            "[Step 12935/50000] [Progress: 25.87%] [learning rate: 3.9e+03]\n",
            "[Step 12938/50000] [Time: 116s] [Train Loss: 2.93e-01] [Train Acc: 0.91]\n",
            "[Step 12959/50000] [Progress: 25.92%] [learning rate: 3.5e+03]\n",
            "[Step 12984/50000] [Progress: 25.97%] [learning rate: 3.5e+03]\n",
            "[Step 13010/50000] [Progress: 26.02%] [learning rate: 3.4e+03]\n",
            "[Step 13011/50000] [Time: 117s] [Train Loss: 2.93e-01] [Train Acc: 0.91]\n",
            "[Step 13035/50000] [Progress: 26.07%] [learning rate: 3.4e+03]\n",
            "[Step 13062/50000] [Progress: 26.12%] [learning rate: 4.0e+03]\n",
            "[Step 13084/50000] [Time: 117s] [Train Loss: 2.92e-01] [Train Acc: 0.91]\n",
            "[Step 13085/50000] [Progress: 26.17%] [learning rate: 3.6e+03]\n",
            "[Step 13110/50000] [Progress: 26.22%] [learning rate: 3.5e+03]\n",
            "[Step 13136/50000] [Progress: 26.27%] [learning rate: 3.5e+03]\n",
            "[Step 13157/50000] [Time: 118s] [Train Loss: 2.91e-01] [Train Acc: 0.91]\n",
            "[Step 13161/50000] [Progress: 26.32%] [learning rate: 3.4e+03]\n",
            "[Step 13187/50000] [Progress: 26.37%] [learning rate: 3.7e+03]\n",
            "[Step 13211/50000] [Progress: 26.42%] [learning rate: 3.7e+03]\n",
            "[Step 13231/50000] [Time: 118s] [Train Loss: 2.90e-01] [Train Acc: 0.91]\n",
            "[Step 13237/50000] [Progress: 26.47%] [learning rate: 4.0e+03]\n",
            "[Step 13261/50000] [Progress: 26.52%] [learning rate: 3.5e+03]\n",
            "[Step 13286/50000] [Progress: 26.57%] [learning rate: 3.5e+03]\n",
            "[Step 13305/50000] [Time: 119s] [Train Loss: 2.90e-01] [Train Acc: 0.91]\n",
            "[Step 13312/50000] [Progress: 26.62%] [learning rate: 3.4e+03]\n",
            "[Step 13337/50000] [Progress: 26.67%] [learning rate: 3.4e+03]\n",
            "[Step 13364/50000] [Progress: 26.73%] [learning rate: 4.0e+03]\n",
            "[Step 13379/50000] [Time: 120s] [Train Loss: 2.89e-01] [Train Acc: 0.91]\n",
            "[Step 13388/50000] [Progress: 26.78%] [learning rate: 4.0e+03]\n",
            "[Step 13411/50000] [Progress: 26.82%] [learning rate: 3.2e+03]\n",
            "[Step 13437/50000] [Progress: 26.87%] [learning rate: 3.5e+03]\n",
            "[Step 13453/50000] [Time: 120s] [Train Loss: 2.88e-01] [Train Acc: 0.91]\n",
            "[Step 13461/50000] [Progress: 26.92%] [learning rate: 3.5e+03]\n",
            "[Step 13486/50000] [Progress: 26.97%] [learning rate: 3.7e+03]\n",
            "[Step 13510/50000] [Progress: 27.02%] [learning rate: 3.3e+03]\n",
            "[Step 13527/50000] [Time: 121s] [Train Loss: 2.88e-01] [Train Acc: 0.91]\n",
            "[Step 13537/50000] [Progress: 27.07%] [learning rate: 4.4e+03]\n",
            "[Step 13558/50000] [Progress: 27.12%] [learning rate: 3.0e+03]\n",
            "[Step 13587/50000] [Progress: 27.17%] [learning rate: 3.9e+03]\n",
            "[Step 13602/50000] [Time: 121s] [Train Loss: 2.87e-01] [Train Acc: 0.91]\n",
            "[Step 13612/50000] [Progress: 27.22%] [learning rate: 3.5e+03]\n",
            "[Step 13638/50000] [Progress: 27.28%] [learning rate: 3.8e+03]\n",
            "[Step 13662/50000] [Progress: 27.32%] [learning rate: 3.4e+03]\n",
            "[Step 13677/50000] [Time: 122s] [Train Loss: 2.86e-01] [Train Acc: 0.91]\n",
            "[Step 13689/50000] [Progress: 27.38%] [learning rate: 4.0e+03]\n",
            "[Step 13714/50000] [Progress: 27.43%] [learning rate: 3.6e+03]\n",
            "[Step 13740/50000] [Progress: 27.48%] [learning rate: 3.5e+03]\n",
            "[Step 13752/50000] [Time: 122s] [Train Loss: 2.85e-01] [Train Acc: 0.91]\n",
            "[Step 13766/50000] [Progress: 27.53%] [learning rate: 3.5e+03]\n",
            "[Step 13791/50000] [Progress: 27.58%] [learning rate: 3.4e+03]\n",
            "[Step 13816/50000] [Progress: 27.63%] [learning rate: 3.7e+03]\n",
            "[Step 13827/50000] [Time: 123s] [Train Loss: 2.85e-01] [Train Acc: 0.91]\n",
            "[Step 13841/50000] [Progress: 27.68%] [learning rate: 4.0e+03]\n",
            "[Step 13864/50000] [Progress: 27.73%] [learning rate: 3.3e+03]\n",
            "[Step 13891/50000] [Progress: 27.78%] [learning rate: 3.9e+03]\n",
            "[Step 13902/50000] [Time: 123s] [Train Loss: 2.84e-01] [Train Acc: 0.91]\n",
            "[Step 13914/50000] [Progress: 27.83%] [learning rate: 3.5e+03]\n",
            "[Step 13939/50000] [Progress: 27.88%] [learning rate: 3.4e+03]\n",
            "[Step 13964/50000] [Progress: 27.93%] [learning rate: 3.7e+03]\n",
            "[Step 13978/50000] [Time: 124s] [Train Loss: 2.83e-01] [Train Acc: 0.91]\n",
            "[Step 13989/50000] [Progress: 27.98%] [learning rate: 4.0e+03]\n",
            "[Step 14012/50000] [Progress: 28.02%] [learning rate: 3.3e+03]\n",
            "[Step 14039/50000] [Progress: 28.08%] [learning rate: 3.9e+03]\n",
            "[Step 14054/50000] [Time: 124s] [Train Loss: 2.83e-01] [Train Acc: 0.92]\n",
            "[Step 14062/50000] [Progress: 28.12%] [learning rate: 3.5e+03]\n",
            "[Step 14087/50000] [Progress: 28.17%] [learning rate: 3.5e+03]\n",
            "[Step 14112/50000] [Progress: 28.22%] [learning rate: 3.8e+03]\n",
            "[Step 14130/50000] [Time: 125s] [Train Loss: 2.82e-01] [Train Acc: 0.92]\n",
            "[Step 14137/50000] [Progress: 28.27%] [learning rate: 3.7e+03]\n",
            "[Step 14163/50000] [Progress: 28.33%] [learning rate: 4.0e+03]\n",
            "[Step 14186/50000] [Progress: 28.37%] [learning rate: 3.3e+03]\n",
            "[Step 14206/50000] [Time: 126s] [Train Loss: 2.81e-01] [Train Acc: 0.92]\n",
            "[Step 14213/50000] [Progress: 28.43%] [learning rate: 3.9e+03]\n",
            "[Step 14236/50000] [Progress: 28.47%] [learning rate: 3.5e+03]\n",
            "[Step 14262/50000] [Progress: 28.52%] [learning rate: 3.8e+03]\n",
            "[Step 14282/50000] [Time: 126s] [Train Loss: 2.81e-01] [Train Acc: 0.92]\n",
            "[Step 14288/50000] [Progress: 28.58%] [learning rate: 4.1e+03]\n",
            "[Step 14311/50000] [Progress: 28.62%] [learning rate: 3.3e+03]\n",
            "[Step 14338/50000] [Progress: 28.68%] [learning rate: 4.0e+03]\n",
            "[Step 14359/50000] [Time: 127s] [Train Loss: 2.80e-01] [Train Acc: 0.92]\n",
            "[Step 14361/50000] [Progress: 28.72%] [learning rate: 3.2e+03]\n",
            "[Step 14387/50000] [Progress: 28.77%] [learning rate: 3.8e+03]\n",
            "[Step 14411/50000] [Progress: 28.82%] [learning rate: 3.4e+03]\n",
            "[Step 14436/50000] [Time: 127s] [Train Loss: 2.79e-01] [Train Acc: 0.92]\n",
            "[Step 14437/50000] [Progress: 28.87%] [learning rate: 4.1e+03]\n",
            "[Step 14460/50000] [Progress: 28.92%] [learning rate: 3.3e+03]\n",
            "[Step 14487/50000] [Progress: 28.97%] [learning rate: 4.0e+03]\n",
            "[Step 14510/50000] [Progress: 29.02%] [learning rate: 3.2e+03]\n",
            "[Step 14513/50000] [Time: 128s] [Train Loss: 2.79e-01] [Train Acc: 0.92]\n",
            "[Step 14536/50000] [Progress: 29.07%] [learning rate: 3.9e+03]\n",
            "[Step 14560/50000] [Progress: 29.12%] [learning rate: 3.5e+03]\n",
            "[Step 14588/50000] [Progress: 29.18%] [learning rate: 4.1e+03]\n",
            "[Step 14590/50000] [Time: 128s] [Train Loss: 2.78e-01] [Train Acc: 0.92]\n",
            "[Step 14612/50000] [Progress: 29.22%] [learning rate: 3.7e+03]\n",
            "[Step 14637/50000] [Progress: 29.27%] [learning rate: 3.6e+03]\n",
            "[Step 14663/50000] [Progress: 29.33%] [learning rate: 3.6e+03]\n",
            "[Step 14667/50000] [Time: 129s] [Train Loss: 2.77e-01] [Train Acc: 0.92]\n",
            "[Step 14688/50000] [Progress: 29.38%] [learning rate: 3.5e+03]\n",
            "[Step 14715/50000] [Progress: 29.43%] [learning rate: 3.8e+03]\n",
            "[Step 14741/50000] [Progress: 29.48%] [learning rate: 3.8e+03]\n",
            "[Step 14744/50000] [Time: 129s] [Train Loss: 2.76e-01] [Train Acc: 0.92]\n",
            "[Step 14767/50000] [Progress: 29.53%] [learning rate: 4.1e+03]\n",
            "[Step 14790/50000] [Progress: 29.58%] [learning rate: 3.3e+03]\n",
            "[Step 14817/50000] [Progress: 29.63%] [learning rate: 4.0e+03]\n",
            "[Step 14822/50000] [Time: 130s] [Train Loss: 2.76e-01] [Train Acc: 0.92]\n",
            "[Step 14840/50000] [Progress: 29.68%] [learning rate: 3.5e+03]\n",
            "[Step 14865/50000] [Progress: 29.73%] [learning rate: 3.8e+03]\n",
            "[Step 14890/50000] [Progress: 29.78%] [learning rate: 3.8e+03]\n",
            "[Step 14900/50000] [Time: 130s] [Train Loss: 2.75e-01] [Train Acc: 0.92]\n",
            "[Step 14916/50000] [Progress: 29.83%] [learning rate: 3.7e+03]\n",
            "[Step 14940/50000] [Progress: 29.88%] [learning rate: 3.7e+03]\n",
            "[Step 14965/50000] [Progress: 29.93%] [learning rate: 3.6e+03]\n",
            "[Step 14978/50000] [Time: 131s] [Train Loss: 2.75e-01] [Train Acc: 0.92]\n",
            "[Step 14991/50000] [Progress: 29.98%] [learning rate: 3.9e+03]\n",
            "[Step 15015/50000] [Progress: 30.03%] [learning rate: 3.5e+03]\n",
            "[Step 15042/50000] [Progress: 30.08%] [learning rate: 4.2e+03]\n",
            "[Step 15056/50000] [Time: 131s] [Train Loss: 2.74e-01] [Train Acc: 0.92]\n",
            "[Step 15065/50000] [Progress: 30.13%] [learning rate: 3.4e+03]\n",
            "[Step 15091/50000] [Progress: 30.18%] [learning rate: 3.7e+03]\n",
            "[Step 15117/50000] [Progress: 30.23%] [learning rate: 4.0e+03]\n",
            "[Step 15134/50000] [Time: 132s] [Train Loss: 2.73e-01] [Train Acc: 0.92]\n",
            "[Step 15140/50000] [Progress: 30.28%] [learning rate: 3.2e+03]\n",
            "[Step 15167/50000] [Progress: 30.33%] [learning rate: 3.9e+03]\n",
            "[Step 15193/50000] [Progress: 30.39%] [learning rate: 3.8e+03]\n",
            "[Step 15212/50000] [Time: 133s] [Train Loss: 2.73e-01] [Train Acc: 0.92]\n",
            "[Step 15219/50000] [Progress: 30.44%] [learning rate: 4.1e+03]\n",
            "[Step 15242/50000] [Progress: 30.48%] [learning rate: 3.4e+03]\n",
            "[Step 15269/50000] [Progress: 30.54%] [learning rate: 4.0e+03]\n",
            "[Step 15291/50000] [Time: 133s] [Train Loss: 2.72e-01] [Train Acc: 0.92]\n",
            "[Step 15292/50000] [Progress: 30.58%] [learning rate: 3.6e+03]\n",
            "[Step 15317/50000] [Progress: 30.63%] [learning rate: 3.9e+03]\n",
            "[Step 15341/50000] [Progress: 30.68%] [learning rate: 3.8e+03]\n",
            "[Step 15366/50000] [Progress: 30.73%] [learning rate: 3.8e+03]\n",
            "[Step 15370/50000] [Time: 134s] [Train Loss: 2.71e-01] [Train Acc: 0.92]\n",
            "[Step 15390/50000] [Progress: 30.78%] [learning rate: 3.7e+03]\n",
            "[Step 15415/50000] [Progress: 30.83%] [learning rate: 3.7e+03]\n",
            "[Step 15441/50000] [Progress: 30.88%] [learning rate: 4.0e+03]\n",
            "[Step 15449/50000] [Time: 134s] [Train Loss: 2.71e-01] [Train Acc: 0.92]\n",
            "[Step 15464/50000] [Progress: 30.93%] [learning rate: 3.5e+03]\n",
            "[Step 15490/50000] [Progress: 30.98%] [learning rate: 3.8e+03]\n",
            "[Step 15515/50000] [Progress: 31.03%] [learning rate: 3.8e+03]\n",
            "[Step 15528/50000] [Time: 135s] [Train Loss: 2.70e-01] [Train Acc: 0.92] [Eval Loss: 5.11e-01] [Eval Acc: 0.76]\n",
            "[Step 15539/50000] [Progress: 31.08%] [learning rate: 3.7e+03]\n",
            "[Step 15564/50000] [Progress: 31.13%] [learning rate: 3.7e+03]\n",
            "[Step 15590/50000] [Progress: 31.18%] [learning rate: 3.6e+03]\n",
            "[Step 15607/50000] [Time: 137s] [Train Loss: 2.69e-01] [Train Acc: 0.92]\n",
            "[Step 15615/50000] [Progress: 31.23%] [learning rate: 3.6e+03]\n",
            "[Step 15641/50000] [Progress: 31.28%] [learning rate: 3.9e+03]\n",
            "[Step 15668/50000] [Progress: 31.34%] [learning rate: 4.2e+03]\n",
            "[Step 15687/50000] [Time: 138s] [Train Loss: 2.69e-01] [Train Acc: 0.92]\n",
            "[Step 15692/50000] [Progress: 31.38%] [learning rate: 3.7e+03]\n",
            "[Step 15717/50000] [Progress: 31.43%] [learning rate: 3.7e+03]\n",
            "[Step 15743/50000] [Progress: 31.49%] [learning rate: 3.6e+03]\n",
            "[Step 15767/50000] [Time: 138s] [Train Loss: 2.68e-01] [Train Acc: 0.92]\n",
            "[Step 15768/50000] [Progress: 31.54%] [learning rate: 3.6e+03]\n",
            "[Step 15793/50000] [Progress: 31.59%] [learning rate: 3.9e+03]\n",
            "[Step 15819/50000] [Progress: 31.64%] [learning rate: 4.6e+03]\n",
            "[Step 15839/50000] [Progress: 31.68%] [learning rate: 3.1e+03]\n",
            "[Step 15847/50000] [Time: 139s] [Train Loss: 2.67e-01] [Train Acc: 0.92]\n",
            "[Step 15867/50000] [Progress: 31.73%] [learning rate: 4.1e+03]\n",
            "[Step 15892/50000] [Progress: 31.78%] [learning rate: 3.7e+03]\n",
            "[Step 15918/50000] [Progress: 31.84%] [learning rate: 4.0e+03]\n",
            "[Step 15927/50000] [Time: 139s] [Train Loss: 2.67e-01] [Train Acc: 0.92]\n",
            "[Step 15942/50000] [Progress: 31.88%] [learning rate: 3.5e+03]\n",
            "[Step 15969/50000] [Progress: 31.94%] [learning rate: 4.6e+03]\n",
            "[Step 15990/50000] [Progress: 31.98%] [learning rate: 3.1e+03]\n",
            "[Step 16007/50000] [Time: 140s] [Train Loss: 2.66e-01] [Train Acc: 0.92]\n",
            "[Step 16019/50000] [Progress: 32.04%] [learning rate: 4.1e+03]\n",
            "[Step 16044/50000] [Progress: 32.09%] [learning rate: 3.7e+03]\n",
            "[Step 16070/50000] [Progress: 32.14%] [learning rate: 4.0e+03]\n",
            "[Step 16087/50000] [Time: 140s] [Train Loss: 2.65e-01] [Train Acc: 0.92]\n",
            "[Step 16094/50000] [Progress: 32.19%] [learning rate: 3.6e+03]\n",
            "[Step 16122/50000] [Progress: 32.24%] [learning rate: 4.7e+03]\n",
            "[Step 16143/50000] [Progress: 32.29%] [learning rate: 3.1e+03]\n",
            "[Step 16167/50000] [Time: 141s] [Train Loss: 2.65e-01] [Train Acc: 0.92]\n",
            "[Step 16172/50000] [Progress: 32.34%] [learning rate: 4.1e+03]\n",
            "[Step 16197/50000] [Progress: 32.39%] [learning rate: 3.7e+03]\n",
            "[Step 16223/50000] [Progress: 32.45%] [learning rate: 4.0e+03]\n",
            "[Step 16247/50000] [Progress: 32.49%] [learning rate: 3.6e+03]\n",
            "[Step 16248/50000] [Time: 141s] [Train Loss: 2.64e-01] [Train Acc: 0.92]\n",
            "[Step 16275/50000] [Progress: 32.55%] [learning rate: 4.3e+03]\n",
            "[Step 16298/50000] [Progress: 32.60%] [learning rate: 3.5e+03]\n",
            "[Step 16325/50000] [Progress: 32.65%] [learning rate: 4.1e+03]\n",
            "[Step 16329/50000] [Time: 142s] [Train Loss: 2.64e-01] [Train Acc: 0.92]\n",
            "[Step 16348/50000] [Progress: 32.70%] [learning rate: 3.4e+03]\n",
            "[Step 16374/50000] [Progress: 32.75%] [learning rate: 4.0e+03]\n",
            "[Step 16398/50000] [Progress: 32.80%] [learning rate: 3.6e+03]\n",
            "[Step 16410/50000] [Time: 143s] [Train Loss: 2.63e-01] [Train Acc: 0.92]\n",
            "[Step 16424/50000] [Progress: 32.85%] [learning rate: 4.3e+03]\n",
            "[Step 16447/50000] [Progress: 32.89%] [learning rate: 3.5e+03]\n",
            "[Step 16474/50000] [Progress: 32.95%] [learning rate: 4.2e+03]\n",
            "[Step 16491/50000] [Time: 143s] [Train Loss: 2.62e-01] [Train Acc: 0.92]\n",
            "[Step 16497/50000] [Progress: 32.99%] [learning rate: 3.7e+03]\n",
            "[Step 16522/50000] [Progress: 33.04%] [learning rate: 3.7e+03]\n",
            "[Step 16547/50000] [Progress: 33.09%] [learning rate: 4.0e+03]\n",
            "[Step 16572/50000] [Progress: 33.14%] [learning rate: 3.9e+03]\n",
            "[Step 16572/50000] [Time: 144s] [Train Loss: 2.62e-01] [Train Acc: 0.92]\n",
            "[Step 16598/50000] [Progress: 33.20%] [learning rate: 3.8e+03]\n",
            "[Step 16622/50000] [Progress: 33.24%] [learning rate: 3.8e+03]\n",
            "[Step 16647/50000] [Progress: 33.29%] [learning rate: 3.7e+03]\n",
            "[Step 16653/50000] [Time: 144s] [Train Loss: 2.61e-01] [Train Acc: 0.93]\n",
            "[Step 16673/50000] [Progress: 33.35%] [learning rate: 4.0e+03]\n",
            "[Step 16697/50000] [Progress: 33.39%] [learning rate: 3.6e+03]\n",
            "[Step 16725/50000] [Progress: 33.45%] [learning rate: 4.3e+03]\n",
            "[Step 16735/50000] [Time: 145s] [Train Loss: 2.60e-01] [Train Acc: 0.93]\n",
            "[Step 16749/50000] [Progress: 33.50%] [learning rate: 3.9e+03]\n",
            "[Step 16774/50000] [Progress: 33.55%] [learning rate: 3.8e+03]\n",
            "[Step 16800/50000] [Progress: 33.60%] [learning rate: 3.8e+03]\n",
            "[Step 16817/50000] [Time: 146s] [Train Loss: 2.60e-01] [Train Acc: 0.93]\n",
            "[Step 16825/50000] [Progress: 33.65%] [learning rate: 3.7e+03]\n",
            "[Step 16852/50000] [Progress: 33.70%] [learning rate: 4.0e+03]\n",
            "[Step 16878/50000] [Progress: 33.76%] [learning rate: 3.9e+03]\n",
            "[Step 16899/50000] [Time: 146s] [Train Loss: 2.59e-01] [Train Acc: 0.93]\n",
            "[Step 16904/50000] [Progress: 33.81%] [learning rate: 4.3e+03]\n",
            "[Step 16927/50000] [Progress: 33.85%] [learning rate: 3.5e+03]\n",
            "[Step 16954/50000] [Progress: 33.91%] [learning rate: 4.1e+03]\n",
            "[Step 16977/50000] [Progress: 33.95%] [learning rate: 3.7e+03]\n",
            "[Step 16981/50000] [Time: 147s] [Train Loss: 2.59e-01] [Train Acc: 0.93]\n",
            "[Step 17002/50000] [Progress: 34.00%] [learning rate: 4.0e+03]\n",
            "[Step 17027/50000] [Progress: 34.05%] [learning rate: 4.0e+03]\n",
            "[Step 17053/50000] [Progress: 34.11%] [learning rate: 3.9e+03]\n",
            "[Step 17063/50000] [Time: 148s] [Train Loss: 2.58e-01] [Train Acc: 0.93]\n",
            "[Step 17077/50000] [Progress: 34.15%] [learning rate: 3.8e+03]\n",
            "[Step 17102/50000] [Progress: 34.20%] [learning rate: 3.8e+03]\n",
            "[Step 17128/50000] [Progress: 34.26%] [learning rate: 4.1e+03]\n",
            "[Step 17145/50000] [Time: 148s] [Train Loss: 2.57e-01] [Train Acc: 0.93]\n",
            "[Step 17152/50000] [Progress: 34.30%] [learning rate: 3.7e+03]\n",
            "[Step 17179/50000] [Progress: 34.36%] [learning rate: 4.0e+03]\n",
            "[Step 17204/50000] [Progress: 34.41%] [learning rate: 3.9e+03]\n",
            "[Step 17227/50000] [Time: 149s] [Train Loss: 2.57e-01] [Train Acc: 0.93]\n",
            "[Step 17230/50000] [Progress: 34.46%] [learning rate: 3.9e+03]\n",
            "[Step 17256/50000] [Progress: 34.51%] [learning rate: 3.8e+03]\n",
            "[Step 17281/50000] [Progress: 34.56%] [learning rate: 3.7e+03]\n",
            "[Step 17308/50000] [Progress: 34.62%] [learning rate: 4.1e+03]\n",
            "[Step 17310/50000] [Time: 149s] [Train Loss: 2.56e-01] [Train Acc: 0.93]\n",
            "[Step 17333/50000] [Progress: 34.67%] [learning rate: 4.0e+03]\n",
            "[Step 17358/50000] [Progress: 34.72%] [learning rate: 4.3e+03]\n",
            "[Step 17381/50000] [Progress: 34.76%] [learning rate: 3.5e+03]\n",
            "[Step 17393/50000] [Time: 150s] [Train Loss: 2.56e-01] [Train Acc: 0.93]\n",
            "[Step 17408/50000] [Progress: 34.82%] [learning rate: 4.2e+03]\n",
            "[Step 17431/50000] [Progress: 34.86%] [learning rate: 3.8e+03]\n",
            "[Step 17456/50000] [Progress: 34.91%] [learning rate: 4.1e+03]\n",
            "[Step 17476/50000] [Time: 150s] [Train Loss: 2.55e-01] [Train Acc: 0.93]\n",
            "[Step 17480/50000] [Progress: 34.96%] [learning rate: 4.0e+03]\n",
            "[Step 17505/50000] [Progress: 35.01%] [learning rate: 4.3e+03]\n",
            "[Step 17528/50000] [Progress: 35.06%] [learning rate: 3.5e+03]\n",
            "[Step 17555/50000] [Progress: 35.11%] [learning rate: 4.2e+03]\n",
            "[Step 17559/50000] [Time: 151s] [Train Loss: 2.54e-01] [Train Acc: 0.93]\n",
            "[Step 17578/50000] [Progress: 35.16%] [learning rate: 3.4e+03]\n",
            "[Step 17605/50000] [Progress: 35.21%] [learning rate: 4.1e+03]\n",
            "[Step 17630/50000] [Progress: 35.26%] [learning rate: 4.0e+03]\n",
            "[Step 17642/50000] [Time: 152s] [Train Loss: 2.54e-01] [Train Acc: 0.93]\n",
            "[Step 17656/50000] [Progress: 35.31%] [learning rate: 4.4e+03]\n",
            "[Step 17680/50000] [Progress: 35.36%] [learning rate: 3.9e+03]\n",
            "[Step 17705/50000] [Progress: 35.41%] [learning rate: 3.9e+03]\n",
            "[Step 17725/50000] [Time: 152s] [Train Loss: 2.53e-01] [Train Acc: 0.93]\n",
            "[Step 17731/50000] [Progress: 35.46%] [learning rate: 3.8e+03]\n",
            "[Step 17756/50000] [Progress: 35.51%] [learning rate: 3.7e+03]\n",
            "[Step 17781/50000] [Progress: 35.56%] [learning rate: 4.1e+03]\n",
            "[Step 17808/50000] [Progress: 35.62%] [learning rate: 5.3e+03]\n",
            "[Step 17809/50000] [Time: 153s] [Train Loss: 2.53e-01] [Train Acc: 0.93]\n",
            "[Step 17825/50000] [Progress: 35.65%] [learning rate: 2.4e+03]\n",
            "[Step 17856/50000] [Progress: 35.71%] [learning rate: 4.7e+03]\n",
            "[Step 17877/50000] [Progress: 35.75%] [learning rate: 3.2e+03]\n",
            "[Step 17893/50000] [Time: 153s] [Train Loss: 2.52e-01] [Train Acc: 0.93]\n",
            "[Step 17905/50000] [Progress: 35.81%] [learning rate: 4.5e+03]\n",
            "[Step 17927/50000] [Progress: 35.85%] [learning rate: 3.4e+03]\n",
            "[Step 17955/50000] [Progress: 35.91%] [learning rate: 4.8e+03]\n",
            "[Step 17976/50000] [Progress: 35.95%] [learning rate: 3.3e+03]\n",
            "[Step 17977/50000] [Time: 154s] [Train Loss: 2.51e-01] [Train Acc: 0.93]\n",
            "[Step 18005/50000] [Progress: 36.01%] [learning rate: 4.3e+03]\n",
            "[Step 18029/50000] [Progress: 36.06%] [learning rate: 3.8e+03]\n",
            "[Step 18054/50000] [Progress: 36.11%] [learning rate: 4.1e+03]\n",
            "[Step 18061/50000] [Time: 154s] [Train Loss: 2.51e-01] [Train Acc: 0.93]\n",
            "[Step 18078/50000] [Progress: 36.16%] [learning rate: 3.7e+03]\n",
            "[Step 18106/50000] [Progress: 36.21%] [learning rate: 4.4e+03]\n",
            "[Step 18129/50000] [Progress: 36.26%] [learning rate: 3.6e+03]\n",
            "[Step 18145/50000] [Time: 155s] [Train Loss: 2.50e-01] [Train Acc: 0.93]\n",
            "[Step 18156/50000] [Progress: 36.31%] [learning rate: 4.3e+03]\n",
            "[Step 18179/50000] [Progress: 36.36%] [learning rate: 3.5e+03]\n",
            "[Step 18205/50000] [Progress: 36.41%] [learning rate: 4.2e+03]\n",
            "[Step 18229/50000] [Progress: 36.46%] [learning rate: 3.7e+03]\n",
            "[Step 18229/50000] [Time: 155s] [Train Loss: 2.50e-01] [Train Acc: 0.93]\n",
            "[Step 18255/50000] [Progress: 36.51%] [learning rate: 4.4e+03]\n",
            "[Step 18278/50000] [Progress: 36.56%] [learning rate: 3.6e+03]\n",
            "[Step 18305/50000] [Progress: 36.61%] [learning rate: 4.3e+03]\n",
            "[Step 18313/50000] [Time: 156s] [Train Loss: 2.49e-01] [Train Acc: 0.93]\n",
            "[Step 18328/50000] [Progress: 36.66%] [learning rate: 3.9e+03]\n",
            "[Step 18353/50000] [Progress: 36.71%] [learning rate: 3.8e+03]\n",
            "[Step 18378/50000] [Progress: 36.76%] [learning rate: 4.1e+03]\n",
            "[Step 18397/50000] [Time: 157s] [Train Loss: 2.49e-01] [Train Acc: 0.93]\n",
            "[Step 18403/50000] [Progress: 36.81%] [learning rate: 4.1e+03]\n",
            "[Step 18429/50000] [Progress: 36.86%] [learning rate: 4.0e+03]\n",
            "[Step 18453/50000] [Progress: 36.91%] [learning rate: 3.9e+03]\n",
            "[Step 18478/50000] [Progress: 36.96%] [learning rate: 3.9e+03]\n",
            "[Step 18482/50000] [Time: 157s] [Train Loss: 2.48e-01] [Train Acc: 0.93]\n",
            "[Step 18504/50000] [Progress: 37.01%] [learning rate: 4.2e+03]\n",
            "[Step 18528/50000] [Progress: 37.06%] [learning rate: 3.8e+03]\n",
            "[Step 18555/50000] [Progress: 37.11%] [learning rate: 4.5e+03]\n",
            "[Step 18567/50000] [Time: 158s] [Train Loss: 2.47e-01] [Train Acc: 0.93]\n",
            "[Step 18578/50000] [Progress: 37.16%] [learning rate: 3.7e+03]\n",
            "[Step 18604/50000] [Progress: 37.21%] [learning rate: 4.0e+03]\n",
            "[Step 18628/50000] [Progress: 37.26%] [learning rate: 3.9e+03]\n",
            "[Step 18652/50000] [Time: 159s] [Train Loss: 2.47e-01] [Train Acc: 0.93]\n",
            "[Step 18653/50000] [Progress: 37.31%] [learning rate: 4.2e+03]\n",
            "[Step 18677/50000] [Progress: 37.35%] [learning rate: 3.8e+03]\n",
            "[Step 18704/50000] [Progress: 37.41%] [learning rate: 4.5e+03]\n",
            "[Step 18727/50000] [Progress: 37.45%] [learning rate: 3.7e+03]\n",
            "[Step 18737/50000] [Time: 159s] [Train Loss: 2.46e-01] [Train Acc: 0.93]\n",
            "[Step 18754/50000] [Progress: 37.51%] [learning rate: 4.4e+03]\n",
            "[Step 18777/50000] [Progress: 37.55%] [learning rate: 3.9e+03]\n",
            "[Step 18802/50000] [Progress: 37.60%] [learning rate: 3.9e+03]\n",
            "[Step 18822/50000] [Time: 160s] [Train Loss: 2.46e-01] [Train Acc: 0.93]\n",
            "[Step 18829/50000] [Progress: 37.66%] [learning rate: 4.2e+03]\n",
            "[Step 18855/50000] [Progress: 37.71%] [learning rate: 4.1e+03]\n",
            "[Step 18881/50000] [Progress: 37.76%] [learning rate: 4.5e+03]\n",
            "[Step 18904/50000] [Progress: 37.81%] [learning rate: 3.6e+03]\n",
            "[Step 18907/50000] [Time: 160s] [Train Loss: 2.45e-01] [Train Acc: 0.93]\n",
            "[Step 18931/50000] [Progress: 37.86%] [learning rate: 4.3e+03]\n",
            "[Step 18954/50000] [Progress: 37.91%] [learning rate: 3.9e+03]\n",
            "[Step 18979/50000] [Progress: 37.96%] [learning rate: 4.2e+03]\n",
            "[Step 18992/50000] [Time: 161s] [Train Loss: 2.45e-01] [Train Acc: 0.93]\n",
            "[Step 19003/50000] [Progress: 38.01%] [learning rate: 4.1e+03]\n",
            "[Step 19028/50000] [Progress: 38.06%] [learning rate: 4.1e+03]\n",
            "[Step 19052/50000] [Progress: 38.10%] [learning rate: 4.0e+03]\n",
            "[Step 19077/50000] [Progress: 38.15%] [learning rate: 4.0e+03]\n",
            "[Step 19078/50000] [Time: 162s] [Train Loss: 2.44e-01] [Train Acc: 0.93]\n",
            "[Step 19103/50000] [Progress: 38.21%] [learning rate: 4.3e+03]\n",
            "[Step 19126/50000] [Progress: 38.25%] [learning rate: 3.8e+03]\n",
            "[Step 19152/50000] [Progress: 38.30%] [learning rate: 4.2e+03]\n",
            "[Step 19164/50000] [Time: 162s] [Train Loss: 2.44e-01] [Train Acc: 0.93]\n",
            "[Step 19177/50000] [Progress: 38.35%] [learning rate: 4.1e+03]\n",
            "[Step 19201/50000] [Progress: 38.40%] [learning rate: 4.0e+03]\n",
            "[Step 19226/50000] [Progress: 38.45%] [learning rate: 4.0e+03]\n",
            "[Step 19250/50000] [Time: 163s] [Train Loss: 2.43e-01] [Train Acc: 0.93]\n",
            "[Step 19252/50000] [Progress: 38.50%] [learning rate: 3.9e+03]\n",
            "[Step 19277/50000] [Progress: 38.55%] [learning rate: 3.9e+03]\n",
            "[Step 19303/50000] [Progress: 38.61%] [learning rate: 4.2e+03]\n",
            "[Step 19330/50000] [Progress: 38.66%] [learning rate: 4.5e+03]\n",
            "[Step 19336/50000] [Time: 163s] [Train Loss: 2.42e-01] [Train Acc: 0.93]\n",
            "[Step 19352/50000] [Progress: 38.70%] [learning rate: 3.7e+03]\n",
            "[Step 19378/50000] [Progress: 38.76%] [learning rate: 4.4e+03]\n",
            "[Step 19401/50000] [Progress: 38.80%] [learning rate: 3.9e+03]\n",
            "[Step 19422/50000] [Time: 164s] [Train Loss: 2.42e-01] [Train Acc: 0.93]\n",
            "[Step 19426/50000] [Progress: 38.85%] [learning rate: 4.3e+03]\n",
            "[Step 19450/50000] [Progress: 38.90%] [learning rate: 3.8e+03]\n",
            "[Step 19479/50000] [Progress: 38.96%] [learning rate: 5.0e+03]\n",
            "[Step 19502/50000] [Progress: 39.00%] [learning rate: 3.7e+03]\n",
            "[Step 19508/50000] [Time: 165s] [Train Loss: 2.41e-01] [Train Acc: 0.93]\n",
            "[Step 19528/50000] [Progress: 39.06%] [learning rate: 4.0e+03]\n",
            "[Step 19553/50000] [Progress: 39.11%] [learning rate: 3.9e+03]\n",
            "[Step 19579/50000] [Progress: 39.16%] [learning rate: 4.3e+03]\n",
            "[Step 19594/50000] [Time: 165s] [Train Loss: 2.41e-01] [Train Acc: 0.93]\n",
            "[Step 19603/50000] [Progress: 39.21%] [learning rate: 3.8e+03]\n",
            "[Step 19631/50000] [Progress: 39.26%] [learning rate: 5.0e+03]\n",
            "[Step 19652/50000] [Progress: 39.30%] [learning rate: 3.4e+03]\n",
            "[Step 19680/50000] [Time: 166s] [Train Loss: 2.40e-01] [Train Acc: 0.93] [Eval Loss: 5.07e-01] [Eval Acc: 0.77]\n",
            "[Step 19681/50000] [Progress: 39.36%] [learning rate: 4.4e+03]\n",
            "[Step 19705/50000] [Progress: 39.41%] [learning rate: 4.0e+03]\n",
            "[Step 19730/50000] [Progress: 39.46%] [learning rate: 4.3e+03]\n",
            "[Step 19754/50000] [Progress: 39.51%] [learning rate: 3.8e+03]\n",
            "[Step 19767/50000] [Time: 168s] [Train Loss: 2.40e-01] [Train Acc: 0.93]\n",
            "[Step 19782/50000] [Progress: 39.56%] [learning rate: 4.6e+03]\n",
            "[Step 19806/50000] [Progress: 39.61%] [learning rate: 4.1e+03]\n",
            "[Step 19831/50000] [Progress: 39.66%] [learning rate: 4.0e+03]\n",
            "[Step 19854/50000] [Time: 169s] [Train Loss: 2.39e-01] [Train Acc: 0.93]\n",
            "[Step 19857/50000] [Progress: 39.71%] [learning rate: 4.0e+03]\n",
            "[Step 19882/50000] [Progress: 39.76%] [learning rate: 3.9e+03]\n",
            "[Step 19909/50000] [Progress: 39.82%] [learning rate: 4.2e+03]\n",
            "[Step 19935/50000] [Progress: 39.87%] [learning rate: 4.6e+03]\n",
            "[Step 19941/50000] [Time: 170s] [Train Loss: 2.39e-01] [Train Acc: 0.93]\n",
            "[Step 19958/50000] [Progress: 39.92%] [learning rate: 3.7e+03]\n",
            "[Step 19985/50000] [Progress: 39.97%] [learning rate: 4.5e+03]\n",
            "[Step 20008/50000] [Progress: 40.02%] [learning rate: 4.0e+03]\n",
            "[Step 20028/50000] [Time: 171s] [Train Loss: 2.38e-01] [Train Acc: 0.93]\n",
            "[Step 20033/50000] [Progress: 40.07%] [learning rate: 3.9e+03]\n",
            "[Step 20060/50000] [Progress: 40.12%] [learning rate: 4.3e+03]\n",
            "[Step 20086/50000] [Progress: 40.17%] [learning rate: 4.2e+03]\n",
            "[Step 20111/50000] [Progress: 40.22%] [learning rate: 4.1e+03]\n",
            "[Step 20115/50000] [Time: 171s] [Train Loss: 2.38e-01] [Train Acc: 0.94]\n",
            "[Step 20137/50000] [Progress: 40.27%] [learning rate: 4.1e+03]\n",
            "[Step 20163/50000] [Progress: 40.33%] [learning rate: 4.0e+03]\n",
            "[Step 20188/50000] [Progress: 40.38%] [learning rate: 4.0e+03]\n",
            "[Step 20202/50000] [Time: 172s] [Train Loss: 2.37e-01] [Train Acc: 0.94]\n",
            "[Step 20215/50000] [Progress: 40.43%] [learning rate: 4.3e+03]\n",
            "[Step 20241/50000] [Progress: 40.48%] [learning rate: 4.2e+03]\n",
            "[Step 20267/50000] [Progress: 40.53%] [learning rate: 4.6e+03]\n",
            "[Step 20289/50000] [Time: 173s] [Train Loss: 2.36e-01] [Train Acc: 0.94]\n",
            "[Step 20290/50000] [Progress: 40.58%] [learning rate: 3.7e+03]\n",
            "[Step 20317/50000] [Progress: 40.63%] [learning rate: 4.4e+03]\n",
            "[Step 20340/50000] [Progress: 40.68%] [learning rate: 4.0e+03]\n",
            "[Step 20365/50000] [Progress: 40.73%] [learning rate: 4.3e+03]\n",
            "[Step 20376/50000] [Time: 173s] [Train Loss: 2.36e-01] [Train Acc: 0.94]\n",
            "[Step 20389/50000] [Progress: 40.78%] [learning rate: 4.2e+03]\n",
            "[Step 20414/50000] [Progress: 40.83%] [learning rate: 4.2e+03]\n",
            "[Step 20438/50000] [Progress: 40.88%] [learning rate: 4.1e+03]\n",
            "[Step 20463/50000] [Progress: 40.93%] [learning rate: 4.1e+03]\n",
            "[Step 20463/50000] [Time: 174s] [Train Loss: 2.35e-01] [Train Acc: 0.94]\n",
            "[Step 20489/50000] [Progress: 40.98%] [learning rate: 4.4e+03]\n",
            "[Step 20512/50000] [Progress: 41.02%] [learning rate: 3.9e+03]\n",
            "[Step 20538/50000] [Progress: 41.08%] [learning rate: 4.7e+03]\n",
            "[Step 20551/50000] [Time: 175s] [Train Loss: 2.35e-01] [Train Acc: 0.94]\n",
            "[Step 20561/50000] [Progress: 41.12%] [learning rate: 3.8e+03]\n",
            "[Step 20587/50000] [Progress: 41.17%] [learning rate: 4.1e+03]\n",
            "[Step 20611/50000] [Progress: 41.22%] [learning rate: 4.1e+03]\n",
            "[Step 20636/50000] [Progress: 41.27%] [learning rate: 4.0e+03]\n",
            "[Step 20639/50000] [Time: 175s] [Train Loss: 2.34e-01] [Train Acc: 0.94]\n",
            "[Step 20661/50000] [Progress: 41.32%] [learning rate: 3.9e+03]\n",
            "[Step 20687/50000] [Progress: 41.37%] [learning rate: 4.3e+03]\n",
            "[Step 20714/50000] [Progress: 41.43%] [learning rate: 4.6e+03]\n",
            "[Step 20727/50000] [Time: 176s] [Train Loss: 2.34e-01] [Train Acc: 0.94]\n",
            "[Step 20738/50000] [Progress: 41.48%] [learning rate: 4.2e+03]\n",
            "[Step 20763/50000] [Progress: 41.53%] [learning rate: 4.1e+03]\n",
            "[Step 20789/50000] [Progress: 41.58%] [learning rate: 4.0e+03]\n",
            "[Step 20814/50000] [Progress: 41.63%] [learning rate: 4.0e+03]\n",
            "[Step 20815/50000] [Time: 177s] [Train Loss: 2.33e-01] [Train Acc: 0.94]\n",
            "[Step 20839/50000] [Progress: 41.68%] [learning rate: 4.3e+03]\n",
            "[Step 20865/50000] [Progress: 41.73%] [learning rate: 5.1e+03]\n",
            "[Step 20886/50000] [Progress: 41.77%] [learning rate: 3.4e+03]\n",
            "[Step 20903/50000] [Time: 178s] [Train Loss: 2.33e-01] [Train Acc: 0.94]\n",
            "[Step 20915/50000] [Progress: 41.83%] [learning rate: 4.5e+03]\n",
            "[Step 20940/50000] [Progress: 41.88%] [learning rate: 4.0e+03]\n",
            "[Step 20966/50000] [Progress: 41.93%] [learning rate: 4.4e+03]\n",
            "[Step 20990/50000] [Progress: 41.98%] [learning rate: 3.9e+03]\n",
            "[Step 20991/50000] [Time: 178s] [Train Loss: 2.32e-01] [Train Acc: 0.94]\n",
            "[Step 21017/50000] [Progress: 42.03%] [learning rate: 4.7e+03]\n",
            "[Step 21041/50000] [Progress: 42.08%] [learning rate: 4.2e+03]\n",
            "[Step 21066/50000] [Progress: 42.13%] [learning rate: 4.1e+03]\n",
            "[Step 21079/50000] [Time: 179s] [Train Loss: 2.32e-01] [Train Acc: 0.94]\n",
            "[Step 21092/50000] [Progress: 42.18%] [learning rate: 4.5e+03]\n",
            "[Step 21115/50000] [Progress: 42.23%] [learning rate: 4.0e+03]\n",
            "[Step 21141/50000] [Progress: 42.28%] [learning rate: 4.3e+03]\n",
            "[Step 21167/50000] [Progress: 42.33%] [learning rate: 4.7e+03]\n",
            "[Step 21167/50000] [Time: 179s] [Train Loss: 2.31e-01] [Train Acc: 0.94]\n",
            "[Step 21190/50000] [Progress: 42.38%] [learning rate: 3.8e+03]\n",
            "[Step 21217/50000] [Progress: 42.43%] [learning rate: 4.6e+03]\n",
            "[Step 21240/50000] [Progress: 42.48%] [learning rate: 4.1e+03]\n",
            "[Step 21255/50000] [Time: 180s] [Train Loss: 2.31e-01] [Train Acc: 0.94]\n",
            "[Step 21265/50000] [Progress: 42.53%] [learning rate: 4.0e+03]\n",
            "[Step 21290/50000] [Progress: 42.58%] [learning rate: 4.4e+03]\n",
            "[Step 21315/50000] [Progress: 42.63%] [learning rate: 4.3e+03]\n",
            "[Step 21341/50000] [Progress: 42.68%] [learning rate: 4.2e+03]\n",
            "[Step 21344/50000] [Time: 181s] [Train Loss: 2.30e-01] [Train Acc: 0.94]\n",
            "[Step 21365/50000] [Progress: 42.73%] [learning rate: 4.2e+03]\n",
            "[Step 21390/50000] [Progress: 42.78%] [learning rate: 4.1e+03]\n",
            "[Step 21416/50000] [Progress: 42.83%] [learning rate: 4.4e+03]\n",
            "[Step 21433/50000] [Time: 181s] [Train Loss: 2.30e-01] [Train Acc: 0.94]\n",
            "[Step 21440/50000] [Progress: 42.88%] [learning rate: 4.0e+03]\n",
            "[Step 21468/50000] [Progress: 42.94%] [learning rate: 4.7e+03]\n",
            "[Step 21492/50000] [Progress: 42.98%] [learning rate: 4.2e+03]\n",
            "[Step 21517/50000] [Progress: 43.03%] [learning rate: 4.2e+03]\n",
            "[Step 21522/50000] [Time: 182s] [Train Loss: 2.29e-01] [Train Acc: 0.94]\n",
            "[Step 21543/50000] [Progress: 43.09%] [learning rate: 4.1e+03]\n",
            "[Step 21568/50000] [Progress: 43.14%] [learning rate: 4.1e+03]\n",
            "[Step 21595/50000] [Progress: 43.19%] [learning rate: 4.4e+03]\n",
            "[Step 21611/50000] [Time: 182s] [Train Loss: 2.29e-01] [Train Acc: 0.94]\n",
            "[Step 21621/50000] [Progress: 43.24%] [learning rate: 4.3e+03]\n",
            "[Step 21647/50000] [Progress: 43.29%] [learning rate: 4.7e+03]\n",
            "[Step 21670/50000] [Progress: 43.34%] [learning rate: 3.8e+03]\n",
            "[Step 21697/50000] [Progress: 43.39%] [learning rate: 4.5e+03]\n",
            "[Step 21700/50000] [Time: 183s] [Train Loss: 2.28e-01] [Train Acc: 0.94]\n",
            "[Step 21720/50000] [Progress: 43.44%] [learning rate: 4.1e+03]\n",
            "[Step 21745/50000] [Progress: 43.49%] [learning rate: 4.4e+03]\n",
            "[Step 21769/50000] [Progress: 43.54%] [learning rate: 4.3e+03]\n",
            "[Step 21789/50000] [Time: 184s] [Train Loss: 2.28e-01] [Train Acc: 0.94]\n",
            "[Step 21794/50000] [Progress: 43.59%] [learning rate: 4.7e+03]\n",
            "[Step 21817/50000] [Progress: 43.63%] [learning rate: 3.8e+03]\n",
            "[Step 21844/50000] [Progress: 43.69%] [learning rate: 4.6e+03]\n",
            "[Step 21867/50000] [Progress: 43.73%] [learning rate: 4.1e+03]\n",
            "[Step 21878/50000] [Time: 184s] [Train Loss: 2.27e-01] [Train Acc: 0.94]\n",
            "[Step 21892/50000] [Progress: 43.78%] [learning rate: 4.4e+03]\n",
            "[Step 21916/50000] [Progress: 43.83%] [learning rate: 4.4e+03]\n",
            "[Step 21941/50000] [Progress: 43.88%] [learning rate: 4.3e+03]\n",
            "[Step 21965/50000] [Progress: 43.93%] [learning rate: 4.2e+03]\n",
            "[Step 21967/50000] [Time: 186s] [Train Loss: 2.27e-01] [Train Acc: 0.94]\n",
            "[Step 21990/50000] [Progress: 43.98%] [learning rate: 4.2e+03]\n",
            "[Step 22016/50000] [Progress: 44.03%] [learning rate: 4.5e+03]\n",
            "[Step 22039/50000] [Progress: 44.08%] [learning rate: 4.0e+03]\n",
            "[Step 22056/50000] [Time: 186s] [Train Loss: 2.26e-01] [Train Acc: 0.94]\n",
            "[Step 22065/50000] [Progress: 44.13%] [learning rate: 4.4e+03]\n",
            "[Step 22092/50000] [Progress: 44.18%] [learning rate: 4.8e+03]\n",
            "[Step 22116/50000] [Progress: 44.23%] [learning rate: 4.3e+03]\n",
            "[Step 22141/50000] [Progress: 44.28%] [learning rate: 4.2e+03]\n",
            "[Step 22145/50000] [Time: 187s] [Train Loss: 2.26e-01] [Train Acc: 0.94]\n",
            "[Step 22167/50000] [Progress: 44.33%] [learning rate: 4.5e+03]\n",
            "[Step 22190/50000] [Progress: 44.38%] [learning rate: 4.1e+03]\n",
            "[Step 22216/50000] [Progress: 44.43%] [learning rate: 4.4e+03]\n",
            "[Step 22235/50000] [Time: 188s] [Train Loss: 2.25e-01] [Train Acc: 0.94]\n",
            "[Step 22244/50000] [Progress: 44.49%] [learning rate: 5.8e+03]\n",
            "[Step 22261/50000] [Progress: 44.52%] [learning rate: 2.7e+03]\n",
            "[Step 22293/50000] [Progress: 44.59%] [learning rate: 5.1e+03]\n",
            "[Step 22316/50000] [Progress: 44.63%] [learning rate: 3.8e+03]\n",
            "[Step 22325/50000] [Time: 189s] [Train Loss: 2.25e-01] [Train Acc: 0.94]\n",
            "[Step 22344/50000] [Progress: 44.69%] [learning rate: 4.5e+03]\n",
            "[Step 22370/50000] [Progress: 44.74%] [learning rate: 4.4e+03]\n",
            "[Step 22397/50000] [Progress: 44.79%] [learning rate: 4.8e+03]\n",
            "[Step 22415/50000] [Time: 190s] [Train Loss: 2.24e-01] [Train Acc: 0.94]\n",
            "[Step 22421/50000] [Progress: 44.84%] [learning rate: 4.3e+03]\n",
            "[Step 22446/50000] [Progress: 44.89%] [learning rate: 4.2e+03]\n",
            "[Step 22472/50000] [Progress: 44.94%] [learning rate: 4.2e+03]\n",
            "[Step 22498/50000] [Progress: 45.00%] [learning rate: 4.5e+03]\n",
            "[Step 22505/50000] [Time: 191s] [Train Loss: 2.24e-01] [Train Acc: 0.94]\n",
            "[Step 22522/50000] [Progress: 45.04%] [learning rate: 4.0e+03]\n",
            "[Step 22548/50000] [Progress: 45.10%] [learning rate: 4.8e+03]\n",
            "[Step 22571/50000] [Progress: 45.14%] [learning rate: 3.9e+03]\n",
            "[Step 22595/50000] [Time: 191s] [Train Loss: 2.23e-01] [Train Acc: 0.94]\n",
            "[Step 22597/50000] [Progress: 45.19%] [learning rate: 4.2e+03]\n",
            "[Step 22622/50000] [Progress: 45.24%] [learning rate: 4.2e+03]\n",
            "[Step 22648/50000] [Progress: 45.30%] [learning rate: 4.5e+03]\n",
            "[Step 22672/50000] [Progress: 45.34%] [learning rate: 4.1e+03]\n",
            "[Step 22685/50000] [Time: 192s] [Train Loss: 2.23e-01] [Train Acc: 0.94]\n",
            "[Step 22700/50000] [Progress: 45.40%] [learning rate: 4.8e+03]\n",
            "[Step 22724/50000] [Progress: 45.45%] [learning rate: 4.3e+03]\n",
            "[Step 22749/50000] [Progress: 45.50%] [learning rate: 4.3e+03]\n",
            "[Step 22775/50000] [Progress: 45.55%] [learning rate: 4.2e+03]\n",
            "[Step 22775/50000] [Time: 193s] [Train Loss: 2.22e-01] [Train Acc: 0.94]\n",
            "[Step 22801/50000] [Progress: 45.60%] [learning rate: 4.6e+03]\n",
            "[Step 22825/50000] [Progress: 45.65%] [learning rate: 4.1e+03]\n",
            "[Step 22853/50000] [Progress: 45.71%] [learning rate: 4.9e+03]\n",
            "[Step 22865/50000] [Time: 194s] [Train Loss: 2.22e-01] [Train Acc: 0.94]\n",
            "[Step 22877/50000] [Progress: 45.75%] [learning rate: 4.4e+03]\n",
            "[Step 22902/50000] [Progress: 45.80%] [learning rate: 4.3e+03]\n",
            "[Step 22928/50000] [Progress: 45.86%] [learning rate: 4.2e+03]\n",
            "[Step 22953/50000] [Progress: 45.91%] [learning rate: 4.2e+03]\n",
            "[Step 22955/50000] [Time: 195s] [Train Loss: 2.21e-01] [Train Acc: 0.94]\n",
            "[Step 22980/50000] [Progress: 45.96%] [learning rate: 4.5e+03]\n",
            "[Step 23006/50000] [Progress: 46.01%] [learning rate: 4.4e+03]\n",
            "[Step 23032/50000] [Progress: 46.06%] [learning rate: 4.8e+03]\n",
            "[Step 23045/50000] [Time: 195s] [Train Loss: 2.21e-01] [Train Acc: 0.94]\n",
            "[Step 23055/50000] [Progress: 46.11%] [learning rate: 3.9e+03]\n",
            "[Step 23082/50000] [Progress: 46.16%] [learning rate: 4.7e+03]\n",
            "[Step 23105/50000] [Progress: 46.21%] [learning rate: 4.2e+03]\n",
            "[Step 23130/50000] [Progress: 46.26%] [learning rate: 4.5e+03]\n",
            "[Step 23136/50000] [Time: 196s] [Train Loss: 2.20e-01] [Train Acc: 0.94]\n",
            "[Step 23154/50000] [Progress: 46.31%] [learning rate: 4.5e+03]\n",
            "[Step 23179/50000] [Progress: 46.36%] [learning rate: 4.4e+03]\n",
            "[Step 23203/50000] [Progress: 46.41%] [learning rate: 4.3e+03]\n",
            "[Step 23227/50000] [Time: 197s] [Train Loss: 2.20e-01] [Train Acc: 0.94]\n",
            "[Step 23228/50000] [Progress: 46.46%] [learning rate: 4.3e+03]\n",
            "[Step 23254/50000] [Progress: 46.51%] [learning rate: 4.6e+03]\n",
            "[Step 23277/50000] [Progress: 46.55%] [learning rate: 4.1e+03]\n",
            "[Step 23303/50000] [Progress: 46.61%] [learning rate: 4.5e+03]\n",
            "[Step 23318/50000] [Time: 197s] [Train Loss: 2.19e-01] [Train Acc: 0.94]\n",
            "[Step 23328/50000] [Progress: 46.66%] [learning rate: 4.4e+03]\n",
            "[Step 23352/50000] [Progress: 46.70%] [learning rate: 4.3e+03]\n",
            "[Step 23377/50000] [Progress: 46.75%] [learning rate: 4.3e+03]\n",
            "[Step 23403/50000] [Progress: 46.81%] [learning rate: 4.2e+03]\n",
            "[Step 23409/50000] [Time: 198s] [Train Loss: 2.19e-01] [Train Acc: 0.94]\n",
            "[Step 23428/50000] [Progress: 46.86%] [learning rate: 4.2e+03]\n",
            "[Step 23454/50000] [Progress: 46.91%] [learning rate: 4.5e+03]\n",
            "[Step 23481/50000] [Progress: 46.96%] [learning rate: 4.9e+03]\n",
            "[Step 23500/50000] [Time: 199s] [Train Loss: 2.18e-01] [Train Acc: 0.94]\n",
            "[Step 23505/50000] [Progress: 47.01%] [learning rate: 4.4e+03]\n",
            "[Step 23530/50000] [Progress: 47.06%] [learning rate: 4.3e+03]\n",
            "[Step 23556/50000] [Progress: 47.11%] [learning rate: 4.7e+03]\n",
            "[Step 23579/50000] [Progress: 47.16%] [learning rate: 4.2e+03]\n",
            "[Step 23591/50000] [Time: 200s] [Train Loss: 2.18e-01] [Train Acc: 0.94]\n",
            "[Step 23605/50000] [Progress: 47.21%] [learning rate: 4.5e+03]\n",
            "[Step 23632/50000] [Progress: 47.26%] [learning rate: 5.4e+03]\n",
            "[Step 23652/50000] [Progress: 47.30%] [learning rate: 3.6e+03]\n",
            "[Step 23680/50000] [Progress: 47.36%] [learning rate: 4.7e+03]\n",
            "[Step 23682/50000] [Time: 200s] [Train Loss: 2.18e-01] [Train Acc: 0.94]\n",
            "[Step 23705/50000] [Progress: 47.41%] [learning rate: 4.3e+03]\n",
            "[Step 23731/50000] [Progress: 47.46%] [learning rate: 4.6e+03]\n",
            "[Step 23755/50000] [Progress: 47.51%] [learning rate: 4.1e+03]\n",
            "[Step 23773/50000] [Time: 201s] [Train Loss: 2.17e-01] [Train Acc: 0.94]\n",
            "[Step 23783/50000] [Progress: 47.57%] [learning rate: 4.9e+03]\n",
            "[Step 23806/50000] [Progress: 47.61%] [learning rate: 4.0e+03]\n",
            "[Step 23833/50000] [Progress: 47.67%] [learning rate: 4.8e+03]\n",
            "[Step 23856/50000] [Progress: 47.71%] [learning rate: 3.9e+03]\n",
            "[Step 23864/50000] [Time: 201s] [Train Loss: 2.17e-01] [Train Acc: 0.94]\n",
            "[Step 23882/50000] [Progress: 47.76%] [learning rate: 4.6e+03]\n",
            "[Step 23906/50000] [Progress: 47.81%] [learning rate: 4.1e+03]\n",
            "[Step 23932/50000] [Progress: 47.86%] [learning rate: 4.9e+03]\n",
            "[Step 23955/50000] [Progress: 47.91%] [learning rate: 4.0e+03]\n",
            "[Step 23955/50000] [Time: 202s] [Train Loss: 2.16e-01] [Train Acc: 0.94]\n",
            "[Step 23982/50000] [Progress: 47.96%] [learning rate: 4.8e+03]\n",
            "[Step 24005/50000] [Progress: 48.01%] [learning rate: 3.9e+03]\n",
            "[Step 24031/50000] [Progress: 48.06%] [learning rate: 4.6e+03]\n",
            "[Step 24046/50000] [Time: 203s] [Train Loss: 2.16e-01] [Train Acc: 0.94]\n",
            "[Step 24055/50000] [Progress: 48.11%] [learning rate: 4.2e+03]\n",
            "[Step 24081/50000] [Progress: 48.16%] [learning rate: 4.5e+03]\n",
            "[Step 24106/50000] [Progress: 48.21%] [learning rate: 4.4e+03]\n",
            "[Step 24132/50000] [Progress: 48.26%] [learning rate: 4.4e+03]\n",
            "[Step 24137/50000] [Time: 203s] [Train Loss: 2.15e-01] [Train Acc: 0.95] [Eval Loss: 5.06e-01] [Eval Acc: 0.77]\n",
            "[Step 24158/50000] [Progress: 48.32%] [learning rate: 4.3e+03]\n",
            "[Step 24183/50000] [Progress: 48.37%] [learning rate: 4.2e+03]\n",
            "[Step 24210/50000] [Progress: 48.42%] [learning rate: 4.6e+03]\n",
            "[Step 24229/50000] [Time: 206s] [Train Loss: 2.15e-01] [Train Acc: 0.95]\n",
            "[Step 24236/50000] [Progress: 48.47%] [learning rate: 4.5e+03]\n",
            "[Step 24262/50000] [Progress: 48.52%] [learning rate: 4.5e+03]\n",
            "[Step 24286/50000] [Progress: 48.57%] [learning rate: 4.4e+03]\n",
            "[Step 24311/50000] [Progress: 48.62%] [learning rate: 4.3e+03]\n",
            "[Step 24321/50000] [Time: 207s] [Train Loss: 2.14e-01] [Train Acc: 0.95]\n",
            "[Step 24337/50000] [Progress: 48.67%] [learning rate: 4.7e+03]\n",
            "[Step 24361/50000] [Progress: 48.72%] [learning rate: 4.2e+03]\n",
            "[Step 24388/50000] [Progress: 48.78%] [learning rate: 5.0e+03]\n",
            "[Step 24411/50000] [Progress: 48.82%] [learning rate: 4.1e+03]\n",
            "[Step 24413/50000] [Time: 207s] [Train Loss: 2.14e-01] [Train Acc: 0.95]\n",
            "[Step 24437/50000] [Progress: 48.87%] [learning rate: 4.4e+03]\n",
            "[Step 24461/50000] [Progress: 48.92%] [learning rate: 4.3e+03]\n",
            "[Step 24486/50000] [Progress: 48.97%] [learning rate: 4.3e+03]\n",
            "[Step 24505/50000] [Time: 208s] [Train Loss: 2.13e-01] [Train Acc: 0.95]\n",
            "[Step 24511/50000] [Progress: 49.02%] [learning rate: 4.2e+03]\n",
            "[Step 24537/50000] [Progress: 49.07%] [learning rate: 4.6e+03]\n",
            "[Step 24563/50000] [Progress: 49.13%] [learning rate: 5.0e+03]\n",
            "[Step 24586/50000] [Progress: 49.17%] [learning rate: 4.0e+03]\n",
            "[Step 24597/50000] [Time: 209s] [Train Loss: 2.13e-01] [Train Acc: 0.95]\n",
            "[Step 24612/50000] [Progress: 49.22%] [learning rate: 4.4e+03]\n",
            "[Step 24637/50000] [Progress: 49.27%] [learning rate: 4.3e+03]\n",
            "[Step 24663/50000] [Progress: 49.33%] [learning rate: 4.7e+03]\n",
            "[Step 24687/50000] [Progress: 49.37%] [learning rate: 4.2e+03]\n",
            "[Step 24689/50000] [Time: 210s] [Train Loss: 2.13e-01] [Train Acc: 0.95]\n",
            "[Step 24714/50000] [Progress: 49.43%] [learning rate: 5.5e+03]\n",
            "[Step 24734/50000] [Progress: 49.47%] [learning rate: 3.7e+03]\n",
            "[Step 24762/50000] [Progress: 49.52%] [learning rate: 4.8e+03]\n",
            "[Step 24781/50000] [Time: 210s] [Train Loss: 2.12e-01] [Train Acc: 0.95]\n",
            "[Step 24787/50000] [Progress: 49.57%] [learning rate: 4.3e+03]\n",
            "[Step 24813/50000] [Progress: 49.63%] [learning rate: 4.7e+03]\n",
            "[Step 24837/50000] [Progress: 49.67%] [learning rate: 4.2e+03]\n",
            "[Step 24864/50000] [Progress: 49.73%] [learning rate: 5.5e+03]\n",
            "[Step 24873/50000] [Time: 211s] [Train Loss: 2.12e-01] [Train Acc: 0.95]\n",
            "[Step 24884/50000] [Progress: 49.77%] [learning rate: 3.7e+03]\n",
            "[Step 24912/50000] [Progress: 49.82%] [learning rate: 4.8e+03]\n",
            "[Step 24937/50000] [Progress: 49.87%] [learning rate: 4.3e+03]\n",
            "[Step 24963/50000] [Progress: 49.93%] [learning rate: 4.7e+03]\n",
            "[Step 24965/50000] [Time: 212s] [Train Loss: 2.11e-01] [Train Acc: 0.95]\n",
            "[Step 24987/50000] [Progress: 49.97%] [learning rate: 4.2e+03]\n",
            "[Step 25013/50000] [Progress: 50.03%] [learning rate: 5.0e+03]\n",
            "[Step 25036/50000] [Progress: 50.07%] [learning rate: 4.1e+03]\n",
            "[Step 25057/50000] [Time: 213s] [Train Loss: 2.11e-01] [Train Acc: 0.95]\n",
            "[Step 25062/50000] [Progress: 50.12%] [learning rate: 4.4e+03]\n",
            "[Step 25086/50000] [Progress: 50.17%] [learning rate: 4.4e+03]\n",
            "[Step 25111/50000] [Progress: 50.22%] [learning rate: 4.7e+03]\n",
            "[Step 25135/50000] [Progress: 50.27%] [learning rate: 4.2e+03]\n",
            "[Step 25149/50000] [Time: 214s] [Train Loss: 2.10e-01] [Train Acc: 0.95]\n",
            "[Step 25163/50000] [Progress: 50.33%] [learning rate: 5.0e+03]\n",
            "[Step 25187/50000] [Progress: 50.37%] [learning rate: 4.5e+03]\n",
            "[Step 25212/50000] [Progress: 50.42%] [learning rate: 4.4e+03]\n",
            "[Step 25238/50000] [Progress: 50.48%] [learning rate: 4.4e+03]\n",
            "[Step 25241/50000] [Time: 215s] [Train Loss: 2.10e-01] [Train Acc: 0.95]\n",
            "[Step 25263/50000] [Progress: 50.53%] [learning rate: 4.3e+03]\n",
            "[Step 25290/50000] [Progress: 50.58%] [learning rate: 4.7e+03]\n",
            "[Step 25316/50000] [Progress: 50.63%] [learning rate: 4.6e+03]\n",
            "[Step 25333/50000] [Time: 215s] [Train Loss: 2.09e-01] [Train Acc: 0.95]\n",
            "[Step 25340/50000] [Progress: 50.68%] [learning rate: 4.5e+03]\n",
            "[Step 25365/50000] [Progress: 50.73%] [learning rate: 4.5e+03]\n",
            "[Step 25391/50000] [Progress: 50.78%] [learning rate: 4.4e+03]\n",
            "[Step 25416/50000] [Progress: 50.83%] [learning rate: 4.3e+03]\n",
            "[Step 25426/50000] [Time: 216s] [Train Loss: 2.09e-01] [Train Acc: 0.95]\n",
            "[Step 25443/50000] [Progress: 50.89%] [learning rate: 4.7e+03]\n",
            "[Step 25469/50000] [Progress: 50.94%] [learning rate: 4.6e+03]\n",
            "[Step 25495/50000] [Progress: 50.99%] [learning rate: 5.0e+03]\n",
            "[Step 25518/50000] [Progress: 51.04%] [learning rate: 4.1e+03]\n",
            "[Step 25519/50000] [Time: 217s] [Train Loss: 2.09e-01] [Train Acc: 0.95]\n",
            "[Step 25545/50000] [Progress: 51.09%] [learning rate: 4.9e+03]\n",
            "[Step 25568/50000] [Progress: 51.14%] [learning rate: 4.4e+03]\n",
            "[Step 25593/50000] [Progress: 51.19%] [learning rate: 4.7e+03]\n",
            "[Step 25612/50000] [Time: 217s] [Train Loss: 2.08e-01] [Train Acc: 0.95]\n",
            "[Step 25617/50000] [Progress: 51.23%] [learning rate: 4.6e+03]\n",
            "[Step 25642/50000] [Progress: 51.28%] [learning rate: 5.0e+03]\n",
            "[Step 25665/50000] [Progress: 51.33%] [learning rate: 4.1e+03]\n",
            "[Step 25692/50000] [Progress: 51.38%] [learning rate: 4.9e+03]\n",
            "[Step 25705/50000] [Time: 218s] [Train Loss: 2.08e-01] [Train Acc: 0.95]\n",
            "[Step 25715/50000] [Progress: 51.43%] [learning rate: 4.4e+03]\n",
            "[Step 25740/50000] [Progress: 51.48%] [learning rate: 4.7e+03]\n",
            "[Step 25764/50000] [Progress: 51.53%] [learning rate: 4.2e+03]\n",
            "[Step 25791/50000] [Progress: 51.58%] [learning rate: 5.1e+03]\n",
            "[Step 25798/50000] [Time: 219s] [Train Loss: 2.07e-01] [Train Acc: 0.95]\n",
            "[Step 25815/50000] [Progress: 51.63%] [learning rate: 4.5e+03]\n",
            "[Step 25840/50000] [Progress: 51.68%] [learning rate: 4.5e+03]\n",
            "[Step 25866/50000] [Progress: 51.73%] [learning rate: 4.4e+03]\n",
            "[Step 25891/50000] [Progress: 51.78%] [learning rate: 4.3e+03]\n",
            "[Step 25891/50000] [Time: 220s] [Train Loss: 2.07e-01] [Train Acc: 0.95]\n",
            "[Step 25917/50000] [Progress: 51.83%] [learning rate: 4.7e+03]\n",
            "[Step 25944/50000] [Progress: 51.89%] [learning rate: 5.1e+03]\n",
            "[Step 25966/50000] [Progress: 51.93%] [learning rate: 4.1e+03]\n",
            "[Step 25984/50000] [Time: 221s] [Train Loss: 2.06e-01] [Train Acc: 0.95]\n",
            "[Step 25992/50000] [Progress: 51.98%] [learning rate: 4.9e+03]\n",
            "[Step 26015/50000] [Progress: 52.03%] [learning rate: 4.4e+03]\n",
            "[Step 26040/50000] [Progress: 52.08%] [learning rate: 4.3e+03]\n",
            "[Step 26065/50000] [Progress: 52.13%] [learning rate: 4.7e+03]\n",
            "[Step 26077/50000] [Time: 222s] [Train Loss: 2.06e-01] [Train Acc: 0.95]\n",
            "[Step 26091/50000] [Progress: 52.18%] [learning rate: 5.1e+03]\n",
            "[Step 26115/50000] [Progress: 52.23%] [learning rate: 4.6e+03]\n",
            "[Step 26140/50000] [Progress: 52.28%] [learning rate: 4.5e+03]\n",
            "[Step 26166/50000] [Progress: 52.33%] [learning rate: 4.4e+03]\n",
            "[Step 26170/50000] [Time: 223s] [Train Loss: 2.06e-01] [Train Acc: 0.95]\n",
            "[Step 26191/50000] [Progress: 52.38%] [learning rate: 4.4e+03]\n",
            "[Step 26218/50000] [Progress: 52.44%] [learning rate: 4.7e+03]\n",
            "[Step 26244/50000] [Progress: 52.49%] [learning rate: 5.1e+03]\n",
            "[Step 26263/50000] [Time: 225s] [Train Loss: 2.05e-01] [Train Acc: 0.95]\n",
            "[Step 26267/50000] [Progress: 52.53%] [learning rate: 4.2e+03]\n",
            "[Step 26293/50000] [Progress: 52.59%] [learning rate: 4.5e+03]\n",
            "[Step 26318/50000] [Progress: 52.64%] [learning rate: 4.5e+03]\n",
            "[Step 26344/50000] [Progress: 52.69%] [learning rate: 4.8e+03]\n",
            "[Step 26356/50000] [Time: 226s] [Train Loss: 2.05e-01] [Train Acc: 0.95]\n",
            "[Step 26368/50000] [Progress: 52.74%] [learning rate: 4.3e+03]\n",
            "[Step 26395/50000] [Progress: 52.79%] [learning rate: 5.1e+03]\n",
            "[Step 26418/50000] [Progress: 52.84%] [learning rate: 4.2e+03]\n",
            "[Step 26444/50000] [Progress: 52.89%] [learning rate: 4.5e+03]\n",
            "[Step 26449/50000] [Time: 227s] [Train Loss: 2.04e-01] [Train Acc: 0.95]\n",
            "[Step 26469/50000] [Progress: 52.94%] [learning rate: 4.5e+03]\n",
            "[Step 26495/50000] [Progress: 52.99%] [learning rate: 4.4e+03]\n",
            "[Step 26520/50000] [Progress: 53.04%] [learning rate: 4.8e+03]\n",
            "[Step 26542/50000] [Time: 228s] [Train Loss: 2.04e-01] [Train Acc: 0.95]\n",
            "[Step 26544/50000] [Progress: 53.09%] [learning rate: 4.7e+03]\n",
            "[Step 26569/50000] [Progress: 53.14%] [learning rate: 4.6e+03]\n",
            "[Step 26593/50000] [Progress: 53.19%] [learning rate: 4.6e+03]\n",
            "[Step 26618/50000] [Progress: 53.24%] [learning rate: 4.5e+03]\n",
            "[Step 26635/50000] [Time: 228s] [Train Loss: 2.03e-01] [Train Acc: 0.95]\n",
            "[Step 26644/50000] [Progress: 53.29%] [learning rate: 4.9e+03]\n",
            "[Step 26668/50000] [Progress: 53.34%] [learning rate: 4.4e+03]\n",
            "[Step 26695/50000] [Progress: 53.39%] [learning rate: 5.2e+03]\n",
            "[Step 26718/50000] [Progress: 53.44%] [learning rate: 4.2e+03]\n",
            "[Step 26729/50000] [Time: 229s] [Train Loss: 2.03e-01] [Train Acc: 0.95]\n",
            "[Step 26744/50000] [Progress: 53.49%] [learning rate: 4.6e+03]\n",
            "[Step 26770/50000] [Progress: 53.54%] [learning rate: 5.0e+03]\n",
            "[Step 26793/50000] [Progress: 53.59%] [learning rate: 4.0e+03]\n",
            "[Step 26820/50000] [Progress: 53.64%] [learning rate: 4.8e+03]\n",
            "[Step 26823/50000] [Time: 230s] [Train Loss: 2.03e-01] [Train Acc: 0.95]\n",
            "[Step 26845/50000] [Progress: 53.69%] [learning rate: 4.7e+03]\n",
            "[Step 26870/50000] [Progress: 53.74%] [learning rate: 5.1e+03]\n",
            "[Step 26893/50000] [Progress: 53.79%] [learning rate: 4.2e+03]\n",
            "[Step 26917/50000] [Time: 230s] [Train Loss: 2.02e-01] [Train Acc: 0.95]\n",
            "[Step 26920/50000] [Progress: 53.84%] [learning rate: 5.0e+03]\n",
            "[Step 26943/50000] [Progress: 53.89%] [learning rate: 4.5e+03]\n",
            "[Step 26968/50000] [Progress: 53.94%] [learning rate: 4.8e+03]\n",
            "[Step 26992/50000] [Progress: 53.98%] [learning rate: 4.8e+03]\n",
            "[Step 27011/50000] [Time: 231s] [Train Loss: 2.02e-01] [Train Acc: 0.95]\n",
            "[Step 27017/50000] [Progress: 54.03%] [learning rate: 5.2e+03]\n",
            "[Step 27040/50000] [Progress: 54.08%] [learning rate: 4.2e+03]\n",
            "[Step 27067/50000] [Progress: 54.13%] [learning rate: 5.0e+03]\n",
            "[Step 27090/50000] [Progress: 54.18%] [learning rate: 4.5e+03]\n",
            "[Step 27105/50000] [Time: 232s] [Train Loss: 2.01e-01] [Train Acc: 0.95]\n",
            "[Step 27115/50000] [Progress: 54.23%] [learning rate: 4.9e+03]\n",
            "[Step 27139/50000] [Progress: 54.28%] [learning rate: 4.3e+03]\n",
            "[Step 27166/50000] [Progress: 54.33%] [learning rate: 5.2e+03]\n",
            "[Step 27188/50000] [Progress: 54.38%] [learning rate: 4.2e+03]\n",
            "[Step 27199/50000] [Time: 232s] [Train Loss: 2.01e-01] [Train Acc: 0.95]\n",
            "[Step 27214/50000] [Progress: 54.43%] [learning rate: 5.0e+03]\n",
            "[Step 27237/50000] [Progress: 54.47%] [learning rate: 4.5e+03]\n",
            "[Step 27262/50000] [Progress: 54.52%] [learning rate: 4.4e+03]\n",
            "[Step 27287/50000] [Progress: 54.57%] [learning rate: 4.8e+03]\n",
            "[Step 27293/50000] [Time: 234s] [Train Loss: 2.01e-01] [Train Acc: 0.95]\n",
            "[Step 27312/50000] [Progress: 54.62%] [learning rate: 5.2e+03]\n",
            "[Step 27335/50000] [Progress: 54.67%] [learning rate: 4.2e+03]\n",
            "[Step 27362/50000] [Progress: 54.72%] [learning rate: 5.1e+03]\n",
            "[Step 27385/50000] [Progress: 54.77%] [learning rate: 4.1e+03]\n",
            "[Step 27387/50000] [Time: 234s] [Train Loss: 2.00e-01] [Train Acc: 0.95]\n",
            "[Step 27412/50000] [Progress: 54.82%] [learning rate: 4.9e+03]\n",
            "[Step 27437/50000] [Progress: 54.87%] [learning rate: 4.4e+03]\n",
            "[Step 27463/50000] [Progress: 54.93%] [learning rate: 5.2e+03]\n",
            "[Step 27481/50000] [Time: 235s] [Train Loss: 2.00e-01] [Train Acc: 0.95]\n",
            "[Step 27486/50000] [Progress: 54.97%] [learning rate: 4.3e+03]\n",
            "[Step 27513/50000] [Progress: 55.03%] [learning rate: 5.1e+03]\n",
            "[Step 27536/50000] [Progress: 55.07%] [learning rate: 4.1e+03]\n",
            "[Step 27562/50000] [Progress: 55.12%] [learning rate: 4.9e+03]\n",
            "[Step 27575/50000] [Time: 236s] [Train Loss: 1.99e-01] [Train Acc: 0.95]\n",
            "[Step 27586/50000] [Progress: 55.17%] [learning rate: 4.4e+03]\n",
            "[Step 27612/50000] [Progress: 55.22%] [learning rate: 4.8e+03]\n",
            "[Step 27636/50000] [Progress: 55.27%] [learning rate: 4.7e+03]\n",
            "[Step 27661/50000] [Progress: 55.32%] [learning rate: 4.6e+03]\n",
            "[Step 27669/50000] [Time: 236s] [Train Loss: 1.99e-01] [Train Acc: 0.95]\n",
            "[Step 27687/50000] [Progress: 55.37%] [learning rate: 4.6e+03]\n",
            "[Step 27712/50000] [Progress: 55.42%] [learning rate: 4.5e+03]\n",
            "[Step 27739/50000] [Progress: 55.48%] [learning rate: 4.9e+03]\n",
            "[Step 27763/50000] [Time: 237s] [Train Loss: 1.98e-01] [Train Acc: 0.95]\n",
            "[Step 27765/50000] [Progress: 55.53%] [learning rate: 4.8e+03]\n",
            "[Step 27791/50000] [Progress: 55.58%] [learning rate: 5.2e+03]\n",
            "[Step 27814/50000] [Progress: 55.63%] [learning rate: 4.2e+03]\n",
            "[Step 27841/50000] [Progress: 55.68%] [learning rate: 5.0e+03]\n",
            "[Step 27857/50000] [Time: 238s] [Train Loss: 1.98e-01] [Train Acc: 0.95]\n",
            "[Step 27864/50000] [Progress: 55.73%] [learning rate: 4.5e+03]\n",
            "[Step 27889/50000] [Progress: 55.78%] [learning rate: 4.9e+03]\n",
            "[Step 27913/50000] [Progress: 55.83%] [learning rate: 4.8e+03]\n",
            "[Step 27938/50000] [Progress: 55.88%] [learning rate: 4.7e+03]\n",
            "[Step 27951/50000] [Time: 239s] [Train Loss: 1.98e-01] [Train Acc: 0.95]\n",
            "[Step 27962/50000] [Progress: 55.92%] [learning rate: 4.7e+03]\n",
            "[Step 27987/50000] [Progress: 55.97%] [learning rate: 4.6e+03]\n",
            "[Step 28013/50000] [Progress: 56.03%] [learning rate: 5.0e+03]\n",
            "[Step 28036/50000] [Progress: 56.07%] [learning rate: 4.5e+03]\n",
            "[Step 28045/50000] [Time: 239s] [Train Loss: 1.97e-01] [Train Acc: 0.95]\n",
            "[Step 28062/50000] [Progress: 56.12%] [learning rate: 4.8e+03]\n",
            "[Step 28087/50000] [Progress: 56.17%] [learning rate: 5.2e+03]\n",
            "[Step 28110/50000] [Progress: 56.22%] [learning rate: 4.3e+03]\n",
            "[Step 28137/50000] [Progress: 56.27%] [learning rate: 5.1e+03]\n",
            "[Step 28139/50000] [Time: 240s] [Train Loss: 1.97e-01] [Train Acc: 0.95]\n",
            "[Step 28160/50000] [Progress: 56.32%] [learning rate: 4.1e+03]\n",
            "[Step 28187/50000] [Progress: 56.37%] [learning rate: 4.9e+03]\n",
            "[Step 28212/50000] [Progress: 56.42%] [learning rate: 4.9e+03]\n",
            "[Step 28234/50000] [Time: 241s] [Train Loss: 1.96e-01] [Train Acc: 0.95]\n",
            "[Step 28238/50000] [Progress: 56.48%] [learning rate: 5.3e+03]\n",
            "[Step 28261/50000] [Progress: 56.52%] [learning rate: 4.3e+03]\n",
            "[Step 28288/50000] [Progress: 56.58%] [learning rate: 5.1e+03]\n",
            "[Step 28311/50000] [Progress: 56.62%] [learning rate: 4.2e+03]\n",
            "[Step 28329/50000] [Time: 242s] [Train Loss: 1.96e-01] [Train Acc: 0.95]\n",
            "[Step 28337/50000] [Progress: 56.67%] [learning rate: 5.0e+03]\n",
            "[Step 28361/50000] [Progress: 56.72%] [learning rate: 4.4e+03]\n",
            "[Step 28388/50000] [Progress: 56.78%] [learning rate: 5.3e+03]\n",
            "[Step 28412/50000] [Progress: 56.82%] [learning rate: 4.7e+03]\n",
            "[Step 28424/50000] [Time: 242s] [Train Loss: 1.96e-01] [Train Acc: 0.95]\n",
            "[Step 28437/50000] [Progress: 56.87%] [learning rate: 4.7e+03]\n",
            "[Step 28463/50000] [Progress: 56.93%] [learning rate: 4.6e+03]\n",
            "[Step 28488/50000] [Progress: 56.98%] [learning rate: 4.5e+03]\n",
            "[Step 28515/50000] [Progress: 57.03%] [learning rate: 4.9e+03]\n",
            "[Step 28519/50000] [Time: 243s] [Train Loss: 1.95e-01] [Train Acc: 0.95]\n",
            "[Step 28541/50000] [Progress: 57.08%] [learning rate: 5.3e+03]\n",
            "[Step 28564/50000] [Progress: 57.13%] [learning rate: 4.3e+03]\n",
            "[Step 28591/50000] [Progress: 57.18%] [learning rate: 5.2e+03]\n",
            "[Step 28614/50000] [Progress: 57.23%] [learning rate: 4.6e+03]\n",
            "[Step 28614/50000] [Time: 244s] [Train Loss: 1.95e-01] [Train Acc: 0.95]\n",
            "[Step 28639/50000] [Progress: 57.28%] [learning rate: 4.5e+03]\n",
            "[Step 28666/50000] [Progress: 57.33%] [learning rate: 4.9e+03]\n",
            "[Step 28692/50000] [Progress: 57.38%] [learning rate: 4.9e+03]\n",
            "[Step 28709/50000] [Time: 245s] [Train Loss: 1.95e-01] [Train Acc: 0.95]\n",
            "[Step 28717/50000] [Progress: 57.43%] [learning rate: 4.8e+03]\n",
            "[Step 28743/50000] [Progress: 57.49%] [learning rate: 4.7e+03]\n",
            "[Step 28769/50000] [Progress: 57.54%] [learning rate: 4.6e+03]\n",
            "[Step 28794/50000] [Progress: 57.59%] [learning rate: 4.6e+03]\n",
            "[Step 28804/50000] [Time: 245s] [Train Loss: 1.94e-01] [Train Acc: 0.95] [Eval Loss: 5.09e-01] [Eval Acc: 0.78]\n",
            "[Step 28821/50000] [Progress: 57.64%] [learning rate: 4.9e+03]\n",
            "[Step 28847/50000] [Progress: 57.69%] [learning rate: 4.9e+03]\n",
            "[Step 28873/50000] [Progress: 57.75%] [learning rate: 4.8e+03]\n",
            "[Step 28897/50000] [Progress: 57.79%] [learning rate: 4.7e+03]\n",
            "[Step 28899/50000] [Time: 248s] [Train Loss: 1.94e-01] [Train Acc: 0.95]\n",
            "[Step 28922/50000] [Progress: 57.84%] [learning rate: 4.7e+03]\n",
            "[Step 28948/50000] [Progress: 57.90%] [learning rate: 5.0e+03]\n",
            "[Step 28972/50000] [Progress: 57.94%] [learning rate: 4.5e+03]\n",
            "[Step 28994/50000] [Time: 248s] [Train Loss: 1.93e-01] [Train Acc: 0.95]\n",
            "[Step 28999/50000] [Progress: 58.00%] [learning rate: 4.9e+03]\n",
            "[Step 29024/50000] [Progress: 58.05%] [learning rate: 4.8e+03]\n",
            "[Step 29050/50000] [Progress: 58.10%] [learning rate: 4.8e+03]\n",
            "[Step 29074/50000] [Progress: 58.15%] [learning rate: 4.7e+03]\n",
            "[Step 29089/50000] [Time: 249s] [Train Loss: 1.93e-01] [Train Acc: 0.95]\n",
            "[Step 29099/50000] [Progress: 58.20%] [learning rate: 4.6e+03]\n",
            "[Step 29124/50000] [Progress: 58.25%] [learning rate: 4.5e+03]\n",
            "[Step 29150/50000] [Progress: 58.30%] [learning rate: 4.9e+03]\n",
            "[Step 29176/50000] [Progress: 58.35%] [learning rate: 5.3e+03]\n",
            "[Step 29184/50000] [Time: 250s] [Train Loss: 1.93e-01] [Train Acc: 0.95]\n",
            "[Step 29199/50000] [Progress: 58.40%] [learning rate: 4.3e+03]\n",
            "[Step 29225/50000] [Progress: 58.45%] [learning rate: 4.7e+03]\n",
            "[Step 29250/50000] [Progress: 58.50%] [learning rate: 4.6e+03]\n",
            "[Step 29276/50000] [Progress: 58.55%] [learning rate: 5.0e+03]\n",
            "[Step 29279/50000] [Time: 250s] [Train Loss: 1.92e-01] [Train Acc: 0.95]\n",
            "[Step 29300/50000] [Progress: 58.60%] [learning rate: 4.5e+03]\n",
            "[Step 29328/50000] [Progress: 58.66%] [learning rate: 5.9e+03]\n",
            "[Step 29351/50000] [Progress: 58.70%] [learning rate: 4.8e+03]\n",
            "[Step 29374/50000] [Time: 251s] [Train Loss: 1.92e-01] [Train Acc: 0.95]\n",
            "[Step 29376/50000] [Progress: 58.75%] [learning rate: 4.7e+03]\n",
            "[Step 29402/50000] [Progress: 58.80%] [learning rate: 4.7e+03]\n",
            "[Step 29427/50000] [Progress: 58.85%] [learning rate: 4.6e+03]\n",
            "[Step 29454/50000] [Progress: 58.91%] [learning rate: 5.0e+03]\n",
            "[Step 29469/50000] [Time: 252s] [Train Loss: 1.91e-01] [Train Acc: 0.95]\n",
            "[Step 29481/50000] [Progress: 58.96%] [learning rate: 5.4e+03]\n",
            "[Step 29505/50000] [Progress: 59.01%] [learning rate: 4.8e+03]\n",
            "[Step 29530/50000] [Progress: 59.06%] [learning rate: 4.7e+03]\n",
            "[Step 29556/50000] [Progress: 59.11%] [learning rate: 4.7e+03]\n",
            "[Step 29564/50000] [Time: 253s] [Train Loss: 1.91e-01] [Train Acc: 0.95]\n",
            "[Step 29581/50000] [Progress: 59.16%] [learning rate: 4.6e+03]\n",
            "[Step 29608/50000] [Progress: 59.22%] [learning rate: 5.0e+03]\n",
            "[Step 29634/50000] [Progress: 59.27%] [learning rate: 5.4e+03]\n",
            "[Step 29657/50000] [Progress: 59.31%] [learning rate: 4.4e+03]\n",
            "[Step 29659/50000] [Time: 253s] [Train Loss: 1.91e-01] [Train Acc: 0.95]\n",
            "[Step 29683/50000] [Progress: 59.37%] [learning rate: 4.8e+03]\n",
            "[Step 29709/50000] [Progress: 59.42%] [learning rate: 5.2e+03]\n",
            "[Step 29732/50000] [Progress: 59.46%] [learning rate: 4.6e+03]\n",
            "[Step 29754/50000] [Time: 254s] [Train Loss: 1.90e-01] [Train Acc: 0.95]\n",
            "[Step 29757/50000] [Progress: 59.51%] [learning rate: 5.0e+03]\n",
            "[Step 29782/50000] [Progress: 59.56%] [learning rate: 4.9e+03]\n",
            "[Step 29808/50000] [Progress: 59.62%] [learning rate: 4.9e+03]\n",
            "[Step 29832/50000] [Progress: 59.66%] [learning rate: 4.8e+03]\n",
            "[Step 29849/50000] [Time: 255s] [Train Loss: 1.90e-01] [Train Acc: 0.95]\n",
            "[Step 29857/50000] [Progress: 59.71%] [learning rate: 4.7e+03]\n",
            "[Step 29883/50000] [Progress: 59.77%] [learning rate: 5.1e+03]\n",
            "[Step 29907/50000] [Progress: 59.81%] [learning rate: 4.6e+03]\n",
            "[Step 29934/50000] [Progress: 59.87%] [learning rate: 5.4e+03]\n",
            "[Step 29944/50000] [Time: 255s] [Train Loss: 1.90e-01] [Train Acc: 0.95]\n",
            "[Step 29957/50000] [Progress: 59.91%] [learning rate: 4.4e+03]\n",
            "[Step 29983/50000] [Progress: 59.97%] [learning rate: 4.8e+03]\n",
            "[Step 30007/50000] [Progress: 60.01%] [learning rate: 4.7e+03]\n",
            "[Step 30032/50000] [Progress: 60.06%] [learning rate: 4.7e+03]\n",
            "[Step 30039/50000] [Time: 256s] [Train Loss: 1.89e-01] [Train Acc: 0.95]\n",
            "[Step 30057/50000] [Progress: 60.11%] [learning rate: 5.1e+03]\n",
            "[Step 30081/50000] [Progress: 60.16%] [learning rate: 5.0e+03]\n",
            "[Step 30106/50000] [Progress: 60.21%] [learning rate: 4.9e+03]\n",
            "[Step 30132/50000] [Progress: 60.26%] [learning rate: 4.8e+03]\n",
            "[Step 30135/50000] [Time: 257s] [Train Loss: 1.89e-01] [Train Acc: 0.95]\n",
            "[Step 30156/50000] [Progress: 60.31%] [learning rate: 4.8e+03]\n",
            "[Step 30181/50000] [Progress: 60.36%] [learning rate: 4.7e+03]\n",
            "[Step 30206/50000] [Progress: 60.41%] [learning rate: 4.6e+03]\n",
            "[Step 30231/50000] [Time: 257s] [Train Loss: 1.88e-01] [Train Acc: 0.96]\n",
            "[Step 30232/50000] [Progress: 60.46%] [learning rate: 5.0e+03]\n",
            "[Step 30259/50000] [Progress: 60.52%] [learning rate: 5.4e+03]\n",
            "[Step 30283/50000] [Progress: 60.57%] [learning rate: 4.8e+03]\n",
            "[Step 30308/50000] [Progress: 60.62%] [learning rate: 4.8e+03]\n",
            "[Step 30327/50000] [Time: 258s] [Train Loss: 1.88e-01] [Train Acc: 0.96]\n",
            "[Step 30334/50000] [Progress: 60.67%] [learning rate: 4.7e+03]\n",
            "[Step 30359/50000] [Progress: 60.72%] [learning rate: 4.6e+03]\n",
            "[Step 30386/50000] [Progress: 60.77%] [learning rate: 5.0e+03]\n",
            "[Step 30412/50000] [Progress: 60.82%] [learning rate: 5.4e+03]\n",
            "[Step 30423/50000] [Time: 259s] [Train Loss: 1.88e-01] [Train Acc: 0.96]\n",
            "[Step 30435/50000] [Progress: 60.87%] [learning rate: 4.4e+03]\n",
            "[Step 30462/50000] [Progress: 60.92%] [learning rate: 5.3e+03]\n",
            "[Step 30485/50000] [Progress: 60.97%] [learning rate: 4.3e+03]\n",
            "[Step 30511/50000] [Progress: 61.02%] [learning rate: 5.1e+03]\n",
            "[Step 30519/50000] [Time: 259s] [Train Loss: 1.87e-01] [Train Acc: 0.96]\n",
            "[Step 30535/50000] [Progress: 61.07%] [learning rate: 4.6e+03]\n",
            "[Step 30562/50000] [Progress: 61.12%] [learning rate: 5.5e+03]\n",
            "[Step 30586/50000] [Progress: 61.17%] [learning rate: 4.9e+03]\n",
            "[Step 30611/50000] [Progress: 61.22%] [learning rate: 4.8e+03]\n",
            "[Step 30615/50000] [Time: 260s] [Train Loss: 1.87e-01] [Train Acc: 0.96]\n",
            "[Step 30637/50000] [Progress: 61.27%] [learning rate: 4.7e+03]\n",
            "[Step 30663/50000] [Progress: 61.33%] [learning rate: 5.1e+03]\n",
            "[Step 30687/50000] [Progress: 61.37%] [learning rate: 4.6e+03]\n",
            "[Step 30711/50000] [Time: 261s] [Train Loss: 1.87e-01] [Train Acc: 0.96]\n",
            "[Step 30713/50000] [Progress: 61.43%] [learning rate: 5.5e+03]\n",
            "[Step 30736/50000] [Progress: 61.47%] [learning rate: 4.5e+03]\n",
            "[Step 30763/50000] [Progress: 61.53%] [learning rate: 5.3e+03]\n",
            "[Step 30786/50000] [Progress: 61.57%] [learning rate: 4.8e+03]\n",
            "[Step 30807/50000] [Time: 261s] [Train Loss: 1.86e-01] [Train Acc: 0.96]\n",
            "[Step 30811/50000] [Progress: 61.62%] [learning rate: 4.7e+03]\n",
            "[Step 30836/50000] [Progress: 61.67%] [learning rate: 4.6e+03]\n",
            "[Step 30862/50000] [Progress: 61.72%] [learning rate: 5.5e+03]\n",
            "[Step 30885/50000] [Progress: 61.77%] [learning rate: 4.5e+03]\n",
            "[Step 30903/50000] [Time: 262s] [Train Loss: 1.86e-01] [Train Acc: 0.96]\n",
            "[Step 30912/50000] [Progress: 61.82%] [learning rate: 5.3e+03]\n",
            "[Step 30935/50000] [Progress: 61.87%] [learning rate: 4.4e+03]\n",
            "[Step 30961/50000] [Progress: 61.92%] [learning rate: 5.2e+03]\n",
            "[Step 30985/50000] [Progress: 61.97%] [learning rate: 4.6e+03]\n",
            "[Step 30999/50000] [Time: 263s] [Train Loss: 1.85e-01] [Train Acc: 0.96]\n",
            "[Step 31012/50000] [Progress: 62.02%] [learning rate: 5.5e+03]\n",
            "[Step 31035/50000] [Progress: 62.07%] [learning rate: 4.5e+03]\n",
            "[Step 31061/50000] [Progress: 62.12%] [learning rate: 4.9e+03]\n",
            "[Step 31085/50000] [Progress: 62.17%] [learning rate: 4.8e+03]\n",
            "[Step 31095/50000] [Time: 264s] [Train Loss: 1.85e-01] [Train Acc: 0.96]\n",
            "[Step 31110/50000] [Progress: 62.22%] [learning rate: 4.7e+03]\n",
            "[Step 31135/50000] [Progress: 62.27%] [learning rate: 5.1e+03]\n",
            "[Step 31159/50000] [Progress: 62.32%] [learning rate: 4.6e+03]\n",
            "[Step 31186/50000] [Progress: 62.37%] [learning rate: 5.5e+03]\n",
            "[Step 31191/50000] [Time: 265s] [Train Loss: 1.85e-01] [Train Acc: 0.96]\n",
            "[Step 31210/50000] [Progress: 62.42%] [learning rate: 4.9e+03]\n",
            "[Step 31235/50000] [Progress: 62.47%] [learning rate: 4.8e+03]\n",
            "[Step 31261/50000] [Progress: 62.52%] [learning rate: 4.8e+03]\n",
            "[Step 31286/50000] [Progress: 62.57%] [learning rate: 4.7e+03]\n",
            "[Step 31287/50000] [Time: 265s] [Train Loss: 1.84e-01] [Train Acc: 0.96]\n",
            "[Step 31311/50000] [Progress: 62.62%] [learning rate: 5.1e+03]\n",
            "[Step 31337/50000] [Progress: 62.67%] [learning rate: 5.5e+03]\n",
            "[Step 31361/50000] [Progress: 62.72%] [learning rate: 4.9e+03]\n",
            "[Step 31383/50000] [Time: 266s] [Train Loss: 1.84e-01] [Train Acc: 0.96]\n",
            "[Step 31386/50000] [Progress: 62.77%] [learning rate: 4.9e+03]\n",
            "[Step 31412/50000] [Progress: 62.82%] [learning rate: 5.3e+03]\n",
            "[Step 31435/50000] [Progress: 62.87%] [learning rate: 4.7e+03]\n",
            "[Step 31461/50000] [Progress: 62.92%] [learning rate: 5.1e+03]\n",
            "[Step 31479/50000] [Time: 267s] [Train Loss: 1.84e-01] [Train Acc: 0.96]\n",
            "[Step 31488/50000] [Progress: 62.98%] [learning rate: 5.5e+03]\n",
            "[Step 31513/50000] [Progress: 63.03%] [learning rate: 5.0e+03]\n",
            "[Step 31539/50000] [Progress: 63.08%] [learning rate: 4.9e+03]\n",
            "[Step 31565/50000] [Progress: 63.13%] [learning rate: 4.8e+03]\n",
            "[Step 31575/50000] [Time: 268s] [Train Loss: 1.83e-01] [Train Acc: 0.96]\n",
            "[Step 31590/50000] [Progress: 63.18%] [learning rate: 4.7e+03]\n",
            "[Step 31615/50000] [Progress: 63.23%] [learning rate: 5.1e+03]\n",
            "[Step 31640/50000] [Progress: 63.28%] [learning rate: 5.0e+03]\n",
            "[Step 31664/50000] [Progress: 63.33%] [learning rate: 5.0e+03]\n",
            "[Step 31671/50000] [Time: 269s] [Train Loss: 1.83e-01] [Train Acc: 0.96]\n",
            "[Step 31689/50000] [Progress: 63.38%] [learning rate: 4.9e+03]\n",
            "[Step 31715/50000] [Progress: 63.43%] [learning rate: 4.8e+03]\n",
            "[Step 31740/50000] [Progress: 63.48%] [learning rate: 4.8e+03]\n",
            "[Step 31767/50000] [Progress: 63.53%] [learning rate: 5.1e+03]\n",
            "[Step 31767/50000] [Time: 269s] [Train Loss: 1.83e-01] [Train Acc: 0.96]\n",
            "[Step 31793/50000] [Progress: 63.59%] [learning rate: 5.6e+03]\n",
            "[Step 31816/50000] [Progress: 63.63%] [learning rate: 4.5e+03]\n",
            "[Step 31843/50000] [Progress: 63.69%] [learning rate: 5.4e+03]\n",
            "[Step 31863/50000] [Time: 270s] [Train Loss: 1.82e-01] [Train Acc: 0.96]\n",
            "[Step 31866/50000] [Progress: 63.73%] [learning rate: 4.4e+03]\n",
            "[Step 31892/50000] [Progress: 63.78%] [learning rate: 5.3e+03]\n",
            "[Step 31916/50000] [Progress: 63.83%] [learning rate: 4.7e+03]\n",
            "[Step 31943/50000] [Progress: 63.89%] [learning rate: 5.6e+03]\n",
            "[Step 31959/50000] [Time: 271s] [Train Loss: 1.82e-01] [Train Acc: 0.96]\n",
            "[Step 31966/50000] [Progress: 63.93%] [learning rate: 5.0e+03]\n",
            "[Step 31991/50000] [Progress: 63.98%] [learning rate: 4.9e+03]\n",
            "[Step 32017/50000] [Progress: 64.03%] [learning rate: 4.9e+03]\n",
            "[Step 32043/50000] [Progress: 64.09%] [learning rate: 5.3e+03]\n",
            "[Step 32055/50000] [Time: 271s] [Train Loss: 1.82e-01] [Train Acc: 0.96]\n",
            "[Step 32067/50000] [Progress: 64.13%] [learning rate: 4.7e+03]\n",
            "[Step 32094/50000] [Progress: 64.19%] [learning rate: 5.6e+03]\n",
            "[Step 32117/50000] [Progress: 64.23%] [learning rate: 4.6e+03]\n",
            "[Step 32143/50000] [Progress: 64.29%] [learning rate: 5.0e+03]\n",
            "[Step 32151/50000] [Time: 272s] [Train Loss: 1.81e-01] [Train Acc: 0.96]\n",
            "[Step 32169/50000] [Progress: 64.34%] [learning rate: 5.4e+03]\n",
            "[Step 32192/50000] [Progress: 64.38%] [learning rate: 4.4e+03]\n",
            "[Step 32219/50000] [Progress: 64.44%] [learning rate: 5.2e+03]\n",
            "[Step 32244/50000] [Progress: 64.49%] [learning rate: 5.1e+03]\n",
            "[Step 32247/50000] [Time: 273s] [Train Loss: 1.81e-01] [Train Acc: 0.96]\n",
            "[Step 32269/50000] [Progress: 64.54%] [learning rate: 5.6e+03]\n",
            "[Step 32292/50000] [Progress: 64.58%] [learning rate: 4.5e+03]\n",
            "[Step 32319/50000] [Progress: 64.64%] [learning rate: 5.4e+03]\n",
            "[Step 32342/50000] [Progress: 64.68%] [learning rate: 4.8e+03]\n",
            "[Step 32344/50000] [Time: 274s] [Train Loss: 1.81e-01] [Train Acc: 0.96]\n",
            "[Step 32367/50000] [Progress: 64.73%] [learning rate: 5.2e+03]\n",
            "[Step 32391/50000] [Progress: 64.78%] [learning rate: 4.7e+03]\n",
            "[Step 32418/50000] [Progress: 64.84%] [learning rate: 6.2e+03]\n",
            "[Step 32439/50000] [Progress: 64.88%] [learning rate: 4.1e+03]\n",
            "[Step 32441/50000] [Time: 274s] [Train Loss: 1.80e-01] [Train Acc: 0.96]\n",
            "[Step 32466/50000] [Progress: 64.93%] [learning rate: 5.4e+03]\n",
            "[Step 32489/50000] [Progress: 64.98%] [learning rate: 4.9e+03]\n",
            "[Step 32514/50000] [Progress: 65.03%] [learning rate: 4.8e+03]\n",
            "[Step 32538/50000] [Time: 275s] [Train Loss: 1.80e-01] [Train Acc: 0.96]\n",
            "[Step 32539/50000] [Progress: 65.08%] [learning rate: 5.2e+03]\n",
            "[Step 32564/50000] [Progress: 65.13%] [learning rate: 5.6e+03]\n",
            "[Step 32587/50000] [Progress: 65.17%] [learning rate: 4.6e+03]\n",
            "[Step 32613/50000] [Progress: 65.23%] [learning rate: 5.0e+03]\n",
            "[Step 32635/50000] [Time: 276s] [Train Loss: 1.79e-01] [Train Acc: 0.96]\n",
            "[Step 32637/50000] [Progress: 65.27%] [learning rate: 4.9e+03]\n",
            "[Step 32662/50000] [Progress: 65.32%] [learning rate: 5.3e+03]\n",
            "[Step 32686/50000] [Progress: 65.37%] [learning rate: 4.7e+03]\n",
            "[Step 32714/50000] [Progress: 65.43%] [learning rate: 5.6e+03]\n",
            "[Step 32732/50000] [Time: 277s] [Train Loss: 1.79e-01] [Train Acc: 0.96]\n",
            "[Step 32739/50000] [Progress: 65.48%] [learning rate: 5.1e+03]\n",
            "[Step 32765/50000] [Progress: 65.53%] [learning rate: 5.0e+03]\n",
            "[Step 32791/50000] [Progress: 65.58%] [learning rate: 4.9e+03]\n",
            "[Step 32816/50000] [Progress: 65.63%] [learning rate: 4.8e+03]\n",
            "[Step 32829/50000] [Time: 277s] [Train Loss: 1.79e-01] [Train Acc: 0.96]\n",
            "[Step 32843/50000] [Progress: 65.69%] [learning rate: 5.2e+03]\n",
            "[Step 32869/50000] [Progress: 65.74%] [learning rate: 5.2e+03]\n",
            "[Step 32893/50000] [Progress: 65.79%] [learning rate: 5.1e+03]\n",
            "[Step 32918/50000] [Progress: 65.84%] [learning rate: 5.0e+03]\n",
            "[Step 32926/50000] [Time: 278s] [Train Loss: 1.78e-01] [Train Acc: 0.96]\n",
            "[Step 32944/50000] [Progress: 65.89%] [learning rate: 4.9e+03]\n",
            "[Step 32969/50000] [Progress: 65.94%] [learning rate: 4.9e+03]\n",
            "[Step 32996/50000] [Progress: 65.99%] [learning rate: 5.3e+03]\n",
            "[Step 33022/50000] [Progress: 66.04%] [learning rate: 5.2e+03]\n",
            "[Step 33023/50000] [Time: 279s] [Train Loss: 1.78e-01] [Train Acc: 0.96]\n",
            "[Step 33048/50000] [Progress: 66.10%] [learning rate: 5.6e+03]\n",
            "[Step 33071/50000] [Progress: 66.14%] [learning rate: 4.6e+03]\n",
            "[Step 33098/50000] [Progress: 66.20%] [learning rate: 5.4e+03]\n",
            "[Step 33120/50000] [Time: 279s] [Train Loss: 1.78e-01] [Train Acc: 0.96]\n",
            "[Step 33121/50000] [Progress: 66.24%] [learning rate: 4.9e+03]\n",
            "[Step 33146/50000] [Progress: 66.29%] [learning rate: 5.3e+03]\n",
            "[Step 33170/50000] [Progress: 66.34%] [learning rate: 5.2e+03]\n",
            "[Step 33195/50000] [Progress: 66.39%] [learning rate: 5.1e+03]\n",
            "[Step 33217/50000] [Time: 280s] [Train Loss: 1.77e-01] [Train Acc: 0.96]\n",
            "[Step 33219/50000] [Progress: 66.44%] [learning rate: 5.0e+03]\n",
            "[Step 33244/50000] [Progress: 66.49%] [learning rate: 5.0e+03]\n",
            "[Step 33270/50000] [Progress: 66.54%] [learning rate: 5.4e+03]\n",
            "[Step 33293/50000] [Progress: 66.59%] [learning rate: 4.8e+03]\n",
            "[Step 33314/50000] [Time: 281s] [Train Loss: 1.77e-01] [Train Acc: 0.96]\n",
            "[Step 33319/50000] [Progress: 66.64%] [learning rate: 5.2e+03]\n",
            "[Step 33346/50000] [Progress: 66.69%] [learning rate: 5.7e+03]\n",
            "[Step 33368/50000] [Progress: 66.74%] [learning rate: 4.6e+03]\n",
            "[Step 33394/50000] [Progress: 66.79%] [learning rate: 5.5e+03]\n",
            "[Step 33411/50000] [Time: 282s] [Train Loss: 1.77e-01] [Train Acc: 0.96]\n",
            "[Step 33417/50000] [Progress: 66.83%] [learning rate: 4.9e+03]\n",
            "[Step 33442/50000] [Progress: 66.88%] [learning rate: 5.3e+03]\n",
            "[Step 33466/50000] [Progress: 66.93%] [learning rate: 4.8e+03]\n",
            "[Step 33495/50000] [Progress: 66.99%] [learning rate: 6.3e+03]\n",
            "[Step 33508/50000] [Time: 282s] [Train Loss: 1.76e-01] [Train Acc: 0.96]\n",
            "[Step 33518/50000] [Progress: 67.04%] [learning rate: 5.1e+03]\n",
            "[Step 33543/50000] [Progress: 67.09%] [learning rate: 5.0e+03]\n",
            "[Step 33569/50000] [Progress: 67.14%] [learning rate: 4.9e+03]\n",
            "[Step 33595/50000] [Progress: 67.19%] [learning rate: 5.4e+03]\n",
            "[Step 33605/50000] [Time: 283s] [Train Loss: 1.76e-01] [Train Acc: 0.96] [Eval Loss: 5.13e-01] [Eval Acc: 0.78]\n",
            "[Step 33619/50000] [Progress: 67.24%] [learning rate: 5.3e+03]\n",
            "[Step 33644/50000] [Progress: 67.29%] [learning rate: 5.2e+03]\n",
            "[Step 33670/50000] [Progress: 67.34%] [learning rate: 5.6e+03]\n",
            "[Step 33693/50000] [Progress: 67.39%] [learning rate: 4.6e+03]\n",
            "[Step 33702/50000] [Time: 285s] [Train Loss: 1.76e-01] [Train Acc: 0.96]\n",
            "[Step 33720/50000] [Progress: 67.44%] [learning rate: 5.5e+03]\n",
            "[Step 33743/50000] [Progress: 67.49%] [learning rate: 4.9e+03]\n",
            "[Step 33769/50000] [Progress: 67.54%] [learning rate: 5.3e+03]\n",
            "[Step 33795/50000] [Progress: 67.59%] [learning rate: 5.2e+03]\n",
            "[Step 33799/50000] [Time: 286s] [Train Loss: 1.75e-01] [Train Acc: 0.96]\n",
            "[Step 33819/50000] [Progress: 67.64%] [learning rate: 5.1e+03]\n",
            "[Step 33844/50000] [Progress: 67.69%] [learning rate: 5.1e+03]\n",
            "[Step 33870/50000] [Progress: 67.74%] [learning rate: 5.0e+03]\n",
            "[Step 33895/50000] [Progress: 67.79%] [learning rate: 4.9e+03]\n",
            "[Step 33896/50000] [Time: 287s] [Train Loss: 1.75e-01] [Train Acc: 0.96]\n",
            "[Step 33922/50000] [Progress: 67.84%] [learning rate: 5.3e+03]\n",
            "[Step 33948/50000] [Progress: 67.90%] [learning rate: 5.2e+03]\n",
            "[Step 33974/50000] [Progress: 67.95%] [learning rate: 5.7e+03]\n",
            "[Step 33993/50000] [Time: 287s] [Train Loss: 1.75e-01] [Train Acc: 0.96]\n",
            "[Step 33997/50000] [Progress: 67.99%] [learning rate: 4.6e+03]\n",
            "[Step 34024/50000] [Progress: 68.05%] [learning rate: 5.5e+03]\n",
            "[Step 34047/50000] [Progress: 68.09%] [learning rate: 4.9e+03]\n",
            "[Step 34072/50000] [Progress: 68.14%] [learning rate: 5.3e+03]\n",
            "[Step 34090/50000] [Time: 288s] [Train Loss: 1.74e-01] [Train Acc: 0.96]\n",
            "[Step 34096/50000] [Progress: 68.19%] [learning rate: 5.3e+03]\n",
            "[Step 34121/50000] [Progress: 68.24%] [learning rate: 5.7e+03]\n",
            "[Step 34144/50000] [Progress: 68.29%] [learning rate: 4.6e+03]\n",
            "[Step 34171/50000] [Progress: 68.34%] [learning rate: 5.5e+03]\n",
            "[Step 34187/50000] [Time: 289s] [Train Loss: 1.74e-01] [Train Acc: 0.96]\n",
            "[Step 34194/50000] [Progress: 68.39%] [learning rate: 5.0e+03]\n",
            "[Step 34219/50000] [Progress: 68.44%] [learning rate: 5.4e+03]\n",
            "[Step 34243/50000] [Progress: 68.49%] [learning rate: 5.3e+03]\n",
            "[Step 34268/50000] [Progress: 68.54%] [learning rate: 5.7e+03]\n",
            "[Step 34284/50000] [Time: 290s] [Train Loss: 1.74e-01] [Train Acc: 0.96]\n",
            "[Step 34291/50000] [Progress: 68.58%] [learning rate: 4.7e+03]\n",
            "[Step 34318/50000] [Progress: 68.64%] [learning rate: 5.6e+03]\n",
            "[Step 34341/50000] [Progress: 68.68%] [learning rate: 4.5e+03]\n",
            "[Step 34368/50000] [Progress: 68.74%] [learning rate: 5.4e+03]\n",
            "[Step 34381/50000] [Time: 291s] [Train Loss: 1.73e-01] [Train Acc: 0.96]\n",
            "[Step 34393/50000] [Progress: 68.79%] [learning rate: 5.3e+03]\n",
            "[Step 34420/50000] [Progress: 68.84%] [learning rate: 6.3e+03]\n",
            "[Step 34443/50000] [Progress: 68.89%] [learning rate: 5.1e+03]\n",
            "[Step 34468/50000] [Progress: 68.94%] [learning rate: 5.1e+03]\n",
            "[Step 34478/50000] [Time: 291s] [Train Loss: 1.73e-01] [Train Acc: 0.96]\n",
            "[Step 34494/50000] [Progress: 68.99%] [learning rate: 5.0e+03]\n",
            "[Step 34519/50000] [Progress: 69.04%] [learning rate: 4.9e+03]\n",
            "[Step 34544/50000] [Progress: 69.09%] [learning rate: 5.3e+03]\n",
            "[Step 34569/50000] [Progress: 69.14%] [learning rate: 5.8e+03]\n",
            "[Step 34575/50000] [Time: 292s] [Train Loss: 1.73e-01] [Train Acc: 0.96]\n",
            "[Step 34592/50000] [Progress: 69.18%] [learning rate: 4.7e+03]\n",
            "[Step 34619/50000] [Progress: 69.24%] [learning rate: 5.6e+03]\n",
            "[Step 34642/50000] [Progress: 69.28%] [learning rate: 5.0e+03]\n",
            "[Step 34667/50000] [Progress: 69.33%] [learning rate: 4.9e+03]\n",
            "[Step 34672/50000] [Time: 293s] [Train Loss: 1.72e-01] [Train Acc: 0.96]\n",
            "[Step 34692/50000] [Progress: 69.38%] [learning rate: 5.4e+03]\n",
            "[Step 34717/50000] [Progress: 69.43%] [learning rate: 5.3e+03]\n",
            "[Step 34743/50000] [Progress: 69.49%] [learning rate: 5.7e+03]\n",
            "[Step 34766/50000] [Progress: 69.53%] [learning rate: 4.7e+03]\n",
            "[Step 34769/50000] [Time: 294s] [Train Loss: 1.72e-01] [Train Acc: 0.96]\n",
            "[Step 34793/50000] [Progress: 69.59%] [learning rate: 5.5e+03]\n",
            "[Step 34816/50000] [Progress: 69.63%] [learning rate: 5.0e+03]\n",
            "[Step 34841/50000] [Progress: 69.68%] [learning rate: 5.4e+03]\n",
            "[Step 34866/50000] [Progress: 69.73%] [learning rate: 5.3e+03]\n",
            "[Step 34866/50000] [Time: 294s] [Train Loss: 1.72e-01] [Train Acc: 0.96]\n",
            "[Step 34892/50000] [Progress: 69.78%] [learning rate: 5.7e+03]\n",
            "[Step 34915/50000] [Progress: 69.83%] [learning rate: 4.7e+03]\n",
            "[Step 34942/50000] [Progress: 69.88%] [learning rate: 5.6e+03]\n",
            "[Step 34963/50000] [Time: 295s] [Train Loss: 1.72e-01] [Train Acc: 0.96]\n",
            "[Step 34965/50000] [Progress: 69.93%] [learning rate: 5.0e+03]\n",
            "[Step 34990/50000] [Progress: 69.98%] [learning rate: 5.4e+03]\n",
            "[Step 35015/50000] [Progress: 70.03%] [learning rate: 5.3e+03]\n",
            "[Step 35041/50000] [Progress: 70.08%] [learning rate: 5.2e+03]\n",
            "[Step 35060/50000] [Time: 296s] [Train Loss: 1.71e-01] [Train Acc: 0.96]\n",
            "[Step 35065/50000] [Progress: 70.13%] [learning rate: 5.2e+03]\n",
            "[Step 35090/50000] [Progress: 70.18%] [learning rate: 5.1e+03]\n",
            "[Step 35116/50000] [Progress: 70.23%] [learning rate: 5.5e+03]\n",
            "[Step 35139/50000] [Progress: 70.28%] [learning rate: 4.9e+03]\n",
            "[Step 35157/50000] [Time: 296s] [Train Loss: 1.71e-01] [Train Acc: 0.96]\n",
            "[Step 35165/50000] [Progress: 70.33%] [learning rate: 5.3e+03]\n",
            "[Step 35190/50000] [Progress: 70.38%] [learning rate: 5.3e+03]\n",
            "[Step 35214/50000] [Progress: 70.43%] [learning rate: 5.2e+03]\n",
            "[Step 35239/50000] [Progress: 70.48%] [learning rate: 5.1e+03]\n",
            "[Step 35255/50000] [Time: 297s] [Train Loss: 1.71e-01] [Train Acc: 0.96]\n",
            "[Step 35265/50000] [Progress: 70.53%] [learning rate: 5.0e+03]\n",
            "[Step 35290/50000] [Progress: 70.58%] [learning rate: 5.0e+03]\n",
            "[Step 35316/50000] [Progress: 70.63%] [learning rate: 5.4e+03]\n",
            "[Step 35343/50000] [Progress: 70.69%] [learning rate: 5.8e+03]\n",
            "[Step 35353/50000] [Time: 298s] [Train Loss: 1.70e-01] [Train Acc: 0.96]\n",
            "[Step 35366/50000] [Progress: 70.73%] [learning rate: 4.7e+03]\n",
            "[Step 35393/50000] [Progress: 70.79%] [learning rate: 5.6e+03]\n",
            "[Step 35416/50000] [Progress: 70.83%] [learning rate: 4.6e+03]\n",
            "[Step 35442/50000] [Progress: 70.88%] [learning rate: 5.5e+03]\n",
            "[Step 35451/50000] [Time: 298s] [Train Loss: 1.70e-01] [Train Acc: 0.96]\n",
            "[Step 35466/50000] [Progress: 70.93%] [learning rate: 5.4e+03]\n",
            "[Step 35491/50000] [Progress: 70.98%] [learning rate: 5.8e+03]\n",
            "[Step 35514/50000] [Progress: 71.03%] [learning rate: 4.8e+03]\n",
            "[Step 35541/50000] [Progress: 71.08%] [learning rate: 5.7e+03]\n",
            "[Step 35549/50000] [Time: 299s] [Train Loss: 1.70e-01] [Train Acc: 0.96]\n",
            "[Step 35564/50000] [Progress: 71.13%] [learning rate: 5.1e+03]\n",
            "[Step 35589/50000] [Progress: 71.18%] [learning rate: 5.0e+03]\n",
            "[Step 35614/50000] [Progress: 71.23%] [learning rate: 5.4e+03]\n",
            "[Step 35639/50000] [Progress: 71.28%] [learning rate: 5.3e+03]\n",
            "[Step 35647/50000] [Time: 300s] [Train Loss: 1.69e-01] [Train Acc: 0.97]\n",
            "[Step 35663/50000] [Progress: 71.33%] [learning rate: 5.3e+03]\n",
            "[Step 35688/50000] [Progress: 71.38%] [learning rate: 5.2e+03]\n",
            "[Step 35714/50000] [Progress: 71.43%] [learning rate: 5.1e+03]\n",
            "[Step 35739/50000] [Progress: 71.48%] [learning rate: 5.0e+03]\n",
            "[Step 35745/50000] [Time: 301s] [Train Loss: 1.69e-01] [Train Acc: 0.97]\n",
            "[Step 35766/50000] [Progress: 71.53%] [learning rate: 5.4e+03]\n",
            "[Step 35792/50000] [Progress: 71.58%] [learning rate: 5.4e+03]\n",
            "[Step 35818/50000] [Progress: 71.64%] [learning rate: 5.8e+03]\n",
            "[Step 35841/50000] [Progress: 71.68%] [learning rate: 4.7e+03]\n",
            "[Step 35843/50000] [Time: 301s] [Train Loss: 1.69e-01] [Train Acc: 0.97]\n",
            "[Step 35868/50000] [Progress: 71.74%] [learning rate: 5.6e+03]\n",
            "[Step 35891/50000] [Progress: 71.78%] [learning rate: 5.0e+03]\n",
            "[Step 35917/50000] [Progress: 71.83%] [learning rate: 5.5e+03]\n",
            "[Step 35941/50000] [Time: 302s] [Train Loss: 1.68e-01] [Train Acc: 0.97]\n",
            "[Step 35943/50000] [Progress: 71.89%] [learning rate: 5.4e+03]\n",
            "[Step 35969/50000] [Progress: 71.94%] [learning rate: 5.3e+03]\n",
            "[Step 35993/50000] [Progress: 71.99%] [learning rate: 5.2e+03]\n",
            "[Step 36018/50000] [Progress: 72.04%] [learning rate: 5.1e+03]\n",
            "[Step 36039/50000] [Time: 303s] [Train Loss: 1.68e-01] [Train Acc: 0.97]\n",
            "[Step 36044/50000] [Progress: 72.09%] [learning rate: 5.6e+03]\n",
            "[Step 36068/50000] [Progress: 72.14%] [learning rate: 5.0e+03]\n",
            "[Step 36095/50000] [Progress: 72.19%] [learning rate: 5.4e+03]\n",
            "[Step 36120/50000] [Progress: 72.24%] [learning rate: 5.3e+03]\n",
            "[Step 36137/50000] [Time: 304s] [Train Loss: 1.68e-01] [Train Acc: 0.97]\n",
            "[Step 36146/50000] [Progress: 72.29%] [learning rate: 5.2e+03]\n",
            "[Step 36170/50000] [Progress: 72.34%] [learning rate: 5.2e+03]\n",
            "[Step 36195/50000] [Progress: 72.39%] [learning rate: 5.1e+03]\n",
            "[Step 36220/50000] [Progress: 72.44%] [learning rate: 5.0e+03]\n",
            "[Step 36235/50000] [Time: 305s] [Train Loss: 1.67e-01] [Train Acc: 0.97]\n",
            "[Step 36245/50000] [Progress: 72.49%] [learning rate: 5.4e+03]\n",
            "[Step 36271/50000] [Progress: 72.54%] [learning rate: 5.9e+03]\n",
            "[Step 36295/50000] [Progress: 72.59%] [learning rate: 5.3e+03]\n",
            "[Step 36320/50000] [Progress: 72.64%] [learning rate: 5.2e+03]\n",
            "[Step 36333/50000] [Time: 305s] [Train Loss: 1.67e-01] [Train Acc: 0.97]\n",
            "[Step 36346/50000] [Progress: 72.69%] [learning rate: 5.1e+03]\n",
            "[Step 36371/50000] [Progress: 72.74%] [learning rate: 5.0e+03]\n",
            "[Step 36396/50000] [Progress: 72.79%] [learning rate: 5.5e+03]\n",
            "[Step 36422/50000] [Progress: 72.84%] [learning rate: 5.9e+03]\n",
            "[Step 36431/50000] [Time: 306s] [Train Loss: 1.67e-01] [Train Acc: 0.97]\n",
            "[Step 36446/50000] [Progress: 72.89%] [learning rate: 5.3e+03]\n",
            "[Step 36471/50000] [Progress: 72.94%] [learning rate: 5.2e+03]\n",
            "[Step 36497/50000] [Progress: 72.99%] [learning rate: 5.1e+03]\n",
            "[Step 36522/50000] [Progress: 73.04%] [learning rate: 5.1e+03]\n",
            "[Step 36529/50000] [Time: 307s] [Train Loss: 1.66e-01] [Train Acc: 0.97]\n",
            "[Step 36549/50000] [Progress: 73.10%] [learning rate: 5.5e+03]\n",
            "[Step 36575/50000] [Progress: 73.15%] [learning rate: 5.9e+03]\n",
            "[Step 36598/50000] [Progress: 73.20%] [learning rate: 4.8e+03]\n",
            "[Step 36624/50000] [Progress: 73.25%] [learning rate: 5.2e+03]\n",
            "[Step 36627/50000] [Time: 307s] [Train Loss: 1.66e-01] [Train Acc: 0.97]\n",
            "[Step 36649/50000] [Progress: 73.30%] [learning rate: 5.2e+03]\n",
            "[Step 36675/50000] [Progress: 73.35%] [learning rate: 5.6e+03]\n",
            "[Step 36699/50000] [Progress: 73.40%] [learning rate: 5.0e+03]\n",
            "[Step 36725/50000] [Time: 308s] [Train Loss: 1.66e-01] [Train Acc: 0.97]\n",
            "[Step 36726/50000] [Progress: 73.45%] [learning rate: 6.0e+03]\n",
            "[Step 36749/50000] [Progress: 73.50%] [learning rate: 4.9e+03]\n",
            "[Step 36775/50000] [Progress: 73.55%] [learning rate: 5.3e+03]\n",
            "[Step 36800/50000] [Progress: 73.60%] [learning rate: 5.2e+03]\n",
            "[Step 36823/50000] [Time: 309s] [Train Loss: 1.66e-01] [Train Acc: 0.97]\n",
            "[Step 36826/50000] [Progress: 73.65%] [learning rate: 5.1e+03]\n",
            "[Step 36851/50000] [Progress: 73.70%] [learning rate: 5.5e+03]\n",
            "[Step 36875/50000] [Progress: 73.75%] [learning rate: 5.4e+03]\n",
            "[Step 36900/50000] [Progress: 73.80%] [learning rate: 5.4e+03]\n",
            "[Step 36921/50000] [Time: 310s] [Train Loss: 1.65e-01] [Train Acc: 0.97]\n",
            "[Step 36924/50000] [Progress: 73.85%] [learning rate: 5.3e+03]\n",
            "[Step 36949/50000] [Progress: 73.90%] [learning rate: 5.2e+03]\n",
            "[Step 36975/50000] [Progress: 73.95%] [learning rate: 5.6e+03]\n",
            "[Step 36998/50000] [Progress: 74.00%] [learning rate: 5.1e+03]\n",
            "[Step 37019/50000] [Time: 310s] [Train Loss: 1.65e-01] [Train Acc: 0.97]\n",
            "[Step 37024/50000] [Progress: 74.05%] [learning rate: 6.0e+03]\n",
            "[Step 37047/50000] [Progress: 74.09%] [learning rate: 4.9e+03]\n",
            "[Step 37073/50000] [Progress: 74.15%] [learning rate: 5.3e+03]\n",
            "[Step 37097/50000] [Progress: 74.19%] [learning rate: 5.2e+03]\n",
            "[Step 37117/50000] [Time: 311s] [Train Loss: 1.65e-01] [Train Acc: 0.97]\n",
            "[Step 37122/50000] [Progress: 74.24%] [learning rate: 5.2e+03]\n",
            "[Step 37147/50000] [Progress: 74.29%] [learning rate: 5.1e+03]\n",
            "[Step 37173/50000] [Progress: 74.35%] [learning rate: 5.5e+03]\n",
            "[Step 37200/50000] [Progress: 74.40%] [learning rate: 6.0e+03]\n",
            "[Step 37215/50000] [Time: 312s] [Train Loss: 1.64e-01] [Train Acc: 0.97]\n",
            "[Step 37224/50000] [Progress: 74.45%] [learning rate: 5.3e+03]\n",
            "[Step 37249/50000] [Progress: 74.50%] [learning rate: 5.3e+03]\n",
            "[Step 37275/50000] [Progress: 74.55%] [learning rate: 5.2e+03]\n",
            "[Step 37300/50000] [Progress: 74.60%] [learning rate: 5.1e+03]\n",
            "[Step 37313/50000] [Time: 313s] [Train Loss: 1.64e-01] [Train Acc: 0.97]\n",
            "[Step 37325/50000] [Progress: 74.65%] [learning rate: 5.5e+03]\n",
            "[Step 37351/50000] [Progress: 74.70%] [learning rate: 6.0e+03]\n",
            "[Step 37375/50000] [Progress: 74.75%] [learning rate: 5.4e+03]\n",
            "[Step 37400/50000] [Progress: 74.80%] [learning rate: 5.3e+03]\n",
            "[Step 37411/50000] [Time: 313s] [Train Loss: 1.64e-01] [Train Acc: 0.97]\n",
            "[Step 37426/50000] [Progress: 74.85%] [learning rate: 5.7e+03]\n",
            "[Step 37449/50000] [Progress: 74.90%] [learning rate: 5.1e+03]\n",
            "[Step 37475/50000] [Progress: 74.95%] [learning rate: 5.5e+03]\n",
            "[Step 37501/50000] [Progress: 75.00%] [learning rate: 6.0e+03]\n",
            "[Step 37509/50000] [Time: 314s] [Train Loss: 1.63e-01] [Train Acc: 0.97]\n",
            "[Step 37524/50000] [Progress: 75.05%] [learning rate: 4.9e+03]\n",
            "[Step 37551/50000] [Progress: 75.10%] [learning rate: 5.8e+03]\n",
            "[Step 37574/50000] [Progress: 75.15%] [learning rate: 4.7e+03]\n",
            "[Step 37600/50000] [Progress: 75.20%] [learning rate: 5.7e+03]\n",
            "[Step 37607/50000] [Time: 315s] [Train Loss: 1.63e-01] [Train Acc: 0.97]\n",
            "[Step 37624/50000] [Progress: 75.25%] [learning rate: 5.1e+03]\n",
            "[Step 37650/50000] [Progress: 75.30%] [learning rate: 6.0e+03]\n",
            "[Step 37673/50000] [Progress: 75.35%] [learning rate: 4.9e+03]\n",
            "[Step 37700/50000] [Progress: 75.40%] [learning rate: 5.9e+03]\n",
            "[Step 37705/50000] [Time: 316s] [Train Loss: 1.63e-01] [Train Acc: 0.97]\n",
            "[Step 37723/50000] [Progress: 75.45%] [learning rate: 4.8e+03]\n",
            "[Step 37749/50000] [Progress: 75.50%] [learning rate: 5.7e+03]\n",
            "[Step 37773/50000] [Progress: 75.55%] [learning rate: 5.1e+03]\n",
            "[Step 37800/50000] [Progress: 75.60%] [learning rate: 6.1e+03]\n",
            "[Step 37803/50000] [Time: 317s] [Train Loss: 1.63e-01] [Train Acc: 0.97]\n",
            "[Step 37823/50000] [Progress: 75.65%] [learning rate: 5.4e+03]\n",
            "[Step 37847/50000] [Progress: 75.69%] [learning rate: 5.3e+03]\n",
            "[Step 37872/50000] [Progress: 75.74%] [learning rate: 5.3e+03]\n",
            "[Step 37898/50000] [Progress: 75.80%] [learning rate: 5.7e+03]\n",
            "[Step 37901/50000] [Time: 317s] [Train Loss: 1.62e-01] [Train Acc: 0.97]\n",
            "[Step 37922/50000] [Progress: 75.84%] [learning rate: 5.1e+03]\n",
            "[Step 37949/50000] [Progress: 75.90%] [learning rate: 6.1e+03]\n",
            "[Step 37972/50000] [Progress: 75.94%] [learning rate: 5.0e+03]\n",
            "[Step 37998/50000] [Progress: 76.00%] [learning rate: 5.4e+03]\n",
            "[Step 37999/50000] [Time: 318s] [Train Loss: 1.62e-01] [Train Acc: 0.97]\n",
            "[Step 38022/50000] [Progress: 76.04%] [learning rate: 5.3e+03]\n",
            "[Step 38047/50000] [Progress: 76.09%] [learning rate: 5.2e+03]\n",
            "[Step 38072/50000] [Progress: 76.14%] [learning rate: 5.1e+03]\n",
            "[Step 38097/50000] [Time: 319s] [Train Loss: 1.62e-01] [Train Acc: 0.97]\n",
            "[Step 38098/50000] [Progress: 76.20%] [learning rate: 5.6e+03]\n",
            "[Step 38125/50000] [Progress: 76.25%] [learning rate: 6.0e+03]\n",
            "[Step 38149/50000] [Progress: 76.30%] [learning rate: 5.4e+03]\n",
            "[Step 38174/50000] [Progress: 76.35%] [learning rate: 5.3e+03]\n",
            "[Step 38195/50000] [Time: 319s] [Train Loss: 1.61e-01] [Train Acc: 0.97]\n",
            "[Step 38200/50000] [Progress: 76.40%] [learning rate: 5.2e+03]\n",
            "[Step 38225/50000] [Progress: 76.45%] [learning rate: 5.2e+03]\n",
            "[Step 38252/50000] [Progress: 76.50%] [learning rate: 5.6e+03]\n",
            "[Step 38278/50000] [Progress: 76.56%] [learning rate: 6.1e+03]\n",
            "[Step 38293/50000] [Time: 320s] [Train Loss: 1.61e-01] [Train Acc: 0.97]\n",
            "[Step 38302/50000] [Progress: 76.60%] [learning rate: 5.4e+03]\n",
            "[Step 38327/50000] [Progress: 76.65%] [learning rate: 5.3e+03]\n",
            "[Step 38353/50000] [Progress: 76.71%] [learning rate: 5.3e+03]\n",
            "[Step 38378/50000] [Progress: 76.76%] [learning rate: 5.2e+03]\n",
            "[Step 38391/50000] [Time: 321s] [Train Loss: 1.61e-01] [Train Acc: 0.97]\n",
            "[Step 38405/50000] [Progress: 76.81%] [learning rate: 5.6e+03]\n",
            "[Step 38430/50000] [Progress: 76.86%] [learning rate: 5.5e+03]\n",
            "[Step 38456/50000] [Progress: 76.91%] [learning rate: 5.4e+03]\n",
            "[Step 38480/50000] [Progress: 76.96%] [learning rate: 5.4e+03]\n",
            "[Step 38489/50000] [Time: 322s] [Train Loss: 1.61e-01] [Train Acc: 0.97] [Eval Loss: 5.19e-01] [Eval Acc: 0.77]\n",
            "[Step 38505/50000] [Progress: 77.01%] [learning rate: 5.3e+03]\n",
            "[Step 38531/50000] [Progress: 77.06%] [learning rate: 5.7e+03]\n",
            "[Step 38555/50000] [Progress: 77.11%] [learning rate: 5.1e+03]\n",
            "[Step 38581/50000] [Progress: 77.16%] [learning rate: 6.1e+03]\n",
            "[Step 38587/50000] [Time: 324s] [Train Loss: 1.60e-01] [Train Acc: 0.97]\n",
            "[Step 38604/50000] [Progress: 77.21%] [learning rate: 5.0e+03]\n",
            "[Step 38631/50000] [Progress: 77.26%] [learning rate: 5.9e+03]\n",
            "[Step 38654/50000] [Progress: 77.31%] [learning rate: 4.8e+03]\n",
            "[Step 38680/50000] [Progress: 77.36%] [learning rate: 5.7e+03]\n",
            "[Step 38685/50000] [Time: 325s] [Train Loss: 1.60e-01] [Train Acc: 0.97]\n",
            "[Step 38704/50000] [Progress: 77.41%] [learning rate: 5.1e+03]\n",
            "[Step 38731/50000] [Progress: 77.46%] [learning rate: 6.1e+03]\n",
            "[Step 38754/50000] [Progress: 77.51%] [learning rate: 5.5e+03]\n",
            "[Step 38778/50000] [Progress: 77.56%] [learning rate: 5.4e+03]\n",
            "[Step 38783/50000] [Time: 325s] [Train Loss: 1.60e-01] [Train Acc: 0.97]\n",
            "[Step 38803/50000] [Progress: 77.61%] [learning rate: 5.3e+03]\n",
            "[Step 38829/50000] [Progress: 77.66%] [learning rate: 5.8e+03]\n",
            "[Step 38853/50000] [Progress: 77.71%] [learning rate: 5.2e+03]\n",
            "[Step 38880/50000] [Progress: 77.76%] [learning rate: 6.2e+03]\n",
            "[Step 38881/50000] [Time: 326s] [Train Loss: 1.59e-01] [Train Acc: 0.97]\n",
            "[Step 38903/50000] [Progress: 77.81%] [learning rate: 5.0e+03]\n",
            "[Step 38929/50000] [Progress: 77.86%] [learning rate: 5.4e+03]\n",
            "[Step 38953/50000] [Progress: 77.91%] [learning rate: 5.4e+03]\n",
            "[Step 38978/50000] [Progress: 77.96%] [learning rate: 5.3e+03]\n",
            "[Step 38979/50000] [Time: 327s] [Train Loss: 1.59e-01] [Train Acc: 0.97]\n",
            "[Step 39003/50000] [Progress: 78.01%] [learning rate: 5.2e+03]\n",
            "[Step 39029/50000] [Progress: 78.06%] [learning rate: 5.6e+03]\n",
            "[Step 39056/50000] [Progress: 78.11%] [learning rate: 6.1e+03]\n",
            "[Step 39077/50000] [Time: 328s] [Train Loss: 1.59e-01] [Train Acc: 0.97]\n",
            "[Step 39080/50000] [Progress: 78.16%] [learning rate: 5.5e+03]\n",
            "[Step 39105/50000] [Progress: 78.21%] [learning rate: 5.4e+03]\n",
            "[Step 39131/50000] [Progress: 78.26%] [learning rate: 5.3e+03]\n",
            "[Step 39158/50000] [Progress: 78.32%] [learning rate: 5.7e+03]\n",
            "[Step 39175/50000] [Time: 329s] [Train Loss: 1.59e-01] [Train Acc: 0.97]\n",
            "[Step 39183/50000] [Progress: 78.37%] [learning rate: 5.7e+03]\n",
            "[Step 39209/50000] [Progress: 78.42%] [learning rate: 6.1e+03]\n",
            "[Step 39231/50000] [Progress: 78.46%] [learning rate: 5.0e+03]\n",
            "[Step 39257/50000] [Progress: 78.51%] [learning rate: 5.9e+03]\n",
            "[Step 39274/50000] [Time: 329s] [Train Loss: 1.58e-01] [Train Acc: 0.97]\n",
            "[Step 39280/50000] [Progress: 78.56%] [learning rate: 5.3e+03]\n",
            "[Step 39305/50000] [Progress: 78.61%] [learning rate: 5.2e+03]\n",
            "[Step 39330/50000] [Progress: 78.66%] [learning rate: 5.7e+03]\n",
            "[Step 39355/50000] [Progress: 78.71%] [learning rate: 6.2e+03]\n",
            "[Step 39373/50000] [Time: 330s] [Train Loss: 1.58e-01] [Train Acc: 0.97]\n",
            "[Step 39378/50000] [Progress: 78.76%] [learning rate: 5.0e+03]\n",
            "[Step 39405/50000] [Progress: 78.81%] [learning rate: 6.0e+03]\n",
            "[Step 39428/50000] [Progress: 78.86%] [learning rate: 4.9e+03]\n",
            "[Step 39455/50000] [Progress: 78.91%] [learning rate: 5.8e+03]\n",
            "[Step 39472/50000] [Time: 331s] [Train Loss: 1.58e-01] [Train Acc: 0.97]\n",
            "[Step 39480/50000] [Progress: 78.96%] [learning rate: 5.2e+03]\n",
            "[Step 39506/50000] [Progress: 79.01%] [learning rate: 6.2e+03]\n",
            "[Step 39529/50000] [Progress: 79.06%] [learning rate: 5.0e+03]\n",
            "[Step 39556/50000] [Progress: 79.11%] [learning rate: 6.0e+03]\n",
            "[Step 39571/50000] [Time: 332s] [Train Loss: 1.57e-01] [Train Acc: 0.97]\n",
            "[Step 39579/50000] [Progress: 79.16%] [learning rate: 4.9e+03]\n",
            "[Step 39605/50000] [Progress: 79.21%] [learning rate: 5.8e+03]\n",
            "[Step 39629/50000] [Progress: 79.26%] [learning rate: 5.2e+03]\n",
            "[Step 39656/50000] [Progress: 79.31%] [learning rate: 6.2e+03]\n",
            "[Step 39670/50000] [Time: 332s] [Train Loss: 1.57e-01] [Train Acc: 0.97]\n",
            "[Step 39679/50000] [Progress: 79.36%] [learning rate: 5.6e+03]\n",
            "[Step 39703/50000] [Progress: 79.41%] [learning rate: 5.5e+03]\n",
            "[Step 39728/50000] [Progress: 79.46%] [learning rate: 5.4e+03]\n",
            "[Step 39754/50000] [Progress: 79.51%] [learning rate: 5.8e+03]\n",
            "[Step 39769/50000] [Time: 333s] [Train Loss: 1.57e-01] [Train Acc: 0.97]\n",
            "[Step 39778/50000] [Progress: 79.56%] [learning rate: 5.2e+03]\n",
            "[Step 39805/50000] [Progress: 79.61%] [learning rate: 6.2e+03]\n",
            "[Step 39828/50000] [Progress: 79.66%] [learning rate: 5.1e+03]\n",
            "[Step 39854/50000] [Progress: 79.71%] [learning rate: 5.5e+03]\n",
            "[Step 39868/50000] [Time: 334s] [Train Loss: 1.57e-01] [Train Acc: 0.97]\n",
            "[Step 39878/50000] [Progress: 79.76%] [learning rate: 5.4e+03]\n",
            "[Step 39903/50000] [Progress: 79.81%] [learning rate: 5.3e+03]\n",
            "[Step 39928/50000] [Progress: 79.86%] [learning rate: 5.3e+03]\n",
            "[Step 39954/50000] [Progress: 79.91%] [learning rate: 5.7e+03]\n",
            "[Step 39967/50000] [Time: 335s] [Train Loss: 1.56e-01] [Train Acc: 0.97]\n",
            "[Step 39981/50000] [Progress: 79.96%] [learning rate: 6.2e+03]\n",
            "[Step 40005/50000] [Progress: 80.01%] [learning rate: 5.5e+03]\n",
            "[Step 40030/50000] [Progress: 80.06%] [learning rate: 5.4e+03]\n",
            "[Step 40056/50000] [Progress: 80.11%] [learning rate: 5.4e+03]\n",
            "[Step 40066/50000] [Time: 336s] [Train Loss: 1.56e-01] [Train Acc: 0.97]\n",
            "[Step 40081/50000] [Progress: 80.16%] [learning rate: 5.3e+03]\n",
            "[Step 40108/50000] [Progress: 80.22%] [learning rate: 5.7e+03]\n",
            "[Step 40134/50000] [Progress: 80.27%] [learning rate: 6.2e+03]\n",
            "[Step 40158/50000] [Progress: 80.32%] [learning rate: 5.5e+03]\n",
            "[Step 40165/50000] [Time: 336s] [Train Loss: 1.56e-01] [Train Acc: 0.97]\n",
            "[Step 40183/50000] [Progress: 80.37%] [learning rate: 5.5e+03]\n",
            "[Step 40209/50000] [Progress: 80.42%] [learning rate: 5.4e+03]\n",
            "[Step 40234/50000] [Progress: 80.47%] [learning rate: 5.3e+03]\n",
            "[Step 40261/50000] [Progress: 80.52%] [learning rate: 5.7e+03]\n",
            "[Step 40264/50000] [Time: 337s] [Train Loss: 1.55e-01] [Train Acc: 0.97]\n",
            "[Step 40286/50000] [Progress: 80.57%] [learning rate: 5.7e+03]\n",
            "[Step 40312/50000] [Progress: 80.62%] [learning rate: 5.6e+03]\n",
            "[Step 40336/50000] [Progress: 80.67%] [learning rate: 5.5e+03]\n",
            "[Step 40361/50000] [Progress: 80.72%] [learning rate: 5.4e+03]\n",
            "[Step 40363/50000] [Time: 338s] [Train Loss: 1.55e-01] [Train Acc: 0.97]\n",
            "[Step 40387/50000] [Progress: 80.77%] [learning rate: 5.9e+03]\n",
            "[Step 40411/50000] [Progress: 80.82%] [learning rate: 5.2e+03]\n",
            "[Step 40439/50000] [Progress: 80.88%] [learning rate: 6.3e+03]\n",
            "[Step 40462/50000] [Time: 338s] [Train Loss: 1.55e-01] [Train Acc: 0.97]\n",
            "[Step 40463/50000] [Progress: 80.93%] [learning rate: 5.6e+03]\n",
            "[Step 40488/50000] [Progress: 80.98%] [learning rate: 5.5e+03]\n",
            "[Step 40514/50000] [Progress: 81.03%] [learning rate: 5.4e+03]\n",
            "[Step 40539/50000] [Progress: 81.08%] [learning rate: 5.3e+03]\n",
            "[Step 40561/50000] [Time: 339s] [Train Loss: 1.55e-01] [Train Acc: 0.97]\n",
            "[Step 40566/50000] [Progress: 81.13%] [learning rate: 5.8e+03]\n",
            "[Step 40592/50000] [Progress: 81.18%] [learning rate: 5.7e+03]\n",
            "[Step 40618/50000] [Progress: 81.24%] [learning rate: 6.2e+03]\n",
            "[Step 40641/50000] [Progress: 81.28%] [learning rate: 5.0e+03]\n",
            "[Step 40660/50000] [Time: 340s] [Train Loss: 1.54e-01] [Train Acc: 0.97]\n",
            "[Step 40668/50000] [Progress: 81.34%] [learning rate: 6.0e+03]\n",
            "[Step 40691/50000] [Progress: 81.38%] [learning rate: 5.4e+03]\n",
            "[Step 40716/50000] [Progress: 81.43%] [learning rate: 5.8e+03]\n",
            "[Step 40740/50000] [Progress: 81.48%] [learning rate: 5.7e+03]\n",
            "[Step 40759/50000] [Time: 341s] [Train Loss: 1.54e-01] [Train Acc: 0.97]\n",
            "[Step 40765/50000] [Progress: 81.53%] [learning rate: 6.2e+03]\n",
            "[Step 40788/50000] [Progress: 81.58%] [learning rate: 5.1e+03]\n",
            "[Step 40815/50000] [Progress: 81.63%] [learning rate: 6.0e+03]\n",
            "[Step 40838/50000] [Progress: 81.68%] [learning rate: 4.9e+03]\n",
            "[Step 40858/50000] [Time: 342s] [Train Loss: 1.54e-01] [Train Acc: 0.97]\n",
            "[Step 40865/50000] [Progress: 81.73%] [learning rate: 5.8e+03]\n",
            "[Step 40890/50000] [Progress: 81.78%] [learning rate: 5.8e+03]\n",
            "[Step 40916/50000] [Progress: 81.83%] [learning rate: 6.2e+03]\n",
            "[Step 40940/50000] [Progress: 81.88%] [learning rate: 5.6e+03]\n",
            "[Step 40957/50000] [Time: 342s] [Train Loss: 1.54e-01] [Train Acc: 0.97]\n",
            "[Step 40965/50000] [Progress: 81.93%] [learning rate: 5.5e+03]\n",
            "[Step 40991/50000] [Progress: 81.98%] [learning rate: 5.4e+03]\n",
            "[Step 41016/50000] [Progress: 82.03%] [learning rate: 5.3e+03]\n",
            "[Step 41043/50000] [Progress: 82.09%] [learning rate: 5.8e+03]\n",
            "[Step 41056/50000] [Time: 343s] [Train Loss: 1.53e-01] [Train Acc: 0.97]\n",
            "[Step 41069/50000] [Progress: 82.14%] [learning rate: 6.3e+03]\n",
            "[Step 41093/50000] [Progress: 82.19%] [learning rate: 5.6e+03]\n",
            "[Step 41118/50000] [Progress: 82.24%] [learning rate: 5.5e+03]\n",
            "[Step 41144/50000] [Progress: 82.29%] [learning rate: 5.4e+03]\n",
            "[Step 41155/50000] [Time: 344s] [Train Loss: 1.53e-01] [Train Acc: 0.97]\n",
            "[Step 41170/50000] [Progress: 82.34%] [learning rate: 5.9e+03]\n",
            "[Step 41194/50000] [Progress: 82.39%] [learning rate: 5.3e+03]\n",
            "[Step 41221/50000] [Progress: 82.44%] [learning rate: 6.3e+03]\n",
            "[Step 41245/50000] [Progress: 82.49%] [learning rate: 5.6e+03]\n",
            "[Step 41254/50000] [Time: 345s] [Train Loss: 1.53e-01] [Train Acc: 0.97]\n",
            "[Step 41270/50000] [Progress: 82.54%] [learning rate: 5.6e+03]\n",
            "[Step 41296/50000] [Progress: 82.59%] [learning rate: 5.5e+03]\n",
            "[Step 41322/50000] [Progress: 82.64%] [learning rate: 5.9e+03]\n",
            "[Step 41346/50000] [Progress: 82.69%] [learning rate: 5.3e+03]\n",
            "[Step 41353/50000] [Time: 345s] [Train Loss: 1.52e-01] [Train Acc: 0.97]\n",
            "[Step 41372/50000] [Progress: 82.74%] [learning rate: 5.7e+03]\n",
            "[Step 41397/50000] [Progress: 82.79%] [learning rate: 5.7e+03]\n",
            "[Step 41423/50000] [Progress: 82.85%] [learning rate: 5.6e+03]\n",
            "[Step 41449/50000] [Progress: 82.90%] [learning rate: 5.5e+03]\n",
            "[Step 41452/50000] [Time: 346s] [Train Loss: 1.52e-01] [Train Acc: 0.97]\n",
            "[Step 41474/50000] [Progress: 82.95%] [learning rate: 5.4e+03]\n",
            "[Step 41501/50000] [Progress: 83.00%] [learning rate: 5.9e+03]\n",
            "[Step 41527/50000] [Progress: 83.05%] [learning rate: 5.8e+03]\n",
            "[Step 41551/50000] [Time: 347s] [Train Loss: 1.52e-01] [Train Acc: 0.97]\n",
            "[Step 41553/50000] [Progress: 83.11%] [learning rate: 6.3e+03]\n",
            "[Step 41576/50000] [Progress: 83.15%] [learning rate: 5.1e+03]\n",
            "[Step 41603/50000] [Progress: 83.21%] [learning rate: 6.1e+03]\n",
            "[Step 41626/50000] [Progress: 83.25%] [learning rate: 5.4e+03]\n",
            "[Step 41650/50000] [Time: 348s] [Train Loss: 1.52e-01] [Train Acc: 0.97]\n",
            "[Step 41651/50000] [Progress: 83.30%] [learning rate: 5.9e+03]\n",
            "[Step 41675/50000] [Progress: 83.35%] [learning rate: 5.8e+03]\n",
            "[Step 41700/50000] [Progress: 83.40%] [learning rate: 5.7e+03]\n",
            "[Step 41724/50000] [Progress: 83.45%] [learning rate: 5.6e+03]\n",
            "[Step 41749/50000] [Progress: 83.50%] [learning rate: 5.5e+03]\n",
            "[Step 41749/50000] [Time: 348s] [Train Loss: 1.51e-01] [Train Acc: 0.97]\n",
            "[Step 41775/50000] [Progress: 83.55%] [learning rate: 6.0e+03]\n",
            "[Step 41798/50000] [Progress: 83.60%] [learning rate: 5.4e+03]\n",
            "[Step 41824/50000] [Progress: 83.65%] [learning rate: 5.8e+03]\n",
            "[Step 41848/50000] [Time: 349s] [Train Loss: 1.51e-01] [Train Acc: 0.97]\n",
            "[Step 41851/50000] [Progress: 83.70%] [learning rate: 6.3e+03]\n",
            "[Step 41875/50000] [Progress: 83.75%] [learning rate: 5.7e+03]\n",
            "[Step 41900/50000] [Progress: 83.80%] [learning rate: 5.6e+03]\n",
            "[Step 41926/50000] [Progress: 83.85%] [learning rate: 6.0e+03]\n",
            "[Step 41947/50000] [Time: 350s] [Train Loss: 1.51e-01] [Train Acc: 0.97]\n",
            "[Step 41949/50000] [Progress: 83.90%] [learning rate: 5.4e+03]\n",
            "[Step 41975/50000] [Progress: 83.95%] [learning rate: 5.9e+03]\n",
            "[Step 42002/50000] [Progress: 84.00%] [learning rate: 6.3e+03]\n",
            "[Step 42027/50000] [Progress: 84.05%] [learning rate: 5.7e+03]\n",
            "[Step 42046/50000] [Time: 350s] [Train Loss: 1.51e-01] [Train Acc: 0.97]\n",
            "[Step 42053/50000] [Progress: 84.11%] [learning rate: 5.6e+03]\n",
            "[Step 42079/50000] [Progress: 84.16%] [learning rate: 5.5e+03]\n",
            "[Step 42104/50000] [Progress: 84.21%] [learning rate: 5.4e+03]\n",
            "[Step 42129/50000] [Progress: 84.26%] [learning rate: 5.9e+03]\n",
            "[Step 42145/50000] [Time: 351s] [Train Loss: 1.50e-01] [Train Acc: 0.97]\n",
            "[Step 42154/50000] [Progress: 84.31%] [learning rate: 5.8e+03]\n",
            "[Step 42178/50000] [Progress: 84.36%] [learning rate: 5.7e+03]\n",
            "[Step 42203/50000] [Progress: 84.41%] [learning rate: 5.6e+03]\n",
            "[Step 42229/50000] [Progress: 84.46%] [learning rate: 5.5e+03]\n",
            "[Step 42244/50000] [Time: 352s] [Train Loss: 1.50e-01] [Train Acc: 0.97]\n",
            "[Step 42254/50000] [Progress: 84.51%] [learning rate: 5.5e+03]\n",
            "[Step 42281/50000] [Progress: 84.56%] [learning rate: 5.9e+03]\n",
            "[Step 42307/50000] [Progress: 84.61%] [learning rate: 5.8e+03]\n",
            "[Step 42332/50000] [Progress: 84.66%] [learning rate: 5.7e+03]\n",
            "[Step 42343/50000] [Time: 353s] [Train Loss: 1.50e-01] [Train Acc: 0.97]\n",
            "[Step 42358/50000] [Progress: 84.72%] [learning rate: 5.6e+03]\n",
            "[Step 42384/50000] [Progress: 84.77%] [learning rate: 5.6e+03]\n",
            "[Step 42409/50000] [Progress: 84.82%] [learning rate: 5.5e+03]\n",
            "[Step 42436/50000] [Progress: 84.87%] [learning rate: 5.9e+03]\n",
            "[Step 42442/50000] [Time: 353s] [Train Loss: 1.50e-01] [Train Acc: 0.97]\n",
            "[Step 42462/50000] [Progress: 84.92%] [learning rate: 5.8e+03]\n",
            "[Step 42488/50000] [Progress: 84.98%] [learning rate: 6.3e+03]\n",
            "[Step 42511/50000] [Progress: 85.02%] [learning rate: 5.2e+03]\n",
            "[Step 42538/50000] [Progress: 85.08%] [learning rate: 6.1e+03]\n",
            "[Step 42541/50000] [Time: 354s] [Train Loss: 1.49e-01] [Train Acc: 0.97]\n",
            "[Step 42561/50000] [Progress: 85.12%] [learning rate: 5.5e+03]\n",
            "[Step 42586/50000] [Progress: 85.17%] [learning rate: 6.0e+03]\n",
            "[Step 42610/50000] [Progress: 85.22%] [learning rate: 5.9e+03]\n",
            "[Step 42635/50000] [Progress: 85.27%] [learning rate: 5.8e+03]\n",
            "[Step 42640/50000] [Time: 355s] [Train Loss: 1.49e-01] [Train Acc: 0.97]\n",
            "[Step 42659/50000] [Progress: 85.32%] [learning rate: 5.7e+03]\n",
            "[Step 42684/50000] [Progress: 85.37%] [learning rate: 5.6e+03]\n",
            "[Step 42710/50000] [Progress: 85.42%] [learning rate: 6.1e+03]\n",
            "[Step 42733/50000] [Progress: 85.47%] [learning rate: 5.4e+03]\n",
            "[Step 42739/50000] [Time: 356s] [Train Loss: 1.49e-01] [Train Acc: 0.97]\n",
            "[Step 42759/50000] [Progress: 85.52%] [learning rate: 5.9e+03]\n",
            "[Step 42786/50000] [Progress: 85.57%] [learning rate: 6.4e+03]\n",
            "[Step 42808/50000] [Progress: 85.62%] [learning rate: 5.2e+03]\n",
            "[Step 42834/50000] [Progress: 85.67%] [learning rate: 6.2e+03]\n",
            "[Step 42838/50000] [Time: 357s] [Train Loss: 1.49e-01] [Train Acc: 0.97]\n",
            "[Step 42857/50000] [Progress: 85.71%] [learning rate: 5.5e+03]\n",
            "[Step 42882/50000] [Progress: 85.76%] [learning rate: 6.0e+03]\n",
            "[Step 42906/50000] [Progress: 85.81%] [learning rate: 5.4e+03]\n",
            "[Step 42934/50000] [Progress: 85.87%] [learning rate: 7.1e+03]\n",
            "[Step 42937/50000] [Time: 357s] [Train Loss: 1.48e-01] [Train Acc: 0.97]\n",
            "[Step 42955/50000] [Progress: 85.91%] [learning rate: 4.7e+03]\n",
            "[Step 42984/50000] [Progress: 85.97%] [learning rate: 6.2e+03]\n",
            "[Step 43008/50000] [Progress: 86.02%] [learning rate: 5.6e+03]\n",
            "[Step 43033/50000] [Progress: 86.07%] [learning rate: 6.0e+03]\n",
            "[Step 43036/50000] [Time: 358s] [Train Loss: 1.48e-01] [Train Acc: 0.97]\n",
            "[Step 43057/50000] [Progress: 86.11%] [learning rate: 5.4e+03]\n",
            "[Step 43085/50000] [Progress: 86.17%] [learning rate: 6.4e+03]\n",
            "[Step 43110/50000] [Progress: 86.22%] [learning rate: 5.8e+03]\n",
            "[Step 43135/50000] [Time: 359s] [Train Loss: 1.48e-01] [Train Acc: 0.97]\n",
            "[Step 43136/50000] [Progress: 86.27%] [learning rate: 5.7e+03]\n",
            "[Step 43162/50000] [Progress: 86.32%] [learning rate: 5.6e+03]\n",
            "[Step 43187/50000] [Progress: 86.37%] [learning rate: 5.5e+03]\n",
            "[Step 43214/50000] [Progress: 86.43%] [learning rate: 6.0e+03]\n",
            "[Step 43234/50000] [Time: 359s] [Train Loss: 1.48e-01] [Train Acc: 0.97]\n",
            "[Step 43240/50000] [Progress: 86.48%] [learning rate: 5.9e+03]\n",
            "[Step 43264/50000] [Progress: 86.53%] [learning rate: 5.8e+03]\n",
            "[Step 43289/50000] [Progress: 86.58%] [learning rate: 5.7e+03]\n",
            "[Step 43315/50000] [Progress: 86.63%] [learning rate: 5.6e+03]\n",
            "[Step 43333/50000] [Time: 360s] [Train Loss: 1.47e-01] [Train Acc: 0.97]\n",
            "[Step 43340/50000] [Progress: 86.68%] [learning rate: 5.5e+03]\n",
            "[Step 43367/50000] [Progress: 86.73%] [learning rate: 6.0e+03]\n",
            "[Step 43393/50000] [Progress: 86.79%] [learning rate: 5.9e+03]\n",
            "[Step 43419/50000] [Progress: 86.84%] [learning rate: 6.4e+03]\n",
            "[Step 43432/50000] [Time: 361s] [Train Loss: 1.47e-01] [Train Acc: 0.97] [Eval Loss: 5.26e-01] [Eval Acc: 0.77]\n",
            "[Step 43442/50000] [Progress: 86.88%] [learning rate: 5.2e+03]\n",
            "[Step 43469/50000] [Progress: 86.94%] [learning rate: 6.2e+03]\n",
            "[Step 43492/50000] [Progress: 86.98%] [learning rate: 5.6e+03]\n",
            "[Step 43517/50000] [Progress: 87.03%] [learning rate: 6.0e+03]\n",
            "[Step 43531/50000] [Time: 364s] [Train Loss: 1.47e-01] [Train Acc: 0.97]\n",
            "[Step 43541/50000] [Progress: 87.08%] [learning rate: 5.9e+03]\n",
            "[Step 43566/50000] [Progress: 87.13%] [learning rate: 5.8e+03]\n",
            "[Step 43590/50000] [Progress: 87.18%] [learning rate: 5.8e+03]\n",
            "[Step 43615/50000] [Progress: 87.23%] [learning rate: 5.7e+03]\n",
            "[Step 43630/50000] [Time: 364s] [Train Loss: 1.46e-01] [Train Acc: 0.97]\n",
            "[Step 43641/50000] [Progress: 87.28%] [learning rate: 6.1e+03]\n",
            "[Step 43664/50000] [Progress: 87.33%] [learning rate: 5.5e+03]\n",
            "[Step 43690/50000] [Progress: 87.38%] [learning rate: 6.0e+03]\n",
            "[Step 43717/50000] [Progress: 87.43%] [learning rate: 7.1e+03]\n",
            "[Step 43729/50000] [Time: 365s] [Train Loss: 1.46e-01] [Train Acc: 0.98]\n",
            "[Step 43737/50000] [Progress: 87.47%] [learning rate: 4.8e+03]\n",
            "[Step 43765/50000] [Progress: 87.53%] [learning rate: 6.3e+03]\n",
            "[Step 43790/50000] [Progress: 87.58%] [learning rate: 5.6e+03]\n",
            "[Step 43816/50000] [Progress: 87.63%] [learning rate: 6.1e+03]\n",
            "[Step 43828/50000] [Time: 366s] [Train Loss: 1.46e-01] [Train Acc: 0.98]\n",
            "[Step 43840/50000] [Progress: 87.68%] [learning rate: 5.4e+03]\n",
            "[Step 43867/50000] [Progress: 87.73%] [learning rate: 6.5e+03]\n",
            "[Step 43891/50000] [Progress: 87.78%] [learning rate: 5.8e+03]\n",
            "[Step 43916/50000] [Progress: 87.83%] [learning rate: 5.7e+03]\n",
            "[Step 43927/50000] [Time: 367s] [Train Loss: 1.46e-01] [Train Acc: 0.98]\n",
            "[Step 43942/50000] [Progress: 87.88%] [learning rate: 5.6e+03]\n",
            "[Step 43967/50000] [Progress: 87.93%] [learning rate: 5.6e+03]\n",
            "[Step 43994/50000] [Progress: 87.99%] [learning rate: 6.0e+03]\n",
            "[Step 44020/50000] [Progress: 88.04%] [learning rate: 6.5e+03]\n",
            "[Step 44026/50000] [Time: 367s] [Train Loss: 1.45e-01] [Train Acc: 0.98]\n",
            "[Step 44043/50000] [Progress: 88.09%] [learning rate: 5.3e+03]\n",
            "[Step 44069/50000] [Progress: 88.14%] [learning rate: 5.8e+03]\n",
            "[Step 44095/50000] [Progress: 88.19%] [learning rate: 6.2e+03]\n",
            "[Step 44118/50000] [Progress: 88.24%] [learning rate: 5.6e+03]\n",
            "[Step 44125/50000] [Time: 368s] [Train Loss: 1.45e-01] [Train Acc: 0.98]\n",
            "[Step 44143/50000] [Progress: 88.29%] [learning rate: 6.0e+03]\n",
            "[Step 44168/50000] [Progress: 88.34%] [learning rate: 6.0e+03]\n",
            "[Step 44194/50000] [Progress: 88.39%] [learning rate: 5.9e+03]\n",
            "[Step 44218/50000] [Progress: 88.44%] [learning rate: 5.8e+03]\n",
            "[Step 44224/50000] [Time: 369s] [Train Loss: 1.45e-01] [Train Acc: 0.98]\n",
            "[Step 44243/50000] [Progress: 88.49%] [learning rate: 5.7e+03]\n",
            "[Step 44269/50000] [Progress: 88.54%] [learning rate: 6.2e+03]\n",
            "[Step 44293/50000] [Progress: 88.59%] [learning rate: 5.5e+03]\n",
            "[Step 44320/50000] [Progress: 88.64%] [learning rate: 6.6e+03]\n",
            "[Step 44323/50000] [Time: 370s] [Train Loss: 1.45e-01] [Train Acc: 0.98]\n",
            "[Step 44343/50000] [Progress: 88.69%] [learning rate: 5.4e+03]\n",
            "[Step 44369/50000] [Progress: 88.74%] [learning rate: 5.8e+03]\n",
            "[Step 44395/50000] [Progress: 88.79%] [learning rate: 6.3e+03]\n",
            "[Step 44418/50000] [Progress: 88.84%] [learning rate: 5.1e+03]\n",
            "[Step 44422/50000] [Time: 371s] [Train Loss: 1.45e-01] [Train Acc: 0.98]\n",
            "[Step 44445/50000] [Progress: 88.89%] [learning rate: 6.1e+03]\n",
            "[Step 44470/50000] [Progress: 88.94%] [learning rate: 6.0e+03]\n",
            "[Step 44495/50000] [Progress: 88.99%] [learning rate: 6.5e+03]\n",
            "[Step 44518/50000] [Progress: 89.04%] [learning rate: 5.3e+03]\n",
            "[Step 44521/50000] [Time: 371s] [Train Loss: 1.44e-01] [Train Acc: 0.98]\n",
            "[Step 44544/50000] [Progress: 89.09%] [learning rate: 5.7e+03]\n",
            "[Step 44570/50000] [Progress: 89.14%] [learning rate: 6.2e+03]\n",
            "[Step 44593/50000] [Progress: 89.19%] [learning rate: 5.6e+03]\n",
            "[Step 44619/50000] [Progress: 89.24%] [learning rate: 6.0e+03]\n",
            "[Step 44620/50000] [Time: 372s] [Train Loss: 1.44e-01] [Train Acc: 0.98]\n",
            "[Step 44645/50000] [Progress: 89.29%] [learning rate: 7.2e+03]\n",
            "[Step 44666/50000] [Progress: 89.33%] [learning rate: 4.8e+03]\n",
            "[Step 44695/50000] [Progress: 89.39%] [learning rate: 6.3e+03]\n",
            "[Step 44719/50000] [Progress: 89.44%] [learning rate: 5.7e+03]\n",
            "[Step 44719/50000] [Time: 373s] [Train Loss: 1.44e-01] [Train Acc: 0.98]\n",
            "[Step 44744/50000] [Progress: 89.49%] [learning rate: 6.2e+03]\n",
            "[Step 44768/50000] [Progress: 89.54%] [learning rate: 5.5e+03]\n",
            "[Step 44794/50000] [Progress: 89.59%] [learning rate: 6.6e+03]\n",
            "[Step 44817/50000] [Progress: 89.63%] [learning rate: 5.3e+03]\n",
            "[Step 44818/50000] [Time: 373s] [Train Loss: 1.44e-01] [Train Acc: 0.98]\n",
            "[Step 44843/50000] [Progress: 89.69%] [learning rate: 5.8e+03]\n",
            "[Step 44868/50000] [Progress: 89.74%] [learning rate: 5.7e+03]\n",
            "[Step 44894/50000] [Progress: 89.79%] [learning rate: 6.2e+03]\n",
            "[Step 44917/50000] [Time: 374s] [Train Loss: 1.43e-01] [Train Acc: 0.98]\n",
            "[Step 44918/50000] [Progress: 89.84%] [learning rate: 5.5e+03]\n",
            "[Step 44946/50000] [Progress: 89.89%] [learning rate: 6.6e+03]\n",
            "[Step 44970/50000] [Progress: 89.94%] [learning rate: 5.9e+03]\n",
            "[Step 44995/50000] [Progress: 89.99%] [learning rate: 5.8e+03]\n",
            "[Step 45016/50000] [Time: 375s] [Train Loss: 1.43e-01] [Train Acc: 0.98]\n",
            "[Step 45021/50000] [Progress: 90.04%] [learning rate: 5.7e+03]\n",
            "[Step 45047/50000] [Progress: 90.09%] [learning rate: 6.2e+03]\n",
            "[Step 45071/50000] [Progress: 90.14%] [learning rate: 5.6e+03]\n",
            "[Step 45098/50000] [Progress: 90.20%] [learning rate: 6.6e+03]\n",
            "[Step 45115/50000] [Time: 375s] [Train Loss: 1.43e-01] [Train Acc: 0.98]\n",
            "[Step 45121/50000] [Progress: 90.24%] [learning rate: 5.4e+03]\n",
            "[Step 45147/50000] [Progress: 90.29%] [learning rate: 5.8e+03]\n",
            "[Step 45172/50000] [Progress: 90.34%] [learning rate: 5.8e+03]\n",
            "[Step 45198/50000] [Progress: 90.40%] [learning rate: 5.7e+03]\n",
            "[Step 45214/50000] [Time: 376s] [Train Loss: 1.43e-01] [Train Acc: 0.98]\n",
            "[Step 45223/50000] [Progress: 90.45%] [learning rate: 5.6e+03]\n",
            "[Step 45249/50000] [Progress: 90.50%] [learning rate: 6.1e+03]\n",
            "[Step 45275/50000] [Progress: 90.55%] [learning rate: 6.6e+03]\n",
            "[Step 45298/50000] [Progress: 90.60%] [learning rate: 5.3e+03]\n",
            "[Step 45313/50000] [Time: 377s] [Train Loss: 1.42e-01] [Train Acc: 0.98]\n",
            "[Step 45324/50000] [Progress: 90.65%] [learning rate: 5.8e+03]\n",
            "[Step 45349/50000] [Progress: 90.70%] [learning rate: 5.7e+03]\n",
            "[Step 45375/50000] [Progress: 90.75%] [learning rate: 6.2e+03]\n",
            "[Step 45399/50000] [Progress: 90.80%] [learning rate: 6.1e+03]\n",
            "[Step 45412/50000] [Time: 378s] [Train Loss: 1.42e-01] [Train Acc: 0.98]\n",
            "[Step 45424/50000] [Progress: 90.85%] [learning rate: 6.6e+03]\n",
            "[Step 45447/50000] [Progress: 90.89%] [learning rate: 5.4e+03]\n",
            "[Step 45475/50000] [Progress: 90.95%] [learning rate: 6.4e+03]\n",
            "[Step 45499/50000] [Progress: 91.00%] [learning rate: 5.7e+03]\n",
            "[Step 45511/50000] [Time: 378s] [Train Loss: 1.42e-01] [Train Acc: 0.98]\n",
            "[Step 45524/50000] [Progress: 91.05%] [learning rate: 6.2e+03]\n",
            "[Step 45548/50000] [Progress: 91.10%] [learning rate: 5.5e+03]\n",
            "[Step 45575/50000] [Progress: 91.15%] [learning rate: 7.3e+03]\n",
            "[Step 45595/50000] [Progress: 91.19%] [learning rate: 4.9e+03]\n",
            "[Step 45610/50000] [Time: 379s] [Train Loss: 1.42e-01] [Train Acc: 0.98]\n",
            "[Step 45623/50000] [Progress: 91.25%] [learning rate: 6.4e+03]\n",
            "[Step 45648/50000] [Progress: 91.30%] [learning rate: 5.7e+03]\n",
            "[Step 45674/50000] [Progress: 91.35%] [learning rate: 6.2e+03]\n",
            "[Step 45698/50000] [Progress: 91.40%] [learning rate: 5.6e+03]\n",
            "[Step 45709/50000] [Time: 380s] [Train Loss: 1.41e-01] [Train Acc: 0.98]\n",
            "[Step 45726/50000] [Progress: 91.45%] [learning rate: 6.6e+03]\n",
            "[Step 45750/50000] [Progress: 91.50%] [learning rate: 5.9e+03]\n",
            "[Step 45775/50000] [Progress: 91.55%] [learning rate: 5.9e+03]\n",
            "[Step 45801/50000] [Progress: 91.60%] [learning rate: 5.8e+03]\n",
            "[Step 45808/50000] [Time: 381s] [Train Loss: 1.41e-01] [Train Acc: 0.98]\n",
            "[Step 45826/50000] [Progress: 91.65%] [learning rate: 5.7e+03]\n",
            "[Step 45853/50000] [Progress: 91.71%] [learning rate: 6.2e+03]\n",
            "[Step 45879/50000] [Progress: 91.76%] [learning rate: 6.7e+03]\n",
            "[Step 45902/50000] [Progress: 91.80%] [learning rate: 5.4e+03]\n",
            "[Step 45907/50000] [Time: 382s] [Train Loss: 1.41e-01] [Train Acc: 0.98]\n",
            "[Step 45929/50000] [Progress: 91.86%] [learning rate: 6.5e+03]\n",
            "[Step 45952/50000] [Progress: 91.90%] [learning rate: 5.3e+03]\n",
            "[Step 45978/50000] [Progress: 91.96%] [learning rate: 6.3e+03]\n",
            "[Step 46002/50000] [Progress: 92.00%] [learning rate: 5.6e+03]\n",
            "[Step 46006/50000] [Time: 382s] [Train Loss: 1.41e-01] [Train Acc: 0.98]\n",
            "[Step 46029/50000] [Progress: 92.06%] [learning rate: 6.7e+03]\n",
            "[Step 46052/50000] [Progress: 92.10%] [learning rate: 6.0e+03]\n",
            "[Step 46076/50000] [Progress: 92.15%] [learning rate: 5.9e+03]\n",
            "[Step 46101/50000] [Progress: 92.20%] [learning rate: 5.8e+03]\n",
            "[Step 46105/50000] [Time: 383s] [Train Loss: 1.40e-01] [Train Acc: 0.98]\n",
            "[Step 46127/50000] [Progress: 92.25%] [learning rate: 6.3e+03]\n",
            "[Step 46151/50000] [Progress: 92.30%] [learning rate: 5.6e+03]\n",
            "[Step 46178/50000] [Progress: 92.36%] [learning rate: 6.1e+03]\n",
            "[Step 46203/50000] [Progress: 92.41%] [learning rate: 6.0e+03]\n",
            "[Step 46205/50000] [Time: 384s] [Train Loss: 1.40e-01] [Train Acc: 0.98]\n",
            "[Step 46229/50000] [Progress: 92.46%] [learning rate: 5.9e+03]\n",
            "[Step 46253/50000] [Progress: 92.51%] [learning rate: 5.8e+03]\n",
            "[Step 46278/50000] [Progress: 92.56%] [learning rate: 5.8e+03]\n",
            "[Step 46303/50000] [Progress: 92.61%] [learning rate: 5.7e+03]\n",
            "[Step 46305/50000] [Time: 384s] [Train Loss: 1.40e-01] [Train Acc: 0.98]\n",
            "[Step 46329/50000] [Progress: 92.66%] [learning rate: 6.1e+03]\n",
            "[Step 46356/50000] [Progress: 92.71%] [learning rate: 6.7e+03]\n",
            "[Step 46380/50000] [Progress: 92.76%] [learning rate: 6.0e+03]\n",
            "[Step 46405/50000] [Progress: 92.81%] [learning rate: 5.9e+03]\n",
            "[Step 46405/50000] [Time: 385s] [Train Loss: 1.40e-01] [Train Acc: 0.98]\n",
            "[Step 46431/50000] [Progress: 92.86%] [learning rate: 6.4e+03]\n",
            "[Step 46454/50000] [Progress: 92.91%] [learning rate: 5.7e+03]\n",
            "[Step 46480/50000] [Progress: 92.96%] [learning rate: 6.2e+03]\n",
            "[Step 46505/50000] [Time: 386s] [Train Loss: 1.39e-01] [Train Acc: 0.98]\n",
            "[Step 46507/50000] [Progress: 93.01%] [learning rate: 6.7e+03]\n",
            "[Step 46531/50000] [Progress: 93.06%] [learning rate: 6.0e+03]\n",
            "[Step 46556/50000] [Progress: 93.11%] [learning rate: 5.9e+03]\n",
            "[Step 46582/50000] [Progress: 93.16%] [learning rate: 5.8e+03]\n",
            "[Step 46605/50000] [Time: 387s] [Train Loss: 1.39e-01] [Train Acc: 0.98]\n",
            "[Step 46607/50000] [Progress: 93.21%] [learning rate: 5.7e+03]\n",
            "[Step 46634/50000] [Progress: 93.27%] [learning rate: 6.2e+03]\n",
            "[Step 46660/50000] [Progress: 93.32%] [learning rate: 6.7e+03]\n",
            "[Step 46683/50000] [Progress: 93.37%] [learning rate: 5.5e+03]\n",
            "[Step 46705/50000] [Time: 387s] [Train Loss: 1.39e-01] [Train Acc: 0.98]\n",
            "[Step 46709/50000] [Progress: 93.42%] [learning rate: 5.9e+03]\n",
            "[Step 46733/50000] [Progress: 93.47%] [learning rate: 5.8e+03]\n",
            "[Step 46758/50000] [Progress: 93.52%] [learning rate: 6.3e+03]\n",
            "[Step 46782/50000] [Progress: 93.56%] [learning rate: 5.7e+03]\n",
            "[Step 46805/50000] [Time: 388s] [Train Loss: 1.39e-01] [Train Acc: 0.98]\n",
            "[Step 46809/50000] [Progress: 93.62%] [learning rate: 6.8e+03]\n",
            "[Step 46832/50000] [Progress: 93.66%] [learning rate: 5.5e+03]\n",
            "[Step 46858/50000] [Progress: 93.72%] [learning rate: 6.0e+03]\n",
            "[Step 46882/50000] [Progress: 93.76%] [learning rate: 5.9e+03]\n",
            "[Step 46905/50000] [Time: 389s] [Train Loss: 1.39e-01] [Train Acc: 0.98]\n",
            "[Step 46907/50000] [Progress: 93.81%] [learning rate: 6.4e+03]\n",
            "[Step 46930/50000] [Progress: 93.86%] [learning rate: 5.7e+03]\n",
            "[Step 46956/50000] [Progress: 93.91%] [learning rate: 6.8e+03]\n",
            "[Step 46979/50000] [Progress: 93.96%] [learning rate: 5.5e+03]\n",
            "[Step 47005/50000] [Progress: 94.01%] [learning rate: 6.0e+03]\n",
            "[Step 47005/50000] [Time: 390s] [Train Loss: 1.38e-01] [Train Acc: 0.98]\n",
            "[Step 47029/50000] [Progress: 94.06%] [learning rate: 5.9e+03]\n",
            "[Step 47054/50000] [Progress: 94.11%] [learning rate: 5.8e+03]\n",
            "[Step 47079/50000] [Progress: 94.16%] [learning rate: 6.3e+03]\n",
            "[Step 47103/50000] [Progress: 94.21%] [learning rate: 5.6e+03]\n",
            "[Step 47105/50000] [Time: 390s] [Train Loss: 1.38e-01] [Train Acc: 0.98]\n",
            "[Step 47130/50000] [Progress: 94.26%] [learning rate: 6.7e+03]\n",
            "[Step 47154/50000] [Progress: 94.31%] [learning rate: 6.0e+03]\n",
            "[Step 47179/50000] [Progress: 94.36%] [learning rate: 5.9e+03]\n",
            "[Step 47205/50000] [Progress: 94.41%] [learning rate: 5.8e+03]\n",
            "[Step 47205/50000] [Time: 391s] [Train Loss: 1.38e-01] [Train Acc: 0.98]\n",
            "[Step 47230/50000] [Progress: 94.46%] [learning rate: 5.7e+03]\n",
            "[Step 47255/50000] [Progress: 94.51%] [learning rate: 6.2e+03]\n",
            "[Step 47282/50000] [Progress: 94.56%] [learning rate: 7.4e+03]\n",
            "[Step 47305/50000] [Progress: 94.61%] [learning rate: 6.0e+03]\n",
            "[Step 47305/50000] [Time: 392s] [Train Loss: 1.38e-01] [Train Acc: 0.98]\n",
            "[Step 47330/50000] [Progress: 94.66%] [learning rate: 5.9e+03]\n",
            "[Step 47356/50000] [Progress: 94.71%] [learning rate: 6.4e+03]\n",
            "[Step 47379/50000] [Progress: 94.76%] [learning rate: 5.8e+03]\n",
            "[Step 47405/50000] [Progress: 94.81%] [learning rate: 6.2e+03]\n",
            "[Step 47405/50000] [Time: 393s] [Train Loss: 1.37e-01] [Train Acc: 0.98]\n",
            "[Step 47431/50000] [Progress: 94.86%] [learning rate: 6.8e+03]\n",
            "[Step 47454/50000] [Progress: 94.91%] [learning rate: 5.5e+03]\n",
            "[Step 47480/50000] [Progress: 94.96%] [learning rate: 6.0e+03]\n",
            "[Step 47504/50000] [Progress: 95.01%] [learning rate: 5.9e+03]\n",
            "[Step 47505/50000] [Time: 395s] [Train Loss: 1.37e-01] [Train Acc: 0.98]\n",
            "[Step 47529/50000] [Progress: 95.06%] [learning rate: 6.4e+03]\n",
            "[Step 47553/50000] [Progress: 95.11%] [learning rate: 5.7e+03]\n",
            "[Step 47581/50000] [Progress: 95.16%] [learning rate: 6.8e+03]\n",
            "[Step 47605/50000] [Progress: 95.21%] [learning rate: 6.1e+03]\n",
            "[Step 47605/50000] [Time: 395s] [Train Loss: 1.37e-01] [Train Acc: 0.98]\n",
            "[Step 47630/50000] [Progress: 95.26%] [learning rate: 6.0e+03]\n",
            "[Step 47656/50000] [Progress: 95.31%] [learning rate: 5.9e+03]\n",
            "[Step 47681/50000] [Progress: 95.36%] [learning rate: 5.8e+03]\n",
            "[Step 47705/50000] [Time: 396s] [Train Loss: 1.37e-01] [Train Acc: 0.98]\n",
            "[Step 47708/50000] [Progress: 95.42%] [learning rate: 6.3e+03]\n",
            "[Step 47734/50000] [Progress: 95.47%] [learning rate: 6.2e+03]\n",
            "[Step 47760/50000] [Progress: 95.52%] [learning rate: 6.7e+03]\n",
            "[Step 47783/50000] [Progress: 95.57%] [learning rate: 5.5e+03]\n",
            "[Step 47805/50000] [Time: 397s] [Train Loss: 1.36e-01] [Train Acc: 0.98]\n",
            "[Step 47810/50000] [Progress: 95.62%] [learning rate: 6.5e+03]\n",
            "[Step 47833/50000] [Progress: 95.67%] [learning rate: 5.8e+03]\n",
            "[Step 47858/50000] [Progress: 95.72%] [learning rate: 6.3e+03]\n",
            "[Step 47882/50000] [Progress: 95.76%] [learning rate: 6.2e+03]\n",
            "[Step 47905/50000] [Time: 397s] [Train Loss: 1.36e-01] [Train Acc: 0.98]\n",
            "[Step 47907/50000] [Progress: 95.81%] [learning rate: 6.1e+03]\n",
            "[Step 47931/50000] [Progress: 95.86%] [learning rate: 6.1e+03]\n",
            "[Step 47956/50000] [Progress: 95.91%] [learning rate: 6.0e+03]\n",
            "[Step 47982/50000] [Progress: 95.96%] [learning rate: 6.5e+03]\n",
            "[Step 48005/50000] [Progress: 96.01%] [learning rate: 5.8e+03]\n",
            "[Step 48005/50000] [Time: 398s] [Train Loss: 1.36e-01] [Train Acc: 0.98]\n",
            "[Step 48031/50000] [Progress: 96.06%] [learning rate: 6.3e+03]\n",
            "[Step 48056/50000] [Progress: 96.11%] [learning rate: 6.8e+03]\n",
            "[Step 48079/50000] [Progress: 96.16%] [learning rate: 5.5e+03]\n",
            "[Step 48105/50000] [Time: 399s] [Train Loss: 1.36e-01] [Train Acc: 0.98]\n",
            "[Step 48106/50000] [Progress: 96.21%] [learning rate: 6.6e+03]\n",
            "[Step 48129/50000] [Progress: 96.26%] [learning rate: 5.4e+03]\n",
            "[Step 48156/50000] [Progress: 96.31%] [learning rate: 6.4e+03]\n",
            "[Step 48181/50000] [Progress: 96.36%] [learning rate: 6.3e+03]\n",
            "[Step 48205/50000] [Time: 400s] [Train Loss: 1.36e-01] [Train Acc: 0.98]\n",
            "[Step 48207/50000] [Progress: 96.41%] [learning rate: 6.8e+03]\n",
            "[Step 48231/50000] [Progress: 96.46%] [learning rate: 6.1e+03]\n",
            "[Step 48256/50000] [Progress: 96.51%] [learning rate: 6.0e+03]\n",
            "[Step 48282/50000] [Progress: 96.56%] [learning rate: 5.9e+03]\n",
            "[Step 48305/50000] [Time: 400s] [Train Loss: 1.35e-01] [Train Acc: 0.98]\n",
            "[Step 48307/50000] [Progress: 96.61%] [learning rate: 5.8e+03]\n",
            "[Step 48334/50000] [Progress: 96.67%] [learning rate: 6.3e+03]\n",
            "[Step 48360/50000] [Progress: 96.72%] [learning rate: 6.8e+03]\n",
            "[Step 48383/50000] [Progress: 96.77%] [learning rate: 5.6e+03]\n",
            "[Step 48405/50000] [Time: 401s] [Train Loss: 1.35e-01] [Train Acc: 0.98] [Eval Loss: 5.35e-01] [Eval Acc: 0.77]\n",
            "[Step 48409/50000] [Progress: 96.82%] [learning rate: 6.0e+03]\n",
            "[Step 48433/50000] [Progress: 96.87%] [learning rate: 6.0e+03]\n",
            "[Step 48458/50000] [Progress: 96.92%] [learning rate: 6.4e+03]\n",
            "[Step 48482/50000] [Progress: 96.96%] [learning rate: 5.8e+03]\n",
            "[Step 48505/50000] [Time: 403s] [Train Loss: 1.35e-01] [Train Acc: 0.98]\n",
            "[Step 48509/50000] [Progress: 97.02%] [learning rate: 6.9e+03]\n",
            "[Step 48532/50000] [Progress: 97.06%] [learning rate: 6.2e+03]\n",
            "[Step 48556/50000] [Progress: 97.11%] [learning rate: 6.1e+03]\n",
            "[Step 48581/50000] [Progress: 97.16%] [learning rate: 6.0e+03]\n",
            "[Step 48605/50000] [Time: 404s] [Train Loss: 1.35e-01] [Train Acc: 0.98]\n",
            "[Step 48607/50000] [Progress: 97.21%] [learning rate: 6.5e+03]\n",
            "[Step 48631/50000] [Progress: 97.26%] [learning rate: 5.8e+03]\n",
            "[Step 48658/50000] [Progress: 97.32%] [learning rate: 6.9e+03]\n",
            "[Step 48681/50000] [Progress: 97.36%] [learning rate: 6.2e+03]\n",
            "[Step 48705/50000] [Progress: 97.41%] [learning rate: 6.1e+03]\n",
            "[Step 48705/50000] [Time: 405s] [Train Loss: 1.34e-01] [Train Acc: 0.98]\n",
            "[Step 48730/50000] [Progress: 97.46%] [learning rate: 6.0e+03]\n",
            "[Step 48756/50000] [Progress: 97.51%] [learning rate: 6.5e+03]\n",
            "[Step 48780/50000] [Progress: 97.56%] [learning rate: 5.8e+03]\n",
            "[Step 48805/50000] [Time: 406s] [Train Loss: 1.34e-01] [Train Acc: 0.98]\n",
            "[Step 48807/50000] [Progress: 97.61%] [learning rate: 6.3e+03]\n",
            "[Step 48832/50000] [Progress: 97.66%] [learning rate: 6.2e+03]\n",
            "[Step 48858/50000] [Progress: 97.72%] [learning rate: 6.1e+03]\n",
            "[Step 48882/50000] [Progress: 97.76%] [learning rate: 6.0e+03]\n",
            "[Step 48905/50000] [Time: 406s] [Train Loss: 1.34e-01] [Train Acc: 0.98]\n",
            "[Step 48907/50000] [Progress: 97.81%] [learning rate: 5.9e+03]\n",
            "[Step 48932/50000] [Progress: 97.86%] [learning rate: 5.9e+03]\n",
            "[Step 48957/50000] [Progress: 97.91%] [learning rate: 6.3e+03]\n",
            "[Step 48983/50000] [Progress: 97.97%] [learning rate: 7.6e+03]\n",
            "[Step 49003/50000] [Progress: 98.01%] [learning rate: 5.1e+03]\n",
            "[Step 49005/50000] [Time: 407s] [Train Loss: 1.34e-01] [Train Acc: 0.98]\n",
            "[Step 49031/50000] [Progress: 98.06%] [learning rate: 6.7e+03]\n",
            "[Step 49056/50000] [Progress: 98.11%] [learning rate: 6.0e+03]\n",
            "[Step 49082/50000] [Progress: 98.16%] [learning rate: 6.5e+03]\n",
            "[Step 49105/50000] [Time: 408s] [Train Loss: 1.34e-01] [Train Acc: 0.98]\n",
            "[Step 49106/50000] [Progress: 98.21%] [learning rate: 5.8e+03]\n",
            "[Step 49133/50000] [Progress: 98.27%] [learning rate: 6.9e+03]\n",
            "[Step 49157/50000] [Progress: 98.31%] [learning rate: 6.2e+03]\n",
            "[Step 49182/50000] [Progress: 98.36%] [learning rate: 6.1e+03]\n",
            "[Step 49205/50000] [Time: 409s] [Train Loss: 1.33e-01] [Train Acc: 0.98]\n",
            "[Step 49208/50000] [Progress: 98.42%] [learning rate: 6.0e+03]\n",
            "[Step 49234/50000] [Progress: 98.47%] [learning rate: 6.5e+03]\n",
            "[Step 49258/50000] [Progress: 98.52%] [learning rate: 5.8e+03]\n",
            "[Step 49284/50000] [Progress: 98.57%] [learning rate: 6.9e+03]\n",
            "[Step 49305/50000] [Time: 409s] [Train Loss: 1.33e-01] [Train Acc: 0.98]\n",
            "[Step 49307/50000] [Progress: 98.61%] [learning rate: 5.6e+03]\n",
            "[Step 49334/50000] [Progress: 98.67%] [learning rate: 6.7e+03]\n",
            "[Step 49357/50000] [Progress: 98.71%] [learning rate: 6.0e+03]\n",
            "[Step 49382/50000] [Progress: 98.76%] [learning rate: 5.9e+03]\n",
            "[Step 49405/50000] [Time: 410s] [Train Loss: 1.33e-01] [Train Acc: 0.98]\n",
            "[Step 49409/50000] [Progress: 98.82%] [learning rate: 6.4e+03]\n",
            "[Step 49435/50000] [Progress: 98.87%] [learning rate: 6.3e+03]\n",
            "[Step 49459/50000] [Progress: 98.92%] [learning rate: 6.2e+03]\n",
            "[Step 49484/50000] [Progress: 98.97%] [learning rate: 6.1e+03]\n",
            "[Step 49505/50000] [Time: 411s] [Train Loss: 1.33e-01] [Train Acc: 0.98]\n",
            "[Step 49510/50000] [Progress: 99.02%] [learning rate: 6.0e+03]\n",
            "[Step 49535/50000] [Progress: 99.07%] [learning rate: 6.0e+03]\n",
            "[Step 49562/50000] [Progress: 99.12%] [learning rate: 6.5e+03]\n",
            "[Step 49588/50000] [Progress: 99.18%] [learning rate: 6.4e+03]\n",
            "[Step 49605/50000] [Time: 411s] [Train Loss: 1.32e-01] [Train Acc: 0.98]\n",
            "[Step 49614/50000] [Progress: 99.23%] [learning rate: 6.9e+03]\n",
            "[Step 49637/50000] [Progress: 99.27%] [learning rate: 5.6e+03]\n",
            "[Step 49664/50000] [Progress: 99.33%] [learning rate: 6.7e+03]\n",
            "[Step 49687/50000] [Progress: 99.37%] [learning rate: 6.0e+03]\n",
            "[Step 49705/50000] [Time: 412s] [Train Loss: 1.32e-01] [Train Acc: 0.98]\n",
            "[Step 49712/50000] [Progress: 99.42%] [learning rate: 6.5e+03]\n",
            "[Step 49736/50000] [Progress: 99.47%] [learning rate: 5.8e+03]\n",
            "[Step 49763/50000] [Progress: 99.53%] [learning rate: 6.9e+03]\n",
            "[Step 49787/50000] [Progress: 99.57%] [learning rate: 6.2e+03]\n",
            "[Step 49805/50000] [Time: 413s] [Train Loss: 1.32e-01] [Train Acc: 0.98]\n",
            "[Step 49812/50000] [Progress: 99.62%] [learning rate: 6.1e+03]\n",
            "[Step 49838/50000] [Progress: 99.68%] [learning rate: 6.6e+03]\n",
            "[Step 49861/50000] [Progress: 99.72%] [learning rate: 5.9e+03]\n",
            "[Step 49887/50000] [Progress: 99.77%] [learning rate: 6.4e+03]\n",
            "[Step 49905/50000] [Time: 414s] [Train Loss: 1.32e-01] [Train Acc: 0.98]\n",
            "[Step 49914/50000] [Progress: 99.83%] [learning rate: 7.6e+03]\n",
            "[Step 49934/50000] [Progress: 99.87%] [learning rate: 5.1e+03]\n",
            "[Step 49962/50000] [Progress: 99.92%] [learning rate: 6.7e+03]\n",
            "[Step 49987/50000] [Progress: 99.97%] [learning rate: 6.0e+03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "def load_results(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        data = torch.load(f, weights_only=False)\n",
        "    args = data.get('args', None)\n",
        "    results = data.get('results', None)\n",
        "\n",
        "    if results is None:\n",
        "        print(f\"No results found in {filename}\")\n",
        "        return None, None\n",
        "\n",
        "    if 'init_kernel' in results:\n",
        "        dynamics = results['init_kernel'].get('dynamics', [])\n",
        "        final_results = results['init_kernel']\n",
        "    else:\n",
        "        print(f\"No 'init_kernel' key found in {filename}\")\n",
        "        return None, None\n",
        "\n",
        "    return args, final_results, dynamics\n",
        "\n",
        "def plot_training_results(args, dynamics):\n",
        "    if args is None or dynamics is None:\n",
        "        print(\"No data to plot.\")\n",
        "        return\n",
        "\n",
        "    steps = [state['step'] for state in dynamics]\n",
        "    train_losses = [state['train']['loss'] for state in dynamics]\n",
        "    train_accuracies = [state['train']['accuracy'] for state in dynamics]\n",
        "\n",
        "    plt.figure(figsize=(9, 5))\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(steps, train_losses, label='Train', color='blue')\n",
        "    if args.track_test_metrics:\n",
        "        test_steps = [state['step'] for state in dynamics if state['test']['loss'] is not None]\n",
        "        test_losses = [state['test']['loss'] for state in dynamics if state['test']['loss'] is not None]\n",
        "        plt.plot(test_steps, test_losses, label='Test', color='red')\n",
        "    plt.xlabel('Step')\n",
        "    # plt.xscale('log')\n",
        "    # plt.yscale('log')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(steps, train_accuracies, label='Train', color='blue')\n",
        "    if args.track_test_metrics:\n",
        "        test_steps = [state['step'] for state in dynamics if state['test']['accuracy'] is not None]\n",
        "        test_accuracies = [state['test']['accuracy'] for state in dynamics if state['test']['accuracy'] is not None]\n",
        "        plt.plot(test_steps, test_accuracies, label='Test', color='red')\n",
        "    plt.xlabel('Step')\n",
        "    # plt.xscale('log')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# テストとトレーニングの出力とラベルの最初の100個を表示する関数\n",
        "def print_outputs_labels(final_results, num_samples=100):\n",
        "    # Training data display\n",
        "    if final_results is None or 'train' not in final_results:\n",
        "        print(\"No train results found in the final results.\")\n",
        "    else:\n",
        "        train_outputs = final_results['train']['outputs']\n",
        "        train_labels = final_results['train']['labels']\n",
        "\n",
        "        if train_outputs is not None and train_labels is not None:\n",
        "            print(f\"\\nFirst {num_samples} Train Outputs:\")\n",
        "            print(train_outputs[:num_samples])\n",
        "\n",
        "            print(f\"\\nFirst {num_samples} Train Labels:\")\n",
        "            print(train_labels[:num_samples])\n",
        "        else:\n",
        "            print(\"Train outputs or labels not found.\")\n",
        "\n",
        "    # Test data display\n",
        "    if final_results is None or 'test' not in final_results:\n",
        "        print(\"No test results found in the final results.\")\n",
        "    else:\n",
        "        test_outputs = final_results['test']['outputs']\n",
        "        test_labels = final_results['test']['labels']\n",
        "\n",
        "        if test_outputs is not None and test_labels is not None:\n",
        "            print(f\"\\nFirst {num_samples} Test Outputs:\")\n",
        "            print(test_outputs[:num_samples])\n",
        "\n",
        "            print(f\"\\nFirst {num_samples} Test Labels:\")\n",
        "            print(test_labels[:num_samples])\n",
        "        else:\n",
        "            print(\"Test outputs or labels not found.\")\n",
        "\n",
        "filename = 'results.pkl'\n",
        "args, final_results, dynamics = load_results(filename)\n",
        "\n",
        "\n",
        "plot_training_results(args, dynamics)\n",
        "\n",
        "# トレーニングとテスト出力とラベルの最初の100個を表示\n",
        "print_outputs_labels(final_results, num_samples=100)\n",
        "\n",
        "\n",
        "# Calculate and display final test accuracy\n",
        "if final_results is not None and 'test' in final_results:\n",
        "    test_outputs = final_results['test']['outputs']\n",
        "    test_labels = final_results['test']['labels']\n",
        "    if test_outputs is not None and test_labels is not None:\n",
        "        test_preds = torch.sigmoid(test_outputs) > 0.5\n",
        "        test_accuracy = (test_preds.int() == test_labels.int()).float().mean().item()\n",
        "        print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n",
        "    else:\n",
        "        print(\"Test outputs or labels not found.\")\n",
        "else:\n",
        "    print(\"No test results found in the final results.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "busmySOVucH0",
        "outputId": "2edbb732-12da-48c3-ea7e-d68d6066c001"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAAEYCAYAAAD/Dg+wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB/zUlEQVR4nO3dd3hT5dsH8G+StummhdJJoezdAgVKARF+lCGIsmQqUBSUoWAdgGwcVZYooihDFFEQBOQVBEqxILL3LpuyuljdbZqc94+HJA1NS0fatM33c13nSvLknJMnN6End54lkyRJAhEREREREZVrcnNXgIiIiIiIiIqPyR0REREREVEFwOSOiIiIiIioAmByR0REREREVAEwuSMiIiIiIqoAmNwRERERERFVAEzuiIiIiIiIKgAmd0RERERERBUAkzsiIiIiIqIKgMkdERERERFRBcDkjqiMWbVqFWQyGY4ePWruqhARERn49ttvIZPJEBQUZO6qEJERTO6IiIiIqEDWrFkDPz8/HD58GFeuXDF3dYjoKUzuiIiIiOiZrl+/jv3792PhwoWoWrUq1qxZY+4qGZWammruKhCZDZM7onLoxIkTeOGFF+Ds7AxHR0d07twZBw8eNNhHpVJh9uzZqFu3LmxtbVGlShW0b98eERERun1iY2MRGhqKatWqQalUwsvLCy+//DJu3LhRyu+IiIjKujVr1sDV1RU9e/ZE//79jSZ3jx49wrvvvgs/Pz8olUpUq1YNw4YNQ2Jiom6fjIwMzJo1C/Xq1YOtrS28vLzQt29fXL16FQAQFRUFmUyGqKgog3PfuHEDMpkMq1at0pWNGDECjo6OuHr1Knr06AEnJycMHToUAPDvv//ilVdeQfXq1aFUKuHr64t3330X6enpuep98eJFDBgwAFWrVoWdnR3q16+PqVOnAgD++ecfyGQybNq0Kddxv/76K2QyGQ4cOFDoeBKVBCtzV4CICufcuXN47rnn4OzsjA8//BDW1tb4/vvv0bFjR+zZs0c3DmLWrFkIDw/HG2+8gdatWyMpKQlHjx7F8ePH0aVLFwBAv379cO7cObz99tvw8/NDfHw8IiIiEBMTAz8/PzO+SyIiKmvWrFmDvn37wsbGBoMHD8Z3332HI0eOoFWrVgCAlJQUPPfcc7hw4QJGjhyJFi1aIDExEVu2bMHt27fh5uYGtVqNF198EZGRkRg0aBAmTJiA5ORkRERE4OzZs6hdu3ah65WdnY1u3bqhffv2mD9/Puzt7QEA69evR1paGsaMGYMqVarg8OHDWLx4MW7fvo3169frjj99+jSee+45WFtbY/To0fDz88PVq1fxf//3f/j000/RsWNH+Pr6Ys2aNejTp0+umNSuXRvBwcHFiCyRCUlEVKb8+OOPEgDpyJEjRp/v3bu3ZGNjI129elVXdvfuXcnJyUnq0KGDriwgIEDq2bNnnq/z8OFDCYA0b94801WeiIgqpKNHj0oApIiICEmSJEmj0UjVqlWTJkyYoNtnxowZEgBp48aNuY7XaDSSJEnSypUrJQDSwoUL89znn3/+kQBI//zzj8Hz169flwBIP/74o65s+PDhEgBp8uTJuc6XlpaWqyw8PFySyWTSzZs3dWUdOnSQnJycDMpy1keSJGnKlCmSUqmUHj16pCuLj4+XrKyspJkzZ+Z6HSJzYbdMonJErVZj586d6N27N2rVqqUr9/LywpAhQ7Bv3z4kJSUBAFxcXHDu3DlcvnzZ6Lns7OxgY2ODqKgoPHz4sFTqT0RE5dOaNWvg4eGBTp06AQBkMhkGDhyItWvXQq1WAwD++OMPBAQE5Grd0u6v3cfNzQ1vv/12nvsUxZgxY3KV2dnZ6e6npqYiMTERbdu2hSRJOHHiBAAgISEBe/fuxciRI1G9evU86zNs2DBkZmZiw4YNurJ169YhOzsbr776apHrTWRqTO6IypGEhASkpaWhfv36uZ5r2LAhNBoNbt26BQCYM2cOHj16hHr16qFp06b44IMPcPr0ad3+SqUSX3zxBf7++294eHigQ4cOmDt3LmJjY0vt/RARUdmnVquxdu1adOrUCdevX8eVK1dw5coVBAUFIS4uDpGRkQCAq1evokmTJvme6+rVq6hfvz6srEw3MsjKygrVqlXLVR4TE4MRI0agcuXKcHR0RNWqVfH8888DAB4/fgwAuHbtGgA8s94NGjRAq1atDMYZrlmzBm3atEGdOnVM9VaIio3JHVEF1aFDB1y9ehUrV65EkyZNsHz5crRo0QLLly/X7TNx4kRcunQJ4eHhsLW1xfTp09GwYUPdL5pERES7d+/GvXv3sHbtWtStW1e3DRgwAABMPmtmXi142hbCpymVSsjl8lz7dunSBVu3bsWkSZOwefNmRERE6CZj0Wg0ha7XsGHDsGfPHty+fRtXr17FwYMH2WpHZQ4nVCEqR6pWrQp7e3tER0fneu7ixYuQy+Xw9fXVlVWuXBmhoaEIDQ1FSkoKOnTogFmzZuGNN97Q7VO7dm289957eO+993D58mU0a9YMCxYswC+//FIq74mIiMq2NWvWwN3dHUuWLMn13MaNG7Fp0yYsXboUtWvXxtmzZ/M9V+3atXHo0CGoVCpYW1sb3cfV1RWAmHkzp5s3bxa4zmfOnMGlS5fw008/YdiwYbrynDNGA9ANcXhWvQFg0KBBCAsLw2+//Yb09HRYW1tj4MCBBa4TUWlgyx1ROaJQKNC1a1f8+eefBssVxMXF4ddff0X79u3h7OwMALh//77BsY6OjqhTpw4yMzMBAGlpacjIyDDYp3bt2nByctLtQ0REli09PR0bN27Eiy++iP79++faxo8fj+TkZGzZsgX9+vXDqVOnjC4ZIEkSADFLc2JiIr755ps896lRowYUCgX27t1r8Py3335b4HorFAqDc2rvf/XVVwb7Va1aFR06dMDKlSsRExNjtD5abm5ueOGFF/DLL79gzZo16N69O9zc3ApcJ6LSwJY7ojJq5cqV2L59e67yWbNmISIiAu3bt8fYsWNhZWWF77//HpmZmZg7d65uv0aNGqFjx44IDAxE5cqVcfToUWzYsAHjx48HAFy6dAmdO3fGgAED0KhRI1hZWWHTpk2Ii4vDoEGDSu19EhFR2bVlyxYkJyfjpZdeMvp8mzZtdAua//rrr9iwYQNeeeUVjBw5EoGBgXjw4AG2bNmCpUuXIiAgAMOGDcPPP/+MsLAwHD58GM899xxSU1Oxa9cujB07Fi+//DIqVaqEV155BYsXL4ZMJkPt2rXx119/IT4+vsD1btCgAWrXro33338fd+7cgbOzM/744w+jE4h9/fXXaN++PVq0aIHRo0ejZs2auHHjBrZu3YqTJ08a7Dts2DD0798fAPDxxx8XPJBEpcWcU3USUW7apRDy2m7duiUdP35c6tatm+To6CjZ29tLnTp1kvbv329wnk8++URq3bq15OLiItnZ2UkNGjSQPv30UykrK0uSJElKTEyUxo0bJzVo0EBycHCQKlWqJAUFBUm///67Od42ERGVQb169ZJsbW2l1NTUPPcZMWKEZG1tLSUmJkr379+Xxo8fL/n4+Eg2NjZStWrVpOHDh0uJiYm6/dPS0qSpU6dKNWvWlKytrSVPT0+pf//+Bkv8JCQkSP369ZPs7e0lV1dX6c0335TOnj1rdCkEBwcHo/U6f/68FBISIjk6Okpubm7SqFGjpFOnTuU6hyRJ0tmzZ6U+ffpILi4ukq2trVS/fn1p+vTpuc6ZmZkpubq6SpUqVZLS09MLGEWi0iOTpKfanImIiIiIKJfs7Gx4e3ujV69eWLFihbmrQ5QLx9wRERERERXA5s2bkZCQYDBJC1FZwpY7IiIiIqJ8HDp0CKdPn8bHH38MNzc3HD9+3NxVIjKKLXdERERERPn47rvvMGbMGLi7u+Pnn382d3WI8sTkjoiIqATt3bsXvXr1gre3N2QyGTZv3vzMY6KiotCiRQsolUrUqVNHt/AyEZnHqlWrkJ2djaNHj6JJkybmrg5RnpjcERERlaDU1FQEBAQYXQDamOvXr6Nnz57o1KkTTp48iYkTJ+KNN97Ajh07SrimRERU3nHMHRERUSmRyWTYtGkTevfunec+kyZNwtatW3H27Fld2aBBg/Do0SOja18SERFpWdwi5hqNBnfv3oWTkxNkMpm5q0NERAUkSRKSk5Ph7e0Nubzidjw5cOAAQkJCDMq6deuGiRMnFvgcvNYREZVPxb3WWVxyd/fuXfj6+pq7GkREVES3bt1CtWrVzF2NEhMbGwsPDw+DMg8PDyQlJSE9PR12dna5jsnMzERmZqbu8Z07d9CoUaMSrysREZWMol7rLC65c3JyAiAC5uzsXKRzqFQq7Ny5E127doW1tbUpq1fuMBZ6jIUeY6HHWOgVNxZJSUnw9fXV/R0nvfDwcMyePTtX+fLly2Fvb2+GGhERUVGkpaXhjTfeKPK1zuKSO233FGdn52Ild/b29nB2duaXNcZCh7HQYyz0GAs9U8Wioncz9PT0RFxcnEFZXFwcnJ2djbbaAcCUKVMQFhame6xNhHv37l2sa11ERAS6dOnCzy5jocNY6DEWeoyFXnFjkZSUhDfeeKPI17oykdwtWbIE8+bNQ2xsLAICArB48WK0bt3a6L4dO3bEnj17cpX36NEDW7duLemqEhERlajg4GBs27bNoCwiIgLBwcF5HqNUKqFUKnOVW1tbF/uLlinOUVEwFnqMhR5jocdY6BU1FsWNn9lHpK9btw5hYWGYOXMmjh8/joCAAHTr1g3x8fFG99+4cSPu3bun286ePQuFQoFXXnmllGtORET0bCkpKTh58iROnjwJQCx1cPLkScTExAAQrW7Dhg3T7f/WW2/h2rVr+PDDD3Hx4kV8++23+P333/Huu++ao/pERFSOmD25W7hwIUaNGoXQ0FA0atQIS5cuhb29PVauXGl0/8qVK8PT01O3RUREwN7enskdERGVSUePHkXz5s3RvHlzAEBYWBiaN2+OGTNmAADu3bunS/QAoGbNmti6dSsiIiIQEBCABQsWYPny5ejWrZtZ6k9EROWHWbtlZmVl4dixY5gyZYquTC6XIyQkBAcOHCjQOVasWIFBgwbBwcHB6PNPzyCWlJQEQPSHValURaq39riiHl+RMBZ6jIWeJcdCrVYjOzsb2iVEs7OzYWVlhZSUFFhZlYme8GbzrFjIZDJYWVlBoVAYPb68fp46duyI/JaUXbVqldFjTpw4UYK1IiKiisis3zQSExOhVquNTvl88eLFZx5/+PBhnD17FitWrMhzn7xmENu5c2eRZxCLP5iGSnap2JHxN+S2lv1lTSsiIsLcVSgzGAs9S4uFk5MTnJyccq1L4+npiWvXrpmpVmXLs2Kh0WiQnJyM5OTkXM+lpaWVZNWIiIgMSBKgbSPSaIDbt4Hs7PyPUamA9HTz5QflOjNZsWIFmjZtmufkK0DeM4h17dq1SDOIqdXA9t4D0Bub8VDmigfLfkf1Yc8Xqf4VAWdH0mMs9CwxFnFxcUhKSkLVqlVhb2+vm+VKkiSkpqbCwcGhws/y+CzPioUkSUhLS0NCQgLq1auX64c/bc8LIiKiorp/Hzh+HLh3z7BcrRbJW1YWcOcOkJwM7NkDJCQU9hWsMW1aFfTrZ6oaF45Zkzs3NzcoFAqjUz57enrme2xqairWrl2LOXPm5LufqWcQS0oC4GCP7FQFXKWHUIwZBOuOh4DatQt9roqEsyPpMRZ6lhILtVqN5ORkeHh4oEqVKgbPaTQaqFQq2NnZ5WrRszQFiYWDgwPkcjni4+Ph5eVl0EXTEj5LRESWSJKAmzeB8+fzbhlLSBAJV17UaiA6Grh7V1+WkgLEx4vzx8cDqan6lriicHAA8liRJgcJVlaaor9IMZk1ubOxsUFgYCAiIyPRu3dvAOLiHxkZifHjx+d77Pr165GZmYlXX321FGqqV6UK0PPhKqxYMhQt3p2JVqqjyGz/PygP7AH8/Eq1LkRUNmjHgnGxaNPQxlGlUuU5/o6IiMoPlQqIixNJ1rlzotXs7Fng1Clxm57+pAGllNSpA9SqBTz9O6OXl0jePD0Be3vA3x9o3Vq/n4ND7mOeplJlY9u2Qjf3mYzZu2WGhYVh+PDhaNmyJVq3bo1FixYhNTUVoaGhAIBhw4bBx8cH4eHhBsetWLECvXv3zvUreWnxrKnCqr5/wnljJ9SPvQT873/A4cOAm5tZ6kNE5mfp3S5NhXEkIipbJEm0et25Y7zlS6UCzp6tApVKhsePRcJ27x5w7JhokVOrxZi1/FhbAw0biqTKGCcnoGrV/M9Ro4boTKdNwKytAR8f8djFBahcGXB2BipVeuZbLrfMntwNHDgQCQkJmDFjBmJjY9GsWTNs375dN9YiJiYmV/ed6Oho7Nu3Dzt37jRHlXXGzqmKkE27ESV1QO3r14Bhw4C//np2Sk9EREREVMoePQJiY8UG6MeZ3boFXLwoEjBJEmWXL+sTsqws4PHj/M5sDaB9vq+tUIivyFWqAAEBgLs70LKlaBlzdhZJmZGRVFRIZk/uAGD8+PF5dsOMiorKVVa/fv18p5UuLfXqAR2H+qDPL5twRB4E5d9/A198AeRY2oGIyJL4+flh4sSJmDhxormrQkRUYaWliVY07STCjx6JiUIePhStZcePAw8eiOcyMvTj0NTq4r2ugwPg6GjsGQlAGvz87ODkJEfTpoCHB9C8OVC/PmBjIx6z/aPklYnkrjybPBlo8os/xmm+wXK8AUybBrRtCzxvuTNoElHZ96yujzNnzsSsWbMKfd4jR47kue4oERHlLT1dTPqRlQUcPapP3LTUaiAmBoiKAv77r+iv4+AAVKumT7S8vcVYsyZN9C1nVaoAjRuLpAwQ+/r4iK6RxhI0Mc5sF3r06AFra2Zw5sTkrpgaNwZefBFY8ddIvFFvL9pc+hkYPlxM18O2ZSIqo+7lmAN63bp1mDFjBqKjo3Vljjl+mpUkCWq1ukCLsFd91oAIIiILJ0nAv/+KBO7uXdHd8cQJMVNkenrBz2NnJ8aRAYCtrUjQ7O2BZs1Ed0dvb0AmE90hq1UTt46OogskVVxM7kxg4kTgr79k6B//LW55RUB28yawYgUwdqy5q0ZEZFTO5WYqVaoEmUymK4uKikKnTp2wbds2TJs2DWfOnMHOnTvh6+uLsLAwHDx4EKmpqWjYsCHCw8MREhKiO9fT3TJlMhmWLVuGrVu3YseOHfDy8sKCBQt0MyQTEVU0arXoMqlWi4lGjh0TY9ru3QPOnBH3L10yfqy1NWBlJWZyrFlTJGc5eXmJ5wYPNmx9I9JicmcCHTuK/2x37jngzICp8P9hPPDpp0BoaEEWwyCiCkiSRJcajUbMMKYdSF7S7O1zfxkoqsmTJ2P+/PmoVasWXF1dcevWLfTo0QOffvoplEolfv75Z/Tq1QvR0dGoXr16nueZPXs25s6diy+++AILFy7Ea6+9hps3b6Jy5cqmqSgRUQnJyhKJmHaGyNhY4MIFkbip1XKcPVsPCxcqcPs2kJhY8On8ra2Bl14SXR2rVBGJWmCgmHqfEwZTcTC5MwGFAhg4EFi0CPgy+Q386PuF+Fnm++9Fsx4RWZy0NO2gczkAl1J73ZQUMZ7CFObMmYMuXbroHleuXBkBAQG6xx9//DE2bdqELVu25Ls26YgRIzB48GBoNBpMnz4d33//PQ4fPozu3bubpqJERAX08KGYaCQxUXSHvHNHJG/p6aJV7e5d/UySgPhx7slSpkYoADQ0+oy1tX68Wo0aImnz8QEaNAB8fUXXyScTwxOZFJM7E3n5ZZHc/b1bCWnOdMjeHA2EhwOjRpnumxYRUSlq2bKlweOUlBTMmjULW7duxb1795CdnY309HTExMTkex5/f3/dfQcHBzg7OyM+Pr5E6kxEBIgf2DZuFL+1JySIpO7gQTHdf2FVqqQfp+bkJBI1OztAo9Hg9u1b6Nq1Gtq1U6BSJTG9PyBa4xQK070fooJicmciwcGiO1RcHHAmcAT8a30OXLsGfPMNMGmSuatHRKXM3l60omk0GiQlJcHZ2TnXmp0l9bqm8vSsl++//z4iIiIwf/581KlTB3Z2dujfvz+ysrLyPY+1tbXBY5lMBs2zVrMlInpKRoZ+vNqlS6KVLTlZJG85Xb8uWuGys42fx9FRJGnu7mJCEn9/MSFJ/fpA9eqiZU3751qpFGXGukqqVGps23YSPXp4w9qamRyVDUzuTESpFKsf/P038M8+a/jPmAGMGAHMnQuMGcOpiYgsjEwmGu01GjE2w8Gh/A98/++//zBixAj06dMHgGjJu3HjhnkrRUQVTmoqEBEhxrbt3i0e37kjkrjCzCbp5wf873/iK1jVqqJ75AsvABzuSxUZkzsTatdOJHeHDwP4aajolhkdDXz1FTB9urmrR0RULHXr1sXGjRvRq1cvyGQyTJ8+nS1wRFQkarV+wqnbt4FTp0Rr240bwI4dYlFuY2xtRZfH1q3FbJK2tmIykpwta3Z2QFAQULcuu0aS5WFyZ0KtW4vbQ4cg5rGdNUvMVbtggWi9c3MzZ/WIiIpl4cKFGDlyJNq2bQs3NzdMmjQJSQWdGo6ILJokiSUB/vkH+OMP4Pjx/CYqEV0hW7QAOnUSM5L7+opu540bM2Ejyg+TOxPSzj1w9Spw/z5QZcAA4PPPxc9RH30E/PCDeStIRGTEiBEjMGLECN3jjh07QpKkXPv5+flh9+7dBmXjxo0zePx0N01j53nw4EGpjD8kotIhSWLJAI1GtMLFxYnulA8fivJbt/Stcsa4uIjxboGBohUuOBjo0KH8d2UnMgcmdybk6grUqycG+R4+DLzwghxYvFj8hVq+HHjjDX3zHhEREVEZJ0nie82jRyLZunRJhp9+CsCaNQrExuqfL8gEuHZ2QOfOYtxbt25i7JuVlZjchIhMg8mdiQUF5UzuADz3HPDaa8Dq1cC4cWIeXvYnICIiojLo1i3R4ejmTdGN8s8/xbpwelYA/PI83s5OTCDVoYP4wVsmE10qa9cG2rTh/HJEJY3JnYm1bi3yuEOHchTOnSv+Oh49Klrw3nzTbPUjIiIi0rp/X6z9tn+/2LZsEd0rc7K1Fa1sWVmAt7eE6tWv4bnn/ODnp4BCIcbENWwoWvacnNidksicmNyZWFCQuD18WHRVkMkAeHoCH38MTJgATJkC9OvHyVWIiIioxKWni1a47GwxHm7/fvH4/n0xNu7o0dzHNG4M1Kollg7o1w9o2xawsRHPqVTZ2LbtLHr0qM613YjKICZ3JhYQIP4A3r8PXLkipuEFAIwdC6xYAZw+LRK8ZcvMWk8iIiKqWNLTxeiPS5eAPXvEpCZxcc8+rkYNMW/ACy8APXoA7duXfF2JqGQwuTMxGxsxde/Bg6Jrpi65s7ICliwRY/BWrBCTq2ib+YiIiIgKSZKAa9eAqChg/XqRzBlbXsDBQWyVKolWuDp1AG9v8dXk+edFckdEFQOTuxLQpo1I7g4eBF59NccT7dsDw4cDP/0kJlc5dIiTqxAREVGBZGaKZO7ff4ENG8T9q1cN9/HxAfz9gaZNga5dRY+iypU5Do7IUjC5KwFt2ojbgweNPPnFF8DmzWIKqmXLgLfeKs2qERERURknSWKSkzVrgMREMYPlw4diFsu0NMN9ra1FR6BOncQPynXrPhnvT0QWicldCdAmd9o/wvb2OZ708BCTq7zzjljYvF8/oGpVs9STiIiIyo4rV8Sk2r/9BsTEGN/HxkYkcyEhYhhIUBC/RhCRntkb6ZcsWQI/Pz/Y2toiKCgIhw8fznf/R48eYdy4cfDy8oJSqUS9evWwbdu2UqptwVSvLibIzM4Gjh83ssOYMaKfxMOHYg28zMxSryMRERGZR3Y28MMP4utAv36i+2TjxqLV7Ysv9Indc88Bs2YBS5cCa9cCR46IH4337gVmzABefJGJHREZMmvL3bp16xAWFoalS5ciKCgIixYtQrdu3RAdHQ13d/dc+2dlZaFLly5wd3fHhg0b4OPjg5s3b8LFxaX0K58PmUy03m3eLLpm5pp1yspKdMl8/nlgxw7xl/2PPwCl0hzVJSILJHtGv62ZM2di1qxZRT73pk2b0Lt37yIdT1QRJSUB588Dv/4qkrNTp3LvI5OJRO+NN8QtF/wmosIya3K3cOFCjBo1CqGhoQCApUuXYuvWrVi5ciUmT56ca/+VK1fiwYMH2L9/P6ytrQEAfn5+pVnlAsuZ3BnVqhXw119Az57A1q3AgAFiqivtQjJERCXo3r17uvvr1q3DjBkzEB0drStzdHQ0R7UqrCVLlmDevHmIjY1FQEAAFi9ejNatWxvdV6VSITw8HD/99BPu3LmD+vXr44svvkD37t1LudZUHGfPisv6oUNAQoJI5tRq/fOOjmLYvZcX4O4uFv9u3x6oUsV8dSai8s9syV1WVhaOHTuGKVOm6MrkcjlCQkJw4MABo8ds2bIFwcHBGDduHP78809UrVoVQ4YMwaRJk6DIY9bJzMxMZObo9piUlARAXDxVxuYLLgDtcfkd37KlDIAVDh6UoFJlG9/puecg27QJij59INuyBZoBA6D+9VcxOrqcKEgsLAVjoWdpsVCpVJAkCRqNBhqNxuA5SZJ0t08/Z045e0c4OTlBJpMZlC1fvhxffvklrl+/Dj8/P7z99tsYM2YMAPH3+7333sPGjRvx8OFDeHh44M0338TkyZNRq1YtAECfPn0AADVq1MC1a9cAFDwWGo0GkiRBpVIZ/G0vr5+nwvZSmTZtGn755RcsW7YMDRo0wI4dO9CnTx/s378fzZs3N8M7oILatAlYtEgsafvoUe7nXVzEWLlu3YCXXhJJHRGRKZktuUtMTIRarYaHh4dBuYeHBy5evGj0mGvXrmH37t0YOnQotm3bhitXrmDs2LFQqVSYOXOm0WPCw8Mxe/bsXOU7d+6EvcFMJ4UXERGR53MZGQrI5T1w544cP/+8G25uGXnuW3XSJAR99hkUf/6J2JAQHH3vPUhW5Wuum/xiYWkYCz1LiYWVlRU8PT2RkpKCrKwsUShJBtPaJaemlk5l7O0LPVVeRkYGJEnS/fj1+++/Y+bMmZg7dy78/f1x+vRpTJgwAXK5HIMHD8bixYvx559/YsWKFahWrRru3LmDO3fuICkpCbt27ULdunWxZMkSdO7cGQqFQndereTk5Hzrk5WVhfT0dOzduxfZ2fofx9KeniawnChsL5XVq1dj6tSp6NGjBwBgzJgx2LVrFxYsWIBffvmlVOtOBRMbCyxYAMyfry+TycSYuB49xLi4+vXFuDrOZElEJalcZRAajQbu7u744YcfoFAoEBgYiDt37mDevHl5JndTpkxBWFiY7nFSUhJ8fX3RtWtXOBexM7tKpUJERAS6dOmi6x5qjL+/DCdPAvb2ndGjh5T3CXv0gBQYCKl/f3gfOIAX166F+uefxdi8Mq6gsbAEjIWepcUiIyMDt27dgqOjI2xtbUVhairk1aqVel00SUliteJCsLW1hUwm0/1NnDt3LubPn4/BgwcDAJo2bYobN25g9erVePPNNxEfH4/69eujW7dukMlkaNKkie5c2nN4enqibt26Bq8jSRKSk5N1LYV5ycjIgJ2dHTp06KCPJ5ArSSwPitJLJTMz0+B9A4CdnR327duX5+uYq5eKpTAWi7Q0YPlyOQ4elGHjRhk0GvGZfvVVDd58U4M6daRcXSyz8+jIU57wc6HHWOgxFnrFjUVxY2i27MHNzQ0KhQJxcXEG5XFxcfD09DR6jJeXF6ytrQ266TRs2BCxsbHIysqCjZHxakqlEkojE5VYW1sX+0vns84RFAScPAmcPGmFJ9+R8tarl5hUpW9fyDdsgNzaGignCR5gmnhWFIyFnqXEQq1WQyaTQS6XQ65dKdhMKwbL5fJCv7a2znK5HKmpqbh69SpGjRqFN998U7dPdnY2KlWqBLlcjtDQUHTp0gUNGzZE9+7d8eKLL6Jr1665zil/qh7arpjaWOVXH5lMluvzUx4/S0XppdKtWzcsXLgQHTp0QO3atREZGYmNGzdCnXPA1lPM1UvF0kRERODBAyUiI6tjw4Z6yMzUfx/x9U3CK69cQocOd3D/PnD/vhkrWgr4udBjLPQYC72ixqK4vVTMljnY2NggMDAQkZGRuhnVNBoNIiMjMX78eKPHtGvXDr/++is0Go3ui8GlS5fg5eVlNLEzt5Ytge+/F+uVF8iLLwIbNgD9+4tFbuRy4KefgDzGExJRGWZvD6SkQKPRICkpCc7OzvkmNCZ93WJISUkBACxbtgxBQUEGz2l/WGvRogWuX7+Ov//+G7t27cKAAQMQEhKCDRs2FOu1Sfjqq68watQoNGjQADKZDLVr10ZoaChWrlyZ5zHm7KViCTIyVPjyy5OIjW2FDRuskJAgWumUSgmDB0sYPFiDTp3sAAQ82Soufi70GAs9xkKvuLEobi8VszYLhYWFYfjw4WjZsiVat26NRYsWITU1VTcuYdiwYfDx8UF4eDgAMe7gm2++wYQJE/D222/j8uXL+Oyzz/DOO++Y823kKTBQ3B47JobfFKif/UsvAb//DrzyCrBmjUjsVq5kgkdU3shkonukRiOmyHNwMFtrXmF4eHjA29sb165dw9ChQ/Pcz9nZGQMHDsTAgQPRv39/dO/eHQ8ePEDlypVhbW2dbyuTJSlKL5WqVati8+bNyMjIwP379+Ht7W0wWY0x5uylUpElJAATJgB//22FR4/a6spr1wZGjQLeekuGSpVkKAPLBpc6S/5cPI2x0GMs9Ioai+LGz6zJ3cCBA5GQkIAZM2YgNjYWzZo1w/bt23XdV2JiYgx+6fb19cWOHTvw7rvvwt/fHz4+PpgwYQImTZpkrreQr8aNxcoGjx4B166Ji0GB9O4tVisdOFB0zQSA774r9i/yREQFMXv2bLzzzjuoVKkSunfvjszMTBw9ehQPHz5EWFgYFi5cCC8vLzRv3hxyuRzr16+Hp6enbs1RPz8/REZGol27dlAqlXB1dTXvGzKjovRS0bK1tYWPjw9UKhX++OMPDBgwoBRqTFoZGWJmy9OnAUAGe3sVXnpJgfbt5Xj9deCpYZFERGWC2Qd0jR8/Ps8LXFRUVK6y4OBgHMxz8biyxcYGCAgAjhwBjh4tRHIHiIXNf/0VGDJEJHj//gt8+y3AdY6IqIS98cYbsLe3x7x58/DBBx/AwcEBTZs2xcSJEwGIpRPmzp2Ly5cvQ6FQoFWrVti2bZvux7gFCxYgLCwMy5Ytg4+PD27cuGG+N1MGFLaXyqFDh3Dnzh00a9YMd+7cwaxZs6DRaPDhhx+a821YlFOnRIudSOyAr75Sw8fnb7z00guwtra8VjoiKj/MntxVdIGBIrk7ckQ0xBXKgAGAszMwejRw/TrwwgviJF9+KVY9JSIygREjRmDEiBEGZUOGDMGQIUOM7j9q1CiMGjUqz/P16tULvXr1MmUVy7XC9lLJyMjAtGnTcO3aNTg6OqJHjx5YvXq1rmWUSkZaGjB1KrB9O6Cd68bOTqxd97//abBtWz6zXhMRlRFM7kpYcDCwdKloeCuS7t2B8+eBmTPFyqjr1okrz+efi6SvHIzhISKydIXppfL888/j/PnzpVArAoALF8RcZmvXisutVr9+wNy5QK1aAGd3J6LygplBCXv+eXF77BjwjHV78+boKFZHPXJETMH5+DEwZgzQrh1w5ozJ6kpERGQpoqOBiRMBf39gxgyR2Hl4ACtWiHHyGzaIxI6IqDxhclfCatQA/PzEZHn79xfzZC1aAAcPAl9/DTg5ifvNmwOTJgGpqaaoLhERUYV24gTQqRPQoAHw1VdiYfEOHUQHmVOngJEjgZo1zV1LIqKiYXJXCjp2FLdG5ocpPIUCePtt8RNj374ia5w7F2jSBPj7bxO8ABERUcWj0QDz5gFBQfrrccuWwF9/AXv2ALNmiZY7IqLyjMldKTBpcqdVrRrwxx/Ali1A9erAjRtAjx5iwpV790z4QkRUUJLECRdMgXEkU/vnH6BZM+DDD8X4uT59gMuXxWiHnj3NXTsiItNhclcKtOPujhwBUlJMfPJevYBz54D33hOter//LvqaLFkiFukhohKnXXA0LS3NzDWpGLRx5EK4VFwaDbB4MdClixii7uAA/PCD+G20Th1z146IyPQ4W2Yp8PMT240bwH//Ad26mfgFHB2B+fOBV18F3nwTOHwYGD8emDZNtOSNGCH6ochkJn5hIgIAhUIBFxcXxMfHAwDs7e0he/L/TaPRICsrCxkZGQbT3VuiZ8VCkiSkpaUhPj4eLi4uUCgUZqglVQTZ2cDChcDKlWLiFAAYPFj87unqat66ERGVJCZ3paRTJ+DHH4GIiBJI7rSaNROztixdKsbhxcQA338vtvr1RZL32muAj08JVYDIcnl6egKALsHTkiQJ6enpsLOz0yV8lqqgsXBxcdHFk6iwHj4Uy8Tu2iUey+XAlCnAnDlcPYiIKj4md6XkhRdEcrdtm2hkKzEKBTBunFgqISoKWLVK9D+JjhZXt48+Ev1TRowAevcWK7QSUbHJZDJ4eXnB3d0dqhyLYqlUKuzduxcdOnSw+G6GBYmFtbU1W+yoSPbvF5e4PXvEY3t7MWJh1CjA19e8dSMiKi1M7kpJly4i77pwAbh+vRSmWZbLgf/9T2xLlogFe1atAvbuBXbuFJuzs77bZnAwu20SmYBCoTBIThQKBbKzs2Fra2vxyR1jQSUhKQn45BOxHKxGI8p8fcV8Y82ambVqRESljh0USomLC9C+vbj/f/9Xyi/u5ASEhoqfM69cEau1+vmJK+KyZWIx9Pr1gc8+A27dKuXKEZHFkCTIcrRqEhWHJInZL2vUEEscaDQiqRs9WkxgxsSOiCwRW+5K0Usvifzqzz+Bd94xUyVq1wZmzxarte7dK1rzNmwQc0JPnSomYencWbTm9ekj+rUQERmj0YgBTomJQEKC/jbnlqPMKiEBbWvXBl5+2dw1p3LuzBng00+BdevE4zp1xJAHfrSIyNIxuStFL70k+v/v2SO+D5l1xi65XCzA17Ej8M03YlzeqlVinN6uXWJzchLPt24ttpYtgcqVzVhpIioxGg3w6JFIxu7fF7fa7enH2rIHD/T94ApABsAmKanE3gJVfA8fAkOHAtu3i5Y7QEwS/c03gBW/0RARMbkrTXXqAE2aAGfPAn/9JSauLBMcHYHhw8V2/TqwerVI9K5fF31Ic/YjrVMHaNVKn/A1aWK2ahNRHjQa4PHjvJMzY4/v3y9UombAyQmoWtVwc3PLVaaqVAn/njiBrqZ9t2QB0tPFenWTJunL2rYVj196yXz1IiIqa5jclbLevUVyt2lTGUrucqpZU4zJmzZNDFo4eFDcHj4sum5euSK2334DAFgpFHi+enUo/u//gDZtROLXuDF/QiUyBUkCUlNFC9mDB6LZQntf+1ibmD2dqKnVRXtNJyeRmGm3KlXyf1y5MmBjU7Bzq1TIvnixaPUii5WaCjRtKn5v1PrtN2DQIPPViYiorOI38FLWr5+Y1WvrVvHdrMz2cpTLxcLnQUH6socPgaNHRaL3ZJPFxsLl+nVgxQqxAWJ5hcBAwxa+mjU5GydZLJlaLRKv5OS8k7S8Erjs7KK/sKNj/onZ02VVqhQ8USMqBfHxQNeu+sQuKEhMnvLcc+atFxFRWcXkrpQ1aya2kyeBNWuAt982c4UKw9VVrOnQpYt4LElQ3biBE99/j0CNBopjx0QrX3IysG+f2LSqVBHJXqtWIgC+vkC1aoC7u1gjgqisy8oSXR1zbo8e5Z+YPXwIqwcP8FJxx5nZ2Ihfglxdxa120z7OK1FTKk3y1onMYedOoGdP8fuGm5sYVzdwoLlrRURUtjG5M4ORI8VsmStXlrPk7mkyGVCtGu4FB0PTowcU1tZizM6lS/rWvSNHRCZ7/74YAb99u+E5FArA21skesY2Hx/xPNfEoqKSJCAjwzApS0rKnajltWn3zcgo0ssbtFc7O+dOzPJL2rT37e3Z8k0WIzMT+OILMakzIC4F//d/XNqAiKggmNyZwdChwPvvi5zn+HGgRQtz18iE5HKgQQOxDRsmyjIzxbzV2oTv4kXgzh3g7l0xLujWrfzX15PJAA8P44lfzvt2dqXzHqnkSRKQliYG22i3lJTcj/NKxJ7eTLm2mqMjUKmSfqtSJe9EzdUVKicn7Dp+HCH9+8Oan1GifMXGArVqiQlUADGUe/du/nknIiooJndmULmyWEJu3TrRelehkjtjlEqxjELLlsDYsfry7GwgLg64fTv3dueO/r5KJa74sbFizF9eqlTRJ3seHuJLuIODuM3r/tNlHG9UcNoWMSMJmOzxY3j/9x9k8fHiW1p+SZqxsrQ0/TznpiKTiclCciZmz9qcnXM/Lmw3YpUKWVeucJIhomc4fx7o0UOf2Pn7A1u2MLEjIiqMMvFtY8mSJZg3bx5iY2MREBCAxYsXo3Xr1kb3XbVqFUJDQw3KlEolMorYZcpcXn9dJHdr1ojB4RZ58bKyEi1uPj6GE7fkpNGIiSjySvy0W1qafpbAU6eKXidr6/yTv7ySQ6USMrUaPqdOQZaUJM4jkxlucnnuMmNbQfbT7qNWi7FgObfMzNxlz9qKckxGRp5T51sBaFX0fwVDdnaG8c65FSZRc3QUcSOiMufRIzGc++5dMf/WV18BvXqZu1ZEROWP2ZO7devWISwsDEuXLkVQUBAWLVqEbt26ITo6Gu7u7kaPcXZ2RnR0tO6xrByORencGaheHYiJATZvBgYPNneNyii5XEy64u6edxOnJIlvBjmTvvh4wxahlBTD+0+XZWWJc6lUYlKMhw8LXVUrAC2L/EbLOVtbg6RLY2+P+5mZqFK9OuQ5kzJjCVp+Zfb2TMiILMCrr4rEztcX+Pdf8ZsfEREVntmTu4ULF2LUqFG61rilS5di69atWLlyJSZPnmz0GJlMBk9Pz9KspsnJ5UBoKDB7tlhBgMldMchkYpyTq2vRF1VXqQqWBBp7PjkZyMqCRqPB/YQEVKlSBXJAJJ1PbxqN8fKi7KfRiNZPG5v8N6Xy2fsU5VilUp+MPdVVUa1SYf+2bejRowfknAyHyiE/Pz+MHDkSI0aMQPXq1c1dnQpt926xPBAAfPYZEzsiouIwa3KXlZWFY8eOYcqUKboyuVyOkJAQHDhwIM/jUlJSUKNGDWg0GrRo0QKfffYZGjdubHTfzMxMZGZm6h4nPZmSXKVSQVXESRa0xxX1eK2hQ4E5c6wQGSnD5csq+PkV63RmYapYlAnaRMXDo0iHq1Qq7I+IQJcuXWBtSQmNRpOre2aF+lwUE2OhV9xYlGYMJ06ciFWrVmHOnDno1KkTXn/9dfTp0wdKLi9hclOnituOHcV1kYiIis6syV1iYiLUajU8nvoy7eHhgYsXLxo9pn79+li5ciX8/f3x+PFjzJ8/H23btsW5c+dQrVq1XPuHh4dj9uzZucp37twJe3v7YtU/IiKiWMcDgL9/ME6dcseUKdfx2msXin0+czFFLCoKxkKPsdBjLPSKGou0tDQT1yRvEydOxMSJE3H8+HGsWrUKb7/9NsaOHYshQ4Zg5MiRaFHhZ8IqHRs2AAcPivuLF3PFDyKi4jJ7t8zCCg4ORnBwsO5x27Zt0bBhQ3z//ff4+OOPc+0/ZcoUhIWF6R4nJSXB19cXXbt2hbOzc5HqoFKpEGGiFhqVSoZXXgF2766L5ctrwsGhWKcrdaaMRXnHWOgxFnqMhV5xY5FU3MXgi6BFixZo0aIFFixYgG+//RaTJk3Cd999h6ZNm+Kdd95BaGhouRz3XRZcvgy88oq4P2pU0XvVExGRnlmTOzc3NygUCsTFxRmUx8XFFXhMnbW1NZo3b44rV64YfV6pVBrtRmNtbV3sL1qmOEefPmJNn2vXZPjtN2uMGVOs05mNKWJRUTAWeoyFHmOhV9RYmCN+KpUKmzZtwo8//oiIiAi0adMGr7/+Om7fvo2PPvoIu3btwq+//lrq9Srv7t4FRowQ9+Vy4OuvzVodIqIKw6zT0NnY2CAwMBCRkZG6Mo1Gg8jISIPWufyo1WqcOXMGXl5eJVXNEqVQABMnivtffpnnzPJERFSKjh8/jrfffhteXl4YP348GjdujLNnz2Lfvn0IDQ3F9OnTsWvXLmzatMncVS13JEkse7B/v3j8yy9iwl0iIio+s88xHhYWhmXLluGnn37ChQsXMGbMGKSmpupmzxw2bJjBhCtz5szBzp07ce3aNRw/fhyvvvoqbt68iTfeeMNcb6HYQkPFMlyXLwP8nkBEZH6tWrXC5cuX8d133+HOnTuYP38+GjRoYLBPzZo1MWjQIDPVsPyKjBQLlgPArl2cLZqIyJTMPuZu4MCBSEhIwIwZMxAbG4tmzZph+/btuklWYmJiIM+xztXDhw8xatQoxMbGwtXVFYGBgdi/fz8aNWpkrrdQbI6OwNtvA598AsyZI7pqcmkvIiLzuXbtGmrUqJHvPg4ODvjxxx9LqUYVQ2amaLUDgDfeEGu+EhGR6ZSJFGL8+PG4efMmMjMzcejQIQQFBemei4qKwqpVq3SPv/zyS92+sbGx2Lp1K5o3b26GWpvWu+8CTk7A6dPAli3mrg0RkWWLj4/HoUOHcpUfOnQIR48eLfT5lixZAj8/P9ja2iIoKAiHDx/Od/9Fixahfv36sLOzg6+vL959911kZGQU+nXLmh9+ELdWVoCROdCIiKiYykRyR0DlyqL1DhALm3PsHRGR+YwbNw63bt3KVX7nzh2MGzeuUOdat24dwsLCMHPmTBw/fhwBAQHo1q0b4uPjje7/66+/YvLkyZg5cyYuXLiAFStWYN26dfjoo4+K9F7KitRU4PPPxf133gEKOG8aEREVApO7MkTbenfyJLB+vblrQ0Rkuc6fP290LbvmzZvjvHbAWAEtXLgQo0aNQmhoKBo1aoSlS5fC3t4eK1euNLr//v370a5dOwwZMgR+fn7o2rUrBg8e/MzWvrLuhRfELJl+fsCnn5q7NkREFZPZx9yRnpsb8P77wMyZwLRpQN++AGdOJyIqfUqlEnFxcahVq5ZB+b1792BlVfBLZ1ZWFo4dO2YwMZhcLkdISAgOHDhg9Ji2bdvil19+weHDh9G6dWtcu3YN27Ztw2uvvZbn62RmZiIzM1P3WLsmoEqlgkqlKnB9c9IeV9Tjc/rtNxn+/VfEberUbCgUEkxw2lJjyliUd4yFHmOhx1joFTcWxY0hk7sy5t13gW++Aa5cAVauBN5809w1IiKyPF27dsWUKVPw559/olKlSgCAR48e4aOPPkIX7YwgBZCYmAi1Wq2bJEzLw8MDFy9eNHrMkCFDkJiYiPbt20OSJGRnZ+Ott97Kt1tmeHg4Zs+enat8586dsLe3L3B9jYmIiCjW8Y8f22D48Bd0jytX3oZt26RindNcihuLioSx0GMs9BgLvaLGIi0trVivy+SujHFyEq12EyaImTOHDhWzaRIRUemZP38+OnTogBo1augm7Tp58iQ8PDywevXqEn3tqKgofPbZZ/j2228RFBSEK1euYMKECfj4448xffp0o8dMmTIFYWFhusdJSUnw9fVF165d4ezsXKR6qFQqREREoEuXLsVaQP7TT/UjQOLiVHB1fSGfvcsmU8WiImAs9BgLPcZCr7ix0Pa8KComd2XQm28CixYB16+LcQnh4eauERGRZfHx8cHp06exZs0anDp1CnZ2dggNDcXgwYMLdbF2c3ODQqFAXFycQXlcXBw885hRZPr06Xjttdd067c2bdoUqampGD16NKZOnWqwPJCWUqmEUqnMVW5tbV3sL1rFOUd6un6GzDffBNzdy/eXPlPEs6JgLPQYCz3GQq+osShu/JjclUFKJfDll0Dv3sCCBcDIkUDduuauFRGRZXFwcMDo0aOLdQ4bGxsEBgYiMjISvXv3BgBoNBpERkZi/PjxRo9JS0vLlcApFAoAgCSVr+6MkyYB9+4BVavyh0oiotLA5K6MeukloFs3YMcO0UVz61ZAJjN3rYiILMv58+cRExODrKwsg/KXXnqpwOcICwvD8OHD0bJlS7Ru3RqLFi1CamoqQkNDAQDDhg2Dj48Pwp9kP7169cLChQvRvHlzXbfM6dOno1evXrokrzxITATWrBH333oLcHU1b32IiCwBk7sySiYDvvoKaNoU+PtvYPNmoE8fc9eKiMgyXLt2DX369MGZM2cgk8l0LWayJ7+yqdXqAp9r4MCBSEhIwIwZMxAbG4tmzZph+/btuklWYmJiDFrqpk2bBplMhmnTpuHOnTuoWrUqevXqhU/L2foB8+YBDx4ADRsCeQwVJCIiEyvSOne3bt3C7du3dY8PHz6MiRMn4gdtx3oyifr1gQ8+EPfHjwcePTJrdYiILMaECRNQs2ZNxMfHw97eHufOncPevXvRsmVLREVFFfp848ePx82bN5GZmYlDhw4hKChI91xUVBRWrVqle2xlZYWZM2fiypUrSE9PR0xMDJYsWQIXF5fiv7FStG+fuH33XS7rQ0RUWoqU3A0ZMgT//PMPACA2NhZdunTB4cOHMXXqVMyZM8ekFbR0U6eK8XZ37wLvvWfu2hARWYYDBw5gzpw5cHNzg1wuh1wuR/v27REeHo533nnH3NUr8xITgYMHxf22bc1bFyIiS1Kkbplnz55F69atAQC///47mjRpgv/++w87d+7EW2+9hRkzZpi0kpbM3l6sd9ehg7gdMECMxSMiopKjVqvh5OQEQMx4effuXdSvXx81atRAdHS0mWtX9r34IqDRAE2aAI0bm7s2RE9IEqBSAVlZ4tbYlt9zT23yjAzUPHkS8suXxQe+gMcValMqxYBVFxf9bc77xsoqVQKsOPLKUhXpX16lUummXN61a5duYHmDBg1w794909WOAADt2wPvvCPG4I0eDZw9K9bDIyKiktGkSROcOnUKNWvWRFBQEObOnQsbGxv88MMPqFWrlrmrV6bt3g0cOiTujxpl3rpQKdJogMzM3FtGRvHKsrLyTrgKm6QVYqxsQSgA+Jv0jCbk5JR38ves5NDRkbP4lWNFSu4aN26MpUuXomfPnoiIiMDHH38MALh79y6qVKli0gqS8OmnwJYtYu27997TrxtERESmN23aNKSmpgIA5syZgxdffBHPPfccqlSpgnXr1pm5dmXbsmX6+2+/bb56UBFlZgI3b4ovHDduiNvr14Hbt4G0NFhlZCDk4UNYKRSGiZhKZe6aF42VlRgUmnOzscldZmTTKBS4l5gIr+rVIVcqC3RMobeMDDHpwqNHwMOHhrfGylJSxPtKThbbrVuFj4lCoU/4XFwAOzvRgmhjk+et3MoKDWJiID91qkD7P/NWuzHJLLQiJXdffPEF+vTpg3nz5mH48OEICAgAAGzZskXXXZNMy8EBWL4cCAkRF85OnYDBg81dKyKiiqlbjv7vderUwcWLF/HgwQO4urrqZsyk3CQJ2LNH3N+7l9/LyqTsbJGo5UzctNuNG2KQfz7rKcoAOBTkdZRKw83WNv/HeZVpv+znlfwU5zkrq2J9SNUqFY5u24YePXpAXlZmDVKpgMePC54MPl2mbeG8f19sBaQAUN/070b8W+WVOBtLzI2VmapcoSjQ50WWnQ1lcnJJRKNAipTcdezYEYmJiUhKSoJrjoVrRo8eDXt7e5NVjgz973/AtGnAxx8DY8YAbdoANWuau1ZERBWLSqWCnZ0dTp48iSZNmujKK1eubMZalQ+3b4tFyxUKIDDQ3LWxUBoNEBubO3nTPr51SyR4+bG3F18watYE/PzEbfXqgJMTshUK7D92DMGdOsHawcF4QsYWF/Oxtgbc3MRWWJIEpKfnTv60XWazsvK8Vaen4+bly/Dz9IQ8O/uZ++f53NNdZ7VdassRKwAu06aZ9fULLT09HZIk6RK7mzdvYtOmTWjYsKHBr51kejNmABERYhayV14RU03b2pq7VkREFYe1tTWqV69eqLXsSNDOkBkQIPIDKiFJScDly8C1a7m7T964Ib4k58fGBqhRQ5+4PZ3IVa2aZ3ImqVR4mJoKNG/ONS4qGplM/Me1twe8vQt1qEalwplt2+Bb3FZMtdp48mdsXGV2dsHKTFVewGuCRpKgcihQ+3aJKFJy9/LLL6Nv375466238OjRIwQFBcHa2hqJiYlYuHAhxowZY+p60hNWVsC6deJv6rFjwLhxorsmfyAjIjKdqVOn4qOPPsLq1avZYlcI2uSuTRvz1qNCUKlEsnbpEhAdrb+NjhYtc/mRy4Fq1YwnbjVrii/u8iKthkVUshQKMWbPzs7cNSkytUqFB9u2me31i5TcHT9+HF9++SUAYMOGDfDw8MCJEyfwxx9/YMaMGUzuSlj16sDatUD37mJ5hMBAYOxYc9eKiKji+Oabb3DlyhV4e3ujRo0acHjqV9jjx4+bqWZl2/ffi1smdwUkSUB8vD5py5nIXb2af/dJd3egdu3crW81awK+vmxVI7JQRUru0tLSdOv/7Ny5E3379oVcLkebNm1w8+ZNk1aQjOvSBQgPByZNAiZMAPz9xZIJRERUfL179zZ3Fcqde/eAJxOMMrl7Wlqa6EZpLIl7/Djv4+zsgHr1xFa/vuGti0upVZ+Iyo8iJXd16tTB5s2b0adPH+zYsQPvvvsuACA+Ph7Ozs6FPt+SJUswb948xMbGIiAgAIsXLy7QrJtr167F4MGD8fLLL2Pz5s2Fft3y7oMPgOPHRTfN/v2Bo0dFLwwiIiqemTNnmrsK5c7Jk/r7deqYrRrmd+cO8OefwLlz+gQuv+noZTIx/q1+/dwJXLVq7D5JRIVSpORuxowZGDJkCN59913873//Q3BwMADRite8efNCnWvdunUICwvD0qVLERQUhEWLFqFbt26Ijo6Gu7t7nsfduHED77//Pp577rmivIUKQSYDVqwALlwATp8G+vYF/vlHLJtARERUmlasELeNGlngOPAHD4A//gB+/VWsBWFsKYHKlQ2TN+39OnU4MxoRmUyRkrv+/fujffv2uHfvnm6NOwDo3Lkz+vTpU6hzLVy4EKNGjUJoaCgAYOnSpdi6dStWrlyJyZMnGz1GrVZj6NChmD17Nv799188evSoKG+jQnBwADZtAlq1Ao4cAfr0EYud8zpBRFR0crk83/XsOJNmbllZ4tZi5p9JSwP+7/9EQvf334bTtbdvL7acrXBFmZqeiKiQipTcAYCnpyc8PT1x+/ZtAEC1atUKvYB5VlYWjh07hilTpujK5HI5QkJCcODAgTyPmzNnDtzd3fH666/j33//zfc1MjMzkZljSuCkpCQAYh0jVRHXzdAeV9TjTc3XF/jzTxm6d1cgIkKGV17RYN06damMpS5rsTAnxkKPsdBjLPSKG4vSjOGmTZtyvfaJEyfw008/Yfbs2aVWj/IkOlrc5rikVzwqFRAZCaxZA2zeDKSk6J8LCACGDAEGDRIznxERmUGRkjuNRoNPPvkECxYsQMqTP2xOTk547733MHXqVMgL2D88MTERarUaHh4eBuUeHh64ePGi0WP27duHFStW4GTOzv35CA8PN3oh3rlzZ7EXXI+IiCjW8aY2eXIVfPxxMP76S4Hu3e9i4sRjUChK57XLWizMibHQYyz0GAu9osYiLS3NxDXJ28svv5yrrH///mjcuDHWrVuH119/vdTqUh7cuCGGlslkwJORGhWHJEF24ACa/vADrEaNAhIS9M/VrCkSusGDgcaNzVdHIqInipTcTZ06FStWrMDnn3+Odu3aARBJ16xZs5CRkYFPP/3UpJXUSk5OxmuvvYZly5bBrYDdG6ZMmYKwsDDd46SkJPj6+qJr165FmvwFEL/gRkREoEuXLrAuQ1MN9+gB+PtL6N9fwr//VkPt2t5YulRdomOxy2oszIGx0GMs9BgLveLGQtvzwpzatGmD0aNHm7saZY7299YmTQBXV7NWxXTOnhVdLn/7DVY3bqCWtrxqVWDgQGDoUCAoyAIHGBJRWVak5O6nn37C8uXL8dJLL+nK/P394ePjg7FjxxY4uXNzc4NCoUBcXJxBeVxcHDw9PXPtf/XqVdy4cQO9evXSlWk0GvFGrKwQHR2N2rVrGxyjVCqhVCpzncva2rrYX7RMcQ5Te+klcS0aOBBYtUoOZ2c5Fi0q+WtPWYyFuTAWeoyFHmOhV9RYmDt+6enp+Prrr+Hj42PWepRF2skg69Uzbz2K7eZN4LffxIX0zBldseToiFutWsH7vfdg1a0bYFXkUS1ERCWqSH+dHjx4gAYNGuQqb9CgAR48eFDg89jY2CAwMBCRkZG6NYU0Gg0iIyMxfvx4o+c/k+OPLQBMmzYNycnJ+Oqrr+Dr61u4N1JB9e8P/PgjMHw48PXXgKMjUEKNqUREFZKrq6vBhCqSJCE5ORn29vb45ZdfzFizsikmRtyWy8twQgKwfr1I6P77T19uYyO6xAwZguxu3XDin3/g1bUrEzsiKtOK9BcqICAA33zzDb7++muD8m+++Qb+/v6FOldYWBiGDx+Oli1bonXr1li0aBFSU1N1s2cOGzYMPj4+CA8Ph62tLZo0aWJwvMuTRTyfLrd0w4aJxWTHjgU++0zMqvnRR+auFRFR+fDll18aJHdyuRxVq1ZFUFAQXCtMv0PT0bbclZvkLj1drEW3ejWwYwegnf1UJgM6dRLj6Pr21fcx5YRIRFROFCm5mzt3Lnr27Ildu3bp1rg7cOAAbt26hW3bthXqXAMHDkRCQgJmzJiB2NhYNGvWDNu3b9dNshITE1PgCVrI0JgxIsH74ANg6lRxzZo8mcMDiIieZcSIEeauQrlSLpI7jUasQbd6NbBhA5CcrH+uZUuR0A0YALDbLRGVY0VK7p5//nlcunQJS5Ys0c1q2bdvX4wePRqffPJJoRcWHz9+vNFumAAQFRWV77GrVq0q1GtZmvffFwnerFmi5S4xEZg3DyU6yQoRUXn3448/wtHREa+88opB+fr165GWlobhw4ebqWZlU5lO7s6dEwndmjXAk+WbAAB+fsCrr4qtfn2zVY+IyJSK3HHc29s718Qpp06dwooVK/DDDz8Uu2JkOjNnAk5OwHvvAQsXigRv+XKUyjp4RETlUXh4OL7//vtc5e7u7hg9ejSTuxzUauDuXXG/zCR3sbFiYpTVq4ETJ/TlLi6ide6114C2bflLJxFVOBwVbCHCwgA3N2DkSODnn4EHD4B164BiLvVHRFQhxcTEoGbNmrnKa9SogRjt7CEEQCR2arWYZ8TIRNelJzVVLCy+ejUQESG6YQLil8wePURC17MnYGtrxkoSEZUsJncWZNgwMTZ8wADgr7+Arl3FePIqVcxdMyKissXd3R2nT5+Gn5+fQfmpU6dQhX80DURHi9tatQCFopRfXK0G/vlHJHQbNwIpKfrngoNFQjdgAC90RGQxmNxZmF69xA+aL74oZnwOChKJnpGVLYiILNbgwYPxzjvvwMnJCR06dAAA7NmzBxMmTMCgQYPMXLuy5cIFcduwYSm9oEYDHDwokrnfftP3CQWA2rX14+jq1CmlChERlR2FSu769u2b7/OPHj0qTl2olLRvLxK7F18Erl4F2rQRXTS7dTN3zYiIyoaPP/4YN27cQOfOnWH1ZF0zjUaDYcOG4bPPPjNz7cqWUknusrKAqChg0ybR9TI2Vv9c5crAwIEioQsO5pTQRGTRCpXcVapU6ZnPDxs2rFgVotLRuDFw6JBYxue//4AXXgDmzBEzanJ8ORFZOhsbG6xbtw6ffPIJTp48CTs7OzRt2hQ1atQwd9XKnIgIcWvyCSdTU4Ht20VC99dfwOPH+uecncUvlK+8IsbT2diY+MWJiMqnQiV3P/74Y0nVg8zA3R2IjATefhtYtgyYPl0kfD//rF+3lYjIktWtWxd169Y1dzXKrLg44MoVcb9ePROc8MED4P/+T3S53LkTyMjQP+fhAbz8MtCnD/C//zGhIyIygm00Fk6pBH74AVi5Utz/6y+xluvJk+auGRGR+fTr1w9ffPFFrvK5c+fmWvvOkh0/rr8fFFTEk6hUwNKlQOfO4lfHESOALVtEYlerlljHZ98+4M4d4Pvvge7dmdgREeWByR0BAEJDgf37xZqu166JYQurVgGSZO6aERGVvr1796JHjx65yl944QXs3bu30OdbsmQJ/Pz8YGtri6CgIBw+fDjPfTt27AiZTJZr69mzZ6Fft6RpZ8rs16+IM2VKEvD668CYMcDu3WL2S39/sUDryZOiWXD+fKBdOzNMxUlEVP4wuSOdFi2AY8fE8IWMDJHwDR1qOMyBiMgSpKSkwMZI65C1tTWSkpIKda5169YhLCwMM2fOxPHjxxEQEIBu3bohPj7e6P4bN27EvXv3dNvZs2ehUCjKZIuhNrkr8ni7RYvEMgYKBRAeLmb5OnUKmDULCAjg5ChERIXE5I4MVK4shjt8+qm41v72G9CsGXDggLlrRkRUepo2bYp169blKl+7di0aNWpUqHMtXLgQo0aNQmhoKBo1aoSlS5fC3t4eK1euNLp/5cqV4enpqdsiIiJgb29f8ZK7iAjg/ffF/QULgMmTRTdMIiIqMq5zR7nI5WLWzE6dgCFDgBs3xPIJ774rZtS0tzd3DYmIStb06dPRt29fXL16Ff/73/8AAJGRkfj111+xYcOGAp8nKysLx44dw5QpU3RlcrkcISEhOFDAX81WrFiBQYMGwcHBIc99MjMzkZmZqXusbV1UqVRQqVQFrm9O2uPyOz462gqADLVrZ0OlKkQ//qtXYTVwIGQaDTTDhkE9ZowYe1dGFSQWloKx0GMs9BgLveLGorgxZHJHeQoOFkMexo8HfvlF/LC6eTOwfDnQsaOZK0dEVIJ69eqFzZs347PPPsOGDRtgZ2eHgIAA7N69G5UrVy7weRITE6FWq+Hh4WFQ7uHhgYsXLz7z+MOHD+Ps2bNYsWJFvvuFh4dj9uzZucp37twJ+2L+IhehXevgKenpVrh7V4wDvHFjBxITswt0PkV6OjpMmgTnhw/xsG5d7HvxRWj+/rtYdSwtecXCEjEWeoyFHmOhV9RYpKWlFet1mdxRvipVEsMhBg0C3npLDIfo1AkYPRqYO5eteERUcfXs2VM3iUlSUhJ+++03vP/++zh27BjUanWp1GHFihVo2rQpWrdune9+U6ZMQVhYmO5xUlISfH190bVrVzg7OxfptVUqFSIiItClSxdYW1vnev7cOXHr6iphwICuBTupRgPFoEGQx8RA8vSEY0QEunt7F6l+pelZsbAkjIUeY6HHWOgVNxaFHdf9NCZ3VCA9e4oL+aRJYsbqH34Atm4FvvlGxvHuRFRh7d27FytWrMAff/wBb29v9O3bF0uWLCnw8W5ublAoFIiLizMoj4uLg6enZ77HpqamYu3atZgzZ84zX0epVEKpVOYqt7a2LvYXrbzOcfeuuPX2lhX8NT7+WHQBsbGBbONGWJezReFNEc+KgrHQYyz0GAu9osaiuPHjhCpUYM7OwHffAVFRQJ06YsmhPn2ssGBBIBISzF07IiLTiI2Nxeeff466devilVdegbOzMzIzM7F582Z8/vnnaNWqVYHPZWNjg8DAQERGRurKNBoNIiMjERwcnO+x69evR2ZmJl599dUiv5eSdPSouG3WrIAH/PknMGOGuP/dd6LvPxERmRSTOyq0558HTp8GPvwQkMsl/PtvNfj7W+HnnwGNxty1IyIqul69eqF+/fo4ffo0Fi1ahLt372Lx4sXFOmdYWBiWLVuGn376CRcuXMCYMWOQmpqK0NBQAMCwYcMMJlzRWrFiBXr37o0qVaoU6/VLyr//itsC5WjnzwPaJHX8eGDkyBKrFxGRJWO3TCoSOzvgiy+APn3UGDw4FTduVMLw4eLH2K+/BgrxwzYRUZnx999/45133sGYMWNQt25dk5xz4MCBSEhIwIwZMxAbG4tmzZph+/btuklWYmJiIJcb/tYaHR2Nffv2YefOnSapg6mpVPolctq3f8bODx8CL78MpKSI2bgWLizp6hERWSy23FGxBAZKmD9/Dz79VA0HB+DgQaB1a2DYMOD2bXPXjoiocPbt24fk5GQEBgYiKCgI33zzDRITE4t93vHjx+PmzZvIzMzEoUOHEBQUpHsuKioKq1atMti/fv36kCQJXbp0KfZrl4QrV4DUVMDREWjaNJ8d1Wpg8GBxQI0awO+/AxyPQ0RUYpjcUbFZWUn44AMNLl0CXntNlK1eDdSrB0yfDiQnm7d+REQF1aZNGyxbtgz37t3Dm2++ibVr18Lb2xsajQYRERFI5h80AEBsrLitVk2sjZqnqVOBHTtEd4/Nm4GqVUujekREFovJHZmMtzfw88/A4cOim056OvDJJ0DdusD335fp9WmJiAw4ODhg5MiR2LdvH86cOYP33nsPn3/+Odzd3fHSSy+Zu3pmp+2Z4eWVz0537wLz54v7P/5YiJlXiIioqMpEcrdkyRL4+fnB1tYWQUFBOHz4cJ77bty4ES1btoSLiwscHBzQrFkzrF69uhRrS8/SqhWwdy/wxx9A7dpAXJxYI69hQ2DNGtFLh4iovKhfvz7mzp2L27dv47fffjN3dcqEmzfFrZ9fPjv9+KP4g9++PTBwYGlUi4jI4pk9uVu3bh3CwsIwc+ZMHD9+HAEBAejWrRvi4+ON7l+5cmVMnToVBw4cwOnTpxEaGorQ0FDs2LGjlGtO+ZHJgL59xQRpixaJnjhXr4rJ0gICgE2bAEkydy2JiApOoVCgd+/e2LJli7mrYnba5C7PZeo0GmD5cnF/1KhSqRMREZWB5G7hwoUYNWoUQkND0ahRIyxduhT29vZYuXKl0f07duyIPn36oGHDhqhduzYmTJgAf39/7Nu3r5RrTgVhYwNMmABcuwZ8+ing4iIWQ+/bV0y88tdfTPKIiMobbbdMX988dti1C7hxA6hUCejfv7SqRURk8cy6FEJWVhaOHTtmsL6PXC5HSEgIDmjnWM6HJEnYvXs3oqOj8cUXXxjdJzMzE5mZmbrHSUlJAACVSgVVEQeBaY8r6vEVSUFjoVQCH3wgfsBduFCOxYvlOHpUhl69gIAACZMmqdGnjwSFojRqXTL4udBjLPQYC73ixoIxLDu0E4i6u+exw7Jl4va11wB7+1KpExERmTm5S0xMhFqt1q31o+Xh4YGLFy/medzjx4/h4+ODzMxMKBQKfPvtt3lOFx0eHo7Zs2fnKt+5cyfsi3nBiYiIKNbxFUlhYtGmDdCggQ02b66D7dtr4tQpKwwZYgUfn2T063cZHTrchpVV+W3O4+dCj7HQYyz0ihqLtLQ0E9eEikqb3Lm5GXkyLk7MjAmwSyYRUSkrl4uYOzk54eTJk0hJSUFkZCTCwsJQq1YtdOzYMde+U6ZMQVhYmO5xUlISfH190bVrVzg7Oxfp9VUqFSIiItClSxdYW/h6PcWJxZAhwIMHEr75Ro0lS+S4c8cJX3/dAlu2NMd772kwfLgGtrYlVPESwM+FHmOhx1joFTcW2p4XZH75Jnc//QRkZwNBQYC/f6nWi4jI0pk1uXNzc4NCoUBcXJxBeVxcHDw9PfM8Ti6Xo06dOgCAZs2a4cKFCwgPDzea3CmVSiiVylzl1tbWxf6iZYpzVBRFjYWHB/Dxx8CHHwLffQcsWADcuCHD228r8PHHCowdK2bafKpxt0zj50KPsdBjLPSKGgvGr2zIyABSUsT9XMmdJOm7ZLLVjoio1Jl1QhUbGxsEBgYiMjJSV6bRaBAZGYng4OACn0ej0RiMq6Pyx8lJJHg3bgBffy0G6cfHA7NmAdWrAyNHAqdPm7uWRER0/764VSjEfCkGoqKAK1fEH3Uuf0BEVOrMPltmWFgYli1bhp9++gkXLlzAmDFjkJqaitDQUADAsGHDDCZcCQ8PR0REBK5du4YLFy5gwYIFWL16NV599VVzvQUyITs74O23xbIJa9eKXj1ZWWK5pIAAoHNnMcMm18ojIjKPnF0yZbKnnvzhB3E7ZAjg6Fiq9SIiojIw5m7gwIFISEjAjBkzEBsbi2bNmmH79u26SVZiYmIgl+tz0NTUVIwdOxa3b9+GnZ0dGjRogF9++QUD+QthhWJtLX70HTgQOHgQ+PJLsSj67t1i8/MDRo8WLXrlqcsmEVF5l+d4u8REYONGcX/06FKtExERCWZP7gBg/PjxGD9+vNHnoqKiDB5/8skn+OSTT0qhVlRWtGkDrFsHxMQAixcDK1aI7psffQTMnCnWzHvrLeD55438ikxERCaVkCBuq1R56onVq0VXixYtxEZERKXO7N0yiQqqenVg3jzgzh1g1SqR9KlUIvHr1Alo3FhMyPLU/DxERGRC2pWKatfOUShJ+i6ZbLUjIjKbMtFyR1QYdnbA8OFiO3kSWLoU+OUX4MIF4P33gcmTgZ49gdBQoEcP0cWTiIhM4/p1cVu3bo7C//4TWZ+9PTB4sFnqRUSlQ61WQ6VSGZSpVCpYWVkhIyMDagufGOFZsVAoFLCysoKshLqbMbmjcq1ZM5HczZ0L/PabmHjl0CHgzz/F5u4OvPaaSPQaNzZ3bYmIyr+YGHFbo0aOQm2r3eDBQBHXkCWisi8lJQW3b9+GJEkG5ZIkwdPTE7du3SqxpKW8KEgs7O3t4eXlBRsbG5O/PpM7qhCcnYE33xTb+fMiyVu9WnTRXLBAbK1aiQnc+vcHqlUzd42JiMqnmzfFbfXqTwoePgTWrxf3ubYdUYWlVqtx+/Zt2Nvbo2rVqgaJi0ajQUpKChwdHQ0mQrRE+cVCkiRkZWUhISEB169fR926dU0eLyZ3VOE0aiTG5n32GbB9u0j0/u//gCNHxPbuu0BwMPDKKyLR8/U1d42JiMqH7Gzg1i1xX9dyt26dWNnc3x9o3dpsdSOikqVSqSBJEqpWrQo7OzuD5zQaDbKysmBra8vk7hmxsLOzg7W1NW7evKnbz5QsO/pUoVlbA716iZm579wRi6M/95yYUfPAASAsTPzy3LatWGpB+4WFiIiMu3ZNJHh2doC395PCLVvE7ZAhnLKYyAJYerdLUyjJBJjJHVkEd3exOPrevcDt23knesHBwMKF+jElRESkd/euuK1eHVAoAKSmisVHAeDFF81WLyIiEpjckcXx9jZM9BYvBjp0EInewYPAe++J7kZt2oixetrxJURElu7OHXGra7XbvRvIzBR/NBs1Mlu9iIhIYHJHFs3bGxg/HtizR3xp+eYb/WLohw6JpRX8/ICgIGD+fCZ6RGTZtC13uuRu61Zx27Mnu2QSkcXw8/PDokWLzF0No5jcET3h5QWMGwdEReVO9A4fBj74QCR6rVsD4eHAuXNi3V4iIkuhTe58fCD+AGqTO3bJJKIySCaT5bvNmjWrSOc9cuQIRo8ebdrKmghnyyQyQpvojRsHxMaKSVnWrxddObWzbn70EVC7NvDSS2LiFk4SR0QVnTaX8/YGcPq06NtuZwd07GjOahERGXXv3j3d/XXr1mHGjBmIjo7WlTk6OuruS5IEtVoNK6tnp0dVq1Y1bUVNiC13RM/g6QmMHQv884/41XrpUtEDSakErl4VM23+73+Al5cVPv+8FVaskOH2bXPXmojI9C5fFrcqFfSZXufOIsEjIosiSWJOJXNsBe055enpqdsqVaoEmUyme3zx4kU4OTnh77//RmBgIJRKJfbt24erV6/i5ZdfhoeHBxwdHdGqVSvs2rXL4LxPd8uUyWRYvnw5+vTpA0dHRwQGBmKLdibhUsbkjqgQPDzEQul//QUkJooWveHDxWycyckyHDzojTFjrODrCzRtCnz4oX6+ASKi8kyj0d/v3h3iDyHALplEFiotDXB0FJuzsxzVqrnA2VmuKyvJLS3NdO9j8uTJ+Pzzz3HhwgX4+/sjJSUFPXr0QGRkJE6cOIHu3bujV69eiHnGVOqzZ8/GgAEDcPLkSXTp0gWvvfYaHjx4YLqKFhCTO6IicnQE+vQBVq0C7t0DDh5UYfDgCwgK0kAmA86eFYupd+4MVKkium8uWQJcvMixekRU/jx6pL9f1zVRTC8MAD16mKU+RESmMGfOHHTp0gW1a9dG5cqVERAQgDfffBNNmjRB3bp18fHHH6N27drPbIkbMWIEBg8ejDp16mD69OlISUnB4cOHS+ld6HHMHZEJyOVAixbAwIGX0KNHHSQlyRERAWzfLra4OOD//k9sgJiMoHNnICRE3OpmniMiKqO0Q1ecnADlP9vFr1T+/oCvr3krRkRmYW8PpKSI+xqNBklJSXB2di7RBbpzvraptGzZ0uBxSkoKZs2aha1bt+LevXvIzs5Genr6M1vu/P39dfcdHBzg7OyM+Ph401W0gJjcEZWAKlWAQYPEptGIeQe2bwd27QL27ROzcf78s9gAoGFDkeR17CjW3CvD43SJyEJ98YW4TU4Gu2QSEWQywMFB3NdoALVaPC6F3M6kHLRv4on3338fERERmD9/PurUqQM7Ozv0798fWVlZ+Z7H2tra4LFMJoMmZ3/2UlLOwk9U/sjlQLNmwOTJIrl7+FDcTp4MtGol/jheuCCWXujfX4zfa9JErL+3YQNghh99iMjElixZAj8/P9ja2iIoKOiZXXUePXqEcePGwcvLC0qlEvXq1cO2bdtKqbbGrV4tbm0VKmDHDvGgZ0/zVYiIqAT8999/GDFiBPr06YOmTZvC09MTN27cMHe1Cowtd0SlzM5OtNJ17iweP3wo1tb75x9xe+aMWEPv3DkxRg8AGjUSrXodO4q199zdzVN3Iiq8devWISwsDEuXLkVQUBAWLVqEbt26ITo6Gu5G/jNnZWWhS5cucHd3x4YNG+Dj44ObN2/CxcWl9Cv/RM5Job4auB/49ZHoohAUZLY6ERGVhLp162Ljxo3o1asXZDIZpk+fbpYWuKJickdkZq6uYmKWPn3E48REsZ5eVJQ+2Tt/Xmzffiv2qVcPaN8eaNdO3NatK1oAiajsWbhwIUaNGoXQ0FAAwNKlS7F161asXLkSkydPzrX/ypUr8eDBA+zfv1/XzcfPz680q5zLzZv6+yM9nyyB8MILgEJhngoREZWQhQsXYuTIkWjbti3c3NwwadIkJCUlmbtaBcbkjqiMcXMD+vYVGyCSvX//1Sd7p08Dly6JbeVKsU/VqvpEr107MbmLjY253gERaWVlZeHYsWOYMmWKrkwulyMkJAQHDhwwesyWLVsQHByMcePG4c8//0TVqlUxZMgQTJo0CYo8kqnMzExk5mhe034RUalUUKlURaq79jiVSoXVq+UAxGsrdv4NAMju2hVSEc9d3uSMhaVjLPQsLRYqlQqSJEGj0eRqyZKeTAOufb4sGjZsGIYNG6arX4cOHaBWqwHAoM7Vq1fPta7dmDFjDPa7du2aweOc59HG4v79+3mOu9Pup1Kpcv1dL+7nqUwkd0uWLMG8efMQGxuLgIAALF68GK1btza677Jly/Dzzz/j7NmzAIDAwEB89tlnee5PVN65uRm27D14AOzfD/z3n5ic5cgRICEB2LxZbIBYYL1ZM6B1a7G1aiVa98rbIGei8i4xMRFqtRoeHh4G5R4eHrh48aLRY65du4bdu3dj6NCh2LZtG65cuYKxY8dCpVJh5syZRo8JDw/H7Nmzc5Xv3LkT9sWcVi4iIgK7drUC4A1P3IPs7FlIMhkiAGSZeRxgaYuIiDB3FcoMxkLPUmJhZWUFT09PpKSk5Dm5SHJycinXquzKLxZZWVlIT0/H3r17kZ2dbfBcWjEX8TN7clfYsQhRUVEYPHgw2rZtC1tbW3zxxRfo2rUrzp07Bx8fHzO8A6LSVbmymKBOO0ldZiZw7Jg+2fvvP+D+feDQIbFpVaokkrxWrfRJH5dgICp7NBoN3N3d8cMPP0ChUCAwMBB37tzBvHnz8kzupkyZgrCwMN3jpKQk+Pr6omvXrnB2di5SPVQqFSIiItClSxds3myLgweBr17cCfwFoFkzhAwaVKTzlkc5Y/H0jHiWhrHQs7RYZGRk4NatW3B0dIStra3Bc5IkITk5GU5OTpBZ+DiRgsQiIyMDdnZ26NChQ65YFrcLqNmTu8KORVizZo3B4+XLl+OPP/5AZGQkhg0bVip1JipLlEqgbVuxffCBWHrq6lXg8GHRqnf4MHD8OPD4sZilM2dPA29vw9a9li0BM87ZQFThuLm5QaFQIC4uzqA8Li4Onp6eRo/x8vKCtbW1QVedhg0bIjY2FllZWbAx0udaqVRCqVTmKre2ti72l05ra2vcvSua/VvcjwQAyLp2tYgvs08zRTwrCsZCz1JioVarIZPJIJfLc61lp+16qH3ekhUkFnK5HDKZzOhnp7ifJbMmd0UZi/C0tLQ0qFQqVK5c2ejzJT0OwdIxFnplKRY1aojtlVfEY5VKzL559KgMR47IcfSoDOfOAXfvygy6cwJAvXoSWraU0KqV2Pz9JTz1o9IzlaVYmBtjoVfcWJTHGNrY2CAwMBCRkZHo3bs3AHHhj4yMxPjx440e065dO/z666/QaDS6LwaXLl2Cl5eX0cSuNOzcCQASfKOfdD/r2tUs9SAiovyZNbkryliEp02aNAne3t4ICQkx+nxJj0MggbHQK8ux8PYGXn5ZbBkZCly9WglXrrji8mUXXL7sirg4B1y6JMOlSzL8+qs4xspKgxo1klC37kPUrfsIdeo8RLVqKVAopGe+XlmORWljLPSKGovijkMwl7CwMAwfPhwtW7ZE69atsWjRIqSmpup6rAwbNgw+Pj4IDw8HIAbuf/PNN5gwYQLefvttXL58GZ999hneeecds9Tfxkb8itwEZ6F8ECvWc2nXzix1ISKi/Jm9W2ZxfP7551i7di2ioqJy9VfVKulxCJbQDJ8fxkKvIsQiMVH1pHVPhmPHxG1CghxXr7rg6lUXbN8u9rO1ldCkiYSAAKBZMwkBARKaNpXg4CCerwixMBXGQq+4sShPU1HnNHDgQCQkJGDGjBmIjY1Fs2bNsH37dt0PmzExMQZdd3x9fbFjxw68++678Pf3h4+PDyZMmIBJkyaVet2fTAAHAOiCJ0l5hw6iPzgREZU5Zk3uijIWQWv+/Pn4/PPPsWvXLvj7++e5X0mPQ7D0L2tajIVeeY6FlxfQq5fYADF+7+ZN/di9I0fE5C0pKTIcPSrD0aP6Y2Uysf5e8+ZA06ZyZGVVRcuW1vDxKZ+xMLXy/LkwtaLGojzHb/z48Xl2w4yKispVFhwcjIMHD5ZwrZ7t8WP99XOkz07gDtglk4ioDDNrcleUsQgAMHfuXHz66afYsWMHWrZsWUq1JbI8Mhng5yc27fg9jUZM2HLyJHDihP42NhaIjhbb2rUKAG0xezbg4QE0aQI0bqy/bdxYzN5JRGXbzZuih4sSGWjyYK8o7NLFjDUiIqL8mL1bZmHHInzxxReYMWMGfv31V/j5+SE2NhYA4OjoCEdHR7O9DyJLIZeLNfPq1tUnfIBI7k6eFNuxYxrs35+Ge/ccEBcnQ1wcEBlpeJ5q1QwTviZNgIYNAf43Jio7VqxoCgBoh/+A9HTA01P8ZyUiojLJ7MldYccifPfdd8jKykL//v0NzjNz5kzMmjWrNKtORDl4egLdu4tNpVJj27ZIdOjQA5cvW+PcOeDsWehu79wBbt8W244dhufx88vd0teggZjDgYhK1+3bTgCAoTYbgCwA3bqJJn0iIiqTzJ7cAYUbi3Djxo2SrxARmYSjo34dvZwePQLOnzdM+M6dA+LigBs3xPbXX/r95XKgdm3Dbp1NmogxfmaaGZ7IYtghDYPxZPrc114zb2WIiArhWQuqF6dxSCaTYdOmTbqhZWVFmUjuiMiyuLjoF17PKTHRMNnT3n/wALh8WWybNun3t7ISCV7Obp316okuo8Vc6YTI4u3dK74U9cVG2GUlATVrAp06mblWREQFd+/ePd39devWYcaMGYiOjtaVVcQhXUzuiKjMcHMDnn9ebFqSJFr0nm7lO3sWSE4WLYDnzwPr1xuey9dXJHpPb35+IikkorwdOQKEhIj/KK9jhSgMDRXN6EREgLhAa9cf1WiA1FRAoSidvxP29gXqIp5z9v1KlSpBJpMZlC1fvhwLFizA9evX4efnh3feeQdjx44FAGRlZSEsLAx//PEHHj58CA8PD7z11luYMmUK/Pz8AAB9+vQBANSoUaPM9C7kVxwiKtNkMjGez9MTCAnRl0uSGLOXM9nTztb58CFw65bYnp7IxcpKdPE0lvh5eXE4EREAvPWWuPXGHXRCFCSZDLLhw81bKSIqW9LSdLOgyQG4lOZrp6RAt7huEa1ZswYzZszAN998g+bNm+PEiRMYNWoUHBwcMHz4cHz99dfYsmULfv/9d1SvXh23bt3CrVu3AABHjhyBu7s7fvzxR3Tv3h0KhcIU78okmNwRUbkkk4nWOV9f4IUXDJ+7fx+4dMlwi44W3TozMvRJ4NMcHY0nfXXriq6kRJZizx7AyQkIxgEAgKxZM6B6dfNWiojIhGbOnIkFCxagb9++AICaNWvi/Pnz+P777zF8+HDExMSgbt26aN++PWQyGWrUqKE7tmrVqgAAFxeXZ67NXdqY3BFRhVOlChAcLLacNBrR2vd04nfpEnD9uvgh8PhxsT3N3V2f7NWqpd9q1gSqVmWLH1Us2mEoQTj05E6Q+SpDRGWTvb24cEKsU52UlARnZ2eDWe5L9LWLITU1FVevXsXrr7+OUaNG6cqzs7NR6clCvCNGjECXLl1Qv359dO/eHS+++CK6du1arNctDUzuiMhiyOWi8aF6dcMungCQlQVcu6Zv5cuZ+MXGAvHxYtu3L/d5HRz0iV7OpK9WLcDHp3TeG5GpTZqkRusvDosHT095S0Qkk+m7Rmo0gFotHpeDsbkpT5LSZcuWIeipH6+0XSxbtGiB69ev4++//8auXbswYMAAhISEYMOGDaVe38JgckdEBLGkQoMGYntaUpLo0pmzle/aNbHduSPGkJ85I7bcrOHq2g0NGihytfjVqgV4e4vx50RlzcczsyBbdAjIBFvuiKhC8fDwgLe3N65du4ahQ4fmuZ+zszMGDhyIgQMHon///ujevTsePHiAypUrw9raGmq1uhRrXTBM7oiInsHZGQgMFNvTMjKAmzdFoqdN+nImf0lJwMOHtjhwADhwIPfxNjZAjRp5t/xxrB+ZzcWLsMrMhOTkBJmxXz2IiMqx2bNn45133kGlSpXQvXt3ZGZm4ujRo3j48CHCwsKwcOFCeHl5oXnz5pDL5Vi/fj08PT3h8uTC7Ofnh8jISLRr1w5KpRKurq7mfUNPMLkjIioGW1ugfn2xPU2SgPh4FX75ZT+8vdshJsbKIPG7eVN0B9Wu4WeMq6tI9GrWFEmgtlupr6+45Xg/Kimyq1cBAFL9+pCVg25WRESF8cYbb8De3h7z5s3DBx98AAcHBzRt2hQTJ04EADg5OWHu3Lm4fPkyFAoFWrVqhW3btunGFC5YsABhYWFYtmwZfHx8uBQCEVFFJ5MBlSsDdeo8Qo8eEqytDZ9Xq8UELzkTvpytf3FxYlmHhw+NT/ICiORSm+g9vWlnE+WC7lQUsps3xZ0cM8QREZVXI0aMwIgRIwzKhgwZgiFDhhjdf9SoUQaTrTytV69e6NWrlymraBJM7oiIzEShEN+ba9QAOnbM/XxqqkjytFtMjFi7LyZGbPfuiW6h+bX8AWJxeGOJn/a+p2e5GP9Ope1Jcic9WayXiIjKPiZ3RERllIMD0KSJ2IzJyhITumiTPe2mTQBv3hSzVCcmii2v1j9ra6BaNX3S5+MjtmrV9Pc9PTnxi6WRabsYMbkjIio3mNwREZVTNjb68XjGSBLw+HHu5C9nAnjnDqBS6VsH8yKXiwTv6aTv6URQOys2lX/abpkSu2USEZUbTO6IiCoomUzMtuniAvj7G98nO1t078yZ9N25I7bbt8XtvXtifODdu2I7ciTv16xUyXji5+0NuLvL8PChsiTeKpmaWi3W/QAg1a5t5soQEVFBMbkjIrJgVlb6iVfatTO+j1otFnB/Oul7ektOFi2Fjx8D588bfTX4+rZFPksKUVlx5QpkGRnIVirFmhxERE9IkmTuKpR7JRlDJndERJQvhQLw8hJby5Z575eUZDzpu31btP7duSPBzS0dgF2p1Z2K6P59SDVrItnKCo4cbElEABRP/hZkZWXBzo5/x4sjLS0NAGD99DTaJsDkjoiITMLZWWwNGxp/XqXKxtatBwH0KNV6URG0bYvs6Gj8u2ULXjB3XYioTLCysoK9vT0SEhJgbW2tW+8NADQaDbKyspCRkWFQbonyi4UkSUhLS0N8fDxcXFx0CbMpMbkjIqJSwwXXyxfJil8TiEiQyWTw8vLC9evXcVO7DuYTkiQhPT0ddnZ2kFn4H/qCxMLFxQWenp4l8vr8q01ERERERM9kY2ODunXrIisry6BcpVJh79696NChQ4l0NSxPnhULa2vrEmmx02JyR0REREREBSKXy2Fra2tQplAokJ2dDVtbW4tP7swdC8vuFEtERERERFRBMLkjIiIiIiKqAJjcERERERERVQAWN+ZOu2hgUlJSkc+hUqmQlpaGpKQki+9XzFjoMRZ6jIUeY6FX3Fho/25zAd1n47XOtBgLPcZCj7HQYyz0zH2ts7jkLjk5GQDg6+tr5poQEVFRJCcno1KlSuauRpnGax0RUflW1GudTLKwn0A1Gg3u3r0LJyenIq/DkZSUBF9fX9y6dQvOzs4mrmH5wljoMRZ6jIUeY6FX3FhIkoTk5GR4e3tb/CK5z8JrnWkxFnqMhR5jocdY6Jn7WmdxLXdyuRzVqlUzybmcnZ0t/gOsxVjoMRZ6jIUeY6FXnFiwxa5geK0rGYyFHmOhx1joMRZ65rrW8adPIiIiIiKiCoDJHRERERERUQXA5K4IlEolZs6cCaVSae6qmB1jocdY6DEWeoyFHmNRvvDfS4+x0GMs9BgLPcZCz9yxsLgJVYiIiIiIiCoittwRERERERFVAEzuiIiIiIiIKgAmd0RERERERBUAkzsiIiIiIqIKgMldESxZsgR+fn6wtbVFUFAQDh8+bO4qFcrevXvRq1cveHt7QyaTYfPmzQbPS5KEGTNmwMvLC3Z2dggJCcHly5cN9nnw4AGGDh0KZ2dnuLi44PXXX0dKSorBPqdPn8Zzzz0HW1tb+Pr6Yu7cubnqsn79ejRo0AC2trZo2rQptm3bZvL3m5fw8HC0atUKTk5OcHd3R+/evREdHW2wT0ZGBsaNG4cqVarA0dER/fr1Q1xcnME+MTEx6NmzJ+zt7eHu7o4PPvgA2dnZBvtERUWhRYsWUCqVqFOnDlatWpWrPub8XH333Xfw9/fXLbgZHByMv//+W/e8pcTBmM8//xwymQwTJ07UlVlSPGbNmgWZTGawNWjQQPe8JcXCkpT3WPM6p8drnR6vdXmz5GtdhbvOSVQoa9eulWxsbKSVK1dK586dk0aNGiW5uLhIcXFx5q5agW3btk2aOnWqtHHjRgmAtGnTJoPnP//8c6lSpUrS5s2bpVOnTkkvvfSSVLNmTSk9PV23T/fu3aWAgADp4MGD0r///ivVqVNHGjx4sO75x48fSx4eHtLQoUOls2fPSr/99ptkZ2cnff/997p9/vvvP0mhUEhz586Vzp8/L02bNk2ytraWzpw5U+IxkCRJ6tatm/Tjjz9KZ8+elU6ePCn16NFDql69upSSkqLb56233pJ8fX2lyMhI6ejRo1KbNm2ktm3b6p7Pzs6WmjRpIoWEhEgnTpyQtm3bJrm5uUlTpkzR7XPt2jXJ3t5eCgsLk86fPy8tXrxYUigU0vbt23X7mPtztWXLFmnr1q3SpUuXpOjoaOmjjz6SrK2tpbNnz1pUHJ52+PBhyc/PT/L395cmTJigK7ekeMycOVNq3LixdO/ePd2WkJCge96SYmEpKkKseZ3T47VOj9c64yz9WlfRrnNM7gqpdevW0rhx43SP1Wq15O3tLYWHh5uxVkX39EVPo9FInp6e0rx583Rljx49kpRKpfTbb79JkiRJ58+flwBIR44c0e3z999/SzKZTLpz544kSZL07bffSq6urlJmZqZun0mTJkn169fXPR4wYIDUs2dPg/oEBQVJb775pknfY0HFx8dLAKQ9e/ZIkiTet7W1tbR+/XrdPhcuXJAASAcOHJAkSXyBkMvlUmxsrG6f7777TnJ2dta99w8//FBq3LixwWsNHDhQ6tatm+5xWfxcubq6SsuXL7fYOCQnJ0t169aVIiIipOeff153wbO0eMycOVMKCAgw+pylxcJSVLRY8zpniNc6Q7zW8VpX0a5z7JZZCFlZWTh27BhCQkJ0ZXK5HCEhIThw4IAZa2Y6169fR2xsrMF7rFSpEoKCgnTv8cCBA3BxcUHLli11+4SEhEAul+PQoUO6fTp06AAbGxvdPt26dUN0dDQePnyo2yfn62j3MVcsHz9+DACoXLkyAODYsWNQqVQGdWzQoAGqV69uEIumTZvCw8NDt0+3bt2QlJSEc+fO6fbJ732Wtc+VWq3G2rVrkZqaiuDgYIuNw7hx49CzZ89cdbbEeFy+fBne3t6oVasWhg4dipiYGACWGYuKzhJibcnXOYDXOi1e6wRe64SKdJ1jclcIiYmJUKvVBv94AODh4YHY2Fgz1cq0tO8jv/cYGxsLd3d3g+etrKxQuXJlg32MnSPna+S1jzliqdFoMHHiRLRr1w5NmjTR1c/GxgYuLi551rE47zMpKQnp6ell5nN15swZODo6QqlU4q233sKmTZvQqFEji4sDAKxduxbHjx9HeHh4rucsLR5BQUFYtWoVtm/fju+++w7Xr1/Hc889h+TkZIuLhSWwhFhb6nUO4LUO4LUuJ17rhIp2nbMq1N5EFdS4ceNw9uxZ7Nu3z9xVMZv69evj5MmTePz4MTZs2IDhw4djz5495q5Wqbt16xYmTJiAiIgI2Nramrs6ZvfCCy/o7vv7+yMoKAg1atTA77//Djs7OzPWjIgKi9c6Xuu0eK3Tq2jXObbcFYKbmxsUCkWuGXLi4uLg6elpplqZlvZ95PcePT09ER8fb/B8dnY2Hjx4YLCPsXPkfI289intWI4fPx5//fUX/vnnH1SrVk1X7unpiaysLDx69CjPOhbnfTo7O8POzq7MfK5sbGxQp04dBAYGIjw8HAEBAfjqq68sLg7Hjh1DfHw8WrRoASsrK1hZWWHPnj34+uuvYWVlBQ8PD4uKx9NcXFxQr149XLlyxeI+G5bAEmJtidc5gNc6LV7rBF7r8lber3NM7grBxsYGgYGBiIyM1JVpNBpERkYiODjYjDUznZo1a8LT09PgPSYlJeHQoUO69xgcHIxHjx7h2LFjun12794NjUaDoKAg3T579+6FSqXS7RMREYH69evD1dVVt0/O19HuU1qxlCQJ48ePx6ZNm7B7927UrFnT4PnAwEBYW1sb1DE6OhoxMTEGsThz5ozBl4CIiAg4OzujUaNGun3ye59l9XOl0WiQmZlpcXHo3Lkzzpw5g5MnT+q2li1bYujQobr7lhSPp6WkpODq1avw8vKyuM+GJbCEWFvSdQ7gte5ZeK3jte5p5f46V6jpV0hau3atpFQqpVWrVknnz5+XRo8eLbm4uBjMkFPWJScnSydOnJBOnDghAZAWLlwonThxQrp586YkSWKKaBcXF+nPP/+UTp8+Lb388stGp4hu3ry5dOjQIWnfvn1S3bp1DaaIfvTokeTh4SG99tpr0tmzZ6W1a9dK9vb2uaaItrKykubPny9duHBBmjlzZqlOET1mzBipUqVKUlRUlMH0t2lpabp93nrrLal69erS7t27paNHj0rBwcFScHCw7nnt9Lddu3aVTp48KW3fvl2qWrWq0elvP/jgA+nChQvSkiVLjE5/a87P1eTJk6U9e/ZI169fl06fPi1NnjxZkslk0s6dOy0qDnnJOYOYJFlWPN577z0pKipKun79uvTff/9JISEhkpubmxQfH29xsbAUFSHWvM7p8Vqnx2td/iz1WlfRrnNM7opg8eLFUvXq1SUbGxupdevW0sGDB81dpUL5559/JAC5tuHDh0uSJKaJnj59uuTh4SEplUqpc+fOUnR0tME57t+/Lw0ePFhydHSUnJ2dpdDQUCk5Odlgn1OnTknt27eXlEql5OPjI33++ee56vL7779L9erVk2xsbKTGjRtLW7duLbH3/TRjMQAg/fjjj7p90tPTpbFjx0qurq6Svb291KdPH+nevXsG57lx44b0wgsvSHZ2dpKbm5v03nvvSSqVymCff/75R2rWrJlkY2Mj1apVy+A1tMz5uRo5cqRUo0YNycbGRqpatarUuXNn3cVOkiwnDnl5+oJnSfEYOHCg5OXlJdnY2Eg+Pj7SwIEDpStXruiet6RYWJLyHmte5/R4rdPjtS5/lnqtq2jXOZkkSVLh2vqIiIiIiIiorOGYOyIiIiIiogqAyR0REREREVEFwOSOiIiIiIioAmByR0REREREVAEwuSMiIiIiIqoAmNwRERERERFVAEzuiIiIiIiIKgAmd0RERERERBUAkzuiMiohIQFjxoxB9erVoVQq4enpiW7duuG///4DAMhkMmzevNm8lSQiIioGXuuITMvK3BUgIuP69euHrKws/PTTT6hVqxbi4uIQGRmJ+/fvm7tqREREJsFrHZFpySRJksxdCSIy9OjRI7i6uiIqKgrPP/98ruf9/Pxw8+ZN3eMaNWrgxo0bAIA///wTs2fPxvnz5+Ht7Y3hw4dj6tSpsLISv+XIZDJ8++232LJlC6KiouDl5YW5c+eif//+pfLeiIiIAF7riEoCu2USlUGOjo5wdHTE5s2bkZmZmev5I0eOAAB+/PFH3Lt3T/f433//xbBhwzBhwgScP38e33//PVatWoVPP/3U4Pjp06ejX79+OHXqFIYOHYpBgwbhwoULJf/GiIiInuC1jsj02HJHVEb98ccfGDVqFNLT09GiRQs8//zzGDRoEPz9/QGIXyU3bdqE3r17644JCQlB586dMWXKFF3ZL7/8gg8//BB3797VHffWW2/hu+++0+3Tpk0btGjRAt9++23pvDkiIiLwWkdkamy5Iyqj+vXrh7t372LLli3o3r07oqKi0KJFC6xatSrPY06dOoU5c+bofg11dHTEqFGjcO/ePaSlpen2Cw4ONjguODiYv2YSEVGp47WOyLQ4oQpRGWZra4suXbqgS5cumD59Ot544w3MnDkTI0aMMLp/SkoKZs+ejb59+xo9FxERUVnDax2R6bDljqgcadSoEVJTUwEA1tbWUKvVBs+3aNEC0dHRqFOnTq5NLtf/dz948KDBcQcPHkTDhg1L/g0QERE9A691REXHljuiMuj+/ft45ZVXMHLkSPj7+8PJyQlHjx7F3Llz8fLLLwMQs4hFRkaiXbt2UCqVcHV1xYwZM/Diiy+ievXq6N+/P+RyOU6dOoWzZ8/ik08+0Z1//fr1aNmyJdq3b481a9bg8OHDWLFihbneLhERWSBe64hKgEREZU5GRoY0efJkqUWLFlKlSpUke3t7qX79+tK0adOktLQ0SZIkacuWLVKdOnUkKysrqUaNGrpjt2/fLrVt21ays7OTnJ2dpdatW0s//PCD7nkA0pIlS6QuXbpISqVS8vPzk9atW1fab5GIiCwcr3VEpsfZMoksjLGZx4iIiCoSXuvIUnHMHRERERERUQXA5I6IiIiIiKgCYLdMIiIiIiKiCoAtd0RERERERBUAkzsiIiIiIqIKgMkdERERERFRBcDkjoiIiIiIqAJgckdERERERFQBMLkjIiIiIiKqAJjcERERERERVQBM7oiIiIiIiCoAJndEREREREQVwP8D8XSH2LHq1KAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First 100 Train Outputs:\n",
            "tensor([ 4.3608,  3.0876, -3.6204,  4.7701,  1.6177, -2.3560, -1.6627, -0.6476,\n",
            "        -0.0862,  2.9219,  4.1155,  6.1505,  2.0947, -2.9837, -1.6973,  0.8027,\n",
            "        -3.3366,  3.1938, -1.4903,  3.4511,  1.9733, -7.1531,  5.9211,  4.3814,\n",
            "        -1.3333,  1.5393,  6.8501,  5.3228,  2.6696,  3.4502,  3.3537, -5.0362,\n",
            "         2.2694,  1.6062, -2.4426,  1.8086,  4.8716, -3.3782,  1.4697,  1.5617,\n",
            "        -2.2715,  2.3956, -2.0794, -1.6324, -5.6512, -2.5626,  5.5744,  0.1727,\n",
            "        -5.0574,  6.7551, -4.1601, -0.0989, -5.2585,  4.5904, -2.9573,  1.6531,\n",
            "         1.7166, -0.3993,  2.7776, -3.6832, -0.1788, -1.7351,  1.9970,  5.2168,\n",
            "        -3.5106, -4.4169,  6.4136, -1.7332, -8.5486,  0.7694, -4.8700,  8.1185,\n",
            "         2.1177,  3.5342,  1.4491,  0.2521,  4.4976,  7.3665,  2.6435,  2.3864,\n",
            "        -4.7190,  3.7756,  2.6326,  2.1277,  2.9645,  4.5208, -5.1278,  3.5505,\n",
            "         5.3586, -6.6160,  3.7203,  4.8991,  6.6004, -3.1968,  6.1535, -2.2456,\n",
            "        -1.8547, -0.8579,  3.1523, -6.3581])\n",
            "\n",
            "First 100 Train Labels:\n",
            "tensor([1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
            "        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
            "        1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
            "        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
            "        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
            "        1., 1., 1., 0., 1., 0., 0., 0., 1., 0.])\n",
            "\n",
            "First 100 Test Outputs:\n",
            "tensor([ 0.4864,  1.5325, -7.8903, -1.8447, -1.9054, -3.2085, -1.4838,  2.5991,\n",
            "         2.8214, -1.8870, -4.4383,  1.1636,  2.6992,  6.7939,  4.9027,  4.6564,\n",
            "         4.3060,  2.0350,  5.0581, -3.8775, -0.0544,  0.9139,  1.0828, -4.8313,\n",
            "        -1.4606, -0.3445, -3.9115, -0.6122, -1.3524,  3.8292,  4.1445, -1.7646,\n",
            "         6.7597,  1.3923,  1.3520,  2.9589,  2.1256, -5.6783, -2.4122, -1.3124,\n",
            "         6.4886, -1.5440,  7.3454,  5.0420,  2.7052,  4.6265,  0.2346,  3.2671,\n",
            "         2.5553,  2.7259, -0.0801,  1.2950,  3.9679,  4.1274, -5.6791,  5.3617,\n",
            "        -4.8908,  1.9402, -1.2276,  2.0081,  3.9700, -1.7448, -5.5141,  7.3647,\n",
            "         0.1492,  0.9947,  1.3893,  0.0692,  3.4807, -0.8419,  1.5442, -0.6486,\n",
            "         0.8674,  0.4439,  5.7843,  2.6664,  3.2780,  2.9794,  1.9543,  0.0697,\n",
            "        -0.3106,  4.8821, -0.3949,  4.8861,  0.4193, -1.0347,  2.1591, -0.8132,\n",
            "        -2.3337,  4.0226,  1.8874,  4.0696,  4.5837,  3.3260,  1.5470, -3.1695,\n",
            "        -0.5486,  0.5326,  0.3307,  4.2177])\n",
            "\n",
            "First 100 Test Labels:\n",
            "tensor([1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
            "        1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
            "        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
            "        1., 1., 1., 1., 0., 0., 0., 1., 0., 1.])\n",
            "Final Test Accuracy: 0.7689\n"
          ]
        }
      ]
    }
  ]
}