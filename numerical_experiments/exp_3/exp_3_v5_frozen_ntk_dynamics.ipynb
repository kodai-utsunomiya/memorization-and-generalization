{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGoA9F8y4COWTQb73IlEWb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kodai-utsunomiya/memorization-and-generalization/blob/main/numerical_experiments/exp_3/exp_3_v5_frozen_ntk_dynamics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class BinaryDataset:\n",
        "    def __init__(self, n, k, train_size, test_size, data_seed, normalize=False, device=None):\n",
        "        self.n = n\n",
        "        self.k = k\n",
        "        self.train_size = train_size\n",
        "        self.test_size = test_size\n",
        "        self.data_seed = data_seed\n",
        "        self.normalize = normalize\n",
        "        self.device = device\n",
        "\n",
        "        (self.train_inputs, self.train_outputs), (self.test_inputs, self.test_outputs) = self._prepare_data()\n",
        "\n",
        "    def _prepare_data(self):\n",
        "        np.random.seed(self.data_seed)\n",
        "        total_size = self.train_size + self.test_size\n",
        "\n",
        "        binary_strings = {tuple(np.random.randint(2, size=self.n)) for _ in range(total_size)}\n",
        "        while len(binary_strings) < total_size:\n",
        "            binary_strings.add(tuple(np.random.randint(2, size=self.n)))\n",
        "\n",
        "        binary_strings = list(binary_strings)\n",
        "        inputs = np.array(binary_strings, dtype=np.float32)\n",
        "        outputs = np.sum(inputs[:, :self.k], axis=-1) % 2\n",
        "\n",
        "        # # 出力ラベルを 0 -> -1, 1 -> 1 に変換（ヒンジ損失用）\n",
        "        # outputs = 2 * outputs - 1\n",
        "\n",
        "        # データの正規化を行う場合\n",
        "        if self.normalize:\n",
        "            inputs = (inputs - inputs.mean(axis=0))\n",
        "            norm = np.linalg.norm(inputs, axis=1, keepdims=True)\n",
        "            inputs = (inputs / np.maximum(norm, 1e-8))  # ゼロ除算防止\n",
        "\n",
        "        indices = np.random.permutation(total_size)\n",
        "        train_indices, test_indices = indices[:self.train_size], indices[self.train_size:]\n",
        "\n",
        "        train_inputs = torch.tensor(inputs[train_indices], dtype=torch.float32).to(self.device)\n",
        "        train_outputs = torch.tensor(outputs[train_indices], dtype=torch.float32).to(self.device)\n",
        "        test_inputs = torch.tensor(inputs[test_indices], dtype=torch.float32).to(self.device)\n",
        "        test_outputs = torch.tensor(outputs[test_indices], dtype=torch.float32).to(self.device)\n",
        "\n",
        "        return (train_inputs, train_outputs), (test_inputs, test_outputs)\n",
        "\n",
        "    def get_data(self):\n",
        "        return (self.train_inputs, self.train_outputs), (self.test_inputs, self.test_outputs)\n",
        "\n",
        "\n",
        "###################################################################\n",
        "\n",
        "import functools\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FC(nn.Module):\n",
        "    def __init__(self, d, h, L, act, bias=False):\n",
        "        super().__init__()\n",
        "\n",
        "        hh = d\n",
        "        for i in range(L):\n",
        "            W = torch.randn(h, hh)\n",
        "\n",
        "            n = max(1, 128 * 256 // hh)\n",
        "            W = nn.ParameterList([nn.Parameter(W[j: j+n]) for j in range(0, len(W), n)])\n",
        "\n",
        "            setattr(self, \"W{}\".format(i), W)\n",
        "            if bias:\n",
        "                self.register_parameter(\"B{}\".format(i), nn.Parameter(torch.zeros(h)))\n",
        "            hh = h\n",
        "\n",
        "        self.register_parameter(\"W{}\".format(L), nn.Parameter(torch.randn(1, hh)))\n",
        "        if bias:\n",
        "            self.register_parameter(\"B{}\".format(L), nn.Parameter(torch.zeros(1)))\n",
        "\n",
        "        self.L = L\n",
        "        self.act = act\n",
        "        self.bias = bias\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(self.L + 1):\n",
        "            W = getattr(self, \"W{}\".format(i))\n",
        "\n",
        "            if isinstance(W, nn.ParameterList):\n",
        "                W = torch.cat(list(W))\n",
        "\n",
        "            if self.bias:\n",
        "                B = self.bias * getattr(self, \"B{}\".format(i))\n",
        "            else:\n",
        "                B = 0\n",
        "\n",
        "            h = x.size(1)\n",
        "\n",
        "            if i < self.L:\n",
        "                x = x @ (W.t() / h ** 0.5)\n",
        "                x = self.act(x + B)\n",
        "            else:\n",
        "                x = x @ (W.t() / h ** 0.5) + B\n",
        "\n",
        "        return x.view(-1)\n",
        "\n",
        "#################################################################################\n",
        "def gradient(outputs, inputs, grad_outputs=None, retain_graph=None, create_graph=False):\n",
        "    r'''\n",
        "    Compute the gradient of `outputs` with respect to `inputs`\n",
        "    ```\n",
        "    gradient(x.sum(), x)\n",
        "    gradient((x * y).sum(), [x, y])\n",
        "    ```\n",
        "    '''\n",
        "    if torch.is_tensor(inputs):\n",
        "        inputs = [inputs]\n",
        "    else:\n",
        "        inputs = list(inputs)\n",
        "    grads = torch.autograd.grad(outputs, inputs, grad_outputs,\n",
        "                                allow_unused=True,\n",
        "                                retain_graph=retain_graph,\n",
        "                                create_graph=create_graph)\n",
        "    grads = [x if x is not None else torch.zeros_like(y) for x, y in zip(grads, inputs)]\n",
        "    return torch.cat([x.contiguous().view(-1) for x in grads])\n",
        "\n",
        "########################################################################################\n",
        "def compute_kernels(f, xtr, xte):\n",
        "\n",
        "    ktrtr = xtr.new_zeros(len(xtr), len(xtr))\n",
        "    ktetr = xtr.new_zeros(len(xte), len(xtr))\n",
        "    ktete = xtr.new_zeros(len(xte), len(xte))\n",
        "\n",
        "    params = []\n",
        "    current = []\n",
        "    for p in sorted(f.parameters(), key=lambda p: p.numel(), reverse=True):\n",
        "        current.append(p)\n",
        "        if sum(p.numel() for p in current) > 2e9 // (8 * (len(xtr) + len(xte))):\n",
        "            if len(current) > 1:\n",
        "                params.append(current[:-1])\n",
        "                current = current[-1:]\n",
        "            else:\n",
        "                params.append(current)\n",
        "                current = []\n",
        "    if len(current) > 0:\n",
        "        params.append(current)\n",
        "\n",
        "    for i, p in enumerate(params):\n",
        "        print(\"[{}/{}] [len={} numel={}]\".format(i, len(params), len(p), sum(x.numel() for x in p)), flush=True)\n",
        "\n",
        "        jtr = xtr.new_empty(len(xtr), sum(u.numel() for u in p))  # (P, N~)\n",
        "        jte = xte.new_empty(len(xte), sum(u.numel() for u in p))  # (P, N~)\n",
        "\n",
        "        for j, x in enumerate(xtr):\n",
        "            jtr[j] = gradient(f(x[None]), p)  # (N~)\n",
        "\n",
        "        for j, x in enumerate(xte):\n",
        "            jte[j] = gradient(f(x[None]), p)  # (N~)\n",
        "\n",
        "        ktrtr.add_(jtr @ jtr.t())\n",
        "        ktetr.add_(jte @ jtr.t())\n",
        "        ktete.add_(jte @ jte.t())\n",
        "        del jtr, jte\n",
        "\n",
        "    return ktrtr, ktetr, ktete"
      ],
      "metadata": {
        "id": "vNMYzp4WJ1uv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frozen NTK dynamics"
      ],
      "metadata": {
        "id": "R3WTZB4qy6xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import itertools\n",
        "import math\n",
        "from time import perf_counter\n",
        "\n",
        "def loglinspace(rate, step, end=None):\n",
        "    t = 0\n",
        "    while end is None or t <= end:\n",
        "        yield t\n",
        "        t = int(t + 1 + step * (1 - math.exp(-t * rate / step)))\n",
        "\n",
        "def train_kernel(args, ktrtr, ytr, tau, max_walltime, alpha, learning_rate, loss_prim, max_dgrad=math.inf, max_dout=math.inf):\n",
        "    # 初期化\n",
        "    otr = torch.zeros(len(ytr), dtype=ktrtr.dtype, device=ktrtr.device)\n",
        "    gradient_update = torch.clone(otr)\n",
        "\n",
        "    last_lr_change_step = 0  # 最後に学習率が変更されたステップ\n",
        "\n",
        "    checkpoint_generator = loglinspace(0.01, 100)\n",
        "    checkpoint = next(checkpoint_generator)  # 最初のチェックポイント\n",
        "    start_time = perf_counter()  # 経過時間計測の開始\n",
        "    converged = False\n",
        "\n",
        "    # 初期の損失関数の勾配を計算\n",
        "    lprim = loss_prim(otr, ytr)\n",
        "    grad = ktrtr @ lprim / len(ytr)\n",
        "\n",
        "    # メインループ\n",
        "    for step in itertools.count():\n",
        "        if step >= args.max_step:\n",
        "            break\n",
        "\n",
        "        # 現在の状態を保存\n",
        "        state = copy.deepcopy((otr, gradient_update))\n",
        "\n",
        "        while True:\n",
        "            gradient_update = -grad.clone()\n",
        "\n",
        "            # 出力を更新\n",
        "            otr = otr + learning_rate * gradient_update\n",
        "\n",
        "            # 新しい勾配を計算\n",
        "            lprim = loss_prim(otr, ytr)\n",
        "            new_grad = ktrtr @ lprim / len(ytr)\n",
        "\n",
        "            # 出力変化量 (dout) の計算\n",
        "            dout = (learning_rate * alpha * gradient_update).abs().max().item()\n",
        "\n",
        "            # 勾配の変化量 (dgrad) の計算\n",
        "            if grad.norm() == 0 or new_grad.norm() == 0:\n",
        "                dgrad = 0\n",
        "            else:\n",
        "                dgrad = ((grad - new_grad).norm() ** 2 / (grad.norm() * new_grad.norm())).item()\n",
        "\n",
        "            # 変化量が許容範囲内なら学習率を調整\n",
        "            if dgrad < max_dgrad and dout < max_dout:\n",
        "                if dgrad < 0.1 * max_dgrad and dout < 0.1 * max_dout:\n",
        "                    learning_rate *= 1.1  # 学習率を大きくする\n",
        "                break\n",
        "\n",
        "            # 学習率を小さくする\n",
        "            learning_rate /= 10\n",
        "\n",
        "            print(\"[Step {:d}/{:d}] [Progress: {:.2%}] [learning rate: {:.1e}]\".format(step, args.max_step, step / args.max_step, learning_rate), flush=True)\n",
        "\n",
        "            # 状態をリセット\n",
        "            last_lr_change_step = step\n",
        "            otr, gradient_update = state\n",
        "\n",
        "        # 勾配を更新\n",
        "        grad = new_grad\n",
        "\n",
        "        save = False\n",
        "        if step == checkpoint:\n",
        "            checkpoint = next(checkpoint_generator)\n",
        "            assert checkpoint > step\n",
        "            save = True\n",
        "\n",
        "        if save:\n",
        "            state = {\n",
        "                'step': step,\n",
        "                'wall': perf_counter() - start_time,\n",
        "                'learning_rate': learning_rate,\n",
        "                'dgrad': dgrad,\n",
        "                'dout': dout,\n",
        "                'grad_norm': grad.norm().item(),\n",
        "            }\n",
        "            yield otr, gradient_update, grad, state, converged\n",
        "\n",
        "        if converged:\n",
        "            break\n",
        "\n",
        "        # 最大経過時間を超えたら終了\n",
        "        if perf_counter() > start_time + max_walltime:\n",
        "            break\n",
        "\n",
        "        # 出力に NaN が含まれていたら終了\n",
        "        if torch.isnan(otr).any():\n",
        "            break"
      ],
      "metadata": {
        "id": "fkHYa7LT0ik_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "from functools import partial\n",
        "from time import perf_counter\n",
        "\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.device = 'cpu'\n",
        "        self.init_seed = 0\n",
        "        self.data_seed = 0\n",
        "        self.batch_seed = 0\n",
        "        self.max_step = 50000\n",
        "        self.n = 13\n",
        "        self.k = 3\n",
        "        self.train_size = 3000\n",
        "        self.test_size = 1900\n",
        "        self.normalize = False\n",
        "        self.bias = True\n",
        "        self.L = 3\n",
        "        self.h = 100\n",
        "        self.learning_rate = 0.01\n",
        "        self.init_kernel = 1\n",
        "        self.store_kernel = 0\n",
        "        self.delta_kernel = 0\n",
        "        self.save_outputs = 0\n",
        "        self.alpha = 1\n",
        "        self.f0 = 1\n",
        "        self.train_time = 18000\n",
        "        self.max_dgrad = 1e-4\n",
        "        self.max_dout = 0.1\n",
        "        self.loss = 'cross_entropy'\n",
        "        self.pickle = 'results.pkl'\n",
        "        self.track_test_metrics = True\n",
        "\n",
        "def loss_func(args, outputs, targets):\n",
        "    if args.loss == 'mse':\n",
        "        return ((targets - outputs) ** 2).mean()\n",
        "    elif args.loss == 'cross_entropy':\n",
        "        return F.binary_cross_entropy_with_logits(outputs, targets)\n",
        "\n",
        "def loss_func_prime(args, outputs, targets):\n",
        "    if args.loss == 'mse':\n",
        "        return -2 * (targets - outputs) / outputs.size(0)\n",
        "    elif args.loss == 'cross_entropy':\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        grad = probs - targets\n",
        "        return grad / outputs.size(0)\n",
        "\n",
        "def run_kernel(args, ktrtr, ktetr, ktete, f, xtr, ytr, xte, yte):\n",
        "    assert args.f0 == 1\n",
        "\n",
        "    dynamics = []\n",
        "    step_counter = 0\n",
        "\n",
        "    tau = 0\n",
        "\n",
        "    for otr, _gradient_update, _grad, state, _converged in train_kernel(args, ktrtr, ytr, tau, args.train_time, args.alpha, args.learning_rate, partial(loss_func_prime, args), args.max_dgrad, args.max_dout):\n",
        "        step_counter += 1\n",
        "\n",
        "        preds = torch.sigmoid(otr) > 0.5\n",
        "        train_accuracy = (preds.int() == ytr.int()).float().mean().item()\n",
        "\n",
        "        state['train'] = {\n",
        "            'loss': loss_func(args, otr, ytr).item(),\n",
        "            'aloss': args.alpha * loss_func(args, otr, ytr).item(),\n",
        "            'accuracy': train_accuracy,\n",
        "            'dfnorm': otr.pow(2).mean().sqrt(),\n",
        "            'outputs': otr if args.save_outputs else None,\n",
        "            'labels': ytr if args.save_outputs else None,\n",
        "        }\n",
        "\n",
        "        if args.track_test_metrics and step_counter % 50 == 0:\n",
        "            c = torch.linalg.lstsq(ktrtr, otr.view(-1, 1)).solution.flatten()\n",
        "\n",
        "            if len(xte) > len(xtr):\n",
        "                a = gradient(f(xtr) @ c, f.parameters())\n",
        "                ote = torch.stack([gradient(f(x[None]), f.parameters()) @ a for x in xte])\n",
        "            else:\n",
        "                ote = ktetr @ c\n",
        "\n",
        "            test_loss = loss_func(args, ote, yte).item()\n",
        "            test_preds = torch.sigmoid(ote) > 0.5\n",
        "            test_accuracy = (test_preds.int() == yte.int()).float().mean().item()\n",
        "\n",
        "            state['test'] = {\n",
        "                'loss': test_loss,\n",
        "                'accuracy': test_accuracy,\n",
        "            }\n",
        "\n",
        "            print(f\"[Step {state['step']:d}/{args.max_step}] [Time: {state['wall']:.0f}s] \"\n",
        "                  f\"[Train Loss: {state['train']['loss']:.2e}] [Train Acc: {state['train']['accuracy']:.2f}] \"\n",
        "                  f\"[Eval Loss: {state['test']['loss']:.2e}] [Eval Acc: {state['test']['accuracy']:.2f}]\",\n",
        "                  flush=True)\n",
        "        else:\n",
        "            state['test'] = {\n",
        "                'loss': None,\n",
        "                'accuracy': None,\n",
        "            }\n",
        "\n",
        "            print(f\"[Step {state['step']:d}/{args.max_step}] [Time: {state['wall']:.0f}s] \"\n",
        "                  f\"[Train Loss: {state['train']['aloss']:.2e}] [Train Acc: {state['train']['accuracy']:.2f}]\",\n",
        "                  flush=True)\n",
        "\n",
        "        dynamics.append(state)\n",
        "\n",
        "    c = torch.linalg.lstsq(ktrtr, otr.view(-1, 1)).solution.flatten()\n",
        "    if len(xte) > len(xtr):\n",
        "        a = gradient(f(xtr) @ c, f.parameters())\n",
        "        ote = torch.stack([gradient(f(x[None]), f.parameters()) @ a for x in xte])\n",
        "    else:\n",
        "        ote = ktetr @ c\n",
        "\n",
        "    final_test_loss = loss_func(args, ote, yte).item()\n",
        "    final_test_preds = torch.sigmoid(ote) > 0.5\n",
        "    final_test_accuracy = (final_test_preds.int() == yte.int()).float().mean().item()\n",
        "\n",
        "    dynamics[-1]['test'] = {\n",
        "        'loss': final_test_loss,\n",
        "        'accuracy': final_test_accuracy,\n",
        "    }\n",
        "\n",
        "    out = {\n",
        "        'dynamics': dynamics,\n",
        "        'train': {\n",
        "            'outputs': otr,\n",
        "            'labels': ytr,\n",
        "        },\n",
        "        'test': {\n",
        "            'outputs': ote,\n",
        "            'labels': yte,\n",
        "        },\n",
        "        'kernel': {\n",
        "            'train': {\n",
        "                'value': ktrtr.cpu() if args.store_kernel == 1 else None,\n",
        "            },\n",
        "            'test': {\n",
        "                'value': ktete.cpu() if args.store_kernel == 1 else None,\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "\n",
        "    return out\n",
        "\n",
        "def execute(args):\n",
        "    torch.set_default_dtype(torch.float64)\n",
        "\n",
        "    dataset = BinaryDataset(args.n, args.k, args.train_size, args.test_size, args.data_seed, args.normalize, args.device)\n",
        "    (xtr, ytr), (xte, yte) = dataset.get_data()\n",
        "\n",
        "    xtr = xtr.type(torch.get_default_dtype())\n",
        "    xte = xte.type(torch.get_default_dtype())\n",
        "    ytr = ytr.type(torch.get_default_dtype())\n",
        "    yte = yte.type(torch.get_default_dtype())\n",
        "\n",
        "    torch.manual_seed(args.init_seed + hash(args.alpha))\n",
        "\n",
        "    act = lambda x: 2 ** 0.5 * torch.relu(x)\n",
        "\n",
        "    xtr = xtr.flatten(1)\n",
        "    xte = xte.flatten(1)\n",
        "    f = FC(xtr.size(1), args.h, args.L, act, args.bias).to(args.device)\n",
        "\n",
        "    if args.delta_kernel == 1 or args.init_kernel == 1:\n",
        "        init_kernel = compute_kernels(f, xtr, xte[:len(xtr)])\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    if args.init_kernel == 1:\n",
        "        results['init_kernel'] = run_kernel(args, *init_kernel, f, xtr, ytr, xte, yte)\n",
        "\n",
        "    if args.delta_kernel == 1:\n",
        "        init_kernel = (init_kernel[0].cpu(), init_kernel[2].cpu())\n",
        "    elif args.init_kernel == 1:\n",
        "        del init_kernel\n",
        "\n",
        "    return {\n",
        "        'args': args,\n",
        "        'results': results\n",
        "    }\n",
        "\n",
        "\n",
        "#####################################\n",
        "\n",
        "args = Args()\n",
        "results_to_save = {'args': args}\n",
        "\n",
        "try:\n",
        "    results = execute(args)\n",
        "    results_to_save.update(results)\n",
        "\n",
        "    with open(args.pickle, 'wb') as f:\n",
        "        torch.save(results_to_save, f)\n",
        "except:\n",
        "    os.remove(args.pickle)\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSMuQJmHzct5",
        "outputId": "6a5ab184-1fd8-4e49-ea9e-09fb04a31f4f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0/1] [len=8 numel=21701]\n",
            "[Step 0/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 1/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 2/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 3/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 4/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 5/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 6/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 7/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 8/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 9/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 10/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 11/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 12/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 13/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 14/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 15/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 16/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 17/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 18/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 19/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 20/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 21/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 22/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 23/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 24/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 25/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 26/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 27/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 28/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 29/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 30/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 31/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 32/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 33/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 34/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 35/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 36/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 37/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 38/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 39/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 40/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 41/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 42/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 43/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 44/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 45/50000] [Time: 1s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 46/50000] [Time: 1s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 47/50000] [Time: 1s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 48/50000] [Time: 1s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 49/50000] [Time: 1s] [Train Loss: 6.93e-01] [Train Acc: 0.55] [Eval Loss: 6.93e-01] [Eval Acc: 0.52]\n",
            "[Step 50/50000] [Time: 2s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 51/50000] [Time: 2s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 52/50000] [Time: 2s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 53/50000] [Time: 2s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 54/50000] [Time: 2s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 55/50000] [Time: 2s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 56/50000] [Time: 2s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 57/50000] [Time: 2s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 58/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 59/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 60/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 61/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 62/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 63/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 64/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 65/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 66/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 67/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 68/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 69/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 70/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 71/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 72/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 73/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 74/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 75/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 76/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 77/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 78/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 79/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 80/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 81/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 82/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 83/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 84/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 85/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 86/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.55]\n",
            "[Step 87/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 88/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 89/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 90/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 91/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 92/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 93/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 94/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 95/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 96/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 97/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 98/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 99/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56] [Eval Loss: 6.93e-01] [Eval Acc: 0.52]\n",
            "[Step 100/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 101/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 103/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 105/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 107/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 109/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 111/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 113/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 115/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 117/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 119/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 121/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 123/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 125/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 127/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 129/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 131/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 133/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 135/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 137/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 139/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 141/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 143/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 145/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 147/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 149/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 151/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 153/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 155/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 157/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 159/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 161/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 163/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 165/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 167/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 169/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 171/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 173/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 175/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 177/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 179/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 181/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 183/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 185/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 187/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 189/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 191/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 193/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 195/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 197/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56] [Eval Loss: 6.93e-01] [Eval Acc: 0.52]\n",
            "[Step 199/50000] [Time: 8s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 201/50000] [Time: 8s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 203/50000] [Time: 8s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 206/50000] [Time: 9s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 209/50000] [Time: 9s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 212/50000] [Time: 9s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 215/50000] [Time: 9s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 218/50000] [Time: 9s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 221/50000] [Time: 9s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 224/50000] [Time: 9s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 227/50000] [Time: 9s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 230/50000] [Time: 9s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 233/50000] [Time: 9s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 236/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 239/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 242/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 245/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 248/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 251/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 254/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 257/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 260/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 263/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 266/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 269/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 272/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 275/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 278/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.58]\n",
            "[Step 281/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.58]\n",
            "[Step 284/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.58]\n",
            "[Step 287/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.58]\n",
            "[Step 290/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.58]\n",
            "[Step 293/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.58]\n",
            "[Step 296/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.58]\n",
            "[Step 299/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.58]\n",
            "[Step 302/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.58]\n",
            "[Step 305/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.59]\n",
            "[Step 309/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.58]\n",
            "[Step 313/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.58]\n",
            "[Step 317/50000] [Time: 10s] [Train Loss: 6.90e-01] [Train Acc: 0.58]\n",
            "[Step 321/50000] [Time: 10s] [Train Loss: 6.90e-01] [Train Acc: 0.58]\n",
            "[Step 325/50000] [Time: 10s] [Train Loss: 6.90e-01] [Train Acc: 0.59]\n",
            "[Step 329/50000] [Time: 10s] [Train Loss: 6.90e-01] [Train Acc: 0.59]\n",
            "[Step 333/50000] [Time: 10s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 337/50000] [Time: 10s] [Train Loss: 6.89e-01] [Train Acc: 0.59]\n",
            "[Step 341/50000] [Time: 10s] [Train Loss: 6.89e-01] [Train Acc: 0.59]\n",
            "[Step 345/50000] [Time: 10s] [Train Loss: 6.89e-01] [Train Acc: 0.59]\n",
            "[Step 349/50000] [Time: 10s] [Train Loss: 6.89e-01] [Train Acc: 0.59]\n",
            "[Step 353/50000] [Time: 10s] [Train Loss: 6.89e-01] [Train Acc: 0.59]\n",
            "[Step 357/50000] [Time: 10s] [Train Loss: 6.88e-01] [Train Acc: 0.59] [Eval Loss: 6.91e-01] [Eval Acc: 0.53]\n",
            "[Step 361/50000] [Time: 12s] [Train Loss: 6.88e-01] [Train Acc: 0.59]\n",
            "[Step 365/50000] [Time: 12s] [Train Loss: 6.88e-01] [Train Acc: 0.59]\n",
            "[Step 369/50000] [Time: 12s] [Train Loss: 6.88e-01] [Train Acc: 0.59]\n",
            "[Step 373/50000] [Time: 12s] [Train Loss: 6.88e-01] [Train Acc: 0.59]\n",
            "[Step 377/50000] [Time: 12s] [Train Loss: 6.88e-01] [Train Acc: 0.59]\n",
            "[Step 381/50000] [Time: 12s] [Train Loss: 6.87e-01] [Train Acc: 0.59]\n",
            "[Step 385/50000] [Time: 12s] [Train Loss: 6.87e-01] [Train Acc: 0.59]\n",
            "[Step 389/50000] [Time: 12s] [Train Loss: 6.87e-01] [Train Acc: 0.59]\n",
            "[Step 393/50000] [Time: 12s] [Train Loss: 6.87e-01] [Train Acc: 0.59]\n",
            "[Step 397/50000] [Time: 12s] [Train Loss: 6.87e-01] [Train Acc: 0.59]\n",
            "[Step 401/50000] [Time: 12s] [Train Loss: 6.86e-01] [Train Acc: 0.59]\n",
            "[Step 405/50000] [Time: 12s] [Train Loss: 6.86e-01] [Train Acc: 0.59]\n",
            "[Step 409/50000] [Time: 12s] [Train Loss: 6.86e-01] [Train Acc: 0.59]\n",
            "[Step 414/50000] [Time: 12s] [Train Loss: 6.86e-01] [Train Acc: 0.59]\n",
            "[Step 419/50000] [Time: 12s] [Train Loss: 6.86e-01] [Train Acc: 0.59]\n",
            "[Step 424/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.60]\n",
            "[Step 429/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.60]\n",
            "[Step 434/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.60]\n",
            "[Step 439/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.60]\n",
            "[Step 444/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.60]\n",
            "[Step 449/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.60]\n",
            "[Step 454/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.60]\n",
            "[Step 459/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.60]\n",
            "[Step 464/50000] [Time: 12s] [Train Loss: 6.83e-01] [Train Acc: 0.60]\n",
            "[Step 469/50000] [Time: 12s] [Train Loss: 6.83e-01] [Train Acc: 0.60]\n",
            "[Step 474/50000] [Time: 13s] [Train Loss: 6.83e-01] [Train Acc: 0.60]\n",
            "[Step 479/50000] [Time: 13s] [Train Loss: 6.83e-01] [Train Acc: 0.60]\n",
            "[Step 484/50000] [Time: 13s] [Train Loss: 6.82e-01] [Train Acc: 0.60]\n",
            "[Step 489/50000] [Time: 13s] [Train Loss: 6.82e-01] [Train Acc: 0.60]\n",
            "[Step 494/50000] [Time: 13s] [Train Loss: 6.82e-01] [Train Acc: 0.60]\n",
            "[Step 499/50000] [Time: 13s] [Train Loss: 6.81e-01] [Train Acc: 0.61]\n",
            "[Step 504/50000] [Time: 13s] [Train Loss: 6.81e-01] [Train Acc: 0.61]\n",
            "[Step 509/50000] [Time: 13s] [Train Loss: 6.81e-01] [Train Acc: 0.61]\n",
            "[Step 514/50000] [Time: 13s] [Train Loss: 6.81e-01] [Train Acc: 0.61]\n",
            "[Step 520/50000] [Time: 13s] [Train Loss: 6.80e-01] [Train Acc: 0.61]\n",
            "[Step 526/50000] [Time: 13s] [Train Loss: 6.80e-01] [Train Acc: 0.61]\n",
            "[Step 532/50000] [Time: 13s] [Train Loss: 6.79e-01] [Train Acc: 0.61]\n",
            "[Step 538/50000] [Time: 13s] [Train Loss: 6.79e-01] [Train Acc: 0.61]\n",
            "[Step 544/50000] [Time: 13s] [Train Loss: 6.79e-01] [Train Acc: 0.61]\n",
            "[Step 550/50000] [Time: 13s] [Train Loss: 6.78e-01] [Train Acc: 0.61]\n",
            "[Step 556/50000] [Time: 13s] [Train Loss: 6.78e-01] [Train Acc: 0.61]\n",
            "[Step 562/50000] [Time: 13s] [Train Loss: 6.78e-01] [Train Acc: 0.61]\n",
            "[Step 568/50000] [Time: 13s] [Train Loss: 6.77e-01] [Train Acc: 0.61]\n",
            "[Step 574/50000] [Time: 13s] [Train Loss: 6.77e-01] [Train Acc: 0.61]\n",
            "[Step 580/50000] [Time: 13s] [Train Loss: 6.76e-01] [Train Acc: 0.61]\n",
            "[Step 586/50000] [Time: 13s] [Train Loss: 6.76e-01] [Train Acc: 0.61]\n",
            "[Step 592/50000] [Time: 13s] [Train Loss: 6.75e-01] [Train Acc: 0.61]\n",
            "[Step 598/50000] [Time: 13s] [Train Loss: 6.75e-01] [Train Acc: 0.61]\n",
            "[Step 604/50000] [Time: 13s] [Train Loss: 6.75e-01] [Train Acc: 0.61]\n",
            "[Step 610/50000] [Time: 14s] [Train Loss: 6.74e-01] [Train Acc: 0.62] [Eval Loss: 6.85e-01] [Eval Acc: 0.55]\n",
            "[Step 616/50000] [Time: 17s] [Train Loss: 6.74e-01] [Train Acc: 0.61]\n",
            "[Step 622/50000] [Time: 17s] [Train Loss: 6.73e-01] [Train Acc: 0.61]\n",
            "[Step 629/50000] [Time: 17s] [Train Loss: 6.73e-01] [Train Acc: 0.61]\n",
            "[Step 636/50000] [Time: 17s] [Train Loss: 6.72e-01] [Train Acc: 0.61]\n",
            "[Step 643/50000] [Time: 17s] [Train Loss: 6.71e-01] [Train Acc: 0.61]\n",
            "[Step 650/50000] [Time: 17s] [Train Loss: 6.71e-01] [Train Acc: 0.61]\n",
            "[Step 657/50000] [Time: 17s] [Train Loss: 6.70e-01] [Train Acc: 0.62]\n",
            "[Step 664/50000] [Time: 17s] [Train Loss: 6.70e-01] [Train Acc: 0.62]\n",
            "[Step 671/50000] [Time: 17s] [Train Loss: 6.69e-01] [Train Acc: 0.62]\n",
            "[Step 678/50000] [Time: 17s] [Train Loss: 6.68e-01] [Train Acc: 0.62]\n",
            "[Step 685/50000] [Time: 17s] [Train Loss: 6.68e-01] [Train Acc: 0.62]\n",
            "[Step 692/50000] [Time: 17s] [Train Loss: 6.67e-01] [Train Acc: 0.62]\n",
            "[Step 699/50000] [Time: 17s] [Train Loss: 6.67e-01] [Train Acc: 0.62]\n",
            "[Step 706/50000] [Time: 18s] [Train Loss: 6.66e-01] [Train Acc: 0.62]\n",
            "[Step 713/50000] [Time: 18s] [Train Loss: 6.65e-01] [Train Acc: 0.62]\n",
            "[Step 720/50000] [Time: 18s] [Train Loss: 6.65e-01] [Train Acc: 0.63]\n",
            "[Step 727/50000] [Time: 18s] [Train Loss: 6.64e-01] [Train Acc: 0.63]\n",
            "[Step 735/50000] [Time: 18s] [Train Loss: 6.63e-01] [Train Acc: 0.63]\n",
            "[Step 743/50000] [Time: 18s] [Train Loss: 6.62e-01] [Train Acc: 0.63]\n",
            "[Step 751/50000] [Time: 18s] [Train Loss: 6.61e-01] [Train Acc: 0.63]\n",
            "[Step 759/50000] [Time: 18s] [Train Loss: 6.61e-01] [Train Acc: 0.63]\n",
            "[Step 767/50000] [Time: 18s] [Train Loss: 6.60e-01] [Train Acc: 0.63]\n",
            "[Step 775/50000] [Time: 18s] [Train Loss: 6.59e-01] [Train Acc: 0.63]\n",
            "[Step 783/50000] [Time: 18s] [Train Loss: 6.58e-01] [Train Acc: 0.63]\n",
            "[Step 791/50000] [Time: 18s] [Train Loss: 6.57e-01] [Train Acc: 0.63]\n",
            "[Step 799/50000] [Time: 18s] [Train Loss: 6.56e-01] [Train Acc: 0.64]\n",
            "[Step 807/50000] [Time: 18s] [Train Loss: 6.55e-01] [Train Acc: 0.64]\n",
            "[Step 815/50000] [Time: 18s] [Train Loss: 6.55e-01] [Train Acc: 0.64]\n",
            "[Step 823/50000] [Time: 18s] [Train Loss: 6.54e-01] [Train Acc: 0.64]\n",
            "[Step 831/50000] [Time: 19s] [Train Loss: 6.53e-01] [Train Acc: 0.64]\n",
            "[Step 839/50000] [Time: 19s] [Train Loss: 6.52e-01] [Train Acc: 0.64]\n",
            "[Step 848/50000] [Time: 19s] [Train Loss: 6.51e-01] [Train Acc: 0.64]\n",
            "[Step 857/50000] [Time: 19s] [Train Loss: 6.50e-01] [Train Acc: 0.65]\n",
            "[Step 866/50000] [Time: 19s] [Train Loss: 6.49e-01] [Train Acc: 0.65]\n",
            "[Step 875/50000] [Time: 19s] [Train Loss: 6.47e-01] [Train Acc: 0.65]\n",
            "[Step 884/50000] [Time: 19s] [Train Loss: 6.46e-01] [Train Acc: 0.66]\n",
            "[Step 893/50000] [Time: 19s] [Train Loss: 6.45e-01] [Train Acc: 0.66]\n",
            "[Step 902/50000] [Time: 19s] [Train Loss: 6.44e-01] [Train Acc: 0.66]\n",
            "[Step 911/50000] [Time: 19s] [Train Loss: 6.43e-01] [Train Acc: 0.66]\n",
            "[Step 920/50000] [Time: 19s] [Train Loss: 6.42e-01] [Train Acc: 0.67]\n",
            "[Step 929/50000] [Time: 19s] [Train Loss: 6.41e-01] [Train Acc: 0.67]\n",
            "[Step 938/50000] [Time: 20s] [Train Loss: 6.39e-01] [Train Acc: 0.67]\n",
            "[Step 947/50000] [Time: 20s] [Train Loss: 6.38e-01] [Train Acc: 0.67]\n",
            "[Step 957/50000] [Time: 20s] [Train Loss: 6.37e-01] [Train Acc: 0.67]\n",
            "[Step 967/50000] [Time: 20s] [Train Loss: 6.35e-01] [Train Acc: 0.68]\n",
            "[Step 977/50000] [Time: 20s] [Train Loss: 6.34e-01] [Train Acc: 0.68]\n",
            "[Step 987/50000] [Time: 20s] [Train Loss: 6.32e-01] [Train Acc: 0.68]\n",
            "[Step 997/50000] [Time: 20s] [Train Loss: 6.31e-01] [Train Acc: 0.68]\n",
            "[Step 1007/50000] [Time: 20s] [Train Loss: 6.29e-01] [Train Acc: 0.68]\n",
            "[Step 1017/50000] [Time: 20s] [Train Loss: 6.27e-01] [Train Acc: 0.68] [Eval Loss: 6.66e-01] [Eval Acc: 0.59]\n",
            "[Step 1027/50000] [Time: 24s] [Train Loss: 6.26e-01] [Train Acc: 0.68]\n",
            "[Step 1037/50000] [Time: 24s] [Train Loss: 6.24e-01] [Train Acc: 0.69]\n",
            "[Step 1047/50000] [Time: 24s] [Train Loss: 6.22e-01] [Train Acc: 0.69]\n",
            "[Step 1057/50000] [Time: 24s] [Train Loss: 6.20e-01] [Train Acc: 0.69]\n",
            "[Step 1068/50000] [Time: 24s] [Train Loss: 6.18e-01] [Train Acc: 0.69]\n",
            "[Step 1079/50000] [Time: 24s] [Train Loss: 6.16e-01] [Train Acc: 0.69]\n",
            "[Step 1090/50000] [Progress: 2.18%] [learning rate: 7.5e+02]\n",
            "[Step 1090/50000] [Time: 24s] [Train Loss: 6.14e-01] [Train Acc: 0.70]\n",
            "[Step 1101/50000] [Time: 24s] [Train Loss: 6.14e-01] [Train Acc: 0.70]\n",
            "[Step 1112/50000] [Time: 25s] [Train Loss: 6.13e-01] [Train Acc: 0.70]\n",
            "[Step 1123/50000] [Time: 25s] [Train Loss: 6.11e-01] [Train Acc: 0.70]\n",
            "[Step 1134/50000] [Time: 25s] [Train Loss: 6.09e-01] [Train Acc: 0.70]\n",
            "[Step 1136/50000] [Progress: 2.27%] [learning rate: 9.0e+02]\n",
            "[Step 1145/50000] [Time: 25s] [Train Loss: 6.08e-01] [Train Acc: 0.70]\n",
            "[Step 1156/50000] [Time: 25s] [Train Loss: 6.07e-01] [Train Acc: 0.71]\n",
            "[Step 1167/50000] [Time: 25s] [Train Loss: 6.05e-01] [Train Acc: 0.71]\n",
            "[Step 1177/50000] [Progress: 2.35%] [learning rate: 1.1e+03]\n",
            "[Step 1179/50000] [Time: 25s] [Train Loss: 6.03e-01] [Train Acc: 0.71]\n",
            "[Step 1191/50000] [Time: 25s] [Train Loss: 6.02e-01] [Train Acc: 0.71]\n",
            "[Step 1203/50000] [Time: 25s] [Train Loss: 6.00e-01] [Train Acc: 0.71]\n",
            "[Step 1215/50000] [Progress: 2.43%] [learning rate: 1.2e+03]\n",
            "[Step 1215/50000] [Time: 25s] [Train Loss: 5.97e-01] [Train Acc: 0.71]\n",
            "[Step 1227/50000] [Time: 26s] [Train Loss: 5.97e-01] [Train Acc: 0.72]\n",
            "[Step 1239/50000] [Time: 26s] [Train Loss: 5.95e-01] [Train Acc: 0.72]\n",
            "[Step 1251/50000] [Time: 26s] [Train Loss: 5.92e-01] [Train Acc: 0.72]\n",
            "[Step 1254/50000] [Progress: 2.51%] [learning rate: 1.3e+03]\n",
            "[Step 1263/50000] [Time: 26s] [Train Loss: 5.91e-01] [Train Acc: 0.72]\n",
            "[Step 1275/50000] [Time: 26s] [Train Loss: 5.90e-01] [Train Acc: 0.72]\n",
            "[Step 1287/50000] [Time: 26s] [Train Loss: 5.87e-01] [Train Acc: 0.73]\n",
            "[Step 1290/50000] [Progress: 2.58%] [learning rate: 1.4e+03]\n",
            "[Step 1300/50000] [Time: 26s] [Train Loss: 5.86e-01] [Train Acc: 0.73]\n",
            "[Step 1313/50000] [Time: 26s] [Train Loss: 5.84e-01] [Train Acc: 0.73]\n",
            "[Step 1325/50000] [Progress: 2.65%] [learning rate: 1.5e+03]\n",
            "[Step 1326/50000] [Time: 26s] [Train Loss: 5.81e-01] [Train Acc: 0.73]\n",
            "[Step 1339/50000] [Time: 26s] [Train Loss: 5.81e-01] [Train Acc: 0.73]\n",
            "[Step 1352/50000] [Time: 27s] [Train Loss: 5.78e-01] [Train Acc: 0.73]\n",
            "[Step 1359/50000] [Progress: 2.72%] [learning rate: 1.6e+03]\n",
            "[Step 1365/50000] [Time: 27s] [Train Loss: 5.76e-01] [Train Acc: 0.74]\n",
            "[Step 1378/50000] [Time: 27s] [Train Loss: 5.75e-01] [Train Acc: 0.74]\n",
            "[Step 1391/50000] [Time: 27s] [Train Loss: 5.72e-01] [Train Acc: 0.74]\n",
            "[Step 1392/50000] [Progress: 2.78%] [learning rate: 1.7e+03]\n",
            "[Step 1404/50000] [Time: 27s] [Train Loss: 5.71e-01] [Train Acc: 0.74]\n",
            "[Step 1418/50000] [Time: 27s] [Train Loss: 5.68e-01] [Train Acc: 0.75]\n",
            "[Step 1425/50000] [Progress: 2.85%] [learning rate: 1.9e+03]\n",
            "[Step 1432/50000] [Time: 27s] [Train Loss: 5.66e-01] [Train Acc: 0.75]\n",
            "[Step 1446/50000] [Time: 27s] [Train Loss: 5.65e-01] [Train Acc: 0.75]\n",
            "[Step 1457/50000] [Progress: 2.91%] [learning rate: 2.0e+03]\n",
            "[Step 1460/50000] [Time: 27s] [Train Loss: 5.62e-01] [Train Acc: 0.75]\n",
            "[Step 1474/50000] [Time: 27s] [Train Loss: 5.60e-01] [Train Acc: 0.75]\n",
            "[Step 1487/50000] [Progress: 2.97%] [learning rate: 2.2e+03]\n",
            "[Step 1488/50000] [Time: 28s] [Train Loss: 5.57e-01] [Train Acc: 0.75]\n",
            "[Step 1502/50000] [Time: 28s] [Train Loss: 5.56e-01] [Train Acc: 0.75]\n",
            "[Step 1516/50000] [Progress: 3.03%] [learning rate: 2.2e+03]\n",
            "[Step 1516/50000] [Time: 28s] [Train Loss: 5.53e-01] [Train Acc: 0.76]\n",
            "[Step 1531/50000] [Time: 28s] [Train Loss: 5.52e-01] [Train Acc: 0.76]\n",
            "[Step 1546/50000] [Time: 28s] [Train Loss: 5.48e-01] [Train Acc: 0.76]\n",
            "[Step 1547/50000] [Progress: 3.09%] [learning rate: 2.4e+03]\n",
            "[Step 1561/50000] [Time: 28s] [Train Loss: 5.47e-01] [Train Acc: 0.76]\n",
            "[Step 1576/50000] [Progress: 3.15%] [learning rate: 2.6e+03]\n",
            "[Step 1576/50000] [Time: 28s] [Train Loss: 5.44e-01] [Train Acc: 0.76]\n",
            "[Step 1591/50000] [Time: 28s] [Train Loss: 5.43e-01] [Train Acc: 0.76]\n",
            "[Step 1602/50000] [Progress: 3.20%] [learning rate: 2.5e+03]\n",
            "[Step 1606/50000] [Time: 28s] [Train Loss: 5.41e-01] [Train Acc: 0.77]\n",
            "[Step 1621/50000] [Time: 28s] [Train Loss: 5.39e-01] [Train Acc: 0.77]\n",
            "[Step 1628/50000] [Progress: 3.26%] [learning rate: 2.7e+03]\n",
            "[Step 1636/50000] [Time: 29s] [Train Loss: 5.37e-01] [Train Acc: 0.77]\n",
            "[Step 1652/50000] [Time: 29s] [Train Loss: 5.34e-01] [Train Acc: 0.77] [Eval Loss: 6.29e-01] [Eval Acc: 0.65]\n",
            "[Step 1654/50000] [Progress: 3.31%] [learning rate: 2.7e+03]\n",
            "[Step 1668/50000] [Time: 31s] [Train Loss: 5.33e-01] [Train Acc: 0.77]\n",
            "[Step 1681/50000] [Progress: 3.36%] [learning rate: 2.9e+03]\n",
            "[Step 1684/50000] [Time: 31s] [Train Loss: 5.30e-01] [Train Acc: 0.78]\n",
            "[Step 1700/50000] [Time: 31s] [Train Loss: 5.28e-01] [Train Acc: 0.78]\n",
            "[Step 1706/50000] [Progress: 3.41%] [learning rate: 2.9e+03]\n",
            "[Step 1716/50000] [Time: 31s] [Train Loss: 5.26e-01] [Train Acc: 0.78]\n",
            "[Step 1730/50000] [Progress: 3.46%] [learning rate: 2.6e+03]\n",
            "[Step 1732/50000] [Time: 31s] [Train Loss: 5.24e-01] [Train Acc: 0.78]\n",
            "[Step 1748/50000] [Time: 31s] [Train Loss: 5.23e-01] [Train Acc: 0.78]\n",
            "[Step 1756/50000] [Progress: 3.51%] [learning rate: 3.1e+03]\n",
            "[Step 1765/50000] [Time: 31s] [Train Loss: 5.20e-01] [Train Acc: 0.78]\n",
            "[Step 1780/50000] [Progress: 3.56%] [learning rate: 2.7e+03]\n",
            "[Step 1782/50000] [Time: 31s] [Train Loss: 5.18e-01] [Train Acc: 0.79]\n",
            "[Step 1799/50000] [Time: 31s] [Train Loss: 5.16e-01] [Train Acc: 0.79]\n",
            "[Step 1807/50000] [Progress: 3.61%] [learning rate: 3.0e+03]\n",
            "[Step 1816/50000] [Time: 32s] [Train Loss: 5.14e-01] [Train Acc: 0.79]\n",
            "[Step 1832/50000] [Progress: 3.66%] [learning rate: 2.9e+03]\n",
            "[Step 1833/50000] [Time: 32s] [Train Loss: 5.12e-01] [Train Acc: 0.79]\n",
            "[Step 1850/50000] [Time: 32s] [Train Loss: 5.10e-01] [Train Acc: 0.79]\n",
            "[Step 1858/50000] [Progress: 3.72%] [learning rate: 2.9e+03]\n",
            "[Step 1867/50000] [Time: 32s] [Train Loss: 5.08e-01] [Train Acc: 0.79]\n",
            "[Step 1883/50000] [Progress: 3.77%] [learning rate: 2.8e+03]\n",
            "[Step 1885/50000] [Time: 32s] [Train Loss: 5.06e-01] [Train Acc: 0.79]\n",
            "[Step 1903/50000] [Time: 32s] [Train Loss: 5.04e-01] [Train Acc: 0.80]\n",
            "[Step 1909/50000] [Progress: 3.82%] [learning rate: 3.1e+03]\n",
            "[Step 1921/50000] [Time: 32s] [Train Loss: 5.03e-01] [Train Acc: 0.80]\n",
            "[Step 1933/50000] [Progress: 3.87%] [learning rate: 2.7e+03]\n",
            "[Step 1939/50000] [Time: 33s] [Train Loss: 5.01e-01] [Train Acc: 0.80]\n",
            "[Step 1957/50000] [Time: 33s] [Train Loss: 4.98e-01] [Train Acc: 0.80]\n",
            "[Step 1960/50000] [Progress: 3.92%] [learning rate: 3.3e+03]\n",
            "[Step 1975/50000] [Time: 33s] [Train Loss: 4.97e-01] [Train Acc: 0.80]\n",
            "[Step 1984/50000] [Progress: 3.97%] [learning rate: 2.7e+03]\n",
            "[Step 1993/50000] [Time: 33s] [Train Loss: 4.95e-01] [Train Acc: 0.80]\n",
            "[Step 2010/50000] [Progress: 4.02%] [learning rate: 3.2e+03]\n",
            "[Step 2012/50000] [Time: 33s] [Train Loss: 4.93e-01] [Train Acc: 0.80]\n",
            "[Step 2031/50000] [Time: 33s] [Train Loss: 4.91e-01] [Train Acc: 0.80]\n",
            "[Step 2033/50000] [Progress: 4.07%] [learning rate: 2.8e+03]\n",
            "[Step 2050/50000] [Time: 33s] [Train Loss: 4.89e-01] [Train Acc: 0.80]\n",
            "[Step 2059/50000] [Progress: 4.12%] [learning rate: 3.1e+03]\n",
            "[Step 2069/50000] [Time: 34s] [Train Loss: 4.87e-01] [Train Acc: 0.81]\n",
            "[Step 2086/50000] [Progress: 4.17%] [learning rate: 3.7e+03]\n",
            "[Step 2088/50000] [Time: 34s] [Train Loss: 4.85e-01] [Train Acc: 0.81]\n",
            "[Step 2107/50000] [Progress: 4.21%] [learning rate: 2.5e+03]\n",
            "[Step 2107/50000] [Time: 34s] [Train Loss: 4.83e-01] [Train Acc: 0.81]\n",
            "[Step 2126/50000] [Time: 34s] [Train Loss: 4.82e-01] [Train Acc: 0.81]\n",
            "[Step 2136/50000] [Progress: 4.27%] [learning rate: 3.2e+03]\n",
            "[Step 2146/50000] [Time: 34s] [Train Loss: 4.80e-01] [Train Acc: 0.81]\n",
            "[Step 2161/50000] [Progress: 4.32%] [learning rate: 2.9e+03]\n",
            "[Step 2166/50000] [Time: 34s] [Train Loss: 4.78e-01] [Train Acc: 0.81]\n",
            "[Step 2186/50000] [Time: 35s] [Train Loss: 4.75e-01] [Train Acc: 0.82]\n",
            "[Step 2188/50000] [Progress: 4.38%] [learning rate: 3.1e+03]\n",
            "[Step 2206/50000] [Time: 35s] [Train Loss: 4.74e-01] [Train Acc: 0.82]\n",
            "[Step 2214/50000] [Progress: 4.43%] [learning rate: 3.1e+03]\n",
            "[Step 2226/50000] [Time: 35s] [Train Loss: 4.72e-01] [Train Acc: 0.82]\n",
            "[Step 2239/50000] [Progress: 4.48%] [learning rate: 3.0e+03]\n",
            "[Step 2246/50000] [Time: 35s] [Train Loss: 4.70e-01] [Train Acc: 0.82]\n",
            "[Step 2265/50000] [Progress: 4.53%] [learning rate: 3.0e+03]\n",
            "[Step 2267/50000] [Time: 35s] [Train Loss: 4.68e-01] [Train Acc: 0.82]\n",
            "[Step 2288/50000] [Time: 36s] [Train Loss: 4.66e-01] [Train Acc: 0.82]\n",
            "[Step 2291/50000] [Progress: 4.58%] [learning rate: 3.0e+03]\n",
            "[Step 2309/50000] [Time: 36s] [Train Loss: 4.65e-01] [Train Acc: 0.83]\n",
            "[Step 2316/50000] [Progress: 4.63%] [learning rate: 2.9e+03]\n",
            "[Step 2330/50000] [Time: 36s] [Train Loss: 4.63e-01] [Train Acc: 0.83]\n",
            "[Step 2342/50000] [Progress: 4.68%] [learning rate: 3.2e+03]\n",
            "[Step 2351/50000] [Time: 36s] [Train Loss: 4.61e-01] [Train Acc: 0.83]\n",
            "[Step 2368/50000] [Progress: 4.74%] [learning rate: 3.4e+03]\n",
            "[Step 2372/50000] [Time: 36s] [Train Loss: 4.59e-01] [Train Acc: 0.83]\n",
            "[Step 2391/50000] [Progress: 4.78%] [learning rate: 2.8e+03]\n",
            "[Step 2394/50000] [Time: 36s] [Train Loss: 4.57e-01] [Train Acc: 0.83]\n",
            "[Step 2416/50000] [Time: 37s] [Train Loss: 4.56e-01] [Train Acc: 0.83]\n",
            "[Step 2419/50000] [Progress: 4.84%] [learning rate: 3.3e+03]\n",
            "[Step 2438/50000] [Time: 37s] [Train Loss: 4.54e-01] [Train Acc: 0.83]\n",
            "[Step 2444/50000] [Progress: 4.89%] [learning rate: 3.0e+03]\n",
            "[Step 2460/50000] [Time: 37s] [Train Loss: 4.52e-01] [Train Acc: 0.84]\n",
            "[Step 2471/50000] [Progress: 4.94%] [learning rate: 3.2e+03]\n",
            "[Step 2482/50000] [Time: 37s] [Train Loss: 4.50e-01] [Train Acc: 0.84]\n",
            "[Step 2498/50000] [Progress: 5.00%] [learning rate: 3.5e+03]\n",
            "[Step 2504/50000] [Time: 37s] [Train Loss: 4.48e-01] [Train Acc: 0.84]\n",
            "[Step 2521/50000] [Progress: 5.04%] [learning rate: 2.8e+03]\n",
            "[Step 2527/50000] [Time: 37s] [Train Loss: 4.47e-01] [Train Acc: 0.84]\n",
            "[Step 2548/50000] [Progress: 5.10%] [learning rate: 3.4e+03]\n",
            "[Step 2550/50000] [Time: 38s] [Train Loss: 4.45e-01] [Train Acc: 0.84]\n",
            "[Step 2571/50000] [Progress: 5.14%] [learning rate: 3.0e+03]\n",
            "[Step 2573/50000] [Time: 38s] [Train Loss: 4.43e-01] [Train Acc: 0.84]\n",
            "[Step 2596/50000] [Progress: 5.19%] [learning rate: 3.3e+03]\n",
            "[Step 2596/50000] [Time: 38s] [Train Loss: 4.41e-01] [Train Acc: 0.84]\n",
            "[Step 2619/50000] [Time: 38s] [Train Loss: 4.39e-01] [Train Acc: 0.84] [Eval Loss: 5.88e-01] [Eval Acc: 0.68]\n",
            "[Step 2621/50000] [Progress: 5.24%] [learning rate: 3.2e+03]\n",
            "[Step 2643/50000] [Time: 40s] [Train Loss: 4.38e-01] [Train Acc: 0.84]\n",
            "[Step 2647/50000] [Progress: 5.29%] [learning rate: 3.2e+03]\n",
            "[Step 2667/50000] [Time: 40s] [Train Loss: 4.36e-01] [Train Acc: 0.85]\n",
            "[Step 2671/50000] [Progress: 5.34%] [learning rate: 3.1e+03]\n",
            "[Step 2691/50000] [Time: 40s] [Train Loss: 4.34e-01] [Train Acc: 0.85]\n",
            "[Step 2696/50000] [Progress: 5.39%] [learning rate: 3.1e+03]\n",
            "[Step 2715/50000] [Time: 40s] [Train Loss: 4.33e-01] [Train Acc: 0.85]\n",
            "[Step 2721/50000] [Progress: 5.44%] [learning rate: 3.0e+03]\n",
            "[Step 2739/50000] [Time: 41s] [Train Loss: 4.31e-01] [Train Acc: 0.85]\n",
            "[Step 2747/50000] [Progress: 5.49%] [learning rate: 3.3e+03]\n",
            "[Step 2763/50000] [Time: 41s] [Train Loss: 4.29e-01] [Train Acc: 0.85]\n",
            "[Step 2773/50000] [Progress: 5.55%] [learning rate: 3.6e+03]\n",
            "[Step 2788/50000] [Time: 41s] [Train Loss: 4.28e-01] [Train Acc: 0.85]\n",
            "[Step 2796/50000] [Progress: 5.59%] [learning rate: 2.9e+03]\n",
            "[Step 2813/50000] [Time: 41s] [Train Loss: 4.26e-01] [Train Acc: 0.85]\n",
            "[Step 2823/50000] [Progress: 5.65%] [learning rate: 3.5e+03]\n",
            "[Step 2838/50000] [Time: 41s] [Train Loss: 4.24e-01] [Train Acc: 0.85]\n",
            "[Step 2846/50000] [Progress: 5.69%] [learning rate: 3.1e+03]\n",
            "[Step 2863/50000] [Time: 41s] [Train Loss: 4.23e-01] [Train Acc: 0.85]\n",
            "[Step 2872/50000] [Progress: 5.74%] [learning rate: 3.4e+03]\n",
            "[Step 2888/50000] [Time: 42s] [Train Loss: 4.21e-01] [Train Acc: 0.85]\n",
            "[Step 2898/50000] [Progress: 5.80%] [learning rate: 3.6e+03]\n",
            "[Step 2914/50000] [Time: 42s] [Train Loss: 4.19e-01] [Train Acc: 0.85]\n",
            "[Step 2921/50000] [Progress: 5.84%] [learning rate: 3.0e+03]\n",
            "[Step 2940/50000] [Time: 42s] [Train Loss: 4.18e-01] [Train Acc: 0.86]\n",
            "[Step 2948/50000] [Progress: 5.90%] [learning rate: 3.5e+03]\n",
            "[Step 2966/50000] [Time: 42s] [Train Loss: 4.16e-01] [Train Acc: 0.86]\n",
            "[Step 2971/50000] [Progress: 5.94%] [learning rate: 3.2e+03]\n",
            "[Step 2992/50000] [Time: 42s] [Train Loss: 4.14e-01] [Train Acc: 0.86]\n",
            "[Step 2996/50000] [Progress: 5.99%] [learning rate: 3.4e+03]\n",
            "[Step 3018/50000] [Time: 43s] [Train Loss: 4.12e-01] [Train Acc: 0.86]\n",
            "[Step 3020/50000] [Progress: 6.04%] [learning rate: 3.4e+03]\n",
            "[Step 3045/50000] [Progress: 6.09%] [learning rate: 3.3e+03]\n",
            "[Step 3045/50000] [Time: 43s] [Train Loss: 4.10e-01] [Train Acc: 0.86]\n",
            "[Step 3069/50000] [Progress: 6.14%] [learning rate: 3.3e+03]\n",
            "[Step 3072/50000] [Time: 43s] [Train Loss: 4.09e-01] [Train Acc: 0.86]\n",
            "[Step 3094/50000] [Progress: 6.19%] [learning rate: 3.2e+03]\n",
            "[Step 3099/50000] [Time: 43s] [Train Loss: 4.07e-01] [Train Acc: 0.86]\n",
            "[Step 3120/50000] [Progress: 6.24%] [learning rate: 3.5e+03]\n",
            "[Step 3126/50000] [Time: 43s] [Train Loss: 4.06e-01] [Train Acc: 0.86]\n",
            "[Step 3144/50000] [Progress: 6.29%] [learning rate: 3.1e+03]\n",
            "[Step 3153/50000] [Time: 44s] [Train Loss: 4.04e-01] [Train Acc: 0.86]\n",
            "[Step 3171/50000] [Progress: 6.34%] [learning rate: 3.7e+03]\n",
            "[Step 3181/50000] [Time: 44s] [Train Loss: 4.02e-01] [Train Acc: 0.87]\n",
            "[Step 3195/50000] [Progress: 6.39%] [learning rate: 3.3e+03]\n",
            "[Step 3209/50000] [Time: 44s] [Train Loss: 4.01e-01] [Train Acc: 0.87]\n",
            "[Step 3220/50000] [Progress: 6.44%] [learning rate: 3.3e+03]\n",
            "[Step 3237/50000] [Time: 44s] [Train Loss: 3.99e-01] [Train Acc: 0.87]\n",
            "[Step 3246/50000] [Progress: 6.49%] [learning rate: 3.6e+03]\n",
            "[Step 3265/50000] [Time: 44s] [Train Loss: 3.97e-01] [Train Acc: 0.87]\n",
            "[Step 3269/50000] [Progress: 6.54%] [learning rate: 3.2e+03]\n",
            "[Step 3293/50000] [Time: 45s] [Train Loss: 3.96e-01] [Train Acc: 0.87]\n",
            "[Step 3295/50000] [Progress: 6.59%] [learning rate: 3.8e+03]\n",
            "[Step 3318/50000] [Progress: 6.64%] [learning rate: 3.1e+03]\n",
            "[Step 3322/50000] [Time: 45s] [Train Loss: 3.94e-01] [Train Acc: 0.87]\n",
            "[Step 3344/50000] [Progress: 6.69%] [learning rate: 3.4e+03]\n",
            "[Step 3351/50000] [Time: 45s] [Train Loss: 3.92e-01] [Train Acc: 0.87]\n",
            "[Step 3368/50000] [Progress: 6.74%] [learning rate: 3.3e+03]\n",
            "[Step 3380/50000] [Time: 45s] [Train Loss: 3.91e-01] [Train Acc: 0.87]\n",
            "[Step 3393/50000] [Progress: 6.79%] [learning rate: 3.6e+03]\n",
            "[Step 3409/50000] [Time: 46s] [Train Loss: 3.89e-01] [Train Acc: 0.88]\n",
            "[Step 3417/50000] [Progress: 6.83%] [learning rate: 3.2e+03]\n",
            "[Step 3438/50000] [Time: 46s] [Train Loss: 3.88e-01] [Train Acc: 0.88]\n",
            "[Step 3445/50000] [Progress: 6.89%] [learning rate: 4.2e+03]\n",
            "[Step 3466/50000] [Progress: 6.93%] [learning rate: 2.8e+03]\n",
            "[Step 3468/50000] [Time: 46s] [Train Loss: 3.86e-01] [Train Acc: 0.88]\n",
            "[Step 3493/50000] [Progress: 6.99%] [learning rate: 3.7e+03]\n",
            "[Step 3498/50000] [Time: 46s] [Train Loss: 3.84e-01] [Train Acc: 0.88]\n",
            "[Step 3516/50000] [Progress: 7.03%] [learning rate: 3.3e+03]\n",
            "[Step 3528/50000] [Time: 46s] [Train Loss: 3.83e-01] [Train Acc: 0.88]\n",
            "[Step 3541/50000] [Progress: 7.08%] [learning rate: 3.6e+03]\n",
            "[Step 3558/50000] [Time: 47s] [Train Loss: 3.81e-01] [Train Acc: 0.88]\n",
            "[Step 3565/50000] [Progress: 7.13%] [learning rate: 3.5e+03]\n",
            "[Step 3588/50000] [Time: 47s] [Train Loss: 3.79e-01] [Train Acc: 0.88]\n",
            "[Step 3590/50000] [Progress: 7.18%] [learning rate: 3.5e+03]\n",
            "[Step 3614/50000] [Progress: 7.23%] [learning rate: 3.4e+03]\n",
            "[Step 3619/50000] [Time: 47s] [Train Loss: 3.78e-01] [Train Acc: 0.88]\n",
            "[Step 3639/50000] [Progress: 7.28%] [learning rate: 3.4e+03]\n",
            "[Step 3650/50000] [Time: 47s] [Train Loss: 3.77e-01] [Train Acc: 0.89]\n",
            "[Step 3665/50000] [Progress: 7.33%] [learning rate: 3.7e+03]\n",
            "[Step 3681/50000] [Time: 48s] [Train Loss: 3.75e-01] [Train Acc: 0.89]\n",
            "[Step 3689/50000] [Progress: 7.38%] [learning rate: 3.3e+03]\n",
            "[Step 3712/50000] [Time: 48s] [Train Loss: 3.73e-01] [Train Acc: 0.89]\n",
            "[Step 3716/50000] [Progress: 7.43%] [learning rate: 3.9e+03]\n",
            "[Step 3740/50000] [Progress: 7.48%] [learning rate: 3.5e+03]\n",
            "[Step 3744/50000] [Time: 48s] [Train Loss: 3.72e-01] [Train Acc: 0.89]\n",
            "[Step 3765/50000] [Progress: 7.53%] [learning rate: 3.5e+03]\n",
            "[Step 3776/50000] [Time: 48s] [Train Loss: 3.70e-01] [Train Acc: 0.89]\n",
            "[Step 3791/50000] [Progress: 7.58%] [learning rate: 3.7e+03]\n",
            "[Step 3808/50000] [Time: 49s] [Train Loss: 3.69e-01] [Train Acc: 0.89]\n",
            "[Step 3814/50000] [Progress: 7.63%] [learning rate: 3.4e+03]\n",
            "[Step 3840/50000] [Progress: 7.68%] [learning rate: 4.0e+03]\n",
            "[Step 3840/50000] [Time: 49s] [Train Loss: 3.67e-01] [Train Acc: 0.89]\n",
            "[Step 3863/50000] [Progress: 7.73%] [learning rate: 3.3e+03]\n",
            "[Step 3872/50000] [Time: 49s] [Train Loss: 3.65e-01] [Train Acc: 0.89]\n",
            "[Step 3889/50000] [Progress: 7.78%] [learning rate: 3.5e+03]\n",
            "[Step 3905/50000] [Time: 50s] [Train Loss: 3.64e-01] [Train Acc: 0.89]\n",
            "[Step 3915/50000] [Progress: 7.83%] [learning rate: 3.8e+03]\n",
            "[Step 3938/50000] [Progress: 7.88%] [learning rate: 3.4e+03]\n",
            "[Step 3938/50000] [Time: 50s] [Train Loss: 3.62e-01] [Train Acc: 0.89]\n",
            "[Step 3963/50000] [Progress: 7.93%] [learning rate: 3.7e+03]\n",
            "[Step 3971/50000] [Time: 50s] [Train Loss: 3.61e-01] [Train Acc: 0.89]\n",
            "[Step 3988/50000] [Progress: 7.98%] [learning rate: 4.0e+03]\n",
            "[Step 4004/50000] [Time: 50s] [Train Loss: 3.59e-01] [Train Acc: 0.89]\n",
            "[Step 4011/50000] [Progress: 8.02%] [learning rate: 3.3e+03]\n",
            "[Step 4037/50000] [Time: 51s] [Train Loss: 3.57e-01] [Train Acc: 0.90] [Eval Loss: 5.52e-01] [Eval Acc: 0.71]\n",
            "[Step 4038/50000] [Progress: 8.08%] [learning rate: 3.9e+03]\n",
            "[Step 4061/50000] [Progress: 8.12%] [learning rate: 3.5e+03]\n",
            "[Step 4071/50000] [Time: 52s] [Train Loss: 3.56e-01] [Train Acc: 0.90]\n",
            "[Step 4086/50000] [Progress: 8.17%] [learning rate: 3.8e+03]\n",
            "[Step 4105/50000] [Time: 53s] [Train Loss: 3.55e-01] [Train Acc: 0.90]\n",
            "[Step 4110/50000] [Progress: 8.22%] [learning rate: 3.7e+03]\n",
            "[Step 4135/50000] [Progress: 8.27%] [learning rate: 3.7e+03]\n",
            "[Step 4139/50000] [Time: 53s] [Train Loss: 3.53e-01] [Train Acc: 0.90]\n",
            "[Step 4159/50000] [Progress: 8.32%] [learning rate: 3.6e+03]\n",
            "[Step 4173/50000] [Time: 53s] [Train Loss: 3.52e-01] [Train Acc: 0.90]\n",
            "[Step 4184/50000] [Progress: 8.37%] [learning rate: 3.6e+03]\n",
            "[Step 4208/50000] [Time: 53s] [Train Loss: 3.50e-01] [Train Acc: 0.90]\n",
            "[Step 4210/50000] [Progress: 8.42%] [learning rate: 3.8e+03]\n",
            "[Step 4234/50000] [Progress: 8.47%] [learning rate: 3.4e+03]\n",
            "[Step 4243/50000] [Time: 54s] [Train Loss: 3.49e-01] [Train Acc: 0.90]\n",
            "[Step 4262/50000] [Progress: 8.52%] [learning rate: 4.1e+03]\n",
            "[Step 4278/50000] [Time: 54s] [Train Loss: 3.47e-01] [Train Acc: 0.90]\n",
            "[Step 4286/50000] [Progress: 8.57%] [learning rate: 3.7e+03]\n",
            "[Step 4311/50000] [Progress: 8.62%] [learning rate: 3.6e+03]\n",
            "[Step 4313/50000] [Time: 54s] [Train Loss: 3.45e-01] [Train Acc: 0.90]\n",
            "[Step 4337/50000] [Progress: 8.67%] [learning rate: 3.6e+03]\n",
            "[Step 4349/50000] [Time: 54s] [Train Loss: 3.44e-01] [Train Acc: 0.90]\n",
            "[Step 4362/50000] [Progress: 8.72%] [learning rate: 3.5e+03]\n",
            "[Step 4385/50000] [Time: 55s] [Train Loss: 3.42e-01] [Train Acc: 0.91]\n",
            "[Step 4388/50000] [Progress: 8.78%] [learning rate: 3.8e+03]\n",
            "[Step 4414/50000] [Progress: 8.83%] [learning rate: 4.1e+03]\n",
            "[Step 4421/50000] [Time: 55s] [Train Loss: 3.41e-01] [Train Acc: 0.91]\n",
            "[Step 4437/50000] [Progress: 8.87%] [learning rate: 3.4e+03]\n",
            "[Step 4457/50000] [Time: 55s] [Train Loss: 3.39e-01] [Train Acc: 0.91]\n",
            "[Step 4465/50000] [Progress: 8.93%] [learning rate: 4.0e+03]\n",
            "[Step 4489/50000] [Progress: 8.98%] [learning rate: 3.6e+03]\n",
            "[Step 4493/50000] [Time: 56s] [Train Loss: 3.38e-01] [Train Acc: 0.91]\n",
            "[Step 4515/50000] [Progress: 9.03%] [learning rate: 3.9e+03]\n",
            "[Step 4530/50000] [Time: 56s] [Train Loss: 3.36e-01] [Train Acc: 0.91]\n",
            "[Step 4541/50000] [Progress: 9.08%] [learning rate: 3.8e+03]\n",
            "[Step 4567/50000] [Progress: 9.13%] [learning rate: 4.1e+03]\n",
            "[Step 4567/50000] [Time: 56s] [Train Loss: 3.35e-01] [Train Acc: 0.91]\n",
            "[Step 4590/50000] [Progress: 9.18%] [learning rate: 3.4e+03]\n",
            "[Step 4604/50000] [Time: 56s] [Train Loss: 3.33e-01] [Train Acc: 0.91]\n",
            "[Step 4617/50000] [Progress: 9.23%] [learning rate: 4.0e+03]\n",
            "[Step 4641/50000] [Progress: 9.28%] [learning rate: 3.6e+03]\n",
            "[Step 4641/50000] [Time: 57s] [Train Loss: 3.32e-01] [Train Acc: 0.91]\n",
            "[Step 4668/50000] [Progress: 9.34%] [learning rate: 3.9e+03]\n",
            "[Step 4679/50000] [Time: 57s] [Train Loss: 3.30e-01] [Train Acc: 0.91]\n",
            "[Step 4695/50000] [Progress: 9.39%] [learning rate: 4.2e+03]\n",
            "[Step 4717/50000] [Time: 57s] [Train Loss: 3.29e-01] [Train Acc: 0.91]\n",
            "[Step 4718/50000] [Progress: 9.44%] [learning rate: 3.4e+03]\n",
            "[Step 4745/50000] [Progress: 9.49%] [learning rate: 4.1e+03]\n",
            "[Step 4755/50000] [Time: 57s] [Train Loss: 3.27e-01] [Train Acc: 0.92]\n",
            "[Step 4768/50000] [Progress: 9.54%] [learning rate: 3.3e+03]\n",
            "[Step 4793/50000] [Time: 58s] [Train Loss: 3.26e-01] [Train Acc: 0.92]\n",
            "[Step 4795/50000] [Progress: 9.59%] [learning rate: 4.0e+03]\n",
            "[Step 4821/50000] [Progress: 9.64%] [learning rate: 3.9e+03]\n",
            "[Step 4832/50000] [Time: 58s] [Train Loss: 3.24e-01] [Train Acc: 0.92]\n",
            "[Step 4847/50000] [Progress: 9.69%] [learning rate: 4.2e+03]\n",
            "[Step 4870/50000] [Progress: 9.74%] [learning rate: 3.5e+03]\n",
            "[Step 4871/50000] [Time: 58s] [Train Loss: 3.23e-01] [Train Acc: 0.92]\n",
            "[Step 4898/50000] [Progress: 9.80%] [learning rate: 4.1e+03]\n",
            "[Step 4910/50000] [Time: 59s] [Train Loss: 3.22e-01] [Train Acc: 0.92]\n",
            "[Step 4923/50000] [Progress: 9.85%] [learning rate: 3.7e+03]\n",
            "[Step 4949/50000] [Time: 59s] [Train Loss: 3.20e-01] [Train Acc: 0.92]\n",
            "[Step 4950/50000] [Progress: 9.90%] [learning rate: 4.0e+03]\n",
            "[Step 4977/50000] [Progress: 9.95%] [learning rate: 4.3e+03]\n",
            "[Step 4989/50000] [Time: 59s] [Train Loss: 3.19e-01] [Train Acc: 0.92]\n",
            "[Step 5001/50000] [Progress: 10.00%] [learning rate: 3.9e+03]\n",
            "[Step 5026/50000] [Progress: 10.05%] [learning rate: 3.8e+03]\n",
            "[Step 5029/50000] [Time: 59s] [Train Loss: 3.17e-01] [Train Acc: 0.92]\n",
            "[Step 5052/50000] [Progress: 10.10%] [learning rate: 4.1e+03]\n",
            "[Step 5069/50000] [Time: 60s] [Train Loss: 3.16e-01] [Train Acc: 0.92]\n",
            "[Step 5075/50000] [Progress: 10.15%] [learning rate: 3.7e+03]\n",
            "[Step 5101/50000] [Progress: 10.20%] [learning rate: 4.4e+03]\n",
            "[Step 5109/50000] [Time: 60s] [Train Loss: 3.14e-01] [Train Acc: 0.92]\n",
            "[Step 5124/50000] [Progress: 10.25%] [learning rate: 3.6e+03]\n",
            "[Step 5150/50000] [Progress: 10.30%] [learning rate: 3.9e+03]\n",
            "[Step 5150/50000] [Time: 61s] [Train Loss: 3.13e-01] [Train Acc: 0.92]\n",
            "[Step 5174/50000] [Progress: 10.35%] [learning rate: 3.8e+03]\n",
            "[Step 5191/50000] [Time: 61s] [Train Loss: 3.11e-01] [Train Acc: 0.92]\n",
            "[Step 5199/50000] [Progress: 10.40%] [learning rate: 3.8e+03]\n",
            "[Step 5224/50000] [Progress: 10.45%] [learning rate: 4.1e+03]\n",
            "[Step 5232/50000] [Time: 61s] [Train Loss: 3.10e-01] [Train Acc: 0.92]\n",
            "[Step 5249/50000] [Progress: 10.50%] [learning rate: 4.0e+03]\n",
            "[Step 5273/50000] [Time: 62s] [Train Loss: 3.08e-01] [Train Acc: 0.92]\n",
            "[Step 5275/50000] [Progress: 10.55%] [learning rate: 4.4e+03]\n",
            "[Step 5298/50000] [Progress: 10.60%] [learning rate: 3.6e+03]\n",
            "[Step 5314/50000] [Time: 62s] [Train Loss: 3.07e-01] [Train Acc: 0.92]\n",
            "[Step 5325/50000] [Progress: 10.65%] [learning rate: 4.2e+03]\n",
            "[Step 5349/50000] [Progress: 10.70%] [learning rate: 3.8e+03]\n",
            "[Step 5356/50000] [Time: 62s] [Train Loss: 3.06e-01] [Train Acc: 0.92]\n",
            "[Step 5376/50000] [Progress: 10.75%] [learning rate: 4.1e+03]\n",
            "[Step 5398/50000] [Time: 63s] [Train Loss: 3.04e-01] [Train Acc: 0.92]\n",
            "[Step 5403/50000] [Progress: 10.81%] [learning rate: 4.5e+03]\n",
            "[Step 5427/50000] [Progress: 10.85%] [learning rate: 4.0e+03]\n",
            "[Step 5440/50000] [Time: 63s] [Train Loss: 3.03e-01] [Train Acc: 0.92]\n",
            "[Step 5452/50000] [Progress: 10.90%] [learning rate: 3.9e+03]\n",
            "[Step 5478/50000] [Progress: 10.96%] [learning rate: 4.3e+03]\n",
            "[Step 5482/50000] [Time: 64s] [Train Loss: 3.01e-01] [Train Acc: 0.93]\n",
            "[Step 5502/50000] [Progress: 11.00%] [learning rate: 3.8e+03]\n",
            "[Step 5525/50000] [Time: 64s] [Train Loss: 3.00e-01] [Train Acc: 0.93]\n",
            "[Step 5529/50000] [Progress: 11.06%] [learning rate: 4.5e+03]\n",
            "[Step 5552/50000] [Progress: 11.10%] [learning rate: 3.7e+03]\n",
            "[Step 5568/50000] [Time: 64s] [Train Loss: 2.99e-01] [Train Acc: 0.93]\n",
            "[Step 5578/50000] [Progress: 11.16%] [learning rate: 4.0e+03]\n",
            "[Step 5602/50000] [Progress: 11.20%] [learning rate: 3.9e+03]\n",
            "[Step 5611/50000] [Time: 65s] [Train Loss: 2.97e-01] [Train Acc: 0.93]\n",
            "[Step 5627/50000] [Progress: 11.25%] [learning rate: 4.3e+03]\n",
            "[Step 5651/50000] [Progress: 11.30%] [learning rate: 3.8e+03]\n",
            "[Step 5654/50000] [Time: 65s] [Train Loss: 2.96e-01] [Train Acc: 0.93]\n",
            "[Step 5679/50000] [Progress: 11.36%] [learning rate: 5.0e+03]\n",
            "[Step 5698/50000] [Time: 65s] [Train Loss: 2.94e-01] [Train Acc: 0.93]\n",
            "[Step 5699/50000] [Progress: 11.40%] [learning rate: 3.4e+03]\n",
            "[Step 5727/50000] [Progress: 11.45%] [learning rate: 4.4e+03]\n",
            "[Step 5742/50000] [Time: 65s] [Train Loss: 2.93e-01] [Train Acc: 0.93]\n",
            "[Step 5752/50000] [Progress: 11.50%] [learning rate: 4.0e+03]\n",
            "[Step 5778/50000] [Progress: 11.56%] [learning rate: 4.3e+03]\n",
            "[Step 5786/50000] [Time: 66s] [Train Loss: 2.92e-01] [Train Acc: 0.93]\n",
            "[Step 5802/50000] [Progress: 11.60%] [learning rate: 4.2e+03]\n",
            "[Step 5827/50000] [Progress: 11.65%] [learning rate: 4.2e+03]\n",
            "[Step 5830/50000] [Time: 66s] [Train Loss: 2.90e-01] [Train Acc: 0.93]\n",
            "[Step 5851/50000] [Progress: 11.70%] [learning rate: 4.1e+03]\n",
            "[Step 5875/50000] [Time: 66s] [Train Loss: 2.89e-01] [Train Acc: 0.93]\n",
            "[Step 5876/50000] [Progress: 11.75%] [learning rate: 4.0e+03]\n",
            "[Step 5902/50000] [Progress: 11.80%] [learning rate: 4.4e+03]\n",
            "[Step 5920/50000] [Time: 67s] [Train Loss: 2.88e-01] [Train Acc: 0.93]\n",
            "[Step 5926/50000] [Progress: 11.85%] [learning rate: 3.9e+03]\n",
            "[Step 5953/50000] [Progress: 11.91%] [learning rate: 4.7e+03]\n",
            "[Step 5965/50000] [Time: 67s] [Train Loss: 2.86e-01] [Train Acc: 0.93]\n",
            "[Step 5976/50000] [Progress: 11.95%] [learning rate: 3.8e+03]\n",
            "[Step 6002/50000] [Progress: 12.00%] [learning rate: 4.1e+03]\n",
            "[Step 6010/50000] [Time: 67s] [Train Loss: 2.85e-01] [Train Acc: 0.93] [Eval Loss: 5.19e-01] [Eval Acc: 0.74]\n",
            "[Step 6027/50000] [Progress: 12.05%] [learning rate: 4.1e+03]\n",
            "[Step 6053/50000] [Progress: 12.11%] [learning rate: 4.4e+03]\n",
            "[Step 6056/50000] [Time: 69s] [Train Loss: 2.84e-01] [Train Acc: 0.93]\n",
            "[Step 6077/50000] [Progress: 12.15%] [learning rate: 3.9e+03]\n",
            "[Step 6102/50000] [Time: 70s] [Train Loss: 2.82e-01] [Train Acc: 0.93]\n",
            "[Step 6105/50000] [Progress: 12.21%] [learning rate: 5.2e+03]\n",
            "[Step 6126/50000] [Progress: 12.25%] [learning rate: 3.5e+03]\n",
            "[Step 6148/50000] [Time: 70s] [Train Loss: 2.81e-01] [Train Acc: 0.93]\n",
            "[Step 6155/50000] [Progress: 12.31%] [learning rate: 4.6e+03]\n",
            "[Step 6180/50000] [Progress: 12.36%] [learning rate: 4.1e+03]\n",
            "[Step 6194/50000] [Time: 70s] [Train Loss: 2.80e-01] [Train Acc: 0.93]\n",
            "[Step 6206/50000] [Progress: 12.41%] [learning rate: 4.4e+03]\n",
            "[Step 6230/50000] [Progress: 12.46%] [learning rate: 4.4e+03]\n",
            "[Step 6241/50000] [Time: 71s] [Train Loss: 2.78e-01] [Train Acc: 0.93]\n",
            "[Step 6255/50000] [Progress: 12.51%] [learning rate: 4.3e+03]\n",
            "[Step 6279/50000] [Progress: 12.56%] [learning rate: 4.2e+03]\n",
            "[Step 6288/50000] [Time: 71s] [Train Loss: 2.77e-01] [Train Acc: 0.93]\n",
            "[Step 6304/50000] [Progress: 12.61%] [learning rate: 4.2e+03]\n",
            "[Step 6330/50000] [Progress: 12.66%] [learning rate: 4.5e+03]\n",
            "[Step 6335/50000] [Time: 71s] [Train Loss: 2.76e-01] [Train Acc: 0.94]\n",
            "[Step 6354/50000] [Progress: 12.71%] [learning rate: 4.0e+03]\n",
            "[Step 6382/50000] [Progress: 12.76%] [learning rate: 4.8e+03]\n",
            "[Step 6382/50000] [Time: 72s] [Train Loss: 2.74e-01] [Train Acc: 0.94]\n",
            "[Step 6406/50000] [Progress: 12.81%] [learning rate: 4.3e+03]\n",
            "[Step 6430/50000] [Time: 72s] [Train Loss: 2.73e-01] [Train Acc: 0.94]\n",
            "[Step 6431/50000] [Progress: 12.86%] [learning rate: 4.2e+03]\n",
            "[Step 6457/50000] [Progress: 12.91%] [learning rate: 4.2e+03]\n",
            "[Step 6478/50000] [Time: 72s] [Train Loss: 2.72e-01] [Train Acc: 0.94]\n",
            "[Step 6482/50000] [Progress: 12.96%] [learning rate: 4.1e+03]\n",
            "[Step 6509/50000] [Progress: 13.02%] [learning rate: 4.5e+03]\n",
            "[Step 6526/50000] [Time: 73s] [Train Loss: 2.70e-01] [Train Acc: 0.94]\n",
            "[Step 6537/50000] [Progress: 13.07%] [learning rate: 5.3e+03]\n",
            "[Step 6560/50000] [Progress: 13.12%] [learning rate: 3.9e+03]\n",
            "[Step 6574/50000] [Time: 73s] [Train Loss: 2.69e-01] [Train Acc: 0.94]\n",
            "[Step 6586/50000] [Progress: 13.17%] [learning rate: 4.3e+03]\n",
            "[Step 6611/50000] [Progress: 13.22%] [learning rate: 4.2e+03]\n",
            "[Step 6623/50000] [Time: 74s] [Train Loss: 2.68e-01] [Train Acc: 0.94]\n",
            "[Step 6637/50000] [Progress: 13.27%] [learning rate: 4.5e+03]\n",
            "[Step 6661/50000] [Progress: 13.32%] [learning rate: 4.5e+03]\n",
            "[Step 6672/50000] [Time: 74s] [Train Loss: 2.66e-01] [Train Acc: 0.94]\n",
            "[Step 6686/50000] [Progress: 13.37%] [learning rate: 4.4e+03]\n",
            "[Step 6710/50000] [Progress: 13.42%] [learning rate: 4.3e+03]\n",
            "[Step 6721/50000] [Time: 74s] [Train Loss: 2.65e-01] [Train Acc: 0.94]\n",
            "[Step 6735/50000] [Progress: 13.47%] [learning rate: 4.3e+03]\n",
            "[Step 6761/50000] [Progress: 13.52%] [learning rate: 4.6e+03]\n",
            "[Step 6770/50000] [Time: 75s] [Train Loss: 2.64e-01] [Train Acc: 0.94]\n",
            "[Step 6785/50000] [Progress: 13.57%] [learning rate: 4.2e+03]\n",
            "[Step 6813/50000] [Progress: 13.63%] [learning rate: 4.9e+03]\n",
            "[Step 6820/50000] [Time: 75s] [Train Loss: 2.63e-01] [Train Acc: 0.94]\n",
            "[Step 6837/50000] [Progress: 13.67%] [learning rate: 4.4e+03]\n",
            "[Step 6862/50000] [Progress: 13.72%] [learning rate: 4.4e+03]\n",
            "[Step 6870/50000] [Time: 76s] [Train Loss: 2.61e-01] [Train Acc: 0.94]\n",
            "[Step 6888/50000] [Progress: 13.78%] [learning rate: 4.3e+03]\n",
            "[Step 6913/50000] [Progress: 13.83%] [learning rate: 4.2e+03]\n",
            "[Step 6920/50000] [Time: 76s] [Train Loss: 2.60e-01] [Train Acc: 0.94]\n",
            "[Step 6940/50000] [Progress: 13.88%] [learning rate: 4.6e+03]\n",
            "[Step 6966/50000] [Progress: 13.93%] [learning rate: 5.5e+03]\n",
            "[Step 6970/50000] [Time: 76s] [Train Loss: 2.59e-01] [Train Acc: 0.94]\n",
            "[Step 6987/50000] [Progress: 13.97%] [learning rate: 3.7e+03]\n",
            "[Step 7016/50000] [Progress: 14.03%] [learning rate: 4.8e+03]\n",
            "[Step 7021/50000] [Time: 77s] [Train Loss: 2.57e-01] [Train Acc: 0.94]\n",
            "[Step 7041/50000] [Progress: 14.08%] [learning rate: 4.3e+03]\n",
            "[Step 7067/50000] [Progress: 14.13%] [learning rate: 4.7e+03]\n",
            "[Step 7072/50000] [Time: 77s] [Train Loss: 2.56e-01] [Train Acc: 0.94]\n",
            "[Step 7091/50000] [Progress: 14.18%] [learning rate: 4.6e+03]\n",
            "[Step 7116/50000] [Progress: 14.23%] [learning rate: 4.5e+03]\n",
            "[Step 7123/50000] [Time: 78s] [Train Loss: 2.55e-01] [Train Acc: 0.95]\n",
            "[Step 7140/50000] [Progress: 14.28%] [learning rate: 4.5e+03]\n",
            "[Step 7165/50000] [Progress: 14.33%] [learning rate: 4.4e+03]\n",
            "[Step 7174/50000] [Time: 78s] [Train Loss: 2.54e-01] [Train Acc: 0.95]\n",
            "[Step 7191/50000] [Progress: 14.38%] [learning rate: 4.8e+03]\n",
            "[Step 7215/50000] [Progress: 14.43%] [learning rate: 4.3e+03]\n",
            "[Step 7226/50000] [Time: 78s] [Train Loss: 2.52e-01] [Train Acc: 0.95]\n",
            "[Step 7242/50000] [Progress: 14.48%] [learning rate: 5.1e+03]\n",
            "[Step 7265/50000] [Progress: 14.53%] [learning rate: 4.1e+03]\n",
            "[Step 7278/50000] [Time: 79s] [Train Loss: 2.51e-01] [Train Acc: 0.95]\n",
            "[Step 7291/50000] [Progress: 14.58%] [learning rate: 4.5e+03]\n",
            "[Step 7316/50000] [Progress: 14.63%] [learning rate: 4.4e+03]\n",
            "[Step 7330/50000] [Time: 79s] [Train Loss: 2.50e-01] [Train Acc: 0.95]\n",
            "[Step 7342/50000] [Progress: 14.68%] [learning rate: 4.8e+03]\n",
            "[Step 7366/50000] [Progress: 14.73%] [learning rate: 4.3e+03]\n",
            "[Step 7382/50000] [Time: 79s] [Train Loss: 2.49e-01] [Train Acc: 0.95]\n",
            "[Step 7393/50000] [Progress: 14.79%] [learning rate: 5.1e+03]\n",
            "[Step 7418/50000] [Progress: 14.84%] [learning rate: 4.6e+03]\n",
            "[Step 7435/50000] [Time: 80s] [Train Loss: 2.48e-01] [Train Acc: 0.95]\n",
            "[Step 7444/50000] [Progress: 14.89%] [learning rate: 4.5e+03]\n",
            "[Step 7470/50000] [Progress: 14.94%] [learning rate: 4.9e+03]\n",
            "[Step 7488/50000] [Time: 80s] [Train Loss: 2.46e-01] [Train Acc: 0.95]\n",
            "[Step 7493/50000] [Progress: 14.99%] [learning rate: 4.4e+03]\n",
            "[Step 7519/50000] [Progress: 15.04%] [learning rate: 4.7e+03]\n",
            "[Step 7541/50000] [Time: 81s] [Train Loss: 2.45e-01] [Train Acc: 0.95]\n",
            "[Step 7544/50000] [Progress: 15.09%] [learning rate: 4.7e+03]\n",
            "[Step 7570/50000] [Progress: 15.14%] [learning rate: 4.6e+03]\n",
            "[Step 7594/50000] [Progress: 15.19%] [learning rate: 4.5e+03]\n",
            "[Step 7594/50000] [Time: 81s] [Train Loss: 2.44e-01] [Train Acc: 0.95]\n",
            "[Step 7619/50000] [Progress: 15.24%] [learning rate: 4.5e+03]\n",
            "[Step 7644/50000] [Progress: 15.29%] [learning rate: 4.8e+03]\n",
            "[Step 7648/50000] [Time: 81s] [Train Loss: 2.43e-01] [Train Acc: 0.95]\n",
            "[Step 7668/50000] [Progress: 15.34%] [learning rate: 4.8e+03]\n",
            "[Step 7693/50000] [Progress: 15.39%] [learning rate: 4.7e+03]\n",
            "[Step 7702/50000] [Time: 82s] [Train Loss: 2.41e-01] [Train Acc: 0.95]\n",
            "[Step 7717/50000] [Progress: 15.43%] [learning rate: 4.6e+03]\n",
            "[Step 7742/50000] [Progress: 15.48%] [learning rate: 4.6e+03]\n",
            "[Step 7756/50000] [Time: 82s] [Train Loss: 2.40e-01] [Train Acc: 0.95]\n",
            "[Step 7768/50000] [Progress: 15.54%] [learning rate: 4.9e+03]\n",
            "[Step 7792/50000] [Progress: 15.58%] [learning rate: 4.4e+03]\n",
            "[Step 7810/50000] [Time: 83s] [Train Loss: 2.39e-01] [Train Acc: 0.95]\n",
            "[Step 7818/50000] [Progress: 15.64%] [learning rate: 5.3e+03]\n",
            "[Step 7841/50000] [Progress: 15.68%] [learning rate: 4.3e+03]\n",
            "[Step 7865/50000] [Time: 83s] [Train Loss: 2.38e-01] [Train Acc: 0.95]\n",
            "[Step 7867/50000] [Progress: 15.73%] [learning rate: 4.6e+03]\n",
            "[Step 7892/50000] [Progress: 15.78%] [learning rate: 4.6e+03]\n",
            "[Step 7918/50000] [Progress: 15.84%] [learning rate: 5.0e+03]\n",
            "[Step 7920/50000] [Time: 83s] [Train Loss: 2.37e-01] [Train Acc: 0.96]\n",
            "[Step 7942/50000] [Progress: 15.88%] [learning rate: 4.9e+03]\n",
            "[Step 7967/50000] [Progress: 15.93%] [learning rate: 5.3e+03]\n",
            "[Step 7975/50000] [Time: 84s] [Train Loss: 2.35e-01] [Train Acc: 0.96]\n",
            "[Step 7990/50000] [Progress: 15.98%] [learning rate: 4.3e+03]\n",
            "[Step 8017/50000] [Progress: 16.03%] [learning rate: 5.1e+03]\n",
            "[Step 8030/50000] [Time: 84s] [Train Loss: 2.34e-01] [Train Acc: 0.96]\n",
            "[Step 8040/50000] [Progress: 16.08%] [learning rate: 4.6e+03]\n",
            "[Step 8065/50000] [Progress: 16.13%] [learning rate: 5.0e+03]\n",
            "[Step 8086/50000] [Time: 85s] [Train Loss: 2.33e-01] [Train Acc: 0.96]\n",
            "[Step 8089/50000] [Progress: 16.18%] [learning rate: 4.9e+03]\n",
            "[Step 8114/50000] [Progress: 16.23%] [learning rate: 4.8e+03]\n",
            "[Step 8138/50000] [Progress: 16.28%] [learning rate: 4.8e+03]\n",
            "[Step 8142/50000] [Time: 85s] [Train Loss: 2.32e-01] [Train Acc: 0.96]\n",
            "[Step 8163/50000] [Progress: 16.33%] [learning rate: 4.7e+03]\n",
            "[Step 8189/50000] [Progress: 16.38%] [learning rate: 5.1e+03]\n",
            "[Step 8198/50000] [Time: 85s] [Train Loss: 2.31e-01] [Train Acc: 0.96]\n",
            "[Step 8213/50000] [Progress: 16.43%] [learning rate: 4.5e+03]\n",
            "[Step 8241/50000] [Progress: 16.48%] [learning rate: 5.4e+03]\n",
            "[Step 8254/50000] [Time: 86s] [Train Loss: 2.30e-01] [Train Acc: 0.96]\n",
            "[Step 8265/50000] [Progress: 16.53%] [learning rate: 4.8e+03]\n",
            "[Step 8290/50000] [Progress: 16.58%] [learning rate: 4.8e+03]\n",
            "[Step 8311/50000] [Time: 86s] [Train Loss: 2.29e-01] [Train Acc: 0.96]\n",
            "[Step 8316/50000] [Progress: 16.63%] [learning rate: 4.7e+03]\n",
            "[Step 8341/50000] [Progress: 16.68%] [learning rate: 4.6e+03]\n",
            "[Step 8366/50000] [Progress: 16.73%] [learning rate: 5.0e+03]\n",
            "[Step 8368/50000] [Time: 87s] [Train Loss: 2.27e-01] [Train Acc: 0.96]\n",
            "[Step 8392/50000] [Progress: 16.78%] [learning rate: 6.0e+03]\n",
            "[Step 8412/50000] [Progress: 16.82%] [learning rate: 4.0e+03]\n",
            "[Step 8425/50000] [Time: 87s] [Train Loss: 2.26e-01] [Train Acc: 0.96]\n",
            "[Step 8440/50000] [Progress: 16.88%] [learning rate: 5.3e+03]\n",
            "[Step 8465/50000] [Progress: 16.93%] [learning rate: 4.7e+03]\n",
            "[Step 8482/50000] [Time: 88s] [Train Loss: 2.25e-01] [Train Acc: 0.96]\n",
            "[Step 8491/50000] [Progress: 16.98%] [learning rate: 5.1e+03]\n",
            "[Step 8515/50000] [Progress: 17.03%] [learning rate: 5.0e+03]\n",
            "[Step 8540/50000] [Progress: 17.08%] [learning rate: 5.5e+03]\n",
            "[Step 8540/50000] [Time: 89s] [Train Loss: 2.24e-01] [Train Acc: 0.96]\n",
            "[Step 8563/50000] [Progress: 17.13%] [learning rate: 4.4e+03]\n",
            "[Step 8590/50000] [Progress: 17.18%] [learning rate: 5.3e+03]\n",
            "[Step 8598/50000] [Time: 89s] [Train Loss: 2.23e-01] [Train Acc: 0.96] [Eval Loss: 4.93e-01] [Eval Acc: 0.77]\n",
            "[Step 8613/50000] [Progress: 17.23%] [learning rate: 4.7e+03]\n",
            "[Step 8638/50000] [Progress: 17.28%] [learning rate: 5.1e+03]\n",
            "[Step 8656/50000] [Time: 92s] [Train Loss: 2.22e-01] [Train Acc: 0.96]\n",
            "[Step 8663/50000] [Progress: 17.33%] [learning rate: 5.1e+03]\n",
            "[Step 8689/50000] [Progress: 17.38%] [learning rate: 5.0e+03]\n",
            "[Step 8713/50000] [Progress: 17.43%] [learning rate: 4.9e+03]\n",
            "[Step 8714/50000] [Time: 92s] [Train Loss: 2.20e-01] [Train Acc: 0.96]\n",
            "[Step 8738/50000] [Progress: 17.48%] [learning rate: 4.8e+03]\n",
            "[Step 8764/50000] [Progress: 17.53%] [learning rate: 5.2e+03]\n",
            "[Step 8773/50000] [Time: 92s] [Train Loss: 2.19e-01] [Train Acc: 0.96]\n",
            "[Step 8788/50000] [Progress: 17.58%] [learning rate: 4.7e+03]\n",
            "[Step 8814/50000] [Progress: 17.63%] [learning rate: 5.6e+03]\n",
            "[Step 8832/50000] [Time: 93s] [Train Loss: 2.18e-01] [Train Acc: 0.96]\n",
            "[Step 8837/50000] [Progress: 17.67%] [learning rate: 4.6e+03]\n",
            "[Step 8863/50000] [Progress: 17.73%] [learning rate: 4.9e+03]\n",
            "[Step 8889/50000] [Progress: 17.78%] [learning rate: 5.3e+03]\n",
            "[Step 8891/50000] [Time: 93s] [Train Loss: 2.17e-01] [Train Acc: 0.96]\n",
            "[Step 8912/50000] [Progress: 17.82%] [learning rate: 4.8e+03]\n",
            "[Step 8938/50000] [Progress: 17.88%] [learning rate: 5.2e+03]\n",
            "[Step 8950/50000] [Time: 94s] [Train Loss: 2.16e-01] [Train Acc: 0.97]\n",
            "[Step 8965/50000] [Progress: 17.93%] [learning rate: 6.2e+03]\n",
            "[Step 8985/50000] [Progress: 17.97%] [learning rate: 4.2e+03]\n",
            "[Step 9010/50000] [Time: 94s] [Train Loss: 2.15e-01] [Train Acc: 0.97]\n",
            "[Step 9013/50000] [Progress: 18.03%] [learning rate: 5.5e+03]\n",
            "[Step 9038/50000] [Progress: 18.08%] [learning rate: 4.9e+03]\n",
            "[Step 9065/50000] [Progress: 18.13%] [learning rate: 5.3e+03]\n",
            "[Step 9070/50000] [Time: 95s] [Train Loss: 2.14e-01] [Train Acc: 0.97]\n",
            "[Step 9090/50000] [Progress: 18.18%] [learning rate: 5.2e+03]\n",
            "[Step 9115/50000] [Progress: 18.23%] [learning rate: 5.6e+03]\n",
            "[Step 9130/50000] [Time: 95s] [Train Loss: 2.13e-01] [Train Acc: 0.97]\n",
            "[Step 9138/50000] [Progress: 18.28%] [learning rate: 4.6e+03]\n",
            "[Step 9165/50000] [Progress: 18.33%] [learning rate: 5.5e+03]\n",
            "[Step 9188/50000] [Progress: 18.38%] [learning rate: 4.9e+03]\n",
            "[Step 9190/50000] [Time: 96s] [Train Loss: 2.12e-01] [Train Acc: 0.97]\n",
            "[Step 9213/50000] [Progress: 18.43%] [learning rate: 5.3e+03]\n",
            "[Step 9238/50000] [Progress: 18.48%] [learning rate: 5.2e+03]\n",
            "[Step 9251/50000] [Time: 96s] [Train Loss: 2.11e-01] [Train Acc: 0.97]\n",
            "[Step 9264/50000] [Progress: 18.53%] [learning rate: 5.7e+03]\n",
            "[Step 9287/50000] [Progress: 18.57%] [learning rate: 4.6e+03]\n",
            "[Step 9312/50000] [Time: 96s] [Train Loss: 2.09e-01] [Train Acc: 0.97]\n",
            "[Step 9314/50000] [Progress: 18.63%] [learning rate: 5.5e+03]\n",
            "[Step 9337/50000] [Progress: 18.67%] [learning rate: 4.9e+03]\n",
            "[Step 9363/50000] [Progress: 18.73%] [learning rate: 5.3e+03]\n",
            "[Step 9373/50000] [Time: 97s] [Train Loss: 2.08e-01] [Train Acc: 0.97]\n",
            "[Step 9389/50000] [Progress: 18.78%] [learning rate: 5.8e+03]\n",
            "[Step 9412/50000] [Progress: 18.82%] [learning rate: 4.7e+03]\n",
            "[Step 9434/50000] [Time: 97s] [Train Loss: 2.07e-01] [Train Acc: 0.97]\n",
            "[Step 9438/50000] [Progress: 18.88%] [learning rate: 5.1e+03]\n",
            "[Step 9463/50000] [Progress: 18.93%] [learning rate: 5.0e+03]\n",
            "[Step 9489/50000] [Progress: 18.98%] [learning rate: 5.4e+03]\n",
            "[Step 9496/50000] [Time: 98s] [Train Loss: 2.06e-01] [Train Acc: 0.97]\n",
            "[Step 9513/50000] [Progress: 19.03%] [learning rate: 5.4e+03]\n",
            "[Step 9538/50000] [Progress: 19.08%] [learning rate: 5.8e+03]\n",
            "[Step 9558/50000] [Time: 98s] [Train Loss: 2.05e-01] [Train Acc: 0.97]\n",
            "[Step 9561/50000] [Progress: 19.12%] [learning rate: 4.7e+03]\n",
            "[Step 9588/50000] [Progress: 19.18%] [learning rate: 5.6e+03]\n",
            "[Step 9611/50000] [Progress: 19.22%] [learning rate: 5.0e+03]\n",
            "[Step 9620/50000] [Time: 99s] [Train Loss: 2.04e-01] [Train Acc: 0.97]\n",
            "[Step 9636/50000] [Progress: 19.27%] [learning rate: 5.5e+03]\n",
            "[Step 9660/50000] [Progress: 19.32%] [learning rate: 5.4e+03]\n",
            "[Step 9682/50000] [Time: 99s] [Train Loss: 2.03e-01] [Train Acc: 0.97]\n",
            "[Step 9685/50000] [Progress: 19.37%] [learning rate: 5.3e+03]\n",
            "[Step 9709/50000] [Progress: 19.42%] [learning rate: 5.2e+03]\n",
            "[Step 9734/50000] [Progress: 19.47%] [learning rate: 5.1e+03]\n",
            "[Step 9745/50000] [Time: 100s] [Train Loss: 2.02e-01] [Train Acc: 0.97]\n",
            "[Step 9760/50000] [Progress: 19.52%] [learning rate: 5.6e+03]\n",
            "[Step 9784/50000] [Progress: 19.57%] [learning rate: 5.0e+03]\n",
            "[Step 9808/50000] [Time: 100s] [Train Loss: 2.01e-01] [Train Acc: 0.97]\n",
            "[Step 9811/50000] [Progress: 19.62%] [learning rate: 6.0e+03]\n",
            "[Step 9834/50000] [Progress: 19.67%] [learning rate: 5.3e+03]\n",
            "[Step 9858/50000] [Progress: 19.72%] [learning rate: 5.3e+03]\n",
            "[Step 9871/50000] [Time: 101s] [Train Loss: 2.00e-01] [Train Acc: 0.97]\n",
            "[Step 9883/50000] [Progress: 19.77%] [learning rate: 5.2e+03]\n",
            "[Step 9908/50000] [Progress: 19.82%] [learning rate: 5.1e+03]\n",
            "[Step 9934/50000] [Time: 101s] [Train Loss: 1.99e-01] [Train Acc: 0.97]\n",
            "[Step 9935/50000] [Progress: 19.87%] [learning rate: 5.5e+03]\n",
            "[Step 9962/50000] [Progress: 19.92%] [learning rate: 6.0e+03]\n",
            "[Step 9986/50000] [Progress: 19.97%] [learning rate: 5.4e+03]\n",
            "[Step 9997/50000] [Time: 102s] [Train Loss: 1.98e-01] [Train Acc: 0.97]\n",
            "[Step 10011/50000] [Progress: 20.02%] [learning rate: 5.3e+03]\n",
            "[Step 10037/50000] [Progress: 20.07%] [learning rate: 5.2e+03]\n",
            "[Step 10061/50000] [Time: 102s] [Train Loss: 1.97e-01] [Train Acc: 0.97]\n",
            "[Step 10064/50000] [Progress: 20.13%] [learning rate: 5.6e+03]\n",
            "[Step 10089/50000] [Progress: 20.18%] [learning rate: 5.5e+03]\n",
            "[Step 10114/50000] [Progress: 20.23%] [learning rate: 6.0e+03]\n",
            "[Step 10125/50000] [Time: 103s] [Train Loss: 1.96e-01] [Train Acc: 0.97]\n",
            "[Step 10137/50000] [Progress: 20.27%] [learning rate: 4.9e+03]\n",
            "[Step 10163/50000] [Progress: 20.33%] [learning rate: 5.3e+03]\n",
            "[Step 10188/50000] [Progress: 20.38%] [learning rate: 5.2e+03]\n",
            "[Step 10189/50000] [Time: 103s] [Train Loss: 1.95e-01] [Train Acc: 0.97]\n",
            "[Step 10214/50000] [Progress: 20.43%] [learning rate: 5.7e+03]\n",
            "[Step 10239/50000] [Progress: 20.48%] [learning rate: 5.6e+03]\n",
            "[Step 10253/50000] [Time: 104s] [Train Loss: 1.94e-01] [Train Acc: 0.97]\n",
            "[Step 10265/50000] [Progress: 20.53%] [learning rate: 5.5e+03]\n",
            "[Step 10289/50000] [Progress: 20.58%] [learning rate: 5.4e+03]\n",
            "[Step 10314/50000] [Progress: 20.63%] [learning rate: 5.3e+03]\n",
            "[Step 10318/50000] [Time: 104s] [Train Loss: 1.93e-01] [Train Acc: 0.97]\n",
            "[Step 10340/50000] [Progress: 20.68%] [learning rate: 5.8e+03]\n",
            "[Step 10364/50000] [Progress: 20.73%] [learning rate: 5.2e+03]\n",
            "[Step 10383/50000] [Time: 105s] [Train Loss: 1.92e-01] [Train Acc: 0.97]\n",
            "[Step 10391/50000] [Progress: 20.78%] [learning rate: 6.2e+03]\n",
            "[Step 10414/50000] [Progress: 20.83%] [learning rate: 5.0e+03]\n",
            "[Step 10440/50000] [Progress: 20.88%] [learning rate: 5.4e+03]\n",
            "[Step 10448/50000] [Time: 105s] [Train Loss: 1.91e-01] [Train Acc: 0.97]\n",
            "[Step 10465/50000] [Progress: 20.93%] [learning rate: 5.3e+03]\n",
            "[Step 10491/50000] [Progress: 20.98%] [learning rate: 5.8e+03]\n",
            "[Step 10513/50000] [Time: 105s] [Train Loss: 1.90e-01] [Train Acc: 0.98]\n",
            "[Step 10515/50000] [Progress: 21.03%] [learning rate: 5.2e+03]\n",
            "[Step 10543/50000] [Progress: 21.09%] [learning rate: 6.2e+03]\n",
            "[Step 10566/50000] [Progress: 21.13%] [learning rate: 5.0e+03]\n",
            "[Step 10579/50000] [Time: 106s] [Train Loss: 1.89e-01] [Train Acc: 0.98]\n",
            "[Step 10593/50000] [Progress: 21.19%] [learning rate: 6.0e+03]\n",
            "[Step 10616/50000] [Progress: 21.23%] [learning rate: 4.9e+03]\n",
            "[Step 10642/50000] [Progress: 21.28%] [learning rate: 5.8e+03]\n",
            "[Step 10645/50000] [Time: 106s] [Train Loss: 1.88e-01] [Train Acc: 0.98]\n",
            "[Step 10666/50000] [Progress: 21.33%] [learning rate: 5.7e+03]\n",
            "[Step 10692/50000] [Progress: 21.38%] [learning rate: 6.2e+03]\n",
            "[Step 10711/50000] [Time: 107s] [Train Loss: 1.87e-01] [Train Acc: 0.98]\n",
            "[Step 10716/50000] [Progress: 21.43%] [learning rate: 5.6e+03]\n",
            "[Step 10741/50000] [Progress: 21.48%] [learning rate: 5.5e+03]\n",
            "[Step 10767/50000] [Progress: 21.53%] [learning rate: 5.4e+03]\n",
            "[Step 10777/50000] [Time: 107s] [Train Loss: 1.86e-01] [Train Acc: 0.98]\n",
            "[Step 10792/50000] [Progress: 21.58%] [learning rate: 5.3e+03]\n",
            "[Step 10818/50000] [Progress: 21.64%] [learning rate: 5.8e+03]\n",
            "[Step 10843/50000] [Time: 108s] [Train Loss: 1.85e-01] [Train Acc: 0.98]\n",
            "[Step 10844/50000] [Progress: 21.69%] [learning rate: 6.2e+03]\n",
            "[Step 10867/50000] [Progress: 21.73%] [learning rate: 5.1e+03]\n",
            "[Step 10895/50000] [Progress: 21.79%] [learning rate: 6.1e+03]\n",
            "[Step 10910/50000] [Time: 108s] [Train Loss: 1.84e-01] [Train Acc: 0.98]\n",
            "[Step 10919/50000] [Progress: 21.84%] [learning rate: 5.4e+03]\n",
            "[Step 10945/50000] [Progress: 21.89%] [learning rate: 5.9e+03]\n",
            "[Step 10971/50000] [Progress: 21.94%] [learning rate: 5.8e+03]\n",
            "[Step 10977/50000] [Time: 109s] [Train Loss: 1.83e-01] [Train Acc: 0.98]\n",
            "[Step 10997/50000] [Progress: 21.99%] [learning rate: 6.3e+03]\n",
            "[Step 11020/50000] [Progress: 22.04%] [learning rate: 5.1e+03]\n",
            "[Step 11044/50000] [Time: 109s] [Train Loss: 1.82e-01] [Train Acc: 0.98]\n",
            "[Step 11047/50000] [Progress: 22.09%] [learning rate: 6.1e+03]\n",
            "[Step 11070/50000] [Progress: 22.14%] [learning rate: 5.4e+03]\n",
            "[Step 11096/50000] [Progress: 22.19%] [learning rate: 5.9e+03]\n",
            "[Step 11111/50000] [Time: 110s] [Train Loss: 1.81e-01] [Train Acc: 0.98]\n",
            "[Step 11122/50000] [Progress: 22.24%] [learning rate: 6.4e+03]\n",
            "[Step 11145/50000] [Progress: 22.29%] [learning rate: 5.2e+03]\n",
            "[Step 11171/50000] [Progress: 22.34%] [learning rate: 5.6e+03]\n",
            "[Step 11179/50000] [Time: 110s] [Train Loss: 1.80e-01] [Train Acc: 0.98]\n",
            "[Step 11197/50000] [Progress: 22.39%] [learning rate: 6.1e+03]\n",
            "[Step 11220/50000] [Progress: 22.44%] [learning rate: 5.5e+03]\n",
            "[Step 11246/50000] [Progress: 22.49%] [learning rate: 5.9e+03]\n",
            "[Step 11247/50000] [Time: 111s] [Train Loss: 1.79e-01] [Train Acc: 0.98]\n",
            "[Step 11274/50000] [Progress: 22.55%] [learning rate: 7.1e+03]\n",
            "[Step 11297/50000] [Progress: 22.59%] [learning rate: 5.2e+03]\n",
            "[Step 11315/50000] [Time: 111s] [Train Loss: 1.78e-01] [Train Acc: 0.98]\n",
            "[Step 11323/50000] [Progress: 22.65%] [learning rate: 5.7e+03]\n",
            "[Step 11348/50000] [Progress: 22.70%] [learning rate: 5.6e+03]\n",
            "[Step 11374/50000] [Progress: 22.75%] [learning rate: 6.0e+03]\n",
            "[Step 11383/50000] [Time: 112s] [Train Loss: 1.77e-01] [Train Acc: 0.98]\n",
            "[Step 11398/50000] [Progress: 22.80%] [learning rate: 5.9e+03]\n",
            "[Step 11423/50000] [Progress: 22.85%] [learning rate: 5.9e+03]\n",
            "[Step 11447/50000] [Progress: 22.89%] [learning rate: 5.8e+03]\n",
            "[Step 11451/50000] [Time: 112s] [Train Loss: 1.76e-01] [Train Acc: 0.98]\n",
            "[Step 11472/50000] [Progress: 22.94%] [learning rate: 5.7e+03]\n",
            "[Step 11498/50000] [Progress: 23.00%] [learning rate: 6.2e+03]\n",
            "[Step 11520/50000] [Time: 113s] [Train Loss: 1.75e-01] [Train Acc: 0.98]\n",
            "[Step 11522/50000] [Progress: 23.04%] [learning rate: 5.5e+03]\n",
            "[Step 11549/50000] [Progress: 23.10%] [learning rate: 6.6e+03]\n",
            "[Step 11572/50000] [Progress: 23.14%] [learning rate: 5.4e+03]\n",
            "[Step 11589/50000] [Time: 114s] [Train Loss: 1.74e-01] [Train Acc: 0.98]\n",
            "[Step 11598/50000] [Progress: 23.20%] [learning rate: 5.8e+03]\n",
            "[Step 11622/50000] [Progress: 23.24%] [learning rate: 5.7e+03]\n",
            "[Step 11647/50000] [Progress: 23.29%] [learning rate: 6.2e+03]\n",
            "[Step 11658/50000] [Time: 114s] [Train Loss: 1.73e-01] [Train Acc: 0.98]\n",
            "[Step 11671/50000] [Progress: 23.34%] [learning rate: 5.5e+03]\n",
            "[Step 11699/50000] [Progress: 23.40%] [learning rate: 6.6e+03]\n",
            "[Step 11723/50000] [Progress: 23.45%] [learning rate: 5.9e+03]\n",
            "[Step 11727/50000] [Time: 115s] [Train Loss: 1.72e-01] [Train Acc: 0.98]\n",
            "[Step 11748/50000] [Progress: 23.50%] [learning rate: 5.8e+03]\n",
            "[Step 11774/50000] [Progress: 23.55%] [learning rate: 5.7e+03]\n",
            "[Step 11797/50000] [Time: 115s] [Train Loss: 1.71e-01] [Train Acc: 0.98] [Eval Loss: 4.74e-01] [Eval Acc: 0.78]\n",
            "[Step 11799/50000] [Progress: 23.60%] [learning rate: 5.6e+03]\n",
            "[Step 11826/50000] [Progress: 23.65%] [learning rate: 6.1e+03]\n",
            "[Step 11851/50000] [Progress: 23.70%] [learning rate: 6.6e+03]\n",
            "[Step 11867/50000] [Time: 117s] [Train Loss: 1.71e-01] [Train Acc: 0.98]\n",
            "[Step 11874/50000] [Progress: 23.75%] [learning rate: 5.4e+03]\n",
            "[Step 11900/50000] [Progress: 23.80%] [learning rate: 5.8e+03]\n",
            "[Step 11925/50000] [Progress: 23.85%] [learning rate: 5.8e+03]\n",
            "[Step 11937/50000] [Time: 118s] [Train Loss: 1.70e-01] [Train Acc: 0.98]\n",
            "[Step 11951/50000] [Progress: 23.90%] [learning rate: 6.2e+03]\n",
            "[Step 11975/50000] [Progress: 23.95%] [learning rate: 6.1e+03]\n",
            "[Step 12000/50000] [Progress: 24.00%] [learning rate: 6.7e+03]\n",
            "[Step 12007/50000] [Time: 118s] [Train Loss: 1.69e-01] [Train Acc: 0.98]\n",
            "[Step 12023/50000] [Progress: 24.05%] [learning rate: 5.4e+03]\n",
            "[Step 12050/50000] [Progress: 24.10%] [learning rate: 6.5e+03]\n",
            "[Step 12073/50000] [Progress: 24.15%] [learning rate: 5.8e+03]\n",
            "[Step 12077/50000] [Time: 119s] [Train Loss: 1.68e-01] [Train Acc: 0.98]\n",
            "[Step 12098/50000] [Progress: 24.20%] [learning rate: 6.3e+03]\n",
            "[Step 12122/50000] [Progress: 24.24%] [learning rate: 6.2e+03]\n",
            "[Step 12147/50000] [Progress: 24.29%] [learning rate: 6.1e+03]\n",
            "[Step 12148/50000] [Time: 119s] [Train Loss: 1.67e-01] [Train Acc: 0.98]\n",
            "[Step 12171/50000] [Progress: 24.34%] [learning rate: 6.0e+03]\n",
            "[Step 12196/50000] [Progress: 24.39%] [learning rate: 5.9e+03]\n",
            "[Step 12219/50000] [Time: 120s] [Train Loss: 1.66e-01] [Train Acc: 0.98]\n",
            "[Step 12222/50000] [Progress: 24.44%] [learning rate: 6.4e+03]\n",
            "[Step 12246/50000] [Progress: 24.49%] [learning rate: 5.7e+03]\n",
            "[Step 12273/50000] [Progress: 24.55%] [learning rate: 6.8e+03]\n",
            "[Step 12290/50000] [Time: 120s] [Train Loss: 1.65e-01] [Train Acc: 0.98]\n",
            "[Step 12296/50000] [Progress: 24.59%] [learning rate: 5.6e+03]\n",
            "[Step 12322/50000] [Progress: 24.64%] [learning rate: 6.0e+03]\n",
            "[Step 12346/50000] [Progress: 24.69%] [learning rate: 5.9e+03]\n",
            "[Step 12361/50000] [Time: 121s] [Train Loss: 1.64e-01] [Train Acc: 0.98]\n",
            "[Step 12371/50000] [Progress: 24.74%] [learning rate: 6.4e+03]\n",
            "[Step 12395/50000] [Progress: 24.79%] [learning rate: 5.8e+03]\n",
            "[Step 12423/50000] [Progress: 24.85%] [learning rate: 6.9e+03]\n",
            "[Step 12432/50000] [Time: 121s] [Train Loss: 1.63e-01] [Train Acc: 0.98]\n",
            "[Step 12448/50000] [Progress: 24.90%] [learning rate: 6.1e+03]\n",
            "[Step 12474/50000] [Progress: 24.95%] [learning rate: 6.0e+03]\n",
            "[Step 12500/50000] [Progress: 25.00%] [learning rate: 6.6e+03]\n",
            "[Step 12504/50000] [Time: 122s] [Train Loss: 1.63e-01] [Train Acc: 0.98]\n",
            "[Step 12523/50000] [Progress: 25.05%] [learning rate: 5.9e+03]\n",
            "[Step 12549/50000] [Progress: 25.10%] [learning rate: 6.4e+03]\n",
            "[Step 12576/50000] [Progress: 25.15%] [learning rate: 7.6e+03]\n",
            "[Step 12576/50000] [Time: 122s] [Train Loss: 1.62e-01] [Train Acc: 0.98]\n",
            "[Step 12597/50000] [Progress: 25.19%] [learning rate: 5.1e+03]\n",
            "[Step 12624/50000] [Progress: 25.25%] [learning rate: 6.7e+03]\n",
            "[Step 12647/50000] [Progress: 25.29%] [learning rate: 6.0e+03]\n",
            "[Step 12648/50000] [Time: 123s] [Train Loss: 1.61e-01] [Train Acc: 0.98]\n",
            "[Step 12672/50000] [Progress: 25.34%] [learning rate: 6.5e+03]\n",
            "[Step 12696/50000] [Progress: 25.39%] [learning rate: 6.4e+03]\n",
            "[Step 12720/50000] [Time: 123s] [Train Loss: 1.60e-01] [Train Acc: 0.98]\n",
            "[Step 12721/50000] [Progress: 25.44%] [learning rate: 6.3e+03]\n",
            "[Step 12745/50000] [Progress: 25.49%] [learning rate: 6.2e+03]\n",
            "[Step 12770/50000] [Progress: 25.54%] [learning rate: 6.1e+03]\n",
            "[Step 12792/50000] [Time: 124s] [Train Loss: 1.59e-01] [Train Acc: 0.98]\n",
            "[Step 12796/50000] [Progress: 25.59%] [learning rate: 6.6e+03]\n",
            "[Step 12820/50000] [Progress: 25.64%] [learning rate: 5.9e+03]\n",
            "[Step 12847/50000] [Progress: 25.69%] [learning rate: 7.1e+03]\n",
            "[Step 12865/50000] [Time: 124s] [Train Loss: 1.58e-01] [Train Acc: 0.98]\n",
            "[Step 12870/50000] [Progress: 25.74%] [learning rate: 5.7e+03]\n",
            "[Step 12897/50000] [Progress: 25.79%] [learning rate: 6.8e+03]\n",
            "[Step 12920/50000] [Progress: 25.84%] [learning rate: 5.6e+03]\n",
            "[Step 12938/50000] [Time: 125s] [Train Loss: 1.57e-01] [Train Acc: 0.98]\n",
            "[Step 12946/50000] [Progress: 25.89%] [learning rate: 6.6e+03]\n",
            "[Step 12970/50000] [Progress: 25.94%] [learning rate: 5.9e+03]\n",
            "[Step 12996/50000] [Progress: 25.99%] [learning rate: 6.4e+03]\n",
            "[Step 13011/50000] [Time: 126s] [Train Loss: 1.57e-01] [Train Acc: 0.98]\n",
            "[Step 13020/50000] [Progress: 26.04%] [learning rate: 6.3e+03]\n",
            "[Step 13045/50000] [Progress: 26.09%] [learning rate: 6.2e+03]\n",
            "[Step 13071/50000] [Progress: 26.14%] [learning rate: 6.8e+03]\n",
            "[Step 13084/50000] [Time: 126s] [Train Loss: 1.56e-01] [Train Acc: 0.98]\n",
            "[Step 13094/50000] [Progress: 26.19%] [learning rate: 6.1e+03]\n",
            "[Step 13119/50000] [Progress: 26.24%] [learning rate: 6.6e+03]\n",
            "[Step 13144/50000] [Progress: 26.29%] [learning rate: 7.1e+03]\n",
            "[Step 13157/50000] [Time: 127s] [Train Loss: 1.55e-01] [Train Acc: 0.98]\n",
            "[Step 13167/50000] [Progress: 26.33%] [learning rate: 5.8e+03]\n",
            "[Step 13194/50000] [Progress: 26.39%] [learning rate: 6.9e+03]\n",
            "[Step 13217/50000] [Progress: 26.43%] [learning rate: 6.2e+03]\n",
            "[Step 13231/50000] [Time: 127s] [Train Loss: 1.54e-01] [Train Acc: 0.98]\n",
            "[Step 13242/50000] [Progress: 26.48%] [learning rate: 6.7e+03]\n",
            "[Step 13266/50000] [Progress: 26.53%] [learning rate: 6.0e+03]\n",
            "[Step 13293/50000] [Progress: 26.59%] [learning rate: 7.9e+03]\n",
            "[Step 13305/50000] [Time: 128s] [Train Loss: 1.53e-01] [Train Acc: 0.98]\n",
            "[Step 13314/50000] [Progress: 26.63%] [learning rate: 5.3e+03]\n",
            "[Step 13343/50000] [Progress: 26.69%] [learning rate: 6.9e+03]\n",
            "[Step 13368/50000] [Progress: 26.74%] [learning rate: 6.2e+03]\n",
            "[Step 13379/50000] [Time: 129s] [Train Loss: 1.52e-01] [Train Acc: 0.98]\n",
            "[Step 13394/50000] [Progress: 26.79%] [learning rate: 6.7e+03]\n",
            "[Step 13418/50000] [Progress: 26.84%] [learning rate: 6.6e+03]\n",
            "[Step 13443/50000] [Progress: 26.89%] [learning rate: 7.2e+03]\n",
            "[Step 13453/50000] [Time: 129s] [Train Loss: 1.52e-01] [Train Acc: 0.98]\n",
            "[Step 13466/50000] [Progress: 26.93%] [learning rate: 5.8e+03]\n",
            "[Step 13493/50000] [Progress: 26.99%] [learning rate: 7.0e+03]\n",
            "[Step 13516/50000] [Progress: 27.03%] [learning rate: 6.2e+03]\n",
            "[Step 13527/50000] [Time: 130s] [Train Loss: 1.51e-01] [Train Acc: 0.98]\n",
            "[Step 13541/50000] [Progress: 27.08%] [learning rate: 6.8e+03]\n",
            "[Step 13565/50000] [Progress: 27.13%] [learning rate: 6.7e+03]\n",
            "[Step 13590/50000] [Progress: 27.18%] [learning rate: 6.6e+03]\n",
            "[Step 13602/50000] [Time: 130s] [Train Loss: 1.50e-01] [Train Acc: 0.98]\n",
            "[Step 13614/50000] [Progress: 27.23%] [learning rate: 6.5e+03]\n",
            "[Step 13639/50000] [Progress: 27.28%] [learning rate: 6.4e+03]\n",
            "[Step 13665/50000] [Progress: 27.33%] [learning rate: 6.9e+03]\n",
            "[Step 13677/50000] [Time: 131s] [Train Loss: 1.49e-01] [Train Acc: 0.98]\n",
            "[Step 13689/50000] [Progress: 27.38%] [learning rate: 6.2e+03]\n",
            "[Step 13717/50000] [Progress: 27.43%] [learning rate: 7.4e+03]\n",
            "[Step 13741/50000] [Progress: 27.48%] [learning rate: 6.6e+03]\n",
            "[Step 13752/50000] [Time: 131s] [Train Loss: 1.48e-01] [Train Acc: 0.99]\n",
            "[Step 13766/50000] [Progress: 27.53%] [learning rate: 6.5e+03]\n",
            "[Step 13792/50000] [Progress: 27.58%] [learning rate: 6.4e+03]\n",
            "[Step 13817/50000] [Progress: 27.63%] [learning rate: 6.3e+03]\n",
            "[Step 13827/50000] [Time: 132s] [Train Loss: 1.48e-01] [Train Acc: 0.99]\n",
            "[Step 13844/50000] [Progress: 27.69%] [learning rate: 6.8e+03]\n",
            "[Step 13871/50000] [Progress: 27.74%] [learning rate: 7.4e+03]\n",
            "[Step 13895/50000] [Progress: 27.79%] [learning rate: 6.6e+03]\n",
            "[Step 13902/50000] [Time: 132s] [Train Loss: 1.47e-01] [Train Acc: 0.99]\n",
            "[Step 13920/50000] [Progress: 27.84%] [learning rate: 6.5e+03]\n",
            "[Step 13946/50000] [Progress: 27.89%] [learning rate: 6.4e+03]\n",
            "[Step 13971/50000] [Progress: 27.94%] [learning rate: 6.3e+03]\n",
            "[Step 13978/50000] [Time: 133s] [Train Loss: 1.46e-01] [Train Acc: 0.99]\n",
            "[Step 13996/50000] [Progress: 27.99%] [learning rate: 6.8e+03]\n",
            "[Step 14022/50000] [Progress: 28.04%] [learning rate: 7.4e+03]\n",
            "[Step 14047/50000] [Progress: 28.09%] [learning rate: 6.6e+03]\n",
            "[Step 14054/50000] [Time: 133s] [Train Loss: 1.45e-01] [Train Acc: 0.99]\n",
            "[Step 14073/50000] [Progress: 28.15%] [learning rate: 6.5e+03]\n",
            "[Step 14099/50000] [Progress: 28.20%] [learning rate: 7.1e+03]\n",
            "[Step 14122/50000] [Progress: 28.24%] [learning rate: 6.3e+03]\n",
            "[Step 14130/50000] [Time: 134s] [Train Loss: 1.44e-01] [Train Acc: 0.99]\n",
            "[Step 14148/50000] [Progress: 28.30%] [learning rate: 6.9e+03]\n",
            "[Step 14173/50000] [Progress: 28.35%] [learning rate: 6.8e+03]\n",
            "[Step 14199/50000] [Progress: 28.40%] [learning rate: 6.7e+03]\n",
            "[Step 14206/50000] [Time: 134s] [Train Loss: 1.44e-01] [Train Acc: 0.99]\n",
            "[Step 14223/50000] [Progress: 28.45%] [learning rate: 6.6e+03]\n",
            "[Step 14248/50000] [Progress: 28.50%] [learning rate: 6.5e+03]\n",
            "[Step 14273/50000] [Progress: 28.55%] [learning rate: 7.0e+03]\n",
            "[Step 14282/50000] [Time: 135s] [Train Loss: 1.43e-01] [Train Acc: 0.99]\n",
            "[Step 14297/50000] [Progress: 28.59%] [learning rate: 6.9e+03]\n",
            "[Step 14322/50000] [Progress: 28.64%] [learning rate: 6.8e+03]\n",
            "[Step 14348/50000] [Progress: 28.70%] [learning rate: 6.7e+03]\n",
            "[Step 14359/50000] [Time: 135s] [Train Loss: 1.42e-01] [Train Acc: 0.99]\n",
            "[Step 14372/50000] [Progress: 28.74%] [learning rate: 6.6e+03]\n",
            "[Step 14397/50000] [Progress: 28.79%] [learning rate: 7.2e+03]\n",
            "[Step 14421/50000] [Progress: 28.84%] [learning rate: 6.4e+03]\n",
            "[Step 14436/50000] [Time: 136s] [Train Loss: 1.41e-01] [Train Acc: 0.99]\n",
            "[Step 14449/50000] [Progress: 28.90%] [learning rate: 7.6e+03]\n",
            "[Step 14473/50000] [Progress: 28.95%] [learning rate: 6.8e+03]\n",
            "[Step 14498/50000] [Progress: 29.00%] [learning rate: 6.7e+03]\n",
            "[Step 14513/50000] [Time: 137s] [Train Loss: 1.40e-01] [Train Acc: 0.99]\n",
            "[Step 14524/50000] [Progress: 29.05%] [learning rate: 6.6e+03]\n",
            "[Step 14550/50000] [Progress: 29.10%] [learning rate: 7.2e+03]\n",
            "[Step 14574/50000] [Progress: 29.15%] [learning rate: 6.4e+03]\n",
            "[Step 14590/50000] [Time: 137s] [Train Loss: 1.40e-01] [Train Acc: 0.99]\n",
            "[Step 14601/50000] [Progress: 29.20%] [learning rate: 7.7e+03]\n",
            "[Step 14625/50000] [Progress: 29.25%] [learning rate: 6.9e+03]\n",
            "[Step 14650/50000] [Progress: 29.30%] [learning rate: 6.8e+03]\n",
            "[Step 14667/50000] [Time: 138s] [Train Loss: 1.39e-01] [Train Acc: 0.99]\n",
            "[Step 14676/50000] [Progress: 29.35%] [learning rate: 6.7e+03]\n",
            "[Step 14701/50000] [Progress: 29.40%] [learning rate: 6.6e+03]\n",
            "[Step 14726/50000] [Progress: 29.45%] [learning rate: 7.1e+03]\n",
            "[Step 14744/50000] [Time: 138s] [Train Loss: 1.38e-01] [Train Acc: 0.99]\n",
            "[Step 14752/50000] [Progress: 29.50%] [learning rate: 7.7e+03]\n",
            "[Step 14774/50000] [Progress: 29.55%] [learning rate: 6.3e+03]\n",
            "[Step 14800/50000] [Progress: 29.60%] [learning rate: 7.5e+03]\n",
            "[Step 14822/50000] [Time: 139s] [Train Loss: 1.37e-01] [Train Acc: 0.99]\n",
            "[Step 14823/50000] [Progress: 29.65%] [learning rate: 6.7e+03]\n",
            "[Step 14848/50000] [Progress: 29.70%] [learning rate: 7.3e+03]\n",
            "[Step 14872/50000] [Progress: 29.74%] [learning rate: 7.1e+03]\n",
            "[Step 14897/50000] [Progress: 29.79%] [learning rate: 7.0e+03]\n",
            "[Step 14900/50000] [Time: 140s] [Train Loss: 1.37e-01] [Train Acc: 0.99]\n",
            "[Step 14921/50000] [Progress: 29.84%] [learning rate: 6.9e+03]\n",
            "[Step 14946/50000] [Progress: 29.89%] [learning rate: 6.8e+03]\n",
            "[Step 14972/50000] [Progress: 29.94%] [learning rate: 7.4e+03]\n",
            "[Step 14978/50000] [Time: 140s] [Train Loss: 1.36e-01] [Train Acc: 0.99]\n",
            "[Step 14996/50000] [Progress: 29.99%] [learning rate: 6.6e+03]\n",
            "[Step 15023/50000] [Progress: 30.05%] [learning rate: 7.9e+03]\n",
            "[Step 15046/50000] [Progress: 30.09%] [learning rate: 6.4e+03]\n",
            "[Step 15056/50000] [Time: 141s] [Train Loss: 1.35e-01] [Train Acc: 0.99]\n",
            "[Step 15073/50000] [Progress: 30.15%] [learning rate: 7.7e+03]\n",
            "[Step 15096/50000] [Progress: 30.19%] [learning rate: 6.9e+03]\n",
            "[Step 15121/50000] [Progress: 30.24%] [learning rate: 6.8e+03]\n",
            "[Step 15134/50000] [Time: 141s] [Train Loss: 1.34e-01] [Train Acc: 0.99]\n",
            "[Step 15148/50000] [Progress: 30.30%] [learning rate: 7.3e+03]\n",
            "[Step 15174/50000] [Progress: 30.35%] [learning rate: 7.2e+03]\n",
            "[Step 15199/50000] [Progress: 30.40%] [learning rate: 7.1e+03]\n",
            "[Step 15212/50000] [Time: 142s] [Train Loss: 1.34e-01] [Train Acc: 0.99]\n",
            "[Step 15225/50000] [Progress: 30.45%] [learning rate: 7.0e+03]\n",
            "[Step 15251/50000] [Progress: 30.50%] [learning rate: 6.9e+03]\n",
            "[Step 15276/50000] [Progress: 30.55%] [learning rate: 6.8e+03]\n",
            "[Step 15291/50000] [Time: 142s] [Train Loss: 1.33e-01] [Train Acc: 0.99]\n",
            "[Step 15303/50000] [Progress: 30.61%] [learning rate: 7.3e+03]\n",
            "[Step 15329/50000] [Progress: 30.66%] [learning rate: 8.0e+03]\n",
            "[Step 15352/50000] [Progress: 30.70%] [learning rate: 6.5e+03]\n",
            "[Step 15370/50000] [Time: 143s] [Train Loss: 1.32e-01] [Train Acc: 0.99]\n",
            "[Step 15378/50000] [Progress: 30.76%] [learning rate: 7.0e+03]\n",
            "[Step 15403/50000] [Progress: 30.81%] [learning rate: 6.9e+03]\n",
            "[Step 15429/50000] [Progress: 30.86%] [learning rate: 7.5e+03]\n",
            "[Step 15449/50000] [Time: 144s] [Train Loss: 1.31e-01] [Train Acc: 0.99]\n",
            "[Step 15453/50000] [Progress: 30.91%] [learning rate: 6.7e+03]\n",
            "[Step 15482/50000] [Progress: 30.96%] [learning rate: 1.1e+04]\n",
            "[Step 15496/50000] [Progress: 30.99%] [learning rate: 3.7e+03]\n",
            "[Step 15528/50000] [Time: 144s] [Train Loss: 1.31e-01] [Train Acc: 0.99] [Eval Loss: 4.65e-01] [Eval Acc: 0.79]\n",
            "[Step 15530/50000] [Progress: 31.06%] [learning rate: 9.4e+03]\n",
            "[Step 15548/50000] [Progress: 31.10%] [learning rate: 4.7e+03]\n",
            "[Step 15579/50000] [Progress: 31.16%] [learning rate: 8.3e+03]\n",
            "[Step 15603/50000] [Progress: 31.21%] [learning rate: 6.7e+03]\n",
            "[Step 15607/50000] [Time: 146s] [Train Loss: 1.30e-01] [Train Acc: 0.99]\n",
            "[Step 15630/50000] [Progress: 31.26%] [learning rate: 8.0e+03]\n",
            "[Step 15654/50000] [Progress: 31.31%] [learning rate: 7.2e+03]\n",
            "[Step 15679/50000] [Progress: 31.36%] [learning rate: 7.1e+03]\n",
            "[Step 15687/50000] [Time: 147s] [Train Loss: 1.29e-01] [Train Acc: 0.99]\n",
            "[Step 15705/50000] [Progress: 31.41%] [learning rate: 7.0e+03]\n",
            "[Step 15730/50000] [Progress: 31.46%] [learning rate: 6.9e+03]\n",
            "[Step 15756/50000] [Progress: 31.51%] [learning rate: 7.4e+03]\n",
            "[Step 15767/50000] [Time: 148s] [Train Loss: 1.29e-01] [Train Acc: 0.99]\n",
            "[Step 15782/50000] [Progress: 31.56%] [learning rate: 8.1e+03]\n",
            "[Step 15805/50000] [Progress: 31.61%] [learning rate: 6.6e+03]\n",
            "[Step 15833/50000] [Progress: 31.67%] [learning rate: 7.8e+03]\n",
            "[Step 15847/50000] [Time: 148s] [Train Loss: 1.28e-01] [Train Acc: 0.99]\n",
            "[Step 15857/50000] [Progress: 31.71%] [learning rate: 7.0e+03]\n",
            "[Step 15883/50000] [Progress: 31.77%] [learning rate: 7.6e+03]\n",
            "[Step 15909/50000] [Progress: 31.82%] [learning rate: 7.5e+03]\n",
            "[Step 15927/50000] [Time: 149s] [Train Loss: 1.27e-01] [Train Acc: 0.99]\n",
            "[Step 15935/50000] [Progress: 31.87%] [learning rate: 8.1e+03]\n",
            "[Step 15958/50000] [Progress: 31.92%] [learning rate: 6.6e+03]\n",
            "[Step 15985/50000] [Progress: 31.97%] [learning rate: 7.9e+03]\n",
            "[Step 16007/50000] [Time: 149s] [Train Loss: 1.26e-01] [Train Acc: 0.99]\n",
            "[Step 16009/50000] [Progress: 32.02%] [learning rate: 7.0e+03]\n",
            "[Step 16036/50000] [Progress: 32.07%] [learning rate: 7.6e+03]\n",
            "[Step 16062/50000] [Progress: 32.12%] [learning rate: 8.3e+03]\n",
            "[Step 16085/50000] [Progress: 32.17%] [learning rate: 6.7e+03]\n",
            "[Step 16087/50000] [Time: 150s] [Train Loss: 1.26e-01] [Train Acc: 0.99]\n",
            "[Step 16112/50000] [Progress: 32.22%] [learning rate: 8.0e+03]\n",
            "[Step 16135/50000] [Progress: 32.27%] [learning rate: 6.5e+03]\n",
            "[Step 16162/50000] [Progress: 32.32%] [learning rate: 7.8e+03]\n",
            "[Step 16167/50000] [Time: 150s] [Train Loss: 1.25e-01] [Train Acc: 0.99]\n",
            "[Step 16187/50000] [Progress: 32.37%] [learning rate: 7.7e+03]\n",
            "[Step 16213/50000] [Progress: 32.43%] [learning rate: 8.3e+03]\n",
            "[Step 16237/50000] [Progress: 32.47%] [learning rate: 7.4e+03]\n",
            "[Step 16248/50000] [Time: 151s] [Train Loss: 1.24e-01] [Train Acc: 0.99]\n",
            "[Step 16262/50000] [Progress: 32.52%] [learning rate: 7.3e+03]\n",
            "[Step 16288/50000] [Progress: 32.58%] [learning rate: 7.2e+03]\n",
            "[Step 16313/50000] [Progress: 32.63%] [learning rate: 7.1e+03]\n",
            "[Step 16329/50000] [Time: 152s] [Train Loss: 1.24e-01] [Train Acc: 0.99]\n",
            "[Step 16339/50000] [Progress: 32.68%] [learning rate: 7.7e+03]\n",
            "[Step 16365/50000] [Progress: 32.73%] [learning rate: 8.3e+03]\n",
            "[Step 16388/50000] [Progress: 32.78%] [learning rate: 6.8e+03]\n",
            "[Step 16410/50000] [Time: 152s] [Train Loss: 1.23e-01] [Train Acc: 0.99]\n",
            "[Step 16414/50000] [Progress: 32.83%] [learning rate: 7.4e+03]\n",
            "[Step 16439/50000] [Progress: 32.88%] [learning rate: 7.2e+03]\n",
            "[Step 16465/50000] [Progress: 32.93%] [learning rate: 7.9e+03]\n",
            "[Step 16490/50000] [Progress: 32.98%] [learning rate: 7.7e+03]\n",
            "[Step 16491/50000] [Time: 153s] [Train Loss: 1.22e-01] [Train Acc: 0.99]\n",
            "[Step 16516/50000] [Progress: 33.03%] [learning rate: 7.6e+03]\n",
            "[Step 16540/50000] [Progress: 33.08%] [learning rate: 7.5e+03]\n",
            "[Step 16565/50000] [Progress: 33.13%] [learning rate: 7.4e+03]\n",
            "[Step 16572/50000] [Time: 154s] [Train Loss: 1.22e-01] [Train Acc: 0.99]\n",
            "[Step 16591/50000] [Progress: 33.18%] [learning rate: 8.0e+03]\n",
            "[Step 16615/50000] [Progress: 33.23%] [learning rate: 7.2e+03]\n",
            "[Step 16642/50000] [Progress: 33.28%] [learning rate: 8.5e+03]\n",
            "[Step 16653/50000] [Time: 154s] [Train Loss: 1.21e-01] [Train Acc: 0.99]\n",
            "[Step 16665/50000] [Progress: 33.33%] [learning rate: 7.0e+03]\n",
            "[Step 16691/50000] [Progress: 33.38%] [learning rate: 7.5e+03]\n",
            "[Step 16715/50000] [Progress: 33.43%] [learning rate: 7.4e+03]\n",
            "[Step 16735/50000] [Time: 155s] [Train Loss: 1.20e-01] [Train Acc: 0.99]\n",
            "[Step 16740/50000] [Progress: 33.48%] [learning rate: 8.0e+03]\n",
            "[Step 16764/50000] [Progress: 33.53%] [learning rate: 7.2e+03]\n",
            "[Step 16792/50000] [Progress: 33.58%] [learning rate: 8.6e+03]\n",
            "[Step 16816/50000] [Progress: 33.63%] [learning rate: 7.7e+03]\n",
            "[Step 16817/50000] [Time: 156s] [Train Loss: 1.20e-01] [Train Acc: 0.99]\n",
            "[Step 16841/50000] [Progress: 33.68%] [learning rate: 7.6e+03]\n",
            "[Step 16867/50000] [Progress: 33.73%] [learning rate: 7.5e+03]\n",
            "[Step 16892/50000] [Progress: 33.78%] [learning rate: 7.3e+03]\n",
            "[Step 16899/50000] [Time: 156s] [Train Loss: 1.19e-01] [Train Acc: 0.99]\n",
            "[Step 16919/50000] [Progress: 33.84%] [learning rate: 8.0e+03]\n",
            "[Step 16946/50000] [Progress: 33.89%] [learning rate: 8.6e+03]\n",
            "[Step 16970/50000] [Progress: 33.94%] [learning rate: 7.7e+03]\n",
            "[Step 16981/50000] [Time: 157s] [Train Loss: 1.18e-01] [Train Acc: 0.99]\n",
            "[Step 16995/50000] [Progress: 33.99%] [learning rate: 7.6e+03]\n",
            "[Step 17021/50000] [Progress: 34.04%] [learning rate: 8.2e+03]\n",
            "[Step 17044/50000] [Progress: 34.09%] [learning rate: 7.4e+03]\n",
            "[Step 17063/50000] [Time: 157s] [Train Loss: 1.18e-01] [Train Acc: 0.99]\n",
            "[Step 17070/50000] [Progress: 34.14%] [learning rate: 8.0e+03]\n",
            "[Step 17097/50000] [Progress: 34.19%] [learning rate: 8.7e+03]\n",
            "[Step 17119/50000] [Progress: 34.24%] [learning rate: 7.0e+03]\n",
            "[Step 17145/50000] [Progress: 34.29%] [learning rate: 8.4e+03]\n",
            "[Step 17145/50000] [Time: 158s] [Train Loss: 1.17e-01] [Train Acc: 0.99]\n",
            "[Step 17168/50000] [Progress: 34.34%] [learning rate: 7.5e+03]\n",
            "[Step 17193/50000] [Progress: 34.39%] [learning rate: 8.2e+03]\n",
            "[Step 17217/50000] [Progress: 34.43%] [learning rate: 8.0e+03]\n",
            "[Step 17227/50000] [Time: 159s] [Train Loss: 1.16e-01] [Train Acc: 0.99]\n",
            "[Step 17242/50000] [Progress: 34.48%] [learning rate: 7.9e+03]\n",
            "[Step 17266/50000] [Progress: 34.53%] [learning rate: 7.8e+03]\n",
            "[Step 17291/50000] [Progress: 34.58%] [learning rate: 7.7e+03]\n",
            "[Step 17310/50000] [Time: 159s] [Train Loss: 1.16e-01] [Train Acc: 0.99]\n",
            "[Step 17317/50000] [Progress: 34.63%] [learning rate: 8.3e+03]\n",
            "[Step 17341/50000] [Progress: 34.68%] [learning rate: 7.4e+03]\n",
            "[Step 17368/50000] [Progress: 34.74%] [learning rate: 8.9e+03]\n",
            "[Step 17391/50000] [Progress: 34.78%] [learning rate: 7.2e+03]\n",
            "[Step 17393/50000] [Time: 160s] [Train Loss: 1.15e-01] [Train Acc: 0.99]\n",
            "[Step 17418/50000] [Progress: 34.84%] [learning rate: 8.6e+03]\n",
            "[Step 17441/50000] [Progress: 34.88%] [learning rate: 7.7e+03]\n",
            "[Step 17466/50000] [Progress: 34.93%] [learning rate: 7.6e+03]\n",
            "[Step 17476/50000] [Time: 160s] [Train Loss: 1.15e-01] [Train Acc: 0.99]\n",
            "[Step 17493/50000] [Progress: 34.99%] [learning rate: 8.2e+03]\n",
            "[Step 17519/50000] [Progress: 35.04%] [learning rate: 8.1e+03]\n",
            "[Step 17544/50000] [Progress: 35.09%] [learning rate: 8.0e+03]\n",
            "[Step 17559/50000] [Time: 161s] [Train Loss: 1.14e-01] [Train Acc: 0.99]\n",
            "[Step 17570/50000] [Progress: 35.14%] [learning rate: 7.9e+03]\n",
            "[Step 17596/50000] [Progress: 35.19%] [learning rate: 7.7e+03]\n",
            "[Step 17621/50000] [Progress: 35.24%] [learning rate: 7.6e+03]\n",
            "[Step 17642/50000] [Time: 162s] [Train Loss: 1.13e-01] [Train Acc: 0.99]\n",
            "[Step 17648/50000] [Progress: 35.30%] [learning rate: 8.3e+03]\n",
            "[Step 17674/50000] [Progress: 35.35%] [learning rate: 8.9e+03]\n",
            "[Step 17697/50000] [Progress: 35.39%] [learning rate: 7.3e+03]\n",
            "[Step 17723/50000] [Progress: 35.45%] [learning rate: 7.9e+03]\n",
            "[Step 17725/50000] [Time: 162s] [Train Loss: 1.13e-01] [Train Acc: 0.99]\n",
            "[Step 17748/50000] [Progress: 35.50%] [learning rate: 7.8e+03]\n",
            "[Step 17774/50000] [Progress: 35.55%] [learning rate: 8.4e+03]\n",
            "[Step 17798/50000] [Progress: 35.60%] [learning rate: 7.5e+03]\n",
            "[Step 17809/50000] [Time: 163s] [Train Loss: 1.12e-01] [Train Acc: 0.99]\n",
            "[Step 17827/50000] [Progress: 35.65%] [learning rate: 9.9e+03]\n",
            "[Step 17850/50000] [Progress: 35.70%] [learning rate: 8.0e+03]\n",
            "[Step 17875/50000] [Progress: 35.75%] [learning rate: 7.9e+03]\n",
            "[Step 17893/50000] [Time: 163s] [Train Loss: 1.11e-01] [Train Acc: 0.99]\n",
            "[Step 17901/50000] [Progress: 35.80%] [learning rate: 7.8e+03]\n",
            "[Step 17926/50000] [Progress: 35.85%] [learning rate: 7.7e+03]\n",
            "[Step 17952/50000] [Progress: 35.90%] [learning rate: 8.3e+03]\n",
            "[Step 17977/50000] [Time: 164s] [Train Loss: 1.11e-01] [Train Acc: 0.99]\n",
            "[Step 17978/50000] [Progress: 35.96%] [learning rate: 9.0e+03]\n",
            "[Step 18001/50000] [Progress: 36.00%] [learning rate: 7.4e+03]\n",
            "[Step 18027/50000] [Progress: 36.05%] [learning rate: 8.0e+03]\n",
            "[Step 18052/50000] [Progress: 36.10%] [learning rate: 7.8e+03]\n",
            "[Step 18061/50000] [Time: 165s] [Train Loss: 1.10e-01] [Train Acc: 0.99]\n",
            "[Step 18078/50000] [Progress: 36.16%] [learning rate: 8.5e+03]\n",
            "[Step 18103/50000] [Progress: 36.21%] [learning rate: 8.4e+03]\n",
            "[Step 18129/50000] [Progress: 36.26%] [learning rate: 8.2e+03]\n",
            "[Step 18145/50000] [Time: 165s] [Train Loss: 1.10e-01] [Train Acc: 0.99]\n",
            "[Step 18153/50000] [Progress: 36.31%] [learning rate: 8.1e+03]\n",
            "[Step 18178/50000] [Progress: 36.36%] [learning rate: 8.0e+03]\n",
            "[Step 18204/50000] [Progress: 36.41%] [learning rate: 8.7e+03]\n",
            "[Step 18228/50000] [Progress: 36.46%] [learning rate: 7.8e+03]\n",
            "[Step 18229/50000] [Time: 166s] [Train Loss: 1.09e-01] [Train Acc: 0.99]\n",
            "[Step 18255/50000] [Progress: 36.51%] [learning rate: 9.3e+03]\n",
            "[Step 18278/50000] [Progress: 36.56%] [learning rate: 7.5e+03]\n",
            "[Step 18304/50000] [Progress: 36.61%] [learning rate: 8.2e+03]\n",
            "[Step 18313/50000] [Time: 167s] [Train Loss: 1.08e-01] [Train Acc: 0.99]\n",
            "[Step 18328/50000] [Progress: 36.66%] [learning rate: 8.0e+03]\n",
            "[Step 18353/50000] [Progress: 36.71%] [learning rate: 8.7e+03]\n",
            "[Step 18377/50000] [Progress: 36.75%] [learning rate: 7.8e+03]\n",
            "[Step 18397/50000] [Time: 167s] [Train Loss: 1.08e-01] [Train Acc: 1.00]\n",
            "[Step 18405/50000] [Progress: 36.81%] [learning rate: 9.3e+03]\n",
            "[Step 18429/50000] [Progress: 36.86%] [learning rate: 8.3e+03]\n",
            "[Step 18454/50000] [Progress: 36.91%] [learning rate: 8.2e+03]\n",
            "[Step 18480/50000] [Progress: 36.96%] [learning rate: 8.1e+03]\n",
            "[Step 18482/50000] [Time: 168s] [Train Loss: 1.07e-01] [Train Acc: 1.00]\n",
            "[Step 18505/50000] [Progress: 37.01%] [learning rate: 8.0e+03]\n",
            "[Step 18532/50000] [Progress: 37.06%] [learning rate: 8.6e+03]\n",
            "[Step 18559/50000] [Progress: 37.12%] [learning rate: 9.3e+03]\n",
            "[Step 18567/50000] [Time: 168s] [Train Loss: 1.06e-01] [Train Acc: 1.00]\n",
            "[Step 18583/50000] [Progress: 37.17%] [learning rate: 8.4e+03]\n",
            "[Step 18608/50000] [Progress: 37.22%] [learning rate: 8.2e+03]\n",
            "[Step 18634/50000] [Progress: 37.27%] [learning rate: 8.1e+03]\n",
            "[Step 18652/50000] [Time: 169s] [Train Loss: 1.06e-01] [Train Acc: 1.00]\n",
            "[Step 18659/50000] [Progress: 37.32%] [learning rate: 8.0e+03]\n",
            "[Step 18684/50000] [Progress: 37.37%] [learning rate: 8.7e+03]\n",
            "[Step 18710/50000] [Progress: 37.42%] [learning rate: 1.0e+04]\n",
            "[Step 18730/50000] [Progress: 37.46%] [learning rate: 6.9e+03]\n",
            "[Step 18737/50000] [Time: 170s] [Train Loss: 1.05e-01] [Train Acc: 1.00]\n",
            "[Step 18758/50000] [Progress: 37.52%] [learning rate: 9.1e+03]\n",
            "[Step 18783/50000] [Progress: 37.57%] [learning rate: 8.1e+03]\n",
            "[Step 18809/50000] [Progress: 37.62%] [learning rate: 8.8e+03]\n",
            "[Step 18822/50000] [Time: 170s] [Train Loss: 1.05e-01] [Train Acc: 1.00]\n",
            "[Step 18833/50000] [Progress: 37.67%] [learning rate: 8.7e+03]\n",
            "[Step 18858/50000] [Progress: 37.72%] [learning rate: 9.4e+03]\n",
            "[Step 18881/50000] [Progress: 37.76%] [learning rate: 7.7e+03]\n",
            "[Step 18907/50000] [Time: 171s] [Train Loss: 1.04e-01] [Train Acc: 1.00]\n",
            "[Step 18908/50000] [Progress: 37.82%] [learning rate: 9.1e+03]\n",
            "[Step 18931/50000] [Progress: 37.86%] [learning rate: 8.2e+03]\n",
            "[Step 18956/50000] [Progress: 37.91%] [learning rate: 8.9e+03]\n",
            "[Step 18980/50000] [Progress: 37.96%] [learning rate: 8.7e+03]\n",
            "[Step 18992/50000] [Time: 172s] [Train Loss: 1.04e-01] [Train Acc: 1.00]\n",
            "[Step 19005/50000] [Progress: 38.01%] [learning rate: 8.6e+03]\n",
            "[Step 19029/50000] [Progress: 38.06%] [learning rate: 8.5e+03]\n",
            "[Step 19054/50000] [Progress: 38.11%] [learning rate: 8.3e+03]\n",
            "[Step 19078/50000] [Time: 172s] [Train Loss: 1.03e-01] [Train Acc: 1.00]\n",
            "[Step 19080/50000] [Progress: 38.16%] [learning rate: 9.0e+03]\n",
            "[Step 19104/50000] [Progress: 38.21%] [learning rate: 8.1e+03]\n",
            "[Step 19131/50000] [Progress: 38.26%] [learning rate: 9.6e+03]\n",
            "[Step 19154/50000] [Progress: 38.31%] [learning rate: 7.9e+03]\n",
            "[Step 19164/50000] [Time: 173s] [Train Loss: 1.02e-01] [Train Acc: 1.00]\n",
            "[Step 19180/50000] [Progress: 38.36%] [learning rate: 8.5e+03]\n",
            "[Step 19204/50000] [Progress: 38.41%] [learning rate: 8.4e+03]\n",
            "[Step 19229/50000] [Progress: 38.46%] [learning rate: 9.1e+03]\n",
            "[Step 19250/50000] [Time: 173s] [Train Loss: 1.02e-01] [Train Acc: 1.00]\n",
            "[Step 19253/50000] [Progress: 38.51%] [learning rate: 8.1e+03]\n",
            "[Step 19281/50000] [Progress: 38.56%] [learning rate: 9.7e+03]\n",
            "[Step 19305/50000] [Progress: 38.61%] [learning rate: 8.7e+03]\n",
            "[Step 19330/50000] [Progress: 38.66%] [learning rate: 8.5e+03]\n",
            "[Step 19336/50000] [Time: 174s] [Train Loss: 1.01e-01] [Train Acc: 1.00]\n",
            "[Step 19356/50000] [Progress: 38.71%] [learning rate: 8.4e+03]\n",
            "[Step 19381/50000] [Progress: 38.76%] [learning rate: 8.3e+03]\n",
            "[Step 19408/50000] [Progress: 38.82%] [learning rate: 9.0e+03]\n",
            "[Step 19422/50000] [Time: 175s] [Train Loss: 1.01e-01] [Train Acc: 1.00]\n",
            "[Step 19435/50000] [Progress: 38.87%] [learning rate: 9.7e+03]\n",
            "[Step 19459/50000] [Progress: 38.92%] [learning rate: 8.7e+03]\n",
            "[Step 19484/50000] [Progress: 38.97%] [learning rate: 8.6e+03]\n",
            "[Step 19508/50000] [Time: 175s] [Train Loss: 1.00e-01] [Train Acc: 1.00]\n",
            "[Step 19510/50000] [Progress: 39.02%] [learning rate: 9.3e+03]\n",
            "[Step 19533/50000] [Progress: 39.07%] [learning rate: 8.3e+03]\n",
            "[Step 19559/50000] [Progress: 39.12%] [learning rate: 9.0e+03]\n",
            "[Step 19586/50000] [Progress: 39.17%] [learning rate: 1.1e+04]\n",
            "[Step 19594/50000] [Time: 176s] [Train Loss: 9.96e-02] [Train Acc: 1.00]\n",
            "[Step 19606/50000] [Progress: 39.21%] [learning rate: 7.2e+03]\n",
            "[Step 19634/50000] [Progress: 39.27%] [learning rate: 9.5e+03]\n",
            "[Step 19659/50000] [Progress: 39.32%] [learning rate: 8.5e+03]\n",
            "[Step 19680/50000] [Time: 177s] [Train Loss: 9.91e-02] [Train Acc: 1.00] [Eval Loss: 4.63e-01] [Eval Acc: 0.79]\n",
            "[Step 19685/50000] [Progress: 39.37%] [learning rate: 9.2e+03]\n",
            "[Step 19709/50000] [Progress: 39.42%] [learning rate: 9.1e+03]\n",
            "[Step 19734/50000] [Progress: 39.47%] [learning rate: 9.8e+03]\n",
            "[Step 19757/50000] [Progress: 39.51%] [learning rate: 8.0e+03]\n",
            "[Step 19767/50000] [Time: 180s] [Train Loss: 9.85e-02] [Train Acc: 1.00]\n",
            "[Step 19784/50000] [Progress: 39.57%] [learning rate: 9.5e+03]\n",
            "[Step 19807/50000] [Progress: 39.61%] [learning rate: 8.5e+03]\n",
            "[Step 19832/50000] [Progress: 39.66%] [learning rate: 9.2e+03]\n",
            "[Step 19854/50000] [Time: 180s] [Train Loss: 9.80e-02] [Train Acc: 1.00]\n",
            "[Step 19856/50000] [Progress: 39.71%] [learning rate: 9.1e+03]\n",
            "[Step 19881/50000] [Progress: 39.76%] [learning rate: 9.0e+03]\n",
            "[Step 19905/50000] [Progress: 39.81%] [learning rate: 8.8e+03]\n",
            "[Step 19930/50000] [Progress: 39.86%] [learning rate: 8.7e+03]\n",
            "[Step 19941/50000] [Time: 181s] [Train Loss: 9.74e-02] [Train Acc: 1.00]\n",
            "[Step 19956/50000] [Progress: 39.91%] [learning rate: 9.4e+03]\n",
            "[Step 19980/50000] [Progress: 39.96%] [learning rate: 8.4e+03]\n",
            "[Step 20007/50000] [Progress: 40.01%] [learning rate: 1.0e+04]\n",
            "[Step 20028/50000] [Time: 182s] [Train Loss: 9.69e-02] [Train Acc: 1.00]\n",
            "[Step 20030/50000] [Progress: 40.06%] [learning rate: 8.2e+03]\n",
            "[Step 20056/50000] [Progress: 40.11%] [learning rate: 8.9e+03]\n",
            "[Step 20080/50000] [Progress: 40.16%] [learning rate: 8.7e+03]\n",
            "[Step 20105/50000] [Progress: 40.21%] [learning rate: 9.5e+03]\n",
            "[Step 20115/50000] [Time: 182s] [Train Loss: 9.64e-02] [Train Acc: 1.00]\n",
            "[Step 20129/50000] [Progress: 40.26%] [learning rate: 8.5e+03]\n",
            "[Step 20157/50000] [Progress: 40.31%] [learning rate: 1.0e+04]\n",
            "[Step 20181/50000] [Progress: 40.36%] [learning rate: 9.0e+03]\n",
            "[Step 20202/50000] [Time: 183s] [Train Loss: 9.58e-02] [Train Acc: 1.00]\n",
            "[Step 20206/50000] [Progress: 40.41%] [learning rate: 8.9e+03]\n",
            "[Step 20232/50000] [Progress: 40.46%] [learning rate: 8.8e+03]\n",
            "[Step 20257/50000] [Progress: 40.51%] [learning rate: 8.6e+03]\n",
            "[Step 20284/50000] [Progress: 40.57%] [learning rate: 9.4e+03]\n",
            "[Step 20289/50000] [Time: 183s] [Train Loss: 9.53e-02] [Train Acc: 1.00]\n",
            "[Step 20311/50000] [Progress: 40.62%] [learning rate: 1.0e+04]\n",
            "[Step 20335/50000] [Progress: 40.67%] [learning rate: 9.1e+03]\n",
            "[Step 20360/50000] [Progress: 40.72%] [learning rate: 9.0e+03]\n",
            "[Step 20376/50000] [Time: 184s] [Train Loss: 9.48e-02] [Train Acc: 1.00]\n",
            "[Step 20386/50000] [Progress: 40.77%] [learning rate: 9.7e+03]\n",
            "[Step 20409/50000] [Progress: 40.82%] [learning rate: 8.7e+03]\n",
            "[Step 20435/50000] [Progress: 40.87%] [learning rate: 9.4e+03]\n",
            "[Step 20462/50000] [Progress: 40.92%] [learning rate: 1.1e+04]\n",
            "[Step 20463/50000] [Time: 185s] [Train Loss: 9.42e-02] [Train Acc: 1.00]\n",
            "[Step 20482/50000] [Progress: 40.96%] [learning rate: 7.5e+03]\n",
            "[Step 20510/50000] [Progress: 41.02%] [learning rate: 9.9e+03]\n",
            "[Step 20535/50000] [Progress: 41.07%] [learning rate: 8.9e+03]\n",
            "[Step 20551/50000] [Time: 185s] [Train Loss: 9.37e-02] [Train Acc: 1.00]\n",
            "[Step 20561/50000] [Progress: 41.12%] [learning rate: 9.6e+03]\n",
            "[Step 20585/50000] [Progress: 41.17%] [learning rate: 9.5e+03]\n",
            "[Step 20610/50000] [Progress: 41.22%] [learning rate: 1.0e+04]\n",
            "[Step 20633/50000] [Progress: 41.27%] [learning rate: 8.3e+03]\n",
            "[Step 20639/50000] [Time: 186s] [Train Loss: 9.32e-02] [Train Acc: 1.00]\n",
            "[Step 20660/50000] [Progress: 41.32%] [learning rate: 9.9e+03]\n",
            "[Step 20683/50000] [Progress: 41.37%] [learning rate: 8.9e+03]\n",
            "[Step 20708/50000] [Progress: 41.42%] [learning rate: 9.6e+03]\n",
            "[Step 20727/50000] [Time: 187s] [Train Loss: 9.27e-02] [Train Acc: 1.00]\n",
            "[Step 20732/50000] [Progress: 41.46%] [learning rate: 9.5e+03]\n",
            "[Step 20757/50000] [Progress: 41.51%] [learning rate: 9.4e+03]\n",
            "[Step 20781/50000] [Progress: 41.56%] [learning rate: 9.2e+03]\n",
            "[Step 20806/50000] [Progress: 41.61%] [learning rate: 9.1e+03]\n",
            "[Step 20815/50000] [Time: 187s] [Train Loss: 9.22e-02] [Train Acc: 1.00]\n",
            "[Step 20832/50000] [Progress: 41.66%] [learning rate: 9.8e+03]\n",
            "[Step 20856/50000] [Progress: 41.71%] [learning rate: 8.8e+03]\n",
            "[Step 20883/50000] [Progress: 41.77%] [learning rate: 1.0e+04]\n",
            "[Step 20903/50000] [Time: 188s] [Train Loss: 9.16e-02] [Train Acc: 1.00]\n",
            "[Step 20906/50000] [Progress: 41.81%] [learning rate: 8.5e+03]\n",
            "[Step 20932/50000] [Progress: 41.86%] [learning rate: 9.3e+03]\n",
            "[Step 20956/50000] [Progress: 41.91%] [learning rate: 9.1e+03]\n",
            "[Step 20981/50000] [Progress: 41.96%] [learning rate: 9.9e+03]\n",
            "[Step 20991/50000] [Time: 189s] [Train Loss: 9.11e-02] [Train Acc: 1.00]\n",
            "[Step 21005/50000] [Progress: 42.01%] [learning rate: 8.8e+03]\n",
            "[Step 21033/50000] [Progress: 42.07%] [learning rate: 1.1e+04]\n",
            "[Step 21057/50000] [Progress: 42.11%] [learning rate: 9.4e+03]\n",
            "[Step 21079/50000] [Time: 189s] [Train Loss: 9.06e-02] [Train Acc: 1.00]\n",
            "[Step 21082/50000] [Progress: 42.16%] [learning rate: 9.3e+03]\n",
            "[Step 21108/50000] [Progress: 42.22%] [learning rate: 9.2e+03]\n",
            "[Step 21133/50000] [Progress: 42.27%] [learning rate: 9.0e+03]\n",
            "[Step 21160/50000] [Progress: 42.32%] [learning rate: 9.8e+03]\n",
            "[Step 21167/50000] [Time: 190s] [Train Loss: 9.01e-02] [Train Acc: 1.00]\n",
            "[Step 21187/50000] [Progress: 42.37%] [learning rate: 1.1e+04]\n",
            "[Step 21211/50000] [Progress: 42.42%] [learning rate: 9.5e+03]\n",
            "[Step 21236/50000] [Progress: 42.47%] [learning rate: 9.3e+03]\n",
            "[Step 21255/50000] [Time: 191s] [Train Loss: 8.96e-02] [Train Acc: 1.00]\n",
            "[Step 21262/50000] [Progress: 42.52%] [learning rate: 1.0e+04]\n",
            "[Step 21285/50000] [Progress: 42.57%] [learning rate: 9.1e+03]\n",
            "[Step 21311/50000] [Progress: 42.62%] [learning rate: 9.8e+03]\n",
            "[Step 21338/50000] [Progress: 42.68%] [learning rate: 1.2e+04]\n",
            "[Step 21344/50000] [Time: 191s] [Train Loss: 8.91e-02] [Train Acc: 1.00]\n",
            "[Step 21358/50000] [Progress: 42.72%] [learning rate: 7.9e+03]\n",
            "[Step 21386/50000] [Progress: 42.77%] [learning rate: 1.0e+04]\n",
            "[Step 21411/50000] [Progress: 42.82%] [learning rate: 9.2e+03]\n",
            "[Step 21433/50000] [Time: 192s] [Train Loss: 8.86e-02] [Train Acc: 1.00]\n",
            "[Step 21437/50000] [Progress: 42.87%] [learning rate: 1.0e+04]\n",
            "[Step 21461/50000] [Progress: 42.92%] [learning rate: 9.9e+03]\n",
            "[Step 21486/50000] [Progress: 42.97%] [learning rate: 1.1e+04]\n",
            "[Step 21509/50000] [Progress: 43.02%] [learning rate: 8.7e+03]\n",
            "[Step 21522/50000] [Time: 193s] [Train Loss: 8.81e-02] [Train Acc: 1.00]\n",
            "[Step 21536/50000] [Progress: 43.07%] [learning rate: 1.0e+04]\n",
            "[Step 21559/50000] [Progress: 43.12%] [learning rate: 9.3e+03]\n",
            "[Step 21584/50000] [Progress: 43.17%] [learning rate: 1.0e+04]\n",
            "[Step 21608/50000] [Progress: 43.22%] [learning rate: 9.9e+03]\n",
            "[Step 21611/50000] [Time: 193s] [Train Loss: 8.76e-02] [Train Acc: 1.00]\n",
            "[Step 21633/50000] [Progress: 43.27%] [learning rate: 1.1e+04]\n",
            "[Step 21656/50000] [Progress: 43.31%] [learning rate: 8.7e+03]\n",
            "[Step 21683/50000] [Progress: 43.37%] [learning rate: 1.0e+04]\n",
            "[Step 21700/50000] [Time: 194s] [Train Loss: 8.72e-02] [Train Acc: 1.00]\n",
            "[Step 21706/50000] [Progress: 43.41%] [learning rate: 9.3e+03]\n",
            "[Step 21731/50000] [Progress: 43.46%] [learning rate: 1.0e+04]\n",
            "[Step 21756/50000] [Progress: 43.51%] [learning rate: 9.9e+03]\n",
            "[Step 21782/50000] [Progress: 43.56%] [learning rate: 9.8e+03]\n",
            "[Step 21789/50000] [Time: 195s] [Train Loss: 8.67e-02] [Train Acc: 1.00]\n",
            "[Step 21806/50000] [Progress: 43.61%] [learning rate: 9.6e+03]\n",
            "[Step 21831/50000] [Progress: 43.66%] [learning rate: 9.5e+03]\n",
            "[Step 21857/50000] [Progress: 43.71%] [learning rate: 1.0e+04]\n",
            "[Step 21878/50000] [Time: 195s] [Train Loss: 8.62e-02] [Train Acc: 1.00]\n",
            "[Step 21881/50000] [Progress: 43.76%] [learning rate: 9.2e+03]\n",
            "[Step 21909/50000] [Progress: 43.82%] [learning rate: 1.1e+04]\n",
            "[Step 21933/50000] [Progress: 43.87%] [learning rate: 9.8e+03]\n",
            "[Step 21958/50000] [Progress: 43.92%] [learning rate: 9.7e+03]\n",
            "[Step 21967/50000] [Time: 196s] [Train Loss: 8.57e-02] [Train Acc: 1.00]\n",
            "[Step 21984/50000] [Progress: 43.97%] [learning rate: 9.5e+03]\n",
            "[Step 22009/50000] [Progress: 44.02%] [learning rate: 9.4e+03]\n",
            "[Step 22034/50000] [Progress: 44.07%] [learning rate: 1.0e+04]\n",
            "[Step 22056/50000] [Time: 197s] [Train Loss: 8.52e-02] [Train Acc: 1.00]\n",
            "[Step 22059/50000] [Progress: 44.12%] [learning rate: 1.1e+04]\n",
            "[Step 22082/50000] [Progress: 44.16%] [learning rate: 9.0e+03]\n",
            "[Step 22109/50000] [Progress: 44.22%] [learning rate: 1.1e+04]\n",
            "[Step 22132/50000] [Progress: 44.26%] [learning rate: 9.6e+03]\n",
            "[Step 22145/50000] [Time: 197s] [Train Loss: 8.48e-02] [Train Acc: 1.00]\n",
            "[Step 22157/50000] [Progress: 44.31%] [learning rate: 9.4e+03]\n",
            "[Step 22183/50000] [Progress: 44.37%] [learning rate: 1.0e+04]\n",
            "[Step 22210/50000] [Progress: 44.42%] [learning rate: 1.2e+04]\n",
            "[Step 22231/50000] [Progress: 44.46%] [learning rate: 8.2e+03]\n",
            "[Step 22235/50000] [Time: 198s] [Train Loss: 8.43e-02] [Train Acc: 1.00]\n",
            "[Step 22260/50000] [Progress: 44.52%] [learning rate: 1.1e+04]\n",
            "[Step 22285/50000] [Progress: 44.57%] [learning rate: 9.6e+03]\n",
            "[Step 22311/50000] [Progress: 44.62%] [learning rate: 1.0e+04]\n",
            "[Step 22325/50000] [Time: 198s] [Train Loss: 8.38e-02] [Train Acc: 1.00]\n",
            "[Step 22335/50000] [Progress: 44.67%] [learning rate: 1.0e+04]\n",
            "[Step 22360/50000] [Progress: 44.72%] [learning rate: 1.1e+04]\n",
            "[Step 22383/50000] [Progress: 44.77%] [learning rate: 9.1e+03]\n",
            "[Step 22410/50000] [Progress: 44.82%] [learning rate: 1.1e+04]\n",
            "[Step 22415/50000] [Time: 199s] [Train Loss: 8.34e-02] [Train Acc: 1.00]\n",
            "[Step 22433/50000] [Progress: 44.87%] [learning rate: 9.7e+03]\n",
            "[Step 22458/50000] [Progress: 44.92%] [learning rate: 1.0e+04]\n",
            "[Step 22482/50000] [Progress: 44.96%] [learning rate: 1.0e+04]\n",
            "[Step 22505/50000] [Time: 200s] [Train Loss: 8.29e-02] [Train Acc: 1.00]\n",
            "[Step 22507/50000] [Progress: 45.01%] [learning rate: 1.0e+04]\n",
            "[Step 22531/50000] [Progress: 45.06%] [learning rate: 1.0e+04]\n",
            "[Step 22556/50000] [Progress: 45.11%] [learning rate: 9.9e+03]\n",
            "[Step 22582/50000] [Progress: 45.16%] [learning rate: 1.1e+04]\n",
            "[Step 22595/50000] [Time: 200s] [Train Loss: 8.25e-02] [Train Acc: 1.00]\n",
            "[Step 22606/50000] [Progress: 45.21%] [learning rate: 9.6e+03]\n",
            "[Step 22633/50000] [Progress: 45.27%] [learning rate: 1.1e+04]\n",
            "[Step 22656/50000] [Progress: 45.31%] [learning rate: 9.3e+03]\n",
            "[Step 22683/50000] [Progress: 45.37%] [learning rate: 1.1e+04]\n",
            "[Step 22685/50000] [Time: 201s] [Train Loss: 8.20e-02] [Train Acc: 1.00]\n",
            "[Step 22706/50000] [Progress: 45.41%] [learning rate: 9.9e+03]\n",
            "[Step 22731/50000] [Progress: 45.46%] [learning rate: 9.8e+03]\n",
            "[Step 22756/50000] [Progress: 45.51%] [learning rate: 1.1e+04]\n",
            "[Step 22775/50000] [Time: 202s] [Train Loss: 8.15e-02] [Train Acc: 1.00]\n",
            "[Step 22781/50000] [Progress: 45.56%] [learning rate: 1.0e+04]\n",
            "[Step 22807/50000] [Progress: 45.61%] [learning rate: 1.0e+04]\n",
            "[Step 22833/50000] [Progress: 45.67%] [learning rate: 1.0e+04]\n",
            "[Step 22858/50000] [Progress: 45.72%] [learning rate: 1.0e+04]\n",
            "[Step 22865/50000] [Time: 202s] [Train Loss: 8.11e-02] [Train Acc: 1.00]\n",
            "[Step 22884/50000] [Progress: 45.77%] [learning rate: 1.1e+04]\n",
            "[Step 22908/50000] [Progress: 45.82%] [learning rate: 9.7e+03]\n",
            "[Step 22936/50000] [Progress: 45.87%] [learning rate: 1.2e+04]\n",
            "[Step 22955/50000] [Time: 203s] [Train Loss: 8.06e-02] [Train Acc: 1.00]\n",
            "[Step 22959/50000] [Progress: 45.92%] [learning rate: 9.4e+03]\n",
            "[Step 22986/50000] [Progress: 45.97%] [learning rate: 1.1e+04]\n",
            "[Step 23009/50000] [Progress: 46.02%] [learning rate: 9.1e+03]\n",
            "[Step 23035/50000] [Progress: 46.07%] [learning rate: 1.1e+04]\n",
            "[Step 23045/50000] [Time: 204s] [Train Loss: 8.02e-02] [Train Acc: 1.00]\n",
            "[Step 23059/50000] [Progress: 46.12%] [learning rate: 1.1e+04]\n",
            "[Step 23085/50000] [Progress: 46.17%] [learning rate: 1.3e+04]\n",
            "[Step 23105/50000] [Progress: 46.21%] [learning rate: 8.6e+03]\n",
            "[Step 23133/50000] [Progress: 46.27%] [learning rate: 1.1e+04]\n",
            "[Step 23136/50000] [Time: 205s] [Train Loss: 7.97e-02] [Train Acc: 1.00]\n",
            "[Step 23158/50000] [Progress: 46.32%] [learning rate: 1.0e+04]\n",
            "[Step 23184/50000] [Progress: 46.37%] [learning rate: 1.1e+04]\n",
            "[Step 23208/50000] [Progress: 46.42%] [learning rate: 1.1e+04]\n",
            "[Step 23227/50000] [Time: 205s] [Train Loss: 7.93e-02] [Train Acc: 1.00]\n",
            "[Step 23233/50000] [Progress: 46.47%] [learning rate: 1.2e+04]\n",
            "[Step 23256/50000] [Progress: 46.51%] [learning rate: 9.5e+03]\n",
            "[Step 23284/50000] [Progress: 46.57%] [learning rate: 1.1e+04]\n",
            "[Step 23308/50000] [Progress: 46.62%] [learning rate: 1.0e+04]\n",
            "[Step 23318/50000] [Time: 206s] [Train Loss: 7.89e-02] [Train Acc: 1.00]\n",
            "[Step 23333/50000] [Progress: 46.67%] [learning rate: 1.1e+04]\n",
            "[Step 23357/50000] [Progress: 46.71%] [learning rate: 1.1e+04]\n",
            "[Step 23382/50000] [Progress: 46.76%] [learning rate: 1.2e+04]\n",
            "[Step 23405/50000] [Progress: 46.81%] [learning rate: 9.5e+03]\n",
            "[Step 23409/50000] [Time: 207s] [Train Loss: 7.84e-02] [Train Acc: 1.00]\n",
            "[Step 23432/50000] [Progress: 46.86%] [learning rate: 1.1e+04]\n",
            "[Step 23455/50000] [Progress: 46.91%] [learning rate: 1.0e+04]\n",
            "[Step 23480/50000] [Progress: 46.96%] [learning rate: 1.1e+04]\n",
            "[Step 23500/50000] [Time: 207s] [Train Loss: 7.80e-02] [Train Acc: 1.00]\n",
            "[Step 23504/50000] [Progress: 47.01%] [learning rate: 1.1e+04]\n",
            "[Step 23529/50000] [Progress: 47.06%] [learning rate: 1.1e+04]\n",
            "[Step 23553/50000] [Progress: 47.11%] [learning rate: 1.0e+04]\n",
            "[Step 23578/50000] [Progress: 47.16%] [learning rate: 1.0e+04]\n",
            "[Step 23591/50000] [Time: 208s] [Train Loss: 7.76e-02] [Train Acc: 1.00]\n",
            "[Step 23604/50000] [Progress: 47.21%] [learning rate: 1.1e+04]\n",
            "[Step 23628/50000] [Progress: 47.26%] [learning rate: 1.0e+04]\n",
            "[Step 23656/50000] [Progress: 47.31%] [learning rate: 1.2e+04]\n",
            "[Step 23680/50000] [Progress: 47.36%] [learning rate: 1.1e+04]\n",
            "[Step 23682/50000] [Time: 208s] [Train Loss: 7.71e-02] [Train Acc: 1.00]\n",
            "[Step 23705/50000] [Progress: 47.41%] [learning rate: 1.1e+04]\n",
            "[Step 23731/50000] [Progress: 47.46%] [learning rate: 1.0e+04]\n",
            "[Step 23756/50000] [Progress: 47.51%] [learning rate: 1.0e+04]\n",
            "[Step 23773/50000] [Time: 209s] [Train Loss: 7.67e-02] [Train Acc: 1.00]\n",
            "[Step 23783/50000] [Progress: 47.57%] [learning rate: 1.1e+04]\n",
            "[Step 23809/50000] [Progress: 47.62%] [learning rate: 1.2e+04]\n",
            "[Step 23832/50000] [Progress: 47.66%] [learning rate: 9.8e+03]\n",
            "[Step 23858/50000] [Progress: 47.72%] [learning rate: 1.1e+04]\n",
            "[Step 23864/50000] [Time: 210s] [Train Loss: 7.63e-02] [Train Acc: 1.00]\n",
            "[Step 23882/50000] [Progress: 47.76%] [learning rate: 1.0e+04]\n",
            "[Step 23907/50000] [Progress: 47.81%] [learning rate: 1.1e+04]\n",
            "[Step 23931/50000] [Progress: 47.86%] [learning rate: 1.0e+04]\n",
            "[Step 23955/50000] [Time: 210s] [Train Loss: 7.58e-02] [Train Acc: 1.00]\n",
            "[Step 23958/50000] [Progress: 47.92%] [learning rate: 1.3e+04]\n",
            "[Step 23978/50000] [Progress: 47.96%] [learning rate: 8.9e+03]\n",
            "[Step 24006/50000] [Progress: 48.01%] [learning rate: 1.2e+04]\n",
            "[Step 24031/50000] [Progress: 48.06%] [learning rate: 1.0e+04]\n",
            "[Step 24046/50000] [Time: 211s] [Train Loss: 7.54e-02] [Train Acc: 1.00]\n",
            "[Step 24057/50000] [Progress: 48.11%] [learning rate: 1.1e+04]\n",
            "[Step 24081/50000] [Progress: 48.16%] [learning rate: 1.1e+04]\n",
            "[Step 24106/50000] [Progress: 48.21%] [learning rate: 1.2e+04]\n",
            "[Step 24129/50000] [Progress: 48.26%] [learning rate: 9.9e+03]\n",
            "[Step 24137/50000] [Time: 212s] [Train Loss: 7.50e-02] [Train Acc: 1.00] [Eval Loss: 4.67e-01] [Eval Acc: 0.80]\n",
            "[Step 24156/50000] [Progress: 48.31%] [learning rate: 1.2e+04]\n",
            "[Step 24179/50000] [Progress: 48.36%] [learning rate: 1.1e+04]\n",
            "[Step 24204/50000] [Progress: 48.41%] [learning rate: 1.1e+04]\n",
            "[Step 24228/50000] [Progress: 48.46%] [learning rate: 1.1e+04]\n",
            "[Step 24229/50000] [Time: 214s] [Train Loss: 7.46e-02] [Train Acc: 1.00]\n",
            "[Step 24253/50000] [Progress: 48.51%] [learning rate: 1.2e+04]\n",
            "[Step 24276/50000] [Progress: 48.55%] [learning rate: 9.9e+03]\n",
            "[Step 24303/50000] [Progress: 48.61%] [learning rate: 1.2e+04]\n",
            "[Step 24321/50000] [Time: 215s] [Train Loss: 7.42e-02] [Train Acc: 1.00]\n",
            "[Step 24326/50000] [Progress: 48.65%] [learning rate: 1.1e+04]\n",
            "[Step 24351/50000] [Progress: 48.70%] [learning rate: 1.1e+04]\n",
            "[Step 24375/50000] [Progress: 48.75%] [learning rate: 1.1e+04]\n",
            "[Step 24400/50000] [Progress: 48.80%] [learning rate: 1.1e+04]\n",
            "[Step 24413/50000] [Time: 215s] [Train Loss: 7.38e-02] [Train Acc: 1.00]\n",
            "[Step 24424/50000] [Progress: 48.85%] [learning rate: 1.1e+04]\n",
            "[Step 24449/50000] [Progress: 48.90%] [learning rate: 1.1e+04]\n",
            "[Step 24475/50000] [Progress: 48.95%] [learning rate: 1.2e+04]\n",
            "[Step 24499/50000] [Progress: 49.00%] [learning rate: 1.0e+04]\n",
            "[Step 24505/50000] [Time: 216s] [Train Loss: 7.34e-02] [Train Acc: 1.00]\n",
            "[Step 24526/50000] [Progress: 49.05%] [learning rate: 1.2e+04]\n",
            "[Step 24549/50000] [Progress: 49.10%] [learning rate: 1.0e+04]\n",
            "[Step 24575/50000] [Progress: 49.15%] [learning rate: 1.1e+04]\n",
            "[Step 24597/50000] [Time: 217s] [Train Loss: 7.30e-02] [Train Acc: 1.00]\n",
            "[Step 24599/50000] [Progress: 49.20%] [learning rate: 1.1e+04]\n",
            "[Step 24624/50000] [Progress: 49.25%] [learning rate: 1.2e+04]\n",
            "[Step 24648/50000] [Progress: 49.30%] [learning rate: 1.1e+04]\n",
            "[Step 24676/50000] [Progress: 49.35%] [learning rate: 1.3e+04]\n",
            "[Step 24689/50000] [Time: 218s] [Train Loss: 7.26e-02] [Train Acc: 1.00]\n",
            "[Step 24700/50000] [Progress: 49.40%] [learning rate: 1.1e+04]\n",
            "[Step 24725/50000] [Progress: 49.45%] [learning rate: 1.1e+04]\n",
            "[Step 24751/50000] [Progress: 49.50%] [learning rate: 1.2e+04]\n",
            "[Step 24774/50000] [Progress: 49.55%] [learning rate: 1.1e+04]\n",
            "[Step 24781/50000] [Time: 218s] [Train Loss: 7.22e-02] [Train Acc: 1.00]\n",
            "[Step 24800/50000] [Progress: 49.60%] [learning rate: 1.2e+04]\n",
            "[Step 24826/50000] [Progress: 49.65%] [learning rate: 1.3e+04]\n",
            "[Step 24849/50000] [Progress: 49.70%] [learning rate: 1.0e+04]\n",
            "[Step 24873/50000] [Time: 219s] [Train Loss: 7.18e-02] [Train Acc: 1.00]\n",
            "[Step 24875/50000] [Progress: 49.75%] [learning rate: 1.1e+04]\n",
            "[Step 24900/50000] [Progress: 49.80%] [learning rate: 1.1e+04]\n",
            "[Step 24926/50000] [Progress: 49.85%] [learning rate: 1.2e+04]\n",
            "[Step 24950/50000] [Progress: 49.90%] [learning rate: 1.1e+04]\n",
            "[Step 24965/50000] [Time: 220s] [Train Loss: 7.14e-02] [Train Acc: 1.00]\n",
            "[Step 24977/50000] [Progress: 49.95%] [learning rate: 1.4e+04]\n",
            "[Step 24998/50000] [Progress: 50.00%] [learning rate: 9.3e+03]\n",
            "[Step 25027/50000] [Progress: 50.05%] [learning rate: 1.2e+04]\n",
            "[Step 25052/50000] [Progress: 50.10%] [learning rate: 1.1e+04]\n",
            "[Step 25057/50000] [Time: 220s] [Train Loss: 7.10e-02] [Train Acc: 1.00]\n",
            "[Step 25078/50000] [Progress: 50.16%] [learning rate: 1.2e+04]\n",
            "[Step 25102/50000] [Progress: 50.20%] [learning rate: 1.2e+04]\n",
            "[Step 25127/50000] [Progress: 50.25%] [learning rate: 1.3e+04]\n",
            "[Step 25149/50000] [Time: 221s] [Train Loss: 7.06e-02] [Train Acc: 1.00]\n",
            "[Step 25150/50000] [Progress: 50.30%] [learning rate: 1.0e+04]\n",
            "[Step 25177/50000] [Progress: 50.35%] [learning rate: 1.2e+04]\n",
            "[Step 25200/50000] [Progress: 50.40%] [learning rate: 1.1e+04]\n",
            "[Step 25225/50000] [Progress: 50.45%] [learning rate: 1.2e+04]\n",
            "[Step 25241/50000] [Time: 221s] [Train Loss: 7.02e-02] [Train Acc: 1.00]\n",
            "[Step 25249/50000] [Progress: 50.50%] [learning rate: 1.2e+04]\n",
            "[Step 25274/50000] [Progress: 50.55%] [learning rate: 1.2e+04]\n",
            "[Step 25298/50000] [Progress: 50.60%] [learning rate: 1.1e+04]\n",
            "[Step 25323/50000] [Progress: 50.65%] [learning rate: 1.1e+04]\n",
            "[Step 25333/50000] [Time: 222s] [Train Loss: 6.98e-02] [Train Acc: 1.00]\n",
            "[Step 25349/50000] [Progress: 50.70%] [learning rate: 1.2e+04]\n",
            "[Step 25373/50000] [Progress: 50.75%] [learning rate: 1.1e+04]\n",
            "[Step 25400/50000] [Progress: 50.80%] [learning rate: 1.3e+04]\n",
            "[Step 25423/50000] [Progress: 50.85%] [learning rate: 1.1e+04]\n",
            "[Step 25426/50000] [Time: 223s] [Train Loss: 6.94e-02] [Train Acc: 1.00]\n",
            "[Step 25449/50000] [Progress: 50.90%] [learning rate: 1.1e+04]\n",
            "[Step 25473/50000] [Progress: 50.95%] [learning rate: 1.1e+04]\n",
            "[Step 25498/50000] [Progress: 51.00%] [learning rate: 1.2e+04]\n",
            "[Step 25519/50000] [Time: 223s] [Train Loss: 6.90e-02] [Train Acc: 1.00]\n",
            "[Step 25522/50000] [Progress: 51.04%] [learning rate: 1.1e+04]\n",
            "[Step 25550/50000] [Progress: 51.10%] [learning rate: 1.3e+04]\n",
            "[Step 25574/50000] [Progress: 51.15%] [learning rate: 1.2e+04]\n",
            "[Step 25599/50000] [Progress: 51.20%] [learning rate: 1.2e+04]\n",
            "[Step 25612/50000] [Time: 224s] [Train Loss: 6.87e-02] [Train Acc: 1.00]\n",
            "[Step 25625/50000] [Progress: 51.25%] [learning rate: 1.1e+04]\n",
            "[Step 25651/50000] [Progress: 51.30%] [learning rate: 1.2e+04]\n",
            "[Step 25675/50000] [Progress: 51.35%] [learning rate: 1.1e+04]\n",
            "[Step 25702/50000] [Progress: 51.40%] [learning rate: 1.3e+04]\n",
            "[Step 25705/50000] [Time: 225s] [Train Loss: 6.83e-02] [Train Acc: 1.00]\n",
            "[Step 25726/50000] [Progress: 51.45%] [learning rate: 1.2e+04]\n",
            "[Step 25751/50000] [Progress: 51.50%] [learning rate: 1.2e+04]\n",
            "[Step 25777/50000] [Progress: 51.55%] [learning rate: 1.1e+04]\n",
            "[Step 25798/50000] [Time: 225s] [Train Loss: 6.79e-02] [Train Acc: 1.00]\n",
            "[Step 25802/50000] [Progress: 51.60%] [learning rate: 1.1e+04]\n",
            "[Step 25827/50000] [Progress: 51.65%] [learning rate: 1.2e+04]\n",
            "[Step 25853/50000] [Progress: 51.71%] [learning rate: 1.4e+04]\n",
            "[Step 25874/50000] [Progress: 51.75%] [learning rate: 9.7e+03]\n",
            "[Step 25891/50000] [Time: 226s] [Train Loss: 6.75e-02] [Train Acc: 1.00]\n",
            "[Step 25903/50000] [Progress: 51.81%] [learning rate: 1.3e+04]\n",
            "[Step 25928/50000] [Progress: 51.86%] [learning rate: 1.1e+04]\n",
            "[Step 25954/50000] [Progress: 51.91%] [learning rate: 1.2e+04]\n",
            "[Step 25978/50000] [Progress: 51.96%] [learning rate: 1.2e+04]\n",
            "[Step 25984/50000] [Time: 227s] [Train Loss: 6.71e-02] [Train Acc: 1.00]\n",
            "[Step 26003/50000] [Progress: 52.01%] [learning rate: 1.3e+04]\n",
            "[Step 26026/50000] [Progress: 52.05%] [learning rate: 1.1e+04]\n",
            "[Step 26053/50000] [Progress: 52.11%] [learning rate: 1.3e+04]\n",
            "[Step 26076/50000] [Progress: 52.15%] [learning rate: 1.1e+04]\n",
            "[Step 26077/50000] [Time: 227s] [Train Loss: 6.68e-02] [Train Acc: 1.00]\n",
            "[Step 26101/50000] [Progress: 52.20%] [learning rate: 1.2e+04]\n",
            "[Step 26125/50000] [Progress: 52.25%] [learning rate: 1.2e+04]\n",
            "[Step 26150/50000] [Progress: 52.30%] [learning rate: 1.2e+04]\n",
            "[Step 26170/50000] [Time: 228s] [Train Loss: 6.64e-02] [Train Acc: 1.00]\n",
            "[Step 26174/50000] [Progress: 52.35%] [learning rate: 1.2e+04]\n",
            "[Step 26199/50000] [Progress: 52.40%] [learning rate: 1.2e+04]\n",
            "[Step 26225/50000] [Progress: 52.45%] [learning rate: 1.3e+04]\n",
            "[Step 26249/50000] [Progress: 52.50%] [learning rate: 1.1e+04]\n",
            "[Step 26263/50000] [Time: 229s] [Train Loss: 6.61e-02] [Train Acc: 1.00]\n",
            "[Step 26276/50000] [Progress: 52.55%] [learning rate: 1.4e+04]\n",
            "[Step 26299/50000] [Progress: 52.60%] [learning rate: 1.1e+04]\n",
            "[Step 26325/50000] [Progress: 52.65%] [learning rate: 1.2e+04]\n",
            "[Step 26349/50000] [Progress: 52.70%] [learning rate: 1.2e+04]\n",
            "[Step 26356/50000] [Time: 229s] [Train Loss: 6.57e-02] [Train Acc: 1.00]\n",
            "[Step 26374/50000] [Progress: 52.75%] [learning rate: 1.3e+04]\n",
            "[Step 26398/50000] [Progress: 52.80%] [learning rate: 1.1e+04]\n",
            "[Step 26425/50000] [Progress: 52.85%] [learning rate: 1.4e+04]\n",
            "[Step 26448/50000] [Progress: 52.90%] [learning rate: 1.1e+04]\n",
            "[Step 26449/50000] [Time: 230s] [Train Loss: 6.53e-02] [Train Acc: 1.00]\n",
            "[Step 26474/50000] [Progress: 52.95%] [learning rate: 1.2e+04]\n",
            "[Step 26499/50000] [Progress: 53.00%] [learning rate: 1.2e+04]\n",
            "[Step 26525/50000] [Progress: 53.05%] [learning rate: 1.3e+04]\n",
            "[Step 26542/50000] [Time: 231s] [Train Loss: 6.50e-02] [Train Acc: 1.00]\n",
            "[Step 26549/50000] [Progress: 53.10%] [learning rate: 1.1e+04]\n",
            "[Step 26577/50000] [Progress: 53.15%] [learning rate: 1.4e+04]\n",
            "[Step 26602/50000] [Progress: 53.20%] [learning rate: 1.2e+04]\n",
            "[Step 26628/50000] [Progress: 53.26%] [learning rate: 1.2e+04]\n",
            "[Step 26635/50000] [Time: 232s] [Train Loss: 6.46e-02] [Train Acc: 1.00]\n",
            "[Step 26654/50000] [Progress: 53.31%] [learning rate: 1.2e+04]\n",
            "[Step 26679/50000] [Progress: 53.36%] [learning rate: 1.2e+04]\n",
            "[Step 26704/50000] [Progress: 53.41%] [learning rate: 1.3e+04]\n",
            "[Step 26729/50000] [Time: 232s] [Train Loss: 6.42e-02] [Train Acc: 1.00]\n",
            "[Step 26730/50000] [Progress: 53.46%] [learning rate: 1.5e+04]\n",
            "[Step 26751/50000] [Progress: 53.50%] [learning rate: 1.0e+04]\n",
            "[Step 26780/50000] [Progress: 53.56%] [learning rate: 1.3e+04]\n",
            "[Step 26805/50000] [Progress: 53.61%] [learning rate: 1.2e+04]\n",
            "[Step 26823/50000] [Time: 233s] [Train Loss: 6.39e-02] [Train Acc: 1.00]\n",
            "[Step 26831/50000] [Progress: 53.66%] [learning rate: 1.3e+04]\n",
            "[Step 26855/50000] [Progress: 53.71%] [learning rate: 1.3e+04]\n",
            "[Step 26880/50000] [Progress: 53.76%] [learning rate: 1.4e+04]\n",
            "[Step 26903/50000] [Progress: 53.81%] [learning rate: 1.1e+04]\n",
            "[Step 26917/50000] [Time: 234s] [Train Loss: 6.35e-02] [Train Acc: 1.00]\n",
            "[Step 26930/50000] [Progress: 53.86%] [learning rate: 1.3e+04]\n",
            "[Step 26953/50000] [Progress: 53.91%] [learning rate: 1.2e+04]\n",
            "[Step 26978/50000] [Progress: 53.96%] [learning rate: 1.3e+04]\n",
            "[Step 27002/50000] [Progress: 54.00%] [learning rate: 1.3e+04]\n",
            "[Step 27011/50000] [Time: 234s] [Train Loss: 6.32e-02] [Train Acc: 1.00]\n",
            "[Step 27027/50000] [Progress: 54.05%] [learning rate: 1.3e+04]\n",
            "[Step 27051/50000] [Progress: 54.10%] [learning rate: 1.2e+04]\n",
            "[Step 27076/50000] [Progress: 54.15%] [learning rate: 1.2e+04]\n",
            "[Step 27102/50000] [Progress: 54.20%] [learning rate: 1.3e+04]\n",
            "[Step 27105/50000] [Time: 235s] [Train Loss: 6.28e-02] [Train Acc: 1.00]\n",
            "[Step 27126/50000] [Progress: 54.25%] [learning rate: 1.2e+04]\n",
            "[Step 27153/50000] [Progress: 54.31%] [learning rate: 1.4e+04]\n",
            "[Step 27176/50000] [Progress: 54.35%] [learning rate: 1.2e+04]\n",
            "[Step 27199/50000] [Time: 236s] [Train Loss: 6.25e-02] [Train Acc: 1.00]\n",
            "[Step 27203/50000] [Progress: 54.41%] [learning rate: 1.4e+04]\n",
            "[Step 27226/50000] [Progress: 54.45%] [learning rate: 1.1e+04]\n",
            "[Step 27252/50000] [Progress: 54.50%] [learning rate: 1.3e+04]\n",
            "[Step 27276/50000] [Progress: 54.55%] [learning rate: 1.2e+04]\n",
            "[Step 27293/50000] [Time: 236s] [Train Loss: 6.22e-02] [Train Acc: 1.00]\n",
            "[Step 27302/50000] [Progress: 54.60%] [learning rate: 1.3e+04]\n",
            "[Step 27326/50000] [Progress: 54.65%] [learning rate: 1.3e+04]\n",
            "[Step 27351/50000] [Progress: 54.70%] [learning rate: 1.3e+04]\n",
            "[Step 27377/50000] [Progress: 54.75%] [learning rate: 1.4e+04]\n",
            "[Step 27387/50000] [Time: 237s] [Train Loss: 6.18e-02] [Train Acc: 1.00]\n",
            "[Step 27400/50000] [Progress: 54.80%] [learning rate: 1.2e+04]\n",
            "[Step 27425/50000] [Progress: 54.85%] [learning rate: 1.3e+04]\n",
            "[Step 27450/50000] [Progress: 54.90%] [learning rate: 1.4e+04]\n",
            "[Step 27473/50000] [Progress: 54.95%] [learning rate: 1.2e+04]\n",
            "[Step 27481/50000] [Time: 238s] [Train Loss: 6.15e-02] [Train Acc: 1.00]\n",
            "[Step 27500/50000] [Progress: 55.00%] [learning rate: 1.4e+04]\n",
            "[Step 27523/50000] [Progress: 55.05%] [learning rate: 1.1e+04]\n",
            "[Step 27549/50000] [Progress: 55.10%] [learning rate: 1.3e+04]\n",
            "[Step 27573/50000] [Progress: 55.15%] [learning rate: 1.3e+04]\n",
            "[Step 27575/50000] [Time: 238s] [Train Loss: 6.11e-02] [Train Acc: 1.00]\n",
            "[Step 27598/50000] [Progress: 55.20%] [learning rate: 1.4e+04]\n",
            "[Step 27621/50000] [Progress: 55.24%] [learning rate: 1.2e+04]\n",
            "[Step 27647/50000] [Progress: 55.29%] [learning rate: 1.3e+04]\n",
            "[Step 27669/50000] [Time: 239s] [Train Loss: 6.08e-02] [Train Acc: 1.00]\n",
            "[Step 27671/50000] [Progress: 55.34%] [learning rate: 1.2e+04]\n",
            "[Step 27696/50000] [Progress: 55.39%] [learning rate: 1.3e+04]\n",
            "[Step 27720/50000] [Progress: 55.44%] [learning rate: 1.3e+04]\n",
            "[Step 27746/50000] [Progress: 55.49%] [learning rate: 1.4e+04]\n",
            "[Step 27763/50000] [Time: 240s] [Train Loss: 6.05e-02] [Train Acc: 1.00]\n",
            "[Step 27770/50000] [Progress: 55.54%] [learning rate: 1.3e+04]\n",
            "[Step 27795/50000] [Progress: 55.59%] [learning rate: 1.3e+04]\n",
            "[Step 27821/50000] [Progress: 55.64%] [learning rate: 1.2e+04]\n",
            "[Step 27846/50000] [Progress: 55.69%] [learning rate: 1.2e+04]\n",
            "[Step 27857/50000] [Time: 240s] [Train Loss: 6.01e-02] [Train Acc: 1.00]\n",
            "[Step 27872/50000] [Progress: 55.74%] [learning rate: 1.3e+04]\n",
            "[Step 27898/50000] [Progress: 55.80%] [learning rate: 1.4e+04]\n",
            "[Step 27921/50000] [Progress: 55.84%] [learning rate: 1.2e+04]\n",
            "[Step 27948/50000] [Progress: 55.90%] [learning rate: 1.4e+04]\n",
            "[Step 27951/50000] [Time: 241s] [Train Loss: 5.98e-02] [Train Acc: 1.00]\n",
            "[Step 27971/50000] [Progress: 55.94%] [learning rate: 1.3e+04]\n",
            "[Step 27996/50000] [Progress: 55.99%] [learning rate: 1.4e+04]\n",
            "[Step 28021/50000] [Progress: 56.04%] [learning rate: 1.3e+04]\n",
            "[Step 28045/50000] [Time: 242s] [Train Loss: 5.95e-02] [Train Acc: 1.00]\n",
            "[Step 28047/50000] [Progress: 56.09%] [learning rate: 1.3e+04]\n",
            "[Step 28071/50000] [Progress: 56.14%] [learning rate: 1.3e+04]\n",
            "[Step 28096/50000] [Progress: 56.19%] [learning rate: 1.3e+04]\n",
            "[Step 28122/50000] [Progress: 56.24%] [learning rate: 1.4e+04]\n",
            "[Step 28139/50000] [Time: 243s] [Train Loss: 5.92e-02] [Train Acc: 1.00]\n",
            "[Step 28146/50000] [Progress: 56.29%] [learning rate: 1.2e+04]\n",
            "[Step 28173/50000] [Progress: 56.35%] [learning rate: 1.5e+04]\n",
            "[Step 28196/50000] [Progress: 56.39%] [learning rate: 1.2e+04]\n",
            "[Step 28222/50000] [Progress: 56.44%] [learning rate: 1.3e+04]\n",
            "[Step 28234/50000] [Time: 243s] [Train Loss: 5.88e-02] [Train Acc: 1.00]\n",
            "[Step 28247/50000] [Progress: 56.49%] [learning rate: 1.3e+04]\n",
            "[Step 28273/50000] [Progress: 56.55%] [learning rate: 1.4e+04]\n",
            "[Step 28297/50000] [Progress: 56.59%] [learning rate: 1.2e+04]\n",
            "[Step 28325/50000] [Progress: 56.65%] [learning rate: 1.5e+04]\n",
            "[Step 28329/50000] [Time: 244s] [Train Loss: 5.85e-02] [Train Acc: 1.00]\n",
            "[Step 28349/50000] [Progress: 56.70%] [learning rate: 1.3e+04]\n",
            "[Step 28374/50000] [Progress: 56.75%] [learning rate: 1.3e+04]\n",
            "[Step 28400/50000] [Progress: 56.80%] [learning rate: 1.3e+04]\n",
            "[Step 28424/50000] [Time: 245s] [Train Loss: 5.82e-02] [Train Acc: 1.00]\n",
            "[Step 28425/50000] [Progress: 56.85%] [learning rate: 1.3e+04]\n",
            "[Step 28452/50000] [Progress: 56.90%] [learning rate: 1.4e+04]\n",
            "[Step 28479/50000] [Progress: 56.96%] [learning rate: 1.5e+04]\n",
            "[Step 28504/50000] [Progress: 57.01%] [learning rate: 1.3e+04]\n",
            "[Step 28519/50000] [Time: 246s] [Train Loss: 5.79e-02] [Train Acc: 1.00]\n",
            "[Step 28530/50000] [Progress: 57.06%] [learning rate: 1.3e+04]\n",
            "[Step 28556/50000] [Progress: 57.11%] [learning rate: 1.4e+04]\n",
            "[Step 28579/50000] [Progress: 57.16%] [learning rate: 1.3e+04]\n",
            "[Step 28605/50000] [Progress: 57.21%] [learning rate: 1.4e+04]\n",
            "[Step 28614/50000] [Time: 246s] [Train Loss: 5.75e-02] [Train Acc: 1.00]\n",
            "[Step 28632/50000] [Progress: 57.26%] [learning rate: 1.5e+04]\n",
            "[Step 28657/50000] [Progress: 57.31%] [learning rate: 1.3e+04]\n",
            "[Step 28683/50000] [Progress: 57.37%] [learning rate: 1.3e+04]\n",
            "[Step 28709/50000] [Progress: 57.42%] [learning rate: 1.4e+04]\n",
            "[Step 28709/50000] [Time: 247s] [Train Loss: 5.72e-02] [Train Acc: 1.00]\n",
            "[Step 28732/50000] [Progress: 57.46%] [learning rate: 1.3e+04]\n",
            "[Step 28758/50000] [Progress: 57.52%] [learning rate: 1.4e+04]\n",
            "[Step 28783/50000] [Progress: 57.57%] [learning rate: 1.4e+04]\n",
            "[Step 28804/50000] [Time: 248s] [Train Loss: 5.69e-02] [Train Acc: 1.00] [Eval Loss: 4.75e-01] [Eval Acc: 0.80]\n",
            "[Step 28809/50000] [Progress: 57.62%] [learning rate: 1.3e+04]\n",
            "[Step 28833/50000] [Progress: 57.67%] [learning rate: 1.3e+04]\n",
            "[Step 28858/50000] [Progress: 57.72%] [learning rate: 1.4e+04]\n",
            "[Step 28881/50000] [Progress: 57.76%] [learning rate: 1.3e+04]\n",
            "[Step 28899/50000] [Time: 250s] [Train Loss: 5.66e-02] [Train Acc: 1.00]\n",
            "[Step 28907/50000] [Progress: 57.81%] [learning rate: 1.5e+04]\n",
            "[Step 28930/50000] [Progress: 57.86%] [learning rate: 1.3e+04]\n",
            "[Step 28956/50000] [Progress: 57.91%] [learning rate: 1.4e+04]\n",
            "[Step 28980/50000] [Progress: 57.96%] [learning rate: 1.3e+04]\n",
            "[Step 28994/50000] [Time: 251s] [Train Loss: 5.63e-02] [Train Acc: 1.00]\n",
            "[Step 29005/50000] [Progress: 58.01%] [learning rate: 1.4e+04]\n",
            "[Step 29029/50000] [Progress: 58.06%] [learning rate: 1.3e+04]\n",
            "[Step 29056/50000] [Progress: 58.11%] [learning rate: 1.5e+04]\n",
            "[Step 29079/50000] [Progress: 58.16%] [learning rate: 1.3e+04]\n",
            "[Step 29089/50000] [Time: 251s] [Train Loss: 5.60e-02] [Train Acc: 1.00]\n",
            "[Step 29105/50000] [Progress: 58.21%] [learning rate: 1.4e+04]\n",
            "[Step 29131/50000] [Progress: 58.26%] [learning rate: 1.5e+04]\n",
            "[Step 29154/50000] [Progress: 58.31%] [learning rate: 1.3e+04]\n",
            "[Step 29179/50000] [Progress: 58.36%] [learning rate: 1.4e+04]\n",
            "[Step 29184/50000] [Time: 252s] [Train Loss: 5.57e-02] [Train Acc: 1.00]\n",
            "[Step 29204/50000] [Progress: 58.41%] [learning rate: 1.4e+04]\n",
            "[Step 29228/50000] [Progress: 58.46%] [learning rate: 1.4e+04]\n",
            "[Step 29253/50000] [Progress: 58.51%] [learning rate: 1.4e+04]\n",
            "[Step 29279/50000] [Progress: 58.56%] [learning rate: 1.3e+04]\n",
            "[Step 29279/50000] [Time: 253s] [Train Loss: 5.53e-02] [Train Acc: 1.00]\n",
            "[Step 29304/50000] [Progress: 58.61%] [learning rate: 1.3e+04]\n",
            "[Step 29329/50000] [Progress: 58.66%] [learning rate: 1.4e+04]\n",
            "[Step 29354/50000] [Progress: 58.71%] [learning rate: 1.6e+04]\n",
            "[Step 29374/50000] [Time: 253s] [Train Loss: 5.50e-02] [Train Acc: 1.00]\n",
            "[Step 29377/50000] [Progress: 58.75%] [learning rate: 1.3e+04]\n",
            "[Step 29404/50000] [Progress: 58.81%] [learning rate: 1.5e+04]\n",
            "[Step 29427/50000] [Progress: 58.85%] [learning rate: 1.4e+04]\n",
            "[Step 29452/50000] [Progress: 58.90%] [learning rate: 1.5e+04]\n",
            "[Step 29469/50000] [Time: 254s] [Train Loss: 5.48e-02] [Train Acc: 1.00]\n",
            "[Step 29476/50000] [Progress: 58.95%] [learning rate: 1.3e+04]\n",
            "[Step 29503/50000] [Progress: 59.01%] [learning rate: 1.7e+04]\n",
            "[Step 29524/50000] [Progress: 59.05%] [learning rate: 1.2e+04]\n",
            "[Step 29553/50000] [Progress: 59.11%] [learning rate: 1.5e+04]\n",
            "[Step 29564/50000] [Time: 255s] [Train Loss: 5.45e-02] [Train Acc: 1.00]\n",
            "[Step 29578/50000] [Progress: 59.16%] [learning rate: 1.4e+04]\n",
            "[Step 29604/50000] [Progress: 59.21%] [learning rate: 1.5e+04]\n",
            "[Step 29628/50000] [Progress: 59.26%] [learning rate: 1.5e+04]\n",
            "[Step 29653/50000] [Progress: 59.31%] [learning rate: 1.6e+04]\n",
            "[Step 29659/50000] [Time: 256s] [Train Loss: 5.42e-02] [Train Acc: 1.00]\n",
            "[Step 29676/50000] [Progress: 59.35%] [learning rate: 1.3e+04]\n",
            "[Step 29703/50000] [Progress: 59.41%] [learning rate: 1.5e+04]\n",
            "[Step 29726/50000] [Progress: 59.45%] [learning rate: 1.4e+04]\n",
            "[Step 29751/50000] [Progress: 59.50%] [learning rate: 1.5e+04]\n",
            "[Step 29754/50000] [Time: 257s] [Train Loss: 5.39e-02] [Train Acc: 1.00]\n",
            "[Step 29775/50000] [Progress: 59.55%] [learning rate: 1.5e+04]\n",
            "[Step 29800/50000] [Progress: 59.60%] [learning rate: 1.6e+04]\n",
            "[Step 29823/50000] [Progress: 59.65%] [learning rate: 1.3e+04]\n",
            "[Step 29849/50000] [Time: 257s] [Train Loss: 5.36e-02] [Train Acc: 1.00]\n",
            "[Step 29850/50000] [Progress: 59.70%] [learning rate: 1.5e+04]\n",
            "[Step 29873/50000] [Progress: 59.75%] [learning rate: 1.4e+04]\n",
            "[Step 29898/50000] [Progress: 59.80%] [learning rate: 1.5e+04]\n",
            "[Step 29923/50000] [Progress: 59.85%] [learning rate: 1.5e+04]\n",
            "[Step 29944/50000] [Time: 258s] [Train Loss: 5.33e-02] [Train Acc: 1.00]\n",
            "[Step 29949/50000] [Progress: 59.90%] [learning rate: 1.4e+04]\n",
            "[Step 29973/50000] [Progress: 59.95%] [learning rate: 1.4e+04]\n",
            "[Step 29998/50000] [Progress: 60.00%] [learning rate: 1.4e+04]\n",
            "[Step 30024/50000] [Progress: 60.05%] [learning rate: 1.5e+04]\n",
            "[Step 30039/50000] [Time: 259s] [Train Loss: 5.30e-02] [Train Acc: 1.00]\n",
            "[Step 30048/50000] [Progress: 60.10%] [learning rate: 1.4e+04]\n",
            "[Step 30076/50000] [Progress: 60.15%] [learning rate: 1.6e+04]\n",
            "[Step 30100/50000] [Progress: 60.20%] [learning rate: 1.4e+04]\n",
            "[Step 30125/50000] [Progress: 60.25%] [learning rate: 1.4e+04]\n",
            "[Step 30135/50000] [Time: 259s] [Train Loss: 5.27e-02] [Train Acc: 1.00]\n",
            "[Step 30151/50000] [Progress: 60.30%] [learning rate: 1.4e+04]\n",
            "[Step 30176/50000] [Progress: 60.35%] [learning rate: 1.4e+04]\n",
            "[Step 30203/50000] [Progress: 60.41%] [learning rate: 1.5e+04]\n",
            "[Step 30228/50000] [Progress: 60.46%] [learning rate: 1.5e+04]\n",
            "[Step 30231/50000] [Time: 260s] [Train Loss: 5.24e-02] [Train Acc: 1.00]\n",
            "[Step 30254/50000] [Progress: 60.51%] [learning rate: 1.5e+04]\n",
            "[Step 30278/50000] [Progress: 60.56%] [learning rate: 1.4e+04]\n",
            "[Step 30303/50000] [Progress: 60.61%] [learning rate: 1.4e+04]\n",
            "[Step 30327/50000] [Time: 261s] [Train Loss: 5.21e-02] [Train Acc: 1.00]\n",
            "[Step 30328/50000] [Progress: 60.66%] [learning rate: 1.4e+04]\n",
            "[Step 30355/50000] [Progress: 60.71%] [learning rate: 1.5e+04]\n",
            "[Step 30381/50000] [Progress: 60.76%] [learning rate: 1.8e+04]\n",
            "[Step 30402/50000] [Progress: 60.80%] [learning rate: 1.2e+04]\n",
            "[Step 30423/50000] [Time: 261s] [Train Loss: 5.18e-02] [Train Acc: 1.00]\n",
            "[Step 30431/50000] [Progress: 60.86%] [learning rate: 1.6e+04]\n",
            "[Step 30456/50000] [Progress: 60.91%] [learning rate: 1.4e+04]\n",
            "[Step 30482/50000] [Progress: 60.96%] [learning rate: 1.5e+04]\n",
            "[Step 30506/50000] [Progress: 61.01%] [learning rate: 1.5e+04]\n",
            "[Step 30519/50000] [Time: 262s] [Train Loss: 5.16e-02] [Train Acc: 1.00]\n",
            "[Step 30531/50000] [Progress: 61.06%] [learning rate: 1.6e+04]\n",
            "[Step 30554/50000] [Progress: 61.11%] [learning rate: 1.3e+04]\n",
            "[Step 30581/50000] [Progress: 61.16%] [learning rate: 1.6e+04]\n",
            "[Step 30604/50000] [Progress: 61.21%] [learning rate: 1.4e+04]\n",
            "[Step 30615/50000] [Time: 263s] [Train Loss: 5.13e-02] [Train Acc: 1.00]\n",
            "[Step 30629/50000] [Progress: 61.26%] [learning rate: 1.5e+04]\n",
            "[Step 30653/50000] [Progress: 61.31%] [learning rate: 1.5e+04]\n",
            "[Step 30678/50000] [Progress: 61.36%] [learning rate: 1.5e+04]\n",
            "[Step 30704/50000] [Progress: 61.41%] [learning rate: 1.5e+04]\n",
            "[Step 30711/50000] [Time: 264s] [Train Loss: 5.10e-02] [Train Acc: 1.00]\n",
            "[Step 30728/50000] [Progress: 61.46%] [learning rate: 1.5e+04]\n",
            "[Step 30753/50000] [Progress: 61.51%] [learning rate: 1.6e+04]\n",
            "[Step 30777/50000] [Progress: 61.55%] [learning rate: 1.4e+04]\n",
            "[Step 30804/50000] [Progress: 61.61%] [learning rate: 1.7e+04]\n",
            "[Step 30807/50000] [Time: 264s] [Train Loss: 5.07e-02] [Train Acc: 1.00]\n",
            "[Step 30827/50000] [Progress: 61.65%] [learning rate: 1.4e+04]\n",
            "[Step 30853/50000] [Progress: 61.71%] [learning rate: 1.5e+04]\n",
            "[Step 30879/50000] [Progress: 61.76%] [learning rate: 1.6e+04]\n",
            "[Step 30902/50000] [Progress: 61.80%] [learning rate: 1.3e+04]\n",
            "[Step 30903/50000] [Time: 265s] [Train Loss: 5.04e-02] [Train Acc: 1.00]\n",
            "[Step 30929/50000] [Progress: 61.86%] [learning rate: 1.6e+04]\n",
            "[Step 30955/50000] [Progress: 61.91%] [learning rate: 1.7e+04]\n",
            "[Step 30978/50000] [Progress: 61.96%] [learning rate: 1.4e+04]\n",
            "[Step 30999/50000] [Time: 266s] [Train Loss: 5.02e-02] [Train Acc: 1.00]\n",
            "[Step 31004/50000] [Progress: 62.01%] [learning rate: 1.5e+04]\n",
            "[Step 31030/50000] [Progress: 62.06%] [learning rate: 1.6e+04]\n",
            "[Step 31053/50000] [Progress: 62.11%] [learning rate: 1.4e+04]\n",
            "[Step 31079/50000] [Progress: 62.16%] [learning rate: 1.6e+04]\n",
            "[Step 31095/50000] [Time: 266s] [Train Loss: 4.99e-02] [Train Acc: 1.00]\n",
            "[Step 31105/50000] [Progress: 62.21%] [learning rate: 1.7e+04]\n",
            "[Step 31128/50000] [Progress: 62.26%] [learning rate: 1.4e+04]\n",
            "[Step 31155/50000] [Progress: 62.31%] [learning rate: 1.6e+04]\n",
            "[Step 31178/50000] [Progress: 62.36%] [learning rate: 1.5e+04]\n",
            "[Step 31191/50000] [Time: 267s] [Train Loss: 4.96e-02] [Train Acc: 1.00]\n",
            "[Step 31203/50000] [Progress: 62.41%] [learning rate: 1.4e+04]\n",
            "[Step 31229/50000] [Progress: 62.46%] [learning rate: 1.6e+04]\n",
            "[Step 31256/50000] [Progress: 62.51%] [learning rate: 1.9e+04]\n",
            "[Step 31276/50000] [Progress: 62.55%] [learning rate: 1.3e+04]\n",
            "[Step 31287/50000] [Time: 268s] [Train Loss: 4.94e-02] [Train Acc: 1.00]\n",
            "[Step 31304/50000] [Progress: 62.61%] [learning rate: 1.7e+04]\n",
            "[Step 31329/50000] [Progress: 62.66%] [learning rate: 1.5e+04]\n",
            "[Step 31355/50000] [Progress: 62.71%] [learning rate: 1.6e+04]\n",
            "[Step 31379/50000] [Progress: 62.76%] [learning rate: 1.6e+04]\n",
            "[Step 31383/50000] [Time: 269s] [Train Loss: 4.91e-02] [Train Acc: 1.00]\n",
            "[Step 31404/50000] [Progress: 62.81%] [learning rate: 1.7e+04]\n",
            "[Step 31427/50000] [Progress: 62.85%] [learning rate: 1.4e+04]\n",
            "[Step 31454/50000] [Progress: 62.91%] [learning rate: 1.7e+04]\n",
            "[Step 31477/50000] [Progress: 62.95%] [learning rate: 1.5e+04]\n",
            "[Step 31479/50000] [Time: 270s] [Train Loss: 4.88e-02] [Train Acc: 1.00]\n",
            "[Step 31502/50000] [Progress: 63.00%] [learning rate: 1.6e+04]\n",
            "[Step 31526/50000] [Progress: 63.05%] [learning rate: 1.6e+04]\n",
            "[Step 31551/50000] [Progress: 63.10%] [learning rate: 1.7e+04]\n",
            "[Step 31574/50000] [Progress: 63.15%] [learning rate: 1.4e+04]\n",
            "[Step 31575/50000] [Time: 270s] [Train Loss: 4.85e-02] [Train Acc: 1.00]\n",
            "[Step 31601/50000] [Progress: 63.20%] [learning rate: 1.7e+04]\n",
            "[Step 31624/50000] [Progress: 63.25%] [learning rate: 1.5e+04]\n",
            "[Step 31649/50000] [Progress: 63.30%] [learning rate: 1.6e+04]\n",
            "[Step 31671/50000] [Time: 271s] [Train Loss: 4.83e-02] [Train Acc: 1.00]\n",
            "[Step 31673/50000] [Progress: 63.35%] [learning rate: 1.6e+04]\n",
            "[Step 31698/50000] [Progress: 63.40%] [learning rate: 1.6e+04]\n",
            "[Step 31722/50000] [Progress: 63.44%] [learning rate: 1.5e+04]\n",
            "[Step 31747/50000] [Progress: 63.49%] [learning rate: 1.5e+04]\n",
            "[Step 31767/50000] [Time: 272s] [Train Loss: 4.80e-02] [Train Acc: 1.00]\n",
            "[Step 31773/50000] [Progress: 63.55%] [learning rate: 1.6e+04]\n",
            "[Step 31797/50000] [Progress: 63.59%] [learning rate: 1.5e+04]\n",
            "[Step 31824/50000] [Progress: 63.65%] [learning rate: 1.8e+04]\n",
            "[Step 31847/50000] [Progress: 63.69%] [learning rate: 1.6e+04]\n",
            "[Step 31863/50000] [Time: 272s] [Train Loss: 4.78e-02] [Train Acc: 1.00]\n",
            "[Step 31871/50000] [Progress: 63.74%] [learning rate: 1.6e+04]\n",
            "[Step 31896/50000] [Progress: 63.79%] [learning rate: 1.5e+04]\n",
            "[Step 31921/50000] [Progress: 63.84%] [learning rate: 1.5e+04]\n",
            "[Step 31948/50000] [Progress: 63.90%] [learning rate: 1.6e+04]\n",
            "[Step 31959/50000] [Time: 273s] [Train Loss: 4.75e-02] [Train Acc: 1.00]\n",
            "[Step 31974/50000] [Progress: 63.95%] [learning rate: 1.8e+04]\n",
            "[Step 31997/50000] [Progress: 63.99%] [learning rate: 1.4e+04]\n",
            "[Step 32023/50000] [Progress: 64.05%] [learning rate: 1.6e+04]\n",
            "[Step 32049/50000] [Progress: 64.10%] [learning rate: 1.7e+04]\n",
            "[Step 32055/50000] [Time: 274s] [Train Loss: 4.72e-02] [Train Acc: 1.00]\n",
            "[Step 32072/50000] [Progress: 64.14%] [learning rate: 1.5e+04]\n",
            "[Step 32098/50000] [Progress: 64.20%] [learning rate: 1.6e+04]\n",
            "[Step 32125/50000] [Progress: 64.25%] [learning rate: 1.8e+04]\n",
            "[Step 32150/50000] [Progress: 64.30%] [learning rate: 1.6e+04]\n",
            "[Step 32151/50000] [Time: 274s] [Train Loss: 4.70e-02] [Train Acc: 1.00]\n",
            "[Step 32176/50000] [Progress: 64.35%] [learning rate: 1.6e+04]\n",
            "[Step 32202/50000] [Progress: 64.40%] [learning rate: 1.5e+04]\n",
            "[Step 32227/50000] [Progress: 64.45%] [learning rate: 1.5e+04]\n",
            "[Step 32247/50000] [Time: 275s] [Train Loss: 4.67e-02] [Train Acc: 1.00]\n",
            "[Step 32253/50000] [Progress: 64.51%] [learning rate: 1.6e+04]\n",
            "[Step 32280/50000] [Progress: 64.56%] [learning rate: 1.8e+04]\n",
            "[Step 32304/50000] [Progress: 64.61%] [learning rate: 1.6e+04]\n",
            "[Step 32329/50000] [Progress: 64.66%] [learning rate: 1.6e+04]\n",
            "[Step 32344/50000] [Time: 276s] [Train Loss: 4.65e-02] [Train Acc: 1.00]\n",
            "[Step 32355/50000] [Progress: 64.71%] [learning rate: 1.5e+04]\n",
            "[Step 32380/50000] [Progress: 64.76%] [learning rate: 1.5e+04]\n",
            "[Step 32406/50000] [Progress: 64.81%] [learning rate: 1.7e+04]\n",
            "[Step 32432/50000] [Progress: 64.86%] [learning rate: 1.8e+04]\n",
            "[Step 32441/50000] [Time: 277s] [Train Loss: 4.62e-02] [Train Acc: 1.00]\n",
            "[Step 32455/50000] [Progress: 64.91%] [learning rate: 1.5e+04]\n",
            "[Step 32482/50000] [Progress: 64.96%] [learning rate: 1.7e+04]\n",
            "[Step 32505/50000] [Progress: 65.01%] [learning rate: 1.6e+04]\n",
            "[Step 32531/50000] [Progress: 65.06%] [learning rate: 1.7e+04]\n",
            "[Step 32538/50000] [Time: 277s] [Train Loss: 4.60e-02] [Train Acc: 1.00]\n",
            "[Step 32557/50000] [Progress: 65.11%] [learning rate: 1.7e+04]\n",
            "[Step 32583/50000] [Progress: 65.17%] [learning rate: 1.6e+04]\n",
            "[Step 32607/50000] [Progress: 65.21%] [learning rate: 1.6e+04]\n",
            "[Step 32632/50000] [Progress: 65.26%] [learning rate: 1.6e+04]\n",
            "[Step 32635/50000] [Time: 278s] [Train Loss: 4.57e-02] [Train Acc: 1.00]\n",
            "[Step 32658/50000] [Progress: 65.32%] [learning rate: 1.7e+04]\n",
            "[Step 32682/50000] [Progress: 65.36%] [learning rate: 1.5e+04]\n",
            "[Step 32710/50000] [Progress: 65.42%] [learning rate: 1.8e+04]\n",
            "[Step 32732/50000] [Time: 279s] [Train Loss: 4.55e-02] [Train Acc: 1.00]\n",
            "[Step 32734/50000] [Progress: 65.47%] [learning rate: 1.6e+04]\n",
            "[Step 32759/50000] [Progress: 65.52%] [learning rate: 1.6e+04]\n",
            "[Step 32785/50000] [Progress: 65.57%] [learning rate: 1.6e+04]\n",
            "[Step 32810/50000] [Progress: 65.62%] [learning rate: 1.6e+04]\n",
            "[Step 32829/50000] [Time: 279s] [Train Loss: 4.52e-02] [Train Acc: 1.00]\n",
            "[Step 32837/50000] [Progress: 65.67%] [learning rate: 1.7e+04]\n",
            "[Step 32863/50000] [Progress: 65.73%] [learning rate: 1.8e+04]\n",
            "[Step 32886/50000] [Progress: 65.77%] [learning rate: 1.5e+04]\n",
            "[Step 32912/50000] [Progress: 65.82%] [learning rate: 1.6e+04]\n",
            "[Step 32926/50000] [Time: 280s] [Train Loss: 4.50e-02] [Train Acc: 1.00]\n",
            "[Step 32937/50000] [Progress: 65.87%] [learning rate: 1.6e+04]\n",
            "[Step 32963/50000] [Progress: 65.93%] [learning rate: 1.7e+04]\n",
            "[Step 32987/50000] [Progress: 65.97%] [learning rate: 1.6e+04]\n",
            "[Step 33014/50000] [Progress: 66.03%] [learning rate: 2.0e+04]\n",
            "[Step 33023/50000] [Time: 281s] [Train Loss: 4.47e-02] [Train Acc: 1.00]\n",
            "[Step 33035/50000] [Progress: 66.07%] [learning rate: 1.4e+04]\n",
            "[Step 33064/50000] [Progress: 66.13%] [learning rate: 1.8e+04]\n",
            "[Step 33089/50000] [Progress: 66.18%] [learning rate: 1.6e+04]\n",
            "[Step 33115/50000] [Progress: 66.23%] [learning rate: 1.7e+04]\n",
            "[Step 33120/50000] [Time: 282s] [Train Loss: 4.45e-02] [Train Acc: 1.00]\n",
            "[Step 33139/50000] [Progress: 66.28%] [learning rate: 1.6e+04]\n",
            "[Step 33166/50000] [Progress: 66.33%] [learning rate: 1.9e+04]\n",
            "[Step 33190/50000] [Progress: 66.38%] [learning rate: 1.7e+04]\n",
            "[Step 33215/50000] [Progress: 66.43%] [learning rate: 1.6e+04]\n",
            "[Step 33217/50000] [Time: 283s] [Train Loss: 4.42e-02] [Train Acc: 1.00]\n",
            "[Step 33241/50000] [Progress: 66.48%] [learning rate: 1.8e+04]\n",
            "[Step 33265/50000] [Progress: 66.53%] [learning rate: 1.6e+04]\n",
            "[Step 33292/50000] [Progress: 66.58%] [learning rate: 1.7e+04]\n",
            "[Step 33314/50000] [Time: 283s] [Train Loss: 4.40e-02] [Train Acc: 1.00]\n",
            "[Step 33317/50000] [Progress: 66.63%] [learning rate: 1.7e+04]\n",
            "[Step 33343/50000] [Progress: 66.69%] [learning rate: 1.7e+04]\n",
            "[Step 33369/50000] [Progress: 66.74%] [learning rate: 1.6e+04]\n",
            "[Step 33394/50000] [Progress: 66.79%] [learning rate: 1.6e+04]\n",
            "[Step 33411/50000] [Time: 284s] [Train Loss: 4.38e-02] [Train Acc: 1.00]\n",
            "[Step 33421/50000] [Progress: 66.84%] [learning rate: 1.8e+04]\n",
            "[Step 33447/50000] [Progress: 66.89%] [learning rate: 1.7e+04]\n",
            "[Step 33473/50000] [Progress: 66.95%] [learning rate: 1.9e+04]\n",
            "[Step 33496/50000] [Progress: 66.99%] [learning rate: 1.5e+04]\n",
            "[Step 33508/50000] [Time: 285s] [Train Loss: 4.35e-02] [Train Acc: 1.00]\n",
            "[Step 33523/50000] [Progress: 67.05%] [learning rate: 1.8e+04]\n",
            "[Step 33546/50000] [Progress: 67.09%] [learning rate: 1.6e+04]\n",
            "[Step 33572/50000] [Progress: 67.14%] [learning rate: 1.8e+04]\n",
            "[Step 33598/50000] [Progress: 67.20%] [learning rate: 1.7e+04]\n",
            "[Step 33605/50000] [Time: 285s] [Train Loss: 4.33e-02] [Train Acc: 1.00] [Eval Loss: 4.87e-01] [Eval Acc: 0.80]\n",
            "[Step 33622/50000] [Progress: 67.24%] [learning rate: 1.7e+04]\n",
            "[Step 33647/50000] [Progress: 67.29%] [learning rate: 1.7e+04]\n",
            "[Step 33673/50000] [Progress: 67.35%] [learning rate: 1.7e+04]\n",
            "[Step 33698/50000] [Progress: 67.40%] [learning rate: 1.6e+04]\n",
            "[Step 33702/50000] [Time: 288s] [Train Loss: 4.30e-02] [Train Acc: 1.00]\n",
            "[Step 33723/50000] [Progress: 67.45%] [learning rate: 1.8e+04]\n",
            "[Step 33748/50000] [Progress: 67.50%] [learning rate: 1.9e+04]\n",
            "[Step 33771/50000] [Progress: 67.54%] [learning rate: 1.6e+04]\n",
            "[Step 33798/50000] [Progress: 67.60%] [learning rate: 1.9e+04]\n",
            "[Step 33799/50000] [Time: 289s] [Train Loss: 4.28e-02] [Train Acc: 1.00]\n",
            "[Step 33821/50000] [Progress: 67.64%] [learning rate: 1.5e+04]\n",
            "[Step 33848/50000] [Progress: 67.70%] [learning rate: 1.8e+04]\n",
            "[Step 33873/50000] [Progress: 67.75%] [learning rate: 1.8e+04]\n",
            "[Step 33896/50000] [Time: 289s] [Train Loss: 4.26e-02] [Train Acc: 1.00]\n",
            "[Step 33900/50000] [Progress: 67.80%] [learning rate: 2.3e+04]\n",
            "[Step 33917/50000] [Progress: 67.83%] [learning rate: 1.1e+04]\n",
            "[Step 33949/50000] [Progress: 67.90%] [learning rate: 2.1e+04]\n",
            "[Step 33972/50000] [Progress: 67.94%] [learning rate: 1.7e+04]\n",
            "[Step 33993/50000] [Time: 290s] [Train Loss: 4.23e-02] [Train Acc: 1.00]\n",
            "[Step 33997/50000] [Progress: 67.99%] [learning rate: 1.8e+04]\n",
            "[Step 34021/50000] [Progress: 68.04%] [learning rate: 1.6e+04]\n",
            "[Step 34048/50000] [Progress: 68.10%] [learning rate: 1.9e+04]\n",
            "[Step 34072/50000] [Progress: 68.14%] [learning rate: 1.7e+04]\n",
            "[Step 34090/50000] [Time: 291s] [Train Loss: 4.21e-02] [Train Acc: 1.00]\n",
            "[Step 34097/50000] [Progress: 68.19%] [learning rate: 1.7e+04]\n",
            "[Step 34123/50000] [Progress: 68.25%] [learning rate: 1.7e+04]\n",
            "[Step 34148/50000] [Progress: 68.30%] [learning rate: 1.8e+04]\n",
            "[Step 34172/50000] [Progress: 68.34%] [learning rate: 1.8e+04]\n",
            "[Step 34187/50000] [Time: 291s] [Train Loss: 4.19e-02] [Train Acc: 1.00]\n",
            "[Step 34197/50000] [Progress: 68.39%] [learning rate: 1.8e+04]\n",
            "[Step 34223/50000] [Progress: 68.45%] [learning rate: 1.7e+04]\n",
            "[Step 34247/50000] [Progress: 68.49%] [learning rate: 1.7e+04]\n",
            "[Step 34272/50000] [Progress: 68.54%] [learning rate: 1.7e+04]\n",
            "[Step 34284/50000] [Time: 292s] [Train Loss: 4.17e-02] [Train Acc: 1.00]\n",
            "[Step 34297/50000] [Progress: 68.59%] [learning rate: 1.8e+04]\n",
            "[Step 34321/50000] [Progress: 68.64%] [learning rate: 1.8e+04]\n",
            "[Step 34346/50000] [Progress: 68.69%] [learning rate: 1.8e+04]\n",
            "[Step 34370/50000] [Progress: 68.74%] [learning rate: 1.8e+04]\n",
            "[Step 34381/50000] [Time: 293s] [Train Loss: 4.14e-02] [Train Acc: 1.00]\n",
            "[Step 34395/50000] [Progress: 68.79%] [learning rate: 1.7e+04]\n",
            "[Step 34421/50000] [Progress: 68.84%] [learning rate: 1.9e+04]\n",
            "[Step 34445/50000] [Progress: 68.89%] [learning rate: 1.7e+04]\n",
            "[Step 34473/50000] [Progress: 68.95%] [learning rate: 2.0e+04]\n",
            "[Step 34478/50000] [Time: 294s] [Train Loss: 4.12e-02] [Train Acc: 1.00]\n",
            "[Step 34497/50000] [Progress: 68.99%] [learning rate: 1.8e+04]\n",
            "[Step 34522/50000] [Progress: 69.04%] [learning rate: 1.8e+04]\n",
            "[Step 34548/50000] [Progress: 69.10%] [learning rate: 1.7e+04]\n",
            "[Step 34573/50000] [Progress: 69.15%] [learning rate: 1.7e+04]\n",
            "[Step 34575/50000] [Time: 294s] [Train Loss: 4.10e-02] [Train Acc: 1.00]\n",
            "[Step 34600/50000] [Progress: 69.20%] [learning rate: 1.8e+04]\n",
            "[Step 34627/50000] [Progress: 69.25%] [learning rate: 2.0e+04]\n",
            "[Step 34651/50000] [Progress: 69.30%] [learning rate: 1.8e+04]\n",
            "[Step 34672/50000] [Time: 295s] [Train Loss: 4.08e-02] [Train Acc: 1.00]\n",
            "[Step 34676/50000] [Progress: 69.35%] [learning rate: 1.8e+04]\n",
            "[Step 34702/50000] [Progress: 69.40%] [learning rate: 1.7e+04]\n",
            "[Step 34729/50000] [Progress: 69.46%] [learning rate: 1.9e+04]\n",
            "[Step 34754/50000] [Progress: 69.51%] [learning rate: 1.9e+04]\n",
            "[Step 34769/50000] [Time: 296s] [Train Loss: 4.06e-02] [Train Acc: 1.00]\n",
            "[Step 34780/50000] [Progress: 69.56%] [learning rate: 2.2e+04]\n",
            "[Step 34801/50000] [Progress: 69.60%] [learning rate: 1.5e+04]\n",
            "[Step 34830/50000] [Progress: 69.66%] [learning rate: 2.0e+04]\n",
            "[Step 34854/50000] [Progress: 69.71%] [learning rate: 1.7e+04]\n",
            "[Step 34866/50000] [Time: 297s] [Train Loss: 4.03e-02] [Train Acc: 1.00]\n",
            "[Step 34879/50000] [Progress: 69.76%] [learning rate: 1.9e+04]\n",
            "[Step 34903/50000] [Progress: 69.81%] [learning rate: 1.9e+04]\n",
            "[Step 34928/50000] [Progress: 69.86%] [learning rate: 2.0e+04]\n",
            "[Step 34951/50000] [Progress: 69.90%] [learning rate: 1.6e+04]\n",
            "[Step 34963/50000] [Time: 298s] [Train Loss: 4.01e-02] [Train Acc: 1.00]\n",
            "[Step 34978/50000] [Progress: 69.96%] [learning rate: 2.0e+04]\n",
            "[Step 35001/50000] [Progress: 70.00%] [learning rate: 1.8e+04]\n",
            "[Step 35026/50000] [Progress: 70.05%] [learning rate: 1.9e+04]\n",
            "[Step 35050/50000] [Progress: 70.10%] [learning rate: 1.9e+04]\n",
            "[Step 35060/50000] [Time: 298s] [Train Loss: 3.99e-02] [Train Acc: 1.00]\n",
            "[Step 35075/50000] [Progress: 70.15%] [learning rate: 1.8e+04]\n",
            "[Step 35099/50000] [Progress: 70.20%] [learning rate: 1.8e+04]\n",
            "[Step 35124/50000] [Progress: 70.25%] [learning rate: 1.8e+04]\n",
            "[Step 35150/50000] [Progress: 70.30%] [learning rate: 1.9e+04]\n",
            "[Step 35157/50000] [Time: 299s] [Train Loss: 3.97e-02] [Train Acc: 1.00]\n",
            "[Step 35174/50000] [Progress: 70.35%] [learning rate: 1.7e+04]\n",
            "[Step 35201/50000] [Progress: 70.40%] [learning rate: 2.1e+04]\n",
            "[Step 35224/50000] [Progress: 70.45%] [learning rate: 1.7e+04]\n",
            "[Step 35250/50000] [Progress: 70.50%] [learning rate: 1.8e+04]\n",
            "[Step 35255/50000] [Time: 300s] [Train Loss: 3.95e-02] [Train Acc: 1.00]\n",
            "[Step 35274/50000] [Progress: 70.55%] [learning rate: 1.8e+04]\n",
            "[Step 35299/50000] [Progress: 70.60%] [learning rate: 1.9e+04]\n",
            "[Step 35323/50000] [Progress: 70.65%] [learning rate: 1.7e+04]\n",
            "[Step 35350/50000] [Progress: 70.70%] [learning rate: 2.1e+04]\n",
            "[Step 35353/50000] [Time: 300s] [Train Loss: 3.93e-02] [Train Acc: 1.00]\n",
            "[Step 35373/50000] [Progress: 70.75%] [learning rate: 1.9e+04]\n",
            "[Step 35397/50000] [Progress: 70.79%] [learning rate: 1.8e+04]\n",
            "[Step 35422/50000] [Progress: 70.84%] [learning rate: 1.8e+04]\n",
            "[Step 35447/50000] [Progress: 70.89%] [learning rate: 1.8e+04]\n",
            "[Step 35451/50000] [Time: 301s] [Train Loss: 3.90e-02] [Train Acc: 1.00]\n",
            "[Step 35474/50000] [Progress: 70.95%] [learning rate: 1.9e+04]\n",
            "[Step 35500/50000] [Progress: 71.00%] [learning rate: 2.1e+04]\n",
            "[Step 35523/50000] [Progress: 71.05%] [learning rate: 1.7e+04]\n",
            "[Step 35549/50000] [Progress: 71.10%] [learning rate: 1.8e+04]\n",
            "[Step 35549/50000] [Time: 302s] [Train Loss: 3.88e-02] [Train Acc: 1.00]\n",
            "[Step 35574/50000] [Progress: 71.15%] [learning rate: 1.8e+04]\n",
            "[Step 35600/50000] [Progress: 71.20%] [learning rate: 2.0e+04]\n",
            "[Step 35624/50000] [Progress: 71.25%] [learning rate: 1.8e+04]\n",
            "[Step 35647/50000] [Time: 302s] [Train Loss: 3.86e-02] [Train Acc: 1.00]\n",
            "[Step 35652/50000] [Progress: 71.30%] [learning rate: 2.3e+04]\n",
            "[Step 35675/50000] [Progress: 71.35%] [learning rate: 1.7e+04]\n",
            "[Step 35701/50000] [Progress: 71.40%] [learning rate: 2.0e+04]\n",
            "[Step 35724/50000] [Progress: 71.45%] [learning rate: 1.7e+04]\n",
            "[Step 35745/50000] [Time: 303s] [Train Loss: 3.84e-02] [Train Acc: 1.00]\n",
            "[Step 35750/50000] [Progress: 71.50%] [learning rate: 2.0e+04]\n",
            "[Step 35774/50000] [Progress: 71.55%] [learning rate: 1.9e+04]\n",
            "[Step 35799/50000] [Progress: 71.60%] [learning rate: 2.1e+04]\n",
            "[Step 35822/50000] [Progress: 71.64%] [learning rate: 1.7e+04]\n",
            "[Step 35843/50000] [Time: 304s] [Train Loss: 3.82e-02] [Train Acc: 1.00]\n",
            "[Step 35850/50000] [Progress: 71.70%] [learning rate: 2.0e+04]\n",
            "[Step 35874/50000] [Progress: 71.75%] [learning rate: 1.8e+04]\n",
            "[Step 35899/50000] [Progress: 71.80%] [learning rate: 2.0e+04]\n",
            "[Step 35923/50000] [Progress: 71.85%] [learning rate: 2.0e+04]\n",
            "[Step 35941/50000] [Time: 305s] [Train Loss: 3.80e-02] [Train Acc: 1.00]\n",
            "[Step 35948/50000] [Progress: 71.90%] [learning rate: 2.1e+04]\n",
            "[Step 35971/50000] [Progress: 71.94%] [learning rate: 1.7e+04]\n",
            "[Step 35998/50000] [Progress: 72.00%] [learning rate: 2.1e+04]\n",
            "[Step 36021/50000] [Progress: 72.04%] [learning rate: 1.8e+04]\n",
            "[Step 36039/50000] [Time: 305s] [Train Loss: 3.78e-02] [Train Acc: 1.00]\n",
            "[Step 36046/50000] [Progress: 72.09%] [learning rate: 2.0e+04]\n",
            "[Step 36071/50000] [Progress: 72.14%] [learning rate: 2.0e+04]\n",
            "[Step 36097/50000] [Progress: 72.19%] [learning rate: 1.9e+04]\n",
            "[Step 36121/50000] [Progress: 72.24%] [learning rate: 1.9e+04]\n",
            "[Step 36137/50000] [Time: 306s] [Train Loss: 3.76e-02] [Train Acc: 1.00]\n",
            "[Step 36146/50000] [Progress: 72.29%] [learning rate: 1.9e+04]\n",
            "[Step 36172/50000] [Progress: 72.34%] [learning rate: 2.0e+04]\n",
            "[Step 36196/50000] [Progress: 72.39%] [learning rate: 1.8e+04]\n",
            "[Step 36224/50000] [Progress: 72.45%] [learning rate: 2.2e+04]\n",
            "[Step 36235/50000] [Time: 307s] [Train Loss: 3.74e-02] [Train Acc: 1.00]\n",
            "[Step 36248/50000] [Progress: 72.50%] [learning rate: 1.9e+04]\n",
            "[Step 36273/50000] [Progress: 72.55%] [learning rate: 1.9e+04]\n",
            "[Step 36299/50000] [Progress: 72.60%] [learning rate: 1.9e+04]\n",
            "[Step 36324/50000] [Progress: 72.65%] [learning rate: 1.9e+04]\n",
            "[Step 36333/50000] [Time: 308s] [Train Loss: 3.72e-02] [Train Acc: 1.00]\n",
            "[Step 36351/50000] [Progress: 72.70%] [learning rate: 2.0e+04]\n",
            "[Step 36377/50000] [Progress: 72.75%] [learning rate: 2.2e+04]\n",
            "[Step 36400/50000] [Progress: 72.80%] [learning rate: 1.8e+04]\n",
            "[Step 36426/50000] [Progress: 72.85%] [learning rate: 1.9e+04]\n",
            "[Step 36431/50000] [Time: 308s] [Train Loss: 3.70e-02] [Train Acc: 1.00]\n",
            "[Step 36451/50000] [Progress: 72.90%] [learning rate: 1.9e+04]\n",
            "[Step 36477/50000] [Progress: 72.95%] [learning rate: 2.1e+04]\n",
            "[Step 36501/50000] [Progress: 73.00%] [learning rate: 1.8e+04]\n",
            "[Step 36529/50000] [Time: 309s] [Train Loss: 3.68e-02] [Train Acc: 1.00]\n",
            "[Step 36530/50000] [Progress: 73.06%] [learning rate: 2.6e+04]\n",
            "[Step 36549/50000] [Progress: 73.10%] [learning rate: 1.3e+04]\n",
            "[Step 36579/50000] [Progress: 73.16%] [learning rate: 2.3e+04]\n",
            "[Step 36600/50000] [Progress: 73.20%] [learning rate: 1.6e+04]\n",
            "[Step 36627/50000] [Time: 310s] [Train Loss: 3.66e-02] [Train Acc: 1.00]\n",
            "[Step 36628/50000] [Progress: 73.26%] [learning rate: 2.1e+04]\n",
            "[Step 36654/50000] [Progress: 73.31%] [learning rate: 2.0e+04]\n",
            "[Step 36681/50000] [Progress: 73.36%] [learning rate: 2.2e+04]\n",
            "[Step 36705/50000] [Progress: 73.41%] [learning rate: 2.0e+04]\n",
            "[Step 36725/50000] [Time: 311s] [Train Loss: 3.64e-02] [Train Acc: 1.00]\n",
            "[Step 36729/50000] [Progress: 73.46%] [learning rate: 1.9e+04]\n",
            "[Step 36754/50000] [Progress: 73.51%] [learning rate: 2.1e+04]\n",
            "[Step 36777/50000] [Progress: 73.55%] [learning rate: 1.9e+04]\n",
            "[Step 36803/50000] [Progress: 73.61%] [learning rate: 2.2e+04]\n",
            "[Step 36823/50000] [Time: 311s] [Train Loss: 3.62e-02] [Train Acc: 1.00]\n",
            "[Step 36826/50000] [Progress: 73.65%] [learning rate: 1.8e+04]\n",
            "[Step 36852/50000] [Progress: 73.70%] [learning rate: 2.0e+04]\n",
            "[Step 36876/50000] [Progress: 73.75%] [learning rate: 1.9e+04]\n",
            "[Step 36901/50000] [Progress: 73.80%] [learning rate: 1.9e+04]\n",
            "[Step 36921/50000] [Time: 312s] [Train Loss: 3.60e-02] [Train Acc: 1.00]\n",
            "[Step 36926/50000] [Progress: 73.85%] [learning rate: 2.1e+04]\n",
            "[Step 36950/50000] [Progress: 73.90%] [learning rate: 2.0e+04]\n",
            "[Step 36975/50000] [Progress: 73.95%] [learning rate: 2.0e+04]\n",
            "[Step 36999/50000] [Progress: 74.00%] [learning rate: 2.0e+04]\n",
            "[Step 37019/50000] [Time: 313s] [Train Loss: 3.58e-02] [Train Acc: 1.00]\n",
            "[Step 37024/50000] [Progress: 74.05%] [learning rate: 2.0e+04]\n",
            "[Step 37050/50000] [Progress: 74.10%] [learning rate: 2.1e+04]\n",
            "[Step 37074/50000] [Progress: 74.15%] [learning rate: 1.9e+04]\n",
            "[Step 37102/50000] [Progress: 74.20%] [learning rate: 2.3e+04]\n",
            "[Step 37117/50000] [Time: 314s] [Train Loss: 3.56e-02] [Train Acc: 1.00]\n",
            "[Step 37126/50000] [Progress: 74.25%] [learning rate: 2.0e+04]\n",
            "[Step 37151/50000] [Progress: 74.30%] [learning rate: 2.0e+04]\n",
            "[Step 37177/50000] [Progress: 74.35%] [learning rate: 2.0e+04]\n",
            "[Step 37202/50000] [Progress: 74.40%] [learning rate: 1.9e+04]\n",
            "[Step 37215/50000] [Time: 314s] [Train Loss: 3.54e-02] [Train Acc: 1.00]\n",
            "[Step 37229/50000] [Progress: 74.46%] [learning rate: 2.1e+04]\n",
            "[Step 37256/50000] [Progress: 74.51%] [learning rate: 2.3e+04]\n",
            "[Step 37280/50000] [Progress: 74.56%] [learning rate: 2.0e+04]\n",
            "[Step 37305/50000] [Progress: 74.61%] [learning rate: 2.0e+04]\n",
            "[Step 37313/50000] [Time: 315s] [Train Loss: 3.52e-02] [Train Acc: 1.00]\n",
            "[Step 37331/50000] [Progress: 74.66%] [learning rate: 2.0e+04]\n",
            "[Step 37356/50000] [Progress: 74.71%] [learning rate: 1.9e+04]\n",
            "[Step 37381/50000] [Progress: 74.76%] [learning rate: 2.1e+04]\n",
            "[Step 37407/50000] [Progress: 74.81%] [learning rate: 2.5e+04]\n",
            "[Step 37411/50000] [Time: 316s] [Train Loss: 3.50e-02] [Train Acc: 1.00]\n",
            "[Step 37428/50000] [Progress: 74.86%] [learning rate: 1.7e+04]\n",
            "[Step 37455/50000] [Progress: 74.91%] [learning rate: 2.2e+04]\n",
            "[Step 37478/50000] [Progress: 74.96%] [learning rate: 2.0e+04]\n",
            "[Step 37503/50000] [Progress: 75.01%] [learning rate: 2.1e+04]\n",
            "[Step 37509/50000] [Time: 316s] [Train Loss: 3.49e-02] [Train Acc: 1.00]\n",
            "[Step 37527/50000] [Progress: 75.05%] [learning rate: 1.9e+04]\n",
            "[Step 37554/50000] [Progress: 75.11%] [learning rate: 2.3e+04]\n",
            "[Step 37578/50000] [Progress: 75.16%] [learning rate: 2.1e+04]\n",
            "[Step 37603/50000] [Progress: 75.21%] [learning rate: 2.0e+04]\n",
            "[Step 37607/50000] [Time: 317s] [Train Loss: 3.47e-02] [Train Acc: 1.00]\n",
            "[Step 37629/50000] [Progress: 75.26%] [learning rate: 2.2e+04]\n",
            "[Step 37653/50000] [Progress: 75.31%] [learning rate: 2.0e+04]\n",
            "[Step 37680/50000] [Progress: 75.36%] [learning rate: 2.1e+04]\n",
            "[Step 37705/50000] [Progress: 75.41%] [learning rate: 2.1e+04]\n",
            "[Step 37705/50000] [Time: 318s] [Train Loss: 3.45e-02] [Train Acc: 1.00]\n",
            "[Step 37731/50000] [Progress: 75.46%] [learning rate: 2.1e+04]\n",
            "[Step 37757/50000] [Progress: 75.51%] [learning rate: 2.2e+04]\n",
            "[Step 37780/50000] [Progress: 75.56%] [learning rate: 1.8e+04]\n",
            "[Step 37803/50000] [Time: 318s] [Train Loss: 3.43e-02] [Train Acc: 1.00]\n",
            "[Step 37807/50000] [Progress: 75.61%] [learning rate: 2.2e+04]\n",
            "[Step 37833/50000] [Progress: 75.67%] [learning rate: 2.1e+04]\n",
            "[Step 37859/50000] [Progress: 75.72%] [learning rate: 2.3e+04]\n",
            "[Step 37882/50000] [Progress: 75.76%] [learning rate: 1.9e+04]\n",
            "[Step 37901/50000] [Time: 319s] [Train Loss: 3.41e-02] [Train Acc: 1.00]\n",
            "[Step 37909/50000] [Progress: 75.82%] [learning rate: 2.2e+04]\n",
            "[Step 37932/50000] [Progress: 75.86%] [learning rate: 2.0e+04]\n",
            "[Step 37958/50000] [Progress: 75.92%] [learning rate: 2.2e+04]\n",
            "[Step 37984/50000] [Progress: 75.97%] [learning rate: 2.4e+04]\n",
            "[Step 37999/50000] [Time: 320s] [Train Loss: 3.39e-02] [Train Acc: 1.00]\n",
            "[Step 38007/50000] [Progress: 76.01%] [learning rate: 1.9e+04]\n",
            "[Step 38034/50000] [Progress: 76.07%] [learning rate: 2.3e+04]\n",
            "[Step 38057/50000] [Progress: 76.11%] [learning rate: 1.9e+04]\n",
            "[Step 38083/50000] [Progress: 76.17%] [learning rate: 2.2e+04]\n",
            "[Step 38097/50000] [Time: 321s] [Train Loss: 3.38e-02] [Train Acc: 1.00]\n",
            "[Step 38107/50000] [Progress: 76.21%] [learning rate: 2.2e+04]\n",
            "[Step 38132/50000] [Progress: 76.26%] [learning rate: 2.2e+04]\n",
            "[Step 38156/50000] [Progress: 76.31%] [learning rate: 2.1e+04]\n",
            "[Step 38181/50000] [Progress: 76.36%] [learning rate: 2.1e+04]\n",
            "[Step 38195/50000] [Time: 322s] [Train Loss: 3.36e-02] [Train Acc: 1.00]\n",
            "[Step 38207/50000] [Progress: 76.41%] [learning rate: 2.3e+04]\n",
            "[Step 38230/50000] [Progress: 76.46%] [learning rate: 2.0e+04]\n",
            "[Step 38256/50000] [Progress: 76.51%] [learning rate: 2.2e+04]\n",
            "[Step 38283/50000] [Progress: 76.57%] [learning rate: 2.6e+04]\n",
            "[Step 38293/50000] [Time: 322s] [Train Loss: 3.34e-02] [Train Acc: 1.00]\n",
            "[Step 38304/50000] [Progress: 76.61%] [learning rate: 1.8e+04]\n",
            "[Step 38331/50000] [Progress: 76.66%] [learning rate: 2.3e+04]\n",
            "[Step 38354/50000] [Progress: 76.71%] [learning rate: 2.1e+04]\n",
            "[Step 38379/50000] [Progress: 76.76%] [learning rate: 2.2e+04]\n",
            "[Step 38391/50000] [Time: 323s] [Train Loss: 3.32e-02] [Train Acc: 1.00]\n",
            "[Step 38403/50000] [Progress: 76.81%] [learning rate: 2.2e+04]\n",
            "[Step 38428/50000] [Progress: 76.86%] [learning rate: 2.2e+04]\n",
            "[Step 38452/50000] [Progress: 76.90%] [learning rate: 2.1e+04]\n",
            "[Step 38477/50000] [Progress: 76.95%] [learning rate: 2.1e+04]\n",
            "[Step 38489/50000] [Time: 324s] [Train Loss: 3.30e-02] [Train Acc: 1.00] [Eval Loss: 5.00e-01] [Eval Acc: 0.81]\n",
            "[Step 38503/50000] [Progress: 77.01%] [learning rate: 2.3e+04]\n",
            "[Step 38527/50000] [Progress: 77.05%] [learning rate: 2.0e+04]\n",
            "[Step 38554/50000] [Progress: 77.11%] [learning rate: 2.2e+04]\n",
            "[Step 38579/50000] [Progress: 77.16%] [learning rate: 2.2e+04]\n",
            "[Step 38587/50000] [Time: 326s] [Train Loss: 3.29e-02] [Train Acc: 1.00]\n",
            "[Step 38605/50000] [Progress: 77.21%] [learning rate: 2.1e+04]\n",
            "[Step 38631/50000] [Progress: 77.26%] [learning rate: 2.1e+04]\n",
            "[Step 38656/50000] [Progress: 77.31%] [learning rate: 2.1e+04]\n",
            "[Step 38683/50000] [Progress: 77.37%] [learning rate: 2.3e+04]\n",
            "[Step 38685/50000] [Time: 327s] [Train Loss: 3.27e-02] [Train Acc: 1.00]\n",
            "[Step 38709/50000] [Progress: 77.42%] [learning rate: 2.2e+04]\n",
            "[Step 38735/50000] [Progress: 77.47%] [learning rate: 2.4e+04]\n",
            "[Step 38758/50000] [Progress: 77.52%] [learning rate: 2.0e+04]\n",
            "[Step 38783/50000] [Time: 327s] [Train Loss: 3.25e-02] [Train Acc: 1.00]\n",
            "[Step 38785/50000] [Progress: 77.57%] [learning rate: 2.3e+04]\n",
            "[Step 38808/50000] [Progress: 77.62%] [learning rate: 2.1e+04]\n",
            "[Step 38834/50000] [Progress: 77.67%] [learning rate: 2.3e+04]\n",
            "[Step 38860/50000] [Progress: 77.72%] [learning rate: 2.2e+04]\n",
            "[Step 38881/50000] [Time: 328s] [Train Loss: 3.23e-02] [Train Acc: 1.00]\n",
            "[Step 38884/50000] [Progress: 77.77%] [learning rate: 2.2e+04]\n",
            "[Step 38909/50000] [Progress: 77.82%] [learning rate: 2.2e+04]\n",
            "[Step 38935/50000] [Progress: 77.87%] [learning rate: 2.1e+04]\n",
            "[Step 38960/50000] [Progress: 77.92%] [learning rate: 2.1e+04]\n",
            "[Step 38979/50000] [Time: 329s] [Train Loss: 3.22e-02] [Train Acc: 1.00]\n",
            "[Step 38985/50000] [Progress: 77.97%] [learning rate: 2.3e+04]\n",
            "[Step 39010/50000] [Progress: 78.02%] [learning rate: 2.5e+04]\n",
            "[Step 39033/50000] [Progress: 78.07%] [learning rate: 2.0e+04]\n",
            "[Step 39060/50000] [Progress: 78.12%] [learning rate: 2.4e+04]\n",
            "[Step 39077/50000] [Time: 330s] [Train Loss: 3.20e-02] [Train Acc: 1.00]\n",
            "[Step 39083/50000] [Progress: 78.17%] [learning rate: 2.1e+04]\n",
            "[Step 39108/50000] [Progress: 78.22%] [learning rate: 2.3e+04]\n",
            "[Step 39132/50000] [Progress: 78.26%] [learning rate: 2.1e+04]\n",
            "[Step 39159/50000] [Progress: 78.32%] [learning rate: 2.7e+04]\n",
            "[Step 39175/50000] [Time: 330s] [Train Loss: 3.18e-02] [Train Acc: 1.00]\n",
            "[Step 39180/50000] [Progress: 78.36%] [learning rate: 1.8e+04]\n",
            "[Step 39209/50000] [Progress: 78.42%] [learning rate: 2.4e+04]\n",
            "[Step 39234/50000] [Progress: 78.47%] [learning rate: 2.2e+04]\n",
            "[Step 39260/50000] [Progress: 78.52%] [learning rate: 2.3e+04]\n",
            "[Step 39274/50000] [Time: 331s] [Train Loss: 3.17e-02] [Train Acc: 1.00]\n",
            "[Step 39284/50000] [Progress: 78.57%] [learning rate: 2.3e+04]\n",
            "[Step 39309/50000] [Progress: 78.62%] [learning rate: 2.5e+04]\n",
            "[Step 39332/50000] [Progress: 78.66%] [learning rate: 2.0e+04]\n",
            "[Step 39359/50000] [Progress: 78.72%] [learning rate: 2.4e+04]\n",
            "[Step 39373/50000] [Time: 332s] [Train Loss: 3.15e-02] [Train Acc: 1.00]\n",
            "[Step 39382/50000] [Progress: 78.76%] [learning rate: 2.2e+04]\n",
            "[Step 39407/50000] [Progress: 78.81%] [learning rate: 2.3e+04]\n",
            "[Step 39431/50000] [Progress: 78.86%] [learning rate: 2.3e+04]\n",
            "[Step 39456/50000] [Progress: 78.91%] [learning rate: 2.3e+04]\n",
            "[Step 39472/50000] [Time: 332s] [Train Loss: 3.13e-02] [Train Acc: 1.00]\n",
            "[Step 39480/50000] [Progress: 78.96%] [learning rate: 2.2e+04]\n",
            "[Step 39505/50000] [Progress: 79.01%] [learning rate: 2.2e+04]\n",
            "[Step 39531/50000] [Progress: 79.06%] [learning rate: 2.4e+04]\n",
            "[Step 39555/50000] [Progress: 79.11%] [learning rate: 2.1e+04]\n",
            "[Step 39571/50000] [Time: 333s] [Train Loss: 3.12e-02] [Train Acc: 1.00]\n",
            "[Step 39582/50000] [Progress: 79.16%] [learning rate: 2.6e+04]\n",
            "[Step 39605/50000] [Progress: 79.21%] [learning rate: 2.1e+04]\n",
            "[Step 39631/50000] [Progress: 79.26%] [learning rate: 2.3e+04]\n",
            "[Step 39655/50000] [Progress: 79.31%] [learning rate: 2.2e+04]\n",
            "[Step 39670/50000] [Time: 334s] [Train Loss: 3.10e-02] [Train Acc: 1.00]\n",
            "[Step 39680/50000] [Progress: 79.36%] [learning rate: 2.4e+04]\n",
            "[Step 39704/50000] [Progress: 79.41%] [learning rate: 2.2e+04]\n",
            "[Step 39731/50000] [Progress: 79.46%] [learning rate: 2.6e+04]\n",
            "[Step 39754/50000] [Progress: 79.51%] [learning rate: 2.3e+04]\n",
            "[Step 39769/50000] [Time: 335s] [Train Loss: 3.08e-02] [Train Acc: 1.00]\n",
            "[Step 39778/50000] [Progress: 79.56%] [learning rate: 2.3e+04]\n",
            "[Step 39803/50000] [Progress: 79.61%] [learning rate: 2.2e+04]\n",
            "[Step 39828/50000] [Progress: 79.66%] [learning rate: 2.2e+04]\n",
            "[Step 39855/50000] [Progress: 79.71%] [learning rate: 2.4e+04]\n",
            "[Step 39868/50000] [Time: 336s] [Train Loss: 3.07e-02] [Train Acc: 1.00]\n",
            "[Step 39882/50000] [Progress: 79.76%] [learning rate: 2.6e+04]\n",
            "[Step 39906/50000] [Progress: 79.81%] [learning rate: 2.3e+04]\n",
            "[Step 39931/50000] [Progress: 79.86%] [learning rate: 2.3e+04]\n",
            "[Step 39957/50000] [Progress: 79.91%] [learning rate: 2.2e+04]\n",
            "[Step 39967/50000] [Time: 336s] [Train Loss: 3.05e-02] [Train Acc: 1.00]\n",
            "[Step 39984/50000] [Progress: 79.97%] [learning rate: 2.4e+04]\n",
            "[Step 40009/50000] [Progress: 80.02%] [learning rate: 2.4e+04]\n",
            "[Step 40035/50000] [Progress: 80.07%] [learning rate: 2.6e+04]\n",
            "[Step 40059/50000] [Progress: 80.12%] [learning rate: 2.3e+04]\n",
            "[Step 40066/50000] [Time: 337s] [Train Loss: 3.03e-02] [Train Acc: 1.00]\n",
            "[Step 40084/50000] [Progress: 80.17%] [learning rate: 2.3e+04]\n",
            "[Step 40110/50000] [Progress: 80.22%] [learning rate: 2.5e+04]\n",
            "[Step 40133/50000] [Progress: 80.27%] [learning rate: 2.2e+04]\n",
            "[Step 40159/50000] [Progress: 80.32%] [learning rate: 2.4e+04]\n",
            "[Step 40165/50000] [Time: 338s] [Train Loss: 3.02e-02] [Train Acc: 1.00]\n",
            "[Step 40184/50000] [Progress: 80.37%] [learning rate: 2.4e+04]\n",
            "[Step 40208/50000] [Progress: 80.42%] [learning rate: 2.3e+04]\n",
            "[Step 40233/50000] [Progress: 80.47%] [learning rate: 2.3e+04]\n",
            "[Step 40259/50000] [Progress: 80.52%] [learning rate: 2.3e+04]\n",
            "[Step 40264/50000] [Time: 338s] [Train Loss: 3.00e-02] [Train Acc: 1.00]\n",
            "[Step 40284/50000] [Progress: 80.57%] [learning rate: 2.4e+04]\n",
            "[Step 40308/50000] [Progress: 80.62%] [learning rate: 2.4e+04]\n",
            "[Step 40333/50000] [Progress: 80.67%] [learning rate: 2.4e+04]\n",
            "[Step 40359/50000] [Progress: 80.72%] [learning rate: 2.3e+04]\n",
            "[Step 40363/50000] [Time: 339s] [Train Loss: 2.98e-02] [Train Acc: 1.00]\n",
            "[Step 40383/50000] [Progress: 80.77%] [learning rate: 2.3e+04]\n",
            "[Step 40408/50000] [Progress: 80.82%] [learning rate: 2.5e+04]\n",
            "[Step 40432/50000] [Progress: 80.86%] [learning rate: 2.2e+04]\n",
            "[Step 40459/50000] [Progress: 80.92%] [learning rate: 2.7e+04]\n",
            "[Step 40462/50000] [Time: 340s] [Train Loss: 2.97e-02] [Train Acc: 1.00]\n",
            "[Step 40482/50000] [Progress: 80.96%] [learning rate: 2.2e+04]\n",
            "[Step 40508/50000] [Progress: 81.02%] [learning rate: 2.3e+04]\n",
            "[Step 40532/50000] [Progress: 81.06%] [learning rate: 2.3e+04]\n",
            "[Step 40557/50000] [Progress: 81.11%] [learning rate: 2.5e+04]\n",
            "[Step 40561/50000] [Time: 340s] [Train Loss: 2.95e-02] [Train Acc: 1.00]\n",
            "[Step 40581/50000] [Progress: 81.16%] [learning rate: 2.2e+04]\n",
            "[Step 40609/50000] [Progress: 81.22%] [learning rate: 2.7e+04]\n",
            "[Step 40633/50000] [Progress: 81.27%] [learning rate: 2.4e+04]\n",
            "[Step 40658/50000] [Progress: 81.32%] [learning rate: 2.4e+04]\n",
            "[Step 40660/50000] [Time: 341s] [Train Loss: 2.94e-02] [Train Acc: 1.00]\n",
            "[Step 40684/50000] [Progress: 81.37%] [learning rate: 2.3e+04]\n",
            "[Step 40709/50000] [Progress: 81.42%] [learning rate: 2.3e+04]\n",
            "[Step 40736/50000] [Progress: 81.47%] [learning rate: 2.5e+04]\n",
            "[Step 40759/50000] [Time: 342s] [Train Loss: 2.92e-02] [Train Acc: 1.00]\n",
            "[Step 40763/50000] [Progress: 81.53%] [learning rate: 2.7e+04]\n",
            "[Step 40788/50000] [Progress: 81.58%] [learning rate: 2.4e+04]\n",
            "[Step 40814/50000] [Progress: 81.63%] [learning rate: 2.4e+04]\n",
            "[Step 40840/50000] [Progress: 81.68%] [learning rate: 2.3e+04]\n",
            "[Step 40858/50000] [Time: 343s] [Train Loss: 2.91e-02] [Train Acc: 1.00]\n",
            "[Step 40865/50000] [Progress: 81.73%] [learning rate: 2.3e+04]\n",
            "[Step 40891/50000] [Progress: 81.78%] [learning rate: 2.5e+04]\n",
            "[Step 40918/50000] [Progress: 81.84%] [learning rate: 2.7e+04]\n",
            "[Step 40942/50000] [Progress: 81.88%] [learning rate: 2.4e+04]\n",
            "[Step 40957/50000] [Time: 343s] [Train Loss: 2.89e-02] [Train Acc: 1.00]\n",
            "[Step 40967/50000] [Progress: 81.93%] [learning rate: 2.4e+04]\n",
            "[Step 40993/50000] [Progress: 81.99%] [learning rate: 2.3e+04]\n",
            "[Step 41018/50000] [Progress: 82.04%] [learning rate: 2.3e+04]\n",
            "[Step 41044/50000] [Progress: 82.09%] [learning rate: 2.5e+04]\n",
            "[Step 41056/50000] [Time: 344s] [Train Loss: 2.87e-02] [Train Acc: 1.00]\n",
            "[Step 41070/50000] [Progress: 82.14%] [learning rate: 2.7e+04]\n",
            "[Step 41093/50000] [Progress: 82.19%] [learning rate: 2.2e+04]\n",
            "[Step 41121/50000] [Progress: 82.24%] [learning rate: 2.6e+04]\n",
            "[Step 41145/50000] [Progress: 82.29%] [learning rate: 2.4e+04]\n",
            "[Step 41155/50000] [Time: 345s] [Train Loss: 2.86e-02] [Train Acc: 1.00]\n",
            "[Step 41170/50000] [Progress: 82.34%] [learning rate: 2.6e+04]\n",
            "[Step 41195/50000] [Progress: 82.39%] [learning rate: 2.5e+04]\n",
            "[Step 41221/50000] [Progress: 82.44%] [learning rate: 2.7e+04]\n",
            "[Step 41244/50000] [Progress: 82.49%] [learning rate: 2.2e+04]\n",
            "[Step 41254/50000] [Time: 345s] [Train Loss: 2.84e-02] [Train Acc: 1.00]\n",
            "[Step 41271/50000] [Progress: 82.54%] [learning rate: 2.6e+04]\n",
            "[Step 41294/50000] [Progress: 82.59%] [learning rate: 2.4e+04]\n",
            "[Step 41319/50000] [Progress: 82.64%] [learning rate: 2.6e+04]\n",
            "[Step 41344/50000] [Progress: 82.69%] [learning rate: 2.5e+04]\n",
            "[Step 41353/50000] [Time: 346s] [Train Loss: 2.83e-02] [Train Acc: 1.00]\n",
            "[Step 41370/50000] [Progress: 82.74%] [learning rate: 2.7e+04]\n",
            "[Step 41393/50000] [Progress: 82.79%] [learning rate: 2.2e+04]\n",
            "[Step 41420/50000] [Progress: 82.84%] [learning rate: 2.7e+04]\n",
            "[Step 41443/50000] [Progress: 82.89%] [learning rate: 2.4e+04]\n",
            "[Step 41452/50000] [Time: 347s] [Train Loss: 2.81e-02] [Train Acc: 1.00]\n",
            "[Step 41469/50000] [Progress: 82.94%] [learning rate: 2.6e+04]\n",
            "[Step 41495/50000] [Progress: 82.99%] [learning rate: 2.8e+04]\n",
            "[Step 41518/50000] [Progress: 83.04%] [learning rate: 2.3e+04]\n",
            "[Step 41545/50000] [Progress: 83.09%] [learning rate: 2.7e+04]\n",
            "[Step 41551/50000] [Time: 348s] [Train Loss: 2.80e-02] [Train Acc: 1.00]\n",
            "[Step 41568/50000] [Progress: 83.14%] [learning rate: 2.4e+04]\n",
            "[Step 41593/50000] [Progress: 83.19%] [learning rate: 2.4e+04]\n",
            "[Step 41618/50000] [Progress: 83.24%] [learning rate: 2.6e+04]\n",
            "[Step 41644/50000] [Progress: 83.29%] [learning rate: 2.8e+04]\n",
            "[Step 41650/50000] [Time: 348s] [Train Loss: 2.78e-02] [Train Acc: 1.00]\n",
            "[Step 41668/50000] [Progress: 83.34%] [learning rate: 2.5e+04]\n",
            "[Step 41693/50000] [Progress: 83.39%] [learning rate: 2.5e+04]\n",
            "[Step 41719/50000] [Progress: 83.44%] [learning rate: 2.4e+04]\n",
            "[Step 41744/50000] [Progress: 83.49%] [learning rate: 2.4e+04]\n",
            "[Step 41749/50000] [Time: 349s] [Train Loss: 2.77e-02] [Train Acc: 1.00]\n",
            "[Step 41769/50000] [Progress: 83.54%] [learning rate: 2.6e+04]\n",
            "[Step 41795/50000] [Progress: 83.59%] [learning rate: 2.8e+04]\n",
            "[Step 41819/50000] [Progress: 83.64%] [learning rate: 2.5e+04]\n",
            "[Step 41844/50000] [Progress: 83.69%] [learning rate: 2.5e+04]\n",
            "[Step 41848/50000] [Time: 350s] [Train Loss: 2.75e-02] [Train Acc: 1.00]\n",
            "[Step 41870/50000] [Progress: 83.74%] [learning rate: 2.4e+04]\n",
            "[Step 41895/50000] [Progress: 83.79%] [learning rate: 2.4e+04]\n",
            "[Step 41921/50000] [Progress: 83.84%] [learning rate: 2.6e+04]\n",
            "[Step 41947/50000] [Progress: 83.89%] [learning rate: 2.8e+04]\n",
            "[Step 41947/50000] [Time: 351s] [Train Loss: 2.74e-02] [Train Acc: 1.00]\n",
            "[Step 41970/50000] [Progress: 83.94%] [learning rate: 2.3e+04]\n",
            "[Step 41997/50000] [Progress: 83.99%] [learning rate: 2.7e+04]\n",
            "[Step 42020/50000] [Progress: 84.04%] [learning rate: 2.5e+04]\n",
            "[Step 42046/50000] [Progress: 84.09%] [learning rate: 2.7e+04]\n",
            "[Step 42046/50000] [Time: 351s] [Train Loss: 2.72e-02] [Train Acc: 1.00]\n",
            "[Step 42072/50000] [Progress: 84.14%] [learning rate: 2.6e+04]\n",
            "[Step 42098/50000] [Progress: 84.20%] [learning rate: 2.6e+04]\n",
            "[Step 42122/50000] [Progress: 84.24%] [learning rate: 2.5e+04]\n",
            "[Step 42145/50000] [Time: 352s] [Train Loss: 2.71e-02] [Train Acc: 1.00]\n",
            "[Step 42147/50000] [Progress: 84.29%] [learning rate: 2.5e+04]\n",
            "[Step 42173/50000] [Progress: 84.35%] [learning rate: 2.7e+04]\n",
            "[Step 42197/50000] [Progress: 84.39%] [learning rate: 2.4e+04]\n",
            "[Step 42224/50000] [Progress: 84.45%] [learning rate: 2.9e+04]\n",
            "[Step 42244/50000] [Time: 353s] [Train Loss: 2.70e-02] [Train Acc: 1.00]\n",
            "[Step 42247/50000] [Progress: 84.49%] [learning rate: 2.4e+04]\n",
            "[Step 42273/50000] [Progress: 84.55%] [learning rate: 2.6e+04]\n",
            "[Step 42298/50000] [Progress: 84.60%] [learning rate: 2.5e+04]\n",
            "[Step 42324/50000] [Progress: 84.65%] [learning rate: 2.7e+04]\n",
            "[Step 42343/50000] [Time: 353s] [Train Loss: 2.68e-02] [Train Acc: 1.00]\n",
            "[Step 42348/50000] [Progress: 84.70%] [learning rate: 2.4e+04]\n",
            "[Step 42376/50000] [Progress: 84.75%] [learning rate: 2.9e+04]\n",
            "[Step 42400/50000] [Progress: 84.80%] [learning rate: 2.6e+04]\n",
            "[Step 42425/50000] [Progress: 84.85%] [learning rate: 2.6e+04]\n",
            "[Step 42442/50000] [Time: 354s] [Train Loss: 2.67e-02] [Train Acc: 1.00]\n",
            "[Step 42451/50000] [Progress: 84.90%] [learning rate: 2.8e+04]\n",
            "[Step 42474/50000] [Progress: 84.95%] [learning rate: 2.5e+04]\n",
            "[Step 42500/50000] [Progress: 85.00%] [learning rate: 2.7e+04]\n",
            "[Step 42527/50000] [Progress: 85.05%] [learning rate: 3.2e+04]\n",
            "[Step 42541/50000] [Time: 355s] [Train Loss: 2.65e-02] [Train Acc: 1.00]\n",
            "[Step 42547/50000] [Progress: 85.09%] [learning rate: 2.2e+04]\n",
            "[Step 42575/50000] [Progress: 85.15%] [learning rate: 2.8e+04]\n",
            "[Step 42600/50000] [Progress: 85.20%] [learning rate: 2.5e+04]\n",
            "[Step 42626/50000] [Progress: 85.25%] [learning rate: 2.7e+04]\n",
            "[Step 42640/50000] [Time: 355s] [Train Loss: 2.64e-02] [Train Acc: 1.00]\n",
            "[Step 42650/50000] [Progress: 85.30%] [learning rate: 2.7e+04]\n",
            "[Step 42675/50000] [Progress: 85.35%] [learning rate: 2.9e+04]\n",
            "[Step 42698/50000] [Progress: 85.40%] [learning rate: 2.4e+04]\n",
            "[Step 42725/50000] [Progress: 85.45%] [learning rate: 2.8e+04]\n",
            "[Step 42739/50000] [Time: 356s] [Train Loss: 2.63e-02] [Train Acc: 1.00]\n",
            "[Step 42748/50000] [Progress: 85.50%] [learning rate: 2.5e+04]\n",
            "[Step 42773/50000] [Progress: 85.55%] [learning rate: 2.8e+04]\n",
            "[Step 42797/50000] [Progress: 85.59%] [learning rate: 2.7e+04]\n",
            "[Step 42822/50000] [Progress: 85.64%] [learning rate: 2.7e+04]\n",
            "[Step 42838/50000] [Time: 357s] [Train Loss: 2.61e-02] [Train Acc: 1.00]\n",
            "[Step 42846/50000] [Progress: 85.69%] [learning rate: 2.6e+04]\n",
            "[Step 42871/50000] [Progress: 85.74%] [learning rate: 2.6e+04]\n",
            "[Step 42897/50000] [Progress: 85.79%] [learning rate: 2.8e+04]\n",
            "[Step 42921/50000] [Progress: 85.84%] [learning rate: 2.5e+04]\n",
            "[Step 42937/50000] [Time: 358s] [Train Loss: 2.60e-02] [Train Acc: 1.00]\n",
            "[Step 42948/50000] [Progress: 85.90%] [learning rate: 3.0e+04]\n",
            "[Step 42971/50000] [Progress: 85.94%] [learning rate: 2.4e+04]\n",
            "[Step 42997/50000] [Progress: 85.99%] [learning rate: 2.7e+04]\n",
            "[Step 43021/50000] [Progress: 86.04%] [learning rate: 2.6e+04]\n",
            "[Step 43036/50000] [Time: 358s] [Train Loss: 2.59e-02] [Train Acc: 1.00]\n",
            "[Step 43046/50000] [Progress: 86.09%] [learning rate: 2.8e+04]\n",
            "[Step 43070/50000] [Progress: 86.14%] [learning rate: 2.5e+04]\n",
            "[Step 43097/50000] [Progress: 86.19%] [learning rate: 3.0e+04]\n",
            "[Step 43120/50000] [Progress: 86.24%] [learning rate: 2.5e+04]\n",
            "[Step 43135/50000] [Time: 359s] [Train Loss: 2.57e-02] [Train Acc: 1.00]\n",
            "[Step 43146/50000] [Progress: 86.29%] [learning rate: 2.7e+04]\n",
            "[Step 43170/50000] [Progress: 86.34%] [learning rate: 2.6e+04]\n",
            "[Step 43195/50000] [Progress: 86.39%] [learning rate: 2.8e+04]\n",
            "[Step 43219/50000] [Progress: 86.44%] [learning rate: 2.5e+04]\n",
            "[Step 43234/50000] [Time: 360s] [Train Loss: 2.56e-02] [Train Acc: 1.00]\n",
            "[Step 43245/50000] [Progress: 86.49%] [learning rate: 3.0e+04]\n",
            "[Step 43268/50000] [Progress: 86.54%] [learning rate: 2.5e+04]\n",
            "[Step 43294/50000] [Progress: 86.59%] [learning rate: 2.7e+04]\n",
            "[Step 43318/50000] [Progress: 86.64%] [learning rate: 2.6e+04]\n",
            "[Step 43333/50000] [Time: 361s] [Train Loss: 2.55e-02] [Train Acc: 1.00]\n",
            "[Step 43343/50000] [Progress: 86.69%] [learning rate: 2.9e+04]\n",
            "[Step 43367/50000] [Progress: 86.73%] [learning rate: 2.6e+04]\n",
            "[Step 43394/50000] [Progress: 86.79%] [learning rate: 3.4e+04]\n",
            "[Step 43414/50000] [Progress: 86.83%] [learning rate: 2.3e+04]\n",
            "[Step 43432/50000] [Time: 362s] [Train Loss: 2.53e-02] [Train Acc: 1.00] [Eval Loss: 5.15e-01] [Eval Acc: 0.81]\n",
            "[Step 43442/50000] [Progress: 86.88%] [learning rate: 3.0e+04]\n",
            "[Step 43467/50000] [Progress: 86.93%] [learning rate: 2.6e+04]\n",
            "[Step 43493/50000] [Progress: 86.99%] [learning rate: 2.9e+04]\n",
            "[Step 43517/50000] [Progress: 87.03%] [learning rate: 2.8e+04]\n",
            "[Step 43531/50000] [Time: 364s] [Train Loss: 2.52e-02] [Train Acc: 1.00]\n",
            "[Step 43542/50000] [Progress: 87.08%] [learning rate: 3.1e+04]\n",
            "[Step 43565/50000] [Progress: 87.13%] [learning rate: 2.5e+04]\n",
            "[Step 43592/50000] [Progress: 87.18%] [learning rate: 3.0e+04]\n",
            "[Step 43615/50000] [Progress: 87.23%] [learning rate: 2.7e+04]\n",
            "[Step 43630/50000] [Time: 365s] [Train Loss: 2.51e-02] [Train Acc: 1.00]\n",
            "[Step 43640/50000] [Progress: 87.28%] [learning rate: 2.9e+04]\n",
            "[Step 43664/50000] [Progress: 87.33%] [learning rate: 2.8e+04]\n",
            "[Step 43689/50000] [Progress: 87.38%] [learning rate: 3.1e+04]\n",
            "[Step 43712/50000] [Progress: 87.42%] [learning rate: 2.5e+04]\n",
            "[Step 43729/50000] [Time: 365s] [Train Loss: 2.49e-02] [Train Acc: 1.00]\n",
            "[Step 43739/50000] [Progress: 87.48%] [learning rate: 3.0e+04]\n",
            "[Step 43762/50000] [Progress: 87.52%] [learning rate: 2.7e+04]\n",
            "[Step 43787/50000] [Progress: 87.57%] [learning rate: 2.9e+04]\n",
            "[Step 43811/50000] [Progress: 87.62%] [learning rate: 2.8e+04]\n",
            "[Step 43828/50000] [Time: 366s] [Train Loss: 2.48e-02] [Train Acc: 1.00]\n",
            "[Step 43836/50000] [Progress: 87.67%] [learning rate: 2.8e+04]\n",
            "[Step 43860/50000] [Progress: 87.72%] [learning rate: 2.8e+04]\n",
            "[Step 43885/50000] [Progress: 87.77%] [learning rate: 2.7e+04]\n",
            "[Step 43911/50000] [Progress: 87.82%] [learning rate: 3.0e+04]\n",
            "[Step 43927/50000] [Time: 367s] [Train Loss: 2.47e-02] [Train Acc: 1.00]\n",
            "[Step 43935/50000] [Progress: 87.87%] [learning rate: 2.6e+04]\n",
            "[Step 43963/50000] [Progress: 87.93%] [learning rate: 3.1e+04]\n",
            "[Step 43987/50000] [Progress: 87.97%] [learning rate: 2.8e+04]\n",
            "[Step 44012/50000] [Progress: 88.02%] [learning rate: 2.8e+04]\n",
            "[Step 44026/50000] [Time: 367s] [Train Loss: 2.45e-02] [Train Acc: 1.00]\n",
            "[Step 44038/50000] [Progress: 88.08%] [learning rate: 2.7e+04]\n",
            "[Step 44063/50000] [Progress: 88.13%] [learning rate: 2.7e+04]\n",
            "[Step 44090/50000] [Progress: 88.18%] [learning rate: 2.9e+04]\n",
            "[Step 44116/50000] [Progress: 88.23%] [learning rate: 3.2e+04]\n",
            "[Step 44125/50000] [Time: 368s] [Train Loss: 2.44e-02] [Train Acc: 1.00]\n",
            "[Step 44139/50000] [Progress: 88.28%] [learning rate: 2.6e+04]\n",
            "[Step 44165/50000] [Progress: 88.33%] [learning rate: 2.8e+04]\n",
            "[Step 44190/50000] [Progress: 88.38%] [learning rate: 2.7e+04]\n",
            "[Step 44216/50000] [Progress: 88.43%] [learning rate: 3.0e+04]\n",
            "[Step 44224/50000] [Time: 369s] [Train Loss: 2.43e-02] [Train Acc: 1.00]\n",
            "[Step 44240/50000] [Progress: 88.48%] [learning rate: 2.7e+04]\n",
            "[Step 44267/50000] [Progress: 88.53%] [learning rate: 3.2e+04]\n",
            "[Step 44290/50000] [Progress: 88.58%] [learning rate: 2.6e+04]\n",
            "[Step 44317/50000] [Progress: 88.63%] [learning rate: 3.1e+04]\n",
            "[Step 44323/50000] [Time: 369s] [Train Loss: 2.41e-02] [Train Acc: 1.00]\n",
            "[Step 44340/50000] [Progress: 88.68%] [learning rate: 2.5e+04]\n",
            "[Step 44367/50000] [Progress: 88.73%] [learning rate: 3.0e+04]\n",
            "[Step 44392/50000] [Progress: 88.78%] [learning rate: 2.9e+04]\n",
            "[Step 44417/50000] [Progress: 88.83%] [learning rate: 3.2e+04]\n",
            "[Step 44422/50000] [Time: 370s] [Train Loss: 2.40e-02] [Train Acc: 1.00]\n",
            "[Step 44440/50000] [Progress: 88.88%] [learning rate: 2.6e+04]\n",
            "[Step 44466/50000] [Progress: 88.93%] [learning rate: 2.8e+04]\n",
            "[Step 44491/50000] [Progress: 88.98%] [learning rate: 2.8e+04]\n",
            "[Step 44517/50000] [Progress: 89.03%] [learning rate: 3.0e+04]\n",
            "[Step 44521/50000] [Time: 371s] [Train Loss: 2.39e-02] [Train Acc: 1.00]\n",
            "[Step 44541/50000] [Progress: 89.08%] [learning rate: 3.0e+04]\n",
            "[Step 44566/50000] [Progress: 89.13%] [learning rate: 2.9e+04]\n",
            "[Step 44590/50000] [Progress: 89.18%] [learning rate: 2.9e+04]\n",
            "[Step 44615/50000] [Progress: 89.23%] [learning rate: 2.8e+04]\n",
            "[Step 44620/50000] [Time: 372s] [Train Loss: 2.38e-02] [Train Acc: 1.00]\n",
            "[Step 44641/50000] [Progress: 89.28%] [learning rate: 3.1e+04]\n",
            "[Step 44665/50000] [Progress: 89.33%] [learning rate: 2.7e+04]\n",
            "[Step 44692/50000] [Progress: 89.38%] [learning rate: 3.3e+04]\n",
            "[Step 44715/50000] [Progress: 89.43%] [learning rate: 2.7e+04]\n",
            "[Step 44719/50000] [Time: 373s] [Train Loss: 2.36e-02] [Train Acc: 1.00]\n",
            "[Step 44741/50000] [Progress: 89.48%] [learning rate: 2.9e+04]\n",
            "[Step 44765/50000] [Progress: 89.53%] [learning rate: 2.8e+04]\n",
            "[Step 44790/50000] [Progress: 89.58%] [learning rate: 3.1e+04]\n",
            "[Step 44814/50000] [Progress: 89.63%] [learning rate: 2.8e+04]\n",
            "[Step 44818/50000] [Time: 373s] [Train Loss: 2.35e-02] [Train Acc: 1.00]\n",
            "[Step 44841/50000] [Progress: 89.68%] [learning rate: 3.3e+04]\n",
            "[Step 44864/50000] [Progress: 89.73%] [learning rate: 2.7e+04]\n",
            "[Step 44890/50000] [Progress: 89.78%] [learning rate: 2.9e+04]\n",
            "[Step 44915/50000] [Progress: 89.83%] [learning rate: 2.9e+04]\n",
            "[Step 44917/50000] [Time: 374s] [Train Loss: 2.34e-02] [Train Acc: 1.00]\n",
            "[Step 44941/50000] [Progress: 89.88%] [learning rate: 3.1e+04]\n",
            "[Step 44965/50000] [Progress: 89.93%] [learning rate: 2.8e+04]\n",
            "[Step 44993/50000] [Progress: 89.99%] [learning rate: 3.3e+04]\n",
            "[Step 45016/50000] [Time: 375s] [Train Loss: 2.33e-02] [Train Acc: 1.00]\n",
            "[Step 45018/50000] [Progress: 90.04%] [learning rate: 3.0e+04]\n",
            "[Step 45044/50000] [Progress: 90.09%] [learning rate: 2.9e+04]\n",
            "[Step 45070/50000] [Progress: 90.14%] [learning rate: 2.9e+04]\n",
            "[Step 45095/50000] [Progress: 90.19%] [learning rate: 2.8e+04]\n",
            "[Step 45115/50000] [Time: 376s] [Train Loss: 2.32e-02] [Train Acc: 1.00]\n",
            "[Step 45120/50000] [Progress: 90.24%] [learning rate: 3.1e+04]\n",
            "[Step 45147/50000] [Progress: 90.29%] [learning rate: 4.0e+04]\n",
            "[Step 45164/50000] [Progress: 90.33%] [learning rate: 2.0e+04]\n",
            "[Step 45195/50000] [Progress: 90.39%] [learning rate: 3.5e+04]\n",
            "[Step 45214/50000] [Time: 376s] [Train Loss: 2.30e-02] [Train Acc: 1.00]\n",
            "[Step 45218/50000] [Progress: 90.44%] [learning rate: 2.6e+04]\n",
            "[Step 45245/50000] [Progress: 90.49%] [learning rate: 3.1e+04]\n",
            "[Step 45270/50000] [Progress: 90.54%] [learning rate: 3.1e+04]\n",
            "[Step 45295/50000] [Progress: 90.59%] [learning rate: 3.3e+04]\n",
            "[Step 45313/50000] [Time: 377s] [Train Loss: 2.29e-02] [Train Acc: 1.00]\n",
            "[Step 45318/50000] [Progress: 90.64%] [learning rate: 2.7e+04]\n",
            "[Step 45344/50000] [Progress: 90.69%] [learning rate: 2.9e+04]\n",
            "[Step 45369/50000] [Progress: 90.74%] [learning rate: 2.9e+04]\n",
            "[Step 45395/50000] [Progress: 90.79%] [learning rate: 3.1e+04]\n",
            "[Step 45412/50000] [Time: 378s] [Train Loss: 2.28e-02] [Train Acc: 1.00]\n",
            "[Step 45419/50000] [Progress: 90.84%] [learning rate: 3.1e+04]\n",
            "[Step 45444/50000] [Progress: 90.89%] [learning rate: 3.3e+04]\n",
            "[Step 45467/50000] [Progress: 90.93%] [learning rate: 2.7e+04]\n",
            "[Step 45494/50000] [Progress: 90.99%] [learning rate: 3.2e+04]\n",
            "[Step 45511/50000] [Time: 378s] [Train Loss: 2.27e-02] [Train Acc: 1.00]\n",
            "[Step 45517/50000] [Progress: 91.03%] [learning rate: 2.9e+04]\n",
            "[Step 45542/50000] [Progress: 91.08%] [learning rate: 3.1e+04]\n",
            "[Step 45567/50000] [Progress: 91.13%] [learning rate: 3.1e+04]\n",
            "[Step 45593/50000] [Progress: 91.19%] [learning rate: 3.1e+04]\n",
            "[Step 45610/50000] [Time: 379s] [Train Loss: 2.26e-02] [Train Acc: 1.00]\n",
            "[Step 45617/50000] [Progress: 91.23%] [learning rate: 3.0e+04]\n",
            "[Step 45642/50000] [Progress: 91.28%] [learning rate: 3.0e+04]\n",
            "[Step 45668/50000] [Progress: 91.34%] [learning rate: 3.2e+04]\n",
            "[Step 45692/50000] [Progress: 91.38%] [learning rate: 2.9e+04]\n",
            "[Step 45709/50000] [Time: 380s] [Train Loss: 2.24e-02] [Train Acc: 1.00]\n",
            "[Step 45720/50000] [Progress: 91.44%] [learning rate: 3.4e+04]\n",
            "[Step 45744/50000] [Progress: 91.49%] [learning rate: 3.1e+04]\n",
            "[Step 45769/50000] [Progress: 91.54%] [learning rate: 3.0e+04]\n",
            "[Step 45795/50000] [Progress: 91.59%] [learning rate: 3.0e+04]\n",
            "[Step 45808/50000] [Time: 381s] [Train Loss: 2.23e-02] [Train Acc: 1.00]\n",
            "[Step 45820/50000] [Progress: 91.64%] [learning rate: 2.9e+04]\n",
            "[Step 45847/50000] [Progress: 91.69%] [learning rate: 3.2e+04]\n",
            "[Step 45874/50000] [Progress: 91.75%] [learning rate: 3.4e+04]\n",
            "[Step 45898/50000] [Progress: 91.80%] [learning rate: 3.1e+04]\n",
            "[Step 45907/50000] [Time: 381s] [Train Loss: 2.22e-02] [Train Acc: 1.00]\n",
            "[Step 45923/50000] [Progress: 91.85%] [learning rate: 3.0e+04]\n",
            "[Step 45949/50000] [Progress: 91.90%] [learning rate: 3.0e+04]\n",
            "[Step 45974/50000] [Progress: 91.95%] [learning rate: 2.9e+04]\n",
            "[Step 45999/50000] [Progress: 92.00%] [learning rate: 3.2e+04]\n",
            "[Step 46006/50000] [Time: 382s] [Train Loss: 2.21e-02] [Train Acc: 1.00]\n",
            "[Step 46025/50000] [Progress: 92.05%] [learning rate: 3.8e+04]\n",
            "[Step 46046/50000] [Progress: 92.09%] [learning rate: 2.6e+04]\n",
            "[Step 46075/50000] [Progress: 92.15%] [learning rate: 3.4e+04]\n",
            "[Step 46100/50000] [Progress: 92.20%] [learning rate: 3.0e+04]\n",
            "[Step 46105/50000] [Time: 383s] [Train Loss: 2.20e-02] [Train Acc: 1.00]\n",
            "[Step 46126/50000] [Progress: 92.25%] [learning rate: 3.3e+04]\n",
            "[Step 46150/50000] [Progress: 92.30%] [learning rate: 3.2e+04]\n",
            "[Step 46175/50000] [Progress: 92.35%] [learning rate: 3.5e+04]\n",
            "[Step 46198/50000] [Progress: 92.40%] [learning rate: 2.8e+04]\n",
            "[Step 46205/50000] [Time: 383s] [Train Loss: 2.18e-02] [Train Acc: 1.00]\n",
            "[Step 46225/50000] [Progress: 92.45%] [learning rate: 3.4e+04]\n",
            "[Step 46248/50000] [Progress: 92.50%] [learning rate: 3.0e+04]\n",
            "[Step 46273/50000] [Progress: 92.55%] [learning rate: 3.3e+04]\n",
            "[Step 46297/50000] [Progress: 92.59%] [learning rate: 3.2e+04]\n",
            "[Step 46305/50000] [Time: 384s] [Train Loss: 2.17e-02] [Train Acc: 1.00]\n",
            "[Step 46322/50000] [Progress: 92.64%] [learning rate: 3.2e+04]\n",
            "[Step 46348/50000] [Progress: 92.70%] [learning rate: 3.1e+04]\n",
            "[Step 46372/50000] [Progress: 92.74%] [learning rate: 3.1e+04]\n",
            "[Step 46397/50000] [Progress: 92.79%] [learning rate: 3.3e+04]\n",
            "[Step 46405/50000] [Time: 385s] [Train Loss: 2.16e-02] [Train Acc: 1.00]\n",
            "[Step 46421/50000] [Progress: 92.84%] [learning rate: 3.0e+04]\n",
            "[Step 46448/50000] [Progress: 92.90%] [learning rate: 3.6e+04]\n",
            "[Step 46471/50000] [Progress: 92.94%] [learning rate: 2.9e+04]\n",
            "[Step 46497/50000] [Progress: 92.99%] [learning rate: 3.1e+04]\n",
            "[Step 46505/50000] [Time: 386s] [Train Loss: 2.15e-02] [Train Acc: 1.00]\n",
            "[Step 46521/50000] [Progress: 93.04%] [learning rate: 3.1e+04]\n",
            "[Step 46546/50000] [Progress: 93.09%] [learning rate: 3.3e+04]\n",
            "[Step 46570/50000] [Progress: 93.14%] [learning rate: 3.0e+04]\n",
            "[Step 46597/50000] [Progress: 93.19%] [learning rate: 3.6e+04]\n",
            "[Step 46605/50000] [Time: 387s] [Train Loss: 2.14e-02] [Train Acc: 1.00]\n",
            "[Step 46620/50000] [Progress: 93.24%] [learning rate: 2.9e+04]\n",
            "[Step 46646/50000] [Progress: 93.29%] [learning rate: 3.1e+04]\n",
            "[Step 46671/50000] [Progress: 93.34%] [learning rate: 3.1e+04]\n",
            "[Step 46697/50000] [Progress: 93.39%] [learning rate: 3.4e+04]\n",
            "[Step 46705/50000] [Time: 387s] [Train Loss: 2.13e-02] [Train Acc: 1.00]\n",
            "[Step 46721/50000] [Progress: 93.44%] [learning rate: 3.0e+04]\n",
            "[Step 46749/50000] [Progress: 93.50%] [learning rate: 3.9e+04]\n",
            "[Step 46769/50000] [Progress: 93.54%] [learning rate: 2.7e+04]\n",
            "[Step 46797/50000] [Progress: 93.59%] [learning rate: 3.5e+04]\n",
            "[Step 46805/50000] [Time: 388s] [Train Loss: 2.12e-02] [Train Acc: 1.00]\n",
            "[Step 46822/50000] [Progress: 93.64%] [learning rate: 3.1e+04]\n",
            "[Step 46848/50000] [Progress: 93.70%] [learning rate: 3.4e+04]\n",
            "[Step 46872/50000] [Progress: 93.74%] [learning rate: 3.3e+04]\n",
            "[Step 46898/50000] [Progress: 93.80%] [learning rate: 3.6e+04]\n",
            "[Step 46905/50000] [Time: 389s] [Train Loss: 2.11e-02] [Train Acc: 1.00]\n",
            "[Step 46922/50000] [Progress: 93.84%] [learning rate: 3.2e+04]\n",
            "[Step 46947/50000] [Progress: 93.89%] [learning rate: 3.2e+04]\n",
            "[Step 46973/50000] [Progress: 93.95%] [learning rate: 3.4e+04]\n",
            "[Step 46996/50000] [Progress: 93.99%] [learning rate: 3.1e+04]\n",
            "[Step 47005/50000] [Time: 390s] [Train Loss: 2.10e-02] [Train Acc: 1.00]\n",
            "[Step 47022/50000] [Progress: 94.04%] [learning rate: 3.3e+04]\n",
            "[Step 47047/50000] [Progress: 94.09%] [learning rate: 3.3e+04]\n",
            "[Step 47073/50000] [Progress: 94.15%] [learning rate: 3.2e+04]\n",
            "[Step 47097/50000] [Progress: 94.19%] [learning rate: 3.2e+04]\n",
            "[Step 47105/50000] [Time: 390s] [Train Loss: 2.08e-02] [Train Acc: 1.00]\n",
            "[Step 47122/50000] [Progress: 94.24%] [learning rate: 3.1e+04]\n",
            "[Step 47147/50000] [Progress: 94.29%] [learning rate: 3.4e+04]\n",
            "[Step 47171/50000] [Progress: 94.34%] [learning rate: 3.4e+04]\n",
            "[Step 47196/50000] [Progress: 94.39%] [learning rate: 3.3e+04]\n",
            "[Step 47205/50000] [Time: 391s] [Train Loss: 2.07e-02] [Train Acc: 1.00]\n",
            "[Step 47222/50000] [Progress: 94.44%] [learning rate: 3.3e+04]\n",
            "[Step 47246/50000] [Progress: 94.49%] [learning rate: 3.2e+04]\n",
            "[Step 47271/50000] [Progress: 94.54%] [learning rate: 3.5e+04]\n",
            "[Step 47295/50000] [Progress: 94.59%] [learning rate: 3.1e+04]\n",
            "[Step 47305/50000] [Time: 392s] [Train Loss: 2.06e-02] [Train Acc: 1.00]\n",
            "[Step 47322/50000] [Progress: 94.64%] [learning rate: 3.7e+04]\n",
            "[Step 47345/50000] [Progress: 94.69%] [learning rate: 3.0e+04]\n",
            "[Step 47371/50000] [Progress: 94.74%] [learning rate: 3.3e+04]\n",
            "[Step 47397/50000] [Progress: 94.79%] [learning rate: 3.5e+04]\n",
            "[Step 47405/50000] [Time: 392s] [Train Loss: 2.05e-02] [Train Acc: 1.00]\n",
            "[Step 47420/50000] [Progress: 94.84%] [learning rate: 3.2e+04]\n",
            "[Step 47445/50000] [Progress: 94.89%] [learning rate: 3.4e+04]\n",
            "[Step 47470/50000] [Progress: 94.94%] [learning rate: 3.4e+04]\n",
            "[Step 47494/50000] [Progress: 94.99%] [learning rate: 3.3e+04]\n",
            "[Step 47505/50000] [Time: 393s] [Train Loss: 2.04e-02] [Train Acc: 1.00]\n",
            "[Step 47519/50000] [Progress: 95.04%] [learning rate: 3.3e+04]\n",
            "[Step 47545/50000] [Progress: 95.09%] [learning rate: 3.2e+04]\n",
            "[Step 47570/50000] [Progress: 95.14%] [learning rate: 3.2e+04]\n",
            "[Step 47595/50000] [Progress: 95.19%] [learning rate: 3.5e+04]\n",
            "[Step 47605/50000] [Time: 394s] [Train Loss: 2.03e-02] [Train Acc: 1.00]\n",
            "[Step 47620/50000] [Progress: 95.24%] [learning rate: 3.7e+04]\n",
            "[Step 47643/50000] [Progress: 95.29%] [learning rate: 3.0e+04]\n",
            "[Step 47669/50000] [Progress: 95.34%] [learning rate: 3.3e+04]\n",
            "[Step 47695/50000] [Progress: 95.39%] [learning rate: 3.6e+04]\n",
            "[Step 47705/50000] [Time: 395s] [Train Loss: 2.02e-02] [Train Acc: 1.00]\n",
            "[Step 47718/50000] [Progress: 95.44%] [learning rate: 3.2e+04]\n",
            "[Step 47744/50000] [Progress: 95.49%] [learning rate: 3.5e+04]\n",
            "[Step 47771/50000] [Progress: 95.54%] [learning rate: 4.1e+04]\n",
            "[Step 47791/50000] [Progress: 95.58%] [learning rate: 2.8e+04]\n",
            "[Step 47805/50000] [Time: 395s] [Train Loss: 2.01e-02] [Train Acc: 1.00]\n",
            "[Step 47819/50000] [Progress: 95.64%] [learning rate: 4.0e+04]\n",
            "[Step 47840/50000] [Progress: 95.68%] [learning rate: 2.7e+04]\n",
            "[Step 47868/50000] [Progress: 95.74%] [learning rate: 3.5e+04]\n",
            "[Step 47892/50000] [Progress: 95.78%] [learning rate: 3.2e+04]\n",
            "[Step 47905/50000] [Time: 396s] [Train Loss: 2.00e-02] [Train Acc: 1.00]\n",
            "[Step 47919/50000] [Progress: 95.84%] [learning rate: 3.8e+04]\n",
            "[Step 47943/50000] [Progress: 95.89%] [learning rate: 3.4e+04]\n",
            "[Step 47968/50000] [Progress: 95.94%] [learning rate: 3.3e+04]\n",
            "[Step 47994/50000] [Progress: 95.99%] [learning rate: 3.3e+04]\n",
            "[Step 48005/50000] [Time: 397s] [Train Loss: 1.99e-02] [Train Acc: 1.00]\n",
            "[Step 48019/50000] [Progress: 96.04%] [learning rate: 3.6e+04]\n",
            "[Step 48043/50000] [Progress: 96.09%] [learning rate: 3.5e+04]\n",
            "[Step 48068/50000] [Progress: 96.14%] [learning rate: 3.4e+04]\n",
            "[Step 48094/50000] [Progress: 96.19%] [learning rate: 3.4e+04]\n",
            "[Step 48105/50000] [Time: 398s] [Train Loss: 1.98e-02] [Train Acc: 1.00]\n",
            "[Step 48118/50000] [Progress: 96.24%] [learning rate: 3.3e+04]\n",
            "[Step 48143/50000] [Progress: 96.29%] [learning rate: 3.6e+04]\n",
            "[Step 48167/50000] [Progress: 96.33%] [learning rate: 3.2e+04]\n",
            "[Step 48194/50000] [Progress: 96.39%] [learning rate: 3.9e+04]\n",
            "[Step 48205/50000] [Time: 398s] [Train Loss: 1.97e-02] [Train Acc: 1.00]\n",
            "[Step 48217/50000] [Progress: 96.43%] [learning rate: 3.1e+04]\n",
            "[Step 48243/50000] [Progress: 96.49%] [learning rate: 3.4e+04]\n",
            "[Step 48267/50000] [Progress: 96.53%] [learning rate: 3.4e+04]\n",
            "[Step 48292/50000] [Progress: 96.58%] [learning rate: 3.6e+04]\n",
            "[Step 48305/50000] [Time: 399s] [Train Loss: 1.96e-02] [Train Acc: 1.00]\n",
            "[Step 48316/50000] [Progress: 96.63%] [learning rate: 3.3e+04]\n",
            "[Step 48344/50000] [Progress: 96.69%] [learning rate: 3.9e+04]\n",
            "[Step 48369/50000] [Progress: 96.74%] [learning rate: 3.5e+04]\n",
            "[Step 48395/50000] [Progress: 96.79%] [learning rate: 3.4e+04]\n",
            "[Step 48405/50000] [Time: 400s] [Train Loss: 1.95e-02] [Train Acc: 1.00] [Eval Loss: 5.32e-01] [Eval Acc: 0.81]\n",
            "[Step 48421/50000] [Progress: 96.84%] [learning rate: 3.4e+04]\n",
            "[Step 48446/50000] [Progress: 96.89%] [learning rate: 3.3e+04]\n",
            "[Step 48473/50000] [Progress: 96.95%] [learning rate: 3.6e+04]\n",
            "[Step 48498/50000] [Progress: 97.00%] [learning rate: 3.9e+04]\n",
            "[Step 48505/50000] [Time: 402s] [Train Loss: 1.94e-02] [Train Acc: 1.00]\n",
            "[Step 48521/50000] [Progress: 97.04%] [learning rate: 3.2e+04]\n",
            "[Step 48547/50000] [Progress: 97.09%] [learning rate: 3.4e+04]\n",
            "[Step 48572/50000] [Progress: 97.14%] [learning rate: 3.4e+04]\n",
            "[Step 48598/50000] [Progress: 97.20%] [learning rate: 3.7e+04]\n",
            "[Step 48605/50000] [Time: 403s] [Train Loss: 1.93e-02] [Train Acc: 1.00]\n",
            "[Step 48622/50000] [Progress: 97.24%] [learning rate: 3.6e+04]\n",
            "[Step 48647/50000] [Progress: 97.29%] [learning rate: 3.9e+04]\n",
            "[Step 48670/50000] [Progress: 97.34%] [learning rate: 3.2e+04]\n",
            "[Step 48698/50000] [Progress: 97.40%] [learning rate: 3.8e+04]\n",
            "[Step 48705/50000] [Time: 404s] [Train Loss: 1.92e-02] [Train Acc: 1.00]\n",
            "[Step 48722/50000] [Progress: 97.44%] [learning rate: 3.4e+04]\n",
            "[Step 48747/50000] [Progress: 97.49%] [learning rate: 3.7e+04]\n",
            "[Step 48771/50000] [Progress: 97.54%] [learning rate: 3.6e+04]\n",
            "[Step 48796/50000] [Progress: 97.59%] [learning rate: 3.9e+04]\n",
            "[Step 48805/50000] [Time: 405s] [Train Loss: 1.91e-02] [Train Acc: 1.00]\n",
            "[Step 48819/50000] [Progress: 97.64%] [learning rate: 3.2e+04]\n",
            "[Step 48846/50000] [Progress: 97.69%] [learning rate: 3.8e+04]\n",
            "[Step 48869/50000] [Progress: 97.74%] [learning rate: 3.4e+04]\n",
            "[Step 48894/50000] [Progress: 97.79%] [learning rate: 3.7e+04]\n",
            "[Step 48905/50000] [Time: 405s] [Train Loss: 1.90e-02] [Train Acc: 1.00]\n",
            "[Step 48918/50000] [Progress: 97.84%] [learning rate: 3.6e+04]\n",
            "[Step 48943/50000] [Progress: 97.89%] [learning rate: 3.6e+04]\n",
            "[Step 48967/50000] [Progress: 97.93%] [learning rate: 3.5e+04]\n",
            "[Step 48992/50000] [Progress: 97.98%] [learning rate: 3.5e+04]\n",
            "[Step 49005/50000] [Time: 406s] [Train Loss: 1.89e-02] [Train Acc: 1.00]\n",
            "[Step 49018/50000] [Progress: 98.04%] [learning rate: 3.8e+04]\n",
            "[Step 49042/50000] [Progress: 98.08%] [learning rate: 3.4e+04]\n",
            "[Step 49069/50000] [Progress: 98.14%] [learning rate: 4.0e+04]\n",
            "[Step 49092/50000] [Progress: 98.18%] [learning rate: 3.3e+04]\n",
            "[Step 49105/50000] [Time: 407s] [Train Loss: 1.88e-02] [Train Acc: 1.00]\n",
            "[Step 49118/50000] [Progress: 98.24%] [learning rate: 3.6e+04]\n",
            "[Step 49143/50000] [Progress: 98.29%] [learning rate: 3.5e+04]\n",
            "[Step 49169/50000] [Progress: 98.34%] [learning rate: 3.8e+04]\n",
            "[Step 49193/50000] [Progress: 98.39%] [learning rate: 3.4e+04]\n",
            "[Step 49205/50000] [Time: 408s] [Train Loss: 1.87e-02] [Train Acc: 1.00]\n",
            "[Step 49221/50000] [Progress: 98.44%] [learning rate: 4.0e+04]\n",
            "[Step 49245/50000] [Progress: 98.49%] [learning rate: 3.6e+04]\n",
            "[Step 49270/50000] [Progress: 98.54%] [learning rate: 3.6e+04]\n",
            "[Step 49296/50000] [Progress: 98.59%] [learning rate: 3.5e+04]\n",
            "[Step 49305/50000] [Time: 408s] [Train Loss: 1.86e-02] [Train Acc: 1.00]\n",
            "[Step 49321/50000] [Progress: 98.64%] [learning rate: 3.5e+04]\n",
            "[Step 49348/50000] [Progress: 98.70%] [learning rate: 3.8e+04]\n",
            "[Step 49374/50000] [Progress: 98.75%] [learning rate: 4.1e+04]\n",
            "[Step 49398/50000] [Progress: 98.80%] [learning rate: 3.6e+04]\n",
            "[Step 49405/50000] [Time: 409s] [Train Loss: 1.85e-02] [Train Acc: 1.00]\n",
            "[Step 49423/50000] [Progress: 98.85%] [learning rate: 3.6e+04]\n",
            "[Step 49449/50000] [Progress: 98.90%] [learning rate: 3.5e+04]\n",
            "[Step 49474/50000] [Progress: 98.95%] [learning rate: 3.5e+04]\n",
            "[Step 49500/50000] [Progress: 99.00%] [learning rate: 3.8e+04]\n",
            "[Step 49505/50000] [Time: 410s] [Train Loss: 1.84e-02] [Train Acc: 1.00]\n",
            "[Step 49526/50000] [Progress: 99.05%] [learning rate: 4.1e+04]\n",
            "[Step 49549/50000] [Progress: 99.10%] [learning rate: 3.3e+04]\n",
            "[Step 49575/50000] [Progress: 99.15%] [learning rate: 3.6e+04]\n",
            "[Step 49600/50000] [Progress: 99.20%] [learning rate: 3.5e+04]\n",
            "[Step 49605/50000] [Time: 411s] [Train Loss: 1.83e-02] [Train Acc: 1.00]\n",
            "[Step 49626/50000] [Progress: 99.25%] [learning rate: 3.8e+04]\n",
            "[Step 49651/50000] [Progress: 99.30%] [learning rate: 3.8e+04]\n",
            "[Step 49677/50000] [Progress: 99.35%] [learning rate: 3.7e+04]\n",
            "[Step 49701/50000] [Progress: 99.40%] [learning rate: 3.7e+04]\n",
            "[Step 49705/50000] [Time: 411s] [Train Loss: 1.82e-02] [Train Acc: 1.00]\n",
            "[Step 49726/50000] [Progress: 99.45%] [learning rate: 3.6e+04]\n",
            "[Step 49752/50000] [Progress: 99.50%] [learning rate: 3.9e+04]\n",
            "[Step 49776/50000] [Progress: 99.55%] [learning rate: 3.5e+04]\n",
            "[Step 49803/50000] [Progress: 99.61%] [learning rate: 4.2e+04]\n",
            "[Step 49805/50000] [Time: 412s] [Train Loss: 1.81e-02] [Train Acc: 1.00]\n",
            "[Step 49826/50000] [Progress: 99.65%] [learning rate: 3.4e+04]\n",
            "[Step 49852/50000] [Progress: 99.70%] [learning rate: 3.7e+04]\n",
            "[Step 49876/50000] [Progress: 99.75%] [learning rate: 3.6e+04]\n",
            "[Step 49901/50000] [Progress: 99.80%] [learning rate: 3.9e+04]\n",
            "[Step 49905/50000] [Time: 413s] [Train Loss: 1.80e-02] [Train Acc: 1.00]\n",
            "[Step 49925/50000] [Progress: 99.85%] [learning rate: 3.5e+04]\n",
            "[Step 49952/50000] [Progress: 99.90%] [learning rate: 4.2e+04]\n",
            "[Step 49975/50000] [Progress: 99.95%] [learning rate: 3.4e+04]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "def load_results(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        data = torch.load(f, weights_only=False)\n",
        "    args = data.get('args', None)\n",
        "    results = data.get('results', None)\n",
        "\n",
        "    if results is None:\n",
        "        print(f\"No results found in {filename}\")\n",
        "        return None, None\n",
        "\n",
        "    if 'init_kernel' in results:\n",
        "        dynamics = results['init_kernel'].get('dynamics', [])\n",
        "        final_results = results['init_kernel']\n",
        "    else:\n",
        "        print(f\"No 'init_kernel' key found in {filename}\")\n",
        "        return None, None\n",
        "\n",
        "    return args, final_results, dynamics\n",
        "\n",
        "def plot_training_results(args, dynamics):\n",
        "    if args is None or dynamics is None:\n",
        "        print(\"No data to plot.\")\n",
        "        return\n",
        "\n",
        "    steps = [state['step'] for state in dynamics]\n",
        "    train_losses = [state['train']['loss'] for state in dynamics]\n",
        "    train_accuracies = [state['train']['accuracy'] for state in dynamics]\n",
        "\n",
        "    plt.figure(figsize=(9, 5))\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(steps, train_losses, label='Train', color='blue')\n",
        "    if args.track_test_metrics:\n",
        "        test_steps = [state['step'] for state in dynamics if state['test']['loss'] is not None]\n",
        "        test_losses = [state['test']['loss'] for state in dynamics if state['test']['loss'] is not None]\n",
        "        plt.plot(test_steps, test_losses, label='Test', color='red')\n",
        "    plt.xlabel('Step')\n",
        "    # plt.xscale('log')\n",
        "    # plt.yscale('log')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(steps, train_accuracies, label='Train', color='blue')\n",
        "    if args.track_test_metrics:\n",
        "        test_steps = [state['step'] for state in dynamics if state['test']['accuracy'] is not None]\n",
        "        test_accuracies = [state['test']['accuracy'] for state in dynamics if state['test']['accuracy'] is not None]\n",
        "        plt.plot(test_steps, test_accuracies, label='Test', color='red')\n",
        "    plt.xlabel('Step')\n",
        "    # plt.xscale('log')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# テストとトレーニングの出力とラベルの最初の100個を表示する関数\n",
        "def print_outputs_labels(final_results, num_samples=100):\n",
        "    # Training data display\n",
        "    if final_results is None or 'train' not in final_results:\n",
        "        print(\"No train results found in the final results.\")\n",
        "    else:\n",
        "        train_outputs = final_results['train']['outputs']\n",
        "        train_labels = final_results['train']['labels']\n",
        "\n",
        "        if train_outputs is not None and train_labels is not None:\n",
        "            print(f\"\\nFirst {num_samples} Train Outputs:\")\n",
        "            print(train_outputs[:num_samples])\n",
        "\n",
        "            print(f\"\\nFirst {num_samples} Train Labels:\")\n",
        "            print(train_labels[:num_samples])\n",
        "        else:\n",
        "            print(\"Train outputs or labels not found.\")\n",
        "\n",
        "    # Test data display\n",
        "    if final_results is None or 'test' not in final_results:\n",
        "        print(\"No test results found in the final results.\")\n",
        "    else:\n",
        "        test_outputs = final_results['test']['outputs']\n",
        "        test_labels = final_results['test']['labels']\n",
        "\n",
        "        if test_outputs is not None and test_labels is not None:\n",
        "            print(f\"\\nFirst {num_samples} Test Outputs:\")\n",
        "            print(test_outputs[:num_samples])\n",
        "\n",
        "            print(f\"\\nFirst {num_samples} Test Labels:\")\n",
        "            print(test_labels[:num_samples])\n",
        "        else:\n",
        "            print(\"Test outputs or labels not found.\")\n",
        "\n",
        "filename = 'results.pkl'\n",
        "args, final_results, dynamics = load_results(filename)\n",
        "\n",
        "\n",
        "plot_training_results(args, dynamics)\n",
        "\n",
        "# トレーニングとテスト出力とラベルの最初の100個を表示\n",
        "print_outputs_labels(final_results, num_samples=100)\n",
        "\n",
        "\n",
        "# Calculate and display final test accuracy\n",
        "if final_results is not None and 'test' in final_results:\n",
        "    test_outputs = final_results['test']['outputs']\n",
        "    test_labels = final_results['test']['labels']\n",
        "    if test_outputs is not None and test_labels is not None:\n",
        "        test_preds = torch.sigmoid(test_outputs) > 0.5\n",
        "        test_accuracy = (test_preds.int() == test_labels.int()).float().mean().item()\n",
        "        print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n",
        "    else:\n",
        "        print(\"Test outputs or labels not found.\")\n",
        "else:\n",
        "    print(\"No test results found in the final results.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "busmySOVucH0",
        "outputId": "9b46209f-6a3f-4fdd-b27c-ff3b1475ce73"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAAEYCAYAAAD/Dg+wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6IUlEQVR4nO3dd3hTZfsH8G+SpmlLJ3RSCi1DNmVJKVuhgCBLkPnKUpT1CtQFynQVURAVBEQB9QVBkPWTitRCRWTvjTJboC2zdLdpcn5/PCRpaAudOWnz/VzXuc7Jk3NO7jyEntw5z1BIkiSBiIiIiIiIyjWl3AEQERERERFRyTG5IyIiIiIiqgCY3BEREREREVUATO6IiIiIiIgqACZ3REREREREFQCTOyIiIiIiogqAyR0REREREVEFwOSOiIiIiIioAmByR0REREREVAEwuSMiIiIiIqoAmNwRWZlVq1ZBoVDg8OHDcodCRERk5uuvv4ZCoUBISIjcoRBRPpjcEREREVGhrF69GoGBgTh48CAuXrwodzhE9Agmd0RERET0RFeuXMHevXuxYMECeHl5YfXq1XKHlK+0tDS5QyCSDZM7onLo2LFjeO655+Dq6gpnZ2d07twZ+/fvN9tHq9Vizpw5qFOnDhwcHFClShW0a9cOUVFRxn0SEhIwatQoVKtWDRqNBn5+fujTpw+uXr1q4XdERETWbvXq1fDw8EDPnj0xYMCAfJO7pKQkTJkyBYGBgdBoNKhWrRqGDx+OO3fuGPfJzMzE7Nmz8dRTT8HBwQF+fn544YUXcOnSJQBATEwMFAoFYmJizM599epVKBQKrFq1ylg2cuRIODs749KlS+jRowdcXFwwbNgwAMBff/2FF198EdWrV4dGo0FAQACmTJmCjIyMPHGfP38eAwcOhJeXFxwdHVG3bl289957AIBdu3ZBoVBg06ZNeY5bs2YNFAoF9u3bV+T6JCoLdnIHQERFc+bMGbRv3x6urq54++23oVarsWzZMnTq1Al//vmnsR/E7NmzERERgVdeeQWtWrVCcnIyDh8+jKNHjyIsLAwA0L9/f5w5cwb//e9/ERgYiFu3biEqKgqxsbEIDAyU8V0SEZG1Wb16NV544QXY29tjyJAhWLJkCQ4dOoSnn34aAJCamor27dvj3LlzGD16NJo3b447d+5g69atuH79Ojw9PaHT6fD8888jOjoagwcPxqRJk5CSkoKoqCicPn0atWrVKnJcOTk56NatG9q1a4fPPvsMTk5OAID169cjPT0d48aNQ5UqVXDw4EF89dVXuH79OtavX288/uTJk2jfvj3UajVeffVVBAYG4tKlS/i///s/fPTRR+jUqRMCAgKwevVq9OvXL0+d1KpVC6GhoSWoWaJSJBGRVVm5cqUEQDp06FC+z/ft21eyt7eXLl26ZCy7efOm5OLiInXo0MFYFhwcLPXs2bPA17l//74EQPr0009LL3giIqqQDh8+LAGQoqKiJEmSJL1eL1WrVk2aNGmScZ+ZM2dKAKSNGzfmOV6v10uSJEkrVqyQAEgLFiwocJ9du3ZJAKRdu3aZPX/lyhUJgLRy5Upj2YgRIyQA0tSpU/OcLz09PU9ZRESEpFAopGvXrhnLOnToILm4uJiV5Y5HkiRp2rRpkkajkZKSkoxlt27dkuzs7KRZs2bleR0iubBZJlE5otPpsGPHDvTt2xc1a9Y0lvv5+WHo0KHYs2cPkpOTAQDu7u44c+YM/v3333zP5ejoCHt7e8TExOD+/fsWiZ+IiMqn1atXw8fHB8888wwAQKFQYNCgQVi7di10Oh0A4JdffkFwcHCeu1uG/Q37eHp64r///W+B+xTHuHHj8pQ5Ojoat9PS0nDnzh20adMGkiTh2LFjAIDbt29j9+7dGD16NKpXr15gPMOHD0dWVhY2bNhgLFu3bh1ycnLwn//8p9hxE5U2JndE5cjt27eRnp6OunXr5nmufv360Ov1iIuLAwC8//77SEpKwlNPPYXGjRvjrbfewsmTJ437azQafPLJJ/jtt9/g4+ODDh06YN68eUhISLDY+yEiIuun0+mwdu1aPPPMM7hy5QouXryIixcvIiQkBImJiYiOjgYAXLp0CY0aNXrsuS5duoS6devCzq70egbZ2dmhWrVqecpjY2MxcuRIVK5cGc7OzvDy8kLHjh0BAA8ePAAAXL58GQCeGHe9evXw9NNPm/UzXL16NVq3bo3atWuX1lshKjEmd0QVVIcOHXDp0iWsWLECjRo1wrfffovmzZvj22+/Ne4zefJk/PPPP4iIiICDgwNmzJiB+vXrG3/RJCIi2rlzJ+Lj47F27VrUqVPHuAwcOBAASn3UzILu4BnuED5Ko9FAqVTm2TcsLAzbtm3DO++8g82bNyMqKso4GItery9yXMOHD8eff/6J69ev49KlS9i/fz/v2pHV4YAqROWIl5cXnJyccOHChTzPnT9/HkqlEgEBAcayypUrY9SoURg1ahRSU1PRoUMHzJ49G6+88opxn1q1auGNN97AG2+8gX///RdNmzbF/Pnz8b///c8i74mIiKzb6tWr4e3tjcWLF+d5buPGjdi0aROWLl2KWrVq4fTp0489V61atXDgwAFotVqo1ep89/Hw8AAgRt7M7dq1a4WO+dSpU/jnn3/w/fffY/jw4cby3CNGAzB2cXhS3AAwePBghIeH46effkJGRgbUajUGDRpU6JiILIF37ojKEZVKha5du2LLli1m0xUkJiZizZo1aNeuHVxdXQEAd+/eNTvW2dkZtWvXRlZWFgAgPT0dmZmZZvvUqlULLi4uxn2IiMi2ZWRkYOPGjXj++ecxYMCAPMvEiRORkpKCrVu3on///jhx4kS+UwZIkgRAjNJ8584dLFq0qMB9atSoAZVKhd27d5s9//XXXxc6bpVKZXZOw/YXX3xhtp+Xlxc6dOiAFStWIDY2Nt94DDw9PfHcc8/hf//7H1avXo3u3bvD09Oz0DERWQLv3BFZqRUrVmD79u15ymfPno2oqCi0a9cO48ePh52dHZYtW4asrCzMmzfPuF+DBg3QqVMntGjRApUrV8bhw4exYcMGTJw4EQDwzz//oHPnzhg4cCAaNGgAOzs7bNq0CYmJiRg8eLDF3icREVmvrVu3IiUlBb179873+datWxsnNF+zZg02bNiAF198EaNHj0aLFi1w7949bN26FUuXLkVwcDCGDx+OH374AeHh4Th48CDat2+PtLQ0/PHHHxg/fjz69OkDNzc3vPjii/jqq6+gUChQq1Yt/Prrr7h161ah465Xrx5q1aqFN998Ezdu3ICrqyt++eWXfAcQ+/LLL9GuXTs0b94cr776KoKCgnD16lVs27YNx48fN9t3+PDhGDBgAADggw8+KHxFElmKnEN1ElFehqkQClri4uKko0ePSt26dZOcnZ0lJycn6ZlnnpH27t1rdp4PP/xQatWqleTu7i45OjpK9erVkz766CMpOztbkiRJunPnjjRhwgSpXr16UqVKlSQ3NzcpJCRE+vnnn+V420REZIV69eolOTg4SGlpaQXuM3LkSEmtVkt37tyR7t69K02cOFHy9/eX7O3tpWrVqkkjRoyQ7ty5Y9w/PT1deu+996SgoCBJrVZLvr6+0oABA8ym+Ll9+7bUv39/ycnJSfLw8JBee+016fTp0/lOhVCpUqV84zp79qzUpUsXydnZWfL09JTGjBkjnThxIs85JEmSTp8+LfXr109yd3eXHBwcpLp160ozZszIc86srCzJw8NDcnNzkzIyMgpZi0SWo5CkR+45ExERERFRHjk5OahatSp69eqF7777Tu5wiPJgnzsiIiIiokLYvHkzbt++bTZIC5E14Z07IiIiIqLHOHDgAE6ePIkPPvgAnp6eOHr0qNwhEeWLd+6IiIiIiB5jyZIlGDduHLy9vfHDDz/IHQ5RgXjnjoiIiIiIqALgnTsiIiIiIqIKgMkdERERERFRBWBzk5jr9XrcvHkTLi4uUCgUcodDRESFJEkSUlJSULVqVSiV/G3ycXitIyIqn0p6rbO55O7mzZsICAiQOwwiIiqmuLg4VKtWTe4wrBqvdURE5Vtxr3U2l9y5uLgAEBXm6uparHNotVrs2LEDXbt2hVqtLs3wyh3WhQnrwoR1YcK6MClpXSQnJyMgIMD4d5wKxmtd6WJdmLAuTFgXJqwLE7mvdTaX3Bmap7i6upbogufk5ARXV1d+gFkXRqwLE9aFCevCpLTqgs0Mn4zXutLFujBhXZiwLkxYFyZyX+vYaYGIiIiIiKgCYHJHRERERERUATC5IyIiKkO7d+9Gr169ULVqVSgUCmzevPmJx8TExKB58+bQaDSoXbs2Vq1aVeZxEhFR+cfkjoiIqAylpaUhODgYixcvLtT+V65cQc+ePfHMM8/g+PHjmDx5Ml555RX8/vvvZRwpERGVdzY3oEppOL3tGjKP30F6g1twq+MvdzhERGTFnnvuOTz33HOF3n/p0qUICgrC/PnzAQD169fHnj178Pnnn6Nbt25lFSaRTZMkID09/+eys4H4+LzlWi0QF+eCs2cBGx9DhHWRi1YLZGTIl2IxuSsinQ6I6xeOQfg/YA7wb50eqPP7IiAoSO7QiIioAti3bx+6dOliVtatWzdMnjy5wGOysrKQlZVlfJycnAxAjNqm1WqLFYfhuOIeX5GwLkyKWxc5OUBKCnD/PpCQoMCdO6I8PR24eVOBhASRYD0qNVWBu3dNj+/cKTgJKwq9XoGbN8X3OkAkcCkpRR2dUA3g2ZIHUyGwLkzUmD69Cnr3Ltnf3uJicldEKSmAzskFd9Mrowruoc6/kchu2Qb20b8BTZvKHR4REZVzCQkJ8PHxMSvz8fFBcnIyMjIy4OjomOeYiIgIzJkzJ0/5jh074OTkVKJ4oqKiSnR8RVLR6iItzQ7Z2SqcPVsFt24V/nMiSbWxYsVN5OQokZamRlycC3JylI/sA9y75wC9XiRMWq0qzz7lSaVK2VCp8sk+ifJhZ6cv9t+L9BL+esHkrojc3YHnk1YhMjIS+36ohyEbByL43klInTpBceYM4M9mmkREZFnTpk1DeHi48bFhEtyuXbuWaJ67qKgohIWFcd6qclwXsbHAtWsKJCaK9YEDCpw7p0BaGnD9uuXnjLS3l+DrC/j5SVAoADs7oGpVwN9fgl0+30rt7QFfX8Aw5ZeLiwQPj9KJxcdHgkYjtpVKwM8P+cagVAKOjgoA5vVVnj8XpY11YSLq4nax68LQ8qK4mNyVwISFNdF6+5/Ymt4ZLR4cBWbNAr79Vu6wiIioHPP19UViYqJZWWJiIlxdXfO9awcAGo0GGsO31FzUanWJv2iVxjkqCmurC0kCjhwB/voLuHQJ2LwZuHkz7z6Po1CIH647dwYqVXrya+r1ely/fh1NmvjDzU0FjQZo2BBwds67r7c3YPjIqtUiiVOpFFAqgUcTpfLM2j4XcmJdmBS3Lkpaf0zuSsDXFxj4qjsmLlyEfWgDrFwJTJki/soREREVQ2hoKCIjI83KoqKiEBoaKlNEZCmSBGRkiAEZzpwBrl0DHjwAkpNFXzUAuHEDuHhRbMfFAdevP/m8QUEi0QoIAFq1Er1InJ2BBg0AN7eixajV6hAZeQw9evhBrVYV7WAiKnNM7kpo7Fhg4cJQ/IL+6K//BZg6Ffi//5M7LCIishKpqam4aPg2DjHVwfHjx1G5cmVUr14d06ZNw40bN/DDDz8AAMaOHYtFixbh7bffxujRo7Fz5078/PPP2LZtm1xvgUpZVhZw5Qqwdy+QmioGCTl5Eti925TEFValSsCzzwLVqwPNmwM9epiaMAKAg0PREzgiKr+Y3JVQ3briF7Bpxz9GP+VmKH/9FYiJATp1kjkyIiKyBocPH8YzzzxjfGzoGzdixAisWrUK8fHxiI2NNT4fFBSEbdu2YcqUKfjiiy9QrVo1fPvtt5wGoRzRaoFNm4CzZ0USd++eGJXRMDrjv/+KBO9xfHyAOnXEHTeNRjxWKETzxmbNRHNHFxegdWughGPmEFEFwuSuFPTpA8w5/hR+D3wNz13+Wty927fP/KczIiKySZ06dYL0mI5Pq1atyveYY8eOlWFUVJqys4HDh0X/t7//Bn75RQz9/zj29kBoqBjEw9kZqFFD/C7cqJFI4Jyc+DWCiIqOyV0p6NEDmDMHmHx3JrprvoPiwAFg/37xV5uIiIgqDEkSiVtMjOjzduwYsHx53jtxbm5A375ArVpiIBGFQtx9c3AQA5g0bQqo2GWNiEoZk7tS0KyZaPP+zwMfJPUdCo/NK4EvvmByR0REVEHEx1fC0KEqREfn3y/O2Rlo2xYIDAR69waeecY0UiQRkaUwuSsFarXI4/74A9hR73UMwkpgwwYxhFW1anKHR0RERMWwZ48YCPvQITucOtXF7Dl7e9HfLTAQ6NkTeOGF/OdIIyKyJP4ZKiXt24vkbvPVphjUoYMY8mrJEuCjj+QOjYiIiArp8mXgm2+AHTtEk0tBdH7r3l2PqVOVaNRItNhxcJAtTCKifDG5KyVt2oj1oUMA5k0Syd2yZcD06WyXQUREZMXu3hUJ3V9/Ab/9Ziq3twdeegl49tkcpKbuxKhRz0CtVsoXKBHREzC5KyXNmon1pUvAg4694Va9OhAbC/z0EzB6tLzBERERUR6xscBnnwFffWVe3qwZMGIEMGAA4O8PaLUSIiMz5AmSiKgI+PNTKalSRUwgCgDHT9sBEyeKB198IYbWIiIiItlJErBmjegvV6OGKbHz9wdmzxYtcI4eBSZNEmVEROUJk7tS1Ly5WB89CuCVV8QkNSdPiiaaREREJKukJKB/f2DYMODAAVHWsKHoIn/uHDBrFtCypawhEhGVCJO7UmRomnnsGAAPD9FQHxB374iIiEg2a9aIO3WbNonHI0cCN24Ap08DY8cCLi6yhkdEVCqY3JWixo3F+syZhwWvvy7WW7aIqwcRERFZ1IMHwH/+I+7WJScDvr7A5s1iioOqVeWOjoiodDG5K0WNGon12bOATgegQQMx8Y1eD4wbJ9ZERERkEWfPimaWq1cDKhUwZw4QFwf06SN3ZEREZYPJXSmqWVPMeZOZCVy58rDw889F37s9e4Dvv5c1PiIiIluQlCRmImraFLh4EfDxEdMczJzJicaJqGJjcleKVCqgfn2xbWyFWb26GH4LAN56S0ymQ0RERKXu8mWgUyegWjXgo48ArRZ4/nmR2IWGyh0dEVHZkz25W7x4MQIDA+Hg4ICQkBAcPHjwsfsnJSVhwoQJ8PPzg0ajwVNPPYXIyEgLRftkhqaZZl3sJk8WT9y9C0ydKkdYREREFdrSpUCtWsCffwJpaWIUzF9+AbZuBerUkTs6IiLLkDW5W7duHcLDwzFr1iwcPXoUwcHB6NatG27dupXv/tnZ2QgLC8PVq1exYcMGXLhwAcuXL4e/FU1Ek29yp1aLcZYB4Ntvgb17LR4XERFRRSRJYgqDceNMZT/9BJw6Jbq9KxTyxUZEZGmyJncLFizAmDFjMGrUKDRo0ABLly6Fk5MTVqxYke/+K1aswL1797B582a0bdsWgYGB6NixI4KDgy0cecEMyZ1xxEyDdu2A0aPF9rhxQE6OReMiIiKqiJYsAd5/X2w//zyQmgoMHsykjohsk2zdirOzs3HkyBFMmzbNWKZUKtGlSxfs27cv32O2bt2K0NBQTJgwAVu2bIGXlxeGDh2Kd955ByqVKt9jsrKykJWVZXycnJwMANBqtdBqtcWK3XBcfsc/9RQAqHH+vIS0tBzY2+d68sMPYbd5MxQnT0L3+efQT55crNe3Jo+rC1vDujBhXZiwLkxKWhesQ8otOxv47jvTrEMffQS8+668MRERyU225O7OnTvQ6XTw8fExK/fx8cH58+fzPeby5cvYuXMnhg0bhsjISFy8eBHjx4+HVqvFrFmz8j0mIiICc+bMyVO+Y8cOODk5leg9REVF5SmTJMDBoScyM+2wYsVfqF49xez56kOGoNnixZBmzsTOypWR6elZohisRX51YatYFyasCxPWhUlx6yI9Pb2UI6Hy6O5dkcStWiUSPEDcscv1WzERkc0qVwMC6/V6eHt745tvvoFKpUKLFi1w48YNfPrppwUmd9OmTUN4eLjxcXJyMgICAtC1a1e4uroWKw6tVouoqCiEhYVBrVbneT44WIkDB4AqVTqgRw/J/Mnu3aE/ehR2+/YhbNs26NatK1YM1uJJdWFLWBcmrAsT1oVJSevC0PKCbNe5c0CvXsClS+Kxi4uYu27iRDbDJCICZEzuPD09oVKpkJiYaFaemJgIX1/ffI/x8/ODWq02a4JZv359JCQkIDs7G/ZmbSAFjUYDjUaTp1ytVpf4i1ZB52jcGDhwADh/3g75vsTSpUDz5lBu2gTlb78BvXuXKA5rUBr1WVGwLkxYFyasC5Pi1gXrz3alpopml/PmAXo9EBQk+tp17sx564iIcpNtQBV7e3u0aNEC0dHRxjK9Xo/o6GiEFjAZTdu2bXHx4kXo9Xpj2T///AM/P798Ezu5NGwo1mYjZubWpAkwZYrYHjwYiImxRFhERETlSkYGMGMG4O8PzJ0rErt27cQPqN26MbEjInqUrKNlhoeHY/ny5fj+++9x7tw5jBs3DmlpaRg1ahQAYPjw4WYDrowbNw737t3DpEmT8M8//2Dbtm34+OOPMWHCBLneQr7ynQ7hUR9+CDz3nLhy9ewpJuYhIiIiAMCFC6IlzIcfAsnJgKenGEAlJgbw8pI7OiIi6yTrb16DBg3C7du3MXPmTCQkJKBp06bYvn27cZCV2NhYKJWm/DMgIAC///47pkyZgiZNmsDf3x+TJk3CO++8I9dbyJchubt0SeRujo757KTRABs3Av36Adu3Az16AL/9BnToYNFYiYiIrI0kiX50ly4BPj6iOebgwYAVNdIhIrJKsjdomDhxIiZOnJjvczH5NFcMDQ3F/v37yziqkvHxAapUESN6nT8PNGtWwI4ODsCmTUDfvsDvv5sSvPbtLRkuERGRVfn4Y+CPP8T2tm1AixbyxkNEVF7I2iyzolIoCtHvzsDBAdi8GejaFUhLE001//qrrEMkIiKySps2AbNni+1Fi5jYEREVBZO7MlKofncGhgQvLMyU4O3ZU5bhERGRBS1evBiBgYFwcHBASEgIDh48WOC+Wq0W77//PmrVqgUHBwcEBwdj+/btFoxWPqdPA8OGATk54jfP8ePljoiIqHxhcldGDMndmTOFPMDREdiyxTzB+/vvMouPiIgsY926dQgPD8esWbNw9OhRBAcHo1u3brh161a++0+fPh3Lli3DV199hbNnz2Ls2LHo168fjh07ZuHILev+faBTJ9FXPTgY+PVXzl1HRFRUTO7KSJHu3BkYErwuXcSkPt27A3v3lkl8RERkGQsWLMCYMWMwatQoNGjQAEuXLoWTkxNWrFiR7/4//vgj3n33XfTo0QM1a9bEuHHj0KNHD8yfP9/CkVvW//4n+qo/9RQQHY3854klIqLHkn1AlYrK0Ofu2jUgJQVwcSnkgYYEr3dvcXXr3l0MtlLA3H9ERGS9srOzceTIEbNpfZRKJbp06YJ9+/ble0xWVhYcHBzMyhwdHbHnMc31s7KykJWVZXycnJwMQDTx1Gq1xYrdcFxxjy+K5GTg9ddFNjd+vA6urnpY4GULzZJ1Ye1YFyasCxPWhUlJ66KkdcjkroxUrgz4+QHx8cDRo0DHjkU42MkJ2LoV6NUL2LlT3Mn7+GMxLrRKVWYxExFR6bpz5w50Op1xih8DHx8fnD9/Pt9junXrhgULFqBDhw6oVasWoqOjsXHjRuh0ugJfJyIiAnPmzMlTvmPHDjg5OZXoPURFRZXo+MJYvDgYQCA0mhx4eu5AZKR1fkG0RF2UF6wLE9aFCevCpLh1kZ6eXqLXZXJXhkJCxDgpJ08WMbkDRIL3f/8HvPCCuHM3eTKwdq2YwbVBgzKIloiIrMEXX3yBMWPGoF69elAoFKhVqxZGjRpVYDNOAJg2bRrCw8ONj5OTkxEQEICuXbvC1dW1WHFotVpERUUhLCwM6jJsI7lmjQJRUeLryNdfAwMHhpXZaxWXpeqiPGBdmLAuTFgXJiWtC0PLi+JicleG6tYV67Nni3kCJycgMhJYvhx46y1g/36gaVPgvfeAadM4mysRkZXz9PSESqVCYmKiWXliYiJ8fX3zPcbLywubN29GZmYm7t69i6pVq2Lq1KmoWbNmga+j0Wig0WjylKvV6hJ/0SqNcxTk/Hlg9GixPX48MHq0dX8tKcu6KG9YFyasCxPWhUlx66Kk9ccBVcpQ8+ZifehQCU6iVAKvvSYyxF69AK1WTADUogVw4EBphElEVPb0euDmTVSKj5c7Eouyt7dHixYtEB0dbSzT6/WIjo5G6BP6Ujs4OMDf3x85OTn45Zdf0KdPn7IO16JycoAxY8RHw9sbmDtX7oiIiMo/6/6JrJwzJHdnzoiLmF1JartaNTHQys8/A//9rxiGMzRUNNf84AOgUqXSCJmIqPhSU4ErV8Ry+bL5cuUK1JmZCG7UCHj5Zbkjtajw8HCMGDECLVu2RKtWrbBw4UKkpaVh1KhRAIDhw4fD398fERERAIADBw7gxo0baNq0KW7cuIHZs2dDr9fj7bfflvNtlLr33hNTulaqBBw8WISBx4iIqEBM7spQzZriopWWBvz7L1C/fglPqFAAgwaJAVamTAF+/BH4/HPRse+bb0Q5EVFZyc4G4uJMCdyVK8DVq6ZkroB52wwkpRLKxwwKUlENGjQIt2/fxsyZM5GQkICmTZti+/btxkFWYmNjoVSaGtJkZmZi+vTpuHz5MpydndGjRw/8+OOPcHd3l+kdlL67d4GvvhLbX38N1KghbzxERBUFk7sypFQCjRuLrnLHjpVCcmdQpQrwww/A0KGiyeaVK2Ly81GjgPnzAQ+PUnohIrIpOh1w44Z50pZ7+8YN0YbucTw8xC9bjy5BQcjx88OeqCj0sMR7sTITJ07ExIkT830uJibG7HHHjh1xttidtcuHL74Qk5U/9RTwn//IHQ0RUcXB5K6MtW4tkru//xa5WKnq3l00z3zvPWDRImDlSjEAy6JFQP/+4k4fEZGBJAGJiXmTNsN2bCyeOLmYoyMQGCiWoCCxBAYaE7jH/rjE+Y8I4veBNWvE9ptvih9CiYiodDC5K2Pt2gELF4p+BWXCxQX48ktg8GDRj+X8eeDFF4E+fYDp04GWLcvohYnI6kgScP9+/s0mDduZmY8/h1oNVK9unrjl3vbx4Q9HVCIxMcClS+LyVeo/ehIR2Tgmd2WsbVuxPnUKSEoCyqzLRJs2wPHjwEcfARERYvCVLVvEqC6vviquoOytTlS+SZLorHTtmlhiY8U6dzKXkvL4cyiVYoCmR5M2w3bVqoBKZYl3QzbKMNf6f/7DscCIiEobk7sy5usL1K4NXLwI7NsHPPdcGb6YRgO8/764czd3LrBhA3D0KDB2rGj7YuijZxjGk4isi1Yr+rUZkrbcCVxsrFjS0598Hl/f/O+6BQUBAQGcI5Nk888/wO7dYnvKFHljISKqiJjcWUD79iK5++uvMk7uDBo3BlavFj3Wv/9ejKT5zz9i/c03oqnma6+JppzOzhYIiIgAiKkC8kvaDGU3bz55wBIA8PMTTSdr1DBvQhkUJMocHcv+vRAVw8PZHtC5s/jhk4iISheTOwto106MdVJm/e4K4ukJvPEGEB4uOjksWwZs3AgcPiyW8HDRLua114DgYAsHR1TBGAYreSRpU125go5nzsBu1CjRH+5J7O3NE7fc6xo1RJNKjabs3w9RKUtLA9avF9uzZ7PrJhFRWWByZwHt2on1wYNAVpYM38sUCuCZZ8Ry+zawapW4g3fxIrBkiVhCQkSSN3AgO0EQPUqSRKfZ69fFcuOGWMfFme66xcWJ/+CPUAJwz13g4ZF/4mZYe3tz+ECqkH78USR4QUGm/uhERFS6mNxZQJ06gJeXyKuOHBFjn8jGywt46y1xR2/XLnE3b9Mm4MABsUyZYrqb17ixjIESWYheL/5z5k7aci+GssL0dVMqxYAkhrts1atDV60aDiYkoGX//lDXqsWBjchm/fijWI8dy7t2RERlhcmdBSgU4u7dpk2i352syZ2BUik6PXTuLJqSrVwJLF8OXL4MLF4sltBQoG9fsW7Zkv14qPzJyQHi4/NP3AyPb9wo/Pxrnp6iWaS/v1hXq2aWyMHfX0wlkIteq8WtyEigYcM8zxHZij//BPbuFdvDhskbCxFRRcbkzkLatxfJ3Z49wDvvyB3NI3x8gKlTgbffBqKjxd28LVvE8J779ol97OyAZs1EomdYqleXN26ybZmZIjF73N22hITCDVCiUIhBSh5N3AyLv79YHBzK/n0RVUBz54r1f/4j/isREVHZYHJnIYZ+d3//Lb5rWmWXGqUSCAsTS3w8sHatuNW4b5/4knzokFi+/FLs7+cHVevWqOXmBoWHB9CqFb/8UsnodKKJZEKCaUlMzP9xYQYnAcTdMkNyll/SVq2amDqAd9WIysThw8Dvv4vt2bNlDYWIqMJjcmchTZsCTk7i++i5c6KFllXz8xP976ZMEYNJXLtmupO3d6+YMD0+HspNm9AIEIO02NuLu3tt2pju7lWrJu/7IPlJEnDv3uMTNcNy+7bYv7AcHfMmbI/effPystJfU4gqPkkCxo0T68GDgVq15I6IiKhiY3JnIWo10Lo1sHOnuBlm9cldbgqFmAA5MBAYMkSUpacDhw9Dt2cPbm3ZAt8rV6C4fds0MMvnn4v9qlUTSZ4h4WvWjBMoVwSSJOZsKyBRU8XHo+OFC7CbOFGUF7ZPGyASMW9v0VzY19d8ebTM3Z0jMxBZsT17xJ07jUZMvUpERGWLyZ0FtW9vSu7GjpU7mhJycgI6dIA+NBQHGzZEj+eegzouznR3b98+4MQJ0e9p/XrT5EYaDdCokbiz4ucnRhY0rA3bXl6ASiXv+7MVej2QnCzurBVmuX/ftJ2dXeBp8wz/DwCVK+efoD1a5unJf3+iCkCnAzp0ENsvvSR+syEiorLF5M6COnUC5swBoqKsuN9dcSkUor1NrVqixzwg7uwcOmSe8N29K+aDOHKk4HOpVOLLfu7E79EEsGpVJoG5abXmiVfu7cctSUmFG3CkIM7O+SZoOV5eOBwXh5Y9e8KuWjXxrY4TbxPZlK1bTdsffCBfHEREtoTJnQW1bQu4uYluRYcOiXnDKzRnZ9Pk6YBoynfxouh0GB8P3LyZd52YKH7uvXlTLI9jSALzSwCrVBFtYR9d7OwKV6ZWi/OXpMmfJImkKyMj75KZWbTygp4z3HVLSSl+nIC4E1u58uMXDw/zx1WqFDjhvaTVIjEyElLLlhyohMhGRUWJteF3HyIiKntM7ixIrQa6dhUtFLdts4Hk7lEKhZjRvU6dgvfJyQFu3co/8cu9feuWeRL4uDuBJVHYZFCvh116Orrevy/+UxmSsZLcFSsOd/f8E7HHJWweHhzllOgRgYGBGD16NEaOHInqnPalyCTJNELmsmXyxkJEZEuY3FlYz54iufv1V+D99+WOxgrZ2Znuvj2OIQnML/GLjxd3s7RasZ9Wm//y6HMFvU5OjkjWnkAB4LHTvDs6mhYHB/PHxX3O1dWUqLm7s5kqUSmZPHkyVq1ahffffx/PPPMMXn75ZfTr1w8aNi8ulL17gcuXxc39zp3ljoaIyHYwubOw554TN7COHROzC9SoIXdE5VTuJLBFi5KfT5LEncDHJYSPK1cokKNW4++jR9Gmc2eoXV3NkzGNhqM6EpUjkydPxuTJk3H06FGsWrUK//3vfzF+/HgMHToUo0ePRvPmzeUO0aqtXi3WL74oWugTEZFlMLmzMG9vMWrm7t3Axo1iGjmyAgqFSBjtiv9fQtJqkZScLOa5YD8zogqhefPmaN68OebPn4+vv/4a77zzDpYsWYLGjRvj9ddfx6hRo6DgDzd57Nwp1n37yhoGEZHNqUjjNZYb/fuL9S+/yBsHERE9nlarxc8//4zevXvjjTfeQMuWLfHtt9+if//+ePfddzFs2DC5Q7Q6sbHAhQtiRGjDVAhERGQZvHMngxdeACZNEn0S4uPFII9EVDHodDpoc/Xh1Gq1sLOzQ2ZmJnQ6nYyRya8wdaFWq6Gygr6jR48excqVK/HTTz9BqVRi+PDh+Pzzz1GvXj3jPv369cPTTz8tY5TW6ddfxbpdOzFeExERWQ6TOxlUqwa0bg3s3w9s2gSMHy93RERUUpIkISEhAUlJSXnKfX19ERcXZ/PN9wpbF+7u7vD19ZW1vp5++mmEhYVhyZIl6Nu3L9T5NLUOCgrC4MGDZYjOup0+LdZt28obBxGRLWJyJ5P+/UVyt349kzuiisCQ2Hl7e8PJycmYmOj1eqSmpsLZ2RlKpW23hH9SXUiShPT0dNy6dQsA4Cdjs4bLly+jxhNGvKpUqRJWrlxpoYjKjwsXxLpuXXnjICKyRUzuZDJwIPD220BMDEfNJCrvdDqdMbGrUqWK2XN6vR7Z2dlwcHBgcleIunB0FBOK3Lp1C97e3rI10bx16xYSEhIQ8siEpAcOHIBKpULLli1lias8YHJHRBVKYUZUz/WcIiMD6tRU2cJlcieT6tWBZ54RI4r98AMwY4bcERFRcRn62Dk5OckcScVgqEetVitbcjdhwgS8/fbbeZK7Gzdu4JNPPsGBAwdkicvaxcUBN26IAYhzdU8kIjInSUBWFpCeLpa0NPP1o9tZWabEKvc6v7LCPFfU44vADoCHjF/smdzJaORIkdx9/z0wfTqnQSMq72y9T11psYZ6PHv2bL5z2TVr1gxnz54t8vkWL16MTz/9FAkJCQgODsZXX32FVq1aFbj/woULsWTJEsTGxsLT0xMDBgxAREQEHBwcivzalrRtm1g3awa4u8saChEVhyQB2dnmiyHBekwSpkxJQYPTp6Hcvh3IzMy7X35Jm14v97stGTs7MfXVI4ukVkMv45RYTO5k9MILor/dpUvA33+LkcWIiEh+Go0GiYmJqFmzpll5fHw87Io4H+a6desQHh6OpUuXIiQkBAsXLkS3bt1w4cIFeHt759l/zZo1mDp1KlasWIE2bdrgn3/+wciRI6FQKLBgwYISva+yZmiS2bGjvHEQycrQjC93E75H7wwVpezRZCv3kpX1+OeLuuQa7bkoVADqFLe+1GqgUiXAyUkshu3cZRqN2M8wJ7FhuzTKCrt/7mTOzq7AuzI5Wi3uREYWtzZKjMmdjCpVAl58EVi5Eli1iskdEZV/gYGBmDx5MiZPnix3KCXStWtXTJs2DVu2bIGbmxsAICkpCe+++y7CwsKKdK4FCxZgzJgxGDVqFABg6dKl2LZtG1asWIGpU6fm2X/v3r1o27Ythg4dCkDU6ZAhQ8pFU9C9e8W6QQN54yAbpdcDGRmmJT398evC7JOdXWASZqfVoltaGuyUyrwJWkWhVJoSrIISr0qVoHNwwOXERNRs2BAqF5cC98tT5uQkkiUqNUzuZDZypEju1q0DPv8ccHGROyIisgVPavo4a9YszJ49u8jnPXToECpVqlTMqKzHZ599hg4dOqBGjRpo1qwZAOD48ePw8fHBjz/+WOjzZGdn48iRI5g2bZqxTKlUokuXLti3b1++x7Rp0wb/+9//cPDgQbRq1QqXL19GZGQkXnrppQJfJysrC1lZWcbHycnJAES/RW0xf4k3HFfY42/cAA4eVEOplNCtW05xbwBYpaLWRUVW6nWRkQHcuwfcuwfF/fvA3bvA/ftQPCxDUhIUhkQrM9OYdCnS080eIz0dilz/ByxBAaAoDaWlgu4a5b4z9LBMMpTZ24tFrTZtP1ykxzxn9nwBi/SYY41LIfs9a7VanI2Kgn9YWL5Txzzh4KLtb+VK+n+kpP+3rCK5K2pfBIO1a9diyJAh6NOnDzZv3lz2gZaB9u3FiGIXLgA//shpEYjIMuLj443b69atw8yZM3HB0KYOgLOzs3FbkiTodLpCNUf08vIq3UBl4u/vj5MnT2L16tU4ceIEHB0dMWrUKAwZMqRIX1zu3LkDnU4HHx8fs3IfHx+cP38+32OGDh2KO3fuoF27dpAkCTk5ORg7dizefffdAl8nIiICc+bMyVO+Y8eOEg/0ExUVVaj9du/2B9ASgYEPcPTonyV6TWtV2LqwBWZ1IUlQZWVBnZIC+9RU2Kemiu2Hjw3l6tRUUZaSIrZTU6HKzi6T+HRqNXT29tDb2yNHo4He3h46jQa6gta5tvX29mLb3h56tRqSSgW9SmVa29nlW6ZXKs2fy12mVFrH4AqG5pdlhP9HTIpbF+np6SV6XdmTu6L2RTC4evUq3nzzTbRv396C0ZY+hQKYMAF4/XVg0SJg3Djr+L9PRBWbr6+vcdvNzQ0KhcJYFhMTg2eeeQaRkZGYPn06Tp06hR07diAgIADh4eHYv38/0tLSUL9+fURERKBLly7Gcz3aLFOhUGD58uXYtm0bfv/9d/j5+WH+/Pno27evJd9usVSqVAmvvvqqxV83JiYGH3/8Mb7++muEhITg4sWLmDRpEj744APMKGAEtmnTpiE8PNz4ODk5GQEBAejatStcXV2LFYdWq0VUVBTCCvlL/KxZ4itFjx4u6NGjR7Fe01oVtS7KPZ0OuH0bSEiAIiFBrBMTgXv3IN25g9sXLsBbrYby3j3g/n1x160ECYNkZwdUrgx4eECqXFlsV64stt3cRDM+R0dITk6Ag4NoyufoCDg5QXJwMG4b1w4OgEoFBURfsLIac9fmPhePwbowKWldGFpeFJfsyV1R+yIAYk6pYcOGYc6cOfjrr7+QlJRkwYhL3/DhwLRpwLlzYt67Z56ROyIiKilJMg0GlpYmWrZYYpo7J6fS+4Fo6tSp+Oyzz1CzZk14eHggLi4OPXr0wEcffQSNRoMffvgBvXr1woULF1C9evUCzzNnzhzMmzcPn3zyCRYsWICXXnoJ165dQ+XKlUsn0DJ09uxZxMbGIvuRL669e/cu1PGenp5QqVRITEw0K09MTDRLsHObMWMGXnrpJbzyyisAgMaNGyMtLQ2vvvoq3nvvvXznCNRoNNBoNHnK1Wp1ib9oFeYcOh1w9arYfuYZFdRqeaawKGulUZ+yyswEEhKA+HjT2rDkfnzrlvhHLYBfQU+o1UCVKsbkDJUr532cT7nC2dn4h6s8/r5d7j8XpYh1YVLcuihp/cma3BWnLwIAvP/++/D29sbLL7+Mv/7667GvYQ39EJ7EyQkYNkyJb75R4csv9WjXruA/qNaG/RBMWBcmtlYXWq0WkiRBr9dD/3Bo57Q0wNVVCUAJwN1isSQn61HULm+GmB9dz549G507dzbu5+7ujsaNGxsfz5kzB5s2bcKWLVswYcIEY7mhLgxGjBiBQYMGQZIkzJgxA8uWLcP+/fvRvXv3AuORJCnPPHeW/DxdvnwZ/fr1w6lTp6BQKCBJEgBTX0XdY7745mZvb48WLVogOjraeLdSr9cjOjoaEydOzPeY9PT0PAmcoR4McVibS5eABw/EjZNC5r1UWiQJSE4uOFHLXXb/fuHPq1AA3t6An59YfH0BT0/o3Nxw6sYNNOrQAXbe3uaJWmn+ukRExVKs5C4uLg4KhQLVqlUDABw8eBBr1qxBgwYNitSEpTh9Efbs2YPvvvsOx48fL9RrWEM/hMJo2NAFwLPYuhX4/vud8PLKLLVzWwLbWJuwLkxspS7s7Ozg6+uL1NRU4x2etDTAkkmdQXJy8uN+cM9XZmYmJEky/vhlaO9ft25ds+Yhqamp+OSTT7Bjxw4kJCRAp9MhIyMD//77r3E/vV6PzMxMs+Nq165tfFypUiW4uLggNja2wKYn2dnZyMjIwO7du5GTa9S5kvZDKIpJkyYhKCgI0dHRCAoKwsGDB3H37l288cYb+Oyzz4p0rvDwcIwYMQItW7ZEq1atsHDhQqSlpRlbrAwfPhz+/v6IiIgAAPTq1QsLFixAs2bNjM0yZ8yYgV69esk2qfuT/PuvWNeuLcaAoBLQ6UQSdvcucOeOacn9+O5dY7NJJCSIAUUKS6MRiZohacudvOV+7OWV7z+mXqvFtchINOzRg6McElmhYv0JHjp0KF599VW89NJLSEhIQFhYGBo2bIjVq1cjISEBM2fOLO04AQApKSl46aWXsHz5cnh6ehbqGGvoh1BYGzfq8eefSpw82QXz55ePiR3ZxtqEdWFia3WRmZmJuLg4ODs7GyeZdnERd9EkSUJKSgpcXFwsMjm3k5NrkX84d3BwgEKhMP5NNPzw5evra/Z38p133sEff/yBefPmoXbt2nB0dMTAgQPNjlUqlXBwcDA7ztXVFa6ursa6UCqVsLe3L/BvcGZmJhwdHdGhQwezSbtL2g+hKPbt24edO3fC09MTSqUSSqUS7dq1Q0REBF5//XUcO3as0OcaNGgQbt++jZkzZyIhIQFNmzbF9u3bjT9sxsbGmt2pmz59OhQKBaZPn44bN27Ay8sLvXr1wkcffVTq77O0GBrbBAfLG4fVyS9Re1LSdu+euBtXVG5u+Sdpj5a5u/PuGlEFVqzk7vTp08bRLH/++Wc0atQIf//9N3bs2IGxY8cWOrkral+ES5cu4erVq+jVq5exzND0x87ODhcuXECtWrXMjpG7H0JRvPsu8OefwPLlKrz7rgoFdMewSmxjbcK6MLGVutDpdFAoFMYkwMDFBQ+bagLOzop8+0pZA0Nc+a1zx7x3716MHDkS/fv3ByDu5F29ehWdOnUy289QF7nPr1QqzZpqPnruR+NRKBR5Pj+W/CzpdDq4PJybxtPTEzdv3kTdunVRo0YNs1FFC2vixIkFNsOMiYkxe2xnZ4dZs2Zh1qxZRX4duZw8KdaFGOi64rp9G9i1C9i5E/j7b9EUsriJGiCSNU9P01KlSt7Hvr6mpYStkYioYihWcqfVao0J0x9//GHsWF6vXj2z4bWfpKh9EerVq4dTp06ZlU2fPh0pKSn44osvEBAQUJy3YzXCwoCQEODAAWD+fODTT+WOiIjIpE6dOti4cSN69eoFhUKBGTNmmCVsFUmjRo1w4sQJBAUFISQkBPPmzYO9vT2++eYb1KxZU+7wrI7h0tykibxxWFRKCrB7NxAdLRK6EycK3jd3opY7ScsvYfP0FP3XbOCHMSIqfcVK7ho2bIilS5eiZ8+eiIqKwgcffAAAuHnzJqpUqVKkcxWlL4KDgwMaNWpkdry7uzsA5CkvjxQKYOZMoGdP4OuvgbffFk3eiYiswYIFCzB69Gi0adMGnp6eeOeddyzaVNKSpk+fjjTRcRLvv/8+nn/+ebRv3x5VqlTBunXrZI7Oujx4YBopM9d4OxWOMjsbipgYU0J38GDeESUbNQI6dxbDXteuzUSNiCyuWMndJ598gn79+uHTTz/FiBEjEPywkf3WrVsLNfl4bkXti1DRPfcc0LIlcPgwsGAB8LB/PRFRmRk5ciRGjhxpfNypU6d8R2UMDAzEzp07zcpyj5IJiDlIc8vvPPfu3bP6v+vdunUzbteuXRvnz5/HvXv34OHhYZG+k+XJ6dNiXa2ayGMqDJ0OOHIEiI6GKjoaPf76K++E2zVrAs8+a0roHhkgjojI0oqV3HXq1Al37txBcnIyPDw8jOWvvvpqsUagLEpfhEetWrWqyK9nzQx373r3FpOav/mmaKVBRESWodVq4ejoiOPHj5u1CikP8/LJwdAks9zftZMk4OxZcVcuOlp0gn/wAICY0AQAJB8fKDp3NiV0gYGyhUtElJ9iJXcZGRmQJMmY2F27dg2bNm1C/fr1zX7tpOJ5/nmgaVPg+HFg4ULgYatXIiKyALVajerVqxd6LjtbZxhMpVz2t7t1C/i//zP1m3tkgDe4uQGdOkHXqRP+VKnQ/rXXoLa3lydWIqJCKFa7mD59+uCHH34AACQlJSEkJATz589H3759sWTJklIN0BYZ7t4BwBdfiAG4iIjIct577z28++67uHfvntyhWL0jR8S6XCV39++LIaqDgoBXXgF++kkkdo6OYnSziAjRp+7OHWDzZugnTEBK9eqcQoCIrF6x7twdPXoUn3/+OQBgw4YN8PHxwbFjx/DLL79g5syZGDduXKkGaYv69AGaNweOHhWJHnNmIiLLWbRoES5evIiqVauiRo0aqFSpktnzR48elSky66LTiesUADRrJm8shZKaKn41/fRTY5NLNG0K9OolmlqGhopJvomIyqliJXfp6enG+X927NiBF154AUqlEq1bt8a1a9dKNUBbpVQCn38OdOwIfPMNMH58BejPQERUThim56HHS0wEcnIAlQp46im5o3mMzExg6VLg449NzWEaNQI++kgkdrwjR0QVRLGSu9q1a2Pz5s3o168ffv/9d0yZMgUAcOvWLbi6upZqgLasQwdgwABgwwZgyhQgKorXHyIiSyhPE4jL6cYNsfb1FQme1dFqgVWrgPffB65fF2W1a4vHgwaJX1KJiCqQYv1VmzlzJt58800EBgaiVatWCA0NBSDu4jUrF+0yyo958wB7e9HX+9df5Y6GiIjI5Px5sba6ed31emDNGqB+feDVV0ViV60asHy5GBFzyBAmdkRUIRXrL9uAAQMQGxuLw4cP4/fffzeWd+7c2dgXj0pHUJC4awcAb7wBPDrFDhERlT6lUgmVSlXgQsLx42LdtKmcUeQiScCWLUBwMDBsGHDpEuDlJYae/vdfMXgKJxQnogqsWM0yAcDX1xe+vr64/rCZQ7Vq1Yo8gTkVzrvvAitXiuvSokVAeLjcERERVWybNm0ye6zVanHs2DF8//33mDNnjkxRWZ9jx8Ra9kY7kgT88QcwfboY5RIQ0xi8/Tbw+uuAs7O88RERWUixkju9Xo8PP/wQ8+fPR2pqKgDAxcUFb7zxBt577z0o2dShVLm6ij7fY8aIkTMHDACqV5c7KiKiiqtPnz55ygYMGICGDRti3bp1ePnll2WIyrpIkpXcudu7F3jvPSAmRjx2cgImTwbefBN4OB8vEZGtKFYW9t5772HRokWYO3cujh07hmPHjuHjjz/GV199hRkzZpR2jARg9GigbVsgLQ2YMEFcVImIikuhUDx2mT17donOvXnz5lKL1Zq0bt0a0dHRcodhFe7dE9PFAaJrm8UdPw48/7y4OMbEiA7qkyYBly+LX0SZ2BGRDSrWnbvvv/8e3377LXr37m0sa9KkCfz9/TF+/Hh89NFHpRYgCUqlmBKhaVMxsMr69cDAgXJHRUTlVXx8vHF73bp1mDlzJi5cuGAsc2YztjwyMjLw5Zdfwt/fX+5QrEJsrFj7+AAODhZ84Zwc4MMPgQ8+EAOnqFTAqFHAjBls1kJENq9Yd+7u3buHevXq5SmvV68e7t27V+KgKH8NGoj+d4DoQsCqJqLiMvSb9vX1hZubGxQKhVnZ2rVrUb9+fTg4OKBevXr4+uuvjcdmZ2dj4sSJ8PPzg4ODA2rUqIGIiAgAQGBgIACgX79+UCgUxsfljYeHBypXrmxcPDw84OLighUrVuDTTz+VOzyrEBcn1hbNp2JjxWTjc+aIxO7FF4Fz58QomEzsiIiKd+cuODgYixYtwpdffmlWvmjRIjRp0qRUAqP8TZsGrFsnhp+eOFGM9ExEVkiSgPR08QU0LU3cXbBEf2QnpxJPiLl69WrMnDkTixYtQrNmzXDs2DGMGTMGlSpVwogRI/Dll19i69at+Pnnn1G9enXExcUh7uE3/UOHDsHb2xsrV65E9+7dy+3Ikp9//jkUuepRqVTCy8sLISEh8GBzPwCmO3cBARZ6wY0bxWiX9+8DLi5iUvKhQy304kRE5UOxkrt58+ahZ8+e+OOPP4xz3O3btw9xcXGIjIws1QDJnEYDfP890KYN8NNPQJ8+Yh5WIrIy6emAszOUANwt+bqpqUClSiU6xaxZszB//ny88MILAICgoCCcPXsWy5Ytw4gRIxAbG4s6deqgXbt2UCgUqFGjhvFYLy8vAIC7uzt8fX1LFIecRo4cKXcIVs+Q3JX5DbOMDDFM9NKl4vHTT4sLYK1aZfzCRETlT7F+Ru7YsSP++ecf9OvXD0lJSUhKSsILL7yAM2fO4McffyztGOkRrVqZmmeOGwfcuCFvPERUcaSlpeHSpUt4+eWX4ezsbFw+/PBDXLp0CYBIfI4fP466devi9ddfx44dO2SOuvStXLkS69evz1O+fv16fP/99zJEZH0MzTLL9M7d6dMimTMkdu+8A+zZw8SOiKgAxZ7nrmrVqnkGTjlx4gS+++47fPPNNyUOjB5vxgwgMhI4cgQYMgSIjua8rERWxckJSE2FXq9HcnIyXF1dLTNNjJNTiQ43TG+zfPlyhISEmD1naGLZvHlzXLlyBb/99hv++OMPDBw4EF26dMGGDRtK9NrWJCIiAsuWLctT7u3tjVdffRUjRoyQISrrcv68WNesWQYnlyRg2TJgyhQgM1OM2vLjj0BYWBm8GBFRxVHs5I7kpVaL/nYtWwJ//QXMmgV8/LHcURGRkUIhmkfq9YBOJ7bLwRygPj4+qFq1Ki5fvoxhw4YVuJ+rqysGDRqEQYMGYcCAAejevTvu3buHypUrQ61WQ6fTWTDq0hcbG4ugoKA85TVq1ECsoT2ijbtyRayfeqqUT3zvnpjYdeNG8bh7d9Efwdu7lF+IiKjiYXJXjj31FPDdd2JKhIgI0Q/v+efljoqIyrs5c+bg9ddfh5ubG7p3746srCwcPnwY9+/fR3h4OBYsWAA/Pz80a9YMSqUS69evh6+vL9zd3QGIETOjo6PRtm1baDSacjkAibe3N06ePJlntM8TJ06gSpUq8gRlRdLTgQcPxHa1aqV44r/+AoYNE20+1Wpg7lwxIXk5+GGEiMga8K9lOffii8D48WJ76FDg7Fl54yGi8u+VV17Bt99+i5UrV6Jx48bo2LEjVq1aZbyT5eLignnz5qFly5Z4+umncfXqVURGRhqbnc6fPx9RUVEICAhAs2bN5HwrxTZkyBC8/vrr2LVrF3Q6HXQ6HXbu3IlJkyZh8ODBcocnu8REsXZwEANXllhOjpjeoFMnkdjVrg3s2ycGUmFiR0RUaEW6c2cYOa0gSUlJJYmFiunzz4EzZ4A//wR69wYOHgQqV5Y7KiIqL0aOHJlndMihQ4diaAHDzI8ZMwZjxowp8Hy9evVCr169SjNEi/vggw9w9epVdO7cGXZ24lKp1+sxfPhwfMw28GYTmJdw5g3g1i1gwABx1w4Ahg8HFi0qpayRiMi2FCm5c3Nze+Lzw4cPL1FAVHT29sD69WIUzUuXRDPN7dsBOza6JSIqFnt7e6xbtw4ffvghjh8/DkdHRzRu3Nhs2gdbdvKkWDdoUMITZWUBffuKu3TOzsCSJcB//lPS8IiIbFaRvv6vXLmyrOKgEvLyArZsEf3uoqOBN94AvvhC7qiIiMq3OnXqoE6dOiU+z+LFi/Hpp58iISEBwcHB+Oqrr9CqVat89+3UqRP+/PPPPOU9evTAtm3bShxLaTBMg1CiwVQkCRg7ViR2bm7A3r2lkC0SEdk2NmSvQJo0AX74QWx/+aUYbIWIiIquf//++OSTT/KUz5s3Dy+++GKRzrVu3TqEh4dj1qxZOHr0KIKDg9GtWzfcunUr3/03btyI+Ph443L69GmoVKoiv25ZKpU57hYuBFatEn3qfv6ZiR0RUSlgclfBvPCC6JMOiB9Ef/9d3niIiMqj3bt3o0ePHnnKn3vuOezevbtI51qwYAHGjBmDUaNGoUGDBli6dCmcnJywYsWKfPevXLkyfH19jUtUVBScnJwqVnL3++/Am2+K7fnzga5dSyUuIiJbx+SuApo+XUxsnpMD9O8vBlghIqLCS01Nhb29fZ5ytVqN5OTkQp8nOzsbR44cQZcuXYxlSqUSXbp0wb59+wp1ju+++w6DBw9GpUqVCv26Za1Eyd2FC8CgQWIOyNGjgUmTSjU2IiJbxiE3KiClUrR0uXMHiIoCnnsO2L0baNhQ7siIKja9Xi93CBWCNdRj48aNsW7dOsycOdOsfO3atWhQhOaDd+7cgU6ng4+Pj1m5j48Pzp8//8TjDx48iNOnT+O7J7Szz8rKQlZWlvGxIQHVarXQarWFjjc3w3GPHq/TATdu2AFQwNdXiyKd/v592PXqBcWDB9CHhkL3xRfil0grV1Bd2CLWhQnrwoR1YVLSuihpHTK5q6Ds7YGNG4HOncWdu2eeAf74Q/TLI6LSZW9vD6VSiZs3b8LLywv29vZQPBwfXq/XIzs7G5mZmcZ54GzVk+pCkiRkZ2fj9u3bUCqV+d45s5QZM2bghRdewKVLl/Dss88CAKKjo7FmzRps2LDBYnF89913aNy4cYGDrxhERERgjqFNfi47duyAk5NTiWKIiooye3znjgN0um5QKvU4dizSOHLmkyh0OrT+4AN4//sv0j09sfu115AVHV2i2Czt0bqwZawLE9aFCevCpLh1kZ6eXqLXZXJXgTk7A7/9BoSFAUePAs8+K+7kldM5hYmsllKpRFBQEOLj43Hz5k2z5yRJQkZGBhwdHY0Jn60qbF04OTmhevXqsibDvXr1wubNm/Hxxx9jw4YNcHR0RHBwMHbu3InKRZhI1NPTEyqVComGWb8fSkxMhK+v72OPTUtLw9q1a/H+++8/8XWmTZuG8PBw4+Pk5GQEBASga9eucHV1LXS8uWm1WkRFRSEsLAxqtdpYvn+/+Lfz91egV6+8/RILonzrLaiOH4fk5AR1ZCQ6N21arLjkUFBd2CLWhQnrwoR1YVLSuihK0//8MLmr4CpXFnfsunUDDh0yJXgtW8odGVHFYm9vj+rVqyMnJwc6nc5YrtVqsXv3bnTo0IEXvELUhUqlgp2dnVUkwj179kTPnj0BiIvtTz/9hDfffBNHjhwx+zd+HHt7e7Ro0QLR0dHo27cvAHEHMzo6GhMnTnzssevXr0dWVhb+U4h53zQaDTQaTZ5ytVpd4s/do+eIjxfrgABF4c+9YoVxfh7FDz9A/fTTJYpJLqVRnxUF68KEdWHCujApbl2UtP6Y3NkADw9T37t9+0RTzd9/B1q3ljsyoopFoVDk+WOuUqmQk5MDBwcHm7/glce62L17N7777jv88ssvqFq1Kl544QUsXry4SOcIDw/HiBEj0LJlS7Rq1QoLFy5EWloaRo0aBQAYPnw4/P39ERERYXbcd999h759+6JKlSql9n5Kg2EwlerVC3nA33+L4ZsBYNYsMdIXERGVCSZ3NsLNTSR0PXsCf/0lRp2OjATatZM7MiIi65KQkIBVq1bhu+++Q3JyMgYOHIisrCxs3ry5SIOpGAwaNAi3b9/GzJkzkZCQgKZNm2L79u3GQVZiY2PzNEG9cOEC9uzZgx07dpTKeypNRRopMzZWzNGj1Yqk7pEBaoiIqHQxubMhLi6iD16vXsCuXUD37sC2bUDHjnJHRkRkHXr16oXdu3ejZ8+eWLhwIbp37w6VSoWlS5eW6LwTJ04ssBlmTExMnrK6detCkqQSvWZZKXRyp9cDAwYAt24BTZsC338vhnMmIqIyw7+yNqZSJeDXX8UgK2lpoqnmH3/IHRURkXX47bff8PLLL2POnDno2bMnVCqV3CFZnUInd7/+Kjp7u7gAW7aICxAREZUpJnc2yMkJ2LoV6NEDyMgQ6+XL5Y6KiEh+e/bsQUpKClq0aIGQkBAsWrQId+7ckTssq1Ko5E6SgI8/FtsTJhShgx4REZUEkzsb5eAg5sEbOFB0hXj1VXH95dyTRGTLWrdujeXLlyM+Ph6vvfYa1q5di6pVq0Kv1yMqKgopKSlyhyir7GzAMKvDY5O7mBjgwAFxsZk82QKRERERwOTOpmk0wNq1wIcfAgoF8PXXQJcuwO3bckdGRCSvSpUqYfTo0dizZw9OnTqFN954A3PnzoW3tzd69+4td3iyiY8XN+XUasDL6zE7Gu7ajR4NPBw4hoiIyh6TOxunUADvvSe6Q7i4ALt3iznwjh+XOzIiIutQt25dzJs3D9evX8dPP/0kdziyuntXrD09xfUjX4cPi87cKhXw1lsWi42IiJjc0UO9eokWNHXqiJGr27QB1q2TOyoiIuuhUqnQt29fbN26Ve5QZGNI7h479Z5hvr6hQ4HAwLIOiYiIcmFyR0b164sEr1s3MdDK4MHAtGmATid3ZEREZA2emNydOyc6dAPA1KkWiYmIiEyY3JEZDw8x952hJc3cuWLahOvX5Y2LiIjk98Tk7pNPxLpvX6AYE74TEVHJMLmjPFQqYN48YPVqMS3Rrl1AkyamH2OJiMg2PTa5u3ZNXDgA0eyDiIgsziqSu8WLFyMwMBAODg4ICQnBwYMHC9x3+fLlaN++PTw8PODh4YEuXbo8dn8qvqFDgWPHxAAr9+8D/fuLKRNSU+WOjIiI5PDY5O6zz4CcHKBzZ6BVK4vGRUREguzJ3bp16xAeHo5Zs2bh6NGjCA4ORrdu3XDr1q1894+JicGQIUOwa9cu7Nu3DwEBAejatStu3Lhh4chtQ506wN9/A++8I0ZGW74caNYM2L9f7siIiMjS7t8X68qVH3kiMRH49luxzbt2RESykT25W7BgAcaMGYNRo0ahQYMGWLp0KZycnLBixYp891+9ejXGjx+Ppk2bol69evj222+h1+sRHR1t4chth7296HsXHS0mrb14EWjbFnjjDSAtTe7oiIjIUpKSxNrD45EnvvgCyMwUd+yefdbSYRER0UN2cr54dnY2jhw5gmm5fuVTKpXo0qUL9u3bV6hzpKenQ6vVonKenxGFrKwsZGVlGR8nJycDALRaLbRabbHiNhxX3OPLq3btgCNHgClTVFi9WokFC4CNG1UYOdILYWG2VRf5sdXPRX5YFyasC5OS1gXrUH6GO3fu7rkKHzwAFi8W29OmPWYCPCIiKmuyJnd37tyBTqeDj4+PWbmPjw/Onz9fqHO88847qFq1Krp06ZLv8xEREZgzZ06e8h07dsDJyanoQecSFRVVouPLqxdfBGrW9MaSJcG4etUJs2e3wZ9/xmLkyDNwc8uWOzzZ2ernIj+sCxPWhUlx6yI9Pb2UI6GiMty5M0vuVq8GkpPF6Ji9e8sQFRERGcia3JXU3LlzsXbtWsTExMDBwSHffaZNm4bw8HDj4+TkZGM/PVdX12K9rlarRVRUFMLCwqBWq4t1jvKuRw9g8mRg+nQtli61w65d1XH8eAAiInQYOVKCUvYGv5bHz4UJ68KEdWFS0rowtLwg+eSb3B04INYvvgib/ONPRGRFZE3uPD09oVKpkJiYaFaemJgIX1/fxx772WefYe7cufjjjz/QpEmTAvfTaDTQaDR5ytVqdYm/aJXGOcqzypWBL77QokaNv7BmTXucPKnA2LF2WLZMTHUUFiZ3hPKw9c9FbqwLE9aFSXHrgvUnL0kyjZZp1ufuyBGxbtHC4jEREZE5WZM7e3t7tGjRAtHR0ejbty8AGAdHmThxYoHHzZs3Dx999BF+//13tGzZ0kLRUkHq1buP/ftzsHSpGrNmiekTunYVyd0nn4jRNYmIqHxLSgIyMsR21aoPC9PTgXPnxDaTOyKboNPp8vSB1mq1sLOzQ2ZmJnQ6nUyRWYcn1YVKpYKdnR0UZdQ/WfZmmeHh4RgxYgRatmyJVq1aYeHChUhLS8OoUaMAAMOHD4e/vz8iIiIAAJ988glmzpyJNWvWIDAwEAkJCQAAZ2dnODs7y/Y+bJ2dHTBlCvDSS8CHHwJffw1ERYll6FBRFhQkd5RERFRc8fFi7e4OODo+LDxxAtDrAR8fwM9PrtCIyEJSU1Nx/fp1SJJkVi5JEnx9fREXF1dmSUt5UZi6cHJygp+fH+zt7Uv99WVP7gYNGoTbt29j5syZSEhIQNOmTbF9+3bjICuxsbFQ5mrDv2TJEmRnZ2PAgAFm55k1axZmz55tydApH56ewMKFwOuvAzNmAGvWiGX9emD8eGD6dLEPERGVLxcvinX16rkKjx4V6xYtOEomUQWn0+lw/fp1ODk5wcvLyyxx0ev1SE1NhbOzs9n3dlv0uLqQJAnZ2dm4ffs2rly5gjp16pR6fcme3AHAxIkTC2yGGRMTY/b46tWrZR8QlVjNmmIAtTfeEBOg//GHmAZp5UrxePJkoISDlRIRkQUdPy7WTZvmKjT0t2ve3MLREJGlabVaSJIELy8vOBpv3wt6vR7Z2dlwcHBgcveEunB0dIRarca1a9eM+5Um2659KnPNm4ummTt2iC8EycnAe+8BtWsDy5cDOTlyR0hERIVhuHNXv36uQg6mQmRzbL3ZZWkoywSYyR1ZRFiY+A7wv/8BgYGi78arr4ppkZYvBzIz5Y6QiIge58oVsTb2n87MBM6cEdtM7oiIrAKTO7IYpRIYNgw4fx74/HOgShXg339FkhcUBMyda5pDiYiIrIshuQsMfFhw8iSg04mO1NWqyRUWERHlwuSOLE6jEX3urlwBFiwQ3wkSEoBp00RH/bfeAm7ckDtKIiIyyM42/V02JnccTIWIbFRgYCAWLlwodxj5YnJHsnFxEdMnXL4MfP890LAhkJICfPaZuJM3apSpOwcREcmnfXvTtpfXww0OpkJEVk6hUDx2Ke5I+4cOHcKrr75ausGWEiZ3JDu1Ghg+HDh1Cvj1V6BDB0CrBVatAlq2BFq1EqNspqfLHSkRke2RJODgQdNj4zgAue/cERFZofj4eOOycOFCuLq6mpW9+eabxn0lSUJOIUf68/LygpOVDvvO5I6shkIB9OwJ/PknsG+fmPzc3h44dAgYPRrw9xfNOc+flztSIqKiWbx4MQIDA+Hg4ICQkBAczJ0t5SMpKQkTJkyAn58fNBoNnnrqKURGRlooWnO5f1jbtOnhRlaW+EUO4J07IhslSUBamjzLI3OoF8jX19e4uLm5QaFQGB+fP38eLi4u+O2339CiRQtoNBrs2bMHly5dQp8+feDj4wNnZ2c8/fTT+OOPP8zO+2izTIVCgW+//Rb9+vWDs7MzWrRoga1bt5ZibRcekzuySq1bi3ny4uLEQCtBQWKwlS++EMNwP/usmBhdq5U7UiKix1u3bh3Cw8Mxa9YsHD16FMHBwejWrRtu3bqV7/7Z2dkICwvD1atXsWHDBly4cAHLly+Hv7+/hSMXrl8Xazs7oG/fh4WnT4s/wB4euTrhEZEtSU8HnJ3F4uqqRLVq7nB1VRrLynIpzdZcU6dOxdy5c3Hu3Dk0adIEqamp6NGjB6Kjo3Hs2DF0794dvXr1Qmxs7GPPM2fOHAwcOBDHjx9HWFgYXnrpJdy7d6/0Ai0kJndk1by9xaTnFy8CkZFAr16iSdCuXcDAgWIAlnffBS5ckDtSIqL8LViwAGPGjMGoUaPQoEEDLF26FE5OTlixYkW++69YsQL37t3D5s2b0bZtWwQGBqJjx44IDg62cORCXJwYLKVu3VyFHEyFiCqI999/H2FhYahVqxYqV66M4OBgvPbaa2jUqBHq1KmDDz74ALVq1XrinbiRI0diyJAhqF27NmbMmIHU1NQnttIoC3YWf0WiYlAqgeeeE0tsrJgb79tvxSibERFiad0aGDECGDBAjMxNRCS37OxsHDlyBNOmTTOWKZVKdOnSBfv27cv3mK1btyI0NBQTJkzAli1b4OXlhaFDh+Kdd96BSqXK95isrCxkZWUZHycnJwMAtFottMVs4mA47upVHQA7VKumh1arE+/h0CGoAOiCg6G3gSYUhroobl1WJKwLE1urC61WC0mSoNfrodfr4eAAPPxTA0mSkJKSAhcXF4tMcu7gAOj1RTtG//CAR9fNmzc3bgNAamoq5syZg8jISMTHxyMnJwcZGRm4du2a2X6GujBo1KgR9Ho9JElCpUqV4OrqioSEBLN9csciSRK0Wm2ev+sl/TwxuaNyp3p14IMPgJkzgS1bxMAr27cD+/eLZeJEMWn64MGiCZGbm9wRE5GtunPnDnQ6HXx8fMzKfXx8cL6ADsSXL1/Gzp07MWzYMERGRuLixYsYP348tFotZs2ale8xERERmDNnTp7yHTt2lLjT/9atNwEEQZJiERl5AgDQISYGHgCOKhS4KVNfQDlERUXJHYLVYF2Y2Epd2NnZwdfXF6mpqcjOzs7zfKVKgF6fYpFYUorxMpmZmZAkyfjjV/rDtp16vd5YBgBTpkxBTEwMPvjgAwQFBcHR0REjRoxAamqqcT+9Xo/MzEyz43JycsweG17j0TJA/PCXkZGB3bt35xnEJb2EbU6Z3FG5pVaLu3QDBog7eKtXA2vWiNZC27eLRaMBevQQid7zzwNWOrAREZGRXq+Ht7c3vvnmG6hUKrRo0QI3btzAp59+WmByN23aNISHhxsfJycnIyAgAF27doWrq2ux4tBqtYiKikJ6enUAQPPmAejRwx/QamH3sO9J09Gj0bR27WKdvzwx1EVYWBjUarXc4ciKdWFia3WRmZmJuLg4ODs7w8HBwew5S9+5Kw4HBwcoFArj30TDD18uLi5mfycPHz6MUaNGYejQoQDEnby4uDjY29sb91MqlXBwcDA7ztHREa6ursa6UCgUefYxyMzMhKOjIzp06JCnLvNLBouCyR1VCL6+wBtviOWff4B164CffgLOnROju23aJH5R6tMHGDRI3NlzdJQ7aiKq6Dw9PaFSqZCYmGhWnpiYCF9f33yP8fPzg1qtNmuqU79+fSQkJCA7Oxv29vZ5jtFoNNBoNHnK1Wp1ib90ZmWJL2pBQSqo1Srg7FkxWqabG9T16tlUn7vSqM+KgnVhYit1odPpoFAooFQqoVSaD9thaHpoeN4aGeLKb5075jp16mDTpk3o3bs3FAoFZsyYAb1en+e9PfrYcJ7czTDzqytDuUKhyPezU9LPknXWPlEJPPUUMGMGcOYMcOIEMG2aGG0zLU3c2evTB6hSRTTZXLECKGDAOiKiErO3t0eLFi0QHR1tLNPr9YiOjkZoaGi+x7Rt2xYXL140+4Lwzz//wM/PL9/ErixJEnDggPiq0LDhw0LD5OXNmtlUYkdEtmHBggXw8PBAmzZt0KtXL3Tr1g3Ny9GUL7xzRxWWQgE0aSKWjz4Sk/D+9JO4ixcbK/rrbdki9gsNFUlf795AvXpyR05EFUl4eDhGjBiBli1bolWrVli4cCHS0tIwatQoAMDw4cPh7++PiIgIAMC4ceOwaNEiTJo0Cf/973/x77//4uOPP8brr79u8dgPHDDdXaxe/eGGIbnj5OVEVI6MHDkSI0eOND7u1KkTpHwmzAsMDMTOnTvNyiZMmGD2+OrVq2aP8zvPvXv3ZLmLyeSObIJCAYSEiOXzz4GTJ0Vit3Wr+J6yd69Y3nlH3Pnr3Rvo2hVo25b99IioZAYNGoTbt29j5syZSEhIQNOmTbF9+3bjICuxsbFmXwACAgLw+++/Y8qUKWjSpAn8/f0xadIkvPPOOxaPfe7ckFxxPdwwDO3N5I6IyOowuSObo1AAwcFimTlTTND7f/8nEr2dO0Wfvc8+E4taLe7qPfOMmDg9JEQM0kJEVBQTJ07ExIkT830uJiYmT1loaCj2799fxlE9WcOGd3DmTK65ZVJTgWPHxHbbtvIERUREBWKfO7J51aoB48YBv/0G3L4NrF8v5ssLCAC0WmD3bmDOHKBjR8DDQwzG8vHHYtqFR0avJSKqUGrUEKO2zZjxsODgQUCnE38gje00iYjIWvDOHVEurq6m6RUkCbh8WdzN27VLrBMTgT/+EAsAODsDHTqIO3sdOojvPEREFcWJE14AxGjDAIC//xZr3rUjIrJKTO6ICqBQALVqiWXMGJHsnT8vkrydO4GYGODePSAyUiyAGpUqPYfOnVXo3Fk042zYkIPJEVH5deOGCwAx+wEAYM8esW7XTp6AiIjosZjcERWSQgHUry+WCRMAvV4MzGK4q7d7t4TkZHts3Sr67wGAl5e4oxcSArRuLcYf4AAtRFQe5G52fvs2RNOEfftEAe/cERFZJSZ3RMWkVAJNm4plyhQgIyMHixbtRXZ2O+zercJff4kvRL/8IhYAUKmAxo1NI3eGhIipF6x0vk8ismH37pm2x44FcOoUkJICuLiIP2RERGR1mNwRlRI7O+Cpp5LQo4ce772nQna2GHtg714x+MqBA8DNm8Dx42JZtkwc5+oKPP20Kdlr3hzw92dzTiKS1507pu3evQEsftjfLjRU/FJFRERWh8kdURmxtxfdUnJ3Tbl+XSR5huXwYSA5GYiOFouBlxfQrJlpad5c9P3jHT4ispTYWPELk1IpAVCY+tuxSSYRkdVickdkQdWqiaV/f/E4Jwc4fdqU7B06BJw7J5pz7tghFgMXFzE3X5MmYqAWw+Lpmf9rERGVRO/e4iuCXv+wGYFhpEwOpkJEZLWY3BHJyM7O1G/vtddEWUaG6Npy7JhpOXlSdHXZs8f047mBl5cp0WvQgEkfEZVcZuYjBbGxQFycaI4ZEiJLTERERaV4Qh+XWbNmYfbs2cU+96ZNm9C3b99iHV9WmNwRWRlHR6BVK7EY5OSIaRiOHRN3+s6cEUOTX7ki7vLFxIglN29v82TPsM2kj4ie5MUXTdseHpLprl2zZrkmvSMism7x8fHG7XXr1mHmzJm4cOGCsczZ2VmOsMoUkzuicsDODmjUSCy5paWJZpxnz4qEL3fSd+uWWApK+ho0AGrXFkutWkBQkEgsiYjefRf49VexffhwDvDZX+IB+9sRkYEkAenpYluvF19KVCrLDBDg5FSoked8fX2N225ublAoFGZl3377LebPn48rV64gMDAQr7/+OsaPHw8AyM7ORnh4OH755Rfcv38fPj4+GDt2LKZNm4bAwEAAQL9+/QAANWrUwNWrV0vv/ZUAkzuicqxSJaBlS7HkVpykDxCjdBombjcshuTPw8Mib4mIrEBoKLBrVw527jyEgICWwF8Pk7sOHeQNjIisR3o68PDOlxKAuyVfOzW1xK0IVq9ejZkzZ2LRokVo1qwZjh07hjFjxqBSpUoYMWIEvvzyS2zduhU///wzqlevjri4OMTFxQEADh06BG9vb6xcuRLdu3eHyopGEGZyR1QBFSbpO3cOuHRJLBcvilE7b9wQy+7dec/p4ZE38TMkf35+HMmTqKJp21bCgwe3xIR3p0+LQg6mQkQVxKxZszB//ny88MILAICgoCCcPXsWy5Ytw4gRIxAbG4s6deqgXbt2UCgUqFGjhvFYLy8vAIC7u7vZnUBrwOSOyIYUlPRJEnD3rinZe3SJjwfu3xdTNxw+nPe8Dg5AYKAYCTQgAKhaVYmkpOpQqRQIChJlrq4WeYtEVMoUe/eKjbp1RbtuIiJANI1MTQUA6PV6JCcnw9XVFUpLNcssgbS0NFy6dAkvv/wyxowZYyzPycmBm5sbAGDkyJEICwtD3bp10b17dzz//PPo2rVriV7XEpjcEREUCjHQiqdn/gPhpaUBly/nn/hdvSpG1jt/XiyCCkAzLF5sOoerqyn5Cwgw3zY8roD9monKPYVhiN727eUNhIisi0Jhahqp1wM6nXhcDprypD5MSpcvX46QR774GJpYNm/eHFeuXMFvv/2GP/74AwMHDkSXLl2wYcMGi8dbFEzuiOiJKlUCGjcWy6O0WjFK+rVrYqT069eBa9d0OHr0NrKzfXD9ugL374tmn2fPiqUg7u7miV+1aqLJp6+vWPv5iRsHdvzLRWQxCsNImUzuiKiC8PHxQdWqVXH58mUMGzaswP1cXV0xaNAgDBo0CAMGDED37t1x7949VK5cGWq1GjqdzoJRFw6/IhFRiajVpv53BlqtHpGRB9CjRw+o1Wqkpoqk7/p1kQAaksDc2w8eAElJYjl1quDXUyjE3H6GhC+/tbe32MfDo1z8gEhktVRZWVAcPSoeMLkjogpkzpw5eP311+Hm5obu3bsjKysLhw8fxv379xEeHo4FCxbAz88PzZo1g1KpxPr16+Hr6wt3d3cAQGBgIKKjo9G2bVtoNBp4WMnIc0zuiKjMOTsD9eqJpSDJyaaEL/c6IUEs8fFAYqJo9WEY8fPkyce/rkolmpp6eZkSvkfXubfd3ZkMEuXmEhsLhVYr/pM8HPqbiKgieOWVV+Dk5IRPP/0Ub731FipVqoTGjRtj8uTJAAAXFxfMmzcP//77L1QqFZ5++mlERkYa+xTOnz8f4eHhWL58Ofz9/TkVAhFRbq6upvn3CqLTiYFf4uNNCZ9hbdhOSBATuyclif0TE8VSGHZ2QJUqQOXK5ouHR96y3IubG5NCqphcrl8XGw0bFmpOKSIiazVy5EiMHDnSrGzo0KEYOnRovvuPGTPGbLCVR/Xq1Qu9evUqzRBLBZM7Iio3VCpxA8HbGwgOfvy+2dnAnTsi0bt1y3ydX9mDB0BOTtGSQQOFwjwBzL3t5qZEQkJN3L2rgLe3SARzLy4u4n0RWSNnQ3L3uNvuRERkNZjcEVGFZG8PVK0qlsLIyhLJ4N27Ylqvwi5paWIqCcPjvFQAGmPFioJf29lZJHquruaJX2Efu7oCGg1vrFDpM965q19f3kCIiKhQmNwREUEkR/7+YimKrCwxB+D9+/knf3fu6HDmTDwcHKri3j0lHjwQdwmTk8WxgJgmKDVVTCBfXCqVSBIfXVxc8i8vzH6OjkwYbZli40b4HTggHjC5IyIqF5jcERGVgEYjRuj09c3/eTFy6BH06OEDtdq8Y15WlinRy530FWU7JUWcS6czlZUWhcKU6FWqJOaMzW8p7HNqNZCY6Fh6AVLZ0ethN3iw6TGTOyKicoHJHRGRTDQaUx/C4tLpgPR0cecvJcV0F/DR5XHPPfp8Wpo4tySJckMCWXJq1KzZCqNGldb5qMw8OhRtYds3E1GFJ0mS3CGUe2VZh1aR3C1evBiffvopEhISEBwcjK+++gqtWrUqcP/169djxowZuHr1KurUqYNPPvkEPXr0sGDERETWQaUSTSpdXMQ8f6VBrzcljIbELz09/yUtreDn8j4vwdU1G0Cl0gmUyo5CAX1YGJRRUdDNnAkV2+cS2TzVw9G/srOz4ejIVhglkZ6eDgBQq9Wlfm7Zk7t169YhPDwcS5cuRUhICBYuXIhu3brhwoUL8M7n5+y9e/diyJAhiIiIwPPPP481a9agb9++OHr0KBo1aiTDOyAiqliUSlNzzNKk1eYgMnIfAP4YZ/WCg6Hbtg3/FxmJHj16gAO6EpGdnR2cnJxw+/ZtqNVq43xvAKDX65GdnY3MzEyzclv0uLqQJAnp6em4desW3N3djQlzaZI9uVuwYAHGjBmDUQ/b6SxduhTbtm3DihUrMHXq1Dz7f/HFF+jevTveeustAMAHH3yAqKgoLFq0CEuXLrVo7ERERIVRlBYqq1atMl4TDTQaDTIzMy0RKhFRvhQKBfz8/HDlyhVcu3bN7DlJkpCRkQFHR0cobPxOf2Hqwt3dHb4FddYvIVmTu+zsbBw5cgTTpk0zlimVSnTp0gX79u3L95h9+/YhPDzcrKxbt27YvHlzWYZKRERULEVtoQIArq6uuHDhgvGxrX9ZIiLrYG9vjzp16iA7O9usXKvVYvfu3ejQoUOZNDUsT55UF2q1ukzu2BnImtzduXMHOp0OPj4+ZuU+Pj44f/58vsckJCTku39CQkK++2dlZSHLMN44gOTkZACi4rVabbHiNhxX3OMrEtaFCevChHVhwrowKWldlNc6LGoLFUAkc2X1qy4RUUkolUo4ODiYlalUKuTk5MDBwcHmkzu560L2ZpllLSIiAnPmzMlTvmPHDjg5OZXo3FFRUSU6viJhXZiwLkxYFyasC5Pi1oWhA3p5UpwWKgCQmpqKGjVqQK/Xo3nz5vj444/RsGHDAvfnD5lli3VhwrowYV2YsC5M5P4hU9bkztPTEyqVComJiWbliYmJBf5i6evrW6T9p02bZtaMMzk5GQEBAejatStcXV2LFbdWq0VUVBTCwsJs/tcJ1oUJ68KEdWHCujApaV0YEpbypDgtVOrWrYsVK1agSZMmePDgAT777DO0adMGZ86cQbVq1fI9hj9kWgbrwoR1YcK6MGFdmMj1Q6asyZ29vT1atGiB6Oho9O3bF4AYYSY6OhoTJ07M95jQ0FBER0dj8uTJxrKoqCiEhobmu79Go4FGo8lTrlarS/xFqzTOUVGwLkxYFyasCxPWhUlx68JW6i80NNTsmtamTRvUr18fy5YtwwcffJDvMfwhs2yxLkxYFyasCxPWhYncP2TK3iwzPDwcI0aMQMuWLdGqVSssXLgQaWlpxr4Jw4cPh7+/PyIiIgAAkyZNQseOHTF//nz07NkTa9euxeHDh/HNN98U6vUMkwaWpOK0Wi3S09ORnJzMDzDrwoh1YcK6MGFdmJS0Lgx/t8vTBLrFaaHyKLVajWbNmuHixYsF7vPoD5mGOsrIyCj2587w75WRkYGcnJxinaOiYF2YsC5MWBcmrAuTktZFRkYGgOJf62RP7gYNGoTbt29j5syZSEhIQNOmTbF9+3ZjE5bY2FizOSLatGmDNWvWYPr06Xj33XdRp04dbN68udBz3KWkpAAAAgICSv/NEBFRmUtJSYGbm5vcYRRKcVqoPEqn0+HUqVPo0aPw8wPyWkdEVL4V91qnkMrTT6ClQK/X4+bNm3BxcSn20NKG5i5xcXHFbu5SUbAuTFgXJqwLE9aFSUnrQpIkpKSkoGrVquVqktx169ZhxIgRWLZsmbGFys8//4zz58/Dx8cnTwuV999/H61bt0bt2rWRlJSETz/9FJs3b8aRI0fQoEGDQr0mr3Wli3VhwrowYV2YsC5M5L7WyX7nztKUSmWBHdKLytXV1eY/wAasCxPWhQnrwoR1YVKSuigvd+xyK2oLlfv372PMmDFISEiAh4cHWrRogb179xY6sQN4rSsrrAsT1oUJ68KEdWEi17XO5pI7IiIiS5s4cWKBzTBjYmLMHn/++ef4/PPPLRAVERFVNOWnXQsREREREREViMldMWg0GsyaNSvfKRZsDevChHVhwrowYV2YsC7KF/57mbAuTFgXJqwLE9aFidx1YXMDqhAREREREVVEvHNHRERERERUATC5IyIiIiIiqgCY3BEREREREVUATO6IiIiIiIgqACZ3xbB48WIEBgbCwcEBISEhOHjwoNwhFcnu3bvRq1cvVK1aFQqFAps3bzZ7XpIkzJw5E35+fnB0dESXLl3w77//mu1z7949DBs2DK6urnB3d8fLL7+M1NRUs31OnjyJ9u3bw8HBAQEBAZg3b16eWNavX4969erBwcEBjRs3RmRkZKm/34JERETg6aefhouLC7y9vdG3b19cuHDBbJ/MzExMmDABVapUgbOzM/r374/ExESzfWJjY9GzZ084OTnB29sbb731FnJycsz2iYmJQfPmzaHRaFC7dm2sWrUqTzxyfq6WLFmCJk2aGCfcDA0NxW+//WZ83lbqIT9z586FQqHA5MmTjWW2VB+zZ8+GQqEwW+rVq2d83pbqwpaU97rmdc6E1zoTXusKZsvXugp3nZOoSNauXSvZ29tLK1askM6cOSONGTNGcnd3lxITE+UOrdAiIyOl9957T9q4caMEQNq0aZPZ83PnzpXc3NykzZs3SydOnJB69+4tBQUFSRkZGcZ9unfvLgUHB0v79++X/vrrL6l27drSkCFDjM8/ePBA8vHxkYYNGyadPn1a+umnnyRHR0dp2bJlxn3+/vtvSaVSSfPmzZPOnj0rTZ8+XVKr1dKpU6fKvA4kSZK6desmrVy5Ujp9+rR0/PhxqUePHlL16tWl1NRU4z5jx46VAgICpOjoaOnw4cNS69atpTZt2hifz8nJkRo1aiR16dJFOnbsmBQZGSl5enpK06ZNM+5z+fJlycnJSQoPD5fOnj0rffXVV5JKpZK2b99u3Efuz9XWrVulbdu2Sf/884904cIF6d1335XUarV0+vRpm6qHRx08eFAKDAyUmjRpIk2aNMlYbkv1MWvWLKlhw4ZSfHy8cbl9+7bxeVuqC1tREeqa1zkTXutMeK3Ln61f6yradY7JXRG1atVKmjBhgvGxTqeTqlatKkVERMgYVfE9etHT6/WSr6+v9OmnnxrLkpKSJI1GI/3000+SJEnS2bNnJQDSoUOHjPv89ttvkkKhkG7cuCFJkiR9/fXXkoeHh5SVlWXc55133pHq1q1rfDxw4ECpZ8+eZvGEhIRIr732Wqm+x8K6deuWBED6888/JUkS71utVkvr16837nPu3DkJgLRv3z5JksQXCKVSKSUkJBj3WbJkieTq6mp872+//bbUsGFDs9caNGiQ1K1bN+Nja/xceXh4SN9++63N1kNKSopUp04dKSoqSurYsaPxgmdr9TFr1iwpODg43+dsrS5sRUWra17nzPFaZ47XOl7rKtp1js0yiyA7OxtHjhxBly5djGVKpRJdunTBvn37ZIys9Fy5cgUJCQlm79HNzQ0hISHG97hv3z64u7ujZcuWxn26dOkCpVKJAwcOGPfp0KED7O3tjft069YNFy5cwP3794375H4dwz5y1eWDBw8AAJUrVwYAHDlyBFqt1izGevXqoXr16mZ10bhxY/j4+Bj36datG5KTk3HmzBnjPo97n9b2udLpdFi7di3S0tIQGhpqs/UwYcIE9OzZM0/Mtlgf//77L6pWrYqaNWti2LBhiI2NBWCbdVHR2UJd2/J1DuC1zoDXOoHXOqEiXeeY3BXBnTt3oNPpzP7xAMDHxwcJCQkyRVW6DO/jce8xISEB3t7eZs/b2dmhcuXKZvvkd47cr1HQPnLUpV6vx+TJk9G2bVs0atTIGJ+9vT3c3d0LjLEk7zM5ORkZGRlW87k6deoUnJ2dodFoMHbsWGzatAkNGjSwuXoAgLVr1+Lo0aOIiIjI85yt1UdISAhWrVqF7du3Y8mSJbhy5Qrat2+PlJQUm6sLW2ALdW2r1zmA1zqA17rceK0TKtp1zq5IexNVUBMmTMDp06exZ88euUORTd26dXH8+HE8ePAAGzZswIgRI/Dnn3/KHZbFxcXFYdKkSYiKioKDg4Pc4cjuueeeM243adIEISEhqFGjBn7++Wc4OjrKGBkRFRWvdbzWGfBaZ1LRrnO8c1cEnp6eUKlUeUbISUxMhK+vr0xRlS7D+3jce/T19cWtW7fMns/JycG9e/fM9snvHLlfo6B9LF2XEydOxK+//opdu3ahWrVqxnJfX19kZ2cjKSmpwBhL8j5dXV3h6OhoNZ8re3t71K5dGy1atEBERASCg4PxxRdf2Fw9HDlyBLdu3ULz5s1hZ2cHOzs7/Pnnn/jyyy9hZ2cHHx8fm6qPR7m7u+Opp57CxYsXbe6zYQtsoa5t8ToH8FpnwGudwGtdwcr7dY7JXRHY29ujRYsWiI6ONpbp9XpER0cjNDRUxshKT1BQEHx9fc3eY3JyMg4cOGB8j6GhoUhKSsKRI0eM++zcuRN6vR4hISHGfXbv3g2tVmvcJyoqCnXr1oWHh4dxn9yvY9jHUnUpSRImTpyITZs2YefOnQgKCjJ7vkWLFlCr1WYxXrhwAbGxsWZ1cerUKbMvAVFRUXB1dUWDBg2M+zzufVrr50qv1yMrK8vm6qFz5844deoUjh8/blxatmyJYcOGGbdtqT4elZqaikuXLsHPz8/mPhu2wBbq2paucwCvdU/Cax2vdY8q99e5Ig2/QtLatWsljUYjrVq1Sjp79qz06quvSu7u7mYj5Fi7lJQU6dixY9KxY8ckANKCBQukY8eOSdeuXZMkSQwR7e7uLm3ZskU6efKk1KdPn3yHiG7WrJl04MABac+ePVKdOnXMhohOSkqSfHx8pJdeekk6ffq0tHbtWsnJySnPENF2dnbSZ599Jp07d06aNWuWRYeIHjdunOTm5ibFxMSYDX+bnp5u3Gfs2LFS9erVpZ07d0qHDx+WQkNDpdDQUOPzhuFvu3btKh0/flzavn275OXlle/wt2+99ZZ07tw5afHixfkOfyvn52rq1KnSn3/+KV25ckU6efKkNHXqVEmhUEg7duywqXooSO4RxCTJturjjTfekGJiYqQrV65If//9t9SlSxfJ09NTunXrls3Vha2oCHXN65wJr3UmvNY9nq1e6yradY7JXTF89dVXUvXq1SV7e3upVatW0v79++UOqUh27dolAcizjBgxQpIkMUz0jBkzJB8fH0mj0UidO3eWLly4YHaOu3fvSkOGDJGcnZ0lV1dXadSoUVJKSorZPidOnJDatWsnaTQayd/fX5o7d26eWH7++Wfpqaeekuzt7aWGDRtK27ZtK7P3/aj86gCAtHLlSuM+GRkZ0vjx4yUPDw/JyclJ6tevnxQfH292nqtXr0rPPfec5OjoKHl6ekpvvPGGpNVqzfbZtWuX1LRpU8ne3l6qWbOm2WsYyPm5Gj16tFSjRg3J3t5e8vLykjp37my82EmS7dRDQR694NlSfQwaNEjy8/OT7O3tJX9/f2nQoEHSxYsXjc/bUl3YkvJe17zOmfBaZ8Jr3ePZ6rWuol3nFJIkSUW710dERERERETWhn3uiIiIiIiIKgAmd0RERERERBUAkzsiIiIiIqIKgMkdERERERFRBcDkjoiIiIiIqAJgckdERERERFQBMLkjIiIiIiKqAJjcERERERERVQBM7ois1O3btzFu3DhUr14dGo0Gvr6+6NatG/7++28AgEKhwObNm+UNkoiIqAR4rSMqXXZyB0BE+evfvz+ys7Px/fffo2bNmkhMTER0dDTu3r0rd2hERESlgtc6otKlkCRJkjsIIjKXlJQEDw8PxMTEoGPHjnmeDwwMxLVr14yPa9SogatXrwIAtmzZgjlz5uDs2bOoWrUqRowYgffeew92duK3HIVCga+//hpbt25FTEwM/Pz8MG/ePAwYMMAi742IiAjgtY6oLLBZJpEVcnZ2hrOzMzZv3oysrKw8zx86dAgAsHLlSsTHxxsf//XXXxg+fDgmTZqEs2fPYtmyZVi1ahU++ugjs+NnzJiB/v3748SJExg2bBgGDx6Mc+fOlf0bIyIieojXOqLSxzt3RFbql19+wZgxY5CRkYHmzZujY8eOGDx4MJo0aQJA/Cq5adMm9O3b13hMly5d0LlzZ0ybNs1Y9r///Q9vv/02bt68aTxu7NixWLJkiXGf1q1bo3nz5vj6668t8+aIiIjAax1RaeOdOyIr1b9/f9y8eRNbt25F9+7dERMTg+bNm2PVqlUFHnPixAm8//77xl9DnZ2dMWbMGMTHxyM9Pd24X2hoqNlxoaGh/DWTiIgsjtc6otLFAVWIrJiDgwPCwsIQFhaGGTNm4JVXXsGsWbMwcuTIfPdPTU3FnDlz8MILL+R7LiIiImvDax1R6eGdO6JypEGDBkhLSwMAqNVq6HQ6s+ebN2+OCxcuoHbt2nkWpdL0333//v1mx+3fvx/169cv+zdARET0BLzWERUf79wRWaG7d+/ixRdfxOjRo9GkSRO4uLjg8OHDmDdvHvr06QNAjCIWHR2Ntm3bQqPRwMPDAzNnzsTzzz+P6tWrY8CAAVAqlThx4gROnz6NDz/80Hj+9evXo2XLlmjXrh1Wr16NgwcP4rvvvpPr7RIRkQ3itY6oDEhEZHUyMzOlqVOnSs2bN5fc3NwkJycnqW7dutL06dOl9PR0SZIkaevWrVLt2rUlOzs7qUaNGsZjt2/fLrVp00ZydHSUXF1dpVatWknffPON8XkA0uLFi6WwsDBJo9FIgYGB0rp16yz9FomIyMbxWkdU+jhaJpGNyW/kMSIiooqE1zqyVexzR0REREREVAEwuSMiIiIiIqoA2CyTiIiIiIioAuCdOyIiIiIiogqAyR0REREREVEFwOSOiIiIiIioAmByR0REREREVAEwuSMiIiIiIqoAmNwRERERERFVAEzuiIiIiIiIKgAmd0RERERERBUAkzsiIiIiIqIK4P8BPqCvZ18CSVUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First 100 Train Outputs:\n",
            "tensor([ 4.0999, 10.6976, -8.1954,  5.1052,  2.8697, -4.4068, -6.3147,  6.0378,\n",
            "         2.4296, 10.0488,  6.9851,  5.8553,  2.9275, -3.5722, -6.6971,  5.6129,\n",
            "        -3.9293,  7.4895, -8.3202,  8.9021,  4.3730, -4.2496,  5.2632,  4.1506,\n",
            "        -6.3656,  4.2507,  6.3276,  5.9729,  9.0542, 12.8752,  4.5688, -6.5302,\n",
            "         3.3858,  4.5987, -3.9050,  2.9038,  9.9248, -3.7602,  4.6794,  3.0108,\n",
            "        -2.9973,  8.6436, -8.0231, -3.9981, -3.0180, -4.1971,  5.1085,  7.0803,\n",
            "        -2.4777,  9.9244, -4.0420, -4.2431, -3.2173,  2.4373, -8.4628,  7.8628,\n",
            "         7.7868, -2.3718,  5.5413, -3.2111, -5.6477, -3.9670,  5.2310,  5.0469,\n",
            "        -8.9229, -5.4001, 10.0655, -9.2351, -6.1677,  2.4222, -3.6902,  2.5976,\n",
            "         3.6994,  3.5264, 17.4848, -5.9011,  5.7861,  4.8138, 10.6870,  5.1747,\n",
            "        -3.8577,  7.4492,  3.1736,  8.5590,  4.1335,  2.9618, -7.1389,  4.9187,\n",
            "         2.8368, -3.1706,  4.2960,  3.1222,  6.3031, -4.6146,  3.3783, -2.9741,\n",
            "        -2.9643, -5.6872,  7.4083, -7.8516])\n",
            "\n",
            "First 100 Train Labels:\n",
            "tensor([1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
            "        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
            "        1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
            "        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
            "        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
            "        1., 1., 1., 0., 1., 0., 0., 0., 1., 0.])\n",
            "\n",
            "First 100 Test Outputs:\n",
            "tensor([ 11.9584,   5.7682, -12.5319,   0.0210,   5.6350,  -9.1795,  -6.0291,\n",
            "         -3.9456,   2.4608,  -9.3587,   0.0956,  -1.0197,   8.1844,   2.6293,\n",
            "          0.1029,   2.7603,  -2.2899,   4.4840,   6.5966,  -1.8400,  -1.6977,\n",
            "        -11.8949,   4.2804,  -3.4969,  -1.8354,   3.5423,   0.2324,  -0.1806,\n",
            "        -13.4175,   4.1170,  -1.7607,   3.2967,   5.1331,  -8.3594,   0.7131,\n",
            "          0.3230,   5.0037,  -3.6907,  -2.1501, -11.8617,   7.9074,  -5.8064,\n",
            "          4.1691,   8.1312,   1.5388,   9.2005,   0.8231,   2.1625,   7.7262,\n",
            "          4.3990,   5.0620,  -1.9745,   2.9977,   6.7677,  -1.7299,   5.9251,\n",
            "         -9.5610,   3.6866,   0.5387,   6.1056,  -2.7388, -10.4246,  -0.6461,\n",
            "          1.0624,  -0.9438,  -0.9249,  -1.3765,   0.5917,  -0.2797,  -4.8026,\n",
            "         11.5156,  -0.3321,   3.8760,  -5.3224,   6.7984,   1.6696,   1.6513,\n",
            "          1.1714,  -2.2873,  -7.9657,   3.7442,  10.7419,  -3.3005,  -0.8456,\n",
            "         -0.1718,   0.8622,   1.0297,  -0.2901,   2.7613,   3.0508,  -1.1641,\n",
            "          2.0257,   0.6457,   5.9459,  -2.7896,  -3.0199,  -4.1053,   5.2752,\n",
            "          0.8884,   1.8582])\n",
            "\n",
            "First 100 Test Labels:\n",
            "tensor([1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
            "        1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
            "        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
            "        1., 1., 1., 1., 0., 0., 0., 1., 0., 1.])\n",
            "Final Test Accuracy: 0.8116\n"
          ]
        }
      ]
    }
  ]
}