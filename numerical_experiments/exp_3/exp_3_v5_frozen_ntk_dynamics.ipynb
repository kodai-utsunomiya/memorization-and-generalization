{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6jPSHMGwtBt9TIfHtZQeh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kodai-utsunomiya/memorization-and-generalization/blob/main/numerical_experiments/exp_3/exp_3_v5_frozen_ntk_dynamics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class BinaryDataset:\n",
        "    def __init__(self, n, k, train_size, test_size, data_seed, normalize=False, device=None):\n",
        "        self.n = n\n",
        "        self.k = k\n",
        "        self.train_size = train_size\n",
        "        self.test_size = test_size\n",
        "        self.data_seed = data_seed\n",
        "        self.normalize = normalize\n",
        "        self.device = device\n",
        "\n",
        "        (self.train_inputs, self.train_outputs), (self.test_inputs, self.test_outputs) = self._prepare_data()\n",
        "\n",
        "    def _prepare_data(self):\n",
        "        np.random.seed(self.data_seed)\n",
        "        total_size = self.train_size + self.test_size\n",
        "\n",
        "        binary_strings = {tuple(np.random.randint(2, size=self.n)) for _ in range(total_size)}\n",
        "        while len(binary_strings) < total_size:\n",
        "            binary_strings.add(tuple(np.random.randint(2, size=self.n)))\n",
        "\n",
        "        binary_strings = list(binary_strings)\n",
        "        inputs = np.array(binary_strings, dtype=np.float32)\n",
        "        outputs = np.sum(inputs[:, :self.k], axis=-1) % 2\n",
        "\n",
        "        # # 出力ラベルを 0 -> -1, 1 -> 1 に変換（ヒンジ損失用）\n",
        "        # outputs = 2 * outputs - 1\n",
        "\n",
        "        # データの正規化を行う場合\n",
        "        if self.normalize:\n",
        "            inputs = (inputs - inputs.mean(axis=0))\n",
        "            norm = np.linalg.norm(inputs, axis=1, keepdims=True)\n",
        "            inputs = (inputs / np.maximum(norm, 1e-8))  # ゼロ除算防止\n",
        "\n",
        "        indices = np.random.permutation(total_size)\n",
        "        train_indices, test_indices = indices[:self.train_size], indices[self.train_size:]\n",
        "\n",
        "        train_inputs = torch.tensor(inputs[train_indices], dtype=torch.float32).to(self.device)\n",
        "        train_outputs = torch.tensor(outputs[train_indices], dtype=torch.float32).to(self.device)\n",
        "        test_inputs = torch.tensor(inputs[test_indices], dtype=torch.float32).to(self.device)\n",
        "        test_outputs = torch.tensor(outputs[test_indices], dtype=torch.float32).to(self.device)\n",
        "\n",
        "        return (train_inputs, train_outputs), (test_inputs, test_outputs)\n",
        "\n",
        "    def get_data(self):\n",
        "        return (self.train_inputs, self.train_outputs), (self.test_inputs, self.test_outputs)\n",
        "\n",
        "\n",
        "###################################################################\n",
        "\n",
        "import functools\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FC(nn.Module):\n",
        "    def __init__(self, d, h, L, act, bias=False):\n",
        "        super().__init__()\n",
        "\n",
        "        hh = d\n",
        "        for i in range(L):\n",
        "            W = torch.randn(h, hh)\n",
        "\n",
        "            n = max(1, 128 * 256 // hh)\n",
        "            W = nn.ParameterList([nn.Parameter(W[j: j+n]) for j in range(0, len(W), n)])\n",
        "\n",
        "            setattr(self, \"W{}\".format(i), W)\n",
        "            if bias:\n",
        "                self.register_parameter(\"B{}\".format(i), nn.Parameter(torch.zeros(h)))\n",
        "            hh = h\n",
        "\n",
        "        self.register_parameter(\"W{}\".format(L), nn.Parameter(torch.randn(1, hh)))\n",
        "        if bias:\n",
        "            self.register_parameter(\"B{}\".format(L), nn.Parameter(torch.zeros(1)))\n",
        "\n",
        "        self.L = L\n",
        "        self.act = act\n",
        "        self.bias = bias\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(self.L + 1):\n",
        "            W = getattr(self, \"W{}\".format(i))\n",
        "\n",
        "            if isinstance(W, nn.ParameterList):\n",
        "                W = torch.cat(list(W))\n",
        "\n",
        "            if self.bias:\n",
        "                B = self.bias * getattr(self, \"B{}\".format(i))\n",
        "            else:\n",
        "                B = 0\n",
        "\n",
        "            h = x.size(1)\n",
        "\n",
        "            if i < self.L:\n",
        "                x = x @ (W.t() / h ** 0.5)\n",
        "                x = self.act(x + B)\n",
        "            else:\n",
        "                x = x @ (W.t() / h ** 0.5) + B\n",
        "\n",
        "        return x.view(-1)\n",
        "\n",
        "#################################################################################\n",
        "def gradient(outputs, inputs, grad_outputs=None, retain_graph=None, create_graph=False):\n",
        "    r'''\n",
        "    Compute the gradient of `outputs` with respect to `inputs`\n",
        "    ```\n",
        "    gradient(x.sum(), x)\n",
        "    gradient((x * y).sum(), [x, y])\n",
        "    ```\n",
        "    '''\n",
        "    if torch.is_tensor(inputs):\n",
        "        inputs = [inputs]\n",
        "    else:\n",
        "        inputs = list(inputs)\n",
        "    grads = torch.autograd.grad(outputs, inputs, grad_outputs,\n",
        "                                allow_unused=True,\n",
        "                                retain_graph=retain_graph,\n",
        "                                create_graph=create_graph)\n",
        "    grads = [x if x is not None else torch.zeros_like(y) for x, y in zip(grads, inputs)]\n",
        "    return torch.cat([x.contiguous().view(-1) for x in grads])\n",
        "\n",
        "########################################################################################\n",
        "def compute_kernels(f, xtr, xte):\n",
        "\n",
        "    ktrtr = xtr.new_zeros(len(xtr), len(xtr))\n",
        "    ktetr = xtr.new_zeros(len(xte), len(xtr))\n",
        "    ktete = xtr.new_zeros(len(xte), len(xte))\n",
        "\n",
        "    params = []\n",
        "    current = []\n",
        "    for p in sorted(f.parameters(), key=lambda p: p.numel(), reverse=True):\n",
        "        current.append(p)\n",
        "        if sum(p.numel() for p in current) > 2e9 // (8 * (len(xtr) + len(xte))):\n",
        "            if len(current) > 1:\n",
        "                params.append(current[:-1])\n",
        "                current = current[-1:]\n",
        "            else:\n",
        "                params.append(current)\n",
        "                current = []\n",
        "    if len(current) > 0:\n",
        "        params.append(current)\n",
        "\n",
        "    for i, p in enumerate(params):\n",
        "        print(\"[{}/{}] [len={} numel={}]\".format(i, len(params), len(p), sum(x.numel() for x in p)), flush=True)\n",
        "\n",
        "        jtr = xtr.new_empty(len(xtr), sum(u.numel() for u in p))  # (P, N~)\n",
        "        jte = xte.new_empty(len(xte), sum(u.numel() for u in p))  # (P, N~)\n",
        "\n",
        "        for j, x in enumerate(xtr):\n",
        "            jtr[j] = gradient(f(x[None]), p)  # (N~)\n",
        "\n",
        "        for j, x in enumerate(xte):\n",
        "            jte[j] = gradient(f(x[None]), p)  # (N~)\n",
        "\n",
        "        ktrtr.add_(jtr @ jtr.t())\n",
        "        ktetr.add_(jte @ jtr.t())\n",
        "        ktete.add_(jte @ jte.t())\n",
        "        del jtr, jte\n",
        "\n",
        "    return ktrtr, ktetr, ktete"
      ],
      "metadata": {
        "id": "vNMYzp4WJ1uv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frozen NTK dynamics"
      ],
      "metadata": {
        "id": "R3WTZB4qy6xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import itertools\n",
        "import math\n",
        "from time import perf_counter\n",
        "\n",
        "def loglinspace(rate, step, end=None):\n",
        "    t = 0\n",
        "    while end is None or t <= end:\n",
        "        yield t\n",
        "        t = int(t + 1 + step * (1 - math.exp(-t * rate / step)))\n",
        "\n",
        "def train_kernel(args, ktrtr, ytr, tau, max_walltime, alpha, learning_rate, loss_prim, max_dgrad=math.inf, max_dout=math.inf):\n",
        "    # 初期化\n",
        "    otr = torch.zeros(len(ytr), dtype=ktrtr.dtype, device=ktrtr.device)\n",
        "    gradient_update = torch.clone(otr)\n",
        "\n",
        "    last_lr_change_step = 0  # 最後に学習率が変更されたステップ\n",
        "\n",
        "    checkpoint_generator = loglinspace(0.01, 100)\n",
        "    checkpoint = next(checkpoint_generator)  # 最初のチェックポイント\n",
        "    start_time = perf_counter()  # 経過時間計測の開始\n",
        "    converged = False\n",
        "\n",
        "    # 初期の損失関数の勾配を計算\n",
        "    lprim = loss_prim(otr, ytr)\n",
        "    grad = ktrtr @ lprim / len(ytr)\n",
        "\n",
        "    # メインループ\n",
        "    for step in itertools.count():\n",
        "        if step >= args.max_step:\n",
        "            break\n",
        "\n",
        "        # 現在の状態を保存\n",
        "        state = copy.deepcopy((otr, gradient_update))\n",
        "\n",
        "        while True:\n",
        "            gradient_update = -grad.clone()\n",
        "\n",
        "            # 出力を更新\n",
        "            otr = otr + learning_rate * gradient_update\n",
        "\n",
        "            # 新しい勾配を計算\n",
        "            lprim = loss_prim(otr, ytr)\n",
        "            new_grad = ktrtr @ lprim / len(ytr)\n",
        "\n",
        "            # 出力変化量 (dout) の計算\n",
        "            dout = (learning_rate * alpha * gradient_update).abs().max().item()\n",
        "\n",
        "            # 勾配の変化量 (dgrad) の計算\n",
        "            if grad.norm() == 0 or new_grad.norm() == 0:\n",
        "                dgrad = 0\n",
        "            else:\n",
        "                dgrad = ((grad - new_grad).norm() ** 2 / (grad.norm() * new_grad.norm())).item()\n",
        "\n",
        "            # 変化量が許容範囲内なら学習率を調整\n",
        "            if dgrad < max_dgrad and dout < max_dout:\n",
        "                if dgrad < 0.1 * max_dgrad and dout < 0.1 * max_dout:\n",
        "                    learning_rate *= 1.1  # 学習率を大きくする\n",
        "                break\n",
        "\n",
        "            # 学習率を小さくする\n",
        "            learning_rate /= 10\n",
        "\n",
        "            print(\"[Step {:d}/{:d}] [Progress: {:.2%}] [learning rate: {:.1e}]\".format(step, args.max_step, step / args.max_step, learning_rate), flush=True)\n",
        "\n",
        "            # 状態をリセット\n",
        "            last_lr_change_step = step\n",
        "            otr, gradient_update = state\n",
        "\n",
        "        # 勾配を更新\n",
        "        grad = new_grad\n",
        "\n",
        "        save = False\n",
        "        if step == checkpoint:\n",
        "            checkpoint = next(checkpoint_generator)\n",
        "            assert checkpoint > step\n",
        "            save = True\n",
        "\n",
        "        if save:\n",
        "            state = {\n",
        "                'step': step,\n",
        "                'wall': perf_counter() - start_time,\n",
        "                'learning_rate': learning_rate,\n",
        "                'dgrad': dgrad,\n",
        "                'dout': dout,\n",
        "                'grad_norm': grad.norm().item(),\n",
        "            }\n",
        "            yield otr, gradient_update, grad, state, converged\n",
        "\n",
        "        if converged:\n",
        "            break\n",
        "\n",
        "        # 最大経過時間を超えたら終了\n",
        "        if perf_counter() > start_time + max_walltime:\n",
        "            break\n",
        "\n",
        "        # 出力に NaN が含まれていたら終了\n",
        "        if torch.isnan(otr).any():\n",
        "            break"
      ],
      "metadata": {
        "id": "fkHYa7LT0ik_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "from functools import partial\n",
        "from time import perf_counter\n",
        "\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.device = 'cpu'\n",
        "        self.init_seed = 0\n",
        "        self.data_seed = 0\n",
        "        self.batch_seed = 0\n",
        "        self.max_step = 50000\n",
        "        self.n = 13\n",
        "        self.k = 3\n",
        "        self.train_size = 3000\n",
        "        self.test_size = 1900\n",
        "        self.normalize = False\n",
        "        self.bias = True\n",
        "        self.L = 3\n",
        "        self.h = 50\n",
        "        self.learning_rate = 0.01\n",
        "        self.init_kernel = 1\n",
        "        self.store_kernel = 0\n",
        "        self.delta_kernel = 0\n",
        "        self.save_outputs = 0\n",
        "        self.alpha = 1\n",
        "        self.f0 = 1\n",
        "        self.train_time = 18000\n",
        "        self.max_dgrad = 1e-4\n",
        "        self.max_dout = 0.1\n",
        "        self.loss = 'cross_entropy'\n",
        "        self.pickle = 'results.pkl'\n",
        "        self.track_test_metrics = True\n",
        "\n",
        "def loss_func(args, outputs, targets):\n",
        "    if args.loss == 'mse':\n",
        "        return ((targets - outputs) ** 2).mean()\n",
        "    elif args.loss == 'cross_entropy':\n",
        "        return F.binary_cross_entropy_with_logits(outputs, targets)\n",
        "\n",
        "def loss_func_prime(args, outputs, targets):\n",
        "    if args.loss == 'mse':\n",
        "        return -2 * (targets - outputs) / outputs.size(0)\n",
        "    elif args.loss == 'cross_entropy':\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        grad = probs - targets\n",
        "        return grad / outputs.size(0)\n",
        "\n",
        "def run_kernel(args, ktrtr, ktetr, ktete, f, xtr, ytr, xte, yte):\n",
        "    assert args.f0 == 1\n",
        "\n",
        "    dynamics = []\n",
        "    step_counter = 0\n",
        "\n",
        "    tau = 0\n",
        "\n",
        "    for otr, _gradient_update, _grad, state, _converged in train_kernel(args, ktrtr, ytr, tau, args.train_time, args.alpha, args.learning_rate, partial(loss_func_prime, args), args.max_dgrad, args.max_dout):\n",
        "        step_counter += 1\n",
        "\n",
        "        preds = torch.sigmoid(otr) > 0.5\n",
        "        train_accuracy = (preds.int() == ytr.int()).float().mean().item()\n",
        "\n",
        "        state['train'] = {\n",
        "            'loss': loss_func(args, otr, ytr).item(),\n",
        "            'aloss': args.alpha * loss_func(args, otr, ytr).item(),\n",
        "            'accuracy': train_accuracy,\n",
        "            'dfnorm': otr.pow(2).mean().sqrt(),\n",
        "            'outputs': otr if args.save_outputs else None,\n",
        "            'labels': ytr if args.save_outputs else None,\n",
        "        }\n",
        "\n",
        "        if args.track_test_metrics and step_counter % 50 == 0:\n",
        "            c = torch.linalg.lstsq(ktrtr, otr.view(-1, 1)).solution.flatten()\n",
        "\n",
        "            if len(xte) > len(xtr):\n",
        "                a = gradient(f(xtr) @ c, f.parameters())\n",
        "                ote = torch.stack([gradient(f(x[None]), f.parameters()) @ a for x in xte])\n",
        "            else:\n",
        "                ote = ktetr @ c\n",
        "\n",
        "            test_loss = loss_func(args, ote, yte).item()\n",
        "            test_preds = torch.sigmoid(ote) > 0.5\n",
        "            test_accuracy = (test_preds.int() == yte.int()).float().mean().item()\n",
        "\n",
        "            state['test'] = {\n",
        "                'loss': test_loss,\n",
        "                'accuracy': test_accuracy,\n",
        "            }\n",
        "\n",
        "            print(f\"[Step {state['step']:d}/{args.max_step}] [Time: {state['wall']:.0f}s] \"\n",
        "                  f\"[Train Loss: {state['train']['loss']:.2e}] [Train Acc: {state['train']['accuracy']:.2f}] \"\n",
        "                  f\"[Eval Loss: {state['test']['loss']:.2e}] [Eval Acc: {state['test']['accuracy']:.2f}]\",\n",
        "                  flush=True)\n",
        "        else:\n",
        "            state['test'] = {\n",
        "                'loss': None,\n",
        "                'accuracy': None,\n",
        "            }\n",
        "\n",
        "            print(f\"[Step {state['step']:d}/{args.max_step}] [Time: {state['wall']:.0f}s] \"\n",
        "                  f\"[Train Loss: {state['train']['aloss']:.2e}] [Train Acc: {state['train']['accuracy']:.2f}]\",\n",
        "                  flush=True)\n",
        "\n",
        "        dynamics.append(state)\n",
        "\n",
        "    c = torch.linalg.lstsq(ktrtr, otr.view(-1, 1)).solution.flatten()\n",
        "    if len(xte) > len(xtr):\n",
        "        a = gradient(f(xtr) @ c, f.parameters())\n",
        "        ote = torch.stack([gradient(f(x[None]), f.parameters()) @ a for x in xte])\n",
        "    else:\n",
        "        ote = ktetr @ c\n",
        "\n",
        "    final_test_loss = loss_func(args, ote, yte).item()\n",
        "    final_test_preds = torch.sigmoid(ote) > 0.5\n",
        "    final_test_accuracy = (final_test_preds.int() == yte.int()).float().mean().item()\n",
        "\n",
        "    dynamics[-1]['test'] = {\n",
        "        'loss': final_test_loss,\n",
        "        'accuracy': final_test_accuracy,\n",
        "    }\n",
        "\n",
        "    out = {\n",
        "        'dynamics': dynamics,\n",
        "        'train': {\n",
        "            'outputs': otr,\n",
        "            'labels': ytr,\n",
        "        },\n",
        "        'test': {\n",
        "            'outputs': ote,\n",
        "            'labels': yte,\n",
        "        },\n",
        "        'kernel': {\n",
        "            'train': {\n",
        "                'value': ktrtr.cpu() if args.store_kernel == 1 else None,\n",
        "            },\n",
        "            'test': {\n",
        "                'value': ktete.cpu() if args.store_kernel == 1 else None,\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "\n",
        "    return out\n",
        "\n",
        "def execute(args):\n",
        "    torch.set_default_dtype(torch.float64)\n",
        "\n",
        "    dataset = BinaryDataset(args.n, args.k, args.train_size, args.test_size, args.data_seed, args.normalize, args.device)\n",
        "    (xtr, ytr), (xte, yte) = dataset.get_data()\n",
        "\n",
        "    xtr = xtr.type(torch.get_default_dtype())\n",
        "    xte = xte.type(torch.get_default_dtype())\n",
        "    ytr = ytr.type(torch.get_default_dtype())\n",
        "    yte = yte.type(torch.get_default_dtype())\n",
        "\n",
        "    torch.manual_seed(args.init_seed + hash(args.alpha))\n",
        "\n",
        "    act = lambda x: 2 ** 0.5 * torch.relu(x)\n",
        "\n",
        "    xtr = xtr.flatten(1)\n",
        "    xte = xte.flatten(1)\n",
        "    f = FC(xtr.size(1), args.h, args.L, act, args.bias).to(args.device)\n",
        "\n",
        "    if args.delta_kernel == 1 or args.init_kernel == 1:\n",
        "        init_kernel = compute_kernels(f, xtr, xte[:len(xtr)])\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    if args.init_kernel == 1:\n",
        "        results['init_kernel'] = run_kernel(args, *init_kernel, f, xtr, ytr, xte, yte)\n",
        "\n",
        "    if args.delta_kernel == 1:\n",
        "        init_kernel = (init_kernel[0].cpu(), init_kernel[2].cpu())\n",
        "    elif args.init_kernel == 1:\n",
        "        del init_kernel\n",
        "\n",
        "    return {\n",
        "        'args': args,\n",
        "        'results': results\n",
        "    }\n",
        "\n",
        "\n",
        "#####################################\n",
        "\n",
        "args = Args()\n",
        "results_to_save = {'args': args}\n",
        "\n",
        "try:\n",
        "    results = execute(args)\n",
        "    results_to_save.update(results)\n",
        "\n",
        "    with open(args.pickle, 'wb') as f:\n",
        "        torch.save(results_to_save, f)\n",
        "except:\n",
        "    os.remove(args.pickle)\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSMuQJmHzct5",
        "outputId": "fcf17fd5-4346-4591-c87a-8bbeb1c5233f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0/1] [len=8 numel=5851]\n",
            "[Step 0/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 1/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 2/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 3/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 4/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 5/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 6/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 7/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 8/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 9/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 10/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 11/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 12/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 13/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 14/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 15/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 16/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 17/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 18/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 19/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 20/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 21/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 22/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 23/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 24/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 25/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 26/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 27/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 28/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 29/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 30/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 31/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 32/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 33/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 34/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 35/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 36/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 37/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 38/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 39/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 40/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 41/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 42/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 43/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 44/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 45/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 46/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 47/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 48/50000] [Time: 0s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 49/50000] [Time: 1s] [Train Loss: 6.93e-01] [Train Acc: 0.57] [Eval Loss: 6.93e-01] [Eval Acc: 0.54]\n",
            "[Step 50/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 51/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 52/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 53/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 54/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 55/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 56/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 57/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 58/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 59/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 60/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 61/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 62/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 63/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 64/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 65/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 66/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 67/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 68/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 69/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 70/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 71/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 72/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 73/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 74/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 75/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 76/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 77/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 78/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 79/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 80/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 81/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 82/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 83/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 84/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 85/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 86/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 87/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 88/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 89/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 90/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 91/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 92/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 93/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 94/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 95/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 96/50000] [Time: 3s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 97/50000] [Time: 4s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 98/50000] [Time: 4s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 99/50000] [Time: 4s] [Train Loss: 6.93e-01] [Train Acc: 0.56] [Eval Loss: 6.93e-01] [Eval Acc: 0.54]\n",
            "[Step 100/50000] [Time: 5s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 101/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 103/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 105/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 107/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 109/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 111/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 113/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 115/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 117/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 119/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 121/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 123/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 125/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 127/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 129/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 131/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 133/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 135/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 137/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 139/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 141/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 143/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 145/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 147/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 149/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 151/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 153/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 155/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 157/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 159/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 161/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 163/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 165/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 167/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 169/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 171/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 173/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 175/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 177/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 179/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 181/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.56]\n",
            "[Step 183/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 185/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 187/50000] [Time: 6s] [Train Loss: 6.93e-01] [Train Acc: 0.57]\n",
            "[Step 189/50000] [Time: 6s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 191/50000] [Time: 6s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 193/50000] [Time: 6s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 195/50000] [Time: 6s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 197/50000] [Time: 6s] [Train Loss: 6.92e-01] [Train Acc: 0.57] [Eval Loss: 6.93e-01] [Eval Acc: 0.55]\n",
            "[Step 199/50000] [Time: 8s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 201/50000] [Time: 8s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 203/50000] [Time: 8s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 206/50000] [Time: 8s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 209/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 212/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 215/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 218/50000] [Time: 9s] [Train Loss: 6.92e-01] [Train Acc: 0.57]\n",
            "[Step 221/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 224/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 227/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 230/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 233/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 236/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 239/50000] [Time: 9s] [Train Loss: 6.91e-01] [Train Acc: 0.57]\n",
            "[Step 242/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 245/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 248/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 251/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 254/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 257/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 260/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 263/50000] [Time: 9s] [Train Loss: 6.90e-01] [Train Acc: 0.57]\n",
            "[Step 266/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.57]\n",
            "[Step 269/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.57]\n",
            "[Step 272/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 275/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 278/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 281/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 284/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 287/50000] [Time: 9s] [Train Loss: 6.89e-01] [Train Acc: 0.58]\n",
            "[Step 290/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 293/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 296/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 299/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 302/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 305/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 309/50000] [Time: 9s] [Train Loss: 6.88e-01] [Train Acc: 0.58]\n",
            "[Step 313/50000] [Time: 9s] [Train Loss: 6.87e-01] [Train Acc: 0.58]\n",
            "[Step 317/50000] [Time: 9s] [Train Loss: 6.87e-01] [Train Acc: 0.58]\n",
            "[Step 321/50000] [Time: 9s] [Train Loss: 6.87e-01] [Train Acc: 0.58]\n",
            "[Step 325/50000] [Time: 9s] [Train Loss: 6.87e-01] [Train Acc: 0.58]\n",
            "[Step 329/50000] [Time: 9s] [Train Loss: 6.87e-01] [Train Acc: 0.58]\n",
            "[Step 333/50000] [Time: 9s] [Train Loss: 6.87e-01] [Train Acc: 0.58]\n",
            "[Step 337/50000] [Time: 9s] [Train Loss: 6.86e-01] [Train Acc: 0.58]\n",
            "[Step 341/50000] [Time: 10s] [Train Loss: 6.86e-01] [Train Acc: 0.58]\n",
            "[Step 345/50000] [Time: 10s] [Train Loss: 6.86e-01] [Train Acc: 0.58]\n",
            "[Step 349/50000] [Time: 10s] [Train Loss: 6.86e-01] [Train Acc: 0.58]\n",
            "[Step 353/50000] [Time: 10s] [Train Loss: 6.86e-01] [Train Acc: 0.58]\n",
            "[Step 357/50000] [Time: 10s] [Train Loss: 6.86e-01] [Train Acc: 0.58] [Eval Loss: 6.88e-01] [Eval Acc: 0.57]\n",
            "[Step 361/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.58]\n",
            "[Step 365/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.58]\n",
            "[Step 369/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.59]\n",
            "[Step 373/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.59]\n",
            "[Step 377/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.59]\n",
            "[Step 381/50000] [Time: 12s] [Train Loss: 6.85e-01] [Train Acc: 0.59]\n",
            "[Step 385/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.59]\n",
            "[Step 389/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.59]\n",
            "[Step 393/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.59]\n",
            "[Step 397/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.59]\n",
            "[Step 401/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.59]\n",
            "[Step 405/50000] [Time: 12s] [Train Loss: 6.84e-01] [Train Acc: 0.59]\n",
            "[Step 409/50000] [Time: 12s] [Train Loss: 6.83e-01] [Train Acc: 0.59]\n",
            "[Step 414/50000] [Time: 12s] [Train Loss: 6.83e-01] [Train Acc: 0.59]\n",
            "[Step 419/50000] [Time: 12s] [Train Loss: 6.83e-01] [Train Acc: 0.59]\n",
            "[Step 424/50000] [Time: 12s] [Train Loss: 6.83e-01] [Train Acc: 0.59]\n",
            "[Step 429/50000] [Time: 12s] [Train Loss: 6.83e-01] [Train Acc: 0.59]\n",
            "[Step 434/50000] [Time: 12s] [Train Loss: 6.82e-01] [Train Acc: 0.59]\n",
            "[Step 439/50000] [Time: 12s] [Train Loss: 6.82e-01] [Train Acc: 0.59]\n",
            "[Step 444/50000] [Time: 12s] [Train Loss: 6.82e-01] [Train Acc: 0.59]\n",
            "[Step 449/50000] [Time: 12s] [Train Loss: 6.82e-01] [Train Acc: 0.59]\n",
            "[Step 454/50000] [Time: 12s] [Train Loss: 6.81e-01] [Train Acc: 0.59]\n",
            "[Step 459/50000] [Time: 12s] [Train Loss: 6.81e-01] [Train Acc: 0.59]\n",
            "[Step 464/50000] [Time: 12s] [Train Loss: 6.81e-01] [Train Acc: 0.59]\n",
            "[Step 469/50000] [Time: 12s] [Train Loss: 6.81e-01] [Train Acc: 0.59]\n",
            "[Step 474/50000] [Time: 12s] [Train Loss: 6.81e-01] [Train Acc: 0.59]\n",
            "[Step 479/50000] [Time: 12s] [Train Loss: 6.80e-01] [Train Acc: 0.59]\n",
            "[Step 484/50000] [Time: 13s] [Train Loss: 6.80e-01] [Train Acc: 0.59]\n",
            "[Step 489/50000] [Time: 13s] [Train Loss: 6.80e-01] [Train Acc: 0.59]\n",
            "[Step 494/50000] [Time: 13s] [Train Loss: 6.80e-01] [Train Acc: 0.59]\n",
            "[Step 499/50000] [Time: 13s] [Train Loss: 6.80e-01] [Train Acc: 0.59]\n",
            "[Step 504/50000] [Time: 13s] [Train Loss: 6.79e-01] [Train Acc: 0.59]\n",
            "[Step 509/50000] [Time: 13s] [Train Loss: 6.79e-01] [Train Acc: 0.59]\n",
            "[Step 514/50000] [Time: 13s] [Train Loss: 6.79e-01] [Train Acc: 0.59]\n",
            "[Step 520/50000] [Time: 13s] [Train Loss: 6.79e-01] [Train Acc: 0.59]\n",
            "[Step 526/50000] [Time: 13s] [Train Loss: 6.78e-01] [Train Acc: 0.59]\n",
            "[Step 532/50000] [Time: 13s] [Train Loss: 6.78e-01] [Train Acc: 0.59]\n",
            "[Step 538/50000] [Time: 13s] [Train Loss: 6.78e-01] [Train Acc: 0.59]\n",
            "[Step 544/50000] [Time: 13s] [Train Loss: 6.78e-01] [Train Acc: 0.59]\n",
            "[Step 550/50000] [Time: 13s] [Train Loss: 6.77e-01] [Train Acc: 0.59]\n",
            "[Step 556/50000] [Time: 13s] [Train Loss: 6.77e-01] [Train Acc: 0.59]\n",
            "[Step 562/50000] [Time: 13s] [Train Loss: 6.77e-01] [Train Acc: 0.59]\n",
            "[Step 568/50000] [Time: 13s] [Train Loss: 6.77e-01] [Train Acc: 0.59]\n",
            "[Step 574/50000] [Time: 13s] [Train Loss: 6.76e-01] [Train Acc: 0.59]\n",
            "[Step 580/50000] [Time: 13s] [Train Loss: 6.76e-01] [Train Acc: 0.60]\n",
            "[Step 586/50000] [Time: 13s] [Train Loss: 6.76e-01] [Train Acc: 0.60]\n",
            "[Step 592/50000] [Time: 13s] [Train Loss: 6.76e-01] [Train Acc: 0.60]\n",
            "[Step 598/50000] [Time: 13s] [Train Loss: 6.75e-01] [Train Acc: 0.60]\n",
            "[Step 604/50000] [Time: 13s] [Train Loss: 6.75e-01] [Train Acc: 0.60]\n",
            "[Step 610/50000] [Time: 13s] [Train Loss: 6.75e-01] [Train Acc: 0.60] [Eval Loss: 6.83e-01] [Eval Acc: 0.58]\n",
            "[Step 616/50000] [Time: 16s] [Train Loss: 6.74e-01] [Train Acc: 0.60]\n",
            "[Step 622/50000] [Time: 17s] [Train Loss: 6.74e-01] [Train Acc: 0.60]\n",
            "[Step 629/50000] [Time: 17s] [Train Loss: 6.74e-01] [Train Acc: 0.60]\n",
            "[Step 636/50000] [Time: 17s] [Train Loss: 6.74e-01] [Train Acc: 0.60]\n",
            "[Step 643/50000] [Time: 17s] [Train Loss: 6.73e-01] [Train Acc: 0.60]\n",
            "[Step 650/50000] [Time: 17s] [Train Loss: 6.73e-01] [Train Acc: 0.60]\n",
            "[Step 657/50000] [Time: 17s] [Train Loss: 6.73e-01] [Train Acc: 0.60]\n",
            "[Step 664/50000] [Time: 17s] [Train Loss: 6.72e-01] [Train Acc: 0.61]\n",
            "[Step 671/50000] [Time: 17s] [Train Loss: 6.72e-01] [Train Acc: 0.61]\n",
            "[Step 678/50000] [Time: 17s] [Train Loss: 6.71e-01] [Train Acc: 0.61]\n",
            "[Step 685/50000] [Time: 17s] [Train Loss: 6.71e-01] [Train Acc: 0.61]\n",
            "[Step 692/50000] [Time: 17s] [Train Loss: 6.71e-01] [Train Acc: 0.61]\n",
            "[Step 699/50000] [Time: 17s] [Train Loss: 6.70e-01] [Train Acc: 0.61]\n",
            "[Step 706/50000] [Time: 17s] [Train Loss: 6.70e-01] [Train Acc: 0.61]\n",
            "[Step 713/50000] [Time: 18s] [Train Loss: 6.70e-01] [Train Acc: 0.61]\n",
            "[Step 720/50000] [Time: 18s] [Train Loss: 6.69e-01] [Train Acc: 0.61]\n",
            "[Step 727/50000] [Time: 18s] [Train Loss: 6.69e-01] [Train Acc: 0.61]\n",
            "[Step 735/50000] [Time: 18s] [Train Loss: 6.68e-01] [Train Acc: 0.61]\n",
            "[Step 743/50000] [Time: 18s] [Train Loss: 6.68e-01] [Train Acc: 0.61]\n",
            "[Step 751/50000] [Time: 18s] [Train Loss: 6.67e-01] [Train Acc: 0.61]\n",
            "[Step 759/50000] [Time: 18s] [Train Loss: 6.67e-01] [Train Acc: 0.61]\n",
            "[Step 767/50000] [Time: 18s] [Train Loss: 6.66e-01] [Train Acc: 0.61]\n",
            "[Step 775/50000] [Time: 18s] [Train Loss: 6.66e-01] [Train Acc: 0.61]\n",
            "[Step 783/50000] [Time: 18s] [Train Loss: 6.65e-01] [Train Acc: 0.61]\n",
            "[Step 791/50000] [Time: 18s] [Train Loss: 6.65e-01] [Train Acc: 0.61]\n",
            "[Step 799/50000] [Time: 18s] [Train Loss: 6.64e-01] [Train Acc: 0.61]\n",
            "[Step 807/50000] [Time: 18s] [Train Loss: 6.64e-01] [Train Acc: 0.62]\n",
            "[Step 815/50000] [Time: 18s] [Train Loss: 6.63e-01] [Train Acc: 0.62]\n",
            "[Step 823/50000] [Time: 18s] [Train Loss: 6.63e-01] [Train Acc: 0.62]\n",
            "[Step 831/50000] [Time: 18s] [Train Loss: 6.62e-01] [Train Acc: 0.62]\n",
            "[Step 839/50000] [Time: 18s] [Train Loss: 6.62e-01] [Train Acc: 0.62]\n",
            "[Step 848/50000] [Time: 18s] [Train Loss: 6.61e-01] [Train Acc: 0.62]\n",
            "[Step 857/50000] [Time: 19s] [Train Loss: 6.60e-01] [Train Acc: 0.62]\n",
            "[Step 866/50000] [Time: 19s] [Train Loss: 6.60e-01] [Train Acc: 0.62]\n",
            "[Step 875/50000] [Time: 19s] [Train Loss: 6.59e-01] [Train Acc: 0.62]\n",
            "[Step 884/50000] [Time: 19s] [Train Loss: 6.58e-01] [Train Acc: 0.62]\n",
            "[Step 893/50000] [Time: 19s] [Train Loss: 6.58e-01] [Train Acc: 0.63]\n",
            "[Step 902/50000] [Time: 19s] [Train Loss: 6.57e-01] [Train Acc: 0.63]\n",
            "[Step 911/50000] [Time: 19s] [Train Loss: 6.56e-01] [Train Acc: 0.63]\n",
            "[Step 920/50000] [Time: 19s] [Train Loss: 6.55e-01] [Train Acc: 0.63]\n",
            "[Step 929/50000] [Time: 19s] [Train Loss: 6.55e-01] [Train Acc: 0.63]\n",
            "[Step 938/50000] [Time: 19s] [Train Loss: 6.54e-01] [Train Acc: 0.64]\n",
            "[Step 947/50000] [Time: 19s] [Train Loss: 6.53e-01] [Train Acc: 0.64]\n",
            "[Step 957/50000] [Time: 19s] [Train Loss: 6.52e-01] [Train Acc: 0.64]\n",
            "[Step 967/50000] [Time: 19s] [Train Loss: 6.51e-01] [Train Acc: 0.64]\n",
            "[Step 977/50000] [Time: 19s] [Train Loss: 6.50e-01] [Train Acc: 0.64]\n",
            "[Step 987/50000] [Time: 19s] [Train Loss: 6.50e-01] [Train Acc: 0.64]\n",
            "[Step 997/50000] [Time: 19s] [Train Loss: 6.49e-01] [Train Acc: 0.64]\n",
            "[Step 1007/50000] [Time: 20s] [Train Loss: 6.48e-01] [Train Acc: 0.64]\n",
            "[Step 1017/50000] [Time: 20s] [Train Loss: 6.47e-01] [Train Acc: 0.65] [Eval Loss: 6.71e-01] [Eval Acc: 0.60]\n",
            "[Step 1027/50000] [Time: 22s] [Train Loss: 6.46e-01] [Train Acc: 0.65]\n",
            "[Step 1037/50000] [Time: 22s] [Train Loss: 6.45e-01] [Train Acc: 0.65]\n",
            "[Step 1047/50000] [Time: 22s] [Train Loss: 6.44e-01] [Train Acc: 0.65]\n",
            "[Step 1057/50000] [Time: 22s] [Train Loss: 6.43e-01] [Train Acc: 0.65]\n",
            "[Step 1068/50000] [Time: 22s] [Train Loss: 6.41e-01] [Train Acc: 0.65]\n",
            "[Step 1079/50000] [Time: 22s] [Train Loss: 6.40e-01] [Train Acc: 0.65]\n",
            "[Step 1090/50000] [Time: 22s] [Train Loss: 6.39e-01] [Train Acc: 0.66]\n",
            "[Step 1101/50000] [Time: 22s] [Train Loss: 6.38e-01] [Train Acc: 0.66]\n",
            "[Step 1112/50000] [Time: 22s] [Train Loss: 6.36e-01] [Train Acc: 0.66]\n",
            "[Step 1123/50000] [Time: 22s] [Train Loss: 6.35e-01] [Train Acc: 0.67]\n",
            "[Step 1134/50000] [Time: 22s] [Train Loss: 6.34e-01] [Train Acc: 0.67]\n",
            "[Step 1145/50000] [Time: 22s] [Train Loss: 6.32e-01] [Train Acc: 0.67]\n",
            "[Step 1155/50000] [Progress: 2.31%] [learning rate: 6.2e+02]\n",
            "[Step 1156/50000] [Time: 22s] [Train Loss: 6.31e-01] [Train Acc: 0.67]\n",
            "[Step 1167/50000] [Time: 23s] [Train Loss: 6.31e-01] [Train Acc: 0.67]\n",
            "[Step 1179/50000] [Time: 23s] [Train Loss: 6.30e-01] [Train Acc: 0.67]\n",
            "[Step 1191/50000] [Time: 23s] [Train Loss: 6.28e-01] [Train Acc: 0.68]\n",
            "[Step 1202/50000] [Progress: 2.40%] [learning rate: 7.4e+02]\n",
            "[Step 1203/50000] [Time: 23s] [Train Loss: 6.27e-01] [Train Acc: 0.68]\n",
            "[Step 1215/50000] [Time: 23s] [Train Loss: 6.26e-01] [Train Acc: 0.68]\n",
            "[Step 1227/50000] [Time: 23s] [Train Loss: 6.25e-01] [Train Acc: 0.68]\n",
            "[Step 1239/50000] [Time: 23s] [Train Loss: 6.24e-01] [Train Acc: 0.68]\n",
            "[Step 1243/50000] [Progress: 2.49%] [learning rate: 8.1e+02]\n",
            "[Step 1251/50000] [Time: 23s] [Train Loss: 6.23e-01] [Train Acc: 0.68]\n",
            "[Step 1263/50000] [Time: 23s] [Train Loss: 6.22e-01] [Train Acc: 0.69]\n",
            "[Step 1275/50000] [Time: 23s] [Train Loss: 6.20e-01] [Train Acc: 0.69]\n",
            "[Step 1281/50000] [Progress: 2.56%] [learning rate: 8.7e+02]\n",
            "[Step 1287/50000] [Time: 23s] [Train Loss: 6.20e-01] [Train Acc: 0.69]\n",
            "[Step 1300/50000] [Time: 23s] [Train Loss: 6.19e-01] [Train Acc: 0.69]\n",
            "[Step 1313/50000] [Time: 24s] [Train Loss: 6.17e-01] [Train Acc: 0.69]\n",
            "[Step 1318/50000] [Progress: 2.64%] [learning rate: 9.5e+02]\n",
            "[Step 1326/50000] [Time: 24s] [Train Loss: 6.16e-01] [Train Acc: 0.69]\n",
            "[Step 1339/50000] [Time: 24s] [Train Loss: 6.15e-01] [Train Acc: 0.69]\n",
            "[Step 1352/50000] [Time: 24s] [Train Loss: 6.13e-01] [Train Acc: 0.69]\n",
            "[Step 1354/50000] [Progress: 2.71%] [learning rate: 1.0e+03]\n",
            "[Step 1365/50000] [Time: 24s] [Train Loss: 6.13e-01] [Train Acc: 0.69]\n",
            "[Step 1378/50000] [Time: 24s] [Train Loss: 6.11e-01] [Train Acc: 0.69]\n",
            "[Step 1389/50000] [Progress: 2.78%] [learning rate: 1.1e+03]\n",
            "[Step 1391/50000] [Time: 24s] [Train Loss: 6.10e-01] [Train Acc: 0.70]\n",
            "[Step 1404/50000] [Time: 24s] [Train Loss: 6.09e-01] [Train Acc: 0.70]\n",
            "[Step 1418/50000] [Time: 24s] [Train Loss: 6.07e-01] [Train Acc: 0.70]\n",
            "[Step 1423/50000] [Progress: 2.85%] [learning rate: 1.2e+03]\n",
            "[Step 1432/50000] [Time: 24s] [Train Loss: 6.06e-01] [Train Acc: 0.70]\n",
            "[Step 1446/50000] [Time: 24s] [Train Loss: 6.05e-01] [Train Acc: 0.70]\n",
            "[Step 1456/50000] [Progress: 2.91%] [learning rate: 1.3e+03]\n",
            "[Step 1460/50000] [Time: 25s] [Train Loss: 6.03e-01] [Train Acc: 0.70]\n",
            "[Step 1474/50000] [Time: 25s] [Train Loss: 6.02e-01] [Train Acc: 0.71]\n",
            "[Step 1488/50000] [Time: 25s] [Train Loss: 6.00e-01] [Train Acc: 0.71]\n",
            "[Step 1489/50000] [Progress: 2.98%] [learning rate: 1.4e+03]\n",
            "[Step 1502/50000] [Time: 25s] [Train Loss: 5.99e-01] [Train Acc: 0.71]\n",
            "[Step 1516/50000] [Time: 25s] [Train Loss: 5.97e-01] [Train Acc: 0.71]\n",
            "[Step 1522/50000] [Progress: 3.04%] [learning rate: 1.5e+03]\n",
            "[Step 1531/50000] [Time: 25s] [Train Loss: 5.96e-01] [Train Acc: 0.71]\n",
            "[Step 1546/50000] [Time: 25s] [Train Loss: 5.94e-01] [Train Acc: 0.71]\n",
            "[Step 1554/50000] [Progress: 3.11%] [learning rate: 1.7e+03]\n",
            "[Step 1561/50000] [Time: 25s] [Train Loss: 5.93e-01] [Train Acc: 0.71]\n",
            "[Step 1576/50000] [Time: 25s] [Train Loss: 5.91e-01] [Train Acc: 0.71]\n",
            "[Step 1583/50000] [Progress: 3.17%] [learning rate: 1.8e+03]\n",
            "[Step 1591/50000] [Time: 26s] [Train Loss: 5.89e-01] [Train Acc: 0.71]\n",
            "[Step 1606/50000] [Time: 26s] [Train Loss: 5.88e-01] [Train Acc: 0.72]\n",
            "[Step 1611/50000] [Progress: 3.22%] [learning rate: 1.9e+03]\n",
            "[Step 1621/50000] [Time: 26s] [Train Loss: 5.86e-01] [Train Acc: 0.72]\n",
            "[Step 1636/50000] [Time: 26s] [Train Loss: 5.84e-01] [Train Acc: 0.72]\n",
            "[Step 1638/50000] [Progress: 3.28%] [learning rate: 2.1e+03]\n",
            "[Step 1652/50000] [Time: 26s] [Train Loss: 5.83e-01] [Train Acc: 0.72] [Eval Loss: 6.45e-01] [Eval Acc: 0.64]\n",
            "[Step 1665/50000] [Progress: 3.33%] [learning rate: 2.1e+03]\n",
            "[Step 1668/50000] [Time: 28s] [Train Loss: 5.81e-01] [Train Acc: 0.72]\n",
            "[Step 1684/50000] [Time: 28s] [Train Loss: 5.80e-01] [Train Acc: 0.72]\n",
            "[Step 1692/50000] [Progress: 3.38%] [learning rate: 2.2e+03]\n",
            "[Step 1700/50000] [Time: 28s] [Train Loss: 5.78e-01] [Train Acc: 0.73]\n",
            "[Step 1716/50000] [Time: 28s] [Train Loss: 5.76e-01] [Train Acc: 0.73]\n",
            "[Step 1718/50000] [Progress: 3.44%] [learning rate: 2.2e+03]\n",
            "[Step 1732/50000] [Time: 28s] [Train Loss: 5.75e-01] [Train Acc: 0.73]\n",
            "[Step 1744/50000] [Progress: 3.49%] [learning rate: 2.2e+03]\n",
            "[Step 1748/50000] [Time: 28s] [Train Loss: 5.73e-01] [Train Acc: 0.74]\n",
            "[Step 1765/50000] [Time: 28s] [Train Loss: 5.72e-01] [Train Acc: 0.74]\n",
            "[Step 1769/50000] [Progress: 3.54%] [learning rate: 2.1e+03]\n",
            "[Step 1782/50000] [Time: 29s] [Train Loss: 5.71e-01] [Train Acc: 0.74]\n",
            "[Step 1796/50000] [Progress: 3.59%] [learning rate: 2.3e+03]\n",
            "[Step 1799/50000] [Time: 29s] [Train Loss: 5.69e-01] [Train Acc: 0.74]\n",
            "[Step 1816/50000] [Time: 29s] [Train Loss: 5.67e-01] [Train Acc: 0.74]\n",
            "[Step 1822/50000] [Progress: 3.64%] [learning rate: 2.3e+03]\n",
            "[Step 1833/50000] [Time: 29s] [Train Loss: 5.66e-01] [Train Acc: 0.75]\n",
            "[Step 1846/50000] [Progress: 3.69%] [learning rate: 2.3e+03]\n",
            "[Step 1850/50000] [Time: 29s] [Train Loss: 5.64e-01] [Train Acc: 0.75]\n",
            "[Step 1867/50000] [Time: 29s] [Train Loss: 5.63e-01] [Train Acc: 0.75]\n",
            "[Step 1871/50000] [Progress: 3.74%] [learning rate: 2.2e+03]\n",
            "[Step 1885/50000] [Time: 29s] [Train Loss: 5.62e-01] [Train Acc: 0.75]\n",
            "[Step 1897/50000] [Progress: 3.79%] [learning rate: 2.2e+03]\n",
            "[Step 1903/50000] [Time: 30s] [Train Loss: 5.60e-01] [Train Acc: 0.75]\n",
            "[Step 1921/50000] [Time: 30s] [Train Loss: 5.58e-01] [Train Acc: 0.75]\n",
            "[Step 1922/50000] [Progress: 3.84%] [learning rate: 2.2e+03]\n",
            "[Step 1939/50000] [Time: 30s] [Train Loss: 5.57e-01] [Train Acc: 0.75]\n",
            "[Step 1947/50000] [Progress: 3.89%] [learning rate: 2.3e+03]\n",
            "[Step 1957/50000] [Time: 30s] [Train Loss: 5.56e-01] [Train Acc: 0.75]\n",
            "[Step 1973/50000] [Progress: 3.95%] [learning rate: 2.5e+03]\n",
            "[Step 1975/50000] [Time: 30s] [Train Loss: 5.54e-01] [Train Acc: 0.76]\n",
            "[Step 1993/50000] [Time: 30s] [Train Loss: 5.53e-01] [Train Acc: 0.76]\n",
            "[Step 1997/50000] [Progress: 3.99%] [learning rate: 2.3e+03]\n",
            "[Step 2012/50000] [Time: 30s] [Train Loss: 5.51e-01] [Train Acc: 0.76]\n",
            "[Step 2022/50000] [Progress: 4.04%] [learning rate: 2.2e+03]\n",
            "[Step 2031/50000] [Time: 31s] [Train Loss: 5.50e-01] [Train Acc: 0.76]\n",
            "[Step 2048/50000] [Progress: 4.10%] [learning rate: 2.4e+03]\n",
            "[Step 2050/50000] [Time: 31s] [Train Loss: 5.48e-01] [Train Acc: 0.76]\n",
            "[Step 2069/50000] [Time: 31s] [Train Loss: 5.47e-01] [Train Acc: 0.76]\n",
            "[Step 2072/50000] [Progress: 4.14%] [learning rate: 2.2e+03]\n",
            "[Step 2088/50000] [Time: 31s] [Train Loss: 5.46e-01] [Train Acc: 0.76]\n",
            "[Step 2099/50000] [Progress: 4.20%] [learning rate: 2.3e+03]\n",
            "[Step 2107/50000] [Time: 31s] [Train Loss: 5.44e-01] [Train Acc: 0.77]\n",
            "[Step 2124/50000] [Progress: 4.25%] [learning rate: 2.3e+03]\n",
            "[Step 2126/50000] [Time: 31s] [Train Loss: 5.42e-01] [Train Acc: 0.77]\n",
            "[Step 2146/50000] [Time: 31s] [Train Loss: 5.41e-01] [Train Acc: 0.77]\n",
            "[Step 2150/50000] [Progress: 4.30%] [learning rate: 2.3e+03]\n",
            "[Step 2166/50000] [Time: 32s] [Train Loss: 5.40e-01] [Train Acc: 0.77]\n",
            "[Step 2176/50000] [Progress: 4.35%] [learning rate: 2.2e+03]\n",
            "[Step 2186/50000] [Time: 32s] [Train Loss: 5.39e-01] [Train Acc: 0.77]\n",
            "[Step 2201/50000] [Progress: 4.40%] [learning rate: 2.2e+03]\n",
            "[Step 2206/50000] [Time: 32s] [Train Loss: 5.37e-01] [Train Acc: 0.77]\n",
            "[Step 2226/50000] [Progress: 4.45%] [learning rate: 2.4e+03]\n",
            "[Step 2226/50000] [Time: 32s] [Train Loss: 5.36e-01] [Train Acc: 0.77]\n",
            "[Step 2246/50000] [Time: 32s] [Train Loss: 5.34e-01] [Train Acc: 0.78]\n",
            "[Step 2251/50000] [Progress: 4.50%] [learning rate: 2.6e+03]\n",
            "[Step 2267/50000] [Time: 32s] [Train Loss: 5.33e-01] [Train Acc: 0.78]\n",
            "[Step 2274/50000] [Progress: 4.55%] [learning rate: 2.1e+03]\n",
            "[Step 2288/50000] [Time: 32s] [Train Loss: 5.32e-01] [Train Acc: 0.78]\n",
            "[Step 2300/50000] [Progress: 4.60%] [learning rate: 2.3e+03]\n",
            "[Step 2309/50000] [Time: 32s] [Train Loss: 5.30e-01] [Train Acc: 0.78]\n",
            "[Step 2325/50000] [Progress: 4.65%] [learning rate: 2.3e+03]\n",
            "[Step 2330/50000] [Time: 33s] [Train Loss: 5.29e-01] [Train Acc: 0.78]\n",
            "[Step 2351/50000] [Progress: 4.70%] [learning rate: 2.4e+03]\n",
            "[Step 2351/50000] [Time: 33s] [Train Loss: 5.27e-01] [Train Acc: 0.78]\n",
            "[Step 2372/50000] [Time: 33s] [Train Loss: 5.26e-01] [Train Acc: 0.78]\n",
            "[Step 2375/50000] [Progress: 4.75%] [learning rate: 2.4e+03]\n",
            "[Step 2394/50000] [Time: 33s] [Train Loss: 5.25e-01] [Train Acc: 0.78]\n",
            "[Step 2400/50000] [Progress: 4.80%] [learning rate: 2.4e+03]\n",
            "[Step 2416/50000] [Time: 33s] [Train Loss: 5.24e-01] [Train Acc: 0.78]\n",
            "[Step 2424/50000] [Progress: 4.85%] [learning rate: 2.3e+03]\n",
            "[Step 2438/50000] [Time: 33s] [Train Loss: 5.22e-01] [Train Acc: 0.78]\n",
            "[Step 2449/50000] [Progress: 4.90%] [learning rate: 2.3e+03]\n",
            "[Step 2460/50000] [Time: 33s] [Train Loss: 5.21e-01] [Train Acc: 0.78]\n",
            "[Step 2475/50000] [Progress: 4.95%] [learning rate: 2.5e+03]\n",
            "[Step 2482/50000] [Time: 34s] [Train Loss: 5.20e-01] [Train Acc: 0.78]\n",
            "[Step 2499/50000] [Progress: 5.00%] [learning rate: 2.2e+03]\n",
            "[Step 2504/50000] [Time: 34s] [Train Loss: 5.18e-01] [Train Acc: 0.78]\n",
            "[Step 2526/50000] [Progress: 5.05%] [learning rate: 2.7e+03]\n",
            "[Step 2527/50000] [Time: 34s] [Train Loss: 5.17e-01] [Train Acc: 0.79]\n",
            "[Step 2549/50000] [Progress: 5.10%] [learning rate: 2.2e+03]\n",
            "[Step 2550/50000] [Time: 34s] [Train Loss: 5.15e-01] [Train Acc: 0.79]\n",
            "[Step 2573/50000] [Time: 34s] [Train Loss: 5.14e-01] [Train Acc: 0.79]\n",
            "[Step 2575/50000] [Progress: 5.15%] [learning rate: 2.3e+03]\n",
            "[Step 2596/50000] [Time: 34s] [Train Loss: 5.13e-01] [Train Acc: 0.79]\n",
            "[Step 2600/50000] [Progress: 5.20%] [learning rate: 2.3e+03]\n",
            "[Step 2619/50000] [Time: 35s] [Train Loss: 5.12e-01] [Train Acc: 0.79] [Eval Loss: 6.11e-01] [Eval Acc: 0.68]\n",
            "[Step 2626/50000] [Progress: 5.25%] [learning rate: 2.3e+03]\n",
            "[Step 2643/50000] [Time: 37s] [Train Loss: 5.11e-01] [Train Acc: 0.79]\n",
            "[Step 2652/50000] [Progress: 5.30%] [learning rate: 2.5e+03]\n",
            "[Step 2667/50000] [Time: 37s] [Train Loss: 5.09e-01] [Train Acc: 0.79]\n",
            "[Step 2679/50000] [Progress: 5.36%] [learning rate: 2.7e+03]\n",
            "[Step 2691/50000] [Time: 37s] [Train Loss: 5.08e-01] [Train Acc: 0.79]\n",
            "[Step 2701/50000] [Progress: 5.40%] [learning rate: 2.2e+03]\n",
            "[Step 2715/50000] [Time: 38s] [Train Loss: 5.07e-01] [Train Acc: 0.79]\n",
            "[Step 2727/50000] [Progress: 5.45%] [learning rate: 2.6e+03]\n",
            "[Step 2739/50000] [Time: 38s] [Train Loss: 5.05e-01] [Train Acc: 0.79]\n",
            "[Step 2750/50000] [Progress: 5.50%] [learning rate: 2.3e+03]\n",
            "[Step 2763/50000] [Time: 38s] [Train Loss: 5.04e-01] [Train Acc: 0.79]\n",
            "[Step 2775/50000] [Progress: 5.55%] [learning rate: 2.5e+03]\n",
            "[Step 2788/50000] [Time: 38s] [Train Loss: 5.03e-01] [Train Acc: 0.79]\n",
            "[Step 2799/50000] [Progress: 5.60%] [learning rate: 2.5e+03]\n",
            "[Step 2813/50000] [Time: 38s] [Train Loss: 5.02e-01] [Train Acc: 0.79]\n",
            "[Step 2824/50000] [Progress: 5.65%] [learning rate: 2.4e+03]\n",
            "[Step 2838/50000] [Time: 38s] [Train Loss: 5.00e-01] [Train Acc: 0.80]\n",
            "[Step 2848/50000] [Progress: 5.70%] [learning rate: 2.4e+03]\n",
            "[Step 2863/50000] [Time: 39s] [Train Loss: 4.99e-01] [Train Acc: 0.80]\n",
            "[Step 2873/50000] [Progress: 5.75%] [learning rate: 2.4e+03]\n",
            "[Step 2888/50000] [Time: 39s] [Train Loss: 4.98e-01] [Train Acc: 0.80]\n",
            "[Step 2899/50000] [Progress: 5.80%] [learning rate: 2.6e+03]\n",
            "[Step 2914/50000] [Time: 39s] [Train Loss: 4.96e-01] [Train Acc: 0.80]\n",
            "[Step 2923/50000] [Progress: 5.85%] [learning rate: 2.3e+03]\n",
            "[Step 2940/50000] [Time: 39s] [Train Loss: 4.95e-01] [Train Acc: 0.80]\n",
            "[Step 2950/50000] [Progress: 5.90%] [learning rate: 2.7e+03]\n",
            "[Step 2966/50000] [Time: 39s] [Train Loss: 4.94e-01] [Train Acc: 0.80]\n",
            "[Step 2973/50000] [Progress: 5.95%] [learning rate: 2.2e+03]\n",
            "[Step 2992/50000] [Time: 40s] [Train Loss: 4.93e-01] [Train Acc: 0.80]\n",
            "[Step 2999/50000] [Progress: 6.00%] [learning rate: 2.4e+03]\n",
            "[Step 3018/50000] [Time: 40s] [Train Loss: 4.91e-01] [Train Acc: 0.80]\n",
            "[Step 3023/50000] [Progress: 6.05%] [learning rate: 2.4e+03]\n",
            "[Step 3045/50000] [Time: 40s] [Train Loss: 4.90e-01] [Train Acc: 0.80]\n",
            "[Step 3048/50000] [Progress: 6.10%] [learning rate: 2.6e+03]\n",
            "[Step 3072/50000] [Progress: 6.14%] [learning rate: 2.3e+03]\n",
            "[Step 3072/50000] [Time: 40s] [Train Loss: 4.89e-01] [Train Acc: 0.80]\n",
            "[Step 3099/50000] [Time: 40s] [Train Loss: 4.87e-01] [Train Acc: 0.80]\n",
            "[Step 3100/50000] [Progress: 6.20%] [learning rate: 2.7e+03]\n",
            "[Step 3123/50000] [Progress: 6.25%] [learning rate: 2.2e+03]\n",
            "[Step 3126/50000] [Time: 40s] [Train Loss: 4.86e-01] [Train Acc: 0.80]\n",
            "[Step 3150/50000] [Progress: 6.30%] [learning rate: 2.7e+03]\n",
            "[Step 3153/50000] [Time: 41s] [Train Loss: 4.85e-01] [Train Acc: 0.80]\n",
            "[Step 3173/50000] [Progress: 6.35%] [learning rate: 2.2e+03]\n",
            "[Step 3181/50000] [Time: 41s] [Train Loss: 4.84e-01] [Train Acc: 0.81]\n",
            "[Step 3200/50000] [Progress: 6.40%] [learning rate: 2.6e+03]\n",
            "[Step 3209/50000] [Time: 41s] [Train Loss: 4.83e-01] [Train Acc: 0.81]\n",
            "[Step 3225/50000] [Progress: 6.45%] [learning rate: 2.5e+03]\n",
            "[Step 3237/50000] [Time: 41s] [Train Loss: 4.81e-01] [Train Acc: 0.81]\n",
            "[Step 3250/50000] [Progress: 6.50%] [learning rate: 2.8e+03]\n",
            "[Step 3265/50000] [Time: 42s] [Train Loss: 4.80e-01] [Train Acc: 0.81]\n",
            "[Step 3273/50000] [Progress: 6.55%] [learning rate: 2.2e+03]\n",
            "[Step 3293/50000] [Time: 42s] [Train Loss: 4.79e-01] [Train Acc: 0.81]\n",
            "[Step 3301/50000] [Progress: 6.60%] [learning rate: 2.7e+03]\n",
            "[Step 3322/50000] [Time: 42s] [Train Loss: 4.78e-01] [Train Acc: 0.81]\n",
            "[Step 3325/50000] [Progress: 6.65%] [learning rate: 2.4e+03]\n",
            "[Step 3350/50000] [Progress: 6.70%] [learning rate: 2.6e+03]\n",
            "[Step 3351/50000] [Time: 42s] [Train Loss: 4.76e-01] [Train Acc: 0.81]\n",
            "[Step 3375/50000] [Progress: 6.75%] [learning rate: 2.6e+03]\n",
            "[Step 3380/50000] [Time: 42s] [Train Loss: 4.75e-01] [Train Acc: 0.81]\n",
            "[Step 3401/50000] [Progress: 6.80%] [learning rate: 2.5e+03]\n",
            "[Step 3409/50000] [Time: 43s] [Train Loss: 4.74e-01] [Train Acc: 0.81]\n",
            "[Step 3425/50000] [Progress: 6.85%] [learning rate: 2.5e+03]\n",
            "[Step 3438/50000] [Time: 43s] [Train Loss: 4.73e-01] [Train Acc: 0.81]\n",
            "[Step 3450/50000] [Progress: 6.90%] [learning rate: 2.4e+03]\n",
            "[Step 3468/50000] [Time: 43s] [Train Loss: 4.72e-01] [Train Acc: 0.81]\n",
            "[Step 3476/50000] [Progress: 6.95%] [learning rate: 2.7e+03]\n",
            "[Step 3498/50000] [Time: 43s] [Train Loss: 4.70e-01] [Train Acc: 0.82]\n",
            "[Step 3500/50000] [Progress: 7.00%] [learning rate: 2.4e+03]\n",
            "[Step 3528/50000] [Progress: 7.06%] [learning rate: 2.8e+03]\n",
            "[Step 3528/50000] [Time: 44s] [Train Loss: 4.69e-01] [Train Acc: 0.82]\n",
            "[Step 3552/50000] [Progress: 7.10%] [learning rate: 2.5e+03]\n",
            "[Step 3558/50000] [Time: 44s] [Train Loss: 4.68e-01] [Train Acc: 0.82]\n",
            "[Step 3577/50000] [Progress: 7.15%] [learning rate: 2.5e+03]\n",
            "[Step 3588/50000] [Time: 44s] [Train Loss: 4.67e-01] [Train Acc: 0.82]\n",
            "[Step 3603/50000] [Progress: 7.21%] [learning rate: 2.5e+03]\n",
            "[Step 3619/50000] [Time: 44s] [Train Loss: 4.66e-01] [Train Acc: 0.82]\n",
            "[Step 3628/50000] [Progress: 7.26%] [learning rate: 2.4e+03]\n",
            "[Step 3650/50000] [Time: 44s] [Train Loss: 4.64e-01] [Train Acc: 0.82]\n",
            "[Step 3655/50000] [Progress: 7.31%] [learning rate: 2.6e+03]\n",
            "[Step 3681/50000] [Time: 45s] [Train Loss: 4.63e-01] [Train Acc: 0.82]\n",
            "[Step 3682/50000] [Progress: 7.36%] [learning rate: 2.8e+03]\n",
            "[Step 3707/50000] [Progress: 7.41%] [learning rate: 2.5e+03]\n",
            "[Step 3712/50000] [Time: 45s] [Train Loss: 4.62e-01] [Train Acc: 0.82]\n",
            "[Step 3733/50000] [Progress: 7.47%] [learning rate: 2.5e+03]\n",
            "[Step 3744/50000] [Time: 45s] [Train Loss: 4.61e-01] [Train Acc: 0.82]\n",
            "[Step 3759/50000] [Progress: 7.52%] [learning rate: 2.5e+03]\n",
            "[Step 3776/50000] [Time: 45s] [Train Loss: 4.60e-01] [Train Acc: 0.82]\n",
            "[Step 3784/50000] [Progress: 7.57%] [learning rate: 2.4e+03]\n",
            "[Step 3808/50000] [Time: 45s] [Train Loss: 4.58e-01] [Train Acc: 0.82]\n",
            "[Step 3810/50000] [Progress: 7.62%] [learning rate: 2.6e+03]\n",
            "[Step 3836/50000] [Progress: 7.67%] [learning rate: 2.9e+03]\n",
            "[Step 3840/50000] [Time: 46s] [Train Loss: 4.57e-01] [Train Acc: 0.82]\n",
            "[Step 3859/50000] [Progress: 7.72%] [learning rate: 2.3e+03]\n",
            "[Step 3872/50000] [Time: 46s] [Train Loss: 4.56e-01] [Train Acc: 0.82]\n",
            "[Step 3885/50000] [Progress: 7.77%] [learning rate: 2.5e+03]\n",
            "[Step 3905/50000] [Time: 46s] [Train Loss: 4.55e-01] [Train Acc: 0.82]\n",
            "[Step 3910/50000] [Progress: 7.82%] [learning rate: 2.5e+03]\n",
            "[Step 3936/50000] [Progress: 7.87%] [learning rate: 2.7e+03]\n",
            "[Step 3938/50000] [Time: 46s] [Train Loss: 4.54e-01] [Train Acc: 0.82]\n",
            "[Step 3961/50000] [Progress: 7.92%] [learning rate: 2.6e+03]\n",
            "[Step 3971/50000] [Time: 47s] [Train Loss: 4.52e-01] [Train Acc: 0.82]\n",
            "[Step 3987/50000] [Progress: 7.97%] [learning rate: 2.6e+03]\n",
            "[Step 4004/50000] [Time: 47s] [Train Loss: 4.51e-01] [Train Acc: 0.83]\n",
            "[Step 4011/50000] [Progress: 8.02%] [learning rate: 2.6e+03]\n",
            "[Step 4036/50000] [Progress: 8.07%] [learning rate: 2.5e+03]\n",
            "[Step 4037/50000] [Time: 47s] [Train Loss: 4.50e-01] [Train Acc: 0.83] [Eval Loss: 5.80e-01] [Eval Acc: 0.71]\n",
            "[Step 4062/50000] [Progress: 8.12%] [learning rate: 2.7e+03]\n",
            "[Step 4071/50000] [Time: 49s] [Train Loss: 4.49e-01] [Train Acc: 0.83]\n",
            "[Step 4086/50000] [Progress: 8.17%] [learning rate: 2.5e+03]\n",
            "[Step 4105/50000] [Time: 49s] [Train Loss: 4.48e-01] [Train Acc: 0.83]\n",
            "[Step 4113/50000] [Progress: 8.23%] [learning rate: 2.9e+03]\n",
            "[Step 4136/50000] [Progress: 8.27%] [learning rate: 2.4e+03]\n",
            "[Step 4139/50000] [Time: 49s] [Train Loss: 4.47e-01] [Train Acc: 0.83]\n",
            "[Step 4162/50000] [Progress: 8.32%] [learning rate: 2.6e+03]\n",
            "[Step 4173/50000] [Time: 49s] [Train Loss: 4.46e-01] [Train Acc: 0.83]\n",
            "[Step 4187/50000] [Progress: 8.37%] [learning rate: 2.5e+03]\n",
            "[Step 4208/50000] [Time: 50s] [Train Loss: 4.44e-01] [Train Acc: 0.83]\n",
            "[Step 4213/50000] [Progress: 8.43%] [learning rate: 2.5e+03]\n",
            "[Step 4238/50000] [Progress: 8.48%] [learning rate: 2.7e+03]\n",
            "[Step 4243/50000] [Time: 50s] [Train Loss: 4.43e-01] [Train Acc: 0.83]\n",
            "[Step 4263/50000] [Progress: 8.53%] [learning rate: 2.7e+03]\n",
            "[Step 4278/50000] [Time: 50s] [Train Loss: 4.42e-01] [Train Acc: 0.83]\n",
            "[Step 4287/50000] [Progress: 8.57%] [learning rate: 2.6e+03]\n",
            "[Step 4312/50000] [Progress: 8.62%] [learning rate: 2.6e+03]\n",
            "[Step 4313/50000] [Time: 50s] [Train Loss: 4.41e-01] [Train Acc: 0.83]\n",
            "[Step 4338/50000] [Progress: 8.68%] [learning rate: 2.6e+03]\n",
            "[Step 4349/50000] [Time: 51s] [Train Loss: 4.40e-01] [Train Acc: 0.84]\n",
            "[Step 4363/50000] [Progress: 8.73%] [learning rate: 2.5e+03]\n",
            "[Step 4385/50000] [Time: 51s] [Train Loss: 4.39e-01] [Train Acc: 0.84]\n",
            "[Step 4388/50000] [Progress: 8.78%] [learning rate: 2.7e+03]\n",
            "[Step 4414/50000] [Progress: 8.83%] [learning rate: 2.9e+03]\n",
            "[Step 4421/50000] [Time: 51s] [Train Loss: 4.37e-01] [Train Acc: 0.84]\n",
            "[Step 4438/50000] [Progress: 8.88%] [learning rate: 2.6e+03]\n",
            "[Step 4457/50000] [Time: 51s] [Train Loss: 4.36e-01] [Train Acc: 0.84]\n",
            "[Step 4463/50000] [Progress: 8.93%] [learning rate: 2.6e+03]\n",
            "[Step 4489/50000] [Progress: 8.98%] [learning rate: 2.6e+03]\n",
            "[Step 4493/50000] [Time: 52s] [Train Loss: 4.35e-01] [Train Acc: 0.84]\n",
            "[Step 4514/50000] [Progress: 9.03%] [learning rate: 2.5e+03]\n",
            "[Step 4530/50000] [Time: 52s] [Train Loss: 4.34e-01] [Train Acc: 0.84]\n",
            "[Step 4540/50000] [Progress: 9.08%] [learning rate: 2.7e+03]\n",
            "[Step 4567/50000] [Progress: 9.13%] [learning rate: 3.0e+03]\n",
            "[Step 4567/50000] [Time: 52s] [Train Loss: 4.33e-01] [Train Acc: 0.84]\n",
            "[Step 4591/50000] [Progress: 9.18%] [learning rate: 2.7e+03]\n",
            "[Step 4604/50000] [Time: 52s] [Train Loss: 4.32e-01] [Train Acc: 0.84]\n",
            "[Step 4616/50000] [Progress: 9.23%] [learning rate: 2.6e+03]\n",
            "[Step 4641/50000] [Time: 53s] [Train Loss: 4.31e-01] [Train Acc: 0.84]\n",
            "[Step 4642/50000] [Progress: 9.28%] [learning rate: 2.6e+03]\n",
            "[Step 4667/50000] [Progress: 9.33%] [learning rate: 2.5e+03]\n",
            "[Step 4679/50000] [Time: 53s] [Train Loss: 4.30e-01] [Train Acc: 0.84]\n",
            "[Step 4693/50000] [Progress: 9.39%] [learning rate: 2.7e+03]\n",
            "[Step 4717/50000] [Time: 53s] [Train Loss: 4.28e-01] [Train Acc: 0.84]\n",
            "[Step 4719/50000] [Progress: 9.44%] [learning rate: 3.0e+03]\n",
            "[Step 4742/50000] [Progress: 9.48%] [learning rate: 2.4e+03]\n",
            "[Step 4755/50000] [Time: 54s] [Train Loss: 4.27e-01] [Train Acc: 0.84]\n",
            "[Step 4769/50000] [Progress: 9.54%] [learning rate: 2.9e+03]\n",
            "[Step 4792/50000] [Progress: 9.58%] [learning rate: 2.6e+03]\n",
            "[Step 4793/50000] [Time: 54s] [Train Loss: 4.26e-01] [Train Acc: 0.84]\n",
            "[Step 4817/50000] [Progress: 9.63%] [learning rate: 2.8e+03]\n",
            "[Step 4832/50000] [Time: 54s] [Train Loss: 4.25e-01] [Train Acc: 0.84]\n",
            "[Step 4842/50000] [Progress: 9.68%] [learning rate: 2.8e+03]\n",
            "[Step 4868/50000] [Progress: 9.74%] [learning rate: 2.7e+03]\n",
            "[Step 4871/50000] [Time: 54s] [Train Loss: 4.24e-01] [Train Acc: 0.84]\n",
            "[Step 4892/50000] [Progress: 9.78%] [learning rate: 2.7e+03]\n",
            "[Step 4910/50000] [Time: 55s] [Train Loss: 4.23e-01] [Train Acc: 0.84]\n",
            "[Step 4917/50000] [Progress: 9.83%] [learning rate: 2.6e+03]\n",
            "[Step 4943/50000] [Progress: 9.89%] [learning rate: 2.9e+03]\n",
            "[Step 4949/50000] [Time: 55s] [Train Loss: 4.22e-01] [Train Acc: 0.84]\n",
            "[Step 4967/50000] [Progress: 9.93%] [learning rate: 2.6e+03]\n",
            "[Step 4989/50000] [Time: 55s] [Train Loss: 4.21e-01] [Train Acc: 0.84]\n",
            "[Step 4995/50000] [Progress: 9.99%] [learning rate: 3.0e+03]\n",
            "[Step 5019/50000] [Progress: 10.04%] [learning rate: 2.7e+03]\n",
            "[Step 5029/50000] [Time: 56s] [Train Loss: 4.20e-01] [Train Acc: 0.84]\n",
            "[Step 5044/50000] [Progress: 10.09%] [learning rate: 2.7e+03]\n",
            "[Step 5069/50000] [Time: 56s] [Train Loss: 4.18e-01] [Train Acc: 0.84]\n",
            "[Step 5070/50000] [Progress: 10.14%] [learning rate: 2.6e+03]\n",
            "[Step 5096/50000] [Progress: 10.19%] [learning rate: 2.9e+03]\n",
            "[Step 5109/50000] [Time: 56s] [Train Loss: 4.18e-01] [Train Acc: 0.85]\n",
            "[Step 5120/50000] [Progress: 10.24%] [learning rate: 2.6e+03]\n",
            "[Step 5146/50000] [Progress: 10.29%] [learning rate: 3.1e+03]\n",
            "[Step 5150/50000] [Time: 57s] [Train Loss: 4.16e-01] [Train Acc: 0.85]\n",
            "[Step 5169/50000] [Progress: 10.34%] [learning rate: 2.5e+03]\n",
            "[Step 5191/50000] [Time: 57s] [Train Loss: 4.15e-01] [Train Acc: 0.85]\n",
            "[Step 5195/50000] [Progress: 10.39%] [learning rate: 2.7e+03]\n",
            "[Step 5221/50000] [Progress: 10.44%] [learning rate: 2.9e+03]\n",
            "[Step 5232/50000] [Time: 57s] [Train Loss: 4.14e-01] [Train Acc: 0.85]\n",
            "[Step 5244/50000] [Progress: 10.49%] [learning rate: 2.6e+03]\n",
            "[Step 5270/50000] [Progress: 10.54%] [learning rate: 2.8e+03]\n",
            "[Step 5273/50000] [Time: 57s] [Train Loss: 4.13e-01] [Train Acc: 0.85]\n",
            "[Step 5297/50000] [Progress: 10.59%] [learning rate: 3.1e+03]\n",
            "[Step 5314/50000] [Time: 58s] [Train Loss: 4.12e-01] [Train Acc: 0.85]\n",
            "[Step 5321/50000] [Progress: 10.64%] [learning rate: 2.8e+03]\n",
            "[Step 5346/50000] [Progress: 10.69%] [learning rate: 2.7e+03]\n",
            "[Step 5356/50000] [Time: 58s] [Train Loss: 4.11e-01] [Train Acc: 0.85]\n",
            "[Step 5372/50000] [Progress: 10.74%] [learning rate: 2.7e+03]\n",
            "[Step 5398/50000] [Time: 58s] [Train Loss: 4.10e-01] [Train Acc: 0.85]\n",
            "[Step 5399/50000] [Progress: 10.80%] [learning rate: 2.9e+03]\n",
            "[Step 5424/50000] [Progress: 10.85%] [learning rate: 2.9e+03]\n",
            "[Step 5440/50000] [Time: 59s] [Train Loss: 4.09e-01] [Train Acc: 0.85]\n",
            "[Step 5450/50000] [Progress: 10.90%] [learning rate: 3.4e+03]\n",
            "[Step 5470/50000] [Progress: 10.94%] [learning rate: 2.3e+03]\n",
            "[Step 5482/50000] [Time: 59s] [Train Loss: 4.08e-01] [Train Acc: 0.85]\n",
            "[Step 5498/50000] [Progress: 11.00%] [learning rate: 3.0e+03]\n",
            "[Step 5523/50000] [Progress: 11.05%] [learning rate: 2.7e+03]\n",
            "[Step 5525/50000] [Time: 59s] [Train Loss: 4.07e-01] [Train Acc: 0.85]\n",
            "[Step 5549/50000] [Progress: 11.10%] [learning rate: 2.9e+03]\n",
            "[Step 5568/50000] [Time: 59s] [Train Loss: 4.06e-01] [Train Acc: 0.85]\n",
            "[Step 5573/50000] [Progress: 11.15%] [learning rate: 2.9e+03]\n",
            "[Step 5598/50000] [Progress: 11.20%] [learning rate: 3.1e+03]\n",
            "[Step 5611/50000] [Time: 60s] [Train Loss: 4.05e-01] [Train Acc: 0.85]\n",
            "[Step 5621/50000] [Progress: 11.24%] [learning rate: 2.5e+03]\n",
            "[Step 5648/50000] [Progress: 11.30%] [learning rate: 3.0e+03]\n",
            "[Step 5654/50000] [Time: 60s] [Train Loss: 4.03e-01] [Train Acc: 0.85]\n",
            "[Step 5671/50000] [Progress: 11.34%] [learning rate: 2.7e+03]\n",
            "[Step 5696/50000] [Progress: 11.39%] [learning rate: 2.9e+03]\n",
            "[Step 5698/50000] [Time: 60s] [Train Loss: 4.02e-01] [Train Acc: 0.85]\n",
            "[Step 5720/50000] [Progress: 11.44%] [learning rate: 2.9e+03]\n",
            "[Step 5742/50000] [Time: 61s] [Train Loss: 4.01e-01] [Train Acc: 0.85]\n",
            "[Step 5745/50000] [Progress: 11.49%] [learning rate: 3.1e+03]\n",
            "[Step 5768/50000] [Progress: 11.54%] [learning rate: 2.5e+03]\n",
            "[Step 5786/50000] [Time: 61s] [Train Loss: 4.00e-01] [Train Acc: 0.85]\n",
            "[Step 5795/50000] [Progress: 11.59%] [learning rate: 3.0e+03]\n",
            "[Step 5818/50000] [Progress: 11.64%] [learning rate: 2.7e+03]\n",
            "[Step 5830/50000] [Time: 61s] [Train Loss: 3.99e-01] [Train Acc: 0.85]\n",
            "[Step 5843/50000] [Progress: 11.69%] [learning rate: 2.9e+03]\n",
            "[Step 5867/50000] [Progress: 11.73%] [learning rate: 2.9e+03]\n",
            "[Step 5875/50000] [Time: 62s] [Train Loss: 3.98e-01] [Train Acc: 0.85]\n",
            "[Step 5892/50000] [Progress: 11.78%] [learning rate: 2.8e+03]\n",
            "[Step 5916/50000] [Progress: 11.83%] [learning rate: 2.8e+03]\n",
            "[Step 5920/50000] [Time: 62s] [Train Loss: 3.97e-01] [Train Acc: 0.85]\n",
            "[Step 5941/50000] [Progress: 11.88%] [learning rate: 2.8e+03]\n",
            "[Step 5965/50000] [Time: 62s] [Train Loss: 3.96e-01] [Train Acc: 0.85]\n",
            "[Step 5967/50000] [Progress: 11.93%] [learning rate: 3.0e+03]\n",
            "[Step 5990/50000] [Progress: 11.98%] [learning rate: 2.7e+03]\n",
            "[Step 6010/50000] [Time: 62s] [Train Loss: 3.95e-01] [Train Acc: 0.85] [Eval Loss: 5.54e-01] [Eval Acc: 0.72]\n",
            "[Step 6016/50000] [Progress: 12.03%] [learning rate: 3.2e+03]\n",
            "[Step 6039/50000] [Progress: 12.08%] [learning rate: 2.6e+03]\n",
            "[Step 6056/50000] [Time: 64s] [Train Loss: 3.94e-01] [Train Acc: 0.86]\n",
            "[Step 6065/50000] [Progress: 12.13%] [learning rate: 2.8e+03]\n",
            "[Step 6089/50000] [Progress: 12.18%] [learning rate: 2.8e+03]\n",
            "[Step 6102/50000] [Time: 65s] [Train Loss: 3.93e-01] [Train Acc: 0.86]\n",
            "[Step 6114/50000] [Progress: 12.23%] [learning rate: 3.0e+03]\n",
            "[Step 6138/50000] [Progress: 12.28%] [learning rate: 2.7e+03]\n",
            "[Step 6148/50000] [Time: 65s] [Train Loss: 3.92e-01] [Train Acc: 0.86]\n",
            "[Step 6165/50000] [Progress: 12.33%] [learning rate: 3.2e+03]\n",
            "[Step 6188/50000] [Progress: 12.38%] [learning rate: 2.6e+03]\n",
            "[Step 6194/50000] [Time: 65s] [Train Loss: 3.91e-01] [Train Acc: 0.86]\n",
            "[Step 6214/50000] [Progress: 12.43%] [learning rate: 2.8e+03]\n",
            "[Step 6240/50000] [Progress: 12.48%] [learning rate: 3.1e+03]\n",
            "[Step 6241/50000] [Time: 66s] [Train Loss: 3.90e-01] [Train Acc: 0.86]\n",
            "[Step 6263/50000] [Progress: 12.53%] [learning rate: 2.5e+03]\n",
            "[Step 6288/50000] [Time: 66s] [Train Loss: 3.89e-01] [Train Acc: 0.86]\n",
            "[Step 6290/50000] [Progress: 12.58%] [learning rate: 3.0e+03]\n",
            "[Step 6316/50000] [Progress: 12.63%] [learning rate: 3.2e+03]\n",
            "[Step 6335/50000] [Time: 66s] [Train Loss: 3.88e-01] [Train Acc: 0.86]\n",
            "[Step 6339/50000] [Progress: 12.68%] [learning rate: 2.6e+03]\n",
            "[Step 6366/50000] [Progress: 12.73%] [learning rate: 3.1e+03]\n",
            "[Step 6382/50000] [Time: 67s] [Train Loss: 3.87e-01] [Train Acc: 0.86]\n",
            "[Step 6389/50000] [Progress: 12.78%] [learning rate: 2.8e+03]\n",
            "[Step 6414/50000] [Progress: 12.83%] [learning rate: 2.8e+03]\n",
            "[Step 6430/50000] [Time: 67s] [Train Loss: 3.86e-01] [Train Acc: 0.86]\n",
            "[Step 6439/50000] [Progress: 12.88%] [learning rate: 3.0e+03]\n",
            "[Step 6464/50000] [Progress: 12.93%] [learning rate: 2.9e+03]\n",
            "[Step 6478/50000] [Time: 67s] [Train Loss: 3.85e-01] [Train Acc: 0.86]\n",
            "[Step 6490/50000] [Progress: 12.98%] [learning rate: 2.9e+03]\n",
            "[Step 6514/50000] [Progress: 13.03%] [learning rate: 2.9e+03]\n",
            "[Step 6526/50000] [Time: 68s] [Train Loss: 3.84e-01] [Train Acc: 0.86]\n",
            "[Step 6539/50000] [Progress: 13.08%] [learning rate: 2.8e+03]\n",
            "[Step 6565/50000] [Progress: 13.13%] [learning rate: 3.0e+03]\n",
            "[Step 6574/50000] [Time: 68s] [Train Loss: 3.83e-01] [Train Acc: 0.86]\n",
            "[Step 6589/50000] [Progress: 13.18%] [learning rate: 2.7e+03]\n",
            "[Step 6615/50000] [Progress: 13.23%] [learning rate: 3.3e+03]\n",
            "[Step 6623/50000] [Time: 69s] [Train Loss: 3.82e-01] [Train Acc: 0.86]\n",
            "[Step 6638/50000] [Progress: 13.28%] [learning rate: 2.6e+03]\n",
            "[Step 6664/50000] [Progress: 13.33%] [learning rate: 2.9e+03]\n",
            "[Step 6672/50000] [Time: 69s] [Train Loss: 3.81e-01] [Train Acc: 0.86]\n",
            "[Step 6688/50000] [Progress: 13.38%] [learning rate: 2.8e+03]\n",
            "[Step 6713/50000] [Progress: 13.43%] [learning rate: 3.1e+03]\n",
            "[Step 6721/50000] [Time: 69s] [Train Loss: 3.80e-01] [Train Acc: 0.86]\n",
            "[Step 6737/50000] [Progress: 13.47%] [learning rate: 2.7e+03]\n",
            "[Step 6763/50000] [Progress: 13.53%] [learning rate: 3.3e+03]\n",
            "[Step 6770/50000] [Time: 70s] [Train Loss: 3.79e-01] [Train Acc: 0.86]\n",
            "[Step 6786/50000] [Progress: 13.57%] [learning rate: 2.7e+03]\n",
            "[Step 6812/50000] [Progress: 13.62%] [learning rate: 2.9e+03]\n",
            "[Step 6820/50000] [Time: 70s] [Train Loss: 3.78e-01] [Train Acc: 0.86]\n",
            "[Step 6837/50000] [Progress: 13.67%] [learning rate: 2.8e+03]\n",
            "[Step 6863/50000] [Progress: 13.73%] [learning rate: 3.1e+03]\n",
            "[Step 6870/50000] [Time: 70s] [Train Loss: 3.77e-01] [Train Acc: 0.86]\n",
            "[Step 6887/50000] [Progress: 13.77%] [learning rate: 2.8e+03]\n",
            "[Step 6914/50000] [Progress: 13.83%] [learning rate: 3.3e+03]\n",
            "[Step 6920/50000] [Time: 71s] [Train Loss: 3.76e-01] [Train Acc: 0.86]\n",
            "[Step 6938/50000] [Progress: 13.88%] [learning rate: 2.9e+03]\n",
            "[Step 6963/50000] [Progress: 13.93%] [learning rate: 2.9e+03]\n",
            "[Step 6970/50000] [Time: 71s] [Train Loss: 3.75e-01] [Train Acc: 0.86]\n",
            "[Step 6989/50000] [Progress: 13.98%] [learning rate: 3.1e+03]\n",
            "[Step 7012/50000] [Progress: 14.02%] [learning rate: 2.8e+03]\n",
            "[Step 7021/50000] [Time: 71s] [Train Loss: 3.74e-01] [Train Acc: 0.87]\n",
            "[Step 7038/50000] [Progress: 14.08%] [learning rate: 3.0e+03]\n",
            "[Step 7066/50000] [Progress: 14.13%] [learning rate: 3.6e+03]\n",
            "[Step 7072/50000] [Time: 72s] [Train Loss: 3.73e-01] [Train Acc: 0.87]\n",
            "[Step 7089/50000] [Progress: 14.18%] [learning rate: 3.0e+03]\n",
            "[Step 7114/50000] [Progress: 14.23%] [learning rate: 2.9e+03]\n",
            "[Step 7123/50000] [Time: 72s] [Train Loss: 3.72e-01] [Train Acc: 0.87]\n",
            "[Step 7140/50000] [Progress: 14.28%] [learning rate: 2.9e+03]\n",
            "[Step 7165/50000] [Progress: 14.33%] [learning rate: 2.8e+03]\n",
            "[Step 7174/50000] [Time: 72s] [Train Loss: 3.71e-01] [Train Acc: 0.87]\n",
            "[Step 7192/50000] [Progress: 14.38%] [learning rate: 3.4e+03]\n",
            "[Step 7216/50000] [Progress: 14.43%] [learning rate: 3.0e+03]\n",
            "[Step 7226/50000] [Time: 73s] [Train Loss: 3.70e-01] [Train Acc: 0.87]\n",
            "[Step 7242/50000] [Progress: 14.48%] [learning rate: 3.0e+03]\n",
            "[Step 7268/50000] [Progress: 14.54%] [learning rate: 2.9e+03]\n",
            "[Step 7278/50000] [Time: 73s] [Train Loss: 3.69e-01] [Train Acc: 0.87]\n",
            "[Step 7293/50000] [Progress: 14.59%] [learning rate: 2.9e+03]\n",
            "[Step 7319/50000] [Progress: 14.64%] [learning rate: 3.1e+03]\n",
            "[Step 7330/50000] [Time: 73s] [Train Loss: 3.68e-01] [Train Acc: 0.87]\n",
            "[Step 7343/50000] [Progress: 14.69%] [learning rate: 3.1e+03]\n",
            "[Step 7368/50000] [Progress: 14.74%] [learning rate: 3.3e+03]\n",
            "[Step 7382/50000] [Time: 74s] [Train Loss: 3.67e-01] [Train Acc: 0.87]\n",
            "[Step 7391/50000] [Progress: 14.78%] [learning rate: 2.7e+03]\n",
            "[Step 7418/50000] [Progress: 14.84%] [learning rate: 3.2e+03]\n",
            "[Step 7435/50000] [Time: 74s] [Train Loss: 3.66e-01] [Train Acc: 0.87]\n",
            "[Step 7441/50000] [Progress: 14.88%] [learning rate: 2.9e+03]\n",
            "[Step 7466/50000] [Progress: 14.93%] [learning rate: 3.1e+03]\n",
            "[Step 7488/50000] [Time: 75s] [Train Loss: 3.65e-01] [Train Acc: 0.87]\n",
            "[Step 7490/50000] [Progress: 14.98%] [learning rate: 3.1e+03]\n",
            "[Step 7515/50000] [Progress: 15.03%] [learning rate: 3.3e+03]\n",
            "[Step 7538/50000] [Progress: 15.08%] [learning rate: 2.7e+03]\n",
            "[Step 7541/50000] [Time: 75s] [Train Loss: 3.64e-01] [Train Acc: 0.87]\n",
            "[Step 7565/50000] [Progress: 15.13%] [learning rate: 3.2e+03]\n",
            "[Step 7588/50000] [Progress: 15.18%] [learning rate: 2.6e+03]\n",
            "[Step 7594/50000] [Time: 75s] [Train Loss: 3.63e-01] [Train Acc: 0.87]\n",
            "[Step 7615/50000] [Progress: 15.23%] [learning rate: 3.1e+03]\n",
            "[Step 7641/50000] [Progress: 15.28%] [learning rate: 3.1e+03]\n",
            "[Step 7648/50000] [Time: 76s] [Train Loss: 3.63e-01] [Train Acc: 0.87]\n",
            "[Step 7667/50000] [Progress: 15.33%] [learning rate: 3.4e+03]\n",
            "[Step 7690/50000] [Progress: 15.38%] [learning rate: 2.7e+03]\n",
            "[Step 7702/50000] [Time: 76s] [Train Loss: 3.62e-01] [Train Acc: 0.87]\n",
            "[Step 7717/50000] [Progress: 15.43%] [learning rate: 3.3e+03]\n",
            "[Step 7740/50000] [Progress: 15.48%] [learning rate: 2.9e+03]\n",
            "[Step 7756/50000] [Time: 76s] [Train Loss: 3.61e-01] [Train Acc: 0.87]\n",
            "[Step 7765/50000] [Progress: 15.53%] [learning rate: 3.2e+03]\n",
            "[Step 7789/50000] [Progress: 15.58%] [learning rate: 3.1e+03]\n",
            "[Step 7810/50000] [Time: 77s] [Train Loss: 3.60e-01] [Train Acc: 0.87]\n",
            "[Step 7814/50000] [Progress: 15.63%] [learning rate: 3.1e+03]\n",
            "[Step 7838/50000] [Progress: 15.68%] [learning rate: 3.0e+03]\n",
            "[Step 7863/50000] [Progress: 15.73%] [learning rate: 3.0e+03]\n",
            "[Step 7865/50000] [Time: 77s] [Train Loss: 3.59e-01] [Train Acc: 0.87]\n",
            "[Step 7889/50000] [Progress: 15.78%] [learning rate: 3.2e+03]\n",
            "[Step 7913/50000] [Progress: 15.83%] [learning rate: 2.9e+03]\n",
            "[Step 7920/50000] [Time: 78s] [Train Loss: 3.58e-01] [Train Acc: 0.87]\n",
            "[Step 7940/50000] [Progress: 15.88%] [learning rate: 3.1e+03]\n",
            "[Step 7965/50000] [Progress: 15.93%] [learning rate: 3.1e+03]\n",
            "[Step 7975/50000] [Time: 78s] [Train Loss: 3.57e-01] [Train Acc: 0.88]\n",
            "[Step 7991/50000] [Progress: 15.98%] [learning rate: 3.0e+03]\n",
            "[Step 8017/50000] [Progress: 16.03%] [learning rate: 3.0e+03]\n",
            "[Step 8030/50000] [Time: 78s] [Train Loss: 3.56e-01] [Train Acc: 0.88]\n",
            "[Step 8042/50000] [Progress: 16.08%] [learning rate: 2.9e+03]\n",
            "[Step 8069/50000] [Progress: 16.14%] [learning rate: 3.2e+03]\n",
            "[Step 8086/50000] [Time: 79s] [Train Loss: 3.55e-01] [Train Acc: 0.88]\n",
            "[Step 8095/50000] [Progress: 16.19%] [learning rate: 3.1e+03]\n",
            "[Step 8121/50000] [Progress: 16.24%] [learning rate: 3.1e+03]\n",
            "[Step 8142/50000] [Time: 79s] [Train Loss: 3.54e-01] [Train Acc: 0.88]\n",
            "[Step 8145/50000] [Progress: 16.29%] [learning rate: 3.0e+03]\n",
            "[Step 8170/50000] [Progress: 16.34%] [learning rate: 3.0e+03]\n",
            "[Step 8196/50000] [Progress: 16.39%] [learning rate: 3.2e+03]\n",
            "[Step 8198/50000] [Time: 79s] [Train Loss: 3.53e-01] [Train Acc: 0.88]\n",
            "[Step 8220/50000] [Progress: 16.44%] [learning rate: 2.9e+03]\n",
            "[Step 8247/50000] [Progress: 16.49%] [learning rate: 3.5e+03]\n",
            "[Step 8254/50000] [Time: 80s] [Train Loss: 3.52e-01] [Train Acc: 0.88]\n",
            "[Step 8270/50000] [Progress: 16.54%] [learning rate: 2.8e+03]\n",
            "[Step 8296/50000] [Progress: 16.59%] [learning rate: 3.1e+03]\n",
            "[Step 8311/50000] [Time: 80s] [Train Loss: 3.51e-01] [Train Acc: 0.88]\n",
            "[Step 8320/50000] [Progress: 16.64%] [learning rate: 3.0e+03]\n",
            "[Step 8345/50000] [Progress: 16.69%] [learning rate: 3.0e+03]\n",
            "[Step 8368/50000] [Time: 81s] [Train Loss: 3.50e-01] [Train Acc: 0.88]\n",
            "[Step 8370/50000] [Progress: 16.74%] [learning rate: 3.2e+03]\n",
            "[Step 8394/50000] [Progress: 16.79%] [learning rate: 3.2e+03]\n",
            "[Step 8419/50000] [Progress: 16.84%] [learning rate: 3.1e+03]\n",
            "[Step 8425/50000] [Time: 81s] [Train Loss: 3.50e-01] [Train Acc: 0.88]\n",
            "[Step 8445/50000] [Progress: 16.89%] [learning rate: 3.1e+03]\n",
            "[Step 8469/50000] [Progress: 16.94%] [learning rate: 3.0e+03]\n",
            "[Step 8482/50000] [Time: 82s] [Train Loss: 3.49e-01] [Train Acc: 0.88]\n",
            "[Step 8494/50000] [Progress: 16.99%] [learning rate: 3.3e+03]\n",
            "[Step 8518/50000] [Progress: 17.04%] [learning rate: 2.9e+03]\n",
            "[Step 8540/50000] [Time: 82s] [Train Loss: 3.48e-01] [Train Acc: 0.88]\n",
            "[Step 8545/50000] [Progress: 17.09%] [learning rate: 3.5e+03]\n",
            "[Step 8568/50000] [Progress: 17.14%] [learning rate: 2.8e+03]\n",
            "[Step 8595/50000] [Progress: 17.19%] [learning rate: 3.4e+03]\n",
            "[Step 8598/50000] [Time: 83s] [Train Loss: 3.47e-01] [Train Acc: 0.88] [Eval Loss: 5.34e-01] [Eval Acc: 0.74]\n",
            "[Step 8618/50000] [Progress: 17.24%] [learning rate: 3.0e+03]\n",
            "[Step 8643/50000] [Progress: 17.29%] [learning rate: 3.0e+03]\n",
            "[Step 8656/50000] [Time: 85s] [Train Loss: 3.46e-01] [Train Acc: 0.88]\n",
            "[Step 8670/50000] [Progress: 17.34%] [learning rate: 3.2e+03]\n",
            "[Step 8696/50000] [Progress: 17.39%] [learning rate: 3.2e+03]\n",
            "[Step 8714/50000] [Time: 85s] [Train Loss: 3.45e-01] [Train Acc: 0.88]\n",
            "[Step 8722/50000] [Progress: 17.44%] [learning rate: 3.5e+03]\n",
            "[Step 8745/50000] [Progress: 17.49%] [learning rate: 2.8e+03]\n",
            "[Step 8772/50000] [Progress: 17.54%] [learning rate: 3.4e+03]\n",
            "[Step 8773/50000] [Time: 85s] [Train Loss: 3.44e-01] [Train Acc: 0.88]\n",
            "[Step 8795/50000] [Progress: 17.59%] [learning rate: 3.0e+03]\n",
            "[Step 8821/50000] [Progress: 17.64%] [learning rate: 3.3e+03]\n",
            "[Step 8832/50000] [Time: 86s] [Train Loss: 3.43e-01] [Train Acc: 0.88]\n",
            "[Step 8847/50000] [Progress: 17.69%] [learning rate: 3.2e+03]\n",
            "[Step 8873/50000] [Progress: 17.75%] [learning rate: 3.5e+03]\n",
            "[Step 8891/50000] [Time: 86s] [Train Loss: 3.42e-01] [Train Acc: 0.88]\n",
            "[Step 8896/50000] [Progress: 17.79%] [learning rate: 2.8e+03]\n",
            "[Step 8923/50000] [Progress: 17.85%] [learning rate: 3.4e+03]\n",
            "[Step 8946/50000] [Progress: 17.89%] [learning rate: 3.0e+03]\n",
            "[Step 8950/50000] [Time: 87s] [Train Loss: 3.42e-01] [Train Acc: 0.88]\n",
            "[Step 8971/50000] [Progress: 17.94%] [learning rate: 3.3e+03]\n",
            "[Step 8996/50000] [Progress: 17.99%] [learning rate: 3.2e+03]\n",
            "[Step 9010/50000] [Time: 87s] [Train Loss: 3.41e-01] [Train Acc: 0.88]\n",
            "[Step 9022/50000] [Progress: 18.04%] [learning rate: 3.2e+03]\n",
            "[Step 9046/50000] [Progress: 18.09%] [learning rate: 3.1e+03]\n",
            "[Step 9070/50000] [Time: 87s] [Train Loss: 3.40e-01] [Train Acc: 0.88]\n",
            "[Step 9071/50000] [Progress: 18.14%] [learning rate: 3.1e+03]\n",
            "[Step 9097/50000] [Progress: 18.19%] [learning rate: 3.3e+03]\n",
            "[Step 9121/50000] [Progress: 18.24%] [learning rate: 3.0e+03]\n",
            "[Step 9130/50000] [Time: 88s] [Train Loss: 3.39e-01] [Train Acc: 0.88]\n",
            "[Step 9148/50000] [Progress: 18.30%] [learning rate: 3.6e+03]\n",
            "[Step 9171/50000] [Progress: 18.34%] [learning rate: 3.2e+03]\n",
            "[Step 9190/50000] [Time: 88s] [Train Loss: 3.38e-01] [Train Acc: 0.89]\n",
            "[Step 9195/50000] [Progress: 18.39%] [learning rate: 3.1e+03]\n",
            "[Step 9220/50000] [Progress: 18.44%] [learning rate: 3.1e+03]\n",
            "[Step 9245/50000] [Progress: 18.49%] [learning rate: 3.0e+03]\n",
            "[Step 9251/50000] [Time: 89s] [Train Loss: 3.37e-01] [Train Acc: 0.89]\n",
            "[Step 9272/50000] [Progress: 18.54%] [learning rate: 3.3e+03]\n",
            "[Step 9298/50000] [Progress: 18.60%] [learning rate: 3.3e+03]\n",
            "[Step 9312/50000] [Time: 89s] [Train Loss: 3.36e-01] [Train Acc: 0.89]\n",
            "[Step 9324/50000] [Progress: 18.65%] [learning rate: 3.5e+03]\n",
            "[Step 9347/50000] [Progress: 18.69%] [learning rate: 2.9e+03]\n",
            "[Step 9373/50000] [Time: 89s] [Train Loss: 3.35e-01] [Train Acc: 0.89]\n",
            "[Step 9374/50000] [Progress: 18.75%] [learning rate: 3.4e+03]\n",
            "[Step 9397/50000] [Progress: 18.79%] [learning rate: 3.1e+03]\n",
            "[Step 9423/50000] [Progress: 18.85%] [learning rate: 3.3e+03]\n",
            "[Step 9434/50000] [Time: 90s] [Train Loss: 3.35e-01] [Train Acc: 0.89]\n",
            "[Step 9449/50000] [Progress: 18.90%] [learning rate: 3.3e+03]\n",
            "[Step 9475/50000] [Progress: 18.95%] [learning rate: 3.5e+03]\n",
            "[Step 9496/50000] [Time: 90s] [Train Loss: 3.34e-01] [Train Acc: 0.89]\n",
            "[Step 9498/50000] [Progress: 19.00%] [learning rate: 2.9e+03]\n",
            "[Step 9525/50000] [Progress: 19.05%] [learning rate: 3.4e+03]\n",
            "[Step 9548/50000] [Progress: 19.10%] [learning rate: 3.1e+03]\n",
            "[Step 9558/50000] [Time: 91s] [Train Loss: 3.33e-01] [Train Acc: 0.89]\n",
            "[Step 9574/50000] [Progress: 19.15%] [learning rate: 3.3e+03]\n",
            "[Step 9600/50000] [Progress: 19.20%] [learning rate: 3.3e+03]\n",
            "[Step 9620/50000] [Time: 91s] [Train Loss: 3.32e-01] [Train Acc: 0.89]\n",
            "[Step 9626/50000] [Progress: 19.25%] [learning rate: 3.6e+03]\n",
            "[Step 9649/50000] [Progress: 19.30%] [learning rate: 2.9e+03]\n",
            "[Step 9676/50000] [Progress: 19.35%] [learning rate: 3.4e+03]\n",
            "[Step 9682/50000] [Time: 92s] [Train Loss: 3.31e-01] [Train Acc: 0.89]\n",
            "[Step 9699/50000] [Progress: 19.40%] [learning rate: 3.1e+03]\n",
            "[Step 9724/50000] [Progress: 19.45%] [learning rate: 3.3e+03]\n",
            "[Step 9745/50000] [Time: 92s] [Train Loss: 3.30e-01] [Train Acc: 0.89]\n",
            "[Step 9749/50000] [Progress: 19.50%] [learning rate: 3.3e+03]\n",
            "[Step 9775/50000] [Progress: 19.55%] [learning rate: 3.6e+03]\n",
            "[Step 9798/50000] [Progress: 19.60%] [learning rate: 2.9e+03]\n",
            "[Step 9808/50000] [Time: 92s] [Train Loss: 3.29e-01] [Train Acc: 0.89]\n",
            "[Step 9825/50000] [Progress: 19.65%] [learning rate: 3.5e+03]\n",
            "[Step 9848/50000] [Progress: 19.70%] [learning rate: 3.1e+03]\n",
            "[Step 9871/50000] [Time: 93s] [Train Loss: 3.29e-01] [Train Acc: 0.89]\n",
            "[Step 9874/50000] [Progress: 19.75%] [learning rate: 3.4e+03]\n",
            "[Step 9900/50000] [Progress: 19.80%] [learning rate: 3.3e+03]\n",
            "[Step 9926/50000] [Progress: 19.85%] [learning rate: 3.6e+03]\n",
            "[Step 9934/50000] [Time: 93s] [Train Loss: 3.28e-01] [Train Acc: 0.89]\n",
            "[Step 9949/50000] [Progress: 19.90%] [learning rate: 2.9e+03]\n",
            "[Step 9976/50000] [Progress: 19.95%] [learning rate: 3.5e+03]\n",
            "[Step 9997/50000] [Time: 94s] [Train Loss: 3.27e-01] [Train Acc: 0.89]\n",
            "[Step 9999/50000] [Progress: 20.00%] [learning rate: 3.1e+03]\n",
            "[Step 10025/50000] [Progress: 20.05%] [learning rate: 3.4e+03]\n",
            "[Step 10051/50000] [Progress: 20.10%] [learning rate: 3.3e+03]\n",
            "[Step 10061/50000] [Time: 94s] [Train Loss: 3.26e-01] [Train Acc: 0.89]\n",
            "[Step 10077/50000] [Progress: 20.15%] [learning rate: 3.6e+03]\n",
            "[Step 10100/50000] [Progress: 20.20%] [learning rate: 2.9e+03]\n",
            "[Step 10125/50000] [Time: 95s] [Train Loss: 3.25e-01] [Train Acc: 0.89]\n",
            "[Step 10127/50000] [Progress: 20.25%] [learning rate: 3.5e+03]\n",
            "[Step 10150/50000] [Progress: 20.30%] [learning rate: 3.1e+03]\n",
            "[Step 10176/50000] [Progress: 20.35%] [learning rate: 3.4e+03]\n",
            "[Step 10189/50000] [Time: 95s] [Train Loss: 3.24e-01] [Train Acc: 0.89]\n",
            "[Step 10202/50000] [Progress: 20.40%] [learning rate: 3.3e+03]\n",
            "[Step 10228/50000] [Progress: 20.46%] [learning rate: 3.6e+03]\n",
            "[Step 10251/50000] [Progress: 20.50%] [learning rate: 2.9e+03]\n",
            "[Step 10253/50000] [Time: 96s] [Train Loss: 3.24e-01] [Train Acc: 0.89]\n",
            "[Step 10278/50000] [Progress: 20.56%] [learning rate: 3.5e+03]\n",
            "[Step 10301/50000] [Progress: 20.60%] [learning rate: 3.1e+03]\n",
            "[Step 10318/50000] [Time: 96s] [Train Loss: 3.23e-01] [Train Acc: 0.89]\n",
            "[Step 10327/50000] [Progress: 20.65%] [learning rate: 3.4e+03]\n",
            "[Step 10353/50000] [Progress: 20.71%] [learning rate: 3.4e+03]\n",
            "[Step 10379/50000] [Progress: 20.76%] [learning rate: 3.6e+03]\n",
            "[Step 10383/50000] [Time: 97s] [Train Loss: 3.22e-01] [Train Acc: 0.89]\n",
            "[Step 10402/50000] [Progress: 20.80%] [learning rate: 3.0e+03]\n",
            "[Step 10429/50000] [Progress: 20.86%] [learning rate: 3.5e+03]\n",
            "[Step 10448/50000] [Time: 97s] [Train Loss: 3.21e-01] [Train Acc: 0.90]\n",
            "[Step 10452/50000] [Progress: 20.90%] [learning rate: 3.2e+03]\n",
            "[Step 10478/50000] [Progress: 20.96%] [learning rate: 3.4e+03]\n",
            "[Step 10504/50000] [Progress: 21.01%] [learning rate: 3.4e+03]\n",
            "[Step 10513/50000] [Time: 98s] [Train Loss: 3.20e-01] [Train Acc: 0.90]\n",
            "[Step 10530/50000] [Progress: 21.06%] [learning rate: 3.7e+03]\n",
            "[Step 10553/50000] [Progress: 21.11%] [learning rate: 3.0e+03]\n",
            "[Step 10579/50000] [Time: 98s] [Train Loss: 3.19e-01] [Train Acc: 0.90]\n",
            "[Step 10580/50000] [Progress: 21.16%] [learning rate: 3.5e+03]\n",
            "[Step 10603/50000] [Progress: 21.21%] [learning rate: 3.2e+03]\n",
            "[Step 10628/50000] [Progress: 21.26%] [learning rate: 3.4e+03]\n",
            "[Step 10645/50000] [Time: 98s] [Train Loss: 3.19e-01] [Train Acc: 0.90]\n",
            "[Step 10653/50000] [Progress: 21.31%] [learning rate: 3.4e+03]\n",
            "[Step 10679/50000] [Progress: 21.36%] [learning rate: 3.7e+03]\n",
            "[Step 10702/50000] [Progress: 21.40%] [learning rate: 3.0e+03]\n",
            "[Step 10711/50000] [Time: 99s] [Train Loss: 3.18e-01] [Train Acc: 0.90]\n",
            "[Step 10729/50000] [Progress: 21.46%] [learning rate: 3.6e+03]\n",
            "[Step 10752/50000] [Progress: 21.50%] [learning rate: 3.2e+03]\n",
            "[Step 10777/50000] [Time: 99s] [Train Loss: 3.17e-01] [Train Acc: 0.90]\n",
            "[Step 10778/50000] [Progress: 21.56%] [learning rate: 3.5e+03]\n",
            "[Step 10804/50000] [Progress: 21.61%] [learning rate: 3.4e+03]\n",
            "[Step 10830/50000] [Progress: 21.66%] [learning rate: 3.7e+03]\n",
            "[Step 10843/50000] [Time: 100s] [Train Loss: 3.16e-01] [Train Acc: 0.90]\n",
            "[Step 10853/50000] [Progress: 21.71%] [learning rate: 3.0e+03]\n",
            "[Step 10880/50000] [Progress: 21.76%] [learning rate: 3.6e+03]\n",
            "[Step 10903/50000] [Progress: 21.81%] [learning rate: 3.2e+03]\n",
            "[Step 10910/50000] [Time: 100s] [Train Loss: 3.15e-01] [Train Acc: 0.90]\n",
            "[Step 10928/50000] [Progress: 21.86%] [learning rate: 3.5e+03]\n",
            "[Step 10953/50000] [Progress: 21.91%] [learning rate: 3.4e+03]\n",
            "[Step 10977/50000] [Time: 101s] [Train Loss: 3.15e-01] [Train Acc: 0.90]\n",
            "[Step 10979/50000] [Progress: 21.96%] [learning rate: 3.7e+03]\n",
            "[Step 11002/50000] [Progress: 22.00%] [learning rate: 3.0e+03]\n",
            "[Step 11029/50000] [Progress: 22.06%] [learning rate: 3.6e+03]\n",
            "[Step 11044/50000] [Time: 101s] [Train Loss: 3.14e-01] [Train Acc: 0.90]\n",
            "[Step 11052/50000] [Progress: 22.10%] [learning rate: 3.2e+03]\n",
            "[Step 11077/50000] [Progress: 22.15%] [learning rate: 3.5e+03]\n",
            "[Step 11102/50000] [Progress: 22.20%] [learning rate: 3.4e+03]\n",
            "[Step 11111/50000] [Time: 102s] [Train Loss: 3.13e-01] [Train Acc: 0.90]\n",
            "[Step 11128/50000] [Progress: 22.26%] [learning rate: 3.4e+03]\n",
            "[Step 11152/50000] [Progress: 22.30%] [learning rate: 3.3e+03]\n",
            "[Step 11177/50000] [Progress: 22.35%] [learning rate: 3.3e+03]\n",
            "[Step 11179/50000] [Time: 102s] [Train Loss: 3.12e-01] [Train Acc: 0.90]\n",
            "[Step 11203/50000] [Progress: 22.41%] [learning rate: 3.6e+03]\n",
            "[Step 11227/50000] [Progress: 22.45%] [learning rate: 3.2e+03]\n",
            "[Step 11247/50000] [Time: 103s] [Train Loss: 3.11e-01] [Train Acc: 0.90]\n",
            "[Step 11254/50000] [Progress: 22.51%] [learning rate: 3.8e+03]\n",
            "[Step 11277/50000] [Progress: 22.55%] [learning rate: 3.1e+03]\n",
            "[Step 11303/50000] [Progress: 22.61%] [learning rate: 3.3e+03]\n",
            "[Step 11315/50000] [Time: 103s] [Train Loss: 3.11e-01] [Train Acc: 0.90]\n",
            "[Step 11327/50000] [Progress: 22.65%] [learning rate: 3.3e+03]\n",
            "[Step 11352/50000] [Progress: 22.70%] [learning rate: 3.6e+03]\n",
            "[Step 11376/50000] [Progress: 22.75%] [learning rate: 3.2e+03]\n",
            "[Step 11383/50000] [Time: 104s] [Train Loss: 3.10e-01] [Train Acc: 0.90]\n",
            "[Step 11403/50000] [Progress: 22.81%] [learning rate: 3.8e+03]\n",
            "[Step 11426/50000] [Progress: 22.85%] [learning rate: 3.1e+03]\n",
            "[Step 11451/50000] [Time: 104s] [Train Loss: 3.09e-01] [Train Acc: 0.90]\n",
            "[Step 11452/50000] [Progress: 22.90%] [learning rate: 3.4e+03]\n",
            "[Step 11478/50000] [Progress: 22.96%] [learning rate: 3.6e+03]\n",
            "[Step 11501/50000] [Progress: 23.00%] [learning rate: 3.0e+03]\n",
            "[Step 11520/50000] [Time: 104s] [Train Loss: 3.08e-01] [Train Acc: 0.90]\n",
            "[Step 11528/50000] [Progress: 23.06%] [learning rate: 3.5e+03]\n",
            "[Step 11554/50000] [Progress: 23.11%] [learning rate: 3.5e+03]\n",
            "[Step 11580/50000] [Progress: 23.16%] [learning rate: 3.8e+03]\n",
            "[Step 11589/50000] [Time: 105s] [Train Loss: 3.08e-01] [Train Acc: 0.91]\n",
            "[Step 11603/50000] [Progress: 23.21%] [learning rate: 3.1e+03]\n",
            "[Step 11630/50000] [Progress: 23.26%] [learning rate: 3.7e+03]\n",
            "[Step 11653/50000] [Progress: 23.31%] [learning rate: 3.3e+03]\n",
            "[Step 11658/50000] [Time: 105s] [Train Loss: 3.07e-01] [Train Acc: 0.91]\n",
            "[Step 11679/50000] [Progress: 23.36%] [learning rate: 3.5e+03]\n",
            "[Step 11705/50000] [Progress: 23.41%] [learning rate: 3.5e+03]\n",
            "[Step 11727/50000] [Time: 106s] [Train Loss: 3.06e-01] [Train Acc: 0.91]\n",
            "[Step 11731/50000] [Progress: 23.46%] [learning rate: 3.4e+03]\n",
            "[Step 11755/50000] [Progress: 23.51%] [learning rate: 3.4e+03]\n",
            "[Step 11780/50000] [Progress: 23.56%] [learning rate: 3.3e+03]\n",
            "[Step 11797/50000] [Time: 106s] [Train Loss: 3.05e-01] [Train Acc: 0.91] [Eval Loss: 5.19e-01] [Eval Acc: 0.75]\n",
            "[Step 11806/50000] [Progress: 23.61%] [learning rate: 3.6e+03]\n",
            "[Step 11830/50000] [Progress: 23.66%] [learning rate: 3.2e+03]\n",
            "[Step 11857/50000] [Progress: 23.71%] [learning rate: 3.9e+03]\n",
            "[Step 11867/50000] [Time: 109s] [Train Loss: 3.04e-01] [Train Acc: 0.91]\n",
            "[Step 11880/50000] [Progress: 23.76%] [learning rate: 3.1e+03]\n",
            "[Step 11906/50000] [Progress: 23.81%] [learning rate: 3.4e+03]\n",
            "[Step 11932/50000] [Progress: 23.86%] [learning rate: 3.7e+03]\n",
            "[Step 11937/50000] [Time: 109s] [Train Loss: 3.04e-01] [Train Acc: 0.91]\n",
            "[Step 11955/50000] [Progress: 23.91%] [learning rate: 3.0e+03]\n",
            "[Step 11982/50000] [Progress: 23.96%] [learning rate: 3.6e+03]\n",
            "[Step 12007/50000] [Time: 110s] [Train Loss: 3.03e-01] [Train Acc: 0.91]\n",
            "[Step 12008/50000] [Progress: 24.02%] [learning rate: 3.5e+03]\n",
            "[Step 12034/50000] [Progress: 24.07%] [learning rate: 3.8e+03]\n",
            "[Step 12057/50000] [Progress: 24.11%] [learning rate: 3.1e+03]\n",
            "[Step 12077/50000] [Time: 110s] [Train Loss: 3.02e-01] [Train Acc: 0.91]\n",
            "[Step 12084/50000] [Progress: 24.17%] [learning rate: 3.7e+03]\n",
            "[Step 12107/50000] [Progress: 24.21%] [learning rate: 3.3e+03]\n",
            "[Step 12132/50000] [Progress: 24.26%] [learning rate: 3.6e+03]\n",
            "[Step 12148/50000] [Time: 111s] [Train Loss: 3.01e-01] [Train Acc: 0.91]\n",
            "[Step 12156/50000] [Progress: 24.31%] [learning rate: 3.5e+03]\n",
            "[Step 12181/50000] [Progress: 24.36%] [learning rate: 3.5e+03]\n",
            "[Step 12205/50000] [Progress: 24.41%] [learning rate: 3.4e+03]\n",
            "[Step 12219/50000] [Time: 111s] [Train Loss: 3.01e-01] [Train Acc: 0.91]\n",
            "[Step 12230/50000] [Progress: 24.46%] [learning rate: 3.4e+03]\n",
            "[Step 12256/50000] [Progress: 24.51%] [learning rate: 3.7e+03]\n",
            "[Step 12280/50000] [Progress: 24.56%] [learning rate: 3.3e+03]\n",
            "[Step 12290/50000] [Time: 112s] [Train Loss: 3.00e-01] [Train Acc: 0.91]\n",
            "[Step 12307/50000] [Progress: 24.61%] [learning rate: 3.6e+03]\n",
            "[Step 12332/50000] [Progress: 24.66%] [learning rate: 3.5e+03]\n",
            "[Step 12358/50000] [Progress: 24.72%] [learning rate: 3.4e+03]\n",
            "[Step 12361/50000] [Time: 112s] [Train Loss: 2.99e-01] [Train Acc: 0.91]\n",
            "[Step 12384/50000] [Progress: 24.77%] [learning rate: 3.4e+03]\n",
            "[Step 12409/50000] [Progress: 24.82%] [learning rate: 3.3e+03]\n",
            "[Step 12432/50000] [Time: 113s] [Train Loss: 2.98e-01] [Train Acc: 0.91]\n",
            "[Step 12436/50000] [Progress: 24.87%] [learning rate: 3.6e+03]\n",
            "[Step 12461/50000] [Progress: 24.92%] [learning rate: 3.6e+03]\n",
            "[Step 12486/50000] [Progress: 24.97%] [learning rate: 3.9e+03]\n",
            "[Step 12504/50000] [Time: 113s] [Train Loss: 2.98e-01] [Train Acc: 0.91]\n",
            "[Step 12509/50000] [Progress: 25.02%] [learning rate: 3.1e+03]\n",
            "[Step 12536/50000] [Progress: 25.07%] [learning rate: 3.8e+03]\n",
            "[Step 12559/50000] [Progress: 25.12%] [learning rate: 3.4e+03]\n",
            "[Step 12576/50000] [Time: 114s] [Train Loss: 2.97e-01] [Train Acc: 0.91]\n",
            "[Step 12584/50000] [Progress: 25.17%] [learning rate: 3.6e+03]\n",
            "[Step 12608/50000] [Progress: 25.22%] [learning rate: 3.6e+03]\n",
            "[Step 12633/50000] [Progress: 25.27%] [learning rate: 3.5e+03]\n",
            "[Step 12648/50000] [Time: 114s] [Train Loss: 2.96e-01] [Train Acc: 0.91]\n",
            "[Step 12657/50000] [Progress: 25.31%] [learning rate: 3.5e+03]\n",
            "[Step 12682/50000] [Progress: 25.36%] [learning rate: 3.4e+03]\n",
            "[Step 12708/50000] [Progress: 25.42%] [learning rate: 3.7e+03]\n",
            "[Step 12720/50000] [Time: 115s] [Train Loss: 2.96e-01] [Train Acc: 0.91]\n",
            "[Step 12731/50000] [Progress: 25.46%] [learning rate: 3.3e+03]\n",
            "[Step 12757/50000] [Progress: 25.51%] [learning rate: 3.6e+03]\n",
            "[Step 12782/50000] [Progress: 25.56%] [learning rate: 3.5e+03]\n",
            "[Step 12792/50000] [Time: 115s] [Train Loss: 2.95e-01] [Train Acc: 0.91]\n",
            "[Step 12806/50000] [Progress: 25.61%] [learning rate: 3.5e+03]\n",
            "[Step 12831/50000] [Progress: 25.66%] [learning rate: 3.4e+03]\n",
            "[Step 12857/50000] [Progress: 25.71%] [learning rate: 3.4e+03]\n",
            "[Step 12865/50000] [Time: 116s] [Train Loss: 2.94e-01] [Train Acc: 0.91]\n",
            "[Step 12882/50000] [Progress: 25.76%] [learning rate: 3.3e+03]\n",
            "[Step 12908/50000] [Progress: 25.82%] [learning rate: 3.6e+03]\n",
            "[Step 12935/50000] [Progress: 25.87%] [learning rate: 3.9e+03]\n",
            "[Step 12938/50000] [Time: 116s] [Train Loss: 2.93e-01] [Train Acc: 0.91]\n",
            "[Step 12959/50000] [Progress: 25.92%] [learning rate: 3.5e+03]\n",
            "[Step 12984/50000] [Progress: 25.97%] [learning rate: 3.5e+03]\n",
            "[Step 13010/50000] [Progress: 26.02%] [learning rate: 3.4e+03]\n",
            "[Step 13011/50000] [Time: 117s] [Train Loss: 2.93e-01] [Train Acc: 0.91]\n",
            "[Step 13035/50000] [Progress: 26.07%] [learning rate: 3.4e+03]\n",
            "[Step 13062/50000] [Progress: 26.12%] [learning rate: 4.0e+03]\n",
            "[Step 13084/50000] [Time: 117s] [Train Loss: 2.92e-01] [Train Acc: 0.91]\n",
            "[Step 13085/50000] [Progress: 26.17%] [learning rate: 3.6e+03]\n",
            "[Step 13110/50000] [Progress: 26.22%] [learning rate: 3.5e+03]\n",
            "[Step 13136/50000] [Progress: 26.27%] [learning rate: 3.5e+03]\n",
            "[Step 13157/50000] [Time: 118s] [Train Loss: 2.91e-01] [Train Acc: 0.91]\n",
            "[Step 13161/50000] [Progress: 26.32%] [learning rate: 3.4e+03]\n",
            "[Step 13187/50000] [Progress: 26.37%] [learning rate: 3.7e+03]\n",
            "[Step 13211/50000] [Progress: 26.42%] [learning rate: 3.7e+03]\n",
            "[Step 13231/50000] [Time: 118s] [Train Loss: 2.90e-01] [Train Acc: 0.91]\n",
            "[Step 13237/50000] [Progress: 26.47%] [learning rate: 4.0e+03]\n",
            "[Step 13261/50000] [Progress: 26.52%] [learning rate: 3.5e+03]\n",
            "[Step 13286/50000] [Progress: 26.57%] [learning rate: 3.5e+03]\n",
            "[Step 13305/50000] [Time: 119s] [Train Loss: 2.90e-01] [Train Acc: 0.91]\n",
            "[Step 13312/50000] [Progress: 26.62%] [learning rate: 3.4e+03]\n",
            "[Step 13337/50000] [Progress: 26.67%] [learning rate: 3.4e+03]\n",
            "[Step 13364/50000] [Progress: 26.73%] [learning rate: 4.0e+03]\n",
            "[Step 13379/50000] [Time: 120s] [Train Loss: 2.89e-01] [Train Acc: 0.91]\n",
            "[Step 13388/50000] [Progress: 26.78%] [learning rate: 4.0e+03]\n",
            "[Step 13411/50000] [Progress: 26.82%] [learning rate: 3.2e+03]\n",
            "[Step 13437/50000] [Progress: 26.87%] [learning rate: 3.5e+03]\n",
            "[Step 13453/50000] [Time: 120s] [Train Loss: 2.88e-01] [Train Acc: 0.91]\n",
            "[Step 13461/50000] [Progress: 26.92%] [learning rate: 3.5e+03]\n",
            "[Step 13486/50000] [Progress: 26.97%] [learning rate: 3.7e+03]\n",
            "[Step 13510/50000] [Progress: 27.02%] [learning rate: 3.3e+03]\n",
            "[Step 13527/50000] [Time: 121s] [Train Loss: 2.88e-01] [Train Acc: 0.91]\n",
            "[Step 13537/50000] [Progress: 27.07%] [learning rate: 4.4e+03]\n",
            "[Step 13558/50000] [Progress: 27.12%] [learning rate: 3.0e+03]\n",
            "[Step 13587/50000] [Progress: 27.17%] [learning rate: 3.9e+03]\n",
            "[Step 13602/50000] [Time: 121s] [Train Loss: 2.87e-01] [Train Acc: 0.91]\n",
            "[Step 13612/50000] [Progress: 27.22%] [learning rate: 3.5e+03]\n",
            "[Step 13638/50000] [Progress: 27.28%] [learning rate: 3.8e+03]\n",
            "[Step 13662/50000] [Progress: 27.32%] [learning rate: 3.4e+03]\n",
            "[Step 13677/50000] [Time: 122s] [Train Loss: 2.86e-01] [Train Acc: 0.91]\n",
            "[Step 13689/50000] [Progress: 27.38%] [learning rate: 4.0e+03]\n",
            "[Step 13714/50000] [Progress: 27.43%] [learning rate: 3.6e+03]\n",
            "[Step 13740/50000] [Progress: 27.48%] [learning rate: 3.5e+03]\n",
            "[Step 13752/50000] [Time: 122s] [Train Loss: 2.85e-01] [Train Acc: 0.91]\n",
            "[Step 13766/50000] [Progress: 27.53%] [learning rate: 3.5e+03]\n",
            "[Step 13791/50000] [Progress: 27.58%] [learning rate: 3.4e+03]\n",
            "[Step 13816/50000] [Progress: 27.63%] [learning rate: 3.7e+03]\n",
            "[Step 13827/50000] [Time: 123s] [Train Loss: 2.85e-01] [Train Acc: 0.91]\n",
            "[Step 13841/50000] [Progress: 27.68%] [learning rate: 4.0e+03]\n",
            "[Step 13864/50000] [Progress: 27.73%] [learning rate: 3.3e+03]\n",
            "[Step 13891/50000] [Progress: 27.78%] [learning rate: 3.9e+03]\n",
            "[Step 13902/50000] [Time: 123s] [Train Loss: 2.84e-01] [Train Acc: 0.91]\n",
            "[Step 13914/50000] [Progress: 27.83%] [learning rate: 3.5e+03]\n",
            "[Step 13939/50000] [Progress: 27.88%] [learning rate: 3.4e+03]\n",
            "[Step 13964/50000] [Progress: 27.93%] [learning rate: 3.7e+03]\n",
            "[Step 13978/50000] [Time: 124s] [Train Loss: 2.83e-01] [Train Acc: 0.91]\n",
            "[Step 13989/50000] [Progress: 27.98%] [learning rate: 4.0e+03]\n",
            "[Step 14012/50000] [Progress: 28.02%] [learning rate: 3.3e+03]\n",
            "[Step 14039/50000] [Progress: 28.08%] [learning rate: 3.9e+03]\n",
            "[Step 14054/50000] [Time: 124s] [Train Loss: 2.83e-01] [Train Acc: 0.92]\n",
            "[Step 14062/50000] [Progress: 28.12%] [learning rate: 3.5e+03]\n",
            "[Step 14087/50000] [Progress: 28.17%] [learning rate: 3.5e+03]\n",
            "[Step 14112/50000] [Progress: 28.22%] [learning rate: 3.8e+03]\n",
            "[Step 14130/50000] [Time: 125s] [Train Loss: 2.82e-01] [Train Acc: 0.92]\n",
            "[Step 14137/50000] [Progress: 28.27%] [learning rate: 3.7e+03]\n",
            "[Step 14163/50000] [Progress: 28.33%] [learning rate: 4.0e+03]\n",
            "[Step 14186/50000] [Progress: 28.37%] [learning rate: 3.3e+03]\n",
            "[Step 14206/50000] [Time: 126s] [Train Loss: 2.81e-01] [Train Acc: 0.92]\n",
            "[Step 14213/50000] [Progress: 28.43%] [learning rate: 3.9e+03]\n",
            "[Step 14236/50000] [Progress: 28.47%] [learning rate: 3.5e+03]\n",
            "[Step 14262/50000] [Progress: 28.52%] [learning rate: 3.8e+03]\n",
            "[Step 14282/50000] [Time: 126s] [Train Loss: 2.81e-01] [Train Acc: 0.92]\n",
            "[Step 14288/50000] [Progress: 28.58%] [learning rate: 4.1e+03]\n",
            "[Step 14311/50000] [Progress: 28.62%] [learning rate: 3.3e+03]\n",
            "[Step 14338/50000] [Progress: 28.68%] [learning rate: 4.0e+03]\n",
            "[Step 14359/50000] [Time: 127s] [Train Loss: 2.80e-01] [Train Acc: 0.92]\n",
            "[Step 14361/50000] [Progress: 28.72%] [learning rate: 3.2e+03]\n",
            "[Step 14387/50000] [Progress: 28.77%] [learning rate: 3.8e+03]\n",
            "[Step 14411/50000] [Progress: 28.82%] [learning rate: 3.4e+03]\n",
            "[Step 14436/50000] [Time: 127s] [Train Loss: 2.79e-01] [Train Acc: 0.92]\n",
            "[Step 14437/50000] [Progress: 28.87%] [learning rate: 4.1e+03]\n",
            "[Step 14460/50000] [Progress: 28.92%] [learning rate: 3.3e+03]\n",
            "[Step 14487/50000] [Progress: 28.97%] [learning rate: 4.0e+03]\n",
            "[Step 14510/50000] [Progress: 29.02%] [learning rate: 3.2e+03]\n",
            "[Step 14513/50000] [Time: 128s] [Train Loss: 2.79e-01] [Train Acc: 0.92]\n",
            "[Step 14536/50000] [Progress: 29.07%] [learning rate: 3.9e+03]\n",
            "[Step 14560/50000] [Progress: 29.12%] [learning rate: 3.5e+03]\n",
            "[Step 14588/50000] [Progress: 29.18%] [learning rate: 4.1e+03]\n",
            "[Step 14590/50000] [Time: 128s] [Train Loss: 2.78e-01] [Train Acc: 0.92]\n",
            "[Step 14612/50000] [Progress: 29.22%] [learning rate: 3.7e+03]\n",
            "[Step 14637/50000] [Progress: 29.27%] [learning rate: 3.6e+03]\n",
            "[Step 14663/50000] [Progress: 29.33%] [learning rate: 3.6e+03]\n",
            "[Step 14667/50000] [Time: 129s] [Train Loss: 2.77e-01] [Train Acc: 0.92]\n",
            "[Step 14688/50000] [Progress: 29.38%] [learning rate: 3.5e+03]\n",
            "[Step 14715/50000] [Progress: 29.43%] [learning rate: 3.8e+03]\n",
            "[Step 14741/50000] [Progress: 29.48%] [learning rate: 3.8e+03]\n",
            "[Step 14744/50000] [Time: 129s] [Train Loss: 2.76e-01] [Train Acc: 0.92]\n",
            "[Step 14767/50000] [Progress: 29.53%] [learning rate: 4.1e+03]\n",
            "[Step 14790/50000] [Progress: 29.58%] [learning rate: 3.3e+03]\n",
            "[Step 14817/50000] [Progress: 29.63%] [learning rate: 4.0e+03]\n",
            "[Step 14822/50000] [Time: 130s] [Train Loss: 2.76e-01] [Train Acc: 0.92]\n",
            "[Step 14840/50000] [Progress: 29.68%] [learning rate: 3.5e+03]\n",
            "[Step 14865/50000] [Progress: 29.73%] [learning rate: 3.8e+03]\n",
            "[Step 14890/50000] [Progress: 29.78%] [learning rate: 3.8e+03]\n",
            "[Step 14900/50000] [Time: 130s] [Train Loss: 2.75e-01] [Train Acc: 0.92]\n",
            "[Step 14916/50000] [Progress: 29.83%] [learning rate: 3.7e+03]\n",
            "[Step 14940/50000] [Progress: 29.88%] [learning rate: 3.7e+03]\n",
            "[Step 14965/50000] [Progress: 29.93%] [learning rate: 3.6e+03]\n",
            "[Step 14978/50000] [Time: 131s] [Train Loss: 2.75e-01] [Train Acc: 0.92]\n",
            "[Step 14991/50000] [Progress: 29.98%] [learning rate: 3.9e+03]\n",
            "[Step 15015/50000] [Progress: 30.03%] [learning rate: 3.5e+03]\n",
            "[Step 15042/50000] [Progress: 30.08%] [learning rate: 4.2e+03]\n",
            "[Step 15056/50000] [Time: 131s] [Train Loss: 2.74e-01] [Train Acc: 0.92]\n",
            "[Step 15065/50000] [Progress: 30.13%] [learning rate: 3.4e+03]\n",
            "[Step 15091/50000] [Progress: 30.18%] [learning rate: 3.7e+03]\n",
            "[Step 15117/50000] [Progress: 30.23%] [learning rate: 4.0e+03]\n",
            "[Step 15134/50000] [Time: 132s] [Train Loss: 2.73e-01] [Train Acc: 0.92]\n",
            "[Step 15140/50000] [Progress: 30.28%] [learning rate: 3.2e+03]\n",
            "[Step 15167/50000] [Progress: 30.33%] [learning rate: 3.9e+03]\n",
            "[Step 15193/50000] [Progress: 30.39%] [learning rate: 3.8e+03]\n",
            "[Step 15212/50000] [Time: 133s] [Train Loss: 2.73e-01] [Train Acc: 0.92]\n",
            "[Step 15219/50000] [Progress: 30.44%] [learning rate: 4.1e+03]\n",
            "[Step 15242/50000] [Progress: 30.48%] [learning rate: 3.4e+03]\n",
            "[Step 15269/50000] [Progress: 30.54%] [learning rate: 4.0e+03]\n",
            "[Step 15291/50000] [Time: 133s] [Train Loss: 2.72e-01] [Train Acc: 0.92]\n",
            "[Step 15292/50000] [Progress: 30.58%] [learning rate: 3.6e+03]\n",
            "[Step 15317/50000] [Progress: 30.63%] [learning rate: 3.9e+03]\n",
            "[Step 15341/50000] [Progress: 30.68%] [learning rate: 3.8e+03]\n",
            "[Step 15366/50000] [Progress: 30.73%] [learning rate: 3.8e+03]\n",
            "[Step 15370/50000] [Time: 134s] [Train Loss: 2.71e-01] [Train Acc: 0.92]\n",
            "[Step 15390/50000] [Progress: 30.78%] [learning rate: 3.7e+03]\n",
            "[Step 15415/50000] [Progress: 30.83%] [learning rate: 3.7e+03]\n",
            "[Step 15441/50000] [Progress: 30.88%] [learning rate: 4.0e+03]\n",
            "[Step 15449/50000] [Time: 134s] [Train Loss: 2.71e-01] [Train Acc: 0.92]\n",
            "[Step 15464/50000] [Progress: 30.93%] [learning rate: 3.5e+03]\n",
            "[Step 15490/50000] [Progress: 30.98%] [learning rate: 3.8e+03]\n",
            "[Step 15515/50000] [Progress: 31.03%] [learning rate: 3.8e+03]\n",
            "[Step 15528/50000] [Time: 135s] [Train Loss: 2.70e-01] [Train Acc: 0.92] [Eval Loss: 5.11e-01] [Eval Acc: 0.76]\n",
            "[Step 15539/50000] [Progress: 31.08%] [learning rate: 3.7e+03]\n",
            "[Step 15564/50000] [Progress: 31.13%] [learning rate: 3.7e+03]\n",
            "[Step 15590/50000] [Progress: 31.18%] [learning rate: 3.6e+03]\n",
            "[Step 15607/50000] [Time: 137s] [Train Loss: 2.69e-01] [Train Acc: 0.92]\n",
            "[Step 15615/50000] [Progress: 31.23%] [learning rate: 3.6e+03]\n",
            "[Step 15641/50000] [Progress: 31.28%] [learning rate: 3.9e+03]\n",
            "[Step 15668/50000] [Progress: 31.34%] [learning rate: 4.2e+03]\n",
            "[Step 15687/50000] [Time: 138s] [Train Loss: 2.69e-01] [Train Acc: 0.92]\n",
            "[Step 15692/50000] [Progress: 31.38%] [learning rate: 3.7e+03]\n",
            "[Step 15717/50000] [Progress: 31.43%] [learning rate: 3.7e+03]\n",
            "[Step 15743/50000] [Progress: 31.49%] [learning rate: 3.6e+03]\n",
            "[Step 15767/50000] [Time: 138s] [Train Loss: 2.68e-01] [Train Acc: 0.92]\n",
            "[Step 15768/50000] [Progress: 31.54%] [learning rate: 3.6e+03]\n",
            "[Step 15793/50000] [Progress: 31.59%] [learning rate: 3.9e+03]\n",
            "[Step 15819/50000] [Progress: 31.64%] [learning rate: 4.6e+03]\n",
            "[Step 15839/50000] [Progress: 31.68%] [learning rate: 3.1e+03]\n",
            "[Step 15847/50000] [Time: 139s] [Train Loss: 2.67e-01] [Train Acc: 0.92]\n",
            "[Step 15867/50000] [Progress: 31.73%] [learning rate: 4.1e+03]\n",
            "[Step 15892/50000] [Progress: 31.78%] [learning rate: 3.7e+03]\n",
            "[Step 15918/50000] [Progress: 31.84%] [learning rate: 4.0e+03]\n",
            "[Step 15927/50000] [Time: 139s] [Train Loss: 2.67e-01] [Train Acc: 0.92]\n",
            "[Step 15942/50000] [Progress: 31.88%] [learning rate: 3.5e+03]\n",
            "[Step 15969/50000] [Progress: 31.94%] [learning rate: 4.6e+03]\n",
            "[Step 15990/50000] [Progress: 31.98%] [learning rate: 3.1e+03]\n",
            "[Step 16007/50000] [Time: 140s] [Train Loss: 2.66e-01] [Train Acc: 0.92]\n",
            "[Step 16019/50000] [Progress: 32.04%] [learning rate: 4.1e+03]\n",
            "[Step 16044/50000] [Progress: 32.09%] [learning rate: 3.7e+03]\n",
            "[Step 16070/50000] [Progress: 32.14%] [learning rate: 4.0e+03]\n",
            "[Step 16087/50000] [Time: 140s] [Train Loss: 2.65e-01] [Train Acc: 0.92]\n",
            "[Step 16094/50000] [Progress: 32.19%] [learning rate: 3.6e+03]\n",
            "[Step 16122/50000] [Progress: 32.24%] [learning rate: 4.7e+03]\n",
            "[Step 16143/50000] [Progress: 32.29%] [learning rate: 3.1e+03]\n",
            "[Step 16167/50000] [Time: 141s] [Train Loss: 2.65e-01] [Train Acc: 0.92]\n",
            "[Step 16172/50000] [Progress: 32.34%] [learning rate: 4.1e+03]\n",
            "[Step 16197/50000] [Progress: 32.39%] [learning rate: 3.7e+03]\n",
            "[Step 16223/50000] [Progress: 32.45%] [learning rate: 4.0e+03]\n",
            "[Step 16247/50000] [Progress: 32.49%] [learning rate: 3.6e+03]\n",
            "[Step 16248/50000] [Time: 141s] [Train Loss: 2.64e-01] [Train Acc: 0.92]\n",
            "[Step 16275/50000] [Progress: 32.55%] [learning rate: 4.3e+03]\n",
            "[Step 16298/50000] [Progress: 32.60%] [learning rate: 3.5e+03]\n",
            "[Step 16325/50000] [Progress: 32.65%] [learning rate: 4.1e+03]\n",
            "[Step 16329/50000] [Time: 142s] [Train Loss: 2.64e-01] [Train Acc: 0.92]\n",
            "[Step 16348/50000] [Progress: 32.70%] [learning rate: 3.4e+03]\n",
            "[Step 16374/50000] [Progress: 32.75%] [learning rate: 4.0e+03]\n",
            "[Step 16398/50000] [Progress: 32.80%] [learning rate: 3.6e+03]\n",
            "[Step 16410/50000] [Time: 143s] [Train Loss: 2.63e-01] [Train Acc: 0.92]\n",
            "[Step 16424/50000] [Progress: 32.85%] [learning rate: 4.3e+03]\n",
            "[Step 16447/50000] [Progress: 32.89%] [learning rate: 3.5e+03]\n",
            "[Step 16474/50000] [Progress: 32.95%] [learning rate: 4.2e+03]\n",
            "[Step 16491/50000] [Time: 143s] [Train Loss: 2.62e-01] [Train Acc: 0.92]\n",
            "[Step 16497/50000] [Progress: 32.99%] [learning rate: 3.7e+03]\n",
            "[Step 16522/50000] [Progress: 33.04%] [learning rate: 3.7e+03]\n",
            "[Step 16547/50000] [Progress: 33.09%] [learning rate: 4.0e+03]\n",
            "[Step 16572/50000] [Progress: 33.14%] [learning rate: 3.9e+03]\n",
            "[Step 16572/50000] [Time: 144s] [Train Loss: 2.62e-01] [Train Acc: 0.92]\n",
            "[Step 16598/50000] [Progress: 33.20%] [learning rate: 3.8e+03]\n",
            "[Step 16622/50000] [Progress: 33.24%] [learning rate: 3.8e+03]\n",
            "[Step 16647/50000] [Progress: 33.29%] [learning rate: 3.7e+03]\n",
            "[Step 16653/50000] [Time: 144s] [Train Loss: 2.61e-01] [Train Acc: 0.93]\n",
            "[Step 16673/50000] [Progress: 33.35%] [learning rate: 4.0e+03]\n",
            "[Step 16697/50000] [Progress: 33.39%] [learning rate: 3.6e+03]\n",
            "[Step 16725/50000] [Progress: 33.45%] [learning rate: 4.3e+03]\n",
            "[Step 16735/50000] [Time: 145s] [Train Loss: 2.60e-01] [Train Acc: 0.93]\n",
            "[Step 16749/50000] [Progress: 33.50%] [learning rate: 3.9e+03]\n",
            "[Step 16774/50000] [Progress: 33.55%] [learning rate: 3.8e+03]\n",
            "[Step 16800/50000] [Progress: 33.60%] [learning rate: 3.8e+03]\n",
            "[Step 16817/50000] [Time: 146s] [Train Loss: 2.60e-01] [Train Acc: 0.93]\n",
            "[Step 16825/50000] [Progress: 33.65%] [learning rate: 3.7e+03]\n",
            "[Step 16852/50000] [Progress: 33.70%] [learning rate: 4.0e+03]\n",
            "[Step 16878/50000] [Progress: 33.76%] [learning rate: 3.9e+03]\n",
            "[Step 16899/50000] [Time: 146s] [Train Loss: 2.59e-01] [Train Acc: 0.93]\n",
            "[Step 16904/50000] [Progress: 33.81%] [learning rate: 4.3e+03]\n",
            "[Step 16927/50000] [Progress: 33.85%] [learning rate: 3.5e+03]\n",
            "[Step 16954/50000] [Progress: 33.91%] [learning rate: 4.1e+03]\n",
            "[Step 16977/50000] [Progress: 33.95%] [learning rate: 3.7e+03]\n",
            "[Step 16981/50000] [Time: 147s] [Train Loss: 2.59e-01] [Train Acc: 0.93]\n",
            "[Step 17002/50000] [Progress: 34.00%] [learning rate: 4.0e+03]\n",
            "[Step 17027/50000] [Progress: 34.05%] [learning rate: 4.0e+03]\n",
            "[Step 17053/50000] [Progress: 34.11%] [learning rate: 3.9e+03]\n",
            "[Step 17063/50000] [Time: 148s] [Train Loss: 2.58e-01] [Train Acc: 0.93]\n",
            "[Step 17077/50000] [Progress: 34.15%] [learning rate: 3.8e+03]\n",
            "[Step 17102/50000] [Progress: 34.20%] [learning rate: 3.8e+03]\n",
            "[Step 17128/50000] [Progress: 34.26%] [learning rate: 4.1e+03]\n",
            "[Step 17145/50000] [Time: 148s] [Train Loss: 2.57e-01] [Train Acc: 0.93]\n",
            "[Step 17152/50000] [Progress: 34.30%] [learning rate: 3.7e+03]\n",
            "[Step 17179/50000] [Progress: 34.36%] [learning rate: 4.0e+03]\n",
            "[Step 17204/50000] [Progress: 34.41%] [learning rate: 3.9e+03]\n",
            "[Step 17227/50000] [Time: 149s] [Train Loss: 2.57e-01] [Train Acc: 0.93]\n",
            "[Step 17230/50000] [Progress: 34.46%] [learning rate: 3.9e+03]\n",
            "[Step 17256/50000] [Progress: 34.51%] [learning rate: 3.8e+03]\n",
            "[Step 17281/50000] [Progress: 34.56%] [learning rate: 3.7e+03]\n",
            "[Step 17308/50000] [Progress: 34.62%] [learning rate: 4.1e+03]\n",
            "[Step 17310/50000] [Time: 149s] [Train Loss: 2.56e-01] [Train Acc: 0.93]\n",
            "[Step 17333/50000] [Progress: 34.67%] [learning rate: 4.0e+03]\n",
            "[Step 17358/50000] [Progress: 34.72%] [learning rate: 4.3e+03]\n",
            "[Step 17381/50000] [Progress: 34.76%] [learning rate: 3.5e+03]\n",
            "[Step 17393/50000] [Time: 150s] [Train Loss: 2.56e-01] [Train Acc: 0.93]\n",
            "[Step 17408/50000] [Progress: 34.82%] [learning rate: 4.2e+03]\n",
            "[Step 17431/50000] [Progress: 34.86%] [learning rate: 3.8e+03]\n",
            "[Step 17456/50000] [Progress: 34.91%] [learning rate: 4.1e+03]\n",
            "[Step 17476/50000] [Time: 150s] [Train Loss: 2.55e-01] [Train Acc: 0.93]\n",
            "[Step 17480/50000] [Progress: 34.96%] [learning rate: 4.0e+03]\n",
            "[Step 17505/50000] [Progress: 35.01%] [learning rate: 4.3e+03]\n",
            "[Step 17528/50000] [Progress: 35.06%] [learning rate: 3.5e+03]\n",
            "[Step 17555/50000] [Progress: 35.11%] [learning rate: 4.2e+03]\n",
            "[Step 17559/50000] [Time: 151s] [Train Loss: 2.54e-01] [Train Acc: 0.93]\n",
            "[Step 17578/50000] [Progress: 35.16%] [learning rate: 3.4e+03]\n",
            "[Step 17605/50000] [Progress: 35.21%] [learning rate: 4.1e+03]\n",
            "[Step 17630/50000] [Progress: 35.26%] [learning rate: 4.0e+03]\n",
            "[Step 17642/50000] [Time: 152s] [Train Loss: 2.54e-01] [Train Acc: 0.93]\n",
            "[Step 17656/50000] [Progress: 35.31%] [learning rate: 4.4e+03]\n",
            "[Step 17680/50000] [Progress: 35.36%] [learning rate: 3.9e+03]\n",
            "[Step 17705/50000] [Progress: 35.41%] [learning rate: 3.9e+03]\n",
            "[Step 17725/50000] [Time: 152s] [Train Loss: 2.53e-01] [Train Acc: 0.93]\n",
            "[Step 17731/50000] [Progress: 35.46%] [learning rate: 3.8e+03]\n",
            "[Step 17756/50000] [Progress: 35.51%] [learning rate: 3.7e+03]\n",
            "[Step 17781/50000] [Progress: 35.56%] [learning rate: 4.1e+03]\n",
            "[Step 17808/50000] [Progress: 35.62%] [learning rate: 5.3e+03]\n",
            "[Step 17809/50000] [Time: 153s] [Train Loss: 2.53e-01] [Train Acc: 0.93]\n",
            "[Step 17825/50000] [Progress: 35.65%] [learning rate: 2.4e+03]\n",
            "[Step 17856/50000] [Progress: 35.71%] [learning rate: 4.7e+03]\n",
            "[Step 17877/50000] [Progress: 35.75%] [learning rate: 3.2e+03]\n",
            "[Step 17893/50000] [Time: 153s] [Train Loss: 2.52e-01] [Train Acc: 0.93]\n",
            "[Step 17905/50000] [Progress: 35.81%] [learning rate: 4.5e+03]\n",
            "[Step 17927/50000] [Progress: 35.85%] [learning rate: 3.4e+03]\n",
            "[Step 17955/50000] [Progress: 35.91%] [learning rate: 4.8e+03]\n",
            "[Step 17976/50000] [Progress: 35.95%] [learning rate: 3.3e+03]\n",
            "[Step 17977/50000] [Time: 154s] [Train Loss: 2.51e-01] [Train Acc: 0.93]\n",
            "[Step 18005/50000] [Progress: 36.01%] [learning rate: 4.3e+03]\n",
            "[Step 18029/50000] [Progress: 36.06%] [learning rate: 3.8e+03]\n",
            "[Step 18054/50000] [Progress: 36.11%] [learning rate: 4.1e+03]\n",
            "[Step 18061/50000] [Time: 154s] [Train Loss: 2.51e-01] [Train Acc: 0.93]\n",
            "[Step 18078/50000] [Progress: 36.16%] [learning rate: 3.7e+03]\n",
            "[Step 18106/50000] [Progress: 36.21%] [learning rate: 4.4e+03]\n",
            "[Step 18129/50000] [Progress: 36.26%] [learning rate: 3.6e+03]\n",
            "[Step 18145/50000] [Time: 155s] [Train Loss: 2.50e-01] [Train Acc: 0.93]\n",
            "[Step 18156/50000] [Progress: 36.31%] [learning rate: 4.3e+03]\n",
            "[Step 18179/50000] [Progress: 36.36%] [learning rate: 3.5e+03]\n",
            "[Step 18205/50000] [Progress: 36.41%] [learning rate: 4.2e+03]\n",
            "[Step 18229/50000] [Progress: 36.46%] [learning rate: 3.7e+03]\n",
            "[Step 18229/50000] [Time: 155s] [Train Loss: 2.50e-01] [Train Acc: 0.93]\n",
            "[Step 18255/50000] [Progress: 36.51%] [learning rate: 4.4e+03]\n",
            "[Step 18278/50000] [Progress: 36.56%] [learning rate: 3.6e+03]\n",
            "[Step 18305/50000] [Progress: 36.61%] [learning rate: 4.3e+03]\n",
            "[Step 18313/50000] [Time: 156s] [Train Loss: 2.49e-01] [Train Acc: 0.93]\n",
            "[Step 18328/50000] [Progress: 36.66%] [learning rate: 3.9e+03]\n",
            "[Step 18353/50000] [Progress: 36.71%] [learning rate: 3.8e+03]\n",
            "[Step 18378/50000] [Progress: 36.76%] [learning rate: 4.1e+03]\n",
            "[Step 18397/50000] [Time: 157s] [Train Loss: 2.49e-01] [Train Acc: 0.93]\n",
            "[Step 18403/50000] [Progress: 36.81%] [learning rate: 4.1e+03]\n",
            "[Step 18429/50000] [Progress: 36.86%] [learning rate: 4.0e+03]\n",
            "[Step 18453/50000] [Progress: 36.91%] [learning rate: 3.9e+03]\n",
            "[Step 18478/50000] [Progress: 36.96%] [learning rate: 3.9e+03]\n",
            "[Step 18482/50000] [Time: 157s] [Train Loss: 2.48e-01] [Train Acc: 0.93]\n",
            "[Step 18504/50000] [Progress: 37.01%] [learning rate: 4.2e+03]\n",
            "[Step 18528/50000] [Progress: 37.06%] [learning rate: 3.8e+03]\n",
            "[Step 18555/50000] [Progress: 37.11%] [learning rate: 4.5e+03]\n",
            "[Step 18567/50000] [Time: 158s] [Train Loss: 2.47e-01] [Train Acc: 0.93]\n",
            "[Step 18578/50000] [Progress: 37.16%] [learning rate: 3.7e+03]\n",
            "[Step 18604/50000] [Progress: 37.21%] [learning rate: 4.0e+03]\n",
            "[Step 18628/50000] [Progress: 37.26%] [learning rate: 3.9e+03]\n",
            "[Step 18652/50000] [Time: 159s] [Train Loss: 2.47e-01] [Train Acc: 0.93]\n",
            "[Step 18653/50000] [Progress: 37.31%] [learning rate: 4.2e+03]\n",
            "[Step 18677/50000] [Progress: 37.35%] [learning rate: 3.8e+03]\n",
            "[Step 18704/50000] [Progress: 37.41%] [learning rate: 4.5e+03]\n",
            "[Step 18727/50000] [Progress: 37.45%] [learning rate: 3.7e+03]\n",
            "[Step 18737/50000] [Time: 159s] [Train Loss: 2.46e-01] [Train Acc: 0.93]\n",
            "[Step 18754/50000] [Progress: 37.51%] [learning rate: 4.4e+03]\n",
            "[Step 18777/50000] [Progress: 37.55%] [learning rate: 3.9e+03]\n",
            "[Step 18802/50000] [Progress: 37.60%] [learning rate: 3.9e+03]\n",
            "[Step 18822/50000] [Time: 160s] [Train Loss: 2.46e-01] [Train Acc: 0.93]\n",
            "[Step 18829/50000] [Progress: 37.66%] [learning rate: 4.2e+03]\n",
            "[Step 18855/50000] [Progress: 37.71%] [learning rate: 4.1e+03]\n",
            "[Step 18881/50000] [Progress: 37.76%] [learning rate: 4.5e+03]\n",
            "[Step 18904/50000] [Progress: 37.81%] [learning rate: 3.6e+03]\n",
            "[Step 18907/50000] [Time: 160s] [Train Loss: 2.45e-01] [Train Acc: 0.93]\n",
            "[Step 18931/50000] [Progress: 37.86%] [learning rate: 4.3e+03]\n",
            "[Step 18954/50000] [Progress: 37.91%] [learning rate: 3.9e+03]\n",
            "[Step 18979/50000] [Progress: 37.96%] [learning rate: 4.2e+03]\n",
            "[Step 18992/50000] [Time: 161s] [Train Loss: 2.45e-01] [Train Acc: 0.93]\n",
            "[Step 19003/50000] [Progress: 38.01%] [learning rate: 4.1e+03]\n",
            "[Step 19028/50000] [Progress: 38.06%] [learning rate: 4.1e+03]\n",
            "[Step 19052/50000] [Progress: 38.10%] [learning rate: 4.0e+03]\n",
            "[Step 19077/50000] [Progress: 38.15%] [learning rate: 4.0e+03]\n",
            "[Step 19078/50000] [Time: 162s] [Train Loss: 2.44e-01] [Train Acc: 0.93]\n",
            "[Step 19103/50000] [Progress: 38.21%] [learning rate: 4.3e+03]\n",
            "[Step 19126/50000] [Progress: 38.25%] [learning rate: 3.8e+03]\n",
            "[Step 19152/50000] [Progress: 38.30%] [learning rate: 4.2e+03]\n",
            "[Step 19164/50000] [Time: 162s] [Train Loss: 2.44e-01] [Train Acc: 0.93]\n",
            "[Step 19177/50000] [Progress: 38.35%] [learning rate: 4.1e+03]\n",
            "[Step 19201/50000] [Progress: 38.40%] [learning rate: 4.0e+03]\n",
            "[Step 19226/50000] [Progress: 38.45%] [learning rate: 4.0e+03]\n",
            "[Step 19250/50000] [Time: 163s] [Train Loss: 2.43e-01] [Train Acc: 0.93]\n",
            "[Step 19252/50000] [Progress: 38.50%] [learning rate: 3.9e+03]\n",
            "[Step 19277/50000] [Progress: 38.55%] [learning rate: 3.9e+03]\n",
            "[Step 19303/50000] [Progress: 38.61%] [learning rate: 4.2e+03]\n",
            "[Step 19330/50000] [Progress: 38.66%] [learning rate: 4.5e+03]\n",
            "[Step 19336/50000] [Time: 163s] [Train Loss: 2.42e-01] [Train Acc: 0.93]\n",
            "[Step 19352/50000] [Progress: 38.70%] [learning rate: 3.7e+03]\n",
            "[Step 19378/50000] [Progress: 38.76%] [learning rate: 4.4e+03]\n",
            "[Step 19401/50000] [Progress: 38.80%] [learning rate: 3.9e+03]\n",
            "[Step 19422/50000] [Time: 164s] [Train Loss: 2.42e-01] [Train Acc: 0.93]\n",
            "[Step 19426/50000] [Progress: 38.85%] [learning rate: 4.3e+03]\n",
            "[Step 19450/50000] [Progress: 38.90%] [learning rate: 3.8e+03]\n",
            "[Step 19479/50000] [Progress: 38.96%] [learning rate: 5.0e+03]\n",
            "[Step 19502/50000] [Progress: 39.00%] [learning rate: 3.7e+03]\n",
            "[Step 19508/50000] [Time: 165s] [Train Loss: 2.41e-01] [Train Acc: 0.93]\n",
            "[Step 19528/50000] [Progress: 39.06%] [learning rate: 4.0e+03]\n",
            "[Step 19553/50000] [Progress: 39.11%] [learning rate: 3.9e+03]\n",
            "[Step 19579/50000] [Progress: 39.16%] [learning rate: 4.3e+03]\n",
            "[Step 19594/50000] [Time: 165s] [Train Loss: 2.41e-01] [Train Acc: 0.93]\n",
            "[Step 19603/50000] [Progress: 39.21%] [learning rate: 3.8e+03]\n",
            "[Step 19631/50000] [Progress: 39.26%] [learning rate: 5.0e+03]\n",
            "[Step 19652/50000] [Progress: 39.30%] [learning rate: 3.4e+03]\n",
            "[Step 19680/50000] [Time: 166s] [Train Loss: 2.40e-01] [Train Acc: 0.93] [Eval Loss: 5.07e-01] [Eval Acc: 0.77]\n",
            "[Step 19681/50000] [Progress: 39.36%] [learning rate: 4.4e+03]\n",
            "[Step 19705/50000] [Progress: 39.41%] [learning rate: 4.0e+03]\n",
            "[Step 19730/50000] [Progress: 39.46%] [learning rate: 4.3e+03]\n",
            "[Step 19754/50000] [Progress: 39.51%] [learning rate: 3.8e+03]\n",
            "[Step 19767/50000] [Time: 168s] [Train Loss: 2.40e-01] [Train Acc: 0.93]\n",
            "[Step 19782/50000] [Progress: 39.56%] [learning rate: 4.6e+03]\n",
            "[Step 19806/50000] [Progress: 39.61%] [learning rate: 4.1e+03]\n",
            "[Step 19831/50000] [Progress: 39.66%] [learning rate: 4.0e+03]\n",
            "[Step 19854/50000] [Time: 169s] [Train Loss: 2.39e-01] [Train Acc: 0.93]\n",
            "[Step 19857/50000] [Progress: 39.71%] [learning rate: 4.0e+03]\n",
            "[Step 19882/50000] [Progress: 39.76%] [learning rate: 3.9e+03]\n",
            "[Step 19909/50000] [Progress: 39.82%] [learning rate: 4.2e+03]\n",
            "[Step 19935/50000] [Progress: 39.87%] [learning rate: 4.6e+03]\n",
            "[Step 19941/50000] [Time: 170s] [Train Loss: 2.39e-01] [Train Acc: 0.93]\n",
            "[Step 19958/50000] [Progress: 39.92%] [learning rate: 3.7e+03]\n",
            "[Step 19985/50000] [Progress: 39.97%] [learning rate: 4.5e+03]\n",
            "[Step 20008/50000] [Progress: 40.02%] [learning rate: 4.0e+03]\n",
            "[Step 20028/50000] [Time: 171s] [Train Loss: 2.38e-01] [Train Acc: 0.93]\n",
            "[Step 20033/50000] [Progress: 40.07%] [learning rate: 3.9e+03]\n",
            "[Step 20060/50000] [Progress: 40.12%] [learning rate: 4.3e+03]\n",
            "[Step 20086/50000] [Progress: 40.17%] [learning rate: 4.2e+03]\n",
            "[Step 20111/50000] [Progress: 40.22%] [learning rate: 4.1e+03]\n",
            "[Step 20115/50000] [Time: 171s] [Train Loss: 2.38e-01] [Train Acc: 0.94]\n",
            "[Step 20137/50000] [Progress: 40.27%] [learning rate: 4.1e+03]\n",
            "[Step 20163/50000] [Progress: 40.33%] [learning rate: 4.0e+03]\n",
            "[Step 20188/50000] [Progress: 40.38%] [learning rate: 4.0e+03]\n",
            "[Step 20202/50000] [Time: 172s] [Train Loss: 2.37e-01] [Train Acc: 0.94]\n",
            "[Step 20215/50000] [Progress: 40.43%] [learning rate: 4.3e+03]\n",
            "[Step 20241/50000] [Progress: 40.48%] [learning rate: 4.2e+03]\n",
            "[Step 20267/50000] [Progress: 40.53%] [learning rate: 4.6e+03]\n",
            "[Step 20289/50000] [Time: 173s] [Train Loss: 2.36e-01] [Train Acc: 0.94]\n",
            "[Step 20290/50000] [Progress: 40.58%] [learning rate: 3.7e+03]\n",
            "[Step 20317/50000] [Progress: 40.63%] [learning rate: 4.4e+03]\n",
            "[Step 20340/50000] [Progress: 40.68%] [learning rate: 4.0e+03]\n",
            "[Step 20365/50000] [Progress: 40.73%] [learning rate: 4.3e+03]\n",
            "[Step 20376/50000] [Time: 173s] [Train Loss: 2.36e-01] [Train Acc: 0.94]\n",
            "[Step 20389/50000] [Progress: 40.78%] [learning rate: 4.2e+03]\n",
            "[Step 20414/50000] [Progress: 40.83%] [learning rate: 4.2e+03]\n",
            "[Step 20438/50000] [Progress: 40.88%] [learning rate: 4.1e+03]\n",
            "[Step 20463/50000] [Progress: 40.93%] [learning rate: 4.1e+03]\n",
            "[Step 20463/50000] [Time: 174s] [Train Loss: 2.35e-01] [Train Acc: 0.94]\n",
            "[Step 20489/50000] [Progress: 40.98%] [learning rate: 4.4e+03]\n",
            "[Step 20512/50000] [Progress: 41.02%] [learning rate: 3.9e+03]\n",
            "[Step 20538/50000] [Progress: 41.08%] [learning rate: 4.7e+03]\n",
            "[Step 20551/50000] [Time: 175s] [Train Loss: 2.35e-01] [Train Acc: 0.94]\n",
            "[Step 20561/50000] [Progress: 41.12%] [learning rate: 3.8e+03]\n",
            "[Step 20587/50000] [Progress: 41.17%] [learning rate: 4.1e+03]\n",
            "[Step 20611/50000] [Progress: 41.22%] [learning rate: 4.1e+03]\n",
            "[Step 20636/50000] [Progress: 41.27%] [learning rate: 4.0e+03]\n",
            "[Step 20639/50000] [Time: 175s] [Train Loss: 2.34e-01] [Train Acc: 0.94]\n",
            "[Step 20661/50000] [Progress: 41.32%] [learning rate: 3.9e+03]\n",
            "[Step 20687/50000] [Progress: 41.37%] [learning rate: 4.3e+03]\n",
            "[Step 20714/50000] [Progress: 41.43%] [learning rate: 4.6e+03]\n",
            "[Step 20727/50000] [Time: 176s] [Train Loss: 2.34e-01] [Train Acc: 0.94]\n",
            "[Step 20738/50000] [Progress: 41.48%] [learning rate: 4.2e+03]\n",
            "[Step 20763/50000] [Progress: 41.53%] [learning rate: 4.1e+03]\n",
            "[Step 20789/50000] [Progress: 41.58%] [learning rate: 4.0e+03]\n",
            "[Step 20814/50000] [Progress: 41.63%] [learning rate: 4.0e+03]\n",
            "[Step 20815/50000] [Time: 177s] [Train Loss: 2.33e-01] [Train Acc: 0.94]\n",
            "[Step 20839/50000] [Progress: 41.68%] [learning rate: 4.3e+03]\n",
            "[Step 20865/50000] [Progress: 41.73%] [learning rate: 5.1e+03]\n",
            "[Step 20886/50000] [Progress: 41.77%] [learning rate: 3.4e+03]\n",
            "[Step 20903/50000] [Time: 178s] [Train Loss: 2.33e-01] [Train Acc: 0.94]\n",
            "[Step 20915/50000] [Progress: 41.83%] [learning rate: 4.5e+03]\n",
            "[Step 20940/50000] [Progress: 41.88%] [learning rate: 4.0e+03]\n",
            "[Step 20966/50000] [Progress: 41.93%] [learning rate: 4.4e+03]\n",
            "[Step 20990/50000] [Progress: 41.98%] [learning rate: 3.9e+03]\n",
            "[Step 20991/50000] [Time: 178s] [Train Loss: 2.32e-01] [Train Acc: 0.94]\n",
            "[Step 21017/50000] [Progress: 42.03%] [learning rate: 4.7e+03]\n",
            "[Step 21041/50000] [Progress: 42.08%] [learning rate: 4.2e+03]\n",
            "[Step 21066/50000] [Progress: 42.13%] [learning rate: 4.1e+03]\n",
            "[Step 21079/50000] [Time: 179s] [Train Loss: 2.32e-01] [Train Acc: 0.94]\n",
            "[Step 21092/50000] [Progress: 42.18%] [learning rate: 4.5e+03]\n",
            "[Step 21115/50000] [Progress: 42.23%] [learning rate: 4.0e+03]\n",
            "[Step 21141/50000] [Progress: 42.28%] [learning rate: 4.3e+03]\n",
            "[Step 21167/50000] [Progress: 42.33%] [learning rate: 4.7e+03]\n",
            "[Step 21167/50000] [Time: 179s] [Train Loss: 2.31e-01] [Train Acc: 0.94]\n",
            "[Step 21190/50000] [Progress: 42.38%] [learning rate: 3.8e+03]\n",
            "[Step 21217/50000] [Progress: 42.43%] [learning rate: 4.6e+03]\n",
            "[Step 21240/50000] [Progress: 42.48%] [learning rate: 4.1e+03]\n",
            "[Step 21255/50000] [Time: 180s] [Train Loss: 2.31e-01] [Train Acc: 0.94]\n",
            "[Step 21265/50000] [Progress: 42.53%] [learning rate: 4.0e+03]\n",
            "[Step 21290/50000] [Progress: 42.58%] [learning rate: 4.4e+03]\n",
            "[Step 21315/50000] [Progress: 42.63%] [learning rate: 4.3e+03]\n",
            "[Step 21341/50000] [Progress: 42.68%] [learning rate: 4.2e+03]\n",
            "[Step 21344/50000] [Time: 181s] [Train Loss: 2.30e-01] [Train Acc: 0.94]\n",
            "[Step 21365/50000] [Progress: 42.73%] [learning rate: 4.2e+03]\n",
            "[Step 21390/50000] [Progress: 42.78%] [learning rate: 4.1e+03]\n",
            "[Step 21416/50000] [Progress: 42.83%] [learning rate: 4.4e+03]\n",
            "[Step 21433/50000] [Time: 181s] [Train Loss: 2.30e-01] [Train Acc: 0.94]\n",
            "[Step 21440/50000] [Progress: 42.88%] [learning rate: 4.0e+03]\n",
            "[Step 21468/50000] [Progress: 42.94%] [learning rate: 4.7e+03]\n",
            "[Step 21492/50000] [Progress: 42.98%] [learning rate: 4.2e+03]\n",
            "[Step 21517/50000] [Progress: 43.03%] [learning rate: 4.2e+03]\n",
            "[Step 21522/50000] [Time: 182s] [Train Loss: 2.29e-01] [Train Acc: 0.94]\n",
            "[Step 21543/50000] [Progress: 43.09%] [learning rate: 4.1e+03]\n",
            "[Step 21568/50000] [Progress: 43.14%] [learning rate: 4.1e+03]\n",
            "[Step 21595/50000] [Progress: 43.19%] [learning rate: 4.4e+03]\n",
            "[Step 21611/50000] [Time: 182s] [Train Loss: 2.29e-01] [Train Acc: 0.94]\n",
            "[Step 21621/50000] [Progress: 43.24%] [learning rate: 4.3e+03]\n",
            "[Step 21647/50000] [Progress: 43.29%] [learning rate: 4.7e+03]\n",
            "[Step 21670/50000] [Progress: 43.34%] [learning rate: 3.8e+03]\n",
            "[Step 21697/50000] [Progress: 43.39%] [learning rate: 4.5e+03]\n",
            "[Step 21700/50000] [Time: 183s] [Train Loss: 2.28e-01] [Train Acc: 0.94]\n",
            "[Step 21720/50000] [Progress: 43.44%] [learning rate: 4.1e+03]\n",
            "[Step 21745/50000] [Progress: 43.49%] [learning rate: 4.4e+03]\n",
            "[Step 21769/50000] [Progress: 43.54%] [learning rate: 4.3e+03]\n",
            "[Step 21789/50000] [Time: 184s] [Train Loss: 2.28e-01] [Train Acc: 0.94]\n",
            "[Step 21794/50000] [Progress: 43.59%] [learning rate: 4.7e+03]\n",
            "[Step 21817/50000] [Progress: 43.63%] [learning rate: 3.8e+03]\n",
            "[Step 21844/50000] [Progress: 43.69%] [learning rate: 4.6e+03]\n",
            "[Step 21867/50000] [Progress: 43.73%] [learning rate: 4.1e+03]\n",
            "[Step 21878/50000] [Time: 184s] [Train Loss: 2.27e-01] [Train Acc: 0.94]\n",
            "[Step 21892/50000] [Progress: 43.78%] [learning rate: 4.4e+03]\n",
            "[Step 21916/50000] [Progress: 43.83%] [learning rate: 4.4e+03]\n",
            "[Step 21941/50000] [Progress: 43.88%] [learning rate: 4.3e+03]\n",
            "[Step 21965/50000] [Progress: 43.93%] [learning rate: 4.2e+03]\n",
            "[Step 21967/50000] [Time: 186s] [Train Loss: 2.27e-01] [Train Acc: 0.94]\n",
            "[Step 21990/50000] [Progress: 43.98%] [learning rate: 4.2e+03]\n",
            "[Step 22016/50000] [Progress: 44.03%] [learning rate: 4.5e+03]\n",
            "[Step 22039/50000] [Progress: 44.08%] [learning rate: 4.0e+03]\n",
            "[Step 22056/50000] [Time: 186s] [Train Loss: 2.26e-01] [Train Acc: 0.94]\n",
            "[Step 22065/50000] [Progress: 44.13%] [learning rate: 4.4e+03]\n",
            "[Step 22092/50000] [Progress: 44.18%] [learning rate: 4.8e+03]\n",
            "[Step 22116/50000] [Progress: 44.23%] [learning rate: 4.3e+03]\n",
            "[Step 22141/50000] [Progress: 44.28%] [learning rate: 4.2e+03]\n",
            "[Step 22145/50000] [Time: 187s] [Train Loss: 2.26e-01] [Train Acc: 0.94]\n",
            "[Step 22167/50000] [Progress: 44.33%] [learning rate: 4.5e+03]\n",
            "[Step 22190/50000] [Progress: 44.38%] [learning rate: 4.1e+03]\n",
            "[Step 22216/50000] [Progress: 44.43%] [learning rate: 4.4e+03]\n",
            "[Step 22235/50000] [Time: 188s] [Train Loss: 2.25e-01] [Train Acc: 0.94]\n",
            "[Step 22244/50000] [Progress: 44.49%] [learning rate: 5.8e+03]\n",
            "[Step 22261/50000] [Progress: 44.52%] [learning rate: 2.7e+03]\n",
            "[Step 22293/50000] [Progress: 44.59%] [learning rate: 5.1e+03]\n",
            "[Step 22316/50000] [Progress: 44.63%] [learning rate: 3.8e+03]\n",
            "[Step 22325/50000] [Time: 189s] [Train Loss: 2.25e-01] [Train Acc: 0.94]\n",
            "[Step 22344/50000] [Progress: 44.69%] [learning rate: 4.5e+03]\n",
            "[Step 22370/50000] [Progress: 44.74%] [learning rate: 4.4e+03]\n",
            "[Step 22397/50000] [Progress: 44.79%] [learning rate: 4.8e+03]\n",
            "[Step 22415/50000] [Time: 190s] [Train Loss: 2.24e-01] [Train Acc: 0.94]\n",
            "[Step 22421/50000] [Progress: 44.84%] [learning rate: 4.3e+03]\n",
            "[Step 22446/50000] [Progress: 44.89%] [learning rate: 4.2e+03]\n",
            "[Step 22472/50000] [Progress: 44.94%] [learning rate: 4.2e+03]\n",
            "[Step 22498/50000] [Progress: 45.00%] [learning rate: 4.5e+03]\n",
            "[Step 22505/50000] [Time: 191s] [Train Loss: 2.24e-01] [Train Acc: 0.94]\n",
            "[Step 22522/50000] [Progress: 45.04%] [learning rate: 4.0e+03]\n",
            "[Step 22548/50000] [Progress: 45.10%] [learning rate: 4.8e+03]\n",
            "[Step 22571/50000] [Progress: 45.14%] [learning rate: 3.9e+03]\n",
            "[Step 22595/50000] [Time: 191s] [Train Loss: 2.23e-01] [Train Acc: 0.94]\n",
            "[Step 22597/50000] [Progress: 45.19%] [learning rate: 4.2e+03]\n",
            "[Step 22622/50000] [Progress: 45.24%] [learning rate: 4.2e+03]\n",
            "[Step 22648/50000] [Progress: 45.30%] [learning rate: 4.5e+03]\n",
            "[Step 22672/50000] [Progress: 45.34%] [learning rate: 4.1e+03]\n",
            "[Step 22685/50000] [Time: 192s] [Train Loss: 2.23e-01] [Train Acc: 0.94]\n",
            "[Step 22700/50000] [Progress: 45.40%] [learning rate: 4.8e+03]\n",
            "[Step 22724/50000] [Progress: 45.45%] [learning rate: 4.3e+03]\n",
            "[Step 22749/50000] [Progress: 45.50%] [learning rate: 4.3e+03]\n",
            "[Step 22775/50000] [Progress: 45.55%] [learning rate: 4.2e+03]\n",
            "[Step 22775/50000] [Time: 193s] [Train Loss: 2.22e-01] [Train Acc: 0.94]\n",
            "[Step 22801/50000] [Progress: 45.60%] [learning rate: 4.6e+03]\n",
            "[Step 22825/50000] [Progress: 45.65%] [learning rate: 4.1e+03]\n",
            "[Step 22853/50000] [Progress: 45.71%] [learning rate: 4.9e+03]\n",
            "[Step 22865/50000] [Time: 194s] [Train Loss: 2.22e-01] [Train Acc: 0.94]\n",
            "[Step 22877/50000] [Progress: 45.75%] [learning rate: 4.4e+03]\n",
            "[Step 22902/50000] [Progress: 45.80%] [learning rate: 4.3e+03]\n",
            "[Step 22928/50000] [Progress: 45.86%] [learning rate: 4.2e+03]\n",
            "[Step 22953/50000] [Progress: 45.91%] [learning rate: 4.2e+03]\n",
            "[Step 22955/50000] [Time: 195s] [Train Loss: 2.21e-01] [Train Acc: 0.94]\n",
            "[Step 22980/50000] [Progress: 45.96%] [learning rate: 4.5e+03]\n",
            "[Step 23006/50000] [Progress: 46.01%] [learning rate: 4.4e+03]\n",
            "[Step 23032/50000] [Progress: 46.06%] [learning rate: 4.8e+03]\n",
            "[Step 23045/50000] [Time: 195s] [Train Loss: 2.21e-01] [Train Acc: 0.94]\n",
            "[Step 23055/50000] [Progress: 46.11%] [learning rate: 3.9e+03]\n",
            "[Step 23082/50000] [Progress: 46.16%] [learning rate: 4.7e+03]\n",
            "[Step 23105/50000] [Progress: 46.21%] [learning rate: 4.2e+03]\n",
            "[Step 23130/50000] [Progress: 46.26%] [learning rate: 4.5e+03]\n",
            "[Step 23136/50000] [Time: 196s] [Train Loss: 2.20e-01] [Train Acc: 0.94]\n",
            "[Step 23154/50000] [Progress: 46.31%] [learning rate: 4.5e+03]\n",
            "[Step 23179/50000] [Progress: 46.36%] [learning rate: 4.4e+03]\n",
            "[Step 23203/50000] [Progress: 46.41%] [learning rate: 4.3e+03]\n",
            "[Step 23227/50000] [Time: 197s] [Train Loss: 2.20e-01] [Train Acc: 0.94]\n",
            "[Step 23228/50000] [Progress: 46.46%] [learning rate: 4.3e+03]\n",
            "[Step 23254/50000] [Progress: 46.51%] [learning rate: 4.6e+03]\n",
            "[Step 23277/50000] [Progress: 46.55%] [learning rate: 4.1e+03]\n",
            "[Step 23303/50000] [Progress: 46.61%] [learning rate: 4.5e+03]\n",
            "[Step 23318/50000] [Time: 197s] [Train Loss: 2.19e-01] [Train Acc: 0.94]\n",
            "[Step 23328/50000] [Progress: 46.66%] [learning rate: 4.4e+03]\n",
            "[Step 23352/50000] [Progress: 46.70%] [learning rate: 4.3e+03]\n",
            "[Step 23377/50000] [Progress: 46.75%] [learning rate: 4.3e+03]\n",
            "[Step 23403/50000] [Progress: 46.81%] [learning rate: 4.2e+03]\n",
            "[Step 23409/50000] [Time: 198s] [Train Loss: 2.19e-01] [Train Acc: 0.94]\n",
            "[Step 23428/50000] [Progress: 46.86%] [learning rate: 4.2e+03]\n",
            "[Step 23454/50000] [Progress: 46.91%] [learning rate: 4.5e+03]\n",
            "[Step 23481/50000] [Progress: 46.96%] [learning rate: 4.9e+03]\n",
            "[Step 23500/50000] [Time: 199s] [Train Loss: 2.18e-01] [Train Acc: 0.94]\n",
            "[Step 23505/50000] [Progress: 47.01%] [learning rate: 4.4e+03]\n",
            "[Step 23530/50000] [Progress: 47.06%] [learning rate: 4.3e+03]\n",
            "[Step 23556/50000] [Progress: 47.11%] [learning rate: 4.7e+03]\n",
            "[Step 23579/50000] [Progress: 47.16%] [learning rate: 4.2e+03]\n",
            "[Step 23591/50000] [Time: 200s] [Train Loss: 2.18e-01] [Train Acc: 0.94]\n",
            "[Step 23605/50000] [Progress: 47.21%] [learning rate: 4.5e+03]\n",
            "[Step 23632/50000] [Progress: 47.26%] [learning rate: 5.4e+03]\n",
            "[Step 23652/50000] [Progress: 47.30%] [learning rate: 3.6e+03]\n",
            "[Step 23680/50000] [Progress: 47.36%] [learning rate: 4.7e+03]\n",
            "[Step 23682/50000] [Time: 200s] [Train Loss: 2.18e-01] [Train Acc: 0.94]\n",
            "[Step 23705/50000] [Progress: 47.41%] [learning rate: 4.3e+03]\n",
            "[Step 23731/50000] [Progress: 47.46%] [learning rate: 4.6e+03]\n",
            "[Step 23755/50000] [Progress: 47.51%] [learning rate: 4.1e+03]\n",
            "[Step 23773/50000] [Time: 201s] [Train Loss: 2.17e-01] [Train Acc: 0.94]\n",
            "[Step 23783/50000] [Progress: 47.57%] [learning rate: 4.9e+03]\n",
            "[Step 23806/50000] [Progress: 47.61%] [learning rate: 4.0e+03]\n",
            "[Step 23833/50000] [Progress: 47.67%] [learning rate: 4.8e+03]\n",
            "[Step 23856/50000] [Progress: 47.71%] [learning rate: 3.9e+03]\n",
            "[Step 23864/50000] [Time: 201s] [Train Loss: 2.17e-01] [Train Acc: 0.94]\n",
            "[Step 23882/50000] [Progress: 47.76%] [learning rate: 4.6e+03]\n",
            "[Step 23906/50000] [Progress: 47.81%] [learning rate: 4.1e+03]\n",
            "[Step 23932/50000] [Progress: 47.86%] [learning rate: 4.9e+03]\n",
            "[Step 23955/50000] [Progress: 47.91%] [learning rate: 4.0e+03]\n",
            "[Step 23955/50000] [Time: 202s] [Train Loss: 2.16e-01] [Train Acc: 0.94]\n",
            "[Step 23982/50000] [Progress: 47.96%] [learning rate: 4.8e+03]\n",
            "[Step 24005/50000] [Progress: 48.01%] [learning rate: 3.9e+03]\n",
            "[Step 24031/50000] [Progress: 48.06%] [learning rate: 4.6e+03]\n",
            "[Step 24046/50000] [Time: 203s] [Train Loss: 2.16e-01] [Train Acc: 0.94]\n",
            "[Step 24055/50000] [Progress: 48.11%] [learning rate: 4.2e+03]\n",
            "[Step 24081/50000] [Progress: 48.16%] [learning rate: 4.5e+03]\n",
            "[Step 24106/50000] [Progress: 48.21%] [learning rate: 4.4e+03]\n",
            "[Step 24132/50000] [Progress: 48.26%] [learning rate: 4.4e+03]\n",
            "[Step 24137/50000] [Time: 203s] [Train Loss: 2.15e-01] [Train Acc: 0.95] [Eval Loss: 5.06e-01] [Eval Acc: 0.77]\n",
            "[Step 24158/50000] [Progress: 48.32%] [learning rate: 4.3e+03]\n",
            "[Step 24183/50000] [Progress: 48.37%] [learning rate: 4.2e+03]\n",
            "[Step 24210/50000] [Progress: 48.42%] [learning rate: 4.6e+03]\n",
            "[Step 24229/50000] [Time: 206s] [Train Loss: 2.15e-01] [Train Acc: 0.95]\n",
            "[Step 24236/50000] [Progress: 48.47%] [learning rate: 4.5e+03]\n",
            "[Step 24262/50000] [Progress: 48.52%] [learning rate: 4.5e+03]\n",
            "[Step 24286/50000] [Progress: 48.57%] [learning rate: 4.4e+03]\n",
            "[Step 24311/50000] [Progress: 48.62%] [learning rate: 4.3e+03]\n",
            "[Step 24321/50000] [Time: 207s] [Train Loss: 2.14e-01] [Train Acc: 0.95]\n",
            "[Step 24337/50000] [Progress: 48.67%] [learning rate: 4.7e+03]\n",
            "[Step 24361/50000] [Progress: 48.72%] [learning rate: 4.2e+03]\n",
            "[Step 24388/50000] [Progress: 48.78%] [learning rate: 5.0e+03]\n",
            "[Step 24411/50000] [Progress: 48.82%] [learning rate: 4.1e+03]\n",
            "[Step 24413/50000] [Time: 207s] [Train Loss: 2.14e-01] [Train Acc: 0.95]\n",
            "[Step 24437/50000] [Progress: 48.87%] [learning rate: 4.4e+03]\n",
            "[Step 24461/50000] [Progress: 48.92%] [learning rate: 4.3e+03]\n",
            "[Step 24486/50000] [Progress: 48.97%] [learning rate: 4.3e+03]\n",
            "[Step 24505/50000] [Time: 208s] [Train Loss: 2.13e-01] [Train Acc: 0.95]\n",
            "[Step 24511/50000] [Progress: 49.02%] [learning rate: 4.2e+03]\n",
            "[Step 24537/50000] [Progress: 49.07%] [learning rate: 4.6e+03]\n",
            "[Step 24563/50000] [Progress: 49.13%] [learning rate: 5.0e+03]\n",
            "[Step 24586/50000] [Progress: 49.17%] [learning rate: 4.0e+03]\n",
            "[Step 24597/50000] [Time: 209s] [Train Loss: 2.13e-01] [Train Acc: 0.95]\n",
            "[Step 24612/50000] [Progress: 49.22%] [learning rate: 4.4e+03]\n",
            "[Step 24637/50000] [Progress: 49.27%] [learning rate: 4.3e+03]\n",
            "[Step 24663/50000] [Progress: 49.33%] [learning rate: 4.7e+03]\n",
            "[Step 24687/50000] [Progress: 49.37%] [learning rate: 4.2e+03]\n",
            "[Step 24689/50000] [Time: 210s] [Train Loss: 2.13e-01] [Train Acc: 0.95]\n",
            "[Step 24714/50000] [Progress: 49.43%] [learning rate: 5.5e+03]\n",
            "[Step 24734/50000] [Progress: 49.47%] [learning rate: 3.7e+03]\n",
            "[Step 24762/50000] [Progress: 49.52%] [learning rate: 4.8e+03]\n",
            "[Step 24781/50000] [Time: 210s] [Train Loss: 2.12e-01] [Train Acc: 0.95]\n",
            "[Step 24787/50000] [Progress: 49.57%] [learning rate: 4.3e+03]\n",
            "[Step 24813/50000] [Progress: 49.63%] [learning rate: 4.7e+03]\n",
            "[Step 24837/50000] [Progress: 49.67%] [learning rate: 4.2e+03]\n",
            "[Step 24864/50000] [Progress: 49.73%] [learning rate: 5.5e+03]\n",
            "[Step 24873/50000] [Time: 211s] [Train Loss: 2.12e-01] [Train Acc: 0.95]\n",
            "[Step 24884/50000] [Progress: 49.77%] [learning rate: 3.7e+03]\n",
            "[Step 24912/50000] [Progress: 49.82%] [learning rate: 4.8e+03]\n",
            "[Step 24937/50000] [Progress: 49.87%] [learning rate: 4.3e+03]\n",
            "[Step 24963/50000] [Progress: 49.93%] [learning rate: 4.7e+03]\n",
            "[Step 24965/50000] [Time: 212s] [Train Loss: 2.11e-01] [Train Acc: 0.95]\n",
            "[Step 24987/50000] [Progress: 49.97%] [learning rate: 4.2e+03]\n",
            "[Step 25013/50000] [Progress: 50.03%] [learning rate: 5.0e+03]\n",
            "[Step 25036/50000] [Progress: 50.07%] [learning rate: 4.1e+03]\n",
            "[Step 25057/50000] [Time: 213s] [Train Loss: 2.11e-01] [Train Acc: 0.95]\n",
            "[Step 25062/50000] [Progress: 50.12%] [learning rate: 4.4e+03]\n",
            "[Step 25086/50000] [Progress: 50.17%] [learning rate: 4.4e+03]\n",
            "[Step 25111/50000] [Progress: 50.22%] [learning rate: 4.7e+03]\n",
            "[Step 25135/50000] [Progress: 50.27%] [learning rate: 4.2e+03]\n",
            "[Step 25149/50000] [Time: 214s] [Train Loss: 2.10e-01] [Train Acc: 0.95]\n",
            "[Step 25163/50000] [Progress: 50.33%] [learning rate: 5.0e+03]\n",
            "[Step 25187/50000] [Progress: 50.37%] [learning rate: 4.5e+03]\n",
            "[Step 25212/50000] [Progress: 50.42%] [learning rate: 4.4e+03]\n",
            "[Step 25238/50000] [Progress: 50.48%] [learning rate: 4.4e+03]\n",
            "[Step 25241/50000] [Time: 215s] [Train Loss: 2.10e-01] [Train Acc: 0.95]\n",
            "[Step 25263/50000] [Progress: 50.53%] [learning rate: 4.3e+03]\n",
            "[Step 25290/50000] [Progress: 50.58%] [learning rate: 4.7e+03]\n",
            "[Step 25316/50000] [Progress: 50.63%] [learning rate: 4.6e+03]\n",
            "[Step 25333/50000] [Time: 215s] [Train Loss: 2.09e-01] [Train Acc: 0.95]\n",
            "[Step 25340/50000] [Progress: 50.68%] [learning rate: 4.5e+03]\n",
            "[Step 25365/50000] [Progress: 50.73%] [learning rate: 4.5e+03]\n",
            "[Step 25391/50000] [Progress: 50.78%] [learning rate: 4.4e+03]\n",
            "[Step 25416/50000] [Progress: 50.83%] [learning rate: 4.3e+03]\n",
            "[Step 25426/50000] [Time: 216s] [Train Loss: 2.09e-01] [Train Acc: 0.95]\n",
            "[Step 25443/50000] [Progress: 50.89%] [learning rate: 4.7e+03]\n",
            "[Step 25469/50000] [Progress: 50.94%] [learning rate: 4.6e+03]\n",
            "[Step 25495/50000] [Progress: 50.99%] [learning rate: 5.0e+03]\n",
            "[Step 25518/50000] [Progress: 51.04%] [learning rate: 4.1e+03]\n",
            "[Step 25519/50000] [Time: 217s] [Train Loss: 2.09e-01] [Train Acc: 0.95]\n",
            "[Step 25545/50000] [Progress: 51.09%] [learning rate: 4.9e+03]\n",
            "[Step 25568/50000] [Progress: 51.14%] [learning rate: 4.4e+03]\n",
            "[Step 25593/50000] [Progress: 51.19%] [learning rate: 4.7e+03]\n",
            "[Step 25612/50000] [Time: 217s] [Train Loss: 2.08e-01] [Train Acc: 0.95]\n",
            "[Step 25617/50000] [Progress: 51.23%] [learning rate: 4.6e+03]\n",
            "[Step 25642/50000] [Progress: 51.28%] [learning rate: 5.0e+03]\n",
            "[Step 25665/50000] [Progress: 51.33%] [learning rate: 4.1e+03]\n",
            "[Step 25692/50000] [Progress: 51.38%] [learning rate: 4.9e+03]\n",
            "[Step 25705/50000] [Time: 218s] [Train Loss: 2.08e-01] [Train Acc: 0.95]\n",
            "[Step 25715/50000] [Progress: 51.43%] [learning rate: 4.4e+03]\n",
            "[Step 25740/50000] [Progress: 51.48%] [learning rate: 4.7e+03]\n",
            "[Step 25764/50000] [Progress: 51.53%] [learning rate: 4.2e+03]\n",
            "[Step 25791/50000] [Progress: 51.58%] [learning rate: 5.1e+03]\n",
            "[Step 25798/50000] [Time: 219s] [Train Loss: 2.07e-01] [Train Acc: 0.95]\n",
            "[Step 25815/50000] [Progress: 51.63%] [learning rate: 4.5e+03]\n",
            "[Step 25840/50000] [Progress: 51.68%] [learning rate: 4.5e+03]\n",
            "[Step 25866/50000] [Progress: 51.73%] [learning rate: 4.4e+03]\n",
            "[Step 25891/50000] [Progress: 51.78%] [learning rate: 4.3e+03]\n",
            "[Step 25891/50000] [Time: 220s] [Train Loss: 2.07e-01] [Train Acc: 0.95]\n",
            "[Step 25917/50000] [Progress: 51.83%] [learning rate: 4.7e+03]\n",
            "[Step 25944/50000] [Progress: 51.89%] [learning rate: 5.1e+03]\n",
            "[Step 25966/50000] [Progress: 51.93%] [learning rate: 4.1e+03]\n",
            "[Step 25984/50000] [Time: 221s] [Train Loss: 2.06e-01] [Train Acc: 0.95]\n",
            "[Step 25992/50000] [Progress: 51.98%] [learning rate: 4.9e+03]\n",
            "[Step 26015/50000] [Progress: 52.03%] [learning rate: 4.4e+03]\n",
            "[Step 26040/50000] [Progress: 52.08%] [learning rate: 4.3e+03]\n",
            "[Step 26065/50000] [Progress: 52.13%] [learning rate: 4.7e+03]\n",
            "[Step 26077/50000] [Time: 222s] [Train Loss: 2.06e-01] [Train Acc: 0.95]\n",
            "[Step 26091/50000] [Progress: 52.18%] [learning rate: 5.1e+03]\n",
            "[Step 26115/50000] [Progress: 52.23%] [learning rate: 4.6e+03]\n",
            "[Step 26140/50000] [Progress: 52.28%] [learning rate: 4.5e+03]\n",
            "[Step 26166/50000] [Progress: 52.33%] [learning rate: 4.4e+03]\n",
            "[Step 26170/50000] [Time: 223s] [Train Loss: 2.06e-01] [Train Acc: 0.95]\n",
            "[Step 26191/50000] [Progress: 52.38%] [learning rate: 4.4e+03]\n",
            "[Step 26218/50000] [Progress: 52.44%] [learning rate: 4.7e+03]\n",
            "[Step 26244/50000] [Progress: 52.49%] [learning rate: 5.1e+03]\n",
            "[Step 26263/50000] [Time: 225s] [Train Loss: 2.05e-01] [Train Acc: 0.95]\n",
            "[Step 26267/50000] [Progress: 52.53%] [learning rate: 4.2e+03]\n",
            "[Step 26293/50000] [Progress: 52.59%] [learning rate: 4.5e+03]\n",
            "[Step 26318/50000] [Progress: 52.64%] [learning rate: 4.5e+03]\n",
            "[Step 26344/50000] [Progress: 52.69%] [learning rate: 4.8e+03]\n",
            "[Step 26356/50000] [Time: 226s] [Train Loss: 2.05e-01] [Train Acc: 0.95]\n",
            "[Step 26368/50000] [Progress: 52.74%] [learning rate: 4.3e+03]\n",
            "[Step 26395/50000] [Progress: 52.79%] [learning rate: 5.1e+03]\n",
            "[Step 26418/50000] [Progress: 52.84%] [learning rate: 4.2e+03]\n",
            "[Step 26444/50000] [Progress: 52.89%] [learning rate: 4.5e+03]\n",
            "[Step 26449/50000] [Time: 227s] [Train Loss: 2.04e-01] [Train Acc: 0.95]\n",
            "[Step 26469/50000] [Progress: 52.94%] [learning rate: 4.5e+03]\n",
            "[Step 26495/50000] [Progress: 52.99%] [learning rate: 4.4e+03]\n",
            "[Step 26520/50000] [Progress: 53.04%] [learning rate: 4.8e+03]\n",
            "[Step 26542/50000] [Time: 228s] [Train Loss: 2.04e-01] [Train Acc: 0.95]\n",
            "[Step 26544/50000] [Progress: 53.09%] [learning rate: 4.7e+03]\n",
            "[Step 26569/50000] [Progress: 53.14%] [learning rate: 4.6e+03]\n",
            "[Step 26593/50000] [Progress: 53.19%] [learning rate: 4.6e+03]\n",
            "[Step 26618/50000] [Progress: 53.24%] [learning rate: 4.5e+03]\n",
            "[Step 26635/50000] [Time: 228s] [Train Loss: 2.03e-01] [Train Acc: 0.95]\n",
            "[Step 26644/50000] [Progress: 53.29%] [learning rate: 4.9e+03]\n",
            "[Step 26668/50000] [Progress: 53.34%] [learning rate: 4.4e+03]\n",
            "[Step 26695/50000] [Progress: 53.39%] [learning rate: 5.2e+03]\n",
            "[Step 26718/50000] [Progress: 53.44%] [learning rate: 4.2e+03]\n",
            "[Step 26729/50000] [Time: 229s] [Train Loss: 2.03e-01] [Train Acc: 0.95]\n",
            "[Step 26744/50000] [Progress: 53.49%] [learning rate: 4.6e+03]\n",
            "[Step 26770/50000] [Progress: 53.54%] [learning rate: 5.0e+03]\n",
            "[Step 26793/50000] [Progress: 53.59%] [learning rate: 4.0e+03]\n",
            "[Step 26820/50000] [Progress: 53.64%] [learning rate: 4.8e+03]\n",
            "[Step 26823/50000] [Time: 230s] [Train Loss: 2.03e-01] [Train Acc: 0.95]\n",
            "[Step 26845/50000] [Progress: 53.69%] [learning rate: 4.7e+03]\n",
            "[Step 26870/50000] [Progress: 53.74%] [learning rate: 5.1e+03]\n",
            "[Step 26893/50000] [Progress: 53.79%] [learning rate: 4.2e+03]\n",
            "[Step 26917/50000] [Time: 230s] [Train Loss: 2.02e-01] [Train Acc: 0.95]\n",
            "[Step 26920/50000] [Progress: 53.84%] [learning rate: 5.0e+03]\n",
            "[Step 26943/50000] [Progress: 53.89%] [learning rate: 4.5e+03]\n",
            "[Step 26968/50000] [Progress: 53.94%] [learning rate: 4.8e+03]\n",
            "[Step 26992/50000] [Progress: 53.98%] [learning rate: 4.8e+03]\n",
            "[Step 27011/50000] [Time: 231s] [Train Loss: 2.02e-01] [Train Acc: 0.95]\n",
            "[Step 27017/50000] [Progress: 54.03%] [learning rate: 5.2e+03]\n",
            "[Step 27040/50000] [Progress: 54.08%] [learning rate: 4.2e+03]\n",
            "[Step 27067/50000] [Progress: 54.13%] [learning rate: 5.0e+03]\n",
            "[Step 27090/50000] [Progress: 54.18%] [learning rate: 4.5e+03]\n",
            "[Step 27105/50000] [Time: 232s] [Train Loss: 2.01e-01] [Train Acc: 0.95]\n",
            "[Step 27115/50000] [Progress: 54.23%] [learning rate: 4.9e+03]\n",
            "[Step 27139/50000] [Progress: 54.28%] [learning rate: 4.3e+03]\n",
            "[Step 27166/50000] [Progress: 54.33%] [learning rate: 5.2e+03]\n",
            "[Step 27188/50000] [Progress: 54.38%] [learning rate: 4.2e+03]\n",
            "[Step 27199/50000] [Time: 232s] [Train Loss: 2.01e-01] [Train Acc: 0.95]\n",
            "[Step 27214/50000] [Progress: 54.43%] [learning rate: 5.0e+03]\n",
            "[Step 27237/50000] [Progress: 54.47%] [learning rate: 4.5e+03]\n",
            "[Step 27262/50000] [Progress: 54.52%] [learning rate: 4.4e+03]\n",
            "[Step 27287/50000] [Progress: 54.57%] [learning rate: 4.8e+03]\n",
            "[Step 27293/50000] [Time: 234s] [Train Loss: 2.01e-01] [Train Acc: 0.95]\n",
            "[Step 27312/50000] [Progress: 54.62%] [learning rate: 5.2e+03]\n",
            "[Step 27335/50000] [Progress: 54.67%] [learning rate: 4.2e+03]\n",
            "[Step 27362/50000] [Progress: 54.72%] [learning rate: 5.1e+03]\n",
            "[Step 27385/50000] [Progress: 54.77%] [learning rate: 4.1e+03]\n",
            "[Step 27387/50000] [Time: 234s] [Train Loss: 2.00e-01] [Train Acc: 0.95]\n",
            "[Step 27412/50000] [Progress: 54.82%] [learning rate: 4.9e+03]\n",
            "[Step 27437/50000] [Progress: 54.87%] [learning rate: 4.4e+03]\n",
            "[Step 27463/50000] [Progress: 54.93%] [learning rate: 5.2e+03]\n",
            "[Step 27481/50000] [Time: 235s] [Train Loss: 2.00e-01] [Train Acc: 0.95]\n",
            "[Step 27486/50000] [Progress: 54.97%] [learning rate: 4.3e+03]\n",
            "[Step 27513/50000] [Progress: 55.03%] [learning rate: 5.1e+03]\n",
            "[Step 27536/50000] [Progress: 55.07%] [learning rate: 4.1e+03]\n",
            "[Step 27562/50000] [Progress: 55.12%] [learning rate: 4.9e+03]\n",
            "[Step 27575/50000] [Time: 236s] [Train Loss: 1.99e-01] [Train Acc: 0.95]\n",
            "[Step 27586/50000] [Progress: 55.17%] [learning rate: 4.4e+03]\n",
            "[Step 27612/50000] [Progress: 55.22%] [learning rate: 4.8e+03]\n",
            "[Step 27636/50000] [Progress: 55.27%] [learning rate: 4.7e+03]\n",
            "[Step 27661/50000] [Progress: 55.32%] [learning rate: 4.6e+03]\n",
            "[Step 27669/50000] [Time: 236s] [Train Loss: 1.99e-01] [Train Acc: 0.95]\n",
            "[Step 27687/50000] [Progress: 55.37%] [learning rate: 4.6e+03]\n",
            "[Step 27712/50000] [Progress: 55.42%] [learning rate: 4.5e+03]\n",
            "[Step 27739/50000] [Progress: 55.48%] [learning rate: 4.9e+03]\n",
            "[Step 27763/50000] [Time: 237s] [Train Loss: 1.98e-01] [Train Acc: 0.95]\n",
            "[Step 27765/50000] [Progress: 55.53%] [learning rate: 4.8e+03]\n",
            "[Step 27791/50000] [Progress: 55.58%] [learning rate: 5.2e+03]\n",
            "[Step 27814/50000] [Progress: 55.63%] [learning rate: 4.2e+03]\n",
            "[Step 27841/50000] [Progress: 55.68%] [learning rate: 5.0e+03]\n",
            "[Step 27857/50000] [Time: 238s] [Train Loss: 1.98e-01] [Train Acc: 0.95]\n",
            "[Step 27864/50000] [Progress: 55.73%] [learning rate: 4.5e+03]\n",
            "[Step 27889/50000] [Progress: 55.78%] [learning rate: 4.9e+03]\n",
            "[Step 27913/50000] [Progress: 55.83%] [learning rate: 4.8e+03]\n",
            "[Step 27938/50000] [Progress: 55.88%] [learning rate: 4.7e+03]\n",
            "[Step 27951/50000] [Time: 239s] [Train Loss: 1.98e-01] [Train Acc: 0.95]\n",
            "[Step 27962/50000] [Progress: 55.92%] [learning rate: 4.7e+03]\n",
            "[Step 27987/50000] [Progress: 55.97%] [learning rate: 4.6e+03]\n",
            "[Step 28013/50000] [Progress: 56.03%] [learning rate: 5.0e+03]\n",
            "[Step 28036/50000] [Progress: 56.07%] [learning rate: 4.5e+03]\n",
            "[Step 28045/50000] [Time: 239s] [Train Loss: 1.97e-01] [Train Acc: 0.95]\n",
            "[Step 28062/50000] [Progress: 56.12%] [learning rate: 4.8e+03]\n",
            "[Step 28087/50000] [Progress: 56.17%] [learning rate: 5.2e+03]\n",
            "[Step 28110/50000] [Progress: 56.22%] [learning rate: 4.3e+03]\n",
            "[Step 28137/50000] [Progress: 56.27%] [learning rate: 5.1e+03]\n",
            "[Step 28139/50000] [Time: 240s] [Train Loss: 1.97e-01] [Train Acc: 0.95]\n",
            "[Step 28160/50000] [Progress: 56.32%] [learning rate: 4.1e+03]\n",
            "[Step 28187/50000] [Progress: 56.37%] [learning rate: 4.9e+03]\n",
            "[Step 28212/50000] [Progress: 56.42%] [learning rate: 4.9e+03]\n",
            "[Step 28234/50000] [Time: 241s] [Train Loss: 1.96e-01] [Train Acc: 0.95]\n",
            "[Step 28238/50000] [Progress: 56.48%] [learning rate: 5.3e+03]\n",
            "[Step 28261/50000] [Progress: 56.52%] [learning rate: 4.3e+03]\n",
            "[Step 28288/50000] [Progress: 56.58%] [learning rate: 5.1e+03]\n",
            "[Step 28311/50000] [Progress: 56.62%] [learning rate: 4.2e+03]\n",
            "[Step 28329/50000] [Time: 242s] [Train Loss: 1.96e-01] [Train Acc: 0.95]\n",
            "[Step 28337/50000] [Progress: 56.67%] [learning rate: 5.0e+03]\n",
            "[Step 28361/50000] [Progress: 56.72%] [learning rate: 4.4e+03]\n",
            "[Step 28388/50000] [Progress: 56.78%] [learning rate: 5.3e+03]\n",
            "[Step 28412/50000] [Progress: 56.82%] [learning rate: 4.7e+03]\n",
            "[Step 28424/50000] [Time: 242s] [Train Loss: 1.96e-01] [Train Acc: 0.95]\n",
            "[Step 28437/50000] [Progress: 56.87%] [learning rate: 4.7e+03]\n",
            "[Step 28463/50000] [Progress: 56.93%] [learning rate: 4.6e+03]\n",
            "[Step 28488/50000] [Progress: 56.98%] [learning rate: 4.5e+03]\n",
            "[Step 28515/50000] [Progress: 57.03%] [learning rate: 4.9e+03]\n",
            "[Step 28519/50000] [Time: 243s] [Train Loss: 1.95e-01] [Train Acc: 0.95]\n",
            "[Step 28541/50000] [Progress: 57.08%] [learning rate: 5.3e+03]\n",
            "[Step 28564/50000] [Progress: 57.13%] [learning rate: 4.3e+03]\n",
            "[Step 28591/50000] [Progress: 57.18%] [learning rate: 5.2e+03]\n",
            "[Step 28614/50000] [Progress: 57.23%] [learning rate: 4.6e+03]\n",
            "[Step 28614/50000] [Time: 244s] [Train Loss: 1.95e-01] [Train Acc: 0.95]\n",
            "[Step 28639/50000] [Progress: 57.28%] [learning rate: 4.5e+03]\n",
            "[Step 28666/50000] [Progress: 57.33%] [learning rate: 4.9e+03]\n",
            "[Step 28692/50000] [Progress: 57.38%] [learning rate: 4.9e+03]\n",
            "[Step 28709/50000] [Time: 245s] [Train Loss: 1.95e-01] [Train Acc: 0.95]\n",
            "[Step 28717/50000] [Progress: 57.43%] [learning rate: 4.8e+03]\n",
            "[Step 28743/50000] [Progress: 57.49%] [learning rate: 4.7e+03]\n",
            "[Step 28769/50000] [Progress: 57.54%] [learning rate: 4.6e+03]\n",
            "[Step 28794/50000] [Progress: 57.59%] [learning rate: 4.6e+03]\n",
            "[Step 28804/50000] [Time: 245s] [Train Loss: 1.94e-01] [Train Acc: 0.95] [Eval Loss: 5.09e-01] [Eval Acc: 0.78]\n",
            "[Step 28821/50000] [Progress: 57.64%] [learning rate: 4.9e+03]\n",
            "[Step 28847/50000] [Progress: 57.69%] [learning rate: 4.9e+03]\n",
            "[Step 28873/50000] [Progress: 57.75%] [learning rate: 4.8e+03]\n",
            "[Step 28897/50000] [Progress: 57.79%] [learning rate: 4.7e+03]\n",
            "[Step 28899/50000] [Time: 248s] [Train Loss: 1.94e-01] [Train Acc: 0.95]\n",
            "[Step 28922/50000] [Progress: 57.84%] [learning rate: 4.7e+03]\n",
            "[Step 28948/50000] [Progress: 57.90%] [learning rate: 5.0e+03]\n",
            "[Step 28972/50000] [Progress: 57.94%] [learning rate: 4.5e+03]\n",
            "[Step 28994/50000] [Time: 248s] [Train Loss: 1.93e-01] [Train Acc: 0.95]\n",
            "[Step 28999/50000] [Progress: 58.00%] [learning rate: 4.9e+03]\n",
            "[Step 29024/50000] [Progress: 58.05%] [learning rate: 4.8e+03]\n",
            "[Step 29050/50000] [Progress: 58.10%] [learning rate: 4.8e+03]\n",
            "[Step 29074/50000] [Progress: 58.15%] [learning rate: 4.7e+03]\n",
            "[Step 29089/50000] [Time: 249s] [Train Loss: 1.93e-01] [Train Acc: 0.95]\n",
            "[Step 29099/50000] [Progress: 58.20%] [learning rate: 4.6e+03]\n",
            "[Step 29124/50000] [Progress: 58.25%] [learning rate: 4.5e+03]\n",
            "[Step 29150/50000] [Progress: 58.30%] [learning rate: 4.9e+03]\n",
            "[Step 29176/50000] [Progress: 58.35%] [learning rate: 5.3e+03]\n",
            "[Step 29184/50000] [Time: 250s] [Train Loss: 1.93e-01] [Train Acc: 0.95]\n",
            "[Step 29199/50000] [Progress: 58.40%] [learning rate: 4.3e+03]\n",
            "[Step 29225/50000] [Progress: 58.45%] [learning rate: 4.7e+03]\n",
            "[Step 29250/50000] [Progress: 58.50%] [learning rate: 4.6e+03]\n",
            "[Step 29276/50000] [Progress: 58.55%] [learning rate: 5.0e+03]\n",
            "[Step 29279/50000] [Time: 250s] [Train Loss: 1.92e-01] [Train Acc: 0.95]\n",
            "[Step 29300/50000] [Progress: 58.60%] [learning rate: 4.5e+03]\n",
            "[Step 29328/50000] [Progress: 58.66%] [learning rate: 5.9e+03]\n",
            "[Step 29351/50000] [Progress: 58.70%] [learning rate: 4.8e+03]\n",
            "[Step 29374/50000] [Time: 251s] [Train Loss: 1.92e-01] [Train Acc: 0.95]\n",
            "[Step 29376/50000] [Progress: 58.75%] [learning rate: 4.7e+03]\n",
            "[Step 29402/50000] [Progress: 58.80%] [learning rate: 4.7e+03]\n",
            "[Step 29427/50000] [Progress: 58.85%] [learning rate: 4.6e+03]\n",
            "[Step 29454/50000] [Progress: 58.91%] [learning rate: 5.0e+03]\n",
            "[Step 29469/50000] [Time: 252s] [Train Loss: 1.91e-01] [Train Acc: 0.95]\n",
            "[Step 29481/50000] [Progress: 58.96%] [learning rate: 5.4e+03]\n",
            "[Step 29505/50000] [Progress: 59.01%] [learning rate: 4.8e+03]\n",
            "[Step 29530/50000] [Progress: 59.06%] [learning rate: 4.7e+03]\n",
            "[Step 29556/50000] [Progress: 59.11%] [learning rate: 4.7e+03]\n",
            "[Step 29564/50000] [Time: 253s] [Train Loss: 1.91e-01] [Train Acc: 0.95]\n",
            "[Step 29581/50000] [Progress: 59.16%] [learning rate: 4.6e+03]\n",
            "[Step 29608/50000] [Progress: 59.22%] [learning rate: 5.0e+03]\n",
            "[Step 29634/50000] [Progress: 59.27%] [learning rate: 5.4e+03]\n",
            "[Step 29657/50000] [Progress: 59.31%] [learning rate: 4.4e+03]\n",
            "[Step 29659/50000] [Time: 253s] [Train Loss: 1.91e-01] [Train Acc: 0.95]\n",
            "[Step 29683/50000] [Progress: 59.37%] [learning rate: 4.8e+03]\n",
            "[Step 29709/50000] [Progress: 59.42%] [learning rate: 5.2e+03]\n",
            "[Step 29732/50000] [Progress: 59.46%] [learning rate: 4.6e+03]\n",
            "[Step 29754/50000] [Time: 254s] [Train Loss: 1.90e-01] [Train Acc: 0.95]\n",
            "[Step 29757/50000] [Progress: 59.51%] [learning rate: 5.0e+03]\n",
            "[Step 29782/50000] [Progress: 59.56%] [learning rate: 4.9e+03]\n",
            "[Step 29808/50000] [Progress: 59.62%] [learning rate: 4.9e+03]\n",
            "[Step 29832/50000] [Progress: 59.66%] [learning rate: 4.8e+03]\n",
            "[Step 29849/50000] [Time: 255s] [Train Loss: 1.90e-01] [Train Acc: 0.95]\n",
            "[Step 29857/50000] [Progress: 59.71%] [learning rate: 4.7e+03]\n",
            "[Step 29883/50000] [Progress: 59.77%] [learning rate: 5.1e+03]\n",
            "[Step 29907/50000] [Progress: 59.81%] [learning rate: 4.6e+03]\n",
            "[Step 29934/50000] [Progress: 59.87%] [learning rate: 5.4e+03]\n",
            "[Step 29944/50000] [Time: 255s] [Train Loss: 1.90e-01] [Train Acc: 0.95]\n",
            "[Step 29957/50000] [Progress: 59.91%] [learning rate: 4.4e+03]\n",
            "[Step 29983/50000] [Progress: 59.97%] [learning rate: 4.8e+03]\n",
            "[Step 30007/50000] [Progress: 60.01%] [learning rate: 4.7e+03]\n",
            "[Step 30032/50000] [Progress: 60.06%] [learning rate: 4.7e+03]\n",
            "[Step 30039/50000] [Time: 256s] [Train Loss: 1.89e-01] [Train Acc: 0.95]\n",
            "[Step 30057/50000] [Progress: 60.11%] [learning rate: 5.1e+03]\n",
            "[Step 30081/50000] [Progress: 60.16%] [learning rate: 5.0e+03]\n",
            "[Step 30106/50000] [Progress: 60.21%] [learning rate: 4.9e+03]\n",
            "[Step 30132/50000] [Progress: 60.26%] [learning rate: 4.8e+03]\n",
            "[Step 30135/50000] [Time: 257s] [Train Loss: 1.89e-01] [Train Acc: 0.95]\n",
            "[Step 30156/50000] [Progress: 60.31%] [learning rate: 4.8e+03]\n",
            "[Step 30181/50000] [Progress: 60.36%] [learning rate: 4.7e+03]\n",
            "[Step 30206/50000] [Progress: 60.41%] [learning rate: 4.6e+03]\n",
            "[Step 30231/50000] [Time: 257s] [Train Loss: 1.88e-01] [Train Acc: 0.96]\n",
            "[Step 30232/50000] [Progress: 60.46%] [learning rate: 5.0e+03]\n",
            "[Step 30259/50000] [Progress: 60.52%] [learning rate: 5.4e+03]\n",
            "[Step 30283/50000] [Progress: 60.57%] [learning rate: 4.8e+03]\n",
            "[Step 30308/50000] [Progress: 60.62%] [learning rate: 4.8e+03]\n",
            "[Step 30327/50000] [Time: 258s] [Train Loss: 1.88e-01] [Train Acc: 0.96]\n",
            "[Step 30334/50000] [Progress: 60.67%] [learning rate: 4.7e+03]\n",
            "[Step 30359/50000] [Progress: 60.72%] [learning rate: 4.6e+03]\n",
            "[Step 30386/50000] [Progress: 60.77%] [learning rate: 5.0e+03]\n",
            "[Step 30412/50000] [Progress: 60.82%] [learning rate: 5.4e+03]\n",
            "[Step 30423/50000] [Time: 259s] [Train Loss: 1.88e-01] [Train Acc: 0.96]\n",
            "[Step 30435/50000] [Progress: 60.87%] [learning rate: 4.4e+03]\n",
            "[Step 30462/50000] [Progress: 60.92%] [learning rate: 5.3e+03]\n",
            "[Step 30485/50000] [Progress: 60.97%] [learning rate: 4.3e+03]\n",
            "[Step 30511/50000] [Progress: 61.02%] [learning rate: 5.1e+03]\n",
            "[Step 30519/50000] [Time: 259s] [Train Loss: 1.87e-01] [Train Acc: 0.96]\n",
            "[Step 30535/50000] [Progress: 61.07%] [learning rate: 4.6e+03]\n",
            "[Step 30562/50000] [Progress: 61.12%] [learning rate: 5.5e+03]\n",
            "[Step 30586/50000] [Progress: 61.17%] [learning rate: 4.9e+03]\n",
            "[Step 30611/50000] [Progress: 61.22%] [learning rate: 4.8e+03]\n",
            "[Step 30615/50000] [Time: 260s] [Train Loss: 1.87e-01] [Train Acc: 0.96]\n",
            "[Step 30637/50000] [Progress: 61.27%] [learning rate: 4.7e+03]\n",
            "[Step 30663/50000] [Progress: 61.33%] [learning rate: 5.1e+03]\n",
            "[Step 30687/50000] [Progress: 61.37%] [learning rate: 4.6e+03]\n",
            "[Step 30711/50000] [Time: 261s] [Train Loss: 1.87e-01] [Train Acc: 0.96]\n",
            "[Step 30713/50000] [Progress: 61.43%] [learning rate: 5.5e+03]\n",
            "[Step 30736/50000] [Progress: 61.47%] [learning rate: 4.5e+03]\n",
            "[Step 30763/50000] [Progress: 61.53%] [learning rate: 5.3e+03]\n",
            "[Step 30786/50000] [Progress: 61.57%] [learning rate: 4.8e+03]\n",
            "[Step 30807/50000] [Time: 261s] [Train Loss: 1.86e-01] [Train Acc: 0.96]\n",
            "[Step 30811/50000] [Progress: 61.62%] [learning rate: 4.7e+03]\n",
            "[Step 30836/50000] [Progress: 61.67%] [learning rate: 4.6e+03]\n",
            "[Step 30862/50000] [Progress: 61.72%] [learning rate: 5.5e+03]\n",
            "[Step 30885/50000] [Progress: 61.77%] [learning rate: 4.5e+03]\n",
            "[Step 30903/50000] [Time: 262s] [Train Loss: 1.86e-01] [Train Acc: 0.96]\n",
            "[Step 30912/50000] [Progress: 61.82%] [learning rate: 5.3e+03]\n",
            "[Step 30935/50000] [Progress: 61.87%] [learning rate: 4.4e+03]\n",
            "[Step 30961/50000] [Progress: 61.92%] [learning rate: 5.2e+03]\n",
            "[Step 30985/50000] [Progress: 61.97%] [learning rate: 4.6e+03]\n",
            "[Step 30999/50000] [Time: 263s] [Train Loss: 1.85e-01] [Train Acc: 0.96]\n",
            "[Step 31012/50000] [Progress: 62.02%] [learning rate: 5.5e+03]\n",
            "[Step 31035/50000] [Progress: 62.07%] [learning rate: 4.5e+03]\n",
            "[Step 31061/50000] [Progress: 62.12%] [learning rate: 4.9e+03]\n",
            "[Step 31085/50000] [Progress: 62.17%] [learning rate: 4.8e+03]\n",
            "[Step 31095/50000] [Time: 264s] [Train Loss: 1.85e-01] [Train Acc: 0.96]\n",
            "[Step 31110/50000] [Progress: 62.22%] [learning rate: 4.7e+03]\n",
            "[Step 31135/50000] [Progress: 62.27%] [learning rate: 5.1e+03]\n",
            "[Step 31159/50000] [Progress: 62.32%] [learning rate: 4.6e+03]\n",
            "[Step 31186/50000] [Progress: 62.37%] [learning rate: 5.5e+03]\n",
            "[Step 31191/50000] [Time: 265s] [Train Loss: 1.85e-01] [Train Acc: 0.96]\n",
            "[Step 31210/50000] [Progress: 62.42%] [learning rate: 4.9e+03]\n",
            "[Step 31235/50000] [Progress: 62.47%] [learning rate: 4.8e+03]\n",
            "[Step 31261/50000] [Progress: 62.52%] [learning rate: 4.8e+03]\n",
            "[Step 31286/50000] [Progress: 62.57%] [learning rate: 4.7e+03]\n",
            "[Step 31287/50000] [Time: 265s] [Train Loss: 1.84e-01] [Train Acc: 0.96]\n",
            "[Step 31311/50000] [Progress: 62.62%] [learning rate: 5.1e+03]\n",
            "[Step 31337/50000] [Progress: 62.67%] [learning rate: 5.5e+03]\n",
            "[Step 31361/50000] [Progress: 62.72%] [learning rate: 4.9e+03]\n",
            "[Step 31383/50000] [Time: 266s] [Train Loss: 1.84e-01] [Train Acc: 0.96]\n",
            "[Step 31386/50000] [Progress: 62.77%] [learning rate: 4.9e+03]\n",
            "[Step 31412/50000] [Progress: 62.82%] [learning rate: 5.3e+03]\n",
            "[Step 31435/50000] [Progress: 62.87%] [learning rate: 4.7e+03]\n",
            "[Step 31461/50000] [Progress: 62.92%] [learning rate: 5.1e+03]\n",
            "[Step 31479/50000] [Time: 267s] [Train Loss: 1.84e-01] [Train Acc: 0.96]\n",
            "[Step 31488/50000] [Progress: 62.98%] [learning rate: 5.5e+03]\n",
            "[Step 31513/50000] [Progress: 63.03%] [learning rate: 5.0e+03]\n",
            "[Step 31539/50000] [Progress: 63.08%] [learning rate: 4.9e+03]\n",
            "[Step 31565/50000] [Progress: 63.13%] [learning rate: 4.8e+03]\n",
            "[Step 31575/50000] [Time: 268s] [Train Loss: 1.83e-01] [Train Acc: 0.96]\n",
            "[Step 31590/50000] [Progress: 63.18%] [learning rate: 4.7e+03]\n",
            "[Step 31615/50000] [Progress: 63.23%] [learning rate: 5.1e+03]\n",
            "[Step 31640/50000] [Progress: 63.28%] [learning rate: 5.0e+03]\n",
            "[Step 31664/50000] [Progress: 63.33%] [learning rate: 5.0e+03]\n",
            "[Step 31671/50000] [Time: 269s] [Train Loss: 1.83e-01] [Train Acc: 0.96]\n",
            "[Step 31689/50000] [Progress: 63.38%] [learning rate: 4.9e+03]\n",
            "[Step 31715/50000] [Progress: 63.43%] [learning rate: 4.8e+03]\n",
            "[Step 31740/50000] [Progress: 63.48%] [learning rate: 4.8e+03]\n",
            "[Step 31767/50000] [Progress: 63.53%] [learning rate: 5.1e+03]\n",
            "[Step 31767/50000] [Time: 269s] [Train Loss: 1.83e-01] [Train Acc: 0.96]\n",
            "[Step 31793/50000] [Progress: 63.59%] [learning rate: 5.6e+03]\n",
            "[Step 31816/50000] [Progress: 63.63%] [learning rate: 4.5e+03]\n",
            "[Step 31843/50000] [Progress: 63.69%] [learning rate: 5.4e+03]\n",
            "[Step 31863/50000] [Time: 270s] [Train Loss: 1.82e-01] [Train Acc: 0.96]\n",
            "[Step 31866/50000] [Progress: 63.73%] [learning rate: 4.4e+03]\n",
            "[Step 31892/50000] [Progress: 63.78%] [learning rate: 5.3e+03]\n",
            "[Step 31916/50000] [Progress: 63.83%] [learning rate: 4.7e+03]\n",
            "[Step 31943/50000] [Progress: 63.89%] [learning rate: 5.6e+03]\n",
            "[Step 31959/50000] [Time: 271s] [Train Loss: 1.82e-01] [Train Acc: 0.96]\n",
            "[Step 31966/50000] [Progress: 63.93%] [learning rate: 5.0e+03]\n",
            "[Step 31991/50000] [Progress: 63.98%] [learning rate: 4.9e+03]\n",
            "[Step 32017/50000] [Progress: 64.03%] [learning rate: 4.9e+03]\n",
            "[Step 32043/50000] [Progress: 64.09%] [learning rate: 5.3e+03]\n",
            "[Step 32055/50000] [Time: 271s] [Train Loss: 1.82e-01] [Train Acc: 0.96]\n",
            "[Step 32067/50000] [Progress: 64.13%] [learning rate: 4.7e+03]\n",
            "[Step 32094/50000] [Progress: 64.19%] [learning rate: 5.6e+03]\n",
            "[Step 32117/50000] [Progress: 64.23%] [learning rate: 4.6e+03]\n",
            "[Step 32143/50000] [Progress: 64.29%] [learning rate: 5.0e+03]\n",
            "[Step 32151/50000] [Time: 272s] [Train Loss: 1.81e-01] [Train Acc: 0.96]\n",
            "[Step 32169/50000] [Progress: 64.34%] [learning rate: 5.4e+03]\n",
            "[Step 32192/50000] [Progress: 64.38%] [learning rate: 4.4e+03]\n",
            "[Step 32219/50000] [Progress: 64.44%] [learning rate: 5.2e+03]\n",
            "[Step 32244/50000] [Progress: 64.49%] [learning rate: 5.1e+03]\n",
            "[Step 32247/50000] [Time: 273s] [Train Loss: 1.81e-01] [Train Acc: 0.96]\n",
            "[Step 32269/50000] [Progress: 64.54%] [learning rate: 5.6e+03]\n",
            "[Step 32292/50000] [Progress: 64.58%] [learning rate: 4.5e+03]\n",
            "[Step 32319/50000] [Progress: 64.64%] [learning rate: 5.4e+03]\n",
            "[Step 32342/50000] [Progress: 64.68%] [learning rate: 4.8e+03]\n",
            "[Step 32344/50000] [Time: 274s] [Train Loss: 1.81e-01] [Train Acc: 0.96]\n",
            "[Step 32367/50000] [Progress: 64.73%] [learning rate: 5.2e+03]\n",
            "[Step 32391/50000] [Progress: 64.78%] [learning rate: 4.7e+03]\n",
            "[Step 32418/50000] [Progress: 64.84%] [learning rate: 6.2e+03]\n",
            "[Step 32439/50000] [Progress: 64.88%] [learning rate: 4.1e+03]\n",
            "[Step 32441/50000] [Time: 274s] [Train Loss: 1.80e-01] [Train Acc: 0.96]\n",
            "[Step 32466/50000] [Progress: 64.93%] [learning rate: 5.4e+03]\n",
            "[Step 32489/50000] [Progress: 64.98%] [learning rate: 4.9e+03]\n",
            "[Step 32514/50000] [Progress: 65.03%] [learning rate: 4.8e+03]\n",
            "[Step 32538/50000] [Time: 275s] [Train Loss: 1.80e-01] [Train Acc: 0.96]\n",
            "[Step 32539/50000] [Progress: 65.08%] [learning rate: 5.2e+03]\n",
            "[Step 32564/50000] [Progress: 65.13%] [learning rate: 5.6e+03]\n",
            "[Step 32587/50000] [Progress: 65.17%] [learning rate: 4.6e+03]\n",
            "[Step 32613/50000] [Progress: 65.23%] [learning rate: 5.0e+03]\n",
            "[Step 32635/50000] [Time: 276s] [Train Loss: 1.79e-01] [Train Acc: 0.96]\n",
            "[Step 32637/50000] [Progress: 65.27%] [learning rate: 4.9e+03]\n",
            "[Step 32662/50000] [Progress: 65.32%] [learning rate: 5.3e+03]\n",
            "[Step 32686/50000] [Progress: 65.37%] [learning rate: 4.7e+03]\n",
            "[Step 32714/50000] [Progress: 65.43%] [learning rate: 5.6e+03]\n",
            "[Step 32732/50000] [Time: 277s] [Train Loss: 1.79e-01] [Train Acc: 0.96]\n",
            "[Step 32739/50000] [Progress: 65.48%] [learning rate: 5.1e+03]\n",
            "[Step 32765/50000] [Progress: 65.53%] [learning rate: 5.0e+03]\n",
            "[Step 32791/50000] [Progress: 65.58%] [learning rate: 4.9e+03]\n",
            "[Step 32816/50000] [Progress: 65.63%] [learning rate: 4.8e+03]\n",
            "[Step 32829/50000] [Time: 277s] [Train Loss: 1.79e-01] [Train Acc: 0.96]\n",
            "[Step 32843/50000] [Progress: 65.69%] [learning rate: 5.2e+03]\n",
            "[Step 32869/50000] [Progress: 65.74%] [learning rate: 5.2e+03]\n",
            "[Step 32893/50000] [Progress: 65.79%] [learning rate: 5.1e+03]\n",
            "[Step 32918/50000] [Progress: 65.84%] [learning rate: 5.0e+03]\n",
            "[Step 32926/50000] [Time: 278s] [Train Loss: 1.78e-01] [Train Acc: 0.96]\n",
            "[Step 32944/50000] [Progress: 65.89%] [learning rate: 4.9e+03]\n",
            "[Step 32969/50000] [Progress: 65.94%] [learning rate: 4.9e+03]\n",
            "[Step 32996/50000] [Progress: 65.99%] [learning rate: 5.3e+03]\n",
            "[Step 33022/50000] [Progress: 66.04%] [learning rate: 5.2e+03]\n",
            "[Step 33023/50000] [Time: 279s] [Train Loss: 1.78e-01] [Train Acc: 0.96]\n",
            "[Step 33048/50000] [Progress: 66.10%] [learning rate: 5.6e+03]\n",
            "[Step 33071/50000] [Progress: 66.14%] [learning rate: 4.6e+03]\n",
            "[Step 33098/50000] [Progress: 66.20%] [learning rate: 5.4e+03]\n",
            "[Step 33120/50000] [Time: 279s] [Train Loss: 1.78e-01] [Train Acc: 0.96]\n",
            "[Step 33121/50000] [Progress: 66.24%] [learning rate: 4.9e+03]\n",
            "[Step 33146/50000] [Progress: 66.29%] [learning rate: 5.3e+03]\n",
            "[Step 33170/50000] [Progress: 66.34%] [learning rate: 5.2e+03]\n",
            "[Step 33195/50000] [Progress: 66.39%] [learning rate: 5.1e+03]\n",
            "[Step 33217/50000] [Time: 280s] [Train Loss: 1.77e-01] [Train Acc: 0.96]\n",
            "[Step 33219/50000] [Progress: 66.44%] [learning rate: 5.0e+03]\n",
            "[Step 33244/50000] [Progress: 66.49%] [learning rate: 5.0e+03]\n",
            "[Step 33270/50000] [Progress: 66.54%] [learning rate: 5.4e+03]\n",
            "[Step 33293/50000] [Progress: 66.59%] [learning rate: 4.8e+03]\n",
            "[Step 33314/50000] [Time: 281s] [Train Loss: 1.77e-01] [Train Acc: 0.96]\n",
            "[Step 33319/50000] [Progress: 66.64%] [learning rate: 5.2e+03]\n",
            "[Step 33346/50000] [Progress: 66.69%] [learning rate: 5.7e+03]\n",
            "[Step 33368/50000] [Progress: 66.74%] [learning rate: 4.6e+03]\n",
            "[Step 33394/50000] [Progress: 66.79%] [learning rate: 5.5e+03]\n",
            "[Step 33411/50000] [Time: 282s] [Train Loss: 1.77e-01] [Train Acc: 0.96]\n",
            "[Step 33417/50000] [Progress: 66.83%] [learning rate: 4.9e+03]\n",
            "[Step 33442/50000] [Progress: 66.88%] [learning rate: 5.3e+03]\n",
            "[Step 33466/50000] [Progress: 66.93%] [learning rate: 4.8e+03]\n",
            "[Step 33495/50000] [Progress: 66.99%] [learning rate: 6.3e+03]\n",
            "[Step 33508/50000] [Time: 282s] [Train Loss: 1.76e-01] [Train Acc: 0.96]\n",
            "[Step 33518/50000] [Progress: 67.04%] [learning rate: 5.1e+03]\n",
            "[Step 33543/50000] [Progress: 67.09%] [learning rate: 5.0e+03]\n",
            "[Step 33569/50000] [Progress: 67.14%] [learning rate: 4.9e+03]\n",
            "[Step 33595/50000] [Progress: 67.19%] [learning rate: 5.4e+03]\n",
            "[Step 33605/50000] [Time: 283s] [Train Loss: 1.76e-01] [Train Acc: 0.96] [Eval Loss: 5.13e-01] [Eval Acc: 0.78]\n",
            "[Step 33619/50000] [Progress: 67.24%] [learning rate: 5.3e+03]\n",
            "[Step 33644/50000] [Progress: 67.29%] [learning rate: 5.2e+03]\n",
            "[Step 33670/50000] [Progress: 67.34%] [learning rate: 5.6e+03]\n",
            "[Step 33693/50000] [Progress: 67.39%] [learning rate: 4.6e+03]\n",
            "[Step 33702/50000] [Time: 285s] [Train Loss: 1.76e-01] [Train Acc: 0.96]\n",
            "[Step 33720/50000] [Progress: 67.44%] [learning rate: 5.5e+03]\n",
            "[Step 33743/50000] [Progress: 67.49%] [learning rate: 4.9e+03]\n",
            "[Step 33769/50000] [Progress: 67.54%] [learning rate: 5.3e+03]\n",
            "[Step 33795/50000] [Progress: 67.59%] [learning rate: 5.2e+03]\n",
            "[Step 33799/50000] [Time: 286s] [Train Loss: 1.75e-01] [Train Acc: 0.96]\n",
            "[Step 33819/50000] [Progress: 67.64%] [learning rate: 5.1e+03]\n",
            "[Step 33844/50000] [Progress: 67.69%] [learning rate: 5.1e+03]\n",
            "[Step 33870/50000] [Progress: 67.74%] [learning rate: 5.0e+03]\n",
            "[Step 33895/50000] [Progress: 67.79%] [learning rate: 4.9e+03]\n",
            "[Step 33896/50000] [Time: 287s] [Train Loss: 1.75e-01] [Train Acc: 0.96]\n",
            "[Step 33922/50000] [Progress: 67.84%] [learning rate: 5.3e+03]\n",
            "[Step 33948/50000] [Progress: 67.90%] [learning rate: 5.2e+03]\n",
            "[Step 33974/50000] [Progress: 67.95%] [learning rate: 5.7e+03]\n",
            "[Step 33993/50000] [Time: 287s] [Train Loss: 1.75e-01] [Train Acc: 0.96]\n",
            "[Step 33997/50000] [Progress: 67.99%] [learning rate: 4.6e+03]\n",
            "[Step 34024/50000] [Progress: 68.05%] [learning rate: 5.5e+03]\n",
            "[Step 34047/50000] [Progress: 68.09%] [learning rate: 4.9e+03]\n",
            "[Step 34072/50000] [Progress: 68.14%] [learning rate: 5.3e+03]\n",
            "[Step 34090/50000] [Time: 288s] [Train Loss: 1.74e-01] [Train Acc: 0.96]\n",
            "[Step 34096/50000] [Progress: 68.19%] [learning rate: 5.3e+03]\n",
            "[Step 34121/50000] [Progress: 68.24%] [learning rate: 5.7e+03]\n",
            "[Step 34144/50000] [Progress: 68.29%] [learning rate: 4.6e+03]\n",
            "[Step 34171/50000] [Progress: 68.34%] [learning rate: 5.5e+03]\n",
            "[Step 34187/50000] [Time: 289s] [Train Loss: 1.74e-01] [Train Acc: 0.96]\n",
            "[Step 34194/50000] [Progress: 68.39%] [learning rate: 5.0e+03]\n",
            "[Step 34219/50000] [Progress: 68.44%] [learning rate: 5.4e+03]\n",
            "[Step 34243/50000] [Progress: 68.49%] [learning rate: 5.3e+03]\n",
            "[Step 34268/50000] [Progress: 68.54%] [learning rate: 5.7e+03]\n",
            "[Step 34284/50000] [Time: 290s] [Train Loss: 1.74e-01] [Train Acc: 0.96]\n",
            "[Step 34291/50000] [Progress: 68.58%] [learning rate: 4.7e+03]\n",
            "[Step 34318/50000] [Progress: 68.64%] [learning rate: 5.6e+03]\n",
            "[Step 34341/50000] [Progress: 68.68%] [learning rate: 4.5e+03]\n",
            "[Step 34368/50000] [Progress: 68.74%] [learning rate: 5.4e+03]\n",
            "[Step 34381/50000] [Time: 291s] [Train Loss: 1.73e-01] [Train Acc: 0.96]\n",
            "[Step 34393/50000] [Progress: 68.79%] [learning rate: 5.3e+03]\n",
            "[Step 34420/50000] [Progress: 68.84%] [learning rate: 6.3e+03]\n",
            "[Step 34443/50000] [Progress: 68.89%] [learning rate: 5.1e+03]\n",
            "[Step 34468/50000] [Progress: 68.94%] [learning rate: 5.1e+03]\n",
            "[Step 34478/50000] [Time: 291s] [Train Loss: 1.73e-01] [Train Acc: 0.96]\n",
            "[Step 34494/50000] [Progress: 68.99%] [learning rate: 5.0e+03]\n",
            "[Step 34519/50000] [Progress: 69.04%] [learning rate: 4.9e+03]\n",
            "[Step 34544/50000] [Progress: 69.09%] [learning rate: 5.3e+03]\n",
            "[Step 34569/50000] [Progress: 69.14%] [learning rate: 5.8e+03]\n",
            "[Step 34575/50000] [Time: 292s] [Train Loss: 1.73e-01] [Train Acc: 0.96]\n",
            "[Step 34592/50000] [Progress: 69.18%] [learning rate: 4.7e+03]\n",
            "[Step 34619/50000] [Progress: 69.24%] [learning rate: 5.6e+03]\n",
            "[Step 34642/50000] [Progress: 69.28%] [learning rate: 5.0e+03]\n",
            "[Step 34667/50000] [Progress: 69.33%] [learning rate: 4.9e+03]\n",
            "[Step 34672/50000] [Time: 293s] [Train Loss: 1.72e-01] [Train Acc: 0.96]\n",
            "[Step 34692/50000] [Progress: 69.38%] [learning rate: 5.4e+03]\n",
            "[Step 34717/50000] [Progress: 69.43%] [learning rate: 5.3e+03]\n",
            "[Step 34743/50000] [Progress: 69.49%] [learning rate: 5.7e+03]\n",
            "[Step 34766/50000] [Progress: 69.53%] [learning rate: 4.7e+03]\n",
            "[Step 34769/50000] [Time: 294s] [Train Loss: 1.72e-01] [Train Acc: 0.96]\n",
            "[Step 34793/50000] [Progress: 69.59%] [learning rate: 5.5e+03]\n",
            "[Step 34816/50000] [Progress: 69.63%] [learning rate: 5.0e+03]\n",
            "[Step 34841/50000] [Progress: 69.68%] [learning rate: 5.4e+03]\n",
            "[Step 34866/50000] [Progress: 69.73%] [learning rate: 5.3e+03]\n",
            "[Step 34866/50000] [Time: 294s] [Train Loss: 1.72e-01] [Train Acc: 0.96]\n",
            "[Step 34892/50000] [Progress: 69.78%] [learning rate: 5.7e+03]\n",
            "[Step 34915/50000] [Progress: 69.83%] [learning rate: 4.7e+03]\n",
            "[Step 34942/50000] [Progress: 69.88%] [learning rate: 5.6e+03]\n",
            "[Step 34963/50000] [Time: 295s] [Train Loss: 1.72e-01] [Train Acc: 0.96]\n",
            "[Step 34965/50000] [Progress: 69.93%] [learning rate: 5.0e+03]\n",
            "[Step 34990/50000] [Progress: 69.98%] [learning rate: 5.4e+03]\n",
            "[Step 35015/50000] [Progress: 70.03%] [learning rate: 5.3e+03]\n",
            "[Step 35041/50000] [Progress: 70.08%] [learning rate: 5.2e+03]\n",
            "[Step 35060/50000] [Time: 296s] [Train Loss: 1.71e-01] [Train Acc: 0.96]\n",
            "[Step 35065/50000] [Progress: 70.13%] [learning rate: 5.2e+03]\n",
            "[Step 35090/50000] [Progress: 70.18%] [learning rate: 5.1e+03]\n",
            "[Step 35116/50000] [Progress: 70.23%] [learning rate: 5.5e+03]\n",
            "[Step 35139/50000] [Progress: 70.28%] [learning rate: 4.9e+03]\n",
            "[Step 35157/50000] [Time: 296s] [Train Loss: 1.71e-01] [Train Acc: 0.96]\n",
            "[Step 35165/50000] [Progress: 70.33%] [learning rate: 5.3e+03]\n",
            "[Step 35190/50000] [Progress: 70.38%] [learning rate: 5.3e+03]\n",
            "[Step 35214/50000] [Progress: 70.43%] [learning rate: 5.2e+03]\n",
            "[Step 35239/50000] [Progress: 70.48%] [learning rate: 5.1e+03]\n",
            "[Step 35255/50000] [Time: 297s] [Train Loss: 1.71e-01] [Train Acc: 0.96]\n",
            "[Step 35265/50000] [Progress: 70.53%] [learning rate: 5.0e+03]\n",
            "[Step 35290/50000] [Progress: 70.58%] [learning rate: 5.0e+03]\n",
            "[Step 35316/50000] [Progress: 70.63%] [learning rate: 5.4e+03]\n",
            "[Step 35343/50000] [Progress: 70.69%] [learning rate: 5.8e+03]\n",
            "[Step 35353/50000] [Time: 298s] [Train Loss: 1.70e-01] [Train Acc: 0.96]\n",
            "[Step 35366/50000] [Progress: 70.73%] [learning rate: 4.7e+03]\n",
            "[Step 35393/50000] [Progress: 70.79%] [learning rate: 5.6e+03]\n",
            "[Step 35416/50000] [Progress: 70.83%] [learning rate: 4.6e+03]\n",
            "[Step 35442/50000] [Progress: 70.88%] [learning rate: 5.5e+03]\n",
            "[Step 35451/50000] [Time: 298s] [Train Loss: 1.70e-01] [Train Acc: 0.96]\n",
            "[Step 35466/50000] [Progress: 70.93%] [learning rate: 5.4e+03]\n",
            "[Step 35491/50000] [Progress: 70.98%] [learning rate: 5.8e+03]\n",
            "[Step 35514/50000] [Progress: 71.03%] [learning rate: 4.8e+03]\n",
            "[Step 35541/50000] [Progress: 71.08%] [learning rate: 5.7e+03]\n",
            "[Step 35549/50000] [Time: 299s] [Train Loss: 1.70e-01] [Train Acc: 0.96]\n",
            "[Step 35564/50000] [Progress: 71.13%] [learning rate: 5.1e+03]\n",
            "[Step 35589/50000] [Progress: 71.18%] [learning rate: 5.0e+03]\n",
            "[Step 35614/50000] [Progress: 71.23%] [learning rate: 5.4e+03]\n",
            "[Step 35639/50000] [Progress: 71.28%] [learning rate: 5.3e+03]\n",
            "[Step 35647/50000] [Time: 300s] [Train Loss: 1.69e-01] [Train Acc: 0.97]\n",
            "[Step 35663/50000] [Progress: 71.33%] [learning rate: 5.3e+03]\n",
            "[Step 35688/50000] [Progress: 71.38%] [learning rate: 5.2e+03]\n",
            "[Step 35714/50000] [Progress: 71.43%] [learning rate: 5.1e+03]\n",
            "[Step 35739/50000] [Progress: 71.48%] [learning rate: 5.0e+03]\n",
            "[Step 35745/50000] [Time: 301s] [Train Loss: 1.69e-01] [Train Acc: 0.97]\n",
            "[Step 35766/50000] [Progress: 71.53%] [learning rate: 5.4e+03]\n",
            "[Step 35792/50000] [Progress: 71.58%] [learning rate: 5.4e+03]\n",
            "[Step 35818/50000] [Progress: 71.64%] [learning rate: 5.8e+03]\n",
            "[Step 35841/50000] [Progress: 71.68%] [learning rate: 4.7e+03]\n",
            "[Step 35843/50000] [Time: 301s] [Train Loss: 1.69e-01] [Train Acc: 0.97]\n",
            "[Step 35868/50000] [Progress: 71.74%] [learning rate: 5.6e+03]\n",
            "[Step 35891/50000] [Progress: 71.78%] [learning rate: 5.0e+03]\n",
            "[Step 35917/50000] [Progress: 71.83%] [learning rate: 5.5e+03]\n",
            "[Step 35941/50000] [Time: 302s] [Train Loss: 1.68e-01] [Train Acc: 0.97]\n",
            "[Step 35943/50000] [Progress: 71.89%] [learning rate: 5.4e+03]\n",
            "[Step 35969/50000] [Progress: 71.94%] [learning rate: 5.3e+03]\n",
            "[Step 35993/50000] [Progress: 71.99%] [learning rate: 5.2e+03]\n",
            "[Step 36018/50000] [Progress: 72.04%] [learning rate: 5.1e+03]\n",
            "[Step 36039/50000] [Time: 303s] [Train Loss: 1.68e-01] [Train Acc: 0.97]\n",
            "[Step 36044/50000] [Progress: 72.09%] [learning rate: 5.6e+03]\n",
            "[Step 36068/50000] [Progress: 72.14%] [learning rate: 5.0e+03]\n",
            "[Step 36095/50000] [Progress: 72.19%] [learning rate: 5.4e+03]\n",
            "[Step 36120/50000] [Progress: 72.24%] [learning rate: 5.3e+03]\n",
            "[Step 36137/50000] [Time: 304s] [Train Loss: 1.68e-01] [Train Acc: 0.97]\n",
            "[Step 36146/50000] [Progress: 72.29%] [learning rate: 5.2e+03]\n",
            "[Step 36170/50000] [Progress: 72.34%] [learning rate: 5.2e+03]\n",
            "[Step 36195/50000] [Progress: 72.39%] [learning rate: 5.1e+03]\n",
            "[Step 36220/50000] [Progress: 72.44%] [learning rate: 5.0e+03]\n",
            "[Step 36235/50000] [Time: 305s] [Train Loss: 1.67e-01] [Train Acc: 0.97]\n",
            "[Step 36245/50000] [Progress: 72.49%] [learning rate: 5.4e+03]\n",
            "[Step 36271/50000] [Progress: 72.54%] [learning rate: 5.9e+03]\n",
            "[Step 36295/50000] [Progress: 72.59%] [learning rate: 5.3e+03]\n",
            "[Step 36320/50000] [Progress: 72.64%] [learning rate: 5.2e+03]\n",
            "[Step 36333/50000] [Time: 305s] [Train Loss: 1.67e-01] [Train Acc: 0.97]\n",
            "[Step 36346/50000] [Progress: 72.69%] [learning rate: 5.1e+03]\n",
            "[Step 36371/50000] [Progress: 72.74%] [learning rate: 5.0e+03]\n",
            "[Step 36396/50000] [Progress: 72.79%] [learning rate: 5.5e+03]\n",
            "[Step 36422/50000] [Progress: 72.84%] [learning rate: 5.9e+03]\n",
            "[Step 36431/50000] [Time: 306s] [Train Loss: 1.67e-01] [Train Acc: 0.97]\n",
            "[Step 36446/50000] [Progress: 72.89%] [learning rate: 5.3e+03]\n",
            "[Step 36471/50000] [Progress: 72.94%] [learning rate: 5.2e+03]\n",
            "[Step 36497/50000] [Progress: 72.99%] [learning rate: 5.1e+03]\n",
            "[Step 36522/50000] [Progress: 73.04%] [learning rate: 5.1e+03]\n",
            "[Step 36529/50000] [Time: 307s] [Train Loss: 1.66e-01] [Train Acc: 0.97]\n",
            "[Step 36549/50000] [Progress: 73.10%] [learning rate: 5.5e+03]\n",
            "[Step 36575/50000] [Progress: 73.15%] [learning rate: 5.9e+03]\n",
            "[Step 36598/50000] [Progress: 73.20%] [learning rate: 4.8e+03]\n",
            "[Step 36624/50000] [Progress: 73.25%] [learning rate: 5.2e+03]\n",
            "[Step 36627/50000] [Time: 307s] [Train Loss: 1.66e-01] [Train Acc: 0.97]\n",
            "[Step 36649/50000] [Progress: 73.30%] [learning rate: 5.2e+03]\n",
            "[Step 36675/50000] [Progress: 73.35%] [learning rate: 5.6e+03]\n",
            "[Step 36699/50000] [Progress: 73.40%] [learning rate: 5.0e+03]\n",
            "[Step 36725/50000] [Time: 308s] [Train Loss: 1.66e-01] [Train Acc: 0.97]\n",
            "[Step 36726/50000] [Progress: 73.45%] [learning rate: 6.0e+03]\n",
            "[Step 36749/50000] [Progress: 73.50%] [learning rate: 4.9e+03]\n",
            "[Step 36775/50000] [Progress: 73.55%] [learning rate: 5.3e+03]\n",
            "[Step 36800/50000] [Progress: 73.60%] [learning rate: 5.2e+03]\n",
            "[Step 36823/50000] [Time: 309s] [Train Loss: 1.66e-01] [Train Acc: 0.97]\n",
            "[Step 36826/50000] [Progress: 73.65%] [learning rate: 5.1e+03]\n",
            "[Step 36851/50000] [Progress: 73.70%] [learning rate: 5.5e+03]\n",
            "[Step 36875/50000] [Progress: 73.75%] [learning rate: 5.4e+03]\n",
            "[Step 36900/50000] [Progress: 73.80%] [learning rate: 5.4e+03]\n",
            "[Step 36921/50000] [Time: 310s] [Train Loss: 1.65e-01] [Train Acc: 0.97]\n",
            "[Step 36924/50000] [Progress: 73.85%] [learning rate: 5.3e+03]\n",
            "[Step 36949/50000] [Progress: 73.90%] [learning rate: 5.2e+03]\n",
            "[Step 36975/50000] [Progress: 73.95%] [learning rate: 5.6e+03]\n",
            "[Step 36998/50000] [Progress: 74.00%] [learning rate: 5.1e+03]\n",
            "[Step 37019/50000] [Time: 310s] [Train Loss: 1.65e-01] [Train Acc: 0.97]\n",
            "[Step 37024/50000] [Progress: 74.05%] [learning rate: 6.0e+03]\n",
            "[Step 37047/50000] [Progress: 74.09%] [learning rate: 4.9e+03]\n",
            "[Step 37073/50000] [Progress: 74.15%] [learning rate: 5.3e+03]\n",
            "[Step 37097/50000] [Progress: 74.19%] [learning rate: 5.2e+03]\n",
            "[Step 37117/50000] [Time: 311s] [Train Loss: 1.65e-01] [Train Acc: 0.97]\n",
            "[Step 37122/50000] [Progress: 74.24%] [learning rate: 5.2e+03]\n",
            "[Step 37147/50000] [Progress: 74.29%] [learning rate: 5.1e+03]\n",
            "[Step 37173/50000] [Progress: 74.35%] [learning rate: 5.5e+03]\n",
            "[Step 37200/50000] [Progress: 74.40%] [learning rate: 6.0e+03]\n",
            "[Step 37215/50000] [Time: 312s] [Train Loss: 1.64e-01] [Train Acc: 0.97]\n",
            "[Step 37224/50000] [Progress: 74.45%] [learning rate: 5.3e+03]\n",
            "[Step 37249/50000] [Progress: 74.50%] [learning rate: 5.3e+03]\n",
            "[Step 37275/50000] [Progress: 74.55%] [learning rate: 5.2e+03]\n",
            "[Step 37300/50000] [Progress: 74.60%] [learning rate: 5.1e+03]\n",
            "[Step 37313/50000] [Time: 313s] [Train Loss: 1.64e-01] [Train Acc: 0.97]\n",
            "[Step 37325/50000] [Progress: 74.65%] [learning rate: 5.5e+03]\n",
            "[Step 37351/50000] [Progress: 74.70%] [learning rate: 6.0e+03]\n",
            "[Step 37375/50000] [Progress: 74.75%] [learning rate: 5.4e+03]\n",
            "[Step 37400/50000] [Progress: 74.80%] [learning rate: 5.3e+03]\n",
            "[Step 37411/50000] [Time: 313s] [Train Loss: 1.64e-01] [Train Acc: 0.97]\n",
            "[Step 37426/50000] [Progress: 74.85%] [learning rate: 5.7e+03]\n",
            "[Step 37449/50000] [Progress: 74.90%] [learning rate: 5.1e+03]\n",
            "[Step 37475/50000] [Progress: 74.95%] [learning rate: 5.5e+03]\n",
            "[Step 37501/50000] [Progress: 75.00%] [learning rate: 6.0e+03]\n",
            "[Step 37509/50000] [Time: 314s] [Train Loss: 1.63e-01] [Train Acc: 0.97]\n",
            "[Step 37524/50000] [Progress: 75.05%] [learning rate: 4.9e+03]\n",
            "[Step 37551/50000] [Progress: 75.10%] [learning rate: 5.8e+03]\n",
            "[Step 37574/50000] [Progress: 75.15%] [learning rate: 4.7e+03]\n",
            "[Step 37600/50000] [Progress: 75.20%] [learning rate: 5.7e+03]\n",
            "[Step 37607/50000] [Time: 315s] [Train Loss: 1.63e-01] [Train Acc: 0.97]\n",
            "[Step 37624/50000] [Progress: 75.25%] [learning rate: 5.1e+03]\n",
            "[Step 37650/50000] [Progress: 75.30%] [learning rate: 6.0e+03]\n",
            "[Step 37673/50000] [Progress: 75.35%] [learning rate: 4.9e+03]\n",
            "[Step 37700/50000] [Progress: 75.40%] [learning rate: 5.9e+03]\n",
            "[Step 37705/50000] [Time: 316s] [Train Loss: 1.63e-01] [Train Acc: 0.97]\n",
            "[Step 37723/50000] [Progress: 75.45%] [learning rate: 4.8e+03]\n",
            "[Step 37749/50000] [Progress: 75.50%] [learning rate: 5.7e+03]\n",
            "[Step 37773/50000] [Progress: 75.55%] [learning rate: 5.1e+03]\n",
            "[Step 37800/50000] [Progress: 75.60%] [learning rate: 6.1e+03]\n",
            "[Step 37803/50000] [Time: 317s] [Train Loss: 1.63e-01] [Train Acc: 0.97]\n",
            "[Step 37823/50000] [Progress: 75.65%] [learning rate: 5.4e+03]\n",
            "[Step 37847/50000] [Progress: 75.69%] [learning rate: 5.3e+03]\n",
            "[Step 37872/50000] [Progress: 75.74%] [learning rate: 5.3e+03]\n",
            "[Step 37898/50000] [Progress: 75.80%] [learning rate: 5.7e+03]\n",
            "[Step 37901/50000] [Time: 317s] [Train Loss: 1.62e-01] [Train Acc: 0.97]\n",
            "[Step 37922/50000] [Progress: 75.84%] [learning rate: 5.1e+03]\n",
            "[Step 37949/50000] [Progress: 75.90%] [learning rate: 6.1e+03]\n",
            "[Step 37972/50000] [Progress: 75.94%] [learning rate: 5.0e+03]\n",
            "[Step 37998/50000] [Progress: 76.00%] [learning rate: 5.4e+03]\n",
            "[Step 37999/50000] [Time: 318s] [Train Loss: 1.62e-01] [Train Acc: 0.97]\n",
            "[Step 38022/50000] [Progress: 76.04%] [learning rate: 5.3e+03]\n",
            "[Step 38047/50000] [Progress: 76.09%] [learning rate: 5.2e+03]\n",
            "[Step 38072/50000] [Progress: 76.14%] [learning rate: 5.1e+03]\n",
            "[Step 38097/50000] [Time: 319s] [Train Loss: 1.62e-01] [Train Acc: 0.97]\n",
            "[Step 38098/50000] [Progress: 76.20%] [learning rate: 5.6e+03]\n",
            "[Step 38125/50000] [Progress: 76.25%] [learning rate: 6.0e+03]\n",
            "[Step 38149/50000] [Progress: 76.30%] [learning rate: 5.4e+03]\n",
            "[Step 38174/50000] [Progress: 76.35%] [learning rate: 5.3e+03]\n",
            "[Step 38195/50000] [Time: 319s] [Train Loss: 1.61e-01] [Train Acc: 0.97]\n",
            "[Step 38200/50000] [Progress: 76.40%] [learning rate: 5.2e+03]\n",
            "[Step 38225/50000] [Progress: 76.45%] [learning rate: 5.2e+03]\n",
            "[Step 38252/50000] [Progress: 76.50%] [learning rate: 5.6e+03]\n",
            "[Step 38278/50000] [Progress: 76.56%] [learning rate: 6.1e+03]\n",
            "[Step 38293/50000] [Time: 320s] [Train Loss: 1.61e-01] [Train Acc: 0.97]\n",
            "[Step 38302/50000] [Progress: 76.60%] [learning rate: 5.4e+03]\n",
            "[Step 38327/50000] [Progress: 76.65%] [learning rate: 5.3e+03]\n",
            "[Step 38353/50000] [Progress: 76.71%] [learning rate: 5.3e+03]\n",
            "[Step 38378/50000] [Progress: 76.76%] [learning rate: 5.2e+03]\n",
            "[Step 38391/50000] [Time: 321s] [Train Loss: 1.61e-01] [Train Acc: 0.97]\n",
            "[Step 38405/50000] [Progress: 76.81%] [learning rate: 5.6e+03]\n",
            "[Step 38430/50000] [Progress: 76.86%] [learning rate: 5.5e+03]\n",
            "[Step 38456/50000] [Progress: 76.91%] [learning rate: 5.4e+03]\n",
            "[Step 38480/50000] [Progress: 76.96%] [learning rate: 5.4e+03]\n",
            "[Step 38489/50000] [Time: 322s] [Train Loss: 1.61e-01] [Train Acc: 0.97] [Eval Loss: 5.19e-01] [Eval Acc: 0.77]\n",
            "[Step 38505/50000] [Progress: 77.01%] [learning rate: 5.3e+03]\n",
            "[Step 38531/50000] [Progress: 77.06%] [learning rate: 5.7e+03]\n",
            "[Step 38555/50000] [Progress: 77.11%] [learning rate: 5.1e+03]\n",
            "[Step 38581/50000] [Progress: 77.16%] [learning rate: 6.1e+03]\n",
            "[Step 38587/50000] [Time: 324s] [Train Loss: 1.60e-01] [Train Acc: 0.97]\n",
            "[Step 38604/50000] [Progress: 77.21%] [learning rate: 5.0e+03]\n",
            "[Step 38631/50000] [Progress: 77.26%] [learning rate: 5.9e+03]\n",
            "[Step 38654/50000] [Progress: 77.31%] [learning rate: 4.8e+03]\n",
            "[Step 38680/50000] [Progress: 77.36%] [learning rate: 5.7e+03]\n",
            "[Step 38685/50000] [Time: 325s] [Train Loss: 1.60e-01] [Train Acc: 0.97]\n",
            "[Step 38704/50000] [Progress: 77.41%] [learning rate: 5.1e+03]\n",
            "[Step 38731/50000] [Progress: 77.46%] [learning rate: 6.1e+03]\n",
            "[Step 38754/50000] [Progress: 77.51%] [learning rate: 5.5e+03]\n",
            "[Step 38778/50000] [Progress: 77.56%] [learning rate: 5.4e+03]\n",
            "[Step 38783/50000] [Time: 325s] [Train Loss: 1.60e-01] [Train Acc: 0.97]\n",
            "[Step 38803/50000] [Progress: 77.61%] [learning rate: 5.3e+03]\n",
            "[Step 38829/50000] [Progress: 77.66%] [learning rate: 5.8e+03]\n",
            "[Step 38853/50000] [Progress: 77.71%] [learning rate: 5.2e+03]\n",
            "[Step 38880/50000] [Progress: 77.76%] [learning rate: 6.2e+03]\n",
            "[Step 38881/50000] [Time: 326s] [Train Loss: 1.59e-01] [Train Acc: 0.97]\n",
            "[Step 38903/50000] [Progress: 77.81%] [learning rate: 5.0e+03]\n",
            "[Step 38929/50000] [Progress: 77.86%] [learning rate: 5.4e+03]\n",
            "[Step 38953/50000] [Progress: 77.91%] [learning rate: 5.4e+03]\n",
            "[Step 38978/50000] [Progress: 77.96%] [learning rate: 5.3e+03]\n",
            "[Step 38979/50000] [Time: 327s] [Train Loss: 1.59e-01] [Train Acc: 0.97]\n",
            "[Step 39003/50000] [Progress: 78.01%] [learning rate: 5.2e+03]\n",
            "[Step 39029/50000] [Progress: 78.06%] [learning rate: 5.6e+03]\n",
            "[Step 39056/50000] [Progress: 78.11%] [learning rate: 6.1e+03]\n",
            "[Step 39077/50000] [Time: 328s] [Train Loss: 1.59e-01] [Train Acc: 0.97]\n",
            "[Step 39080/50000] [Progress: 78.16%] [learning rate: 5.5e+03]\n",
            "[Step 39105/50000] [Progress: 78.21%] [learning rate: 5.4e+03]\n",
            "[Step 39131/50000] [Progress: 78.26%] [learning rate: 5.3e+03]\n",
            "[Step 39158/50000] [Progress: 78.32%] [learning rate: 5.7e+03]\n",
            "[Step 39175/50000] [Time: 329s] [Train Loss: 1.59e-01] [Train Acc: 0.97]\n",
            "[Step 39183/50000] [Progress: 78.37%] [learning rate: 5.7e+03]\n",
            "[Step 39209/50000] [Progress: 78.42%] [learning rate: 6.1e+03]\n",
            "[Step 39231/50000] [Progress: 78.46%] [learning rate: 5.0e+03]\n",
            "[Step 39257/50000] [Progress: 78.51%] [learning rate: 5.9e+03]\n",
            "[Step 39274/50000] [Time: 329s] [Train Loss: 1.58e-01] [Train Acc: 0.97]\n",
            "[Step 39280/50000] [Progress: 78.56%] [learning rate: 5.3e+03]\n",
            "[Step 39305/50000] [Progress: 78.61%] [learning rate: 5.2e+03]\n",
            "[Step 39330/50000] [Progress: 78.66%] [learning rate: 5.7e+03]\n",
            "[Step 39355/50000] [Progress: 78.71%] [learning rate: 6.2e+03]\n",
            "[Step 39373/50000] [Time: 330s] [Train Loss: 1.58e-01] [Train Acc: 0.97]\n",
            "[Step 39378/50000] [Progress: 78.76%] [learning rate: 5.0e+03]\n",
            "[Step 39405/50000] [Progress: 78.81%] [learning rate: 6.0e+03]\n",
            "[Step 39428/50000] [Progress: 78.86%] [learning rate: 4.9e+03]\n",
            "[Step 39455/50000] [Progress: 78.91%] [learning rate: 5.8e+03]\n",
            "[Step 39472/50000] [Time: 331s] [Train Loss: 1.58e-01] [Train Acc: 0.97]\n",
            "[Step 39480/50000] [Progress: 78.96%] [learning rate: 5.2e+03]\n",
            "[Step 39506/50000] [Progress: 79.01%] [learning rate: 6.2e+03]\n",
            "[Step 39529/50000] [Progress: 79.06%] [learning rate: 5.0e+03]\n",
            "[Step 39556/50000] [Progress: 79.11%] [learning rate: 6.0e+03]\n",
            "[Step 39571/50000] [Time: 332s] [Train Loss: 1.57e-01] [Train Acc: 0.97]\n",
            "[Step 39579/50000] [Progress: 79.16%] [learning rate: 4.9e+03]\n",
            "[Step 39605/50000] [Progress: 79.21%] [learning rate: 5.8e+03]\n",
            "[Step 39629/50000] [Progress: 79.26%] [learning rate: 5.2e+03]\n",
            "[Step 39656/50000] [Progress: 79.31%] [learning rate: 6.2e+03]\n",
            "[Step 39670/50000] [Time: 332s] [Train Loss: 1.57e-01] [Train Acc: 0.97]\n",
            "[Step 39679/50000] [Progress: 79.36%] [learning rate: 5.6e+03]\n",
            "[Step 39703/50000] [Progress: 79.41%] [learning rate: 5.5e+03]\n",
            "[Step 39728/50000] [Progress: 79.46%] [learning rate: 5.4e+03]\n",
            "[Step 39754/50000] [Progress: 79.51%] [learning rate: 5.8e+03]\n",
            "[Step 39769/50000] [Time: 333s] [Train Loss: 1.57e-01] [Train Acc: 0.97]\n",
            "[Step 39778/50000] [Progress: 79.56%] [learning rate: 5.2e+03]\n",
            "[Step 39805/50000] [Progress: 79.61%] [learning rate: 6.2e+03]\n",
            "[Step 39828/50000] [Progress: 79.66%] [learning rate: 5.1e+03]\n",
            "[Step 39854/50000] [Progress: 79.71%] [learning rate: 5.5e+03]\n",
            "[Step 39868/50000] [Time: 334s] [Train Loss: 1.57e-01] [Train Acc: 0.97]\n",
            "[Step 39878/50000] [Progress: 79.76%] [learning rate: 5.4e+03]\n",
            "[Step 39903/50000] [Progress: 79.81%] [learning rate: 5.3e+03]\n",
            "[Step 39928/50000] [Progress: 79.86%] [learning rate: 5.3e+03]\n",
            "[Step 39954/50000] [Progress: 79.91%] [learning rate: 5.7e+03]\n",
            "[Step 39967/50000] [Time: 335s] [Train Loss: 1.56e-01] [Train Acc: 0.97]\n",
            "[Step 39981/50000] [Progress: 79.96%] [learning rate: 6.2e+03]\n",
            "[Step 40005/50000] [Progress: 80.01%] [learning rate: 5.5e+03]\n",
            "[Step 40030/50000] [Progress: 80.06%] [learning rate: 5.4e+03]\n",
            "[Step 40056/50000] [Progress: 80.11%] [learning rate: 5.4e+03]\n",
            "[Step 40066/50000] [Time: 336s] [Train Loss: 1.56e-01] [Train Acc: 0.97]\n",
            "[Step 40081/50000] [Progress: 80.16%] [learning rate: 5.3e+03]\n",
            "[Step 40108/50000] [Progress: 80.22%] [learning rate: 5.7e+03]\n",
            "[Step 40134/50000] [Progress: 80.27%] [learning rate: 6.2e+03]\n",
            "[Step 40158/50000] [Progress: 80.32%] [learning rate: 5.5e+03]\n",
            "[Step 40165/50000] [Time: 336s] [Train Loss: 1.56e-01] [Train Acc: 0.97]\n",
            "[Step 40183/50000] [Progress: 80.37%] [learning rate: 5.5e+03]\n",
            "[Step 40209/50000] [Progress: 80.42%] [learning rate: 5.4e+03]\n",
            "[Step 40234/50000] [Progress: 80.47%] [learning rate: 5.3e+03]\n",
            "[Step 40261/50000] [Progress: 80.52%] [learning rate: 5.7e+03]\n",
            "[Step 40264/50000] [Time: 337s] [Train Loss: 1.55e-01] [Train Acc: 0.97]\n",
            "[Step 40286/50000] [Progress: 80.57%] [learning rate: 5.7e+03]\n",
            "[Step 40312/50000] [Progress: 80.62%] [learning rate: 5.6e+03]\n",
            "[Step 40336/50000] [Progress: 80.67%] [learning rate: 5.5e+03]\n",
            "[Step 40361/50000] [Progress: 80.72%] [learning rate: 5.4e+03]\n",
            "[Step 40363/50000] [Time: 338s] [Train Loss: 1.55e-01] [Train Acc: 0.97]\n",
            "[Step 40387/50000] [Progress: 80.77%] [learning rate: 5.9e+03]\n",
            "[Step 40411/50000] [Progress: 80.82%] [learning rate: 5.2e+03]\n",
            "[Step 40439/50000] [Progress: 80.88%] [learning rate: 6.3e+03]\n",
            "[Step 40462/50000] [Time: 338s] [Train Loss: 1.55e-01] [Train Acc: 0.97]\n",
            "[Step 40463/50000] [Progress: 80.93%] [learning rate: 5.6e+03]\n",
            "[Step 40488/50000] [Progress: 80.98%] [learning rate: 5.5e+03]\n",
            "[Step 40514/50000] [Progress: 81.03%] [learning rate: 5.4e+03]\n",
            "[Step 40539/50000] [Progress: 81.08%] [learning rate: 5.3e+03]\n",
            "[Step 40561/50000] [Time: 339s] [Train Loss: 1.55e-01] [Train Acc: 0.97]\n",
            "[Step 40566/50000] [Progress: 81.13%] [learning rate: 5.8e+03]\n",
            "[Step 40592/50000] [Progress: 81.18%] [learning rate: 5.7e+03]\n",
            "[Step 40618/50000] [Progress: 81.24%] [learning rate: 6.2e+03]\n",
            "[Step 40641/50000] [Progress: 81.28%] [learning rate: 5.0e+03]\n",
            "[Step 40660/50000] [Time: 340s] [Train Loss: 1.54e-01] [Train Acc: 0.97]\n",
            "[Step 40668/50000] [Progress: 81.34%] [learning rate: 6.0e+03]\n",
            "[Step 40691/50000] [Progress: 81.38%] [learning rate: 5.4e+03]\n",
            "[Step 40716/50000] [Progress: 81.43%] [learning rate: 5.8e+03]\n",
            "[Step 40740/50000] [Progress: 81.48%] [learning rate: 5.7e+03]\n",
            "[Step 40759/50000] [Time: 341s] [Train Loss: 1.54e-01] [Train Acc: 0.97]\n",
            "[Step 40765/50000] [Progress: 81.53%] [learning rate: 6.2e+03]\n",
            "[Step 40788/50000] [Progress: 81.58%] [learning rate: 5.1e+03]\n",
            "[Step 40815/50000] [Progress: 81.63%] [learning rate: 6.0e+03]\n",
            "[Step 40838/50000] [Progress: 81.68%] [learning rate: 4.9e+03]\n",
            "[Step 40858/50000] [Time: 342s] [Train Loss: 1.54e-01] [Train Acc: 0.97]\n",
            "[Step 40865/50000] [Progress: 81.73%] [learning rate: 5.8e+03]\n",
            "[Step 40890/50000] [Progress: 81.78%] [learning rate: 5.8e+03]\n",
            "[Step 40916/50000] [Progress: 81.83%] [learning rate: 6.2e+03]\n",
            "[Step 40940/50000] [Progress: 81.88%] [learning rate: 5.6e+03]\n",
            "[Step 40957/50000] [Time: 342s] [Train Loss: 1.54e-01] [Train Acc: 0.97]\n",
            "[Step 40965/50000] [Progress: 81.93%] [learning rate: 5.5e+03]\n",
            "[Step 40991/50000] [Progress: 81.98%] [learning rate: 5.4e+03]\n",
            "[Step 41016/50000] [Progress: 82.03%] [learning rate: 5.3e+03]\n",
            "[Step 41043/50000] [Progress: 82.09%] [learning rate: 5.8e+03]\n",
            "[Step 41056/50000] [Time: 343s] [Train Loss: 1.53e-01] [Train Acc: 0.97]\n",
            "[Step 41069/50000] [Progress: 82.14%] [learning rate: 6.3e+03]\n",
            "[Step 41093/50000] [Progress: 82.19%] [learning rate: 5.6e+03]\n",
            "[Step 41118/50000] [Progress: 82.24%] [learning rate: 5.5e+03]\n",
            "[Step 41144/50000] [Progress: 82.29%] [learning rate: 5.4e+03]\n",
            "[Step 41155/50000] [Time: 344s] [Train Loss: 1.53e-01] [Train Acc: 0.97]\n",
            "[Step 41170/50000] [Progress: 82.34%] [learning rate: 5.9e+03]\n",
            "[Step 41194/50000] [Progress: 82.39%] [learning rate: 5.3e+03]\n",
            "[Step 41221/50000] [Progress: 82.44%] [learning rate: 6.3e+03]\n",
            "[Step 41245/50000] [Progress: 82.49%] [learning rate: 5.6e+03]\n",
            "[Step 41254/50000] [Time: 345s] [Train Loss: 1.53e-01] [Train Acc: 0.97]\n",
            "[Step 41270/50000] [Progress: 82.54%] [learning rate: 5.6e+03]\n",
            "[Step 41296/50000] [Progress: 82.59%] [learning rate: 5.5e+03]\n",
            "[Step 41322/50000] [Progress: 82.64%] [learning rate: 5.9e+03]\n",
            "[Step 41346/50000] [Progress: 82.69%] [learning rate: 5.3e+03]\n",
            "[Step 41353/50000] [Time: 345s] [Train Loss: 1.52e-01] [Train Acc: 0.97]\n",
            "[Step 41372/50000] [Progress: 82.74%] [learning rate: 5.7e+03]\n",
            "[Step 41397/50000] [Progress: 82.79%] [learning rate: 5.7e+03]\n",
            "[Step 41423/50000] [Progress: 82.85%] [learning rate: 5.6e+03]\n",
            "[Step 41449/50000] [Progress: 82.90%] [learning rate: 5.5e+03]\n",
            "[Step 41452/50000] [Time: 346s] [Train Loss: 1.52e-01] [Train Acc: 0.97]\n",
            "[Step 41474/50000] [Progress: 82.95%] [learning rate: 5.4e+03]\n",
            "[Step 41501/50000] [Progress: 83.00%] [learning rate: 5.9e+03]\n",
            "[Step 41527/50000] [Progress: 83.05%] [learning rate: 5.8e+03]\n",
            "[Step 41551/50000] [Time: 347s] [Train Loss: 1.52e-01] [Train Acc: 0.97]\n",
            "[Step 41553/50000] [Progress: 83.11%] [learning rate: 6.3e+03]\n",
            "[Step 41576/50000] [Progress: 83.15%] [learning rate: 5.1e+03]\n",
            "[Step 41603/50000] [Progress: 83.21%] [learning rate: 6.1e+03]\n",
            "[Step 41626/50000] [Progress: 83.25%] [learning rate: 5.4e+03]\n",
            "[Step 41650/50000] [Time: 348s] [Train Loss: 1.52e-01] [Train Acc: 0.97]\n",
            "[Step 41651/50000] [Progress: 83.30%] [learning rate: 5.9e+03]\n",
            "[Step 41675/50000] [Progress: 83.35%] [learning rate: 5.8e+03]\n",
            "[Step 41700/50000] [Progress: 83.40%] [learning rate: 5.7e+03]\n",
            "[Step 41724/50000] [Progress: 83.45%] [learning rate: 5.6e+03]\n",
            "[Step 41749/50000] [Progress: 83.50%] [learning rate: 5.5e+03]\n",
            "[Step 41749/50000] [Time: 348s] [Train Loss: 1.51e-01] [Train Acc: 0.97]\n",
            "[Step 41775/50000] [Progress: 83.55%] [learning rate: 6.0e+03]\n",
            "[Step 41798/50000] [Progress: 83.60%] [learning rate: 5.4e+03]\n",
            "[Step 41824/50000] [Progress: 83.65%] [learning rate: 5.8e+03]\n",
            "[Step 41848/50000] [Time: 349s] [Train Loss: 1.51e-01] [Train Acc: 0.97]\n",
            "[Step 41851/50000] [Progress: 83.70%] [learning rate: 6.3e+03]\n",
            "[Step 41875/50000] [Progress: 83.75%] [learning rate: 5.7e+03]\n",
            "[Step 41900/50000] [Progress: 83.80%] [learning rate: 5.6e+03]\n",
            "[Step 41926/50000] [Progress: 83.85%] [learning rate: 6.0e+03]\n",
            "[Step 41947/50000] [Time: 350s] [Train Loss: 1.51e-01] [Train Acc: 0.97]\n",
            "[Step 41949/50000] [Progress: 83.90%] [learning rate: 5.4e+03]\n",
            "[Step 41975/50000] [Progress: 83.95%] [learning rate: 5.9e+03]\n",
            "[Step 42002/50000] [Progress: 84.00%] [learning rate: 6.3e+03]\n",
            "[Step 42027/50000] [Progress: 84.05%] [learning rate: 5.7e+03]\n",
            "[Step 42046/50000] [Time: 350s] [Train Loss: 1.51e-01] [Train Acc: 0.97]\n",
            "[Step 42053/50000] [Progress: 84.11%] [learning rate: 5.6e+03]\n",
            "[Step 42079/50000] [Progress: 84.16%] [learning rate: 5.5e+03]\n",
            "[Step 42104/50000] [Progress: 84.21%] [learning rate: 5.4e+03]\n",
            "[Step 42129/50000] [Progress: 84.26%] [learning rate: 5.9e+03]\n",
            "[Step 42145/50000] [Time: 351s] [Train Loss: 1.50e-01] [Train Acc: 0.97]\n",
            "[Step 42154/50000] [Progress: 84.31%] [learning rate: 5.8e+03]\n",
            "[Step 42178/50000] [Progress: 84.36%] [learning rate: 5.7e+03]\n",
            "[Step 42203/50000] [Progress: 84.41%] [learning rate: 5.6e+03]\n",
            "[Step 42229/50000] [Progress: 84.46%] [learning rate: 5.5e+03]\n",
            "[Step 42244/50000] [Time: 352s] [Train Loss: 1.50e-01] [Train Acc: 0.97]\n",
            "[Step 42254/50000] [Progress: 84.51%] [learning rate: 5.5e+03]\n",
            "[Step 42281/50000] [Progress: 84.56%] [learning rate: 5.9e+03]\n",
            "[Step 42307/50000] [Progress: 84.61%] [learning rate: 5.8e+03]\n",
            "[Step 42332/50000] [Progress: 84.66%] [learning rate: 5.7e+03]\n",
            "[Step 42343/50000] [Time: 353s] [Train Loss: 1.50e-01] [Train Acc: 0.97]\n",
            "[Step 42358/50000] [Progress: 84.72%] [learning rate: 5.6e+03]\n",
            "[Step 42384/50000] [Progress: 84.77%] [learning rate: 5.6e+03]\n",
            "[Step 42409/50000] [Progress: 84.82%] [learning rate: 5.5e+03]\n",
            "[Step 42436/50000] [Progress: 84.87%] [learning rate: 5.9e+03]\n",
            "[Step 42442/50000] [Time: 353s] [Train Loss: 1.50e-01] [Train Acc: 0.97]\n",
            "[Step 42462/50000] [Progress: 84.92%] [learning rate: 5.8e+03]\n",
            "[Step 42488/50000] [Progress: 84.98%] [learning rate: 6.3e+03]\n",
            "[Step 42511/50000] [Progress: 85.02%] [learning rate: 5.2e+03]\n",
            "[Step 42538/50000] [Progress: 85.08%] [learning rate: 6.1e+03]\n",
            "[Step 42541/50000] [Time: 354s] [Train Loss: 1.49e-01] [Train Acc: 0.97]\n",
            "[Step 42561/50000] [Progress: 85.12%] [learning rate: 5.5e+03]\n",
            "[Step 42586/50000] [Progress: 85.17%] [learning rate: 6.0e+03]\n",
            "[Step 42610/50000] [Progress: 85.22%] [learning rate: 5.9e+03]\n",
            "[Step 42635/50000] [Progress: 85.27%] [learning rate: 5.8e+03]\n",
            "[Step 42640/50000] [Time: 355s] [Train Loss: 1.49e-01] [Train Acc: 0.97]\n",
            "[Step 42659/50000] [Progress: 85.32%] [learning rate: 5.7e+03]\n",
            "[Step 42684/50000] [Progress: 85.37%] [learning rate: 5.6e+03]\n",
            "[Step 42710/50000] [Progress: 85.42%] [learning rate: 6.1e+03]\n",
            "[Step 42733/50000] [Progress: 85.47%] [learning rate: 5.4e+03]\n",
            "[Step 42739/50000] [Time: 356s] [Train Loss: 1.49e-01] [Train Acc: 0.97]\n",
            "[Step 42759/50000] [Progress: 85.52%] [learning rate: 5.9e+03]\n",
            "[Step 42786/50000] [Progress: 85.57%] [learning rate: 6.4e+03]\n",
            "[Step 42808/50000] [Progress: 85.62%] [learning rate: 5.2e+03]\n",
            "[Step 42834/50000] [Progress: 85.67%] [learning rate: 6.2e+03]\n",
            "[Step 42838/50000] [Time: 357s] [Train Loss: 1.49e-01] [Train Acc: 0.97]\n",
            "[Step 42857/50000] [Progress: 85.71%] [learning rate: 5.5e+03]\n",
            "[Step 42882/50000] [Progress: 85.76%] [learning rate: 6.0e+03]\n",
            "[Step 42906/50000] [Progress: 85.81%] [learning rate: 5.4e+03]\n",
            "[Step 42934/50000] [Progress: 85.87%] [learning rate: 7.1e+03]\n",
            "[Step 42937/50000] [Time: 357s] [Train Loss: 1.48e-01] [Train Acc: 0.97]\n",
            "[Step 42955/50000] [Progress: 85.91%] [learning rate: 4.7e+03]\n",
            "[Step 42984/50000] [Progress: 85.97%] [learning rate: 6.2e+03]\n",
            "[Step 43008/50000] [Progress: 86.02%] [learning rate: 5.6e+03]\n",
            "[Step 43033/50000] [Progress: 86.07%] [learning rate: 6.0e+03]\n",
            "[Step 43036/50000] [Time: 358s] [Train Loss: 1.48e-01] [Train Acc: 0.97]\n",
            "[Step 43057/50000] [Progress: 86.11%] [learning rate: 5.4e+03]\n",
            "[Step 43085/50000] [Progress: 86.17%] [learning rate: 6.4e+03]\n",
            "[Step 43110/50000] [Progress: 86.22%] [learning rate: 5.8e+03]\n",
            "[Step 43135/50000] [Time: 359s] [Train Loss: 1.48e-01] [Train Acc: 0.97]\n",
            "[Step 43136/50000] [Progress: 86.27%] [learning rate: 5.7e+03]\n",
            "[Step 43162/50000] [Progress: 86.32%] [learning rate: 5.6e+03]\n",
            "[Step 43187/50000] [Progress: 86.37%] [learning rate: 5.5e+03]\n",
            "[Step 43214/50000] [Progress: 86.43%] [learning rate: 6.0e+03]\n",
            "[Step 43234/50000] [Time: 359s] [Train Loss: 1.48e-01] [Train Acc: 0.97]\n",
            "[Step 43240/50000] [Progress: 86.48%] [learning rate: 5.9e+03]\n",
            "[Step 43264/50000] [Progress: 86.53%] [learning rate: 5.8e+03]\n",
            "[Step 43289/50000] [Progress: 86.58%] [learning rate: 5.7e+03]\n",
            "[Step 43315/50000] [Progress: 86.63%] [learning rate: 5.6e+03]\n",
            "[Step 43333/50000] [Time: 360s] [Train Loss: 1.47e-01] [Train Acc: 0.97]\n",
            "[Step 43340/50000] [Progress: 86.68%] [learning rate: 5.5e+03]\n",
            "[Step 43367/50000] [Progress: 86.73%] [learning rate: 6.0e+03]\n",
            "[Step 43393/50000] [Progress: 86.79%] [learning rate: 5.9e+03]\n",
            "[Step 43419/50000] [Progress: 86.84%] [learning rate: 6.4e+03]\n",
            "[Step 43432/50000] [Time: 361s] [Train Loss: 1.47e-01] [Train Acc: 0.97] [Eval Loss: 5.26e-01] [Eval Acc: 0.77]\n",
            "[Step 43442/50000] [Progress: 86.88%] [learning rate: 5.2e+03]\n",
            "[Step 43469/50000] [Progress: 86.94%] [learning rate: 6.2e+03]\n",
            "[Step 43492/50000] [Progress: 86.98%] [learning rate: 5.6e+03]\n",
            "[Step 43517/50000] [Progress: 87.03%] [learning rate: 6.0e+03]\n",
            "[Step 43531/50000] [Time: 364s] [Train Loss: 1.47e-01] [Train Acc: 0.97]\n",
            "[Step 43541/50000] [Progress: 87.08%] [learning rate: 5.9e+03]\n",
            "[Step 43566/50000] [Progress: 87.13%] [learning rate: 5.8e+03]\n",
            "[Step 43590/50000] [Progress: 87.18%] [learning rate: 5.8e+03]\n",
            "[Step 43615/50000] [Progress: 87.23%] [learning rate: 5.7e+03]\n",
            "[Step 43630/50000] [Time: 364s] [Train Loss: 1.46e-01] [Train Acc: 0.97]\n",
            "[Step 43641/50000] [Progress: 87.28%] [learning rate: 6.1e+03]\n",
            "[Step 43664/50000] [Progress: 87.33%] [learning rate: 5.5e+03]\n",
            "[Step 43690/50000] [Progress: 87.38%] [learning rate: 6.0e+03]\n",
            "[Step 43717/50000] [Progress: 87.43%] [learning rate: 7.1e+03]\n",
            "[Step 43729/50000] [Time: 365s] [Train Loss: 1.46e-01] [Train Acc: 0.98]\n",
            "[Step 43737/50000] [Progress: 87.47%] [learning rate: 4.8e+03]\n",
            "[Step 43765/50000] [Progress: 87.53%] [learning rate: 6.3e+03]\n",
            "[Step 43790/50000] [Progress: 87.58%] [learning rate: 5.6e+03]\n",
            "[Step 43816/50000] [Progress: 87.63%] [learning rate: 6.1e+03]\n",
            "[Step 43828/50000] [Time: 366s] [Train Loss: 1.46e-01] [Train Acc: 0.98]\n",
            "[Step 43840/50000] [Progress: 87.68%] [learning rate: 5.4e+03]\n",
            "[Step 43867/50000] [Progress: 87.73%] [learning rate: 6.5e+03]\n",
            "[Step 43891/50000] [Progress: 87.78%] [learning rate: 5.8e+03]\n",
            "[Step 43916/50000] [Progress: 87.83%] [learning rate: 5.7e+03]\n",
            "[Step 43927/50000] [Time: 367s] [Train Loss: 1.46e-01] [Train Acc: 0.98]\n",
            "[Step 43942/50000] [Progress: 87.88%] [learning rate: 5.6e+03]\n",
            "[Step 43967/50000] [Progress: 87.93%] [learning rate: 5.6e+03]\n",
            "[Step 43994/50000] [Progress: 87.99%] [learning rate: 6.0e+03]\n",
            "[Step 44020/50000] [Progress: 88.04%] [learning rate: 6.5e+03]\n",
            "[Step 44026/50000] [Time: 367s] [Train Loss: 1.45e-01] [Train Acc: 0.98]\n",
            "[Step 44043/50000] [Progress: 88.09%] [learning rate: 5.3e+03]\n",
            "[Step 44069/50000] [Progress: 88.14%] [learning rate: 5.8e+03]\n",
            "[Step 44095/50000] [Progress: 88.19%] [learning rate: 6.2e+03]\n",
            "[Step 44118/50000] [Progress: 88.24%] [learning rate: 5.6e+03]\n",
            "[Step 44125/50000] [Time: 368s] [Train Loss: 1.45e-01] [Train Acc: 0.98]\n",
            "[Step 44143/50000] [Progress: 88.29%] [learning rate: 6.0e+03]\n",
            "[Step 44168/50000] [Progress: 88.34%] [learning rate: 6.0e+03]\n",
            "[Step 44194/50000] [Progress: 88.39%] [learning rate: 5.9e+03]\n",
            "[Step 44218/50000] [Progress: 88.44%] [learning rate: 5.8e+03]\n",
            "[Step 44224/50000] [Time: 369s] [Train Loss: 1.45e-01] [Train Acc: 0.98]\n",
            "[Step 44243/50000] [Progress: 88.49%] [learning rate: 5.7e+03]\n",
            "[Step 44269/50000] [Progress: 88.54%] [learning rate: 6.2e+03]\n",
            "[Step 44293/50000] [Progress: 88.59%] [learning rate: 5.5e+03]\n",
            "[Step 44320/50000] [Progress: 88.64%] [learning rate: 6.6e+03]\n",
            "[Step 44323/50000] [Time: 370s] [Train Loss: 1.45e-01] [Train Acc: 0.98]\n",
            "[Step 44343/50000] [Progress: 88.69%] [learning rate: 5.4e+03]\n",
            "[Step 44369/50000] [Progress: 88.74%] [learning rate: 5.8e+03]\n",
            "[Step 44395/50000] [Progress: 88.79%] [learning rate: 6.3e+03]\n",
            "[Step 44418/50000] [Progress: 88.84%] [learning rate: 5.1e+03]\n",
            "[Step 44422/50000] [Time: 371s] [Train Loss: 1.45e-01] [Train Acc: 0.98]\n",
            "[Step 44445/50000] [Progress: 88.89%] [learning rate: 6.1e+03]\n",
            "[Step 44470/50000] [Progress: 88.94%] [learning rate: 6.0e+03]\n",
            "[Step 44495/50000] [Progress: 88.99%] [learning rate: 6.5e+03]\n",
            "[Step 44518/50000] [Progress: 89.04%] [learning rate: 5.3e+03]\n",
            "[Step 44521/50000] [Time: 371s] [Train Loss: 1.44e-01] [Train Acc: 0.98]\n",
            "[Step 44544/50000] [Progress: 89.09%] [learning rate: 5.7e+03]\n",
            "[Step 44570/50000] [Progress: 89.14%] [learning rate: 6.2e+03]\n",
            "[Step 44593/50000] [Progress: 89.19%] [learning rate: 5.6e+03]\n",
            "[Step 44619/50000] [Progress: 89.24%] [learning rate: 6.0e+03]\n",
            "[Step 44620/50000] [Time: 372s] [Train Loss: 1.44e-01] [Train Acc: 0.98]\n",
            "[Step 44645/50000] [Progress: 89.29%] [learning rate: 7.2e+03]\n",
            "[Step 44666/50000] [Progress: 89.33%] [learning rate: 4.8e+03]\n",
            "[Step 44695/50000] [Progress: 89.39%] [learning rate: 6.3e+03]\n",
            "[Step 44719/50000] [Progress: 89.44%] [learning rate: 5.7e+03]\n",
            "[Step 44719/50000] [Time: 373s] [Train Loss: 1.44e-01] [Train Acc: 0.98]\n",
            "[Step 44744/50000] [Progress: 89.49%] [learning rate: 6.2e+03]\n",
            "[Step 44768/50000] [Progress: 89.54%] [learning rate: 5.5e+03]\n",
            "[Step 44794/50000] [Progress: 89.59%] [learning rate: 6.6e+03]\n",
            "[Step 44817/50000] [Progress: 89.63%] [learning rate: 5.3e+03]\n",
            "[Step 44818/50000] [Time: 373s] [Train Loss: 1.44e-01] [Train Acc: 0.98]\n",
            "[Step 44843/50000] [Progress: 89.69%] [learning rate: 5.8e+03]\n",
            "[Step 44868/50000] [Progress: 89.74%] [learning rate: 5.7e+03]\n",
            "[Step 44894/50000] [Progress: 89.79%] [learning rate: 6.2e+03]\n",
            "[Step 44917/50000] [Time: 374s] [Train Loss: 1.43e-01] [Train Acc: 0.98]\n",
            "[Step 44918/50000] [Progress: 89.84%] [learning rate: 5.5e+03]\n",
            "[Step 44946/50000] [Progress: 89.89%] [learning rate: 6.6e+03]\n",
            "[Step 44970/50000] [Progress: 89.94%] [learning rate: 5.9e+03]\n",
            "[Step 44995/50000] [Progress: 89.99%] [learning rate: 5.8e+03]\n",
            "[Step 45016/50000] [Time: 375s] [Train Loss: 1.43e-01] [Train Acc: 0.98]\n",
            "[Step 45021/50000] [Progress: 90.04%] [learning rate: 5.7e+03]\n",
            "[Step 45047/50000] [Progress: 90.09%] [learning rate: 6.2e+03]\n",
            "[Step 45071/50000] [Progress: 90.14%] [learning rate: 5.6e+03]\n",
            "[Step 45098/50000] [Progress: 90.20%] [learning rate: 6.6e+03]\n",
            "[Step 45115/50000] [Time: 375s] [Train Loss: 1.43e-01] [Train Acc: 0.98]\n",
            "[Step 45121/50000] [Progress: 90.24%] [learning rate: 5.4e+03]\n",
            "[Step 45147/50000] [Progress: 90.29%] [learning rate: 5.8e+03]\n",
            "[Step 45172/50000] [Progress: 90.34%] [learning rate: 5.8e+03]\n",
            "[Step 45198/50000] [Progress: 90.40%] [learning rate: 5.7e+03]\n",
            "[Step 45214/50000] [Time: 376s] [Train Loss: 1.43e-01] [Train Acc: 0.98]\n",
            "[Step 45223/50000] [Progress: 90.45%] [learning rate: 5.6e+03]\n",
            "[Step 45249/50000] [Progress: 90.50%] [learning rate: 6.1e+03]\n",
            "[Step 45275/50000] [Progress: 90.55%] [learning rate: 6.6e+03]\n",
            "[Step 45298/50000] [Progress: 90.60%] [learning rate: 5.3e+03]\n",
            "[Step 45313/50000] [Time: 377s] [Train Loss: 1.42e-01] [Train Acc: 0.98]\n",
            "[Step 45324/50000] [Progress: 90.65%] [learning rate: 5.8e+03]\n",
            "[Step 45349/50000] [Progress: 90.70%] [learning rate: 5.7e+03]\n",
            "[Step 45375/50000] [Progress: 90.75%] [learning rate: 6.2e+03]\n",
            "[Step 45399/50000] [Progress: 90.80%] [learning rate: 6.1e+03]\n",
            "[Step 45412/50000] [Time: 378s] [Train Loss: 1.42e-01] [Train Acc: 0.98]\n",
            "[Step 45424/50000] [Progress: 90.85%] [learning rate: 6.6e+03]\n",
            "[Step 45447/50000] [Progress: 90.89%] [learning rate: 5.4e+03]\n",
            "[Step 45475/50000] [Progress: 90.95%] [learning rate: 6.4e+03]\n",
            "[Step 45499/50000] [Progress: 91.00%] [learning rate: 5.7e+03]\n",
            "[Step 45511/50000] [Time: 378s] [Train Loss: 1.42e-01] [Train Acc: 0.98]\n",
            "[Step 45524/50000] [Progress: 91.05%] [learning rate: 6.2e+03]\n",
            "[Step 45548/50000] [Progress: 91.10%] [learning rate: 5.5e+03]\n",
            "[Step 45575/50000] [Progress: 91.15%] [learning rate: 7.3e+03]\n",
            "[Step 45595/50000] [Progress: 91.19%] [learning rate: 4.9e+03]\n",
            "[Step 45610/50000] [Time: 379s] [Train Loss: 1.42e-01] [Train Acc: 0.98]\n",
            "[Step 45623/50000] [Progress: 91.25%] [learning rate: 6.4e+03]\n",
            "[Step 45648/50000] [Progress: 91.30%] [learning rate: 5.7e+03]\n",
            "[Step 45674/50000] [Progress: 91.35%] [learning rate: 6.2e+03]\n",
            "[Step 45698/50000] [Progress: 91.40%] [learning rate: 5.6e+03]\n",
            "[Step 45709/50000] [Time: 380s] [Train Loss: 1.41e-01] [Train Acc: 0.98]\n",
            "[Step 45726/50000] [Progress: 91.45%] [learning rate: 6.6e+03]\n",
            "[Step 45750/50000] [Progress: 91.50%] [learning rate: 5.9e+03]\n",
            "[Step 45775/50000] [Progress: 91.55%] [learning rate: 5.9e+03]\n",
            "[Step 45801/50000] [Progress: 91.60%] [learning rate: 5.8e+03]\n",
            "[Step 45808/50000] [Time: 381s] [Train Loss: 1.41e-01] [Train Acc: 0.98]\n",
            "[Step 45826/50000] [Progress: 91.65%] [learning rate: 5.7e+03]\n",
            "[Step 45853/50000] [Progress: 91.71%] [learning rate: 6.2e+03]\n",
            "[Step 45879/50000] [Progress: 91.76%] [learning rate: 6.7e+03]\n",
            "[Step 45902/50000] [Progress: 91.80%] [learning rate: 5.4e+03]\n",
            "[Step 45907/50000] [Time: 382s] [Train Loss: 1.41e-01] [Train Acc: 0.98]\n",
            "[Step 45929/50000] [Progress: 91.86%] [learning rate: 6.5e+03]\n",
            "[Step 45952/50000] [Progress: 91.90%] [learning rate: 5.3e+03]\n",
            "[Step 45978/50000] [Progress: 91.96%] [learning rate: 6.3e+03]\n",
            "[Step 46002/50000] [Progress: 92.00%] [learning rate: 5.6e+03]\n",
            "[Step 46006/50000] [Time: 382s] [Train Loss: 1.41e-01] [Train Acc: 0.98]\n",
            "[Step 46029/50000] [Progress: 92.06%] [learning rate: 6.7e+03]\n",
            "[Step 46052/50000] [Progress: 92.10%] [learning rate: 6.0e+03]\n",
            "[Step 46076/50000] [Progress: 92.15%] [learning rate: 5.9e+03]\n",
            "[Step 46101/50000] [Progress: 92.20%] [learning rate: 5.8e+03]\n",
            "[Step 46105/50000] [Time: 383s] [Train Loss: 1.40e-01] [Train Acc: 0.98]\n",
            "[Step 46127/50000] [Progress: 92.25%] [learning rate: 6.3e+03]\n",
            "[Step 46151/50000] [Progress: 92.30%] [learning rate: 5.6e+03]\n",
            "[Step 46178/50000] [Progress: 92.36%] [learning rate: 6.1e+03]\n",
            "[Step 46203/50000] [Progress: 92.41%] [learning rate: 6.0e+03]\n",
            "[Step 46205/50000] [Time: 384s] [Train Loss: 1.40e-01] [Train Acc: 0.98]\n",
            "[Step 46229/50000] [Progress: 92.46%] [learning rate: 5.9e+03]\n",
            "[Step 46253/50000] [Progress: 92.51%] [learning rate: 5.8e+03]\n",
            "[Step 46278/50000] [Progress: 92.56%] [learning rate: 5.8e+03]\n",
            "[Step 46303/50000] [Progress: 92.61%] [learning rate: 5.7e+03]\n",
            "[Step 46305/50000] [Time: 384s] [Train Loss: 1.40e-01] [Train Acc: 0.98]\n",
            "[Step 46329/50000] [Progress: 92.66%] [learning rate: 6.1e+03]\n",
            "[Step 46356/50000] [Progress: 92.71%] [learning rate: 6.7e+03]\n",
            "[Step 46380/50000] [Progress: 92.76%] [learning rate: 6.0e+03]\n",
            "[Step 46405/50000] [Progress: 92.81%] [learning rate: 5.9e+03]\n",
            "[Step 46405/50000] [Time: 385s] [Train Loss: 1.40e-01] [Train Acc: 0.98]\n",
            "[Step 46431/50000] [Progress: 92.86%] [learning rate: 6.4e+03]\n",
            "[Step 46454/50000] [Progress: 92.91%] [learning rate: 5.7e+03]\n",
            "[Step 46480/50000] [Progress: 92.96%] [learning rate: 6.2e+03]\n",
            "[Step 46505/50000] [Time: 386s] [Train Loss: 1.39e-01] [Train Acc: 0.98]\n",
            "[Step 46507/50000] [Progress: 93.01%] [learning rate: 6.7e+03]\n",
            "[Step 46531/50000] [Progress: 93.06%] [learning rate: 6.0e+03]\n",
            "[Step 46556/50000] [Progress: 93.11%] [learning rate: 5.9e+03]\n",
            "[Step 46582/50000] [Progress: 93.16%] [learning rate: 5.8e+03]\n",
            "[Step 46605/50000] [Time: 387s] [Train Loss: 1.39e-01] [Train Acc: 0.98]\n",
            "[Step 46607/50000] [Progress: 93.21%] [learning rate: 5.7e+03]\n",
            "[Step 46634/50000] [Progress: 93.27%] [learning rate: 6.2e+03]\n",
            "[Step 46660/50000] [Progress: 93.32%] [learning rate: 6.7e+03]\n",
            "[Step 46683/50000] [Progress: 93.37%] [learning rate: 5.5e+03]\n",
            "[Step 46705/50000] [Time: 387s] [Train Loss: 1.39e-01] [Train Acc: 0.98]\n",
            "[Step 46709/50000] [Progress: 93.42%] [learning rate: 5.9e+03]\n",
            "[Step 46733/50000] [Progress: 93.47%] [learning rate: 5.8e+03]\n",
            "[Step 46758/50000] [Progress: 93.52%] [learning rate: 6.3e+03]\n",
            "[Step 46782/50000] [Progress: 93.56%] [learning rate: 5.7e+03]\n",
            "[Step 46805/50000] [Time: 388s] [Train Loss: 1.39e-01] [Train Acc: 0.98]\n",
            "[Step 46809/50000] [Progress: 93.62%] [learning rate: 6.8e+03]\n",
            "[Step 46832/50000] [Progress: 93.66%] [learning rate: 5.5e+03]\n",
            "[Step 46858/50000] [Progress: 93.72%] [learning rate: 6.0e+03]\n",
            "[Step 46882/50000] [Progress: 93.76%] [learning rate: 5.9e+03]\n",
            "[Step 46905/50000] [Time: 389s] [Train Loss: 1.39e-01] [Train Acc: 0.98]\n",
            "[Step 46907/50000] [Progress: 93.81%] [learning rate: 6.4e+03]\n",
            "[Step 46930/50000] [Progress: 93.86%] [learning rate: 5.7e+03]\n",
            "[Step 46956/50000] [Progress: 93.91%] [learning rate: 6.8e+03]\n",
            "[Step 46979/50000] [Progress: 93.96%] [learning rate: 5.5e+03]\n",
            "[Step 47005/50000] [Progress: 94.01%] [learning rate: 6.0e+03]\n",
            "[Step 47005/50000] [Time: 390s] [Train Loss: 1.38e-01] [Train Acc: 0.98]\n",
            "[Step 47029/50000] [Progress: 94.06%] [learning rate: 5.9e+03]\n",
            "[Step 47054/50000] [Progress: 94.11%] [learning rate: 5.8e+03]\n",
            "[Step 47079/50000] [Progress: 94.16%] [learning rate: 6.3e+03]\n",
            "[Step 47103/50000] [Progress: 94.21%] [learning rate: 5.6e+03]\n",
            "[Step 47105/50000] [Time: 390s] [Train Loss: 1.38e-01] [Train Acc: 0.98]\n",
            "[Step 47130/50000] [Progress: 94.26%] [learning rate: 6.7e+03]\n",
            "[Step 47154/50000] [Progress: 94.31%] [learning rate: 6.0e+03]\n",
            "[Step 47179/50000] [Progress: 94.36%] [learning rate: 5.9e+03]\n",
            "[Step 47205/50000] [Progress: 94.41%] [learning rate: 5.8e+03]\n",
            "[Step 47205/50000] [Time: 391s] [Train Loss: 1.38e-01] [Train Acc: 0.98]\n",
            "[Step 47230/50000] [Progress: 94.46%] [learning rate: 5.7e+03]\n",
            "[Step 47255/50000] [Progress: 94.51%] [learning rate: 6.2e+03]\n",
            "[Step 47282/50000] [Progress: 94.56%] [learning rate: 7.4e+03]\n",
            "[Step 47305/50000] [Progress: 94.61%] [learning rate: 6.0e+03]\n",
            "[Step 47305/50000] [Time: 392s] [Train Loss: 1.38e-01] [Train Acc: 0.98]\n",
            "[Step 47330/50000] [Progress: 94.66%] [learning rate: 5.9e+03]\n",
            "[Step 47356/50000] [Progress: 94.71%] [learning rate: 6.4e+03]\n",
            "[Step 47379/50000] [Progress: 94.76%] [learning rate: 5.8e+03]\n",
            "[Step 47405/50000] [Progress: 94.81%] [learning rate: 6.2e+03]\n",
            "[Step 47405/50000] [Time: 393s] [Train Loss: 1.37e-01] [Train Acc: 0.98]\n",
            "[Step 47431/50000] [Progress: 94.86%] [learning rate: 6.8e+03]\n",
            "[Step 47454/50000] [Progress: 94.91%] [learning rate: 5.5e+03]\n",
            "[Step 47480/50000] [Progress: 94.96%] [learning rate: 6.0e+03]\n",
            "[Step 47504/50000] [Progress: 95.01%] [learning rate: 5.9e+03]\n",
            "[Step 47505/50000] [Time: 395s] [Train Loss: 1.37e-01] [Train Acc: 0.98]\n",
            "[Step 47529/50000] [Progress: 95.06%] [learning rate: 6.4e+03]\n",
            "[Step 47553/50000] [Progress: 95.11%] [learning rate: 5.7e+03]\n",
            "[Step 47581/50000] [Progress: 95.16%] [learning rate: 6.8e+03]\n",
            "[Step 47605/50000] [Progress: 95.21%] [learning rate: 6.1e+03]\n",
            "[Step 47605/50000] [Time: 395s] [Train Loss: 1.37e-01] [Train Acc: 0.98]\n",
            "[Step 47630/50000] [Progress: 95.26%] [learning rate: 6.0e+03]\n",
            "[Step 47656/50000] [Progress: 95.31%] [learning rate: 5.9e+03]\n",
            "[Step 47681/50000] [Progress: 95.36%] [learning rate: 5.8e+03]\n",
            "[Step 47705/50000] [Time: 396s] [Train Loss: 1.37e-01] [Train Acc: 0.98]\n",
            "[Step 47708/50000] [Progress: 95.42%] [learning rate: 6.3e+03]\n",
            "[Step 47734/50000] [Progress: 95.47%] [learning rate: 6.2e+03]\n",
            "[Step 47760/50000] [Progress: 95.52%] [learning rate: 6.7e+03]\n",
            "[Step 47783/50000] [Progress: 95.57%] [learning rate: 5.5e+03]\n",
            "[Step 47805/50000] [Time: 397s] [Train Loss: 1.36e-01] [Train Acc: 0.98]\n",
            "[Step 47810/50000] [Progress: 95.62%] [learning rate: 6.5e+03]\n",
            "[Step 47833/50000] [Progress: 95.67%] [learning rate: 5.8e+03]\n",
            "[Step 47858/50000] [Progress: 95.72%] [learning rate: 6.3e+03]\n",
            "[Step 47882/50000] [Progress: 95.76%] [learning rate: 6.2e+03]\n",
            "[Step 47905/50000] [Time: 397s] [Train Loss: 1.36e-01] [Train Acc: 0.98]\n",
            "[Step 47907/50000] [Progress: 95.81%] [learning rate: 6.1e+03]\n",
            "[Step 47931/50000] [Progress: 95.86%] [learning rate: 6.1e+03]\n",
            "[Step 47956/50000] [Progress: 95.91%] [learning rate: 6.0e+03]\n",
            "[Step 47982/50000] [Progress: 95.96%] [learning rate: 6.5e+03]\n",
            "[Step 48005/50000] [Progress: 96.01%] [learning rate: 5.8e+03]\n",
            "[Step 48005/50000] [Time: 398s] [Train Loss: 1.36e-01] [Train Acc: 0.98]\n",
            "[Step 48031/50000] [Progress: 96.06%] [learning rate: 6.3e+03]\n",
            "[Step 48056/50000] [Progress: 96.11%] [learning rate: 6.8e+03]\n",
            "[Step 48079/50000] [Progress: 96.16%] [learning rate: 5.5e+03]\n",
            "[Step 48105/50000] [Time: 399s] [Train Loss: 1.36e-01] [Train Acc: 0.98]\n",
            "[Step 48106/50000] [Progress: 96.21%] [learning rate: 6.6e+03]\n",
            "[Step 48129/50000] [Progress: 96.26%] [learning rate: 5.4e+03]\n",
            "[Step 48156/50000] [Progress: 96.31%] [learning rate: 6.4e+03]\n",
            "[Step 48181/50000] [Progress: 96.36%] [learning rate: 6.3e+03]\n",
            "[Step 48205/50000] [Time: 400s] [Train Loss: 1.36e-01] [Train Acc: 0.98]\n",
            "[Step 48207/50000] [Progress: 96.41%] [learning rate: 6.8e+03]\n",
            "[Step 48231/50000] [Progress: 96.46%] [learning rate: 6.1e+03]\n",
            "[Step 48256/50000] [Progress: 96.51%] [learning rate: 6.0e+03]\n",
            "[Step 48282/50000] [Progress: 96.56%] [learning rate: 5.9e+03]\n",
            "[Step 48305/50000] [Time: 400s] [Train Loss: 1.35e-01] [Train Acc: 0.98]\n",
            "[Step 48307/50000] [Progress: 96.61%] [learning rate: 5.8e+03]\n",
            "[Step 48334/50000] [Progress: 96.67%] [learning rate: 6.3e+03]\n",
            "[Step 48360/50000] [Progress: 96.72%] [learning rate: 6.8e+03]\n",
            "[Step 48383/50000] [Progress: 96.77%] [learning rate: 5.6e+03]\n",
            "[Step 48405/50000] [Time: 401s] [Train Loss: 1.35e-01] [Train Acc: 0.98] [Eval Loss: 5.35e-01] [Eval Acc: 0.77]\n",
            "[Step 48409/50000] [Progress: 96.82%] [learning rate: 6.0e+03]\n",
            "[Step 48433/50000] [Progress: 96.87%] [learning rate: 6.0e+03]\n",
            "[Step 48458/50000] [Progress: 96.92%] [learning rate: 6.4e+03]\n",
            "[Step 48482/50000] [Progress: 96.96%] [learning rate: 5.8e+03]\n",
            "[Step 48505/50000] [Time: 403s] [Train Loss: 1.35e-01] [Train Acc: 0.98]\n",
            "[Step 48509/50000] [Progress: 97.02%] [learning rate: 6.9e+03]\n",
            "[Step 48532/50000] [Progress: 97.06%] [learning rate: 6.2e+03]\n",
            "[Step 48556/50000] [Progress: 97.11%] [learning rate: 6.1e+03]\n",
            "[Step 48581/50000] [Progress: 97.16%] [learning rate: 6.0e+03]\n",
            "[Step 48605/50000] [Time: 404s] [Train Loss: 1.35e-01] [Train Acc: 0.98]\n",
            "[Step 48607/50000] [Progress: 97.21%] [learning rate: 6.5e+03]\n",
            "[Step 48631/50000] [Progress: 97.26%] [learning rate: 5.8e+03]\n",
            "[Step 48658/50000] [Progress: 97.32%] [learning rate: 6.9e+03]\n",
            "[Step 48681/50000] [Progress: 97.36%] [learning rate: 6.2e+03]\n",
            "[Step 48705/50000] [Progress: 97.41%] [learning rate: 6.1e+03]\n",
            "[Step 48705/50000] [Time: 405s] [Train Loss: 1.34e-01] [Train Acc: 0.98]\n",
            "[Step 48730/50000] [Progress: 97.46%] [learning rate: 6.0e+03]\n",
            "[Step 48756/50000] [Progress: 97.51%] [learning rate: 6.5e+03]\n",
            "[Step 48780/50000] [Progress: 97.56%] [learning rate: 5.8e+03]\n",
            "[Step 48805/50000] [Time: 406s] [Train Loss: 1.34e-01] [Train Acc: 0.98]\n",
            "[Step 48807/50000] [Progress: 97.61%] [learning rate: 6.3e+03]\n",
            "[Step 48832/50000] [Progress: 97.66%] [learning rate: 6.2e+03]\n",
            "[Step 48858/50000] [Progress: 97.72%] [learning rate: 6.1e+03]\n",
            "[Step 48882/50000] [Progress: 97.76%] [learning rate: 6.0e+03]\n",
            "[Step 48905/50000] [Time: 406s] [Train Loss: 1.34e-01] [Train Acc: 0.98]\n",
            "[Step 48907/50000] [Progress: 97.81%] [learning rate: 5.9e+03]\n",
            "[Step 48932/50000] [Progress: 97.86%] [learning rate: 5.9e+03]\n",
            "[Step 48957/50000] [Progress: 97.91%] [learning rate: 6.3e+03]\n",
            "[Step 48983/50000] [Progress: 97.97%] [learning rate: 7.6e+03]\n",
            "[Step 49003/50000] [Progress: 98.01%] [learning rate: 5.1e+03]\n",
            "[Step 49005/50000] [Time: 407s] [Train Loss: 1.34e-01] [Train Acc: 0.98]\n",
            "[Step 49031/50000] [Progress: 98.06%] [learning rate: 6.7e+03]\n",
            "[Step 49056/50000] [Progress: 98.11%] [learning rate: 6.0e+03]\n",
            "[Step 49082/50000] [Progress: 98.16%] [learning rate: 6.5e+03]\n",
            "[Step 49105/50000] [Time: 408s] [Train Loss: 1.34e-01] [Train Acc: 0.98]\n",
            "[Step 49106/50000] [Progress: 98.21%] [learning rate: 5.8e+03]\n",
            "[Step 49133/50000] [Progress: 98.27%] [learning rate: 6.9e+03]\n",
            "[Step 49157/50000] [Progress: 98.31%] [learning rate: 6.2e+03]\n",
            "[Step 49182/50000] [Progress: 98.36%] [learning rate: 6.1e+03]\n",
            "[Step 49205/50000] [Time: 409s] [Train Loss: 1.33e-01] [Train Acc: 0.98]\n",
            "[Step 49208/50000] [Progress: 98.42%] [learning rate: 6.0e+03]\n",
            "[Step 49234/50000] [Progress: 98.47%] [learning rate: 6.5e+03]\n",
            "[Step 49258/50000] [Progress: 98.52%] [learning rate: 5.8e+03]\n",
            "[Step 49284/50000] [Progress: 98.57%] [learning rate: 6.9e+03]\n",
            "[Step 49305/50000] [Time: 409s] [Train Loss: 1.33e-01] [Train Acc: 0.98]\n",
            "[Step 49307/50000] [Progress: 98.61%] [learning rate: 5.6e+03]\n",
            "[Step 49334/50000] [Progress: 98.67%] [learning rate: 6.7e+03]\n",
            "[Step 49357/50000] [Progress: 98.71%] [learning rate: 6.0e+03]\n",
            "[Step 49382/50000] [Progress: 98.76%] [learning rate: 5.9e+03]\n",
            "[Step 49405/50000] [Time: 410s] [Train Loss: 1.33e-01] [Train Acc: 0.98]\n",
            "[Step 49409/50000] [Progress: 98.82%] [learning rate: 6.4e+03]\n",
            "[Step 49435/50000] [Progress: 98.87%] [learning rate: 6.3e+03]\n",
            "[Step 49459/50000] [Progress: 98.92%] [learning rate: 6.2e+03]\n",
            "[Step 49484/50000] [Progress: 98.97%] [learning rate: 6.1e+03]\n",
            "[Step 49505/50000] [Time: 411s] [Train Loss: 1.33e-01] [Train Acc: 0.98]\n",
            "[Step 49510/50000] [Progress: 99.02%] [learning rate: 6.0e+03]\n",
            "[Step 49535/50000] [Progress: 99.07%] [learning rate: 6.0e+03]\n",
            "[Step 49562/50000] [Progress: 99.12%] [learning rate: 6.5e+03]\n",
            "[Step 49588/50000] [Progress: 99.18%] [learning rate: 6.4e+03]\n",
            "[Step 49605/50000] [Time: 411s] [Train Loss: 1.32e-01] [Train Acc: 0.98]\n",
            "[Step 49614/50000] [Progress: 99.23%] [learning rate: 6.9e+03]\n",
            "[Step 49637/50000] [Progress: 99.27%] [learning rate: 5.6e+03]\n",
            "[Step 49664/50000] [Progress: 99.33%] [learning rate: 6.7e+03]\n",
            "[Step 49687/50000] [Progress: 99.37%] [learning rate: 6.0e+03]\n",
            "[Step 49705/50000] [Time: 412s] [Train Loss: 1.32e-01] [Train Acc: 0.98]\n",
            "[Step 49712/50000] [Progress: 99.42%] [learning rate: 6.5e+03]\n",
            "[Step 49736/50000] [Progress: 99.47%] [learning rate: 5.8e+03]\n",
            "[Step 49763/50000] [Progress: 99.53%] [learning rate: 6.9e+03]\n",
            "[Step 49787/50000] [Progress: 99.57%] [learning rate: 6.2e+03]\n",
            "[Step 49805/50000] [Time: 413s] [Train Loss: 1.32e-01] [Train Acc: 0.98]\n",
            "[Step 49812/50000] [Progress: 99.62%] [learning rate: 6.1e+03]\n",
            "[Step 49838/50000] [Progress: 99.68%] [learning rate: 6.6e+03]\n",
            "[Step 49861/50000] [Progress: 99.72%] [learning rate: 5.9e+03]\n",
            "[Step 49887/50000] [Progress: 99.77%] [learning rate: 6.4e+03]\n",
            "[Step 49905/50000] [Time: 414s] [Train Loss: 1.32e-01] [Train Acc: 0.98]\n",
            "[Step 49914/50000] [Progress: 99.83%] [learning rate: 7.6e+03]\n",
            "[Step 49934/50000] [Progress: 99.87%] [learning rate: 5.1e+03]\n",
            "[Step 49962/50000] [Progress: 99.92%] [learning rate: 6.7e+03]\n",
            "[Step 49987/50000] [Progress: 99.97%] [learning rate: 6.0e+03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "def load_results(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        data = torch.load(f, weights_only=False)\n",
        "    args = data.get('args', None)\n",
        "    results = data.get('results', None)\n",
        "\n",
        "    if results is None:\n",
        "        print(f\"No results found in {filename}\")\n",
        "        return None, None\n",
        "\n",
        "    if 'init_kernel' in results:\n",
        "        dynamics = results['init_kernel'].get('dynamics', [])\n",
        "        final_results = results['init_kernel']\n",
        "    else:\n",
        "        print(f\"No 'init_kernel' key found in {filename}\")\n",
        "        return None, None\n",
        "\n",
        "    return args, final_results, dynamics\n",
        "\n",
        "def plot_training_results(args, dynamics):\n",
        "    if args is None or dynamics is None:\n",
        "        print(\"No data to plot.\")\n",
        "        return\n",
        "\n",
        "    steps = [state['step'] for state in dynamics]\n",
        "    train_losses = [state['train']['loss'] for state in dynamics]\n",
        "    train_accuracies = [state['train']['accuracy'] for state in dynamics]\n",
        "\n",
        "    plt.figure(figsize=(9, 5))\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(steps, train_losses, label='Train Loss', color='blue')\n",
        "    if args.track_test_metrics:\n",
        "        test_steps = [state['step'] for state in dynamics if state['test']['loss'] is not None]\n",
        "        test_losses = [state['test']['loss'] for state in dynamics if state['test']['loss'] is not None]\n",
        "        plt.plot(test_steps, test_losses, label='Test Loss', color='red')\n",
        "    plt.xlabel('Step')\n",
        "    # plt.xscale('log')\n",
        "    # plt.yscale('log')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(steps, train_accuracies, label='Train Accuracy', color='blue')\n",
        "    if args.track_test_metrics:\n",
        "        test_steps = [state['step'] for state in dynamics if state['test']['accuracy'] is not None]\n",
        "        test_accuracies = [state['test']['accuracy'] for state in dynamics if state['test']['accuracy'] is not None]\n",
        "        plt.plot(test_steps, test_accuracies, label='Test Accuracy', color='red')\n",
        "    plt.xlabel('Step')\n",
        "    # plt.xscale('log')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# テストとトレーニングの出力とラベルの最初の100個を表示する関数\n",
        "def print_outputs_labels(final_results, num_samples=100):\n",
        "    # Training data display\n",
        "    if final_results is None or 'train' not in final_results:\n",
        "        print(\"No train results found in the final results.\")\n",
        "    else:\n",
        "        train_outputs = final_results['train']['outputs']\n",
        "        train_labels = final_results['train']['labels']\n",
        "\n",
        "        if train_outputs is not None and train_labels is not None:\n",
        "            print(f\"\\nFirst {num_samples} Train Outputs:\")\n",
        "            print(train_outputs[:num_samples])\n",
        "\n",
        "            print(f\"\\nFirst {num_samples} Train Labels:\")\n",
        "            print(train_labels[:num_samples])\n",
        "        else:\n",
        "            print(\"Train outputs or labels not found.\")\n",
        "\n",
        "    # Test data display\n",
        "    if final_results is None or 'test' not in final_results:\n",
        "        print(\"No test results found in the final results.\")\n",
        "    else:\n",
        "        test_outputs = final_results['test']['outputs']\n",
        "        test_labels = final_results['test']['labels']\n",
        "\n",
        "        if test_outputs is not None and test_labels is not None:\n",
        "            print(f\"\\nFirst {num_samples} Test Outputs:\")\n",
        "            print(test_outputs[:num_samples])\n",
        "\n",
        "            print(f\"\\nFirst {num_samples} Test Labels:\")\n",
        "            print(test_labels[:num_samples])\n",
        "        else:\n",
        "            print(\"Test outputs or labels not found.\")\n",
        "\n",
        "filename = 'results.pkl'\n",
        "args, final_results, dynamics = load_results(filename)\n",
        "\n",
        "\n",
        "plot_training_results(args, dynamics)\n",
        "\n",
        "# トレーニングとテスト出力とラベルの最初の100個を表示\n",
        "print_outputs_labels(final_results, num_samples=100)\n",
        "\n",
        "\n",
        "# Calculate and display final test accuracy\n",
        "if final_results is not None and 'test' in final_results:\n",
        "    test_outputs = final_results['test']['outputs']\n",
        "    test_labels = final_results['test']['labels']\n",
        "    if test_outputs is not None and test_labels is not None:\n",
        "        test_preds = torch.sigmoid(test_outputs) > 0.5\n",
        "        test_accuracy = (test_preds.int() == test_labels.int()).float().mean().item()\n",
        "        print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n",
        "    else:\n",
        "        print(\"Test outputs or labels not found.\")\n",
        "else:\n",
        "    print(\"No test results found in the final results.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "busmySOVucH0",
        "outputId": "0f458329-4b8f-46ec-9ec6-0bd3cfbd995f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First 100 Train Outputs:\n",
            "tensor([ 4.3608,  3.0876, -3.6204,  4.7701,  1.6177, -2.3560, -1.6627, -0.6476,\n",
            "        -0.0862,  2.9219,  4.1155,  6.1505,  2.0947, -2.9837, -1.6973,  0.8027,\n",
            "        -3.3366,  3.1938, -1.4903,  3.4511,  1.9733, -7.1531,  5.9211,  4.3814,\n",
            "        -1.3333,  1.5393,  6.8501,  5.3228,  2.6696,  3.4502,  3.3537, -5.0362,\n",
            "         2.2694,  1.6062, -2.4426,  1.8086,  4.8716, -3.3782,  1.4697,  1.5617,\n",
            "        -2.2715,  2.3956, -2.0794, -1.6324, -5.6512, -2.5626,  5.5744,  0.1727,\n",
            "        -5.0574,  6.7551, -4.1601, -0.0989, -5.2585,  4.5904, -2.9573,  1.6531,\n",
            "         1.7166, -0.3993,  2.7776, -3.6832, -0.1788, -1.7351,  1.9970,  5.2168,\n",
            "        -3.5106, -4.4169,  6.4136, -1.7332, -8.5486,  0.7694, -4.8700,  8.1185,\n",
            "         2.1177,  3.5342,  1.4491,  0.2521,  4.4976,  7.3665,  2.6435,  2.3864,\n",
            "        -4.7190,  3.7756,  2.6326,  2.1277,  2.9645,  4.5208, -5.1278,  3.5505,\n",
            "         5.3586, -6.6160,  3.7203,  4.8991,  6.6004, -3.1968,  6.1535, -2.2456,\n",
            "        -1.8547, -0.8579,  3.1523, -6.3581])\n",
            "\n",
            "First 100 Train Labels:\n",
            "tensor([1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
            "        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
            "        1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
            "        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
            "        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
            "        1., 1., 1., 0., 1., 0., 0., 0., 1., 0.])\n",
            "\n",
            "First 100 Test Outputs:\n",
            "tensor([ 0.4864,  1.5325, -7.8903, -1.8447, -1.9054, -3.2085, -1.4838,  2.5991,\n",
            "         2.8214, -1.8870, -4.4383,  1.1636,  2.6992,  6.7939,  4.9027,  4.6564,\n",
            "         4.3060,  2.0350,  5.0581, -3.8775, -0.0544,  0.9139,  1.0828, -4.8313,\n",
            "        -1.4606, -0.3445, -3.9115, -0.6122, -1.3524,  3.8292,  4.1445, -1.7646,\n",
            "         6.7597,  1.3923,  1.3520,  2.9589,  2.1256, -5.6783, -2.4122, -1.3124,\n",
            "         6.4886, -1.5440,  7.3454,  5.0420,  2.7052,  4.6265,  0.2346,  3.2671,\n",
            "         2.5553,  2.7259, -0.0801,  1.2950,  3.9679,  4.1274, -5.6791,  5.3617,\n",
            "        -4.8908,  1.9402, -1.2276,  2.0081,  3.9700, -1.7448, -5.5141,  7.3647,\n",
            "         0.1492,  0.9947,  1.3893,  0.0692,  3.4807, -0.8419,  1.5442, -0.6486,\n",
            "         0.8674,  0.4439,  5.7843,  2.6664,  3.2780,  2.9794,  1.9543,  0.0697,\n",
            "        -0.3106,  4.8821, -0.3949,  4.8861,  0.4193, -1.0347,  2.1591, -0.8132,\n",
            "        -2.3337,  4.0226,  1.8874,  4.0696,  4.5837,  3.3260,  1.5470, -3.1695,\n",
            "        -0.5486,  0.5326,  0.3307,  4.2177])\n",
            "\n",
            "First 100 Test Labels:\n",
            "tensor([1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
            "        1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
            "        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
            "        1., 1., 1., 1., 0., 0., 0., 1., 0., 1.])\n",
            "Final Test Accuracy: 0.7689\n"
          ]
        }
      ]
    }
  ]
}